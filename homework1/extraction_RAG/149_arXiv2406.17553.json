{
    "S5.T1.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S5.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S5.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.1.2.1\">F1</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T1.1.2.1.1\">GPT-4</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T1.1.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.2.1.2.1\">0.39</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T1.1.3.2.1\">Llama-3-70b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.3.2.2\">0.33</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T1.1.4.3.1\">Llama-3-8b</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.4.3.2\">0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T1.1.5.4.1\">Llama-3-8b (fine-tuned)</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T1.1.5.4.2\">0.19</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\" id=\"S5.T1.1.6.5.1\">BAP (fine-tuned)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S5.T1.1.6.5.2\">0.21</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1: Micro-Average F1-score for the builder action prediction task. The BAP (fine-tuned) model results are reported for H2 in game history and with 4x data augmentation (Jayannavar et al., 2020)",
        "footnotes": [],
        "references": [
            "The results compared to the baseline Builder Action Prediction (BAP) model by Jayannavar et al. (2020), are presented in Table 1. GPT-4 achieved the best result (0.390.390.390.39) closely followed by Llama-3-70b (0.330.330.330.33). The fine-tuned version of Llama-3-8b showed a ∼6%similar-toabsentpercent6\\sim 6\\%∼ 6 % improvement over the vanilla version. Even though GPT-4 significantly outperforms the fine-tuned baseline, the upper bound for this task remains low. To understand this, we analysed the dialogues and identified references to spatial relations, real-world/geometric shapes, and anaphora. We then show how the GPT-4’s performance in these categories. The performance of other models is discussed in Section C in the Appendix. Additionally, we identified two more factors complicating the interpretation of architect utterances, which may further impact action prediction.",
            "This fine-tuned model is then used for testing on the test set and is indicated as the Llama-3-8b (fine-tuned) model in Table 1. Compared to the baseline (pre-trained) model, the fine-tuned model shows an enhancement of ∼6%similar-toabsentpercent6\\sim 6\\%∼ 6 % in the F1-score. This improvement, although marginal, indicates a potential to improve the model’s ability for the action prediction task."
        ]
    },
    "A3.T2.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A3.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A3.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T2.1.1.1.1.1\">Prompt</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A3.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A3.T2.1.1.1.2.1\">F1</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A3.T2.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T2.1.2.1.1\">System Info + Env Info + Task Info + Context Info (Zero Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A3.T2.1.2.1.2\">0.15</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.3.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.3.2.1\">System Info + Env Info + Task Info + Context Info (One Sample) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.3.2.2\">0.17</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.4.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.4.3.1\">System Info + Env Info + Task Info + Context Info (Two Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.4.3.2\">0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.5.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.5.4.1\">System Info + Env Info + Task Info + Context Info (Three Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.5.4.2\">0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.6.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.6.5.1\">System Info + Env Info + Task Info + Context Info (Four Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.6.5.2\">0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.7.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.7.6.1\">System Info + Env Info + Task Info + Context Info (Five Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.7.6.2\">0.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.8.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.8.7.1\">Env Info + Task Info + Context Info (Three Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.8.7.2\">0.19</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.9.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.9.8.1\">System Info + Task Info + Context Info (Three Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.9.8.2\">0.17</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.10.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.10.9.1\">System Info + Env Info + Context Info (Three Samples) + Other Info</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.10.9.2\">0.17</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A3.T2.1.11.10\">\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.11.10.1\">System Info + Env Info + Context Info (Three Samples)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A3.T2.1.11.10.2\">0.17</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2: Ablation study for the number of in-context examples and components of the prompt structre on validation split of the Minecraft dataset using Llama-3-8b.",
        "footnotes": [],
        "references": [
            "We investigate how the building blocks of the prompt structure shown in Figure 3 impact overall task performance. Using the validation set of the Minecraft Dialogue dataset for our ablation study, we observe that the prompt structure with all components is optimal for the action prediction task and the LLMs in our experiments, as demonstrated in Table 2. Specifically, omitting in-context examples results in poor performance, while excluding environment information reduced the score slightly. Consequently, we use the prompt featuring all components with three in-context examples to ensure the best performance."
        ]
    }
}