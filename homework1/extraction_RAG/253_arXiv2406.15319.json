{
    "A1.EGx1": {
        "table": "<table class=\"ltx_equationgroup ltx_eqn_align ltx_eqn_table\" id=\"A1.EGx1\">\n<tbody id=\"S2.Ex1\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math alttext=\"\\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.Ex1.m1.4\"><semantics id=\"S2.Ex1.m1.4a\"><mrow id=\"S2.Ex1.m1.4.5\" xref=\"S2.Ex1.m1.4.5.cmml\"><mrow id=\"S2.Ex1.m1.4.5.2\" xref=\"S2.Ex1.m1.4.5.2.cmml\"><mi id=\"S2.Ex1.m1.4.5.2.2\" xref=\"S2.Ex1.m1.4.5.2.2.cmml\">s</mi><mo id=\"S2.Ex1.m1.4.5.2.1\" xref=\"S2.Ex1.m1.4.5.2.1.cmml\">&#8290;</mo><mi id=\"S2.Ex1.m1.4.5.2.3\" xref=\"S2.Ex1.m1.4.5.2.3.cmml\">i</mi><mo id=\"S2.Ex1.m1.4.5.2.1a\" xref=\"S2.Ex1.m1.4.5.2.1.cmml\">&#8290;</mo><mi id=\"S2.Ex1.m1.4.5.2.4\" xref=\"S2.Ex1.m1.4.5.2.4.cmml\">m</mi><mo id=\"S2.Ex1.m1.4.5.2.1b\" xref=\"S2.Ex1.m1.4.5.2.1.cmml\">&#8290;</mo><mrow id=\"S2.Ex1.m1.4.5.2.5.2\" xref=\"S2.Ex1.m1.4.5.2.5.1.cmml\"><mo id=\"S2.Ex1.m1.4.5.2.5.2.1\" stretchy=\"false\" xref=\"S2.Ex1.m1.4.5.2.5.1.cmml\">(</mo><mi id=\"S2.Ex1.m1.1.1\" xref=\"S2.Ex1.m1.1.1.cmml\">q</mi><mo id=\"S2.Ex1.m1.4.5.2.5.2.2\" xref=\"S2.Ex1.m1.4.5.2.5.1.cmml\">,</mo><mi id=\"S2.Ex1.m1.2.2\" xref=\"S2.Ex1.m1.2.2.cmml\">g</mi><mo id=\"S2.Ex1.m1.4.5.2.5.2.3\" stretchy=\"false\" xref=\"S2.Ex1.m1.4.5.2.5.1.cmml\">)</mo></mrow></mrow><mo id=\"S2.Ex1.m1.4.5.1\" xref=\"S2.Ex1.m1.4.5.1.cmml\">=</mo><mrow id=\"S2.Ex1.m1.4.5.3\" xref=\"S2.Ex1.m1.4.5.3.cmml\"><msub id=\"S2.Ex1.m1.4.5.3.2\" xref=\"S2.Ex1.m1.4.5.3.2.cmml\"><mi id=\"S2.Ex1.m1.4.5.3.2.2\" xref=\"S2.Ex1.m1.4.5.3.2.2.cmml\">E</mi><mi id=\"S2.Ex1.m1.4.5.3.2.3\" xref=\"S2.Ex1.m1.4.5.3.2.3.cmml\">Q</mi></msub><mo id=\"S2.Ex1.m1.4.5.3.1\" xref=\"S2.Ex1.m1.4.5.3.1.cmml\">&#8290;</mo><msup id=\"S2.Ex1.m1.4.5.3.3\" xref=\"S2.Ex1.m1.4.5.3.3.cmml\"><mrow id=\"S2.Ex1.m1.4.5.3.3.2.2\" xref=\"S2.Ex1.m1.4.5.3.3.cmml\"><mo id=\"S2.Ex1.m1.4.5.3.3.2.2.1\" stretchy=\"false\" xref=\"S2.Ex1.m1.4.5.3.3.cmml\">(</mo><mi id=\"S2.Ex1.m1.3.3\" xref=\"S2.Ex1.m1.3.3.cmml\">q</mi><mo id=\"S2.Ex1.m1.4.5.3.3.2.2.2\" stretchy=\"false\" xref=\"S2.Ex1.m1.4.5.3.3.cmml\">)</mo></mrow><mi id=\"S2.Ex1.m1.4.5.3.3.3\" xref=\"S2.Ex1.m1.4.5.3.3.3.cmml\">T</mi></msup><mo id=\"S2.Ex1.m1.4.5.3.1a\" xref=\"S2.Ex1.m1.4.5.3.1.cmml\">&#8290;</mo><msub id=\"S2.Ex1.m1.4.5.3.4\" xref=\"S2.Ex1.m1.4.5.3.4.cmml\"><mi id=\"S2.Ex1.m1.4.5.3.4.2\" xref=\"S2.Ex1.m1.4.5.3.4.2.cmml\">E</mi><mi id=\"S2.Ex1.m1.4.5.3.4.3\" xref=\"S2.Ex1.m1.4.5.3.4.3.cmml\">C</mi></msub><mo id=\"S2.Ex1.m1.4.5.3.1b\" xref=\"S2.Ex1.m1.4.5.3.1.cmml\">&#8290;</mo><mrow id=\"S2.Ex1.m1.4.5.3.5.2\" xref=\"S2.Ex1.m1.4.5.3.cmml\"><mo id=\"S2.Ex1.m1.4.5.3.5.2.1\" stretchy=\"false\" xref=\"S2.Ex1.m1.4.5.3.cmml\">(</mo><mi id=\"S2.Ex1.m1.4.4\" xref=\"S2.Ex1.m1.4.4.cmml\">g</mi><mo id=\"S2.Ex1.m1.4.5.3.5.2.2\" stretchy=\"false\" xref=\"S2.Ex1.m1.4.5.3.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.Ex1.m1.4b\"><apply id=\"S2.Ex1.m1.4.5.cmml\" xref=\"S2.Ex1.m1.4.5\"><eq id=\"S2.Ex1.m1.4.5.1.cmml\" xref=\"S2.Ex1.m1.4.5.1\"></eq><apply id=\"S2.Ex1.m1.4.5.2.cmml\" xref=\"S2.Ex1.m1.4.5.2\"><times id=\"S2.Ex1.m1.4.5.2.1.cmml\" xref=\"S2.Ex1.m1.4.5.2.1\"></times><ci id=\"S2.Ex1.m1.4.5.2.2.cmml\" xref=\"S2.Ex1.m1.4.5.2.2\">&#119904;</ci><ci id=\"S2.Ex1.m1.4.5.2.3.cmml\" xref=\"S2.Ex1.m1.4.5.2.3\">&#119894;</ci><ci id=\"S2.Ex1.m1.4.5.2.4.cmml\" xref=\"S2.Ex1.m1.4.5.2.4\">&#119898;</ci><interval closure=\"open\" id=\"S2.Ex1.m1.4.5.2.5.1.cmml\" xref=\"S2.Ex1.m1.4.5.2.5.2\"><ci id=\"S2.Ex1.m1.1.1.cmml\" xref=\"S2.Ex1.m1.1.1\">&#119902;</ci><ci id=\"S2.Ex1.m1.2.2.cmml\" xref=\"S2.Ex1.m1.2.2\">&#119892;</ci></interval></apply><apply id=\"S2.Ex1.m1.4.5.3.cmml\" xref=\"S2.Ex1.m1.4.5.3\"><times id=\"S2.Ex1.m1.4.5.3.1.cmml\" xref=\"S2.Ex1.m1.4.5.3.1\"></times><apply id=\"S2.Ex1.m1.4.5.3.2.cmml\" xref=\"S2.Ex1.m1.4.5.3.2\"><csymbol cd=\"ambiguous\" id=\"S2.Ex1.m1.4.5.3.2.1.cmml\" xref=\"S2.Ex1.m1.4.5.3.2\">subscript</csymbol><ci id=\"S2.Ex1.m1.4.5.3.2.2.cmml\" xref=\"S2.Ex1.m1.4.5.3.2.2\">&#119864;</ci><ci id=\"S2.Ex1.m1.4.5.3.2.3.cmml\" xref=\"S2.Ex1.m1.4.5.3.2.3\">&#119876;</ci></apply><apply id=\"S2.Ex1.m1.4.5.3.3.cmml\" xref=\"S2.Ex1.m1.4.5.3.3\"><csymbol cd=\"ambiguous\" id=\"S2.Ex1.m1.4.5.3.3.1.cmml\" xref=\"S2.Ex1.m1.4.5.3.3\">superscript</csymbol><ci id=\"S2.Ex1.m1.3.3.cmml\" xref=\"S2.Ex1.m1.3.3\">&#119902;</ci><ci id=\"S2.Ex1.m1.4.5.3.3.3.cmml\" xref=\"S2.Ex1.m1.4.5.3.3.3\">&#119879;</ci></apply><apply id=\"S2.Ex1.m1.4.5.3.4.cmml\" xref=\"S2.Ex1.m1.4.5.3.4\"><csymbol cd=\"ambiguous\" id=\"S2.Ex1.m1.4.5.3.4.1.cmml\" xref=\"S2.Ex1.m1.4.5.3.4\">subscript</csymbol><ci id=\"S2.Ex1.m1.4.5.3.4.2.cmml\" xref=\"S2.Ex1.m1.4.5.3.4.2\">&#119864;</ci><ci id=\"S2.Ex1.m1.4.5.3.4.3.cmml\" xref=\"S2.Ex1.m1.4.5.3.4.3\">&#119862;</ci></apply><ci id=\"S2.Ex1.m1.4.4.cmml\" xref=\"S2.Ex1.m1.4.4\">&#119892;</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.Ex1.m1.4c\">\\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.Ex1.m1.4d\">italic_s italic_i italic_m ( italic_q , italic_g ) = italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g )</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": []
    },
    "A1.EGx2": {
        "table": "<table class=\"ltx_equationgroup ltx_eqn_align ltx_eqn_table\" id=\"A1.EGx2\">\n<tbody id=\"S2.Ex2\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math alttext=\"\\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\\approx\\max_{g^{\\prime}\\subseteq g}%\n(E_{Q}(q)^{T}E_{C}(g^{\\prime}))\" class=\"ltx_Math\" display=\"inline\" id=\"S2.Ex2.m1.7\"><semantics id=\"S2.Ex2.m1.7a\"><mrow id=\"S2.Ex2.m1.7.7\" xref=\"S2.Ex2.m1.7.7.cmml\"><mrow id=\"S2.Ex2.m1.7.7.4\" xref=\"S2.Ex2.m1.7.7.4.cmml\"><mi id=\"S2.Ex2.m1.7.7.4.2\" xref=\"S2.Ex2.m1.7.7.4.2.cmml\">s</mi><mo id=\"S2.Ex2.m1.7.7.4.1\" xref=\"S2.Ex2.m1.7.7.4.1.cmml\">&#8290;</mo><mi id=\"S2.Ex2.m1.7.7.4.3\" xref=\"S2.Ex2.m1.7.7.4.3.cmml\">i</mi><mo id=\"S2.Ex2.m1.7.7.4.1a\" xref=\"S2.Ex2.m1.7.7.4.1.cmml\">&#8290;</mo><mi id=\"S2.Ex2.m1.7.7.4.4\" xref=\"S2.Ex2.m1.7.7.4.4.cmml\">m</mi><mo id=\"S2.Ex2.m1.7.7.4.1b\" xref=\"S2.Ex2.m1.7.7.4.1.cmml\">&#8290;</mo><mrow id=\"S2.Ex2.m1.7.7.4.5.2\" xref=\"S2.Ex2.m1.7.7.4.5.1.cmml\"><mo id=\"S2.Ex2.m1.7.7.4.5.2.1\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.4.5.1.cmml\">(</mo><mi id=\"S2.Ex2.m1.1.1\" xref=\"S2.Ex2.m1.1.1.cmml\">q</mi><mo id=\"S2.Ex2.m1.7.7.4.5.2.2\" xref=\"S2.Ex2.m1.7.7.4.5.1.cmml\">,</mo><mi id=\"S2.Ex2.m1.2.2\" xref=\"S2.Ex2.m1.2.2.cmml\">g</mi><mo id=\"S2.Ex2.m1.7.7.4.5.2.3\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.4.5.1.cmml\">)</mo></mrow></mrow><mo id=\"S2.Ex2.m1.7.7.5\" xref=\"S2.Ex2.m1.7.7.5.cmml\">=</mo><mrow id=\"S2.Ex2.m1.7.7.6\" xref=\"S2.Ex2.m1.7.7.6.cmml\"><msub id=\"S2.Ex2.m1.7.7.6.2\" xref=\"S2.Ex2.m1.7.7.6.2.cmml\"><mi id=\"S2.Ex2.m1.7.7.6.2.2\" xref=\"S2.Ex2.m1.7.7.6.2.2.cmml\">E</mi><mi id=\"S2.Ex2.m1.7.7.6.2.3\" xref=\"S2.Ex2.m1.7.7.6.2.3.cmml\">Q</mi></msub><mo id=\"S2.Ex2.m1.7.7.6.1\" xref=\"S2.Ex2.m1.7.7.6.1.cmml\">&#8290;</mo><msup id=\"S2.Ex2.m1.7.7.6.3\" xref=\"S2.Ex2.m1.7.7.6.3.cmml\"><mrow id=\"S2.Ex2.m1.7.7.6.3.2.2\" xref=\"S2.Ex2.m1.7.7.6.3.cmml\"><mo id=\"S2.Ex2.m1.7.7.6.3.2.2.1\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.6.3.cmml\">(</mo><mi id=\"S2.Ex2.m1.3.3\" xref=\"S2.Ex2.m1.3.3.cmml\">q</mi><mo id=\"S2.Ex2.m1.7.7.6.3.2.2.2\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.6.3.cmml\">)</mo></mrow><mi id=\"S2.Ex2.m1.7.7.6.3.3\" xref=\"S2.Ex2.m1.7.7.6.3.3.cmml\">T</mi></msup><mo id=\"S2.Ex2.m1.7.7.6.1a\" xref=\"S2.Ex2.m1.7.7.6.1.cmml\">&#8290;</mo><msub id=\"S2.Ex2.m1.7.7.6.4\" xref=\"S2.Ex2.m1.7.7.6.4.cmml\"><mi id=\"S2.Ex2.m1.7.7.6.4.2\" xref=\"S2.Ex2.m1.7.7.6.4.2.cmml\">E</mi><mi id=\"S2.Ex2.m1.7.7.6.4.3\" xref=\"S2.Ex2.m1.7.7.6.4.3.cmml\">C</mi></msub><mo id=\"S2.Ex2.m1.7.7.6.1b\" xref=\"S2.Ex2.m1.7.7.6.1.cmml\">&#8290;</mo><mrow id=\"S2.Ex2.m1.7.7.6.5.2\" xref=\"S2.Ex2.m1.7.7.6.cmml\"><mo id=\"S2.Ex2.m1.7.7.6.5.2.1\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.6.cmml\">(</mo><mi id=\"S2.Ex2.m1.4.4\" xref=\"S2.Ex2.m1.4.4.cmml\">g</mi><mo id=\"S2.Ex2.m1.7.7.6.5.2.2\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.6.cmml\">)</mo></mrow></mrow><mo id=\"S2.Ex2.m1.7.7.7\" xref=\"S2.Ex2.m1.7.7.7.cmml\">&#8776;</mo><mrow id=\"S2.Ex2.m1.7.7.2.2\" xref=\"S2.Ex2.m1.7.7.2.3.cmml\"><munder id=\"S2.Ex2.m1.6.6.1.1.1\" xref=\"S2.Ex2.m1.6.6.1.1.1.cmml\"><mi id=\"S2.Ex2.m1.6.6.1.1.1.2\" xref=\"S2.Ex2.m1.6.6.1.1.1.2.cmml\">max</mi><mrow id=\"S2.Ex2.m1.6.6.1.1.1.3\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.cmml\"><msup id=\"S2.Ex2.m1.6.6.1.1.1.3.2\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2.cmml\"><mi id=\"S2.Ex2.m1.6.6.1.1.1.3.2.2\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2.2.cmml\">g</mi><mo id=\"S2.Ex2.m1.6.6.1.1.1.3.2.3\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2.3.cmml\">&#8242;</mo></msup><mo id=\"S2.Ex2.m1.6.6.1.1.1.3.1\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.1.cmml\">&#8838;</mo><mi id=\"S2.Ex2.m1.6.6.1.1.1.3.3\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.3.cmml\">g</mi></mrow></munder><mo id=\"S2.Ex2.m1.7.7.2.2a\" xref=\"S2.Ex2.m1.7.7.2.3.cmml\">&#8289;</mo><mrow id=\"S2.Ex2.m1.7.7.2.2.2\" xref=\"S2.Ex2.m1.7.7.2.3.cmml\"><mo id=\"S2.Ex2.m1.7.7.2.2.2.2\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.2.3.cmml\">(</mo><mrow id=\"S2.Ex2.m1.7.7.2.2.2.1\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.cmml\"><msub id=\"S2.Ex2.m1.7.7.2.2.2.1.3\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3.cmml\"><mi id=\"S2.Ex2.m1.7.7.2.2.2.1.3.2\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3.2.cmml\">E</mi><mi id=\"S2.Ex2.m1.7.7.2.2.2.1.3.3\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3.3.cmml\">Q</mi></msub><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.2\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.2.cmml\">&#8290;</mo><msup id=\"S2.Ex2.m1.7.7.2.2.2.1.4\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4.cmml\"><mrow id=\"S2.Ex2.m1.7.7.2.2.2.1.4.2.2\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4.cmml\"><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.4.2.2.1\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4.cmml\">(</mo><mi id=\"S2.Ex2.m1.5.5\" xref=\"S2.Ex2.m1.5.5.cmml\">q</mi><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.4.2.2.2\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4.cmml\">)</mo></mrow><mi id=\"S2.Ex2.m1.7.7.2.2.2.1.4.3\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4.3.cmml\">T</mi></msup><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.2a\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.2.cmml\">&#8290;</mo><msub id=\"S2.Ex2.m1.7.7.2.2.2.1.5\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5.cmml\"><mi id=\"S2.Ex2.m1.7.7.2.2.2.1.5.2\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5.2.cmml\">E</mi><mi id=\"S2.Ex2.m1.7.7.2.2.2.1.5.3\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5.3.cmml\">C</mi></msub><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.2b\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.2.cmml\">&#8290;</mo><mrow id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml\"><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.2\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml\">(</mo><msup id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml\"><mi id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2.cmml\">g</mi><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3.cmml\">&#8242;</mo></msup><mo id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.3\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S2.Ex2.m1.7.7.2.2.2.3\" stretchy=\"false\" xref=\"S2.Ex2.m1.7.7.2.3.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.Ex2.m1.7b\"><apply id=\"S2.Ex2.m1.7.7.cmml\" xref=\"S2.Ex2.m1.7.7\"><and id=\"S2.Ex2.m1.7.7a.cmml\" xref=\"S2.Ex2.m1.7.7\"></and><apply id=\"S2.Ex2.m1.7.7b.cmml\" xref=\"S2.Ex2.m1.7.7\"><eq id=\"S2.Ex2.m1.7.7.5.cmml\" xref=\"S2.Ex2.m1.7.7.5\"></eq><apply id=\"S2.Ex2.m1.7.7.4.cmml\" xref=\"S2.Ex2.m1.7.7.4\"><times id=\"S2.Ex2.m1.7.7.4.1.cmml\" xref=\"S2.Ex2.m1.7.7.4.1\"></times><ci id=\"S2.Ex2.m1.7.7.4.2.cmml\" xref=\"S2.Ex2.m1.7.7.4.2\">&#119904;</ci><ci id=\"S2.Ex2.m1.7.7.4.3.cmml\" xref=\"S2.Ex2.m1.7.7.4.3\">&#119894;</ci><ci id=\"S2.Ex2.m1.7.7.4.4.cmml\" xref=\"S2.Ex2.m1.7.7.4.4\">&#119898;</ci><interval closure=\"open\" id=\"S2.Ex2.m1.7.7.4.5.1.cmml\" xref=\"S2.Ex2.m1.7.7.4.5.2\"><ci id=\"S2.Ex2.m1.1.1.cmml\" xref=\"S2.Ex2.m1.1.1\">&#119902;</ci><ci id=\"S2.Ex2.m1.2.2.cmml\" xref=\"S2.Ex2.m1.2.2\">&#119892;</ci></interval></apply><apply id=\"S2.Ex2.m1.7.7.6.cmml\" xref=\"S2.Ex2.m1.7.7.6\"><times id=\"S2.Ex2.m1.7.7.6.1.cmml\" xref=\"S2.Ex2.m1.7.7.6.1\"></times><apply id=\"S2.Ex2.m1.7.7.6.2.cmml\" xref=\"S2.Ex2.m1.7.7.6.2\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.6.2.1.cmml\" xref=\"S2.Ex2.m1.7.7.6.2\">subscript</csymbol><ci id=\"S2.Ex2.m1.7.7.6.2.2.cmml\" xref=\"S2.Ex2.m1.7.7.6.2.2\">&#119864;</ci><ci id=\"S2.Ex2.m1.7.7.6.2.3.cmml\" xref=\"S2.Ex2.m1.7.7.6.2.3\">&#119876;</ci></apply><apply id=\"S2.Ex2.m1.7.7.6.3.cmml\" xref=\"S2.Ex2.m1.7.7.6.3\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.6.3.1.cmml\" xref=\"S2.Ex2.m1.7.7.6.3\">superscript</csymbol><ci id=\"S2.Ex2.m1.3.3.cmml\" xref=\"S2.Ex2.m1.3.3\">&#119902;</ci><ci id=\"S2.Ex2.m1.7.7.6.3.3.cmml\" xref=\"S2.Ex2.m1.7.7.6.3.3\">&#119879;</ci></apply><apply id=\"S2.Ex2.m1.7.7.6.4.cmml\" xref=\"S2.Ex2.m1.7.7.6.4\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.6.4.1.cmml\" xref=\"S2.Ex2.m1.7.7.6.4\">subscript</csymbol><ci id=\"S2.Ex2.m1.7.7.6.4.2.cmml\" xref=\"S2.Ex2.m1.7.7.6.4.2\">&#119864;</ci><ci id=\"S2.Ex2.m1.7.7.6.4.3.cmml\" xref=\"S2.Ex2.m1.7.7.6.4.3\">&#119862;</ci></apply><ci id=\"S2.Ex2.m1.4.4.cmml\" xref=\"S2.Ex2.m1.4.4\">&#119892;</ci></apply></apply><apply id=\"S2.Ex2.m1.7.7c.cmml\" xref=\"S2.Ex2.m1.7.7\"><approx id=\"S2.Ex2.m1.7.7.7.cmml\" xref=\"S2.Ex2.m1.7.7.7\"></approx><share href=\"https://arxiv.org/html/2406.15319v3#S2.Ex2.m1.7.7.6.cmml\" id=\"S2.Ex2.m1.7.7d.cmml\" xref=\"S2.Ex2.m1.7.7\"></share><apply id=\"S2.Ex2.m1.7.7.2.3.cmml\" xref=\"S2.Ex2.m1.7.7.2.2\"><apply id=\"S2.Ex2.m1.6.6.1.1.1.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.6.6.1.1.1.1.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1\">subscript</csymbol><max id=\"S2.Ex2.m1.6.6.1.1.1.2.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.2\"></max><apply id=\"S2.Ex2.m1.6.6.1.1.1.3.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3\"><subset id=\"S2.Ex2.m1.6.6.1.1.1.3.1.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.1\"></subset><apply id=\"S2.Ex2.m1.6.6.1.1.1.3.2.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.6.6.1.1.1.3.2.1.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2\">superscript</csymbol><ci id=\"S2.Ex2.m1.6.6.1.1.1.3.2.2.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2.2\">&#119892;</ci><ci id=\"S2.Ex2.m1.6.6.1.1.1.3.2.3.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.2.3\">&#8242;</ci></apply><ci id=\"S2.Ex2.m1.6.6.1.1.1.3.3.cmml\" xref=\"S2.Ex2.m1.6.6.1.1.1.3.3\">&#119892;</ci></apply></apply><apply id=\"S2.Ex2.m1.7.7.2.2.2.1.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1\"><times id=\"S2.Ex2.m1.7.7.2.2.2.1.2.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.2\"></times><apply id=\"S2.Ex2.m1.7.7.2.2.2.1.3.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.2.2.2.1.3.1.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3\">subscript</csymbol><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.3.2.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3.2\">&#119864;</ci><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.3.3.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.3.3\">&#119876;</ci></apply><apply id=\"S2.Ex2.m1.7.7.2.2.2.1.4.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.2.2.2.1.4.1.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4\">superscript</csymbol><ci id=\"S2.Ex2.m1.5.5.cmml\" xref=\"S2.Ex2.m1.5.5\">&#119902;</ci><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.4.3.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.4.3\">&#119879;</ci></apply><apply id=\"S2.Ex2.m1.7.7.2.2.2.1.5.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.2.2.2.1.5.1.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5\">subscript</csymbol><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.5.2.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5.2\">&#119864;</ci><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.5.3.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.5.3\">&#119862;</ci></apply><apply id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.1.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1\">superscript</csymbol><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2\">&#119892;</ci><ci id=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3.cmml\" xref=\"S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3\">&#8242;</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.Ex2.m1.7c\">\\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\\approx\\max_{g^{\\prime}\\subseteq g}%\n(E_{Q}(q)^{T}E_{C}(g^{\\prime}))</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.Ex2.m1.7d\">italic_s italic_i italic_m ( italic_q , italic_g ) = italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g ) &#8776; roman_max start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT &#8242; end_POSTSUPERSCRIPT &#8838; italic_g end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g start_POSTSUPERSCRIPT &#8242; end_POSTSUPERSCRIPT ) )</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": []
    },
    "S3.T1.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.1.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.2.1\">Corpus source</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.1.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.3.1.1.1.1\">Avg. Doc.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.3.1.2.1.1\">Length</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.4.1\"># of Documents</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.5.1\"># of Text cases</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\" id=\"S3.T1.1.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.6.1\">Metric</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2.2.1\">NQ</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2.2.2\">Wikipedia</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2.2.3\">800</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2.2.4\">3M</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2.2.5\">3,610</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T1.1.1.2.2.6\">EM</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.3.3.1\">HotpotQA</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.3.3.2\">Wikipedia</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.3.3.3\">130</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.3.3.4\">5.2M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.3.3.5\">7,405</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.3.3.6\">EM</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.4.4.1\">Qasper</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.4.4.2\">Science</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.4.4.3\">4.7K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.4.4.4\">416</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T1.1.1.4.4.5\">371</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.4.4.6\">F1</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.1.5.5.1\">MultiFieldQA-en</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.1.5.5.2\">Multi-field</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.1.5.5.3\">6.9K</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.1.5.5.4\">150</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T1.1.1.5.5.5\">150</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S3.T1.1.1.5.5.6\">F1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1: An overview of the four datasets used in our experiments is provided. “Corpus source” refers to the origin of the retrieval corpus. We selected NQ and HotpotQA from Wikipedia, Qasper from scientific documents, and MultifieldQA-en from multi-field documents. The two Wikipedia-based datasets utilize a massive retrieval corpus containing millions of short documents. In contrast, the other two datasets employ a smaller corpus consisting of hundreds of long documents.",
        "footnotes": [],
        "references": [
            "Our proposed methods were tested on four question-answering datasets. The basic statistics are shown in Table 1. Additionally, we have provided some examples in Appendix A.4."
        ]
    },
    "S3.T1.1.1.1.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.T1.1.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.1.3.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.3.1.1.1.1\">Avg. Doc.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T1.1.1.1.1.3.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.3.1.2.1.1\">Length</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 1: An overview of the four datasets used in our experiments is provided. “Corpus source” refers to the origin of the retrieval corpus. We selected NQ and HotpotQA from Wikipedia, Qasper from scientific documents, and MultifieldQA-en from multi-field documents. The two Wikipedia-based datasets utilize a massive retrieval corpus containing millions of short documents. In contrast, the other two datasets employ a smaller corpus consisting of hundreds of long documents.",
        "footnotes": [],
        "references": [
            "Our proposed methods were tested on four question-answering datasets. The basic statistics are shown in Table 1. Additionally, we have provided some examples in Appendix A.4."
        ]
    },
    "S3.T2.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T2.1.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.1.1\">Retrieval Unit</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T2.1.1.1.1.2\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.2.1\">Corpus Size</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T2.1.1.1.1.3\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.3.1\">Num of Retrieval Units</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S3.T2.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.4.1\">Average Num of Tokens</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T2.1.1.1.1.5\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.5.1\">Answer Recall (AR)</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T2.1.1.2.2.1\">Corpus</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T2.1.1.2.2.2\">Test Set</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.3.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.3.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.1.1\">Passage</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.3.1.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.1.1.3.1.2.1\">22M</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.3.1.3\">1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.3.1.4\">120</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.3.1.5\">130</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.3.1.6\">52.24</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.4.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T2.1.1.4.2.1\">100</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.4.2.2\">12K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.4.2.3\">14K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.1.1.4.2.4\">89.92</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.5.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T2.1.1.5.3.1\">200</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.5.3.2\">24K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.5.3.3\">28K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.1.1.5.3.4\">91.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.6.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.6.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.1.1.6.4.1.1\">Document</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.6.4.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.1.1.6.4.2.1\">3M</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.6.4.3\">1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.6.4.4\">820</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.6.4.5\">4K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.6.4.6\">69.45</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.7.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T2.1.1.7.5.1\">5</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.7.5.2\">4K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.7.5.3\">18K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.1.1.7.5.4\">85.37</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.8.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T2.1.1.8.6.1\">10</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.8.6.2\">8K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.8.6.3\">34K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.1.1.8.6.4\">88.12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.9.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S3.T2.1.1.9.7.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.1.1.9.7.1.1\">Grouped Documents</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S3.T2.1.1.9.7.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T2.1.1.9.7.2.1\">600K</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T2.1.1.9.7.3\">1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.9.7.4\">4K</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.9.7.5\">6K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T2.1.1.9.7.6\">71.69</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.10.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T2.1.1.10.8.1\">4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.10.8.2\">16K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T2.1.1.10.8.3\">25K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T2.1.1.10.8.4\">86.30</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.11.9\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T2.1.1.11.9.1\">8</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.1.1.11.9.2\">32K</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T2.1.1.11.9.3\">50K</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S3.T2.1.1.11.9.4\">88.53</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2: The table illustrates the retrieval performance on NQ. Employing a long-context retriever (with an average number of tokens for each retrieval unit up to 6K) compresses the corpus size by up to 30 times (from 22M to 600K), enhancing top-1 answer recall by approximately 20 points (from 52.24 to 71.69). Furthermore, long-context retriever requires significantly fewer retrieval units (10x fewer) to achieve comparable results. Therefore, integrating long-context retrieval significantly alleviates the burden of retriever.",
        "footnotes": [],
        "references": [
            "Table 2 and Table 3 have shown the retrieval results on NQ and HotpotQA. In the NQ dataset, we utilize three different retrieval units, ranging from shorter to longer: passage, document, and grouped documents. In the table, we have mentioned two kinds of average number of tokens in each retrieval unit: one for the entire corpus and one for each test set. The retrieval units for each test case can sometimes be much longer than the average size across the whole corpus, as the corpus might include some Wikipedia pages with very few words, while the test cases may focus more on longer documents. Generally, our long-context retriever (at the document level and grouped document level) uses retrieval units containing an average of 6K tokens. By using longer retrieval units, there are several advantages: 1) It will significantly alleviate the burden on the retriever by compressing the corpus size by approximately 30 times, from 22M to 600K. The top-1 answer recall improves by about 20 points, from 52.24 to 71.69. We could use significantly fewer retrieval units to achieve comparable retrieval performance. For instance, 8 retrieval units at the grouped document level can achieve similar recall as 100 retrieval units at the passage level. 2) It could provide more comprehensive information to the reader. In the original passage-level RAG setup, information might be incomplete due to the chunking operation. In the HotpotQA dataset, we observe similar results. One notable difference is that in HotpotQA, the retrieval units are only at the document level and grouped document level, as HotpotQA uses only abstract paragraphs from each Wikipedia page."
        ]
    },
    "S3.T3.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T3.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.1.1\">Retrieval Unit</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1.2\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.2.1\">Corpus Size</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1.3\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.3.1\">Num of Retrieval Units</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S3.T3.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.4.1\">Average Num of Tokens</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T3.1.1.1.1.5.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.1.1.1.1.5.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.1.1.1.1.5.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T3.1.1.1.1.5.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.5.1.1.1.1.1\">Recall</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.1.1.1.1.5.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T3.1.1.1.1.5.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.5.1.1.2.1.1\">(R)</span></span></span>\n</span></span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T3.1.1.1.1.6\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S3.T3.1.1.1.1.6.1\">\n<span class=\"ltx_tabular ltx_align_middle\" id=\"S3.T3.1.1.1.1.6.1.1\">\n<span class=\"ltx_tr\" id=\"S3.T3.1.1.1.1.6.1.1.1\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T3.1.1.1.1.6.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.6.1.1.1.1.1\">Answer Recall</span></span></span>\n<span class=\"ltx_tr\" id=\"S3.T3.1.1.1.1.6.1.1.2\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T3.1.1.1.1.6.1.1.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T3.1.1.1.1.6.1.1.2.1.1\">(AR)</span></span></span>\n</span></span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.1.1.2.2.1\">Corpus</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S3.T3.1.1.2.2.2\">Test Set</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.3.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.3.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T3.1.1.3.1.1.1\">Document</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.3.1.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T3.1.1.3.1.2.1\">5.2M</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.3.1.3\">2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.3.1.4\">130</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.3.1.5\">200</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.1.1.3.1.6\">30.01</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.3.1.7\">47.75</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.4.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.1.1.4.2.1\">100</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.1.1.4.2.2\">6.5K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.1.1.4.2.3\">10K</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.4.2.4\">74.84</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T3.1.1.4.2.5\">84.67</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.5.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.1.1.5.3.1\">200</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.1.1.5.3.2\">13K</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T3.1.1.5.3.3\">20K</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T3.1.1.5.3.4\">79.68</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T3.1.1.5.3.5\">88.34</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.6.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S3.T3.1.1.6.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T3.1.1.6.4.1.1\">Grouped Documents</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S3.T3.1.1.6.4.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S3.T3.1.1.6.4.2.1\">500K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.6.4.3\">2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.6.4.4\">1K</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.6.4.5\">8K</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T3.1.1.6.4.6\">56.30</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T3.1.1.6.4.7\">72.49</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T3.1.1.7.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.1.1.7.5.1\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.1.1.7.5.2\">4K</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T3.1.1.7.5.3\">29K</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T3.1.1.7.5.4\">74.71</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S3.T3.1.1.7.5.5\">84.40</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 3: The table illustrates the retrieval performance on HotpotQA. Similar to the findings on NQ, a long-context retrieval could significantly alleviate the burden on the retriever component.",
        "footnotes": [],
        "references": [
            "Table 2 and Table 3 have shown the retrieval results on NQ and HotpotQA. In the NQ dataset, we utilize three different retrieval units, ranging from shorter to longer: passage, document, and grouped documents. In the table, we have mentioned two kinds of average number of tokens in each retrieval unit: one for the entire corpus and one for each test set. The retrieval units for each test case can sometimes be much longer than the average size across the whole corpus, as the corpus might include some Wikipedia pages with very few words, while the test cases may focus more on longer documents. Generally, our long-context retriever (at the document level and grouped document level) uses retrieval units containing an average of 6K tokens. By using longer retrieval units, there are several advantages: 1) It will significantly alleviate the burden on the retriever by compressing the corpus size by approximately 30 times, from 22M to 600K. The top-1 answer recall improves by about 20 points, from 52.24 to 71.69. We could use significantly fewer retrieval units to achieve comparable retrieval performance. For instance, 8 retrieval units at the grouped document level can achieve similar recall as 100 retrieval units at the passage level. 2) It could provide more comprehensive information to the reader. In the original passage-level RAG setup, information might be incomplete due to the chunking operation. In the HotpotQA dataset, we observe similar results. One notable difference is that in HotpotQA, the retrieval units are only at the document level and grouped document level, as HotpotQA uses only abstract paragraphs from each Wikipedia page."
        ]
    },
    "S3.T4.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.1.1.1.1\"><span class=\"ltx_text\" id=\"S3.T4.1.1.1.1.1\" style=\"font-size:90%;\">Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.1.1.1.2\"><span class=\"ltx_text\" id=\"S3.T4.1.1.1.2.1\" style=\"font-size:90%;\">Granularity</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T4.1.1.1.3\"><span class=\"ltx_text\" id=\"S3.T4.1.1.1.3.1\" style=\"font-size:90%;\">AR@1</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T4.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T4.1.2.1.1\"><span class=\"ltx_text\" id=\"S3.T4.1.2.1.1.1\" style=\"font-size:90%;\">BGE-Large</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T4.1.2.1.2\"><span class=\"ltx_text\" id=\"S3.T4.1.2.1.2.1\" style=\"font-size:90%;\">512-tokens chunk</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S3.T4.1.2.1.3\"><span class=\"ltx_text\" id=\"S3.T4.1.2.1.3.1\" style=\"font-size:90%;\">71.7%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T4.1.3.2.1\"><span class=\"ltx_text\" id=\"S3.T4.1.3.2.1.1\" style=\"font-size:90%;\">E5-Mistral-7B</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T4.1.3.2.2\"><span class=\"ltx_text\" id=\"S3.T4.1.3.2.2.1\" style=\"font-size:90%;\">4000-tokens chunk</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S3.T4.1.3.2.3\"><span class=\"ltx_text\" id=\"S3.T4.1.3.2.3.1\" style=\"font-size:90%;\">54.2%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T4.1.4.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T4.1.4.3.1\"><span class=\"ltx_text\" id=\"S3.T4.1.4.3.1.1\" style=\"font-size:90%;\">E5-Mistral-7B</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T4.1.4.3.2\"><span class=\"ltx_text\" id=\"S3.T4.1.4.3.2.1\" style=\"font-size:90%;\">entire grouped retrieval unit</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S3.T4.1.4.3.3\"><span class=\"ltx_text\" id=\"S3.T4.1.4.3.3.1\" style=\"font-size:90%;\">23.4%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 4: Different methods to encode the long retrieval unit in the long retriever. Using a general embedding model and approximating by maximizing the similarity scores between the query and all chunks within the retrieval unit is better than using the existing long embedding model to encode the entire context.",
        "footnotes": [],
        "references": [
            "We approximate it by maximizing the scores of all chunks g′superscript𝑔′g^{\\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT within the retrieval unit g𝑔gitalic_g, akin to the MaxP design in (Dai & Callan, 2019). We consider different levels of granularity of chunk g′superscript𝑔′g^{\\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, including 512 tokens, 4K tokens, and encoding the entire g𝑔gitalic_g completely. The empirical study about this settings is in Table 4.\nWith this similarity score setup, we will retrieve the top k𝑘kitalic_k retrieval units closest to the given query. For efficient retrieval, we precompute the embedding of each retrieval unit g′superscript𝑔′g^{\\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and predict the exact inner product search index in FAISS (Johnson et al., 2019).",
            "As discussed in Section 2.2, it’s very challenging to employ an encoder, EC⁢(⋅)subscript𝐸𝐶⋅E_{C}(\\cdot)italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( ⋅ ), to map the retrieval unit g𝑔gitalic_g to a d𝑑ditalic_d-dimensional vector when g𝑔gitalic_g is very long. Therefore, we use an approximation in our proposed system. Table 4 demonstrates that our approximation, s⁢i⁢m⁢(q,g)=EQ⁢(q)T⁢EC⁢(g)≈maxg′⊆g⁡(EQ⁢(q)T⁢EC⁢(g′))𝑠𝑖𝑚𝑞𝑔subscript𝐸𝑄superscript𝑞𝑇subscript𝐸𝐶𝑔subscriptsuperscript𝑔′𝑔subscript𝐸𝑄superscript𝑞𝑇subscript𝐸𝐶superscript𝑔′sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\\approx\\max_{g^{\\prime}\\subseteq g}(E_{Q}(q)^{T}E%\n_{C}(g^{\\prime}))italic_s italic_i italic_m ( italic_q , italic_g ) = italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g ) ≈ roman_max start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ⊆ italic_g end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ), is much more effective than encoding the entire long context directly.\nWe compare three methods: 1) Using the general embedding model “bge-large-en-v1.5” (Xiao et al., 2023), with g′superscript𝑔′g^{\\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT selected as text of 512-token size. 2) Using long embedding model “E5-Mistral-7B” (Zhu et al., 2024a), with g′superscript𝑔′g^{\\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT selected as the whole document, which has an average size of 4K tokens. 3) Using long embeddings model “E5-Mistral-7B”, with no approximation, we encode the entire g𝑔gitalic_g, which is composed of multiple documents, directly. The average size of g𝑔gitalic_g is 6K tokens. We can notice from the table that our approximation by taking the maximum score between the query and each text piece from the long context produces much better results than encoding them directly using the long embedding model. We believe that future advancements in long embedding models, which focus on encoding long contexts or multiple documents, will further enhance our framework and reduce memory consumption."
        ]
    },
    "S3.T5.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"S3.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T5.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T5.1.2.1.1\"><span class=\"ltx_text\" id=\"S3.T5.1.2.1.1.1\" style=\"font-size:90%;\">NQ</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T5.1.2.1.2\"><span class=\"ltx_text\" id=\"S3.T5.1.2.1.2.1\" style=\"font-size:90%;\">EM</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S3.T5.1.3.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T5.1.3.2.1.1\" style=\"font-size:90%;\">Closed-Book</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T5.1.4.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.4.1.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.4.1.1.1\" style=\"font-size:90%;\">GPT-4-Turbo </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.4.1.1.2.1\" style=\"font-size:90%;\">(</span>Achiam et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.4.1.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib1\" title=\"\">2023</a><span class=\"ltx_text\" id=\"S3.T5.1.4.1.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.4.1.2\"><span class=\"ltx_text\" id=\"S3.T5.1.4.1.2.1\" style=\"font-size:90%;\">41.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.5.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.5.2.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.5.2.1.1\" style=\"font-size:90%;\">Gemini-1.5-Pro </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.5.2.1.2.1\" style=\"font-size:90%;\">(</span>Reid et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.5.2.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib46\" title=\"\">2024</a><span class=\"ltx_text\" id=\"S3.T5.1.5.2.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.5.2.2\"><span class=\"ltx_text\" id=\"S3.T5.1.5.2.2.1\" style=\"font-size:90%;\">47.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.6.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.6.3.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.6.3.1.1\" style=\"font-size:90%;\">Claude-3-Opus </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.6.3.1.2.1\" style=\"font-size:90%;\">(</span>Anthropic<span class=\"ltx_text\" id=\"S3.T5.1.6.3.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib3\" title=\"\">2024</a><span class=\"ltx_text\" id=\"S3.T5.1.6.3.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.6.3.2\"><span class=\"ltx_text\" id=\"S3.T5.1.6.3.2.1\" style=\"font-size:90%;\">49.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.7.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S3.T5.1.7.4.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T5.1.7.4.1.1\" style=\"font-size:90%;\">Fully-supervised RAG</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.8.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.8.5.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.8.5.1.1\" style=\"font-size:90%;\">REALM </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.8.5.1.2.1\" style=\"font-size:90%;\">(</span>Guu et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.8.5.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib20\" title=\"\">2020</a><span class=\"ltx_text\" id=\"S3.T5.1.8.5.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.8.5.2\"><span class=\"ltx_text\" id=\"S3.T5.1.8.5.2.1\" style=\"font-size:90%;\">40.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.9.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.9.6.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.9.6.1.1\" style=\"font-size:90%;\">DPR </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.9.6.1.2.1\" style=\"font-size:90%;\">(</span>Karpukhin et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.9.6.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib28\" title=\"\">2020</a><span class=\"ltx_text\" id=\"S3.T5.1.9.6.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.9.6.2\"><span class=\"ltx_text\" id=\"S3.T5.1.9.6.2.1\" style=\"font-size:90%;\">41.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.10.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.10.7.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.10.7.1.1\" style=\"font-size:90%;\">RAG </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.10.7.1.2.1\" style=\"font-size:90%;\">(</span>Lewis et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.10.7.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib33\" title=\"\">2020</a><span class=\"ltx_text\" id=\"S3.T5.1.10.7.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.10.7.2\"><span class=\"ltx_text\" id=\"S3.T5.1.10.7.2.1\" style=\"font-size:90%;\">44.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.11.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.11.8.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.11.8.1.1\" style=\"font-size:90%;\">RETRO </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.11.8.1.2.1\" style=\"font-size:90%;\">(</span>Borgeaud et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.11.8.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib6\" title=\"\">2022</a><span class=\"ltx_text\" id=\"S3.T5.1.11.8.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.11.8.2\"><span class=\"ltx_text\" id=\"S3.T5.1.11.8.2.1\" style=\"font-size:90%;\">45.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.12.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.12.9.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.12.9.1.1\" style=\"font-size:90%;\">RePAQ </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.12.9.1.2.1\" style=\"font-size:90%;\">(</span>Lewis et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.12.9.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib34\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.1.12.9.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.12.9.2\"><span class=\"ltx_text\" id=\"S3.T5.1.12.9.2.1\" style=\"font-size:90%;\">47.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.13.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.13.10.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.13.10.1.1\" style=\"font-size:90%;\">FID </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.13.10.1.2.1\" style=\"font-size:90%;\">(</span>Izacard &amp; Grave<span class=\"ltx_text\" id=\"S3.T5.1.13.10.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib23\" title=\"\">2020b</a><span class=\"ltx_text\" id=\"S3.T5.1.13.10.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.13.10.2\"><span class=\"ltx_text\" id=\"S3.T5.1.13.10.2.1\" style=\"font-size:90%;\">51.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.1.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.1.1.1\" style=\"font-size:90%;\">EMDR</span><sup class=\"ltx_sup\" id=\"S3.T5.1.1.1.2\"><span class=\"ltx_text\" id=\"S3.T5.1.1.1.2.1\" style=\"font-size:90%;\">2</span></sup><span class=\"ltx_text\" id=\"S3.T5.1.1.1.3\" style=\"font-size:90%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.1.1.4.1\" style=\"font-size:90%;\">(</span>Singh et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.1.1.5.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib49\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.1.1.1.6.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.1.2\"><span class=\"ltx_text\" id=\"S3.T5.1.1.2.1\" style=\"font-size:90%;\">52.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.14.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.14.11.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.14.11.1.1\" style=\"font-size:90%;\">FID-KD </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.14.11.1.2.1\" style=\"font-size:90%;\">(</span>Izacard &amp; Grave<span class=\"ltx_text\" id=\"S3.T5.1.14.11.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib24\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.1.14.11.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.14.11.2\"><span class=\"ltx_text\" id=\"S3.T5.1.14.11.2.1\" style=\"font-size:90%;\">54.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.15.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.15.12.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.15.12.1.1\" style=\"font-size:90%;\">R2-D2 </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.15.12.1.2.1\" style=\"font-size:90%;\">(</span>Fajcik et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.15.12.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib16\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.1.15.12.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.15.12.2\"><span class=\"ltx_text\" id=\"S3.T5.1.15.12.2.1\" style=\"font-size:90%;\">55.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.16.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.16.13.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.16.13.1.1\" style=\"font-size:90%;\">Atlas </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.16.13.1.2.1\" style=\"font-size:90%;\">(</span>Izacard et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.16.13.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib25\" title=\"\">2022</a><span class=\"ltx_text\" id=\"S3.T5.1.16.13.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.16.13.2\"><span class=\"ltx_text\" id=\"S3.T5.1.16.13.2.1\" style=\"font-size:90%;\">64.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.17.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S3.T5.1.17.14.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T5.1.17.14.1.1\" style=\"font-size:90%;\">No Fine-tuning RAG</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.18.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.18.15.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.18.15.1.1\" style=\"font-size:90%;\">REPLUG </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.18.15.1.2.1\" style=\"font-size:90%;\">(</span>Shi et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.18.15.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib48\" title=\"\">2023</a><span class=\"ltx_text\" id=\"S3.T5.1.18.15.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.18.15.2\"><span class=\"ltx_text\" id=\"S3.T5.1.18.15.2.1\" style=\"font-size:90%;\">44.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.19.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.19.16.1\">\n<span class=\"ltx_text\" id=\"S3.T5.1.19.16.1.1\" style=\"font-size:90%;\">REPLUG + LSR </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.1.19.16.1.2.1\" style=\"font-size:90%;\">(</span>Shi et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.1.19.16.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib48\" title=\"\">2023</a><span class=\"ltx_text\" id=\"S3.T5.1.19.16.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.19.16.2\"><span class=\"ltx_text\" id=\"S3.T5.1.19.16.2.1\" style=\"font-size:90%;\">45.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.20.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.1.20.17.1\"><span class=\"ltx_text\" id=\"S3.T5.1.20.17.1.1\" style=\"font-size:90%;\">LongRAG (Gemini-1.5-Pro; Recall 4 units)</span></th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.1.20.17.2\"><span class=\"ltx_text\" id=\"S3.T5.1.20.17.2.1\" style=\"font-size:90%;\">58.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.1.21.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T5.1.21.18.1\"><span class=\"ltx_text\" id=\"S3.T5.1.21.18.1.1\" style=\"font-size:90%;\">LongRAG (GPT-4o; Recall 4 units)</span></th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S3.T5.1.21.18.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.1.21.18.2.1\" style=\"font-size:90%;\">62.7</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 5: The tables show the QA results on the NQ test dataset (left) and Hotpot-QA dev set (right). We compare the results with three groups of baselines: closed-book, which involves directly prompting state-of-the-art LLMs with 16-shot in-context examples; fully-supervised RAG, where the RAG framework is used and the model is fully supervised and trained on the training data; and No Fine-tuning RAG, which employs the RAG framework without any tuning.",
        "footnotes": [
            "Achiam et al. (2023)\n\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.\n\n\nGpt-4 technical report.\n\n\narXiv preprint arXiv:2303.08774, 2023.",
            "Reid et al. (2024)\n\nMachel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al.\n\n\nGemini 1.5: Unlocking multimodal understanding across millions of tokens of context.\n\n\narXiv preprint arXiv:2403.05530, 2024.",
            "Anthropic (2024)\n\nAnthropic.\n\n\nIntroducing the next generation of claude.\n\n\n2024.",
            "Guu et al. (2020)\n\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang.\n\n\nRetrieval augmented language model pre-training.\n\n\nIn International conference on machine learning, pp.  3929–3938. PMLR, 2020.",
            "Karpukhin et al. (2020)\n\nVladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.\n\n\nDense passage retrieval for open-domain question answering.\n\n\narXiv preprint arXiv:2004.04906, 2020.",
            "Lewis et al. (2020)\n\nPatrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.\n\n\nRetrieval-augmented generation for knowledge-intensive nlp tasks.\n\n\nArXiv, abs/2005.11401, 2020.",
            "Borgeaud et al. (2022)\n\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al.\n\n\nImproving language models by retrieving from trillions of tokens.\n\n\nIn International conference on machine learning, pp.  2206–2240. PMLR, 2022.",
            "Lewis et al. (2021)\n\nPatrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich Küttler, Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel.\n\n\nPaq: 65 million probably-asked questions and what you can do with them.\n\n\nTransactions of the Association for Computational Linguistics, 9:1098–1115, 2021.",
            "Izacard & Grave (2020b)\n\nGautier Izacard and Edouard Grave.\n\n\nLeveraging passage retrieval with generative models for open domain question answering.\n\n\narXiv preprint arXiv:2007.01282, 2020b.",
            "Singh et al. (2021)\n\nDevendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, and Dani Yogatama.\n\n\nEnd-to-end training of multi-document reader and retriever for open-domain question answering.\n\n\nAdvances in Neural Information Processing Systems, 34:25968–25981, 2021.",
            "Izacard & Grave (2021)\n\nGautier Izacard and Edouard Grave.\n\n\nDistilling knowledge from reader to retriever for question answering.\n\n\nIn ICLR 2021-9th International Conference on Learning Representations, 2021.",
            "Fajcik et al. (2021)\n\nMartin Fajcik, Martin Docekal, Karel Ondrej, and Pavel Smrz.\n\n\nR2-d2: A modular baseline for open-domain question answering.\n\n\nIn Findings of the Association for Computational Linguistics: EMNLP 2021, pp.  854–870, 2021.",
            "Izacard et al. (2022)\n\nGautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane A. Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave.\n\n\nFew-shot learning with retrieval augmented language models.\n\n\nArXiv, abs/2208.03299, 2022.",
            "Shi et al. (2023)\n\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.\n\n\nReplug: Retrieval-augmented black-box language models.\n\n\narXiv preprint arXiv:2301.12652, 2023.",
            "Shi et al. (2023)\n\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.\n\n\nReplug: Retrieval-augmented black-box language models.\n\n\narXiv preprint arXiv:2301.12652, 2023."
        ],
        "references": [
            "For NQ and HotpotQA, we compare our model with several groups of strong previous models as baselines. The first group is “Closed-Book”: These baselines mean that no retrieval component is used; instead, state-of-the-art LLMs are employed to directly obtain the final result. We evaluate our results on Gemini-1.5-pro (Reid et al., 2024), Claude-3-Opus (Anthropic, 2024) and GPT-4-Turbo (Achiam et al., 2023). All models are evaluated on 16-shot in-context learning with direct prompting; The second group is “Fully-supervised RAG”, and these baselines involve full-supervised fine-tuning on the training dataset. The third group is “No Fine-tuning RAG”, and these baselines doesn’t involve any supervised fine-tuning. The QA results on NQ and HotpotQA are presented in Table 5. On the NQ dataset, LongRAG achieves a 62.7 exact match rate, which is on par of the strongest fine-tuned RAG model like Atlas. On the HotpotQA dataset, LongRAG achieves a 64.3 exact match rate, which is also close to the SoTA fully-supervised RAG frameworks."
        ]
    },
    "S3.T5.2": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\" id=\"S3.T5.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T5.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T5.2.1.1.1\"><span class=\"ltx_text\" id=\"S3.T5.2.1.1.1.1\" style=\"font-size:90%;\">HotpotQA</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T5.2.1.1.2\"><span class=\"ltx_text\" id=\"S3.T5.2.1.1.2.1\" style=\"font-size:90%;\">EM</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S3.T5.2.2.2.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T5.2.2.2.1.1\" style=\"font-size:90%;\">Closed-Book</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T5.2.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.3.1.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.3.1.1.1\" style=\"font-size:90%;\">Claude-3-Opus </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.3.1.1.2.1\" style=\"font-size:90%;\">(</span>Anthropic<span class=\"ltx_text\" id=\"S3.T5.2.3.1.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib3\" title=\"\">2024</a><span class=\"ltx_text\" id=\"S3.T5.2.3.1.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.3.1.2\"><span class=\"ltx_text\" id=\"S3.T5.2.3.1.2.1\" style=\"font-size:90%;\">32.8</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.4.2.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.4.2.1.1\" style=\"font-size:90%;\">Gemini-1.5-Pro </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.4.2.1.2.1\" style=\"font-size:90%;\">(</span>Reid et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.4.2.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib46\" title=\"\">2024</a><span class=\"ltx_text\" id=\"S3.T5.2.4.2.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.4.2.2\"><span class=\"ltx_text\" id=\"S3.T5.2.4.2.2.1\" style=\"font-size:90%;\">33.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.5.3.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.5.3.1.1\" style=\"font-size:90%;\">GPT-4-Turbo </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.5.3.1.2.1\" style=\"font-size:90%;\">(</span>Achiam et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.5.3.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib1\" title=\"\">2023</a><span class=\"ltx_text\" id=\"S3.T5.2.5.3.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.5.3.2\"><span class=\"ltx_text\" id=\"S3.T5.2.5.3.2.1\" style=\"font-size:90%;\">42.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S3.T5.2.6.4.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T5.2.6.4.1.1\" style=\"font-size:90%;\">Fully-supervised RAG</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.7.5.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.7.5.1.1\" style=\"font-size:90%;\">DrKIT </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.7.5.1.2.1\" style=\"font-size:90%;\">(</span>Dhingra et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.7.5.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib15\" title=\"\">2020</a><span class=\"ltx_text\" id=\"S3.T5.2.7.5.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.7.5.2\"><span class=\"ltx_text\" id=\"S3.T5.2.7.5.2.1\" style=\"font-size:90%;\">42.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.8.6.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.8.6.1.1\" style=\"font-size:90%;\">Transformer-XH&#160;</span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.8.6.1.2.1\" style=\"font-size:90%;\">(</span>Zhao et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.8.6.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib60\" title=\"\">2019</a><span class=\"ltx_text\" id=\"S3.T5.2.8.6.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.8.6.2\"><span class=\"ltx_text\" id=\"S3.T5.2.8.6.2.1\" style=\"font-size:90%;\">51.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.9.7.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.9.7.1.1\" style=\"font-size:90%;\">QAMAT+ </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.9.7.1.2.1\" style=\"font-size:90%;\">(</span>Chen et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.9.7.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib10\" title=\"\">2023b</a><span class=\"ltx_text\" id=\"S3.T5.2.9.7.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.9.7.2\"><span class=\"ltx_text\" id=\"S3.T5.2.9.7.2.1\" style=\"font-size:90%;\">57.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.10.8.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.10.8.1.1\" style=\"font-size:90%;\">HGN </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.10.8.1.2.1\" style=\"font-size:90%;\">(</span>Fang et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.10.8.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib17\" title=\"\">2019</a><span class=\"ltx_text\" id=\"S3.T5.2.10.8.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.10.8.2\"><span class=\"ltx_text\" id=\"S3.T5.2.10.8.2.1\" style=\"font-size:90%;\">59.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.11.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.11.9.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.11.9.1.1\" style=\"font-size:90%;\">PathRetriever </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.11.9.1.2.1\" style=\"font-size:90%;\">(</span>Asai et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.11.9.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib4\" title=\"\">2019</a><span class=\"ltx_text\" id=\"S3.T5.2.11.9.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.11.9.2\"><span class=\"ltx_text\" id=\"S3.T5.2.11.9.2.1\" style=\"font-size:90%;\">60.0</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.12.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.12.10.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.12.10.1.1\" style=\"font-size:90%;\">HopRetrieve </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.12.10.1.2.1\" style=\"font-size:90%;\">(</span>Li et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.12.10.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib35\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.2.12.10.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.12.10.2\"><span class=\"ltx_text\" id=\"S3.T5.2.12.10.2.1\" style=\"font-size:90%;\">62.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.13.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.13.11.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.13.11.1.1\" style=\"font-size:90%;\">MDR </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.13.11.1.2.1\" style=\"font-size:90%;\">(</span>Xiong et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.13.11.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib55\" title=\"\">2020b</a><span class=\"ltx_text\" id=\"S3.T5.2.13.11.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.13.11.2\"><span class=\"ltx_text\" id=\"S3.T5.2.13.11.2.1\" style=\"font-size:90%;\">62.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.14.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.14.12.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.14.12.1.1\" style=\"font-size:90%;\">HopRetrieve-plus </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.14.12.1.2.1\" style=\"font-size:90%;\">(</span>Li et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.14.12.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib35\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.2.14.12.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.14.12.2\"><span class=\"ltx_text\" id=\"S3.T5.2.14.12.2.1\" style=\"font-size:90%;\">66.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.15.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.15.13.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.15.13.1.1\" style=\"font-size:90%;\">AISO </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.15.13.1.2.1\" style=\"font-size:90%;\">(</span>Zhu et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.15.13.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib63\" title=\"\">2021</a><span class=\"ltx_text\" id=\"S3.T5.2.15.13.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.15.13.2\"><span class=\"ltx_text\" id=\"S3.T5.2.15.13.2.1\" style=\"font-size:90%;\">68.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.16.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.16.14.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.16.14.1.1\" style=\"font-size:90%;\">COS </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.16.14.1.2.1\" style=\"font-size:90%;\">(</span>Ma et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.16.14.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib37\" title=\"\">2023</a><span class=\"ltx_text\" id=\"S3.T5.2.16.14.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.16.14.2\"><span class=\"ltx_text\" id=\"S3.T5.2.16.14.2.1\" style=\"font-size:90%;\">68.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.17.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"2\" id=\"S3.T5.2.17.15.1\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\" id=\"S3.T5.2.17.15.1.1\" style=\"font-size:90%;\">No Fine-tuning RAG</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.18.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.18.16.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.18.16.1.1\" style=\"font-size:90%;\">DSP </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.18.16.1.2.1\" style=\"font-size:90%;\">(</span>Khattab et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.18.16.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib31\" title=\"\">2022</a><span class=\"ltx_text\" id=\"S3.T5.2.18.16.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.18.16.2\"><span class=\"ltx_text\" id=\"S3.T5.2.18.16.2.1\" style=\"font-size:90%;\">51.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.19.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.19.17.1\">\n<span class=\"ltx_text\" id=\"S3.T5.2.19.17.1.1\" style=\"font-size:90%;\">PromptRank </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S3.T5.2.19.17.1.2.1\" style=\"font-size:90%;\">(</span>Khalifa et&#160;al.<span class=\"ltx_text\" id=\"S3.T5.2.19.17.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15319v3#bib.bib30\" title=\"\">2023</a><span class=\"ltx_text\" id=\"S3.T5.2.19.17.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.19.17.2\"><span class=\"ltx_text\" id=\"S3.T5.2.19.17.2.1\" style=\"font-size:90%;\">55.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.20.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S3.T5.2.20.18.1\"><span class=\"ltx_text\" id=\"S3.T5.2.20.18.1.1\" style=\"font-size:90%;\">LongRAG (Gemini-1.5-Pro; Recall 8 units)</span></th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T5.2.20.18.2\"><span class=\"ltx_text\" id=\"S3.T5.2.20.18.2.1\" style=\"font-size:90%;\">57.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T5.2.21.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T5.2.21.19.1\"><span class=\"ltx_text\" id=\"S3.T5.2.21.19.1.1\" style=\"font-size:90%;\">LongRAG (GPT-4o; Recall 8 units)</span></th>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S3.T5.2.21.19.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T5.2.21.19.2.1\" style=\"font-size:90%;\">64.3</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 5: The tables show the QA results on the NQ test dataset (left) and Hotpot-QA dev set (right). We compare the results with three groups of baselines: closed-book, which involves directly prompting state-of-the-art LLMs with 16-shot in-context examples; fully-supervised RAG, where the RAG framework is used and the model is fully supervised and trained on the training data; and No Fine-tuning RAG, which employs the RAG framework without any tuning.",
        "footnotes": [
            "Anthropic (2024)\n\nAnthropic.\n\n\nIntroducing the next generation of claude.\n\n\n2024.",
            "Reid et al. (2024)\n\nMachel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al.\n\n\nGemini 1.5: Unlocking multimodal understanding across millions of tokens of context.\n\n\narXiv preprint arXiv:2403.05530, 2024.",
            "Achiam et al. (2023)\n\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.\n\n\nGpt-4 technical report.\n\n\narXiv preprint arXiv:2303.08774, 2023.",
            "Dhingra et al. (2020)\n\nBhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, and William W Cohen.\n\n\nDifferentiable reasoning over a virtual knowledge base.\n\n\narXiv preprint arXiv:2002.10640, 2020.",
            "Zhao et al. (2019)\n\nChen Zhao, Chenyan Xiong, Corby Rosset, Xia Song, Paul Bennett, and Saurabh Tiwary.\n\n\nTransformer-xh: Multi-evidence reasoning with extra hop attention.\n\n\nIn International Conference on Learning Representations, 2019.",
            "Chen et al. (2023b)\n\nWenhu Chen, Pat Verga, Michiel de Jong, John Wieting, and William Cohen.\n\n\nAugmenting pre-trained language models with qa-memory for open-domain question answering.\n\n\nIn Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pp.  1597–1610, 2023b.",
            "Fang et al. (2019)\n\nYuwei Fang, Siqi Sun, Zhe Gan, Rohit Pillai, Shuohang Wang, and Jingjing Liu.\n\n\nHierarchical graph network for multi-hop question answering.\n\n\narXiv preprint arXiv:1911.03631, 2019.",
            "Asai et al. (2019)\n\nAkari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong.\n\n\nLearning to retrieve reasoning paths over wikipedia graph for question answering.\n\n\narXiv preprint arXiv:1911.10470, 2019.",
            "Li et al. (2021)\n\nShaobo Li, Xiaoguang Li, Lifeng Shang, Xin Jiang, Qun Liu, Chengjie Sun, Zhenzhou Ji, and Bingquan Liu.\n\n\nHopretriever: Retrieve hops over wikipedia to answer complex questions.\n\n\nIn Proceedings of the AAAI conference on artificial intelligence, volume 35, pp.  13279–13287, 2021.",
            "Xiong et al. (2020b)\n\nWenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, et al.\n\n\nAnswering complex open-domain questions with multi-hop dense retrieval.\n\n\narXiv preprint arXiv:2009.12756, 2020b.",
            "Li et al. (2021)\n\nShaobo Li, Xiaoguang Li, Lifeng Shang, Xin Jiang, Qun Liu, Chengjie Sun, Zhenzhou Ji, and Bingquan Liu.\n\n\nHopretriever: Retrieve hops over wikipedia to answer complex questions.\n\n\nIn Proceedings of the AAAI conference on artificial intelligence, volume 35, pp.  13279–13287, 2021.",
            "Zhu et al. (2021)\n\nYunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng.\n\n\nAdaptive information seeking for open-domain question answering.\n\n\nIn Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp.  3615–3626, 2021.",
            "Ma et al. (2023)\n\nKaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, and Jianfeng Gao.\n\n\nChain-of-skills: A configurable model for open-domain question answering.\n\n\nIn The 61st Annual Meeting Of The Association For Computational Linguistics, 2023.",
            "Khattab et al. (2022)\n\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia.\n\n\nDemonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.\n\n\narXiv preprint arXiv:2212.14024, 2022.",
            "Khalifa et al. (2023)\n\nMuhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang.\n\n\nFew-shot reranking for multi-hop qa via language model prompting.\n\n\narXiv preprint arXiv:2205.12650, 2023."
        ],
        "references": [
            "For NQ and HotpotQA, we compare our model with several groups of strong previous models as baselines. The first group is “Closed-Book”: These baselines mean that no retrieval component is used; instead, state-of-the-art LLMs are employed to directly obtain the final result. We evaluate our results on Gemini-1.5-pro (Reid et al., 2024), Claude-3-Opus (Anthropic, 2024) and GPT-4-Turbo (Achiam et al., 2023). All models are evaluated on 16-shot in-context learning with direct prompting; The second group is “Fully-supervised RAG”, and these baselines involve full-supervised fine-tuning on the training dataset. The third group is “No Fine-tuning RAG”, and these baselines doesn’t involve any supervised fine-tuning. The QA results on NQ and HotpotQA are presented in Table 5. On the NQ dataset, LongRAG achieves a 62.7 exact match rate, which is on par of the strongest fine-tuned RAG model like Atlas. On the HotpotQA dataset, LongRAG achieves a 64.3 exact match rate, which is also close to the SoTA fully-supervised RAG frameworks."
        ]
    },
    "S3.T6.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S3.T6.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T6.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.1.1.1.1.1.1\" style=\"font-size:90%;\">Retrieval Unit</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S3.T6.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.1.1.1.1.2.1\" style=\"font-size:90%;\">Num of Retrieval Units</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T6.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.1.1.1.1.3.1\" style=\"font-size:90%;\">Qasper</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S3.T6.1.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.1.1.1.1.4.1\" style=\"font-size:90%;\">MutilfieldQA-en</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T6.1.1.2.1.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S3.T6.1.1.2.1.1.1\" style=\"font-size:90%;\">Passage</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T6.1.1.2.1.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.2.1.2.1\" style=\"font-size:90%;\">1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T6.1.1.2.1.3\"><span class=\"ltx_text\" id=\"S3.T6.1.1.2.1.3.1\" style=\"font-size:90%;\">15.5</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T6.1.1.2.1.4\"><span class=\"ltx_text\" id=\"S3.T6.1.1.2.1.4.1\" style=\"font-size:90%;\">38.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T6.1.1.3.2.1\"><span class=\"ltx_text\" id=\"S3.T6.1.1.3.2.1.1\" style=\"font-size:90%;\">10</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T6.1.1.3.2.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.3.2.2.1\" style=\"font-size:90%;\">20.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T6.1.1.3.2.3\"><span class=\"ltx_text\" id=\"S3.T6.1.1.3.2.3.1\" style=\"font-size:90%;\">47.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T6.1.1.4.3.1\"><span class=\"ltx_text\" id=\"S3.T6.1.1.4.3.1.1\" style=\"font-size:90%;\">100</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T6.1.1.4.3.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.4.3.2.1\" style=\"font-size:90%;\">22.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T6.1.1.4.3.3\"><span class=\"ltx_text\" id=\"S3.T6.1.1.4.3.3.1\" style=\"font-size:90%;\">51.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.5.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T6.1.1.5.4.1\"><span class=\"ltx_text\" id=\"S3.T6.1.1.5.4.1.1\" style=\"font-size:90%;\">200</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T6.1.1.5.4.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.5.4.2.1\" style=\"font-size:90%;\">21.9</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T6.1.1.5.4.3\"><span class=\"ltx_text\" id=\"S3.T6.1.1.5.4.3.1\" style=\"font-size:90%;\">50.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.6.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S3.T6.1.1.6.5.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S3.T6.1.1.6.5.1.1\" style=\"font-size:90%;\">Document</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" id=\"S3.T6.1.1.6.5.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.6.5.2.1\" style=\"font-size:90%;\">1</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S3.T6.1.1.6.5.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.1.1.6.5.3.1\" style=\"font-size:90%;\">26.3</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" id=\"S3.T6.1.1.6.5.4\"><span class=\"ltx_text\" id=\"S3.T6.1.1.6.5.4.1\" style=\"font-size:90%;\">49.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.7.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T6.1.1.7.6.1\"><span class=\"ltx_text\" id=\"S3.T6.1.1.7.6.1.1\" style=\"font-size:90%;\">2</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T6.1.1.7.6.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.7.6.2.1\" style=\"font-size:90%;\">25.9</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T6.1.1.7.6.3\"><span class=\"ltx_text\" id=\"S3.T6.1.1.7.6.3.1\" style=\"font-size:90%;\">50.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.8.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S3.T6.1.1.8.7.1\"><span class=\"ltx_text\" id=\"S3.T6.1.1.8.7.1.1\" style=\"font-size:90%;\">5</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S3.T6.1.1.8.7.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.8.7.2.1\" style=\"font-size:90%;\">23.9</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S3.T6.1.1.8.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T6.1.1.8.7.3.1\" style=\"font-size:90%;\">57.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T6.1.1.9.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S3.T6.1.1.9.8.1\"><span class=\"ltx_text\" id=\"S3.T6.1.1.9.8.1.1\" style=\"font-size:90%;\">10</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S3.T6.1.1.9.8.2\"><span class=\"ltx_text\" id=\"S3.T6.1.1.9.8.2.1\" style=\"font-size:90%;\">21.6</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" id=\"S3.T6.1.1.9.8.3\"><span class=\"ltx_text\" id=\"S3.T6.1.1.9.8.3.1\" style=\"font-size:90%;\">56.8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 6: This table presents the QA results on two non-Wiki datasets: Qasper and MultifieldQA-en. The results are evaluated based on token-level F1. Both datasets contain long documents, averaging at least 4K tokens. The results demonstrate that our LongRAG, which operates on long retrieval units, achieves better performance compared to traditional RAG, which operates on short retrieval units.",
        "footnotes": [],
        "references": [
            "For datasets that generate long answers, such as Qasper and MultifieldQA-en, we use the token-level F1 score (F1) as the evaluation metric. For Qasper and MultifieldQA-en, since we repurpose the datasets from single-document QA to a RAG task, we do not directly compare the results with previous models. Instead, we compare the performance of traditional RAG, which operates on 200-token passages, with our LongRAG, which operates on entire documents ranging from 4K to 6K tokens. The results are shown in Table 6. We observe that using long retrieval units at the whole document level performs better than using hundreds of short chunked retrieval units. On the Qasper dataset, gathering 100 short retrieval units of 200 tokens each into the reader achieves a 22.6% F1 score, while using a single long retrieval unit of 5K tokens achieves a 26.3% F1 score. Similarly, on the MultifieldQA-en dataset, gathering 100 short retrieval units of 200 tokens each into the reader results in a 51.3% F1 score, whereas using five long retrieval units of 7K tokens each results in a 57.5% F1 score."
        ]
    },
    "A1.T7.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T7.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T7.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T7.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T7.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T7.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T7.1.1.1.2.1\">Prompt</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T7.1.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T7.1.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.2.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.2.1.1.1.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A1.T7.1.2.1.1.1.1.1\">Closed-Book</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T7.1.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.2.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.2.1.2.1.1\" style=\"width:341.4pt;\">Here are some examples of questions and their corresponding answer, each with a &#8220;Question&#8221; field and an &#8220;Answer&#8221; field. Answer the question directly and don&#8217;t output other thing.\n\n<br class=\"ltx_break\">&#8220;Question&#8221;: &#8230;&#8220;Answer&#8221;: &#8230;\n<br class=\"ltx_break\">&#8220;Question&#8221;: &#8230;&#8220;Answer&#8221;: &#8230;\n<br class=\"ltx_break\">&#8230;\n<br class=\"ltx_break\">&#8220;Question&#8221;: &#8230;&#8220;Answer&#8221;: &#8230;\n<br class=\"ltx_break\">Answer the following question.\n\n<br class=\"ltx_break\">&#8220;Question&#8221;: who is the owner of reading football club &#8220;Answer&#8221;:</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T7.1.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"A1.T7.1.3.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.3.2.1.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.3.2.1.1.1\" style=\"width:56.9pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A1.T7.1.3.2.1.1.1.1\">LongRAG</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"A1.T7.1.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T7.1.3.2.2.1\">\n<span class=\"ltx_p\" id=\"A1.T7.1.3.2.2.1.1\" style=\"width:341.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T7.1.3.2.2.1.1.1\">Turn 1:</span> Go through the following context and then answer the question. The context is a list of Wikipedia documents, ordered by title: &#8230;.\n\n<br class=\"ltx_break\">Each Wikipedia document contains a title field and a text field. The context is:\n\n<br class=\"ltx_break\">&#8220;Title&#8221;: &#8230;&#8220;Text&#8221;: &#8230;\n<br class=\"ltx_break\">&#8220;Title&#8221;: &#8230;&#8220;Text&#8221;: &#8230;\n<br class=\"ltx_break\">&#8230;\n<br class=\"ltx_break\">&#8220;Title&#8221;: &#8230;&#8220;Text&#8221;: &#8230;\n<br class=\"ltx_break\">Find the useful documents from the context, then answer the question: when did the philadelphia eagles play in the super bowl last.\nAnswer the question directly. Your response should be very concise.\n\n<br class=\"ltx_break\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T7.1.3.2.2.1.1.2\">Turn 2</span>: You have been provided with a question and its long answer. Your task is to derive a very concise short answer from the given long answer. It&#8217;s important to ensure that the output short answer remains as simple as possible. Here a few examples:\n\n<br class=\"ltx_break\">&#8220;Question&#8221;: &#8230;&#8220;Long Answer&#8221;: &#8230;&#8220;Short Answer&#8221;: &#8230;\n<br class=\"ltx_break\">&#8220;Question&#8221;: &#8230;&#8220;Long Answer&#8221;: &#8230;&#8220;Short Answer&#8221;: &#8230;\n<br class=\"ltx_break\">&#8230;\n<br class=\"ltx_break\">&#8220;Question&#8221;: &#8230;&#8220;Long Answer&#8221;: &#8230;&#8220;Short Answer&#8221;: &#8230;\n<br class=\"ltx_break\">Extract the short answer of the following question and long answer:\n\n<br class=\"ltx_break\">&#8220;Question&#8221;: when did the philadelphia eagles play in the super bowl last &#8220;Long Answer&#8221;: The Philadelphia Eagles last played in the Super Bowl on February 4, 2018, in Super Bowl LII. &#8220;Short Answer&#8221;:</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 7: Here are the prompts we used for all the experiments. For the closed-book method, we use 16-shot in-context examples. For LongRAG, we use a two-turn approach to extract the final answer. The first turn doesn’t require any in-context examples and generate a longer answer, typically ranging from a few words to a few sentences. In the second turn, we use 8-shot in-context examples to calibrate and extract the exact short answer, which is typically just a few words.",
        "footnotes": [],
        "references": [
            "We leverage Gemini-1.5-Pro and GPT-4o as the reader in our LongRAG framework.\nThe prompt we use for our experiments are in Table 7. For Wiki-based datasets, such as NQ and HotpotQA, which generate short answers typically less than 5 tokens, we use EM (Exact Match rate) as the evaluation metric. We also refine the standard exact match rate definition to more fairly evaluate LongRAG’s performance. More details can be found in Section A.2.",
            "We have put out prompts used for the experiments in Table 7. For the closed-book method, we use 16-shot in-context examples. For LongRAG, we use a two-turn approach to extract the final answer. In the first turn, the long retrieved context and the question are concatenated as input, and we do not use any in-context examples here due to the context being around 30K tokens. Empirically, we found it beneficial to let the reader generate a longer answer initially, typically ranging from a few words to a few sentences. In the second turn, we use 8-shot in-context examples to guide the reader in further extracting the most important part of the long answer as the short answer, which is typically just a few words."
        ]
    },
    "A1.T8.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"A1.T8.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T8.1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.1.1\">Question</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T8.1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.2.1\">Ground truth</span></th>\n<th class=\"ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T8.1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T8.1.1.1.1.3.1\">LongRAG prediction</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T8.1.1.2.1.1\">where does the bob and tom show broadcast from</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"A1.T8.1.1.2.1.2\">Indianapolis , Indiana</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\" id=\"A1.T8.1.1.2.1.3\">Indianapolis</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T8.1.1.3.2.1\">who has given the theory of unbalanced economic growth</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T8.1.1.3.2.2\">Hirschman</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A1.T8.1.1.3.2.3\">Albert O. Hirschman</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T8.1.1.4.3.1\">when does season 6 of the next step start</td>\n<td class=\"ltx_td ltx_align_left\" id=\"A1.T8.1.1.4.3.2\">2018</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"A1.T8.1.1.4.3.3\">September 29, 2018</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T8.1.1.5.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T8.1.1.5.4.1\">what was the precursor to the present day internet</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"A1.T8.1.1.5.4.2\">the ARPANET project</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb\" id=\"A1.T8.1.1.5.4.3\">ARPANET</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 8: Some examples demonstrate that LongRAG has extracted aliases or different forms of the ground truth.",
        "footnotes": [],
        "references": [
            "The most standard metric used in open-domain extractive question answering tasks is EM (Exact Match), since the correct answer must be a substring within the corpus. In our framework, since the long retrieved context, which contains multiple highly-related documents to the given query, is fed into the reader, there is a much higher possibility that an alias of the ground truth exists in the context and can be extracted by the reader. As shown in Table 8, although LongRAG’s prediction doesn’t exactly match the ground truth, it’s obvious that LongRAG’s prediction is correct. To better and more fairly evaluate LongRAG’s performance, we have refined the EM metric slightly. We recognize it as an exact match if the prediction is less than five tokens (indicating that the short answer is successfully extracted as described in Section A.1) and the ground truth is a substring of the prediction or vice versa. We have also manually verified that this refined metric indeed captures aliases or other forms of the ground truth. For the fully-supervised RAG baselines used in our paper, given that they are fine-tuned on the training data and the retrieval unit is a small snippet, we believe that the difference won’t be significant when using the refined EM."
        ]
    },
    "A1.T9.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A1.T9.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A1.T9.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt\" id=\"A1.T9.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.1.1.2.1\">Prompt</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A1.T9.1.2.1\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T9.1.2.1.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.2.1.1.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.2.1.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A1.T9.1.2.1.1.1.1.1\">NQ</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T9.1.2.1.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.2.1.2.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.2.1.2.1.1\" style=\"width:341.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.2.1.2.1.1.1\">Question:</span> how many episodes are in series 7 game of thrones\n\n<br class=\"ltx_break\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.2.1.2.1.1.2\">Answer:</span> seven</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.3.2\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T9.1.3.2.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.3.2.1.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.3.2.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A1.T9.1.3.2.1.1.1.1\">HotpotQA</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T9.1.3.2.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.3.2.2.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.3.2.2.1.1\" style=\"width:341.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.3.2.2.1.1.1\">Question:</span> What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n\n<br class=\"ltx_break\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.3.2.2.1.1.2\">Answer:</span> Chief of Protocol</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.4.3\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T9.1.4.3.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.4.3.1.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.4.3.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A1.T9.1.4.3.1.1.1.1\">Qasper</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" id=\"A1.T9.1.4.3.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.4.3.2.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.4.3.2.1.1\" style=\"width:341.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.4.3.2.1.1.1\">Question:</span> In the paper &#8217;End-to-End Trainable Non-Collaborative Dialog System&#8217;, How is intent annotated?\n\n<br class=\"ltx_break\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.4.3.2.1.1.2\">Answer:</span> using a role-playing task on the Amazon Mechanical Turk platform and collecting typed conversations</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A1.T9.1.5.4\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"A1.T9.1.5.4.1\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.5.4.1.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.5.4.1.1.1\" style=\"width:85.4pt;\"><span class=\"ltx_text ltx_font_smallcaps\" id=\"A1.T9.1.5.4.1.1.1.1\">MultifieldQA-en</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t\" id=\"A1.T9.1.5.4.2\">\n<span class=\"ltx_inline-block ltx_align_top\" id=\"A1.T9.1.5.4.2.1\">\n<span class=\"ltx_p\" id=\"A1.T9.1.5.4.2.1.1\" style=\"width:341.4pt;\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.5.4.2.1.1.1\">Question:</span> What is the name of the most active fan club?\n\n<br class=\"ltx_break\"><span class=\"ltx_text ltx_font_bold\" id=\"A1.T9.1.5.4.2.1.1.2\">Answer:</span> South West Ultras fan club.</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 9: Here are some examples from the four datasets used in our experiments.",
        "footnotes": [],
        "references": []
    }
}