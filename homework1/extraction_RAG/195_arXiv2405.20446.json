{
    "S2.E1": {
        "table": "<table class=\"ltx_equation ltx_eqn_table\" id=\"S2.E1\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"\\text{Response}=G(C\\parallel p)\" class=\"ltx_Math\" display=\"block\" id=\"S2.E1.m1.1\"><semantics id=\"S2.E1.m1.1a\"><mrow id=\"S2.E1.m1.1.1\" xref=\"S2.E1.m1.1.1.cmml\"><mtext id=\"S2.E1.m1.1.1.3\" xref=\"S2.E1.m1.1.1.3a.cmml\">Response</mtext><mo id=\"S2.E1.m1.1.1.2\" xref=\"S2.E1.m1.1.1.2.cmml\">=</mo><mrow id=\"S2.E1.m1.1.1.1\" xref=\"S2.E1.m1.1.1.1.cmml\"><mi id=\"S2.E1.m1.1.1.1.3\" xref=\"S2.E1.m1.1.1.1.3.cmml\">G</mi><mo id=\"S2.E1.m1.1.1.1.2\" xref=\"S2.E1.m1.1.1.1.2.cmml\">&#8290;</mo><mrow id=\"S2.E1.m1.1.1.1.1.1\" xref=\"S2.E1.m1.1.1.1.1.1.1.cmml\"><mo id=\"S2.E1.m1.1.1.1.1.1.2\" stretchy=\"false\" xref=\"S2.E1.m1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S2.E1.m1.1.1.1.1.1.1\" xref=\"S2.E1.m1.1.1.1.1.1.1.cmml\"><mi id=\"S2.E1.m1.1.1.1.1.1.1.2\" xref=\"S2.E1.m1.1.1.1.1.1.1.2.cmml\">C</mi><mo id=\"S2.E1.m1.1.1.1.1.1.1.1\" xref=\"S2.E1.m1.1.1.1.1.1.1.1.cmml\">&#8741;</mo><mi id=\"S2.E1.m1.1.1.1.1.1.1.3\" xref=\"S2.E1.m1.1.1.1.1.1.1.3.cmml\">p</mi></mrow><mo id=\"S2.E1.m1.1.1.1.1.1.3\" stretchy=\"false\" xref=\"S2.E1.m1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.E1.m1.1b\"><apply id=\"S2.E1.m1.1.1.cmml\" xref=\"S2.E1.m1.1.1\"><eq id=\"S2.E1.m1.1.1.2.cmml\" xref=\"S2.E1.m1.1.1.2\"></eq><ci id=\"S2.E1.m1.1.1.3a.cmml\" xref=\"S2.E1.m1.1.1.3\"><mtext id=\"S2.E1.m1.1.1.3.cmml\" xref=\"S2.E1.m1.1.1.3\">Response</mtext></ci><apply id=\"S2.E1.m1.1.1.1.cmml\" xref=\"S2.E1.m1.1.1.1\"><times id=\"S2.E1.m1.1.1.1.2.cmml\" xref=\"S2.E1.m1.1.1.1.2\"></times><ci id=\"S2.E1.m1.1.1.1.3.cmml\" xref=\"S2.E1.m1.1.1.1.3\">&#119866;</ci><apply id=\"S2.E1.m1.1.1.1.1.1.1.cmml\" xref=\"S2.E1.m1.1.1.1.1.1\"><csymbol cd=\"latexml\" id=\"S2.E1.m1.1.1.1.1.1.1.1.cmml\" xref=\"S2.E1.m1.1.1.1.1.1.1.1\">conditional</csymbol><ci id=\"S2.E1.m1.1.1.1.1.1.1.2.cmml\" xref=\"S2.E1.m1.1.1.1.1.1.1.2\">&#119862;</ci><ci id=\"S2.E1.m1.1.1.1.1.1.1.3.cmml\" xref=\"S2.E1.m1.1.1.1.1.1.1.3\">&#119901;</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.E1.m1.1c\">\\text{Response}=G(C\\parallel p)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.E1.m1.1d\">Response = italic_G ( italic_C &#8741; italic_p )</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(1)</span></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": []
    },
    "S3.F3.4": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S3.F3.4\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.F3.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.2.2.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.F3.2.2.2.2\">\n<tr class=\"ltx_tr\" id=\"S3.F3.2.2.2.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.2.2.2.2.3.1\">Black-Box</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.1.1.1.1.1.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.1.1.1.1.1.1.g1\" src=\"x3.png\" width=\"373\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.2.2.2.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.2.2.2.2.2.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.2.2.2.2.2.1.g1\" src=\"x4.png\" width=\"373\"></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center\" id=\"S3.F3.4.4.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.F3.4.4.4.2\">\n<tr class=\"ltx_tr\" id=\"S3.F3.4.4.4.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.4.4.4.2.3.1\">Gray-Box</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.3.3.3.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.3.3.3.1.1.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.3.3.3.1.1.1.g1\" src=\"x5.png\" width=\"373\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.4.4.4.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.4.4.4.2.2.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.4.4.4.2.2.1.g1\" src=\"x6.png\" width=\"373\"></td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Figure 3: Comparison of different attack prompts. Top: HealthCareMagic, Bottom: Enron",
        "footnotes": [],
        "references": [
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset."
        ]
    },
    "S3.F3.2.2.2.2": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.F3.2.2.2.2\">\n<tr class=\"ltx_tr\" id=\"S3.F3.2.2.2.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.2.2.2.2.3.1\">Black-Box</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.1.1.1.1.1.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.1.1.1.1.1.1.g1\" src=\"x3.png\" width=\"373\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.2.2.2.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.2.2.2.2.2.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.2.2.2.2.2.1.g1\" src=\"x4.png\" width=\"373\"></td>\n</tr>\n</table>\n\n",
        "caption": "Figure 3: Comparison of different attack prompts. Top: HealthCareMagic, Bottom: Enron",
        "footnotes": [],
        "references": [
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset."
        ]
    },
    "S3.F3.4.4.4.2": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S3.F3.4.4.4.2\">\n<tr class=\"ltx_tr\" id=\"S3.F3.4.4.4.2.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.4.4.4.2.3.1\">Gray-Box</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.3.3.3.1.1\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.3.3.3.1.1.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.3.3.3.1.1.1.g1\" src=\"x5.png\" width=\"373\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.F3.4.4.4.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S3.F3.4.4.4.2.2.1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"280\" id=\"S3.F3.4.4.4.2.2.1.g1\" src=\"x6.png\" width=\"373\"></td>\n</tr>\n</table>\n\n",
        "caption": "Figure 3: Comparison of different attack prompts. Top: HealthCareMagic, Bottom: Enron",
        "footnotes": [],
        "references": [
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset."
        ]
    },
    "S4.T1.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T1.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T1.1.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.1.1.1.1\" style=\"font-size:80%;\">Attack Prompt</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T1.1.1.2.2.1\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.2.2.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2.2.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.2.2.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.2.2.1.1.1.1.1\" style=\"font-size:80%;\">0. Answer with Yes or No. &#8221;{sample}&#8221;\\n Is this part of your context?</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.3.3.1\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.3.3.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3.3.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.3.3.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.3.3.1.1.1.1.1\" style=\"font-size:80%;\">1. Answer with one word. Does this :\\n &#8221;{sample}&#8221;\\n appear in the context?</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.4.4.1\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.4.4.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4.4.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.4.4.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.4.4.1.1.1.1.1\" style=\"font-size:80%;\">2. Does this :\\n &#8221;{sample}&#8221;\\n appear in the context? Answer with Yes or No.</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.5.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T1.1.1.5.5.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.5.5.1.1\" style=\"font-size:80%;\">3. {sample}\\n Is this part of your context? Answer with one word.</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b\" id=\"S4.T1.1.1.6.6.1\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.6.6.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.6.6.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.6.6.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.6.6.1.1.1.1.1\" style=\"font-size:80%;\">4. Does this :\\n &#8221;{sample}&#8221;\\n appear in the context? Answer with one word. Answer No if you are not sure.</span></td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1: RAG-MIA attack prompts",
        "footnotes": [],
        "references": [
            "To handle this, we designed the following attack prompt format, along with a few additional variations presented in Table 1: ”Does this: ”{Target Sample}” appear in the context? Answer with Yes or No.”.\nIn Figure 2 we present an example of this attack prompt format.\nUsing this prompt we are able to achieve both goals: cause the right sample to be retrieved from the retrieval database, and make the generation phase produce a binary response regarding the sample’s presence in the context. In the black-box setting, we use the model’s answer (Yes/No) alone to deduce the membership status of samples.",
            "In our evaluation we experimented with 5 different attack prompts, listed in Table 1. Each attack prompt includes a placeholder for a sample, which can be a member or a non-member sample, as shown in Section 3. In the case of the Enron dataset, the sample is the full email body, or its first 1000 characters if it is longer. In HealthCareMagic, the human part of the dialogue is used as the sample.",
            "One important aspect of performing attacks against any generative model is the prompt used to trigger the attack.\nIn the case of RAG, the attack prompt is first used to fetch the relevant documents from the retrieval database, and is then incorporated together with the fetched documents into the RAG template and provided to the generative model.\nTo achieve the best performance, we experimented with five possible attack prompts, described in Table 1.\nEach one tries to manipulate the RAG system in a slightly different manner to both fetch the relevant documents from the retrieval database, and cause the generative model to output whether the target document was indeed in the retrieval database."
        ]
    },
    "S4.T1.1.1.2.2.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.2.2.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2.2.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.2.2.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.2.2.1.1.1.1.1\" style=\"font-size:80%;\">0. Answer with Yes or No. &#8221;{sample}&#8221;\\n Is this part of your context?</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 1: RAG-MIA attack prompts",
        "footnotes": [],
        "references": [
            "To handle this, we designed the following attack prompt format, along with a few additional variations presented in Table 1: ”Does this: ”{Target Sample}” appear in the context? Answer with Yes or No.”.\nIn Figure 2 we present an example of this attack prompt format.\nUsing this prompt we are able to achieve both goals: cause the right sample to be retrieved from the retrieval database, and make the generation phase produce a binary response regarding the sample’s presence in the context. In the black-box setting, we use the model’s answer (Yes/No) alone to deduce the membership status of samples.",
            "In our evaluation we experimented with 5 different attack prompts, listed in Table 1. Each attack prompt includes a placeholder for a sample, which can be a member or a non-member sample, as shown in Section 3. In the case of the Enron dataset, the sample is the full email body, or its first 1000 characters if it is longer. In HealthCareMagic, the human part of the dialogue is used as the sample.",
            "One important aspect of performing attacks against any generative model is the prompt used to trigger the attack.\nIn the case of RAG, the attack prompt is first used to fetch the relevant documents from the retrieval database, and is then incorporated together with the fetched documents into the RAG template and provided to the generative model.\nTo achieve the best performance, we experimented with five possible attack prompts, described in Table 1.\nEach one tries to manipulate the RAG system in a slightly different manner to both fetch the relevant documents from the retrieval database, and cause the generative model to output whether the target document was indeed in the retrieval database."
        ]
    },
    "S4.T1.1.1.3.3.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.3.3.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3.3.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.3.3.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.3.3.1.1.1.1.1\" style=\"font-size:80%;\">1. Answer with one word. Does this :\\n &#8221;{sample}&#8221;\\n appear in the context?</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 1: RAG-MIA attack prompts",
        "footnotes": [],
        "references": [
            "To handle this, we designed the following attack prompt format, along with a few additional variations presented in Table 1: ”Does this: ”{Target Sample}” appear in the context? Answer with Yes or No.”.\nIn Figure 2 we present an example of this attack prompt format.\nUsing this prompt we are able to achieve both goals: cause the right sample to be retrieved from the retrieval database, and make the generation phase produce a binary response regarding the sample’s presence in the context. In the black-box setting, we use the model’s answer (Yes/No) alone to deduce the membership status of samples.",
            "In our evaluation we experimented with 5 different attack prompts, listed in Table 1. Each attack prompt includes a placeholder for a sample, which can be a member or a non-member sample, as shown in Section 3. In the case of the Enron dataset, the sample is the full email body, or its first 1000 characters if it is longer. In HealthCareMagic, the human part of the dialogue is used as the sample.",
            "One important aspect of performing attacks against any generative model is the prompt used to trigger the attack.\nIn the case of RAG, the attack prompt is first used to fetch the relevant documents from the retrieval database, and is then incorporated together with the fetched documents into the RAG template and provided to the generative model.\nTo achieve the best performance, we experimented with five possible attack prompts, described in Table 1.\nEach one tries to manipulate the RAG system in a slightly different manner to both fetch the relevant documents from the retrieval database, and cause the generative model to output whether the target document was indeed in the retrieval database."
        ]
    },
    "S4.T1.1.1.4.4.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.4.4.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4.4.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.4.4.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.4.4.1.1.1.1.1\" style=\"font-size:80%;\">2. Does this :\\n &#8221;{sample}&#8221;\\n appear in the context? Answer with Yes or No.</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 1: RAG-MIA attack prompts",
        "footnotes": [],
        "references": [
            "To handle this, we designed the following attack prompt format, along with a few additional variations presented in Table 1: ”Does this: ”{Target Sample}” appear in the context? Answer with Yes or No.”.\nIn Figure 2 we present an example of this attack prompt format.\nUsing this prompt we are able to achieve both goals: cause the right sample to be retrieved from the retrieval database, and make the generation phase produce a binary response regarding the sample’s presence in the context. In the black-box setting, we use the model’s answer (Yes/No) alone to deduce the membership status of samples.",
            "In our evaluation we experimented with 5 different attack prompts, listed in Table 1. Each attack prompt includes a placeholder for a sample, which can be a member or a non-member sample, as shown in Section 3. In the case of the Enron dataset, the sample is the full email body, or its first 1000 characters if it is longer. In HealthCareMagic, the human part of the dialogue is used as the sample.",
            "One important aspect of performing attacks against any generative model is the prompt used to trigger the attack.\nIn the case of RAG, the attack prompt is first used to fetch the relevant documents from the retrieval database, and is then incorporated together with the fetched documents into the RAG template and provided to the generative model.\nTo achieve the best performance, we experimented with five possible attack prompts, described in Table 1.\nEach one tries to manipulate the RAG system in a slightly different manner to both fetch the relevant documents from the retrieval database, and cause the generative model to output whether the target document was indeed in the retrieval database."
        ]
    },
    "S4.T1.1.1.6.6.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T1.1.1.6.6.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.6.6.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\" id=\"S4.T1.1.1.6.6.1.1.1.1\"><span class=\"ltx_text\" id=\"S4.T1.1.1.6.6.1.1.1.1.1\" style=\"font-size:80%;\">4. Does this :\\n &#8221;{sample}&#8221;\\n appear in the context? Answer with one word. Answer No if you are not sure.</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 1: RAG-MIA attack prompts",
        "footnotes": [],
        "references": [
            "To handle this, we designed the following attack prompt format, along with a few additional variations presented in Table 1: ”Does this: ”{Target Sample}” appear in the context? Answer with Yes or No.”.\nIn Figure 2 we present an example of this attack prompt format.\nUsing this prompt we are able to achieve both goals: cause the right sample to be retrieved from the retrieval database, and make the generation phase produce a binary response regarding the sample’s presence in the context. In the black-box setting, we use the model’s answer (Yes/No) alone to deduce the membership status of samples.",
            "In our evaluation we experimented with 5 different attack prompts, listed in Table 1. Each attack prompt includes a placeholder for a sample, which can be a member or a non-member sample, as shown in Section 3. In the case of the Enron dataset, the sample is the full email body, or its first 1000 characters if it is longer. In HealthCareMagic, the human part of the dialogue is used as the sample.",
            "One important aspect of performing attacks against any generative model is the prompt used to trigger the attack.\nIn the case of RAG, the attack prompt is first used to fetch the relevant documents from the retrieval database, and is then incorporated together with the fetched documents into the RAG template and provided to the generative model.\nTo achieve the best performance, we experimented with five possible attack prompts, described in Table 1.\nEach one tries to manipulate the RAG system in a slightly different manner to both fetch the relevant documents from the retrieval database, and cause the generative model to output whether the target document was indeed in the retrieval database."
        ]
    },
    "S4.T2.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T2.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.1.1.1.1.2\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.1.3\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T2.1.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.3.1.1.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.3.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.3.1.2.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.3.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.1.1.1.1.4\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T2.1.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S4.T2.1.1.2.1.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.2.1.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" id=\"S4.T2.1.1.2.1.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.2.1.2.1\" style=\"font-size:80%;\">Model</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"S4.T2.1.1.2.1.3\"></th>\n<td class=\"ltx_td\" id=\"S4.T2.1.1.2.1.4\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.1.3.2.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.3.2.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.1.3.2.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.3.2.2.1\" style=\"font-size:80%;\">flan</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.1.1.3.2.3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.3.2.3.1\" style=\"font-size:80%;\">0.80</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.1.1.3.2.4\"><span class=\"ltx_text\" id=\"S4.T2.1.1.3.2.4.1\" style=\"font-size:80%;\">1.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.1.4.3.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.4.3.1.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.1.1.4.3.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.4.3.2.1\" style=\"font-size:80%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.1.1.4.3.3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.4.3.3.1\" style=\"font-size:80%;\">0.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.1.5.4.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.5.4.1.1\" style=\"font-size:80%;\">mistral</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.1.1.5.4.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.5.4.2.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.1.1.5.4.3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.5.4.3.1\" style=\"font-size:80%;\">0.83</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T2.1.1.6.5.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.6.5.1.1\" style=\"font-size:80%;\">Enron</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.1.6.5.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.6.5.2.1\" style=\"font-size:80%;\">flan</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.1.1.6.5.3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.6.5.3.1\" style=\"font-size:80%;\">0.82</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T2.1.1.6.5.4\"><span class=\"ltx_text\" id=\"S4.T2.1.1.6.5.4.1\" style=\"font-size:80%;\">0.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.1.7.6.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.7.6.1.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.1.1.7.6.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.7.6.2.1\" style=\"font-size:80%;\">0.79</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T2.1.1.7.6.3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.7.6.3.1\" style=\"font-size:80%;\">0.83</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b\" id=\"S4.T2.1.1.8.7.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.8.7.1.1\" style=\"font-size:80%;\">mistral</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"S4.T2.1.1.8.7.2\"><span class=\"ltx_text\" id=\"S4.T2.1.1.8.7.2.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"S4.T2.1.1.8.7.3\"><span class=\"ltx_text\" id=\"S4.T2.1.1.8.7.3.1\" style=\"font-size:80%;\">0.82</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2: RAG-MIA results summary",
        "footnotes": [],
        "references": [
            "To quantify the overall MIA risk, we summarize the best results (across prompts) for each combination of model and dataset in Table 2 .\nWe can see that, on average, the attack success rate is highest for flan, in both threat models.\nIn addition, we observe that the overall risk in the black-box setting is similar between almost all models, with the exception of the HealthCareMagic-llama case. However in the gray-box setting the results vary more."
        ]
    },
    "S4.T2.1.1.1.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T2.1.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.3.1.1.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.3.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.3.1.2.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.3.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 2: RAG-MIA results summary",
        "footnotes": [],
        "references": [
            "To quantify the overall MIA risk, we summarize the best results (across prompts) for each combination of model and dataset in Table 2 .\nWe can see that, on average, the attack success rate is highest for flan, in both threat models.\nIn addition, we observe that the overall risk in the black-box setting is similar between almost all models, with the exception of the HealthCareMagic-llama case. However in the gray-box setting the results vary more."
        ]
    },
    "S4.T2.1.1.1.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T2.1.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T2.1.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"S4.T2.1.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 2: RAG-MIA results summary",
        "footnotes": [],
        "references": [
            "To quantify the overall MIA risk, we summarize the best results (across prompts) for each combination of model and dataset in Table 2 .\nWe can see that, on average, the attack success rate is highest for flan, in both threat models.\nIn addition, we observe that the overall risk in the black-box setting is similar between almost all models, with the exception of the HealthCareMagic-llama case. However in the gray-box setting the results vary more."
        ]
    },
    "S4.T3.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"S4.T3.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.1.1.2\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T3.1.1.1.1.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.1.3.1\" style=\"font-size:80%;\">Without defense</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" id=\"S4.T3.1.1.1.1.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.1.4.1\" style=\"font-size:80%;\">With defense</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S4.T3.1.1.2.2.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.2.2.2\"></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.2.2.3\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.3.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.3.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.3.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.3.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.1.1.2.2.4\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.4.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.4.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.4.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.2.2.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.5.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.5.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.5.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.5.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.5.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.2.2.6\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.6.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.6.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.6.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.6.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.6.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.6.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.6.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.1.1.3.3.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.3.3.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.3.3.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.3.3.2.1\" style=\"font-size:80%;\">Model</span></th>\n<td class=\"ltx_td\" id=\"S4.T3.1.1.3.3.3\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T3.1.1.3.3.4\"></td>\n<td class=\"ltx_td\" id=\"S4.T3.1.1.3.3.5\"></td>\n<td class=\"ltx_td\" id=\"S4.T3.1.1.3.3.6\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.1.1.4.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.4.4.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.4.4.2.1\" style=\"font-size:80%;\">flan</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.1.4.4.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.4.4.3.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.4.4.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.4.4.4.1\" style=\"font-size:80%;\">0.99</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.1.4.4.5\"><span class=\"ltx_text\" id=\"S4.T3.1.1.4.4.5.1\" style=\"font-size:80%;\">0.86</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.1.4.4.6\"><span class=\"ltx_text\" id=\"S4.T3.1.1.4.4.6.1\" style=\"font-size:80%;\">0.90</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.5.5.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.5.5.1.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.5.5.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.5.5.2.1\" style=\"font-size:80%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.1.1.5.5.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.5.5.3.1\" style=\"font-size:80%;\">0.96</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.5.5.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.5.5.4.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.5.5.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.5.5.5.1\" style=\"font-size:80%;\">0.51</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.6.6.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.6.6.1.1\" style=\"font-size:80%;\">mistral</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.6.6.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.6.6.2.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.1.1.6.6.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.6.6.3.1\" style=\"font-size:80%;\">0.83</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.6.6.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.6.6.4.1\" style=\"font-size:80%;\">0.72</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.6.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.6.6.5.1\" style=\"font-size:80%;\">0.44</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T3.1.1.7.7.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.1.1\" style=\"font-size:80%;\">Enron</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.7.7.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.2.1\" style=\"font-size:80%;\">flan</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.1.7.7.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.3.1\" style=\"font-size:80%;\">0.82</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.7.7.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.4.1\" style=\"font-size:80%;\">0.97</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.1.7.7.5\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.5.1\" style=\"font-size:80%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T3.1.1.7.7.6\"><span class=\"ltx_text\" id=\"S4.T3.1.1.7.7.6.1\" style=\"font-size:80%;\">0.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.8.8.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.8.8.1.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.8.8.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.8.8.2.1\" style=\"font-size:80%;\">0.79</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T3.1.1.8.8.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.8.8.3.1\" style=\"font-size:80%;\">0.84</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.8.8.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.8.8.4.1\" style=\"font-size:80%;\">0.77</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T3.1.1.8.8.5\"><span class=\"ltx_text\" id=\"S4.T3.1.1.8.8.5.1\" style=\"font-size:80%;\">0.78</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r\" id=\"S4.T3.1.1.9.9.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.9.9.1.1\" style=\"font-size:80%;\">mistral</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"S4.T3.1.1.9.9.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.9.9.2.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_r\" id=\"S4.T3.1.1.9.9.3\"><span class=\"ltx_text\" id=\"S4.T3.1.1.9.9.3.1\" style=\"font-size:80%;\">0.80</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"S4.T3.1.1.9.9.4\"><span class=\"ltx_text\" id=\"S4.T3.1.1.9.9.4.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"S4.T3.1.1.9.9.5\"><span class=\"ltx_text\" id=\"S4.T3.1.1.9.9.5.1\" style=\"font-size:80%;\">0.72</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 3: RAG MIA results with defense",
        "footnotes": [],
        "references": [
            "We have slightly adapted the RAG template for the llama model, such that it will respond to the defense instructions better, by placing the defense instructions inside the system prompt, an integral capability of llama models.\nIn Table 3 we present the results, and compare them to the scenario where no defense is placed in the RAG system."
        ]
    },
    "S4.T3.1.1.2.2.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.3.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.3.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.3.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.3.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 3: RAG MIA results with defense",
        "footnotes": [],
        "references": [
            "We have slightly adapted the RAG template for the llama model, such that it will respond to the defense instructions better, by placing the defense instructions inside the system prompt, an integral capability of llama models.\nIn Table 3 we present the results, and compare them to the scenario where no defense is placed in the RAG system."
        ]
    },
    "S4.T3.1.1.2.2.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.4.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.4.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.4.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 3: RAG MIA results with defense",
        "footnotes": [],
        "references": [
            "We have slightly adapted the RAG template for the llama model, such that it will respond to the defense instructions better, by placing the defense instructions inside the system prompt, an integral capability of llama models.\nIn Table 3 we present the results, and compare them to the scenario where no defense is placed in the RAG system."
        ]
    },
    "S4.T3.1.1.2.2.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.5.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.5.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.5.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.5.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.5.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 3: RAG MIA results with defense",
        "footnotes": [],
        "references": [
            "We have slightly adapted the RAG template for the llama model, such that it will respond to the defense instructions better, by placing the defense instructions inside the system prompt, an integral capability of llama models.\nIn Table 3 we present the results, and compare them to the scenario where no defense is placed in the RAG system."
        ]
    },
    "S4.T3.1.1.2.2.6.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T3.1.1.2.2.6.1\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.6.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.6.1.1.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.6.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2.6.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T3.1.1.2.2.6.1.2.1\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.2.6.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 3: RAG MIA results with defense",
        "footnotes": [],
        "references": [
            "We have slightly adapted the RAG template for the llama model, such that it will respond to the defense instructions better, by placing the defense instructions inside the system prompt, an integral capability of llama models.\nIn Table 3 we present the results, and compare them to the scenario where no defense is placed in the RAG system."
        ]
    },
    "S4.T4.1.1": {
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T4.1.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T4.1.1.1.1.2\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T4.1.1.1.1.3\"><span class=\"ltx_text\" id=\"S4.T4.1.1.1.1.3.1\" style=\"font-size:80%;\">Without Defense</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T4.1.1.1.1.4\"><span class=\"ltx_text\" id=\"S4.T4.1.1.1.1.4.1\" style=\"font-size:80%;\">With Defense #1</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\" id=\"S4.T4.1.1.1.1.5\"><span class=\"ltx_text\" id=\"S4.T4.1.1.1.1.5.1\" style=\"font-size:80%;\">With Defense #2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S4.T4.1.1.2.1.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.1.2.1.2\"></th>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T4.1.1.2.1.3\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.3.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.3.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.3.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.3.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T4.1.1.2.1.4\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.4.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.4.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.4.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T4.1.1.2.1.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.5.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.5.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.5.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.5.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.5.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S4.T4.1.1.2.1.6\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.6.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.6.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.6.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.6.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.6.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.6.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.6.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T4.1.1.2.1.7\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.7.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.7.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.7.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.7.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.7.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.7.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.7.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S4.T4.1.1.2.1.8\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.8.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.8.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.8.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.8.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.8.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T4.1.1.3.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.3.2.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.1.3.2.2\"><span class=\"ltx_text\" id=\"S4.T4.1.1.3.2.2.1\" style=\"font-size:80%;\">Model</span></th>\n<td class=\"ltx_td\" id=\"S4.T4.1.1.3.2.3\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T4.1.1.3.2.4\"></td>\n<td class=\"ltx_td\" id=\"S4.T4.1.1.3.2.5\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"S4.T4.1.1.3.2.6\"></td>\n<td class=\"ltx_td\" id=\"S4.T4.1.1.3.2.7\"></td>\n<td class=\"ltx_td\" id=\"S4.T4.1.1.3.2.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T4.1.1.4.3.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.3.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.4.3.2\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.3.2.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.1.4.3.3\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.3.3.1\" style=\"font-size:80%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.4.3.4\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.3.4.1\" style=\"font-size:80%;\">0.96</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.1.4.3.5\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.3.5.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.6.1\" style=\"font-size:80%;\">0.51</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.1.4.3.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.7.1\" style=\"font-size:80%;\">0.42</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S4.T4.1.1.4.3.8\"><span class=\"ltx_text\" id=\"S4.T4.1.1.4.3.8.1\" style=\"font-size:80%;\">0.75</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T4.1.1.5.4.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.1.1\" style=\"font-size:80%;\">Enron</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.5.4.2\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.2.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T4.1.1.5.4.3\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.3.1\" style=\"font-size:80%;\">0.79</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.5.4.4\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.4.1\" style=\"font-size:80%;\">0.84</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T4.1.1.5.4.5\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.5.1\" style=\"font-size:80%;\">0.77</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.5.4.6\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.6.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T4.1.1.5.4.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.5.4.7.1\" style=\"font-size:80%;\">0.46</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_t\" id=\"S4.T4.1.1.5.4.8\"><span class=\"ltx_text\" id=\"S4.T4.1.1.5.4.8.1\" style=\"font-size:80%;\">0.92</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "S4.T4.1.1.2.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.3.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.3.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.3.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.3.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "S4.T4.1.1.2.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.4.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.4.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.4.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "S4.T4.1.1.2.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.5.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.5.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.5.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.5.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.5.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "S4.T4.1.1.2.1.6.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.6.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.6.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.6.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.6.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.6.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.6.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.6.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "S4.T4.1.1.2.1.7.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.7.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.7.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.7.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.7.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.7.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.7.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.7.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "S4.T4.1.1.2.1.8.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S4.T4.1.1.2.1.8.1\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.8.1.1.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.8.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T4.1.1.2.1.8.1.2.1\"><span class=\"ltx_text\" id=\"S4.T4.1.1.2.1.8.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 4: Llama defenses",
        "footnotes": [],
        "references": [
            "Since llama models have a dedicated section in the input prompt for system instructions, as mentioned in Section 4.3, we have experimented with placing the retrieved database content within this dedicated section.\nWe compare two cases: (1) With Defense #1 - only the defense instructions are added to the system section (2) With Defense #2 - both defense instructions and retrieved database content are placed in the system section.\nWe present the results for this experiment in Table 4.",
            "As shown in Table 4, placing defense instructions and retrieved database content in the system section provides robust defense against black-box attacks. However, this approach is less effective against gray-box attacks, where Defense #1 is preferred. Since black-box attacks are more common and require less effort from the attacker, we recommend using Defense #2. Nevertheless, we encourage the research community to develop a defense strategy that can effectively protect from both kinds of attack."
        ]
    },
    "Pt0.Ax1.T5.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Pt0.Ax1.T5.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"Pt0.Ax1.T5.1.1.1.1\"></td>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T5.1.1.1.2\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T5.1.1.1.3\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T5.1.1.1.4\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T5.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T5.1.1.1.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T5.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T5.1.2.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.2.2.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T5.1.2.2.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.2.2.2.1\" style=\"font-size:80%;\">Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T5.1.2.2.3\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T5.1.2.2.3.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.2.2.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.2.2.3.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.2.2.3.1.1.1.1\" style=\"font-size:80%;\">Attack</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.2.2.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.2.2.3.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.2.2.3.1.2.1.1\" style=\"font-size:80%;\">Prompt</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T5.1.2.2.4\"></th>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T5.1.2.2.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T5.1.3.3.1\" rowspan=\"15\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.3.3.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></td>\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T5.1.3.3.2\" rowspan=\"5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.3.3.2.1\" style=\"font-size:80%;\">flan</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T5.1.3.3.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.3.3.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.3.3.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.3.3.4.1\" style=\"font-size:80%;\">0.80</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.3.3.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.3.3.5.1\" style=\"font-size:80%;\">0.98</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.4.4.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.4.4.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.4.4.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.4.4.2.1\" style=\"font-size:80%;\">0.75</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.4.4.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.4.4.3.1\" style=\"font-size:80%;\">0.97</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.5.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.5.5.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.5.5.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.5.5.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.5.5.2.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.5.5.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.5.5.3.1\" style=\"font-size:80%;\">0.99</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.6.6\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.6.6.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.6.6.1.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.6.6.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.6.6.2.1\" style=\"font-size:80%;\">0.76</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.6.6.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.6.6.3.1\" style=\"font-size:80%;\">0.84</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.7.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.7.7.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.7.7.1.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.7.7.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.7.7.2.1\" style=\"font-size:80%;\">0.80</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.7.7.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.7.7.3.1\" style=\"font-size:80%;\">1.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T5.1.8.8.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.8.8.1.1\" style=\"font-size:80%;\">llama</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T5.1.8.8.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.8.8.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.8.8.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.8.8.3.1\" style=\"font-size:80%;\">0.82</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.8.8.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.8.8.4.1\" style=\"font-size:80%;\">0.88</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.9.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.9.9.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.9.9.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.9.9.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.9.9.2.1\" style=\"font-size:80%;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.9.9.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.9.9.3.1\" style=\"font-size:80%;\">0.64</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.10.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.10.10.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.10.10.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.10.10.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.10.10.2.1\" style=\"font-size:80%;\">0.88</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.10.10.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.10.10.3.1\" style=\"font-size:80%;\">0.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.11.11\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.11.11.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.11.11.1.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.11.11.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.11.11.2.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.11.11.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.11.11.3.1\" style=\"font-size:80%;\">0.83</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.12.12\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.12.12.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.12.12.1.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.12.12.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.12.12.2.1\" style=\"font-size:80%;\">0.84</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.12.12.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.12.12.3.1\" style=\"font-size:80%;\">0.89</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T5.1.13.13.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.13.13.1.1\" style=\"font-size:80%;\">mistral</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T5.1.13.13.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.13.13.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.13.13.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.13.13.3.1\" style=\"font-size:80%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.13.13.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.13.13.4.1\" style=\"font-size:80%;\">0.73</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.14.14\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.14.14.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.14.14.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.14.14.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.14.14.2.1\" style=\"font-size:80%;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.14.14.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.14.14.3.1\" style=\"font-size:80%;\">0.65</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.15.15\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.15.15.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.15.15.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.15.15.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.15.15.2.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.15.15.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.15.15.3.1\" style=\"font-size:80%;\">0.83</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.16.16\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.16.16.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.16.16.1.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.16.16.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.16.16.2.1\" style=\"font-size:80%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.16.16.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.16.16.3.1\" style=\"font-size:80%;\">0.73</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.17.17\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.17.17.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.17.17.1.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.17.17.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.17.17.2.1\" style=\"font-size:80%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.17.17.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.17.17.3.1\" style=\"font-size:80%;\">0.55</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.18.18\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_b ltx_border_t\" id=\"Pt0.Ax1.T5.1.18.18.1\" rowspan=\"15\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.18.18.1.1\" style=\"font-size:80%;\">Enron</span></td>\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T5.1.18.18.2\" rowspan=\"5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.18.18.2.1\" style=\"font-size:80%;\">flan</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T5.1.18.18.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.18.18.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.18.18.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.18.18.4.1\" style=\"font-size:80%;\">0.79</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.18.18.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.18.18.5.1\" style=\"font-size:80%;\">0.93</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.19.19\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.19.19.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.19.19.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.19.19.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.19.19.2.1\" style=\"font-size:80%;\">0.68</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.19.19.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.19.19.3.1\" style=\"font-size:80%;\">0.80</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.20.20\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.20.20.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.20.20.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.20.20.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.20.20.2.1\" style=\"font-size:80%;\">0.82</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.20.20.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.20.20.3.1\" style=\"font-size:80%;\">0.96</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.21.21\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.21.21.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.21.21.1.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.21.21.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.21.21.2.1\" style=\"font-size:80%;\">0.60</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.21.21.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.21.21.3.1\" style=\"font-size:80%;\">0.62</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.22.22\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.22.22.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.22.22.1.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.22.22.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.22.22.2.1\" style=\"font-size:80%;\">0.80</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.22.22.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.22.22.3.1\" style=\"font-size:80%;\">0.92</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.23.23\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T5.1.23.23.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.23.23.1.1\" style=\"font-size:80%;\">llama</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T5.1.23.23.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.23.23.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.23.23.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.23.23.3.1\" style=\"font-size:80%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.23.23.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.23.23.4.1\" style=\"font-size:80%;\">0.65</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.24.24\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.24.24.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.24.24.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.24.24.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.24.24.2.1\" style=\"font-size:80%;\">0.62</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.24.24.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.24.24.3.1\" style=\"font-size:80%;\">0.54</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.25.25\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.25.25.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.25.25.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.25.25.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.25.25.2.1\" style=\"font-size:80%;\">0.79</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.25.25.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.25.25.3.1\" style=\"font-size:80%;\">0.83</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.26.26\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.26.26.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.26.26.1.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.26.26.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.26.26.2.1\" style=\"font-size:80%;\">0.69</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.26.26.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.26.26.3.1\" style=\"font-size:80%;\">0.58</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.27.27\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.27.27.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.27.27.1.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.27.27.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.27.27.2.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.27.27.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.27.27.3.1\" style=\"font-size:80%;\">0.74</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.28.28\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_b ltx_border_t\" id=\"Pt0.Ax1.T5.1.28.28.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.28.28.1.1\" style=\"font-size:80%;\">mistral</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T5.1.28.28.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.28.28.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.28.28.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.28.28.3.1\" style=\"font-size:80%;\">0.66</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T5.1.28.28.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.28.28.4.1\" style=\"font-size:80%;\">0.60</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.29.29\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.29.29.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.29.29.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.29.29.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.29.29.2.1\" style=\"font-size:80%;\">0.70</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.29.29.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.29.29.3.1\" style=\"font-size:80%;\">0.68</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.30.30\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.30.30.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.30.30.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.30.30.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.30.30.2.1\" style=\"font-size:80%;\">0.78</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.30.30.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.30.30.3.1\" style=\"font-size:80%;\">0.82</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.31.31\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T5.1.31.31.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.31.31.1.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.31.31.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.31.31.2.1\" style=\"font-size:80%;\">0.64</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T5.1.31.31.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.31.31.3.1\" style=\"font-size:80%;\">0.53</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.32.32\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T5.1.32.32.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.32.32.1.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T5.1.32.32.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.32.32.2.1\" style=\"font-size:80%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T5.1.32.32.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.32.32.3.1\" style=\"font-size:80%;\">0.69</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 5: Full RAG-MIA results",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T5.1.1.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T5.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Black-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 5: Full RAG-MIA results",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T5.1.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T5.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Gray-Box</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">AUC ROC</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 5: Full RAG-MIA results",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T5.1.2.2.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T5.1.2.2.3.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.2.2.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.2.2.3.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.2.2.3.1.1.1.1\" style=\"font-size:80%;\">Attack</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T5.1.2.2.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T5.1.2.2.3.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T5.1.2.2.3.1.2.1.1\" style=\"font-size:80%;\">Prompt</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 5: Full RAG-MIA results",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T6.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Pt0.Ax1.T6.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"Pt0.Ax1.T6.1.1.1.1\"></td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T6.1.1.1.2\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.2.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.2.1.1.1.1\" style=\"font-size:80%;\">Attack</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.2.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.2.1.2.1.1\" style=\"font-size:80%;\">prompt</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T6.1.1.1.3\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.3.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.3.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.3.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.3.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T6.1.1.1.4\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Total</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T6.1.1.1.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">percent</span></td>\n</tr>\n</table>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T6.1.2.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.2.2.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T6.1.2.2.2\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T6.1.2.2.3\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T6.1.2.2.4\"></th>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T6.1.2.2.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T6.1.3.3.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.3.3.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T6.1.3.3.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.3.3.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T6.1.3.3.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.3.3.3.1\" style=\"font-size:80%;\">1928</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T6.1.3.3.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.3.3.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T6.1.3.3.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.3.3.5.1\" style=\"font-size:80%;\">96.40</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.4.4.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.4.4.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.4.4.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.4.4.2.1\" style=\"font-size:80%;\">1921</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.4.4.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.4.4.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.4.4.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.4.4.4.1\" style=\"font-size:80%;\">96.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.5.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.5.5.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.5.5.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.5.5.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.5.5.2.1\" style=\"font-size:80%;\">1921</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.5.5.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.5.5.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.5.5.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.5.5.4.1\" style=\"font-size:80%;\">96.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.6.6\">\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T6.1.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.6.6.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.6.6.2.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.6.6.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.6.6.3.1\" style=\"font-size:80%;\">1930</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.6.6.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.6.6.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.6.6.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.6.6.5.1\" style=\"font-size:80%;\">96.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.7.7\">\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T6.1.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.7.7.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.7.7.2.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.7.7.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.7.7.3.1\" style=\"font-size:80%;\">1924</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.7.7.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.7.7.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.7.7.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.7.7.5.1\" style=\"font-size:80%;\">96.20</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T6.1.8.8.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.8.8.1.1\" style=\"font-size:80%;\">Enron</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T6.1.8.8.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.8.8.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T6.1.8.8.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.8.8.3.1\" style=\"font-size:80%;\">1910</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T6.1.8.8.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.8.8.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T6.1.8.8.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.8.8.5.1\" style=\"font-size:80%;\">95.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.9.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.9.9.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.9.9.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.9.9.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.9.9.2.1\" style=\"font-size:80%;\">1908</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.9.9.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.9.9.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.9.9.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.9.9.4.1\" style=\"font-size:80%;\">95.40</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.10.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.10.10.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.10.10.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.10.10.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.10.10.2.1\" style=\"font-size:80%;\">1907</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.10.10.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.10.10.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.10.10.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.10.10.4.1\" style=\"font-size:80%;\">95.35</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.11.11\">\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T6.1.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T6.1.11.11.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.11.11.2.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.11.11.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.11.11.3.1\" style=\"font-size:80%;\">1910</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.11.11.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.11.11.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T6.1.11.11.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.11.11.5.1\" style=\"font-size:80%;\">95.50</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.12.12\">\n<td class=\"ltx_td ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T6.1.12.12.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T6.1.12.12.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.12.12.2.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T6.1.12.12.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.12.12.3.1\" style=\"font-size:80%;\">1908</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T6.1.12.12.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.12.12.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T6.1.12.12.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.12.12.5.1\" style=\"font-size:80%;\">95.40</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 6: Database retrieval of member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T6.1.1.1.2.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.2.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.2.1.1.1.1\" style=\"font-size:80%;\">Attack</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.2.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.2.1.2.1.1\" style=\"font-size:80%;\">prompt</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6: Database retrieval of member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T6.1.1.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.3.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.3.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.3.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.3.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6: Database retrieval of member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T6.1.1.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Total</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6: Database retrieval of member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T6.1.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T6.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T6.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T6.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T6.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">percent</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 6: Database retrieval of member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T7.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Pt0.Ax1.T7.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"Pt0.Ax1.T7.1.1.1.1\"></td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T7.1.1.1.2\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.2.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.2.1.1.1.1\" style=\"font-size:80%;\">Attack</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.2.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.2.1.2.1.1\" style=\"font-size:80%;\">prompt</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T7.1.1.1.3\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.3.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.3.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.3.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.3.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T7.1.1.1.4\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Total</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T7.1.1.1.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">percent</span></td>\n</tr>\n</table>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T7.1.2.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.2.2.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T7.1.2.2.2\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T7.1.2.2.3\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T7.1.2.2.4\"></th>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T7.1.2.2.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T7.1.3.3.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.3.3.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T7.1.3.3.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.3.3.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T7.1.3.3.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.3.3.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T7.1.3.3.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.3.3.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T7.1.3.3.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.3.3.5.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.4.4.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.4.4.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.4.4.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.4.4.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.4.4.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.4.4.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.4.4.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.4.4.4.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.5.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.5.5.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.5.5.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.5.5.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.5.5.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.5.5.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.5.5.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.5.5.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.5.5.4.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.6.6\">\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T7.1.6.6.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.6.6.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.6.6.2.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.6.6.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.6.6.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.6.6.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.6.6.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.6.6.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.6.6.5.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.7.7\">\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T7.1.7.7.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.7.7.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.7.7.2.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.7.7.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.7.7.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.7.7.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.7.7.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.7.7.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.7.7.5.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T7.1.8.8.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.8.8.1.1\" style=\"font-size:80%;\">Enron</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T7.1.8.8.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.8.8.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T7.1.8.8.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.8.8.3.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T7.1.8.8.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.8.8.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T7.1.8.8.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.8.8.5.1\" style=\"font-size:80%;\">0.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.9.9\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.9.9.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.9.9.1.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.9.9.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.9.9.2.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.9.9.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.9.9.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.9.9.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.9.9.4.1\" style=\"font-size:80%;\">0.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.10.10\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.10.10.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.10.10.1.1\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.10.10.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.10.10.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.10.10.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.10.10.3.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.10.10.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.10.10.4.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.11.11\">\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T7.1.11.11.1\"></td>\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T7.1.11.11.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.11.11.2.1\" style=\"font-size:80%;\">3</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.11.11.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.11.11.3.1\" style=\"font-size:80%;\">1</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.11.11.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.11.11.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T7.1.11.11.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.11.11.5.1\" style=\"font-size:80%;\">0.05</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.12.12\">\n<td class=\"ltx_td ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T7.1.12.12.1\"></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T7.1.12.12.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.12.12.2.1\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T7.1.12.12.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.12.12.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T7.1.12.12.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.12.12.4.1\" style=\"font-size:80%;\">2000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T7.1.12.12.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.12.12.5.1\" style=\"font-size:80%;\">0.00</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 7: Database retrieval of non-member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T7.1.1.1.2.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.2.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.2.1.1.1.1\" style=\"font-size:80%;\">Attack</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.2.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.2.1.2.1.1\" style=\"font-size:80%;\">prompt</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 7: Database retrieval of non-member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T7.1.1.1.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.3.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.3.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.3.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.3.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 7: Database retrieval of non-member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T7.1.1.1.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.4.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.4.1.1.1.1\" style=\"font-size:80%;\">Total</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.4.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.4.1.2.1.1\" style=\"font-size:80%;\">count</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 7: Database retrieval of non-member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T7.1.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T7.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Equal</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T7.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T7.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T7.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">percent</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 7: Database retrieval of non-member documents",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T8.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Pt0.Ax1.T8.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.1.1\">\n<td class=\"ltx_td ltx_border_tt\" id=\"Pt0.Ax1.T8.1.1.1.1\"></td>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T8.1.1.1.2\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T8.1.1.1.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.1.1.3.1\" style=\"font-size:80%;\">Missing</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T8.1.1.1.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.1.1.4.1\" style=\"font-size:80%;\">Total</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" id=\"Pt0.Ax1.T8.1.1.1.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T8.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T8.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Percent</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T8.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">missing</span></td>\n</tr>\n</table>\n</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T8.1.2.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.2.2.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"Pt0.Ax1.T8.1.2.2.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.2.2.2.1\" style=\"font-size:80%;\">Model</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T8.1.2.2.3\"></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" id=\"Pt0.Ax1.T8.1.2.2.4\"></th>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T8.1.2.2.5\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_t\" id=\"Pt0.Ax1.T8.1.3.3.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.3.3.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T8.1.3.3.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.3.3.2.1\" style=\"font-size:80%;\">flan</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T8.1.3.3.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.3.3.3.1\" style=\"font-size:80%;\">923</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T8.1.3.3.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.3.3.4.1\" style=\"font-size:80%;\">20000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T8.1.3.3.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.3.3.5.1\" style=\"font-size:80%;\">4.62%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.4.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T8.1.4.4.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.4.4.1.1\" style=\"font-size:80%;\">llama</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.4.4.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.4.4.2.1\" style=\"font-size:80%;\">1253</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.4.4.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.4.4.3.1\" style=\"font-size:80%;\">20000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.4.4.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.4.4.4.1\" style=\"font-size:80%;\">6.27%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.5.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T8.1.5.5.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.5.5.1.1\" style=\"font-size:80%;\">mistral</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.5.5.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.5.5.2.1\" style=\"font-size:80%;\">1736</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.5.5.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.5.5.3.1\" style=\"font-size:80%;\">20000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.5.5.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.5.5.4.1\" style=\"font-size:80%;\">8.68%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_align_top ltx_border_bb ltx_border_b ltx_border_t\" id=\"Pt0.Ax1.T8.1.6.6.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.6.6.1.1\" style=\"font-size:80%;\">Enron</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"Pt0.Ax1.T8.1.6.6.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.6.6.2.1\" style=\"font-size:80%;\">flan</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T8.1.6.6.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.6.6.3.1\" style=\"font-size:80%;\">1327</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T8.1.6.6.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.6.6.4.1\" style=\"font-size:80%;\">20000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T8.1.6.6.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.6.6.5.1\" style=\"font-size:80%;\">6.64%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.7.7\">\n<td class=\"ltx_td ltx_align_left\" id=\"Pt0.Ax1.T8.1.7.7.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.7.7.1.1\" style=\"font-size:80%;\">llama</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.7.7.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.7.7.2.1\" style=\"font-size:80%;\">954</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.7.7.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.7.7.3.1\" style=\"font-size:80%;\">20000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T8.1.7.7.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.7.7.4.1\" style=\"font-size:80%;\">4.77%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T8.1.8.8.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.8.8.1.1\" style=\"font-size:80%;\">mistral</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T8.1.8.8.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.8.8.2.1\" style=\"font-size:80%;\">1125</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T8.1.8.8.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.8.8.3.1\" style=\"font-size:80%;\">20000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T8.1.8.8.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.8.8.4.1\" style=\"font-size:80%;\">5.63%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 8: Model outputs missing yes/no tokens",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T8.1.1.1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T8.1.1.1.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.1.1.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T8.1.1.1.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.1.1.5.1.1.1.1\" style=\"font-size:80%;\">Percent</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T8.1.1.1.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T8.1.1.1.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T8.1.1.1.5.1.2.1.1\" style=\"font-size:80%;\">missing</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 8: Model outputs missing yes/no tokens",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T9.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"Pt0.Ax1.T9.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.1.1\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\" id=\"Pt0.Ax1.T9.1.1.1.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"Pt0.Ax1.T9.1.1.1.2\"></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"Pt0.Ax1.T9.1.1.1.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.1.1.3.1\" style=\"font-size:80%;\">Without defense</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"Pt0.Ax1.T9.1.1.1.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.1.1.4.1\" style=\"font-size:80%;\">With defense</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"Pt0.Ax1.T9.1.2.2.1\"></th>\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_r\" id=\"Pt0.Ax1.T9.1.2.2.2\"></th>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.2.2.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.3.1\" style=\"font-size:80%;\">Missing</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.2.2.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.4.1\" style=\"font-size:80%;\">Total</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"Pt0.Ax1.T9.1.2.2.5\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T9.1.2.2.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.5.1.1.1.1\" style=\"font-size:80%;\">Percent</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.5.1.2.1.1\" style=\"font-size:80%;\">missing</span></td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.2.2.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.6.1\" style=\"font-size:80%;\">Missing</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.2.2.7\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.7.1\" style=\"font-size:80%;\">Total</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.2.2.8\">\n<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T9.1.2.2.8.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.8.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.8.1.1.1.1\" style=\"font-size:80%;\">Percent</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.8.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.8.1.2.1.1\" style=\"font-size:80%;\">missing</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"Pt0.Ax1.T9.1.3.3.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.3.3.1.1\" style=\"font-size:80%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"Pt0.Ax1.T9.1.3.3.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.3.3.2.1\" style=\"font-size:80%;\">Model</span></th>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T9.1.3.3.3\"></td>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T9.1.3.3.4\"></td>\n<td class=\"ltx_td ltx_border_r\" id=\"Pt0.Ax1.T9.1.3.3.5\"></td>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T9.1.3.3.6\"></td>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T9.1.3.3.7\"></td>\n<td class=\"ltx_td\" id=\"Pt0.Ax1.T9.1.3.3.8\"></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.1.1\" style=\"font-size:80%;\">HealthCareMagic</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.2.1\" style=\"font-size:80%;\">flan</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.4.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.6.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.7\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.7.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.4.4.8\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.4.4.8.1\" style=\"font-size:80%;\">0.00%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"Pt0.Ax1.T9.1.5.5.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.5.5.1.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.5.5.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.5.5.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.5.5.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.5.5.3.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"Pt0.Ax1.T9.1.5.5.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.5.5.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.5.5.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.5.5.5.1\" style=\"font-size:80%;\">3868</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.5.5.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.5.5.6.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.5.5.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Pt0.Ax1.T9.1.5.5.7.1\" style=\"font-size:80%;\">96.70%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"Pt0.Ax1.T9.1.6.6.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.6.6.1.1\" style=\"font-size:80%;\">mistral</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.6.6.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.6.6.2.1\" style=\"font-size:80%;\">101</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.6.6.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.6.6.3.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"Pt0.Ax1.T9.1.6.6.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.6.6.4.1\" style=\"font-size:80%;\">2.53%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.6.6.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.6.6.5.1\" style=\"font-size:80%;\">3719</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.6.6.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.6.6.6.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.6.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Pt0.Ax1.T9.1.6.6.7.1\" style=\"font-size:80%;\">92.97%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.1.1\" style=\"font-size:80%;\">Enron</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.2.1\" style=\"font-size:80%;\">flan</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.3.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.4.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.5.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.6.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.7\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.7.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"Pt0.Ax1.T9.1.7.7.8\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.7.7.8.1\" style=\"font-size:80%;\">0.00%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"Pt0.Ax1.T9.1.8.8.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.8.8.1.1\" style=\"font-size:80%;\">llama</span></th>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.8.8.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.8.8.2.1\" style=\"font-size:80%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.8.8.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.8.8.3.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"Pt0.Ax1.T9.1.8.8.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.8.8.4.1\" style=\"font-size:80%;\">0.00%</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.8.8.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.8.8.5.1\" style=\"font-size:80%;\">3805</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.8.8.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.8.8.6.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"Pt0.Ax1.T9.1.8.8.7\"><span class=\"ltx_text ltx_font_bold\" id=\"Pt0.Ax1.T9.1.8.8.7.1\" style=\"font-size:80%;\">95.12%</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r\" id=\"Pt0.Ax1.T9.1.9.9.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.1.1\" style=\"font-size:80%;\">mistral</span></th>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T9.1.9.9.2\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.2.1\" style=\"font-size:80%;\">41</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T9.1.9.9.3\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.3.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b ltx_border_r\" id=\"Pt0.Ax1.T9.1.9.9.4\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.4.1\" style=\"font-size:80%;\">1.03%</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T9.1.9.9.5\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.5.1\" style=\"font-size:80%;\">2743</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T9.1.9.9.6\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.6.1\" style=\"font-size:80%;\">4000</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_b\" id=\"Pt0.Ax1.T9.1.9.9.7\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.9.9.7.1\" style=\"font-size:80%;\">68.58%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 9: Model outputs missing yes/no tokens with defense prompt",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T9.1.2.2.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T9.1.2.2.5.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.5.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.5.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.5.1.1.1.1\" style=\"font-size:80%;\">Percent</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.5.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.5.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.5.1.2.1.1\" style=\"font-size:80%;\">missing</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 9: Model outputs missing yes/no tokens with defense prompt",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    },
    "Pt0.Ax1.T9.1.2.2.8.1": {
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"Pt0.Ax1.T9.1.2.2.8.1\">\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.8.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.8.1.1.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.8.1.1.1.1\" style=\"font-size:80%;\">Percent</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"Pt0.Ax1.T9.1.2.2.8.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"Pt0.Ax1.T9.1.2.2.8.1.2.1\"><span class=\"ltx_text\" id=\"Pt0.Ax1.T9.1.2.2.8.1.2.1.1\" style=\"font-size:80%;\">missing</span></td>\n</tr>\n</table>\n\n",
        "caption": "Table 9: Model outputs missing yes/no tokens with defense prompt",
        "footnotes": [],
        "references": [
            "In both the black-box and the gray-box scenarios we ran our attack using random samples containing 2000 member documents and 2000 non-member documents.\nIn the gray-box case, these documents were split between 40 attack models in the ensemble [13], each model trained 5 times with different train-test splits.\nIn this evaluation, we classified model outputs that failed to include either the ”Yes” or ”No” tokens as non-member documents. This case accounted for approximately 6% of the total outputs. We present the statistics on the amount of such documents in Appendix C.",
            "In Figure 3 we present the Area Under the Receiver Operating Characteristic curve (AUC ROC) for both threat models, black-box and gray-box, and for the different attack prompts. The full results can be found in Appendix A.\nThe attack prompt that, on average, resulted in the best MIA performance across all models and datasets is prompt #2:\n”Does this :\\n ”{Target Sample}”\\n appear in the context? Answer with Yes or No.”. Input format #4 comes in second best on the Enron dataset, but produces poor results for the mistral model on the HealthCareMagic dataset.",
            "To further explore this difference, we analyze the percentage of samples that are correctly retrieved from the database for each prompt. We found that over 95% of the member samples are indeed retrieved for both datasets. This is in contrast with the non-member samples, which are retrieved in nearly 0% of the cases. The full results of this analysis can be found in Appendix B.\nThus, we conclude that the flan model is more grounded to the content of its input prompt (context grounding), and thereby more sure of the presence/absence of a piece of text from it in comparison to the llama and mistral models.",
            "Furthermore, our analysis of the model outputs reveals that a significant proportion of responses do not contain either ”Yes” or ”No” tokens (classified as non-member documents), accounting for approximately 96% of the total outputs on llama, and about 93% on mistral with HealthCareMagic dataset, which explains the defense performance for these cases. On the other hand, for flan, they remain the same (0%). We present the statistics on the amount of such documents in Appendix D.",
            "Table 5 presents the AUC ROC scores for both threat models: black-box and gray-box, and for the different attack prompts.",
            "Tables 6 and 7 show the percent of exact matches between the retrieved documents and the member and non-member samples, respectively, for the different attack prompts. We see that the chosen attack prompts do not differ in their influence on the retrieval accuracy.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens across attack prompts for each dataset and model combination are shown in Table 8.",
            "The number of model outputs that did not contain either of the ”Yes” or ”No” tokens when using a defense prompt for each dataset and model combination are shown in Table 9. This is compared to the corresponding model outputs when using attack prompt #2 without the defense. The number of missing answers increases significantly for the llama and mistral models, and remains the same for flan."
        ]
    }
}