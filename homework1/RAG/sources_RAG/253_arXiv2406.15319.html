<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs</title>
<!--Generated on Sun Sep  1 16:53:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.15319v3/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S1" title="In LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2" title="In LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>LongRAG</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.SS1" title="In 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Long Retriever</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.SS1.SSS0.Px1" title="In 2.1 Long Retriever ‣ 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Formulate long retrieval units</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.SS1.SSS0.Px2" title="In 2.1 Long Retriever ‣ 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Similarity search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.SS1.SSS0.Px3" title="In 2.1 Long Retriever ‣ 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Aggregate retrieval result</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.SS2" title="In 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Long Reader</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3" title="In LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS1" title="In 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS2" title="In 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Retrieval Performance</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS2.SSS0.Px1" title="In 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS2.SSS0.Px2" title="In 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Experiment Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS2.SSS0.Px3" title="In 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Encode the long retrieval unit</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS3" title="In 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Full QA Performance on Wikipedia-based Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS4" title="In 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Full QA Performance on non-Wikipedia-based Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS5" title="In 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Ablation Studies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS5.SSS0.Px1" title="In 3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Retrieval Unit Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS5.SSS0.Px2" title="In 3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Recall vs. EM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.SS5.SSS0.Px3" title="In 3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title">Reader Model</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S4" title="In LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S4.SS1" title="In 4 Related Work ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Retrieval-Augmented Generation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S4.SS2" title="In 4 Related Work ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Long Context Large Language Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S4.SS3" title="In 4 Related Work ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Long Context Embedding</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S5" title="In LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1" title="In LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS1" title="In Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Prompts Template for Long Context Reader</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS2" title="In Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Refined Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS3" title="In Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Group Documents Algorithm</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS4" title="In Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Dataset Examples</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">LongRAG: Enhancing Retrieval-Augmented Generation 
<br class="ltx_break"/>with Long-context LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><sup class="ltx_sup" id="id6.5.id1"><span class="ltx_text ltx_font_italic" id="id6.5.id1.1">♠</span></sup>Ziyan Jiang, <sup class="ltx_sup" id="id7.6.id2"><span class="ltx_text ltx_font_italic" id="id7.6.id2.1">♠</span></sup>Xueguang Ma, <sup class="ltx_sup" id="id8.7.id3"><span class="ltx_text ltx_font_italic" id="id8.7.id3.1">♠</span></sup>Wenhu Chen 
<br class="ltx_break"/><sup class="ltx_sup" id="id9.8.id4">♠</sup>University of Waterloo 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id10.9.id5">ziyanjiang528@gmail.com</span>,
<span class="ltx_text ltx_font_typewriter" id="id11.10.id6">{x93ma ,wenhuchen}@uwaterloo.ca</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.1">In traditional RAG framework, the basic retrieval units are normally short.
The common retrievers like DPR normally work with 100-word Wikipedia paragraphs.
Such a design forces the retriever to search over a large corpus to find the “needle” unit. In contrast, the readers only need to generate answers from the short retrieved units.
The imbalanced “heavy” retriever and “light” reader design can lead to sub-optimal performance. The loss of contextual information in the short, chunked units may increase the likelihood of introducing hard negatives during the retrieval stage. Additionally, the reader might not fully leverage the capabilities of recent advancements in LLMs. In order to alleviate the imbalance, we propose a new framework LongRAG, consisting of a <span class="ltx_text ltx_font_bold" id="id5.1.1">“long retriever”</span> and a <span class="ltx_text ltx_font_bold" id="id5.1.2">“long reader”</span>.
In the two Wikipedia-based datasets, NQ and HotpotQA, where the average document size is less than 1K tokens, LongRAG processes the entire Wikipedia corpus into 4K-token units by grouping related documents, making these units 30 times longer than before. By increasing the unit size, we significantly reduce the total number of units from 22M to 600K. This greatly reduces the burden on the retriever, resulting in strong retrieval performance with only a few (less than 8) top units. Compared to traditional RAG, which may require hundreds of short units to achieve similar retrieval performance, our approach minimizes the likelihood of retrieving hard negatives while maintaining semantic integrity of each unit.
Then we feed these retrieved units (<math alttext="\approx" class="ltx_Math" display="inline" id="id5.1.m1.1"><semantics id="id5.1.m1.1a"><mo id="id5.1.m1.1.1" xref="id5.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="id5.1.m1.1b"><approx id="id5.1.m1.1.1.cmml" xref="id5.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="id5.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="id5.1.m1.1d">≈</annotation></semantics></math> 30K tokens) to an existing long-context LLM to perform zero-shot answer generation. Without requiring any training, LongRAG achieves an EM of 62.7% on NQ and 64.3% on HotpotQA, which are on par with the (fully-trained) SoTA model. Furthermore, we test on two non-Wikipedia-based datasets, Qasper and MultiFieldQA-en, where the average document length is already above 4K tokens. LongRAG processes each individual document as a single (long) unit rather than chunking them into smaller units. By doing so, we achieve an F1 score of 25.9% on Qasper (previously 22.5%) and 57.5% on MultiFieldQA-en (previously 51.2%). Our study offers insights into the future roadmap for combining RAG with long-context LLMs.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">Project Website:</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://tiger-ai-lab.github.io/LongRAG/" title="">https://tiger-ai-lab.github.io/LongRAG/</a>
<br class="ltx_break"/>
<br class="ltx_break"/></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="408" id="S1.F1.g1" src="x1.png" width="899"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Traditional RAG vs. LongRAG.
(Up) Traditional RAG operates on short retrieval units, where the retriever needs to scan over a massive amount of units to find the relevant piece. In contrast, LongRAG operates on long retrieval units (30x longer). The retriever of LongRAG has a significantly reduced workload, achieving strong retrieval quality by leveraging only a few top units without the need for additional ranking mechanisms or other complex components. LongRAG could fully exploit the ability of long-context language models to achieve strong performance. (Down) QA performance compared with other methods on the NQ dataset and the HotpotQA dataset.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Retrieval-Augmented Generation (RAG) methods have long been employed to enhance large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Mialon et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib38" title="">2023</a>)</cite>. Knowledge in the form of natural language can be entirely offloaded from the parametric knowledge of LLMs by leveraging a standalone retrieval component from an external corpus. The existing RAG framework tends to use short retrieval units, such as 100-word passages in popular open-domain question-answering tasks <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib7" title="">2017</a>; Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib33" title="">2020</a>; Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib28" title="">2020</a>)</cite>. The retriever is tasked with finding the “needle” (i.e. the precise tiny retrieval unit) from the “haystack” (i.e. the massive corpus with up to tens of millions of information units). Subsequently, the retrieved units are passed to the reader to generate the final response. On the contrary, the reader only needs to extract answers from these retrievals, which is a fairly easy task. This kind of imbalanced design, with a “heavy” retriever and a “light” reader, puts too much pressure on the retriever. Therefore, existing RAG models <cite class="ltx_cite ltx_citemacro_citep">(Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib23" title="">2020b</a>)</cite> have to recall huge amounts of units, such as the top-100/200, combined with additional re-ranker to achieve the best performance. Moreover, short retrieval units can lead to semantic incompleteness due to document truncation. This can result in the loss of contextual information, which may ultimately harm overall performance. This design choice was made in an era when the reader models were heavily restricted by their ability to handle long and contexts. With the recent advances in long-context language models, the reader can potentially handle up to 128K or even millions of tokens as input <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib46" title="">2024</a>; Achiam et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib1" title="">2023</a>)</cite>. In this paper, we propose to revisit this design choice for open-domain question answering and propose the LongRAG framework as a solution to balance the workload between the retriever and the reader, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>. There are three important designs in our novel framework:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1"><span class="ltx_text ltx_font_bold" id="S1.p2.1.1">Long Retrieval Unit</span>: By using entire documents or grouping multiple related documents, we can construct long retrieval units with more than 4K tokens. This design could also significantly reduce the corpus size (number of retrieval units in the corpus). This makes the retriever’s task much easier by providing more complete information, allowing the
retriever’s architecture to be simplified without the need for additional re-rankers or iterative retrieval.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Long Retriever</span>: The long retriever will identify coarse relevant information for the given query by searching through all the long retrieval units in the corpus. Only a few top retrieval units (1 to 8 retrieval units in the four datasets we tested on), without re-ranking, are used for the next step. Compared to retrieving hundreds of short units, the long retriever only needs to retrieve a few candidates, which significantly reduces the likelihood to encounter hard negatives (it will confuse the reader).</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.p4.1.1">Long Reader</span>: The long reader will further extract answers from the concatenation of retrievals, which is normally around 30K tokens. We simply prompt an existing long-context LM (like Gemini or GPT4) with the question to produce the answers in a zero-shot fashion.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">These three novel designs significantly boost the overall performance of RAG on open-domain question-answering tasks like NQ <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib32" title="">2019</a>)</cite>, HotpotQA <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib56" title="">2018</a>)</cite>, Qasper <cite class="ltx_cite ltx_citemacro_citep">(Dasigi et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib14" title="">2021</a>)</cite> and MultiFieldQA-en <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib5" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In our experiments, we adopt off-the-shelf retrievers like BGE <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib53" title="">2023</a>)</cite> and readers like Gemini-1.5-Pro <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib46" title="">2024</a>)</cite> or GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib40" title="">2024</a>)</cite> without any further tuning. To demonstrate the generalizability of our proposed framework, we tested it on four datasets from different scenarios. First, we evaluate it on NQ and HotpotQA, which are Wikipedia-based dataset. The corpus of both datasets are composed of relatively short (averaging less than 1K tokens) but vast Wikipedia documents. By forming longer retrieval units through the grouping of multiple related documents, we reduce the NQ corpus size from 22M to 600K units, which improves the answer recall@1 from 52% (DPR) to 71%. Similarly, we reduce the HotpotQA corpus size from 5M to 500K, which improves the recall@2 from 47% (DPR) to 72%.
By exploiting the long-context understanding ability of GPT-4o, LongRAG can achieve an EM of 62.7% on NQ and 64.3% on HotpotQA. These results could be comparable to the strongest fully trained RAG models like Atlas <cite class="ltx_cite ltx_citemacro_citep">(Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib25" title="">2022</a>)</cite> and MDR <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib55" title="">2020b</a>)</cite>. Furthermore, we test on two non-Wikipedia-based datasets, Qasper and MultiFieldQA-en, where the corpus consists of relatively long documents averaging
more than 4K tokens. LongRAG processes each entire document as a single unit rather
than chunking them into smaller units. By doing so, we achieve an F1 score of 25.9% on
Qasper (previously 22.5%) and 57.5% on MultiFieldQA-en (previously 51.2%).</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">We perform ablation studies in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.15319v3#S3.SS5" title="3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">subsection 3.5</span></a> to prove why longer retrieval units are necessary. Given a budget of 40K recall tokens, with “short retriever units”, we can increase the number of recalled units to reach a marvelously high recall score (91% for recall@200). However, the end performance dips significantly due to the huge amount of “hard negatives”, which confuses the reader. With “long retriever units”, we observe an entirely different trend. As we recall more units (from 1 to 8 units), both the recall and end performance will increase or plateau. The impact of “hard negative” is much less severe in LongRAG. It shows that LongRAG can better exploit the advances in the long-context LLMs (reader). As the long-context methods evolve, the performance of LongRAG will continue to improve. Therefore, we believe the modern RAG systems should re-consider the granularity of their retrieval units to exploit the advantages of the current long-context LLMs.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>LongRAG</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our proposed LongRAG framework is comprised of two components: the <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Long Retriever</span> and the <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">Long Reader</span>. Compared to traditional RAG, which operates on a large number of short retrieval units, LongRAG operates on long retrieval units, with only a few (typically fewer than 10) being fed into the reader. An illustrative example is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.F2" title="Figure 2 ‣ 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="410" id="S2.F2.g1" src="x2.png" width="720"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>LongRAG example. We form the long retrieval unit which is at least 4K tokens by using the entire document or grouping related documents, depending on the orinal docuemnt size. In this example, multiple Wikipedia documents are grouped through hyperlinks. This approach enables even multi-hop question-answering cases from HotpotQA to be addressed using only a few retrieval units, which are then fed into a long reader. Compared to traditional RAG, which retrieves hundreds of short units, our proposed LongRAG reduces the likelihood of retrieving hard negatives during the retrieval stage and more effectively leverages recent advances in long-context LLMs.</figcaption>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Long Retriever</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The traditional RAG framework employs smaller retrieval units and prioritizes retrieving the exact fine-grained short context containing the answer. In contrast, our proposed LongRAG framework places greater emphasis on recall, aiming to retrieve relevant context with much coarse granularity. This design choice shifts more burden from the retriever to the reader to extract the exact answers from the relevant context.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.11">We denote our corpus for retrieval as <math alttext="\mathcal{C}=\{d_{1},d_{2},\ldots,d_{D}\}" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.4"><semantics id="S2.SS1.p2.1.m1.4a"><mrow id="S2.SS1.p2.1.m1.4.4" xref="S2.SS1.p2.1.m1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.1.m1.4.4.5" xref="S2.SS1.p2.1.m1.4.4.5.cmml">𝒞</mi><mo id="S2.SS1.p2.1.m1.4.4.4" xref="S2.SS1.p2.1.m1.4.4.4.cmml">=</mo><mrow id="S2.SS1.p2.1.m1.4.4.3.3" xref="S2.SS1.p2.1.m1.4.4.3.4.cmml"><mo id="S2.SS1.p2.1.m1.4.4.3.3.4" stretchy="false" xref="S2.SS1.p2.1.m1.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p2.1.m1.2.2.1.1.1" xref="S2.SS1.p2.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.2.2.1.1.1.2" xref="S2.SS1.p2.1.m1.2.2.1.1.1.2.cmml">d</mi><mn id="S2.SS1.p2.1.m1.2.2.1.1.1.3" xref="S2.SS1.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p2.1.m1.4.4.3.3.5" xref="S2.SS1.p2.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p2.1.m1.3.3.2.2.2" xref="S2.SS1.p2.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS1.p2.1.m1.3.3.2.2.2.2" xref="S2.SS1.p2.1.m1.3.3.2.2.2.2.cmml">d</mi><mn id="S2.SS1.p2.1.m1.3.3.2.2.2.3" xref="S2.SS1.p2.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p2.1.m1.4.4.3.3.6" xref="S2.SS1.p2.1.m1.4.4.3.4.cmml">,</mo><mi id="S2.SS1.p2.1.m1.1.1" mathvariant="normal" xref="S2.SS1.p2.1.m1.1.1.cmml">…</mi><mo id="S2.SS1.p2.1.m1.4.4.3.3.7" xref="S2.SS1.p2.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p2.1.m1.4.4.3.3.3" xref="S2.SS1.p2.1.m1.4.4.3.3.3.cmml"><mi id="S2.SS1.p2.1.m1.4.4.3.3.3.2" xref="S2.SS1.p2.1.m1.4.4.3.3.3.2.cmml">d</mi><mi id="S2.SS1.p2.1.m1.4.4.3.3.3.3" xref="S2.SS1.p2.1.m1.4.4.3.3.3.3.cmml">D</mi></msub><mo id="S2.SS1.p2.1.m1.4.4.3.3.8" stretchy="false" xref="S2.SS1.p2.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.4b"><apply id="S2.SS1.p2.1.m1.4.4.cmml" xref="S2.SS1.p2.1.m1.4.4"><eq id="S2.SS1.p2.1.m1.4.4.4.cmml" xref="S2.SS1.p2.1.m1.4.4.4"></eq><ci id="S2.SS1.p2.1.m1.4.4.5.cmml" xref="S2.SS1.p2.1.m1.4.4.5">𝒞</ci><set id="S2.SS1.p2.1.m1.4.4.3.4.cmml" xref="S2.SS1.p2.1.m1.4.4.3.3"><apply id="S2.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S2.SS1.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.2.2.1.1.1.2">𝑑</ci><cn id="S2.SS1.p2.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p2.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS1.p2.1.m1.3.3.2.2.2.2">𝑑</ci><cn id="S2.SS1.p2.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS1.p2.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">…</ci><apply id="S2.SS1.p2.1.m1.4.4.3.3.3.cmml" xref="S2.SS1.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.4.4.3.3.3.1.cmml" xref="S2.SS1.p2.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p2.1.m1.4.4.3.3.3.2.cmml" xref="S2.SS1.p2.1.m1.4.4.3.3.3.2">𝑑</ci><ci id="S2.SS1.p2.1.m1.4.4.3.3.3.3.cmml" xref="S2.SS1.p2.1.m1.4.4.3.3.3.3">𝐷</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.4c">\mathcal{C}=\{d_{1},d_{2},\ldots,d_{D}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.4d">caligraphic_C = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT }</annotation></semantics></math>, which is a collection of <math alttext="D" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">italic_D</annotation></semantics></math> documents. Formally speaking, the long context retriever is a function: <math alttext="\mathcal{F}:(q,\mathcal{C})\rightarrow\mathcal{C}_{\mathcal{F}}" class="ltx_Math" display="inline" id="S2.SS1.p2.3.m3.2"><semantics id="S2.SS1.p2.3.m3.2a"><mrow id="S2.SS1.p2.3.m3.2.3" xref="S2.SS1.p2.3.m3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.3.m3.2.3.2" xref="S2.SS1.p2.3.m3.2.3.2.cmml">ℱ</mi><mo id="S2.SS1.p2.3.m3.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p2.3.m3.2.3.1.cmml">:</mo><mrow id="S2.SS1.p2.3.m3.2.3.3" xref="S2.SS1.p2.3.m3.2.3.3.cmml"><mrow id="S2.SS1.p2.3.m3.2.3.3.2.2" xref="S2.SS1.p2.3.m3.2.3.3.2.1.cmml"><mo id="S2.SS1.p2.3.m3.2.3.3.2.2.1" stretchy="false" xref="S2.SS1.p2.3.m3.2.3.3.2.1.cmml">(</mo><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">q</mi><mo id="S2.SS1.p2.3.m3.2.3.3.2.2.2" xref="S2.SS1.p2.3.m3.2.3.3.2.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.3.m3.2.2" xref="S2.SS1.p2.3.m3.2.2.cmml">𝒞</mi><mo id="S2.SS1.p2.3.m3.2.3.3.2.2.3" stretchy="false" xref="S2.SS1.p2.3.m3.2.3.3.2.1.cmml">)</mo></mrow><mo id="S2.SS1.p2.3.m3.2.3.3.1" stretchy="false" xref="S2.SS1.p2.3.m3.2.3.3.1.cmml">→</mo><msub id="S2.SS1.p2.3.m3.2.3.3.3" xref="S2.SS1.p2.3.m3.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.3.m3.2.3.3.3.2" xref="S2.SS1.p2.3.m3.2.3.3.3.2.cmml">𝒞</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.3.m3.2.3.3.3.3" xref="S2.SS1.p2.3.m3.2.3.3.3.3.cmml">ℱ</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.2b"><apply id="S2.SS1.p2.3.m3.2.3.cmml" xref="S2.SS1.p2.3.m3.2.3"><ci id="S2.SS1.p2.3.m3.2.3.1.cmml" xref="S2.SS1.p2.3.m3.2.3.1">:</ci><ci id="S2.SS1.p2.3.m3.2.3.2.cmml" xref="S2.SS1.p2.3.m3.2.3.2">ℱ</ci><apply id="S2.SS1.p2.3.m3.2.3.3.cmml" xref="S2.SS1.p2.3.m3.2.3.3"><ci id="S2.SS1.p2.3.m3.2.3.3.1.cmml" xref="S2.SS1.p2.3.m3.2.3.3.1">→</ci><interval closure="open" id="S2.SS1.p2.3.m3.2.3.3.2.1.cmml" xref="S2.SS1.p2.3.m3.2.3.3.2.2"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">𝑞</ci><ci id="S2.SS1.p2.3.m3.2.2.cmml" xref="S2.SS1.p2.3.m3.2.2">𝒞</ci></interval><apply id="S2.SS1.p2.3.m3.2.3.3.3.cmml" xref="S2.SS1.p2.3.m3.2.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.2.3.3.3.1.cmml" xref="S2.SS1.p2.3.m3.2.3.3.3">subscript</csymbol><ci id="S2.SS1.p2.3.m3.2.3.3.3.2.cmml" xref="S2.SS1.p2.3.m3.2.3.3.3.2">𝒞</ci><ci id="S2.SS1.p2.3.m3.2.3.3.3.3.cmml" xref="S2.SS1.p2.3.m3.2.3.3.3.3">ℱ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.2c">\mathcal{F}:(q,\mathcal{C})\rightarrow\mathcal{C}_{\mathcal{F}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.3.m3.2d">caligraphic_F : ( italic_q , caligraphic_C ) → caligraphic_C start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT</annotation></semantics></math> that takes as input a question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS1.p2.4.m4.1"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.4.m4.1d">italic_q</annotation></semantics></math> and a corpus <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S2.SS1.p2.5.m5.1"><semantics id="S2.SS1.p2.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.5.m5.1d">caligraphic_C</annotation></semantics></math> and returns a filtered set of texts <math alttext="\mathcal{C}_{\mathcal{F}}\subset\mathcal{C}" class="ltx_Math" display="inline" id="S2.SS1.p2.6.m6.1"><semantics id="S2.SS1.p2.6.m6.1a"><mrow id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml"><msub id="S2.SS1.p2.6.m6.1.1.2" xref="S2.SS1.p2.6.m6.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.6.m6.1.1.2.2" xref="S2.SS1.p2.6.m6.1.1.2.2.cmml">𝒞</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.6.m6.1.1.2.3" xref="S2.SS1.p2.6.m6.1.1.2.3.cmml">ℱ</mi></msub><mo id="S2.SS1.p2.6.m6.1.1.1" xref="S2.SS1.p2.6.m6.1.1.1.cmml">⊂</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.6.m6.1.1.3" xref="S2.SS1.p2.6.m6.1.1.3.cmml">𝒞</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1"><subset id="S2.SS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1.1"></subset><apply id="S2.SS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.2.1.cmml" xref="S2.SS1.p2.6.m6.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.2.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2.2">𝒞</ci><ci id="S2.SS1.p2.6.m6.1.1.2.3.cmml" xref="S2.SS1.p2.6.m6.1.1.2.3">ℱ</ci></apply><ci id="S2.SS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3">𝒞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">\mathcal{C}_{\mathcal{F}}\subset\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.6.m6.1d">caligraphic_C start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT ⊂ caligraphic_C</annotation></semantics></math>. In traditional RAG, <math alttext="\mathcal{C}_{\mathcal{F}}" class="ltx_Math" display="inline" id="S2.SS1.p2.7.m7.1"><semantics id="S2.SS1.p2.7.m7.1a"><msub id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml">𝒞</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml">ℱ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2">𝒞</ci><ci id="S2.SS1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3">ℱ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">\mathcal{C}_{\mathcal{F}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.7.m7.1d">caligraphic_C start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT</annotation></semantics></math> is usually small which contains about hundred of tokens, which should contain exact information related to the question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS1.p2.8.m8.1"><semantics id="S2.SS1.p2.8.m8.1a"><mi id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><ci id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.8.m8.1d">italic_q</annotation></semantics></math>. In our framework, <math alttext="\mathcal{C}_{\mathcal{F}}" class="ltx_Math" display="inline" id="S2.SS1.p2.9.m9.1"><semantics id="S2.SS1.p2.9.m9.1a"><msub id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.9.m9.1.1.2" xref="S2.SS1.p2.9.m9.1.1.2.cmml">𝒞</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.9.m9.1.1.3" xref="S2.SS1.p2.9.m9.1.1.3.cmml">ℱ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.1b"><apply id="S2.SS1.p2.9.m9.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.2.cmml" xref="S2.SS1.p2.9.m9.1.1.2">𝒞</ci><ci id="S2.SS1.p2.9.m9.1.1.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3">ℱ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.1c">\mathcal{C}_{\mathcal{F}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.9.m9.1d">caligraphic_C start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT</annotation></semantics></math> is usually more than 4K tokens, which contains relavant but not exact information related to the question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS1.p2.10.m10.1"><semantics id="S2.SS1.p2.10.m10.1a"><mi id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.1b"><ci id="S2.SS1.p2.10.m10.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.10.m10.1d">italic_q</annotation></semantics></math>. The long retriever function <math alttext="\mathcal{F}:(q,\mathcal{C})" class="ltx_Math" display="inline" id="S2.SS1.p2.11.m11.2"><semantics id="S2.SS1.p2.11.m11.2a"><mrow id="S2.SS1.p2.11.m11.2.3" xref="S2.SS1.p2.11.m11.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.11.m11.2.3.2" xref="S2.SS1.p2.11.m11.2.3.2.cmml">ℱ</mi><mo id="S2.SS1.p2.11.m11.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p2.11.m11.2.3.1.cmml">:</mo><mrow id="S2.SS1.p2.11.m11.2.3.3.2" xref="S2.SS1.p2.11.m11.2.3.3.1.cmml"><mo id="S2.SS1.p2.11.m11.2.3.3.2.1" stretchy="false" xref="S2.SS1.p2.11.m11.2.3.3.1.cmml">(</mo><mi id="S2.SS1.p2.11.m11.1.1" xref="S2.SS1.p2.11.m11.1.1.cmml">q</mi><mo id="S2.SS1.p2.11.m11.2.3.3.2.2" xref="S2.SS1.p2.11.m11.2.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.11.m11.2.2" xref="S2.SS1.p2.11.m11.2.2.cmml">𝒞</mi><mo id="S2.SS1.p2.11.m11.2.3.3.2.3" stretchy="false" xref="S2.SS1.p2.11.m11.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.11.m11.2b"><apply id="S2.SS1.p2.11.m11.2.3.cmml" xref="S2.SS1.p2.11.m11.2.3"><ci id="S2.SS1.p2.11.m11.2.3.1.cmml" xref="S2.SS1.p2.11.m11.2.3.1">:</ci><ci id="S2.SS1.p2.11.m11.2.3.2.cmml" xref="S2.SS1.p2.11.m11.2.3.2">ℱ</ci><interval closure="open" id="S2.SS1.p2.11.m11.2.3.3.1.cmml" xref="S2.SS1.p2.11.m11.2.3.3.2"><ci id="S2.SS1.p2.11.m11.1.1.cmml" xref="S2.SS1.p2.11.m11.1.1">𝑞</ci><ci id="S2.SS1.p2.11.m11.2.2.cmml" xref="S2.SS1.p2.11.m11.2.2">𝒞</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.11.m11.2c">\mathcal{F}:(q,\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.11.m11.2d">caligraphic_F : ( italic_q , caligraphic_C )</annotation></semantics></math> is then divided into three steps:</p>
</div>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Formulate long retrieval units</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.5">A function is applied to the corpus to form <math alttext="M" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px1.p1.1.m1.1d">italic_M</annotation></semantics></math> retrieval units: <math alttext="\mathcal{G}(\mathcal{C})=\{g_{1},g_{2},\dots,g_{M}\}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.2.m2.5"><semantics id="S2.SS1.SSS0.Px1.p1.2.m2.5a"><mrow id="S2.SS1.SSS0.Px1.p1.2.m2.5.5" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.cmml"><mrow id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.2.cmml">𝒢</mi><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.1" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.1.cmml">⁢</mo><mrow id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.3.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.cmml"><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.3.2.1" stretchy="false" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">𝒞</mi><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.3.2.2" stretchy="false" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.4" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.4.cmml">=</mo><mrow id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml"><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.4" stretchy="false" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml">{</mo><msub id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.2.cmml">g</mi><mn id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.5" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml">,</mo><msub id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.cmml"><mi id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.2.cmml">g</mi><mn id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.6" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml">,</mo><mi id="S2.SS1.SSS0.Px1.p1.2.m2.2.2" mathvariant="normal" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.cmml">…</mi><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.7" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml">,</mo><msub id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.2.cmml">g</mi><mi id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.3.cmml">M</mi></msub><mo id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.8" stretchy="false" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.2.m2.5b"><apply id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5"><eq id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.4.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.4"></eq><apply id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5"><times id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.1"></times><ci id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.5.2">𝒢</ci><ci id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1">𝒞</ci></apply><set id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.4.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3"><apply id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.2">𝑔</ci><cn id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.3.cmml" type="integer" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.1.1.1.3">1</cn></apply><apply id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.2">𝑔</ci><cn id="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.3.cmml" type="integer" xref="S2.SS1.SSS0.Px1.p1.2.m2.4.4.2.2.2.3">2</cn></apply><ci id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2">…</ci><apply id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.2">𝑔</ci><ci id="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.5.5.3.3.3.3">𝑀</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.2.m2.5c">\mathcal{G}(\mathcal{C})=\{g_{1},g_{2},\dots,g_{M}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px1.p1.2.m2.5d">caligraphic_G ( caligraphic_C ) = { italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_g start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math>. In traditional RAG, the retrieval unit <math alttext="g" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="S2.SS1.SSS0.Px1.p1.3.m3.1a"><mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.3.m3.1b"><ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.3.m3.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px1.p1.3.m3.1d">italic_g</annotation></semantics></math> is typically a short span of passage which is split from the documents <math alttext="d" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S2.SS1.SSS0.Px1.p1.4.m4.1a"><mi id="S2.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.4.m4.1b"><ci id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.4.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px1.p1.4.m4.1d">italic_d</annotation></semantics></math>, containing hundreds of tokens. In our framework, <math alttext="g" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.5.m5.1"><semantics id="S2.SS1.SSS0.Px1.p1.5.m5.1a"><mi id="S2.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.5.m5.1b"><ci id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.5.m5.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px1.p1.5.m5.1d">italic_g</annotation></semantics></math> could be as long as the whole document or even a group of documents, resulting in much longer retrieval units.
If the original document is already long (e.g., longer than 4K tokens), we treat the entire document as a single unit. If the original document is relatively short (e.g., shorter than 1K tokens), we group related documents together to form a single unit. We provide an example of a grouping algorithm in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS3" title="A.3 Group Documents Algorithm ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">A.3</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p2.1">By having a longer retrieval unit, there are two key advantages: First, only very few (e.g., 4 to 8 retrieval units) are fed into the reader, which greatly reduces the likelihood of encountering hard negatives compared to traditional RAG, which may require hundreds of short units in its reader. Second, by retaining the entire document or even related documents within a single retrieval unit, the contextual information is preserved.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Similarity search</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.4">We utilize an encoder, denoted as <math alttext="E_{Q}(\cdot)" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="S2.SS1.SSS0.Px2.p1.1.m1.1.2" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.cmml"><msub id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.cmml"><mi id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.2" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.2.cmml">E</mi><mi id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.3" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.3.cmml">Q</mi></msub><mo id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.1" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.3.2" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.cmml"><mo id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.cmml">(</mo><mo id="S2.SS1.SSS0.Px2.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">⋅</mo><mo id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2"><times id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.1"></times><apply id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.2">𝐸</ci><ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.2.2.3">𝑄</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.1.m1.1c">E_{Q}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p1.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math>, to map the input question to a <math alttext="d" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.2.m2.1"><semantics id="S2.SS1.SSS0.Px2.p1.2.m2.1a"><mi id="S2.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.2.m2.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p1.2.m2.1d">italic_d</annotation></semantics></math>-dimensional vector. Additionally, we employ another encoder, <math alttext="E_{C}(\cdot)" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.3.m3.1"><semantics id="S2.SS1.SSS0.Px2.p1.3.m3.1a"><mrow id="S2.SS1.SSS0.Px2.p1.3.m3.1.2" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.cmml"><msub id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.cmml"><mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.2" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.2.cmml">E</mi><mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.3" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.3.cmml">C</mi></msub><mo id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.1" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.3.2" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.cmml"><mo id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.3.2.1" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.cmml">(</mo><mo id="S2.SS1.SSS0.Px2.p1.3.m3.1.1" lspace="0em" rspace="0em" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml">⋅</mo><mo id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.3.2.2" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2"><times id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.1"></times><apply id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.2">𝐸</ci><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.2.2.3">𝐶</ci></apply><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.3.m3.1c">E_{C}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p1.3.m3.1d">italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math>, to map the retrieval unit to a <math alttext="d" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.4.m4.1"><semantics id="S2.SS1.SSS0.Px2.p1.4.m4.1a"><mi id="S2.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.4.m4.1b"><ci id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.4.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p1.4.m4.1d">italic_d</annotation></semantics></math>-dimensional vector. We define the similarity between the question and the retrieval unit using the dot product of their vectors:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx1">
<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)" class="ltx_Math" display="inline" id="S2.Ex1.m1.4"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4.5" xref="S2.Ex1.m1.4.5.cmml"><mrow id="S2.Ex1.m1.4.5.2" xref="S2.Ex1.m1.4.5.2.cmml"><mi id="S2.Ex1.m1.4.5.2.2" xref="S2.Ex1.m1.4.5.2.2.cmml">s</mi><mo id="S2.Ex1.m1.4.5.2.1" xref="S2.Ex1.m1.4.5.2.1.cmml">⁢</mo><mi id="S2.Ex1.m1.4.5.2.3" xref="S2.Ex1.m1.4.5.2.3.cmml">i</mi><mo id="S2.Ex1.m1.4.5.2.1a" xref="S2.Ex1.m1.4.5.2.1.cmml">⁢</mo><mi id="S2.Ex1.m1.4.5.2.4" xref="S2.Ex1.m1.4.5.2.4.cmml">m</mi><mo id="S2.Ex1.m1.4.5.2.1b" xref="S2.Ex1.m1.4.5.2.1.cmml">⁢</mo><mrow id="S2.Ex1.m1.4.5.2.5.2" xref="S2.Ex1.m1.4.5.2.5.1.cmml"><mo id="S2.Ex1.m1.4.5.2.5.2.1" stretchy="false" xref="S2.Ex1.m1.4.5.2.5.1.cmml">(</mo><mi id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">q</mi><mo id="S2.Ex1.m1.4.5.2.5.2.2" xref="S2.Ex1.m1.4.5.2.5.1.cmml">,</mo><mi id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml">g</mi><mo id="S2.Ex1.m1.4.5.2.5.2.3" stretchy="false" xref="S2.Ex1.m1.4.5.2.5.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.4.5.1" xref="S2.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S2.Ex1.m1.4.5.3" xref="S2.Ex1.m1.4.5.3.cmml"><msub id="S2.Ex1.m1.4.5.3.2" xref="S2.Ex1.m1.4.5.3.2.cmml"><mi id="S2.Ex1.m1.4.5.3.2.2" xref="S2.Ex1.m1.4.5.3.2.2.cmml">E</mi><mi id="S2.Ex1.m1.4.5.3.2.3" xref="S2.Ex1.m1.4.5.3.2.3.cmml">Q</mi></msub><mo id="S2.Ex1.m1.4.5.3.1" xref="S2.Ex1.m1.4.5.3.1.cmml">⁢</mo><msup id="S2.Ex1.m1.4.5.3.3" xref="S2.Ex1.m1.4.5.3.3.cmml"><mrow id="S2.Ex1.m1.4.5.3.3.2.2" xref="S2.Ex1.m1.4.5.3.3.cmml"><mo id="S2.Ex1.m1.4.5.3.3.2.2.1" stretchy="false" xref="S2.Ex1.m1.4.5.3.3.cmml">(</mo><mi id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml">q</mi><mo id="S2.Ex1.m1.4.5.3.3.2.2.2" stretchy="false" xref="S2.Ex1.m1.4.5.3.3.cmml">)</mo></mrow><mi id="S2.Ex1.m1.4.5.3.3.3" xref="S2.Ex1.m1.4.5.3.3.3.cmml">T</mi></msup><mo id="S2.Ex1.m1.4.5.3.1a" xref="S2.Ex1.m1.4.5.3.1.cmml">⁢</mo><msub id="S2.Ex1.m1.4.5.3.4" xref="S2.Ex1.m1.4.5.3.4.cmml"><mi id="S2.Ex1.m1.4.5.3.4.2" xref="S2.Ex1.m1.4.5.3.4.2.cmml">E</mi><mi id="S2.Ex1.m1.4.5.3.4.3" xref="S2.Ex1.m1.4.5.3.4.3.cmml">C</mi></msub><mo id="S2.Ex1.m1.4.5.3.1b" xref="S2.Ex1.m1.4.5.3.1.cmml">⁢</mo><mrow id="S2.Ex1.m1.4.5.3.5.2" xref="S2.Ex1.m1.4.5.3.cmml"><mo id="S2.Ex1.m1.4.5.3.5.2.1" stretchy="false" xref="S2.Ex1.m1.4.5.3.cmml">(</mo><mi id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml">g</mi><mo id="S2.Ex1.m1.4.5.3.5.2.2" stretchy="false" xref="S2.Ex1.m1.4.5.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.4b"><apply id="S2.Ex1.m1.4.5.cmml" xref="S2.Ex1.m1.4.5"><eq id="S2.Ex1.m1.4.5.1.cmml" xref="S2.Ex1.m1.4.5.1"></eq><apply id="S2.Ex1.m1.4.5.2.cmml" xref="S2.Ex1.m1.4.5.2"><times id="S2.Ex1.m1.4.5.2.1.cmml" xref="S2.Ex1.m1.4.5.2.1"></times><ci id="S2.Ex1.m1.4.5.2.2.cmml" xref="S2.Ex1.m1.4.5.2.2">𝑠</ci><ci id="S2.Ex1.m1.4.5.2.3.cmml" xref="S2.Ex1.m1.4.5.2.3">𝑖</ci><ci id="S2.Ex1.m1.4.5.2.4.cmml" xref="S2.Ex1.m1.4.5.2.4">𝑚</ci><interval closure="open" id="S2.Ex1.m1.4.5.2.5.1.cmml" xref="S2.Ex1.m1.4.5.2.5.2"><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">𝑞</ci><ci id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.2.2">𝑔</ci></interval></apply><apply id="S2.Ex1.m1.4.5.3.cmml" xref="S2.Ex1.m1.4.5.3"><times id="S2.Ex1.m1.4.5.3.1.cmml" xref="S2.Ex1.m1.4.5.3.1"></times><apply id="S2.Ex1.m1.4.5.3.2.cmml" xref="S2.Ex1.m1.4.5.3.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.4.5.3.2.1.cmml" xref="S2.Ex1.m1.4.5.3.2">subscript</csymbol><ci id="S2.Ex1.m1.4.5.3.2.2.cmml" xref="S2.Ex1.m1.4.5.3.2.2">𝐸</ci><ci id="S2.Ex1.m1.4.5.3.2.3.cmml" xref="S2.Ex1.m1.4.5.3.2.3">𝑄</ci></apply><apply id="S2.Ex1.m1.4.5.3.3.cmml" xref="S2.Ex1.m1.4.5.3.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.4.5.3.3.1.cmml" xref="S2.Ex1.m1.4.5.3.3">superscript</csymbol><ci id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3">𝑞</ci><ci id="S2.Ex1.m1.4.5.3.3.3.cmml" xref="S2.Ex1.m1.4.5.3.3.3">𝑇</ci></apply><apply id="S2.Ex1.m1.4.5.3.4.cmml" xref="S2.Ex1.m1.4.5.3.4"><csymbol cd="ambiguous" id="S2.Ex1.m1.4.5.3.4.1.cmml" xref="S2.Ex1.m1.4.5.3.4">subscript</csymbol><ci id="S2.Ex1.m1.4.5.3.4.2.cmml" xref="S2.Ex1.m1.4.5.3.4.2">𝐸</ci><ci id="S2.Ex1.m1.4.5.3.4.3.cmml" xref="S2.Ex1.m1.4.5.3.4.3">𝐶</ci></apply><ci id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.4d">italic_s italic_i italic_m ( italic_q , italic_g ) = italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p2.2">In LongRAG settings, <math alttext="E_{C}(g)" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.1.m1.1"><semantics id="S2.SS1.SSS0.Px2.p2.1.m1.1a"><mrow id="S2.SS1.SSS0.Px2.p2.1.m1.1.2" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.cmml"><msub id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.cmml"><mi id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.2" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.2.cmml">E</mi><mi id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.3" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.3.cmml">C</mi></msub><mo id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.1" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.3.2" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.cmml"><mo id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.cmml">(</mo><mi id="S2.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.1.cmml">g</mi><mo id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2"><times id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.1.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.1"></times><apply id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.1.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.2.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.2">𝐸</ci><ci id="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.3.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.2.2.3">𝐶</ci></apply><ci id="S2.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.1.m1.1.1">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.1.m1.1c">E_{C}(g)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g )</annotation></semantics></math> is challenging given the length of <math alttext="g" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.2.m2.1"><semantics id="S2.SS1.SSS0.Px2.p2.2.m2.1a"><mi id="S2.SS1.SSS0.Px2.p2.2.m2.1.1" xref="S2.SS1.SSS0.Px2.p2.2.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.2.m2.1b"><ci id="S2.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.2.m2.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.2.m2.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.2.m2.1d">italic_g</annotation></semantics></math>, so we resort to an approximation as below.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx2">
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\approx\max_{g^{\prime}\subseteq g}%
(E_{Q}(q)^{T}E_{C}(g^{\prime}))" class="ltx_Math" display="inline" id="S2.Ex2.m1.7"><semantics id="S2.Ex2.m1.7a"><mrow id="S2.Ex2.m1.7.7" xref="S2.Ex2.m1.7.7.cmml"><mrow id="S2.Ex2.m1.7.7.4" xref="S2.Ex2.m1.7.7.4.cmml"><mi id="S2.Ex2.m1.7.7.4.2" xref="S2.Ex2.m1.7.7.4.2.cmml">s</mi><mo id="S2.Ex2.m1.7.7.4.1" xref="S2.Ex2.m1.7.7.4.1.cmml">⁢</mo><mi id="S2.Ex2.m1.7.7.4.3" xref="S2.Ex2.m1.7.7.4.3.cmml">i</mi><mo id="S2.Ex2.m1.7.7.4.1a" xref="S2.Ex2.m1.7.7.4.1.cmml">⁢</mo><mi id="S2.Ex2.m1.7.7.4.4" xref="S2.Ex2.m1.7.7.4.4.cmml">m</mi><mo id="S2.Ex2.m1.7.7.4.1b" xref="S2.Ex2.m1.7.7.4.1.cmml">⁢</mo><mrow id="S2.Ex2.m1.7.7.4.5.2" xref="S2.Ex2.m1.7.7.4.5.1.cmml"><mo id="S2.Ex2.m1.7.7.4.5.2.1" stretchy="false" xref="S2.Ex2.m1.7.7.4.5.1.cmml">(</mo><mi id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml">q</mi><mo id="S2.Ex2.m1.7.7.4.5.2.2" xref="S2.Ex2.m1.7.7.4.5.1.cmml">,</mo><mi id="S2.Ex2.m1.2.2" xref="S2.Ex2.m1.2.2.cmml">g</mi><mo id="S2.Ex2.m1.7.7.4.5.2.3" stretchy="false" xref="S2.Ex2.m1.7.7.4.5.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.7.7.5" xref="S2.Ex2.m1.7.7.5.cmml">=</mo><mrow id="S2.Ex2.m1.7.7.6" xref="S2.Ex2.m1.7.7.6.cmml"><msub id="S2.Ex2.m1.7.7.6.2" xref="S2.Ex2.m1.7.7.6.2.cmml"><mi id="S2.Ex2.m1.7.7.6.2.2" xref="S2.Ex2.m1.7.7.6.2.2.cmml">E</mi><mi id="S2.Ex2.m1.7.7.6.2.3" xref="S2.Ex2.m1.7.7.6.2.3.cmml">Q</mi></msub><mo id="S2.Ex2.m1.7.7.6.1" xref="S2.Ex2.m1.7.7.6.1.cmml">⁢</mo><msup id="S2.Ex2.m1.7.7.6.3" xref="S2.Ex2.m1.7.7.6.3.cmml"><mrow id="S2.Ex2.m1.7.7.6.3.2.2" xref="S2.Ex2.m1.7.7.6.3.cmml"><mo id="S2.Ex2.m1.7.7.6.3.2.2.1" stretchy="false" xref="S2.Ex2.m1.7.7.6.3.cmml">(</mo><mi id="S2.Ex2.m1.3.3" xref="S2.Ex2.m1.3.3.cmml">q</mi><mo id="S2.Ex2.m1.7.7.6.3.2.2.2" stretchy="false" xref="S2.Ex2.m1.7.7.6.3.cmml">)</mo></mrow><mi id="S2.Ex2.m1.7.7.6.3.3" xref="S2.Ex2.m1.7.7.6.3.3.cmml">T</mi></msup><mo id="S2.Ex2.m1.7.7.6.1a" xref="S2.Ex2.m1.7.7.6.1.cmml">⁢</mo><msub id="S2.Ex2.m1.7.7.6.4" xref="S2.Ex2.m1.7.7.6.4.cmml"><mi id="S2.Ex2.m1.7.7.6.4.2" xref="S2.Ex2.m1.7.7.6.4.2.cmml">E</mi><mi id="S2.Ex2.m1.7.7.6.4.3" xref="S2.Ex2.m1.7.7.6.4.3.cmml">C</mi></msub><mo id="S2.Ex2.m1.7.7.6.1b" xref="S2.Ex2.m1.7.7.6.1.cmml">⁢</mo><mrow id="S2.Ex2.m1.7.7.6.5.2" xref="S2.Ex2.m1.7.7.6.cmml"><mo id="S2.Ex2.m1.7.7.6.5.2.1" stretchy="false" xref="S2.Ex2.m1.7.7.6.cmml">(</mo><mi id="S2.Ex2.m1.4.4" xref="S2.Ex2.m1.4.4.cmml">g</mi><mo id="S2.Ex2.m1.7.7.6.5.2.2" stretchy="false" xref="S2.Ex2.m1.7.7.6.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.7.7.7" xref="S2.Ex2.m1.7.7.7.cmml">≈</mo><mrow id="S2.Ex2.m1.7.7.2.2" xref="S2.Ex2.m1.7.7.2.3.cmml"><munder id="S2.Ex2.m1.6.6.1.1.1" xref="S2.Ex2.m1.6.6.1.1.1.cmml"><mi id="S2.Ex2.m1.6.6.1.1.1.2" xref="S2.Ex2.m1.6.6.1.1.1.2.cmml">max</mi><mrow id="S2.Ex2.m1.6.6.1.1.1.3" xref="S2.Ex2.m1.6.6.1.1.1.3.cmml"><msup id="S2.Ex2.m1.6.6.1.1.1.3.2" xref="S2.Ex2.m1.6.6.1.1.1.3.2.cmml"><mi id="S2.Ex2.m1.6.6.1.1.1.3.2.2" xref="S2.Ex2.m1.6.6.1.1.1.3.2.2.cmml">g</mi><mo id="S2.Ex2.m1.6.6.1.1.1.3.2.3" xref="S2.Ex2.m1.6.6.1.1.1.3.2.3.cmml">′</mo></msup><mo id="S2.Ex2.m1.6.6.1.1.1.3.1" xref="S2.Ex2.m1.6.6.1.1.1.3.1.cmml">⊆</mo><mi id="S2.Ex2.m1.6.6.1.1.1.3.3" xref="S2.Ex2.m1.6.6.1.1.1.3.3.cmml">g</mi></mrow></munder><mo id="S2.Ex2.m1.7.7.2.2a" xref="S2.Ex2.m1.7.7.2.3.cmml">⁡</mo><mrow id="S2.Ex2.m1.7.7.2.2.2" xref="S2.Ex2.m1.7.7.2.3.cmml"><mo id="S2.Ex2.m1.7.7.2.2.2.2" stretchy="false" xref="S2.Ex2.m1.7.7.2.3.cmml">(</mo><mrow id="S2.Ex2.m1.7.7.2.2.2.1" xref="S2.Ex2.m1.7.7.2.2.2.1.cmml"><msub id="S2.Ex2.m1.7.7.2.2.2.1.3" xref="S2.Ex2.m1.7.7.2.2.2.1.3.cmml"><mi id="S2.Ex2.m1.7.7.2.2.2.1.3.2" xref="S2.Ex2.m1.7.7.2.2.2.1.3.2.cmml">E</mi><mi id="S2.Ex2.m1.7.7.2.2.2.1.3.3" xref="S2.Ex2.m1.7.7.2.2.2.1.3.3.cmml">Q</mi></msub><mo id="S2.Ex2.m1.7.7.2.2.2.1.2" xref="S2.Ex2.m1.7.7.2.2.2.1.2.cmml">⁢</mo><msup id="S2.Ex2.m1.7.7.2.2.2.1.4" xref="S2.Ex2.m1.7.7.2.2.2.1.4.cmml"><mrow id="S2.Ex2.m1.7.7.2.2.2.1.4.2.2" xref="S2.Ex2.m1.7.7.2.2.2.1.4.cmml"><mo id="S2.Ex2.m1.7.7.2.2.2.1.4.2.2.1" stretchy="false" xref="S2.Ex2.m1.7.7.2.2.2.1.4.cmml">(</mo><mi id="S2.Ex2.m1.5.5" xref="S2.Ex2.m1.5.5.cmml">q</mi><mo id="S2.Ex2.m1.7.7.2.2.2.1.4.2.2.2" stretchy="false" xref="S2.Ex2.m1.7.7.2.2.2.1.4.cmml">)</mo></mrow><mi id="S2.Ex2.m1.7.7.2.2.2.1.4.3" xref="S2.Ex2.m1.7.7.2.2.2.1.4.3.cmml">T</mi></msup><mo id="S2.Ex2.m1.7.7.2.2.2.1.2a" xref="S2.Ex2.m1.7.7.2.2.2.1.2.cmml">⁢</mo><msub id="S2.Ex2.m1.7.7.2.2.2.1.5" xref="S2.Ex2.m1.7.7.2.2.2.1.5.cmml"><mi id="S2.Ex2.m1.7.7.2.2.2.1.5.2" xref="S2.Ex2.m1.7.7.2.2.2.1.5.2.cmml">E</mi><mi id="S2.Ex2.m1.7.7.2.2.2.1.5.3" xref="S2.Ex2.m1.7.7.2.2.2.1.5.3.cmml">C</mi></msub><mo id="S2.Ex2.m1.7.7.2.2.2.1.2b" xref="S2.Ex2.m1.7.7.2.2.2.1.2.cmml">⁢</mo><mrow id="S2.Ex2.m1.7.7.2.2.2.1.1.1" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml"><mo id="S2.Ex2.m1.7.7.2.2.2.1.1.1.2" stretchy="false" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml">(</mo><msup id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml"><mi id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2.cmml">g</mi><mo id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3.cmml">′</mo></msup><mo id="S2.Ex2.m1.7.7.2.2.2.1.1.1.3" stretchy="false" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.7.7.2.2.2.3" stretchy="false" xref="S2.Ex2.m1.7.7.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.7b"><apply id="S2.Ex2.m1.7.7.cmml" xref="S2.Ex2.m1.7.7"><and id="S2.Ex2.m1.7.7a.cmml" xref="S2.Ex2.m1.7.7"></and><apply id="S2.Ex2.m1.7.7b.cmml" xref="S2.Ex2.m1.7.7"><eq id="S2.Ex2.m1.7.7.5.cmml" xref="S2.Ex2.m1.7.7.5"></eq><apply id="S2.Ex2.m1.7.7.4.cmml" xref="S2.Ex2.m1.7.7.4"><times id="S2.Ex2.m1.7.7.4.1.cmml" xref="S2.Ex2.m1.7.7.4.1"></times><ci id="S2.Ex2.m1.7.7.4.2.cmml" xref="S2.Ex2.m1.7.7.4.2">𝑠</ci><ci id="S2.Ex2.m1.7.7.4.3.cmml" xref="S2.Ex2.m1.7.7.4.3">𝑖</ci><ci id="S2.Ex2.m1.7.7.4.4.cmml" xref="S2.Ex2.m1.7.7.4.4">𝑚</ci><interval closure="open" id="S2.Ex2.m1.7.7.4.5.1.cmml" xref="S2.Ex2.m1.7.7.4.5.2"><ci id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1">𝑞</ci><ci id="S2.Ex2.m1.2.2.cmml" xref="S2.Ex2.m1.2.2">𝑔</ci></interval></apply><apply id="S2.Ex2.m1.7.7.6.cmml" xref="S2.Ex2.m1.7.7.6"><times id="S2.Ex2.m1.7.7.6.1.cmml" xref="S2.Ex2.m1.7.7.6.1"></times><apply id="S2.Ex2.m1.7.7.6.2.cmml" xref="S2.Ex2.m1.7.7.6.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.6.2.1.cmml" xref="S2.Ex2.m1.7.7.6.2">subscript</csymbol><ci id="S2.Ex2.m1.7.7.6.2.2.cmml" xref="S2.Ex2.m1.7.7.6.2.2">𝐸</ci><ci id="S2.Ex2.m1.7.7.6.2.3.cmml" xref="S2.Ex2.m1.7.7.6.2.3">𝑄</ci></apply><apply id="S2.Ex2.m1.7.7.6.3.cmml" xref="S2.Ex2.m1.7.7.6.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.6.3.1.cmml" xref="S2.Ex2.m1.7.7.6.3">superscript</csymbol><ci id="S2.Ex2.m1.3.3.cmml" xref="S2.Ex2.m1.3.3">𝑞</ci><ci id="S2.Ex2.m1.7.7.6.3.3.cmml" xref="S2.Ex2.m1.7.7.6.3.3">𝑇</ci></apply><apply id="S2.Ex2.m1.7.7.6.4.cmml" xref="S2.Ex2.m1.7.7.6.4"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.6.4.1.cmml" xref="S2.Ex2.m1.7.7.6.4">subscript</csymbol><ci id="S2.Ex2.m1.7.7.6.4.2.cmml" xref="S2.Ex2.m1.7.7.6.4.2">𝐸</ci><ci id="S2.Ex2.m1.7.7.6.4.3.cmml" xref="S2.Ex2.m1.7.7.6.4.3">𝐶</ci></apply><ci id="S2.Ex2.m1.4.4.cmml" xref="S2.Ex2.m1.4.4">𝑔</ci></apply></apply><apply id="S2.Ex2.m1.7.7c.cmml" xref="S2.Ex2.m1.7.7"><approx id="S2.Ex2.m1.7.7.7.cmml" xref="S2.Ex2.m1.7.7.7"></approx><share href="https://arxiv.org/html/2406.15319v3#S2.Ex2.m1.7.7.6.cmml" id="S2.Ex2.m1.7.7d.cmml" xref="S2.Ex2.m1.7.7"></share><apply id="S2.Ex2.m1.7.7.2.3.cmml" xref="S2.Ex2.m1.7.7.2.2"><apply id="S2.Ex2.m1.6.6.1.1.1.cmml" xref="S2.Ex2.m1.6.6.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.6.6.1.1.1.1.cmml" xref="S2.Ex2.m1.6.6.1.1.1">subscript</csymbol><max id="S2.Ex2.m1.6.6.1.1.1.2.cmml" xref="S2.Ex2.m1.6.6.1.1.1.2"></max><apply id="S2.Ex2.m1.6.6.1.1.1.3.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3"><subset id="S2.Ex2.m1.6.6.1.1.1.3.1.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3.1"></subset><apply id="S2.Ex2.m1.6.6.1.1.1.3.2.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.6.6.1.1.1.3.2.1.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3.2">superscript</csymbol><ci id="S2.Ex2.m1.6.6.1.1.1.3.2.2.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3.2.2">𝑔</ci><ci id="S2.Ex2.m1.6.6.1.1.1.3.2.3.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3.2.3">′</ci></apply><ci id="S2.Ex2.m1.6.6.1.1.1.3.3.cmml" xref="S2.Ex2.m1.6.6.1.1.1.3.3">𝑔</ci></apply></apply><apply id="S2.Ex2.m1.7.7.2.2.2.1.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1"><times id="S2.Ex2.m1.7.7.2.2.2.1.2.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.2"></times><apply id="S2.Ex2.m1.7.7.2.2.2.1.3.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.2.2.2.1.3.1.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.3">subscript</csymbol><ci id="S2.Ex2.m1.7.7.2.2.2.1.3.2.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.3.2">𝐸</ci><ci id="S2.Ex2.m1.7.7.2.2.2.1.3.3.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.3.3">𝑄</ci></apply><apply id="S2.Ex2.m1.7.7.2.2.2.1.4.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.4"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.2.2.2.1.4.1.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.4">superscript</csymbol><ci id="S2.Ex2.m1.5.5.cmml" xref="S2.Ex2.m1.5.5">𝑞</ci><ci id="S2.Ex2.m1.7.7.2.2.2.1.4.3.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.4.3">𝑇</ci></apply><apply id="S2.Ex2.m1.7.7.2.2.2.1.5.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.5"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.2.2.2.1.5.1.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.5">subscript</csymbol><ci id="S2.Ex2.m1.7.7.2.2.2.1.5.2.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.5.2">𝐸</ci><ci id="S2.Ex2.m1.7.7.2.2.2.1.5.3.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.5.3">𝐶</ci></apply><apply id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.1.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1">superscript</csymbol><ci id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.2">𝑔</ci><ci id="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3.cmml" xref="S2.Ex2.m1.7.7.2.2.2.1.1.1.1.3">′</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.7c">\displaystyle sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\approx\max_{g^{\prime}\subseteq g}%
(E_{Q}(q)^{T}E_{C}(g^{\prime}))</annotation><annotation encoding="application/x-llamapun" id="S2.Ex2.m1.7d">italic_s italic_i italic_m ( italic_q , italic_g ) = italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g ) ≈ roman_max start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ⊆ italic_g end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p2.8">We approximate it by maximizing the scores of all chunks <math alttext="g^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.3.m1.1"><semantics id="S2.SS1.SSS0.Px2.p2.3.m1.1a"><msup id="S2.SS1.SSS0.Px2.p2.3.m1.1.1" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p2.3.m1.1.1.2" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1.2.cmml">g</mi><mo id="S2.SS1.SSS0.Px2.p2.3.m1.1.1.3" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.3.m1.1b"><apply id="S2.SS1.SSS0.Px2.p2.3.m1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p2.3.m1.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p2.3.m1.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1.2">𝑔</ci><ci id="S2.SS1.SSS0.Px2.p2.3.m1.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p2.3.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.3.m1.1c">g^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.3.m1.1d">italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> within the retrieval unit <math alttext="g" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.4.m2.1"><semantics id="S2.SS1.SSS0.Px2.p2.4.m2.1a"><mi id="S2.SS1.SSS0.Px2.p2.4.m2.1.1" xref="S2.SS1.SSS0.Px2.p2.4.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.4.m2.1b"><ci id="S2.SS1.SSS0.Px2.p2.4.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.4.m2.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.4.m2.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.4.m2.1d">italic_g</annotation></semantics></math>, akin to the MaxP design in <cite class="ltx_cite ltx_citemacro_citep">(Dai &amp; Callan, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib12" title="">2019</a>)</cite>. We consider different levels of granularity of chunk <math alttext="g^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.5.m3.1"><semantics id="S2.SS1.SSS0.Px2.p2.5.m3.1a"><msup id="S2.SS1.SSS0.Px2.p2.5.m3.1.1" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p2.5.m3.1.1.2" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1.2.cmml">g</mi><mo id="S2.SS1.SSS0.Px2.p2.5.m3.1.1.3" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.5.m3.1b"><apply id="S2.SS1.SSS0.Px2.p2.5.m3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p2.5.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p2.5.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1.2">𝑔</ci><ci id="S2.SS1.SSS0.Px2.p2.5.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p2.5.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.5.m3.1c">g^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.5.m3.1d">italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, including 512 tokens, 4K tokens, and encoding the entire <math alttext="g" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.6.m4.1"><semantics id="S2.SS1.SSS0.Px2.p2.6.m4.1a"><mi id="S2.SS1.SSS0.Px2.p2.6.m4.1.1" xref="S2.SS1.SSS0.Px2.p2.6.m4.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.6.m4.1b"><ci id="S2.SS1.SSS0.Px2.p2.6.m4.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.6.m4.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.6.m4.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.6.m4.1d">italic_g</annotation></semantics></math> completely. The empirical study about this settings is in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T4" title="Table 4 ‣ Experiment Setup ‣ 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">4</span></a>.
With this similarity score setup, we will retrieve the top <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.7.m5.1"><semantics id="S2.SS1.SSS0.Px2.p2.7.m5.1a"><mi id="S2.SS1.SSS0.Px2.p2.7.m5.1.1" xref="S2.SS1.SSS0.Px2.p2.7.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.7.m5.1b"><ci id="S2.SS1.SSS0.Px2.p2.7.m5.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.7.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.7.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.7.m5.1d">italic_k</annotation></semantics></math> retrieval units closest to the given query. For efficient retrieval, we precompute the embedding of each retrieval unit <math alttext="g^{\prime}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p2.8.m6.1"><semantics id="S2.SS1.SSS0.Px2.p2.8.m6.1a"><msup id="S2.SS1.SSS0.Px2.p2.8.m6.1.1" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1.cmml"><mi id="S2.SS1.SSS0.Px2.p2.8.m6.1.1.2" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1.2.cmml">g</mi><mo id="S2.SS1.SSS0.Px2.p2.8.m6.1.1.3" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p2.8.m6.1b"><apply id="S2.SS1.SSS0.Px2.p2.8.m6.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p2.8.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px2.p2.8.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1.2">𝑔</ci><ci id="S2.SS1.SSS0.Px2.p2.8.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px2.p2.8.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p2.8.m6.1c">g^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px2.p2.8.m6.1d">italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> and predict the exact inner product search index in FAISS <cite class="ltx_cite ltx_citemacro_citep">(Johnson et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib27" title="">2019</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Aggregate retrieval result</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px3.p1.6">We will concatenate the top <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S2.SS1.SSS0.Px3.p1.1.m1.1a"><mi id="S2.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.1.m1.1b"><ci id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px3.p1.1.m1.1d">italic_k</annotation></semantics></math> retrieval units into the long context as the retrieval result, denoted by <math alttext="\mathcal{C}_{\mathcal{F}}=\text{Concat}(g^{1},g^{2},\ldots,g^{k})" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.2.m2.4"><semantics id="S2.SS1.SSS0.Px3.p1.2.m2.4a"><mrow id="S2.SS1.SSS0.Px3.p1.2.m2.4.4" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.cmml"><msub id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.2" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.2.cmml">𝒞</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.3.cmml">ℱ</mi></msub><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.4" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.cmml"><mtext id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.5" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.5a.cmml">Concat</mtext><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.4" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.4.cmml">⁢</mo><mrow id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml"><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.4" stretchy="false" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml">(</mo><msup id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.cmml"><mi id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.2" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.2.cmml">g</mi><mn id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.3.cmml">1</mn></msup><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.5" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml">,</mo><msup id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.cmml"><mi id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.2" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.2.cmml">g</mi><mn id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.3.cmml">2</mn></msup><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.6" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml">,</mo><mi id="S2.SS1.SSS0.Px3.p1.2.m2.1.1" mathvariant="normal" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.cmml">…</mi><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.7" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml">,</mo><msup id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.cmml"><mi id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.2" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.2.cmml">g</mi><mi id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.3.cmml">k</mi></msup><mo id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.8" stretchy="false" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.2.m2.4b"><apply id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4"><eq id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.4.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.4"></eq><apply id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5">subscript</csymbol><ci id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.2.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.2">𝒞</ci><ci id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.3.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.5.3">ℱ</ci></apply><apply id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3"><times id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.4.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.4"></times><ci id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.5a.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.5"><mtext id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.5.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.5">Concat</mtext></ci><vector id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.4.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3"><apply id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1">superscript</csymbol><ci id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.2">𝑔</ci><cn id="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.3.cmml" type="integer" xref="S2.SS1.SSS0.Px3.p1.2.m2.2.2.1.1.1.1.3">1</cn></apply><apply id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2">superscript</csymbol><ci id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.2">𝑔</ci><cn id="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.3.cmml" type="integer" xref="S2.SS1.SSS0.Px3.p1.2.m2.3.3.2.2.2.2.3">2</cn></apply><ci id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1">…</ci><apply id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3">superscript</csymbol><ci id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.2.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.2">𝑔</ci><ci id="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.3.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.4.4.3.3.3.3.3">𝑘</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.2.m2.4c">\mathcal{C}_{\mathcal{F}}=\text{Concat}(g^{1},g^{2},\ldots,g^{k})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px3.p1.2.m2.4d">caligraphic_C start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT = Concat ( italic_g start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_g start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , italic_g start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT )</annotation></semantics></math>. Depending on the selection of retrieval units, a larger retrieval unit size will result in a smaller value of <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.3.m3.1"><semantics id="S2.SS1.SSS0.Px3.p1.3.m3.1a"><mi id="S2.SS1.SSS0.Px3.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.3.m3.1b"><ci id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px3.p1.3.m3.1d">italic_k</annotation></semantics></math> being used. For instance, in NQ dataset, if the retrieval unit is a passage, <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.4.m4.1"><semantics id="S2.SS1.SSS0.Px3.p1.4.m4.1a"><mi id="S2.SS1.SSS0.Px3.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px3.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.4.m4.1b"><ci id="S2.SS1.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px3.p1.4.m4.1d">italic_k</annotation></semantics></math> is approximately above 100; if it’s a document, <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.5.m5.1"><semantics id="S2.SS1.SSS0.Px3.p1.5.m5.1a"><mi id="S2.SS1.SSS0.Px3.p1.5.m5.1.1" xref="S2.SS1.SSS0.Px3.p1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.5.m5.1b"><ci id="S2.SS1.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px3.p1.5.m5.1d">italic_k</annotation></semantics></math> is around 10; and for grouped documents as retrieval units, we typically set <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.6.m6.1"><semantics id="S2.SS1.SSS0.Px3.p1.6.m6.1a"><mi id="S2.SS1.SSS0.Px3.p1.6.m6.1.1" xref="S2.SS1.SSS0.Px3.p1.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.6.m6.1b"><ci id="S2.SS1.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.SSS0.Px3.p1.6.m6.1d">italic_k</annotation></semantics></math> to 4 to 8.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Long Reader</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.3">The long reader operates straightforwardly. We feed the related instruction <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_i</annotation></semantics></math>, the question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">italic_q</annotation></semantics></math>, and the long retrieval result <math alttext="\mathcal{C}_{\mathcal{F}}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.1"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">𝒞</mi><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">ℱ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">𝒞</ci><ci id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">ℱ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">\mathcal{C}_{\mathcal{F}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.1d">caligraphic_C start_POSTSUBSCRIPT caligraphic_F end_POSTSUBSCRIPT</annotation></semantics></math> into an LLM, enabling it to reason over the long context and generate the final output.
It’s important that the LLM used in the long reader can handle long contexts and does not exhibit excessive position bias. We select Gemini-1.5-Pro <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib46" title="">2024</a>)</cite> and GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib40" title="">2024</a>)</cite> as our long reader given their strong ability to handle long context input. We utilize different approaches for short and long contexts. For short contexts, typically containing fewer than 1K tokens, we instruct the reader to directly generate the answer from the provided context retrieved from the corpus. For long contexts, typically longer than 4K tokens, we empirically find that using a similar prompt as for short contexts, where the model extracts the final answer directly from the long context, often leads to decreased performance. Instead, the most effective approach is to utilize the LLM as a chat model. Initially, it outputs a long answer, typically spanning a few words to a few sentences. Subsequently, we prompt it to generate a short answer by further extracting it from the long answer. The prompt is provided in the Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS1" title="A.1 Prompts Template for Long Context Reader ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we will first provide detailed descriptions of the four datasets we use, followed by a demonstration of the retriever’s performance. Next, we will present the final question-answering performance. Finally, we conduct detailed ablation studies to explain why operating on long retrieval units benefits performance.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Our proposed methods were tested on four question-answering datasets. The basic statistics are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T1" title="Table 1 ‣ 3.1 Dataset ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>. Additionally, we have provided some examples in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS4" title="A.4 Dataset Examples ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:422.8pt;height:113.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.7pt,-0.2pt) scale(1.0032917293458,1.0032917293458) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.2.1">Corpus source</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1.1.1.3.1">
<tr class="ltx_tr" id="S3.T1.1.1.1.1.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.1.1.3.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.3.1.1.1.1">Avg. Doc.</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.1.1.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.1.1.3.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.3.1.2.1.1">Length</span></td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.4.1"># of Documents</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.5.1"># of Text cases</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.6.1">Metric</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.2">Wikipedia</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.3">800</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.4">3M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.5">3,610</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2.6">EM</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3.3">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3.1">HotpotQA</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3.2">Wikipedia</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3.3">130</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3.4">5.2M</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3.5">7,405</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.3.3.6">EM</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4.4">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4.1">Qasper</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4.2">Science</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4.3">4.7K</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4.4">416</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4.5">371</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.1.4.4.6">F1</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.5.5.1">MultiFieldQA-en</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.5.5.2">Multi-field</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.5.5.3">6.9K</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.5.5.4">150</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.5.5.5">150</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T1.1.1.5.5.6">F1</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>An overview of the four datasets used in our experiments is provided. “Corpus source” refers to the origin of the retrieval corpus. We selected NQ and HotpotQA from Wikipedia, Qasper from scientific documents, and MultifieldQA-en from multi-field documents. The two Wikipedia-based datasets utilize a massive retrieval corpus containing millions of short documents. In contrast, the other two datasets employ a smaller corpus consisting of hundreds of long documents.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Natural Question</span> <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib32" title="">2019</a>)</cite> is designed for end-to-end question answering. The questions are mined from real Google search queries and the answers were spans in Wikipedia articles identified by annotators. This dataset contains 3,610 questions. For NQ, we use the Wikipedia dumps from December 20, 2018, which contain approximately 3 million documents and 22 million passages.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">HotpotQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib56" title="">2018</a>)</cite> consists of two-hop questions over diverse topics. We focus on the fullwiki setting in which two Wikipedia passages are required to answer the questions. Since the gold passages for the test set are not available, we follow prior work <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib55" title="">2020b</a>)</cite> and evaluate on the development set, which has 7,405 questions. There are two main question types in HotpotQA: (1) comparison questions usually require contrasting two entities and (2) bridge questions can be answered by following a connecting entity that links one document to another. For HotpotQA, we use the abstract paragraphs from the October 1, 2017 dump, which contain around 5 million documents.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Qasper</span> <cite class="ltx_cite ltx_citemacro_citep">(Dasigi et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib14" title="">2021</a>)</cite> is an information-seeking question answering dataset over academic research papers. Each question is written as a followup to the title and abstract of a particular paper, and the answer, if present, is identified in the rest of the paper. The original Qasper dataset is a single-document QA dataset. We refactor it into a RAG task, where the system first retrieves the necessary document and then answers the given question, following a design similar to LoCoV1 <cite class="ltx_cite ltx_citemacro_citep">(Saad-Falcon et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib47" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">MultifieldQA-en</span> <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib5" title="">2023</a>)</cite> is a question-answering dataset based on long documents from diverse sources, including legal documents, government reports, encyclopedias, and academic papers. The original MultifieldQA-en is a single-document QA dataset. We refactor the dataset into a RAG task, where the system first retrieves the necessary document and then answers the given question, following a design similar to LoCoV1 <cite class="ltx_cite ltx_citemacro_citep">(Saad-Falcon et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib47" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Retrieval Performance</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In this section, we present the retrieval performance on two extractive QA datasets, NQ and HotpotQA, to demonstrate that comparable retrieval performance can be achieved using only a few long retrieval units (such as 4 to 8). This approach contrasts with the use of hundreds of short retrieval units, which may lead to information loss and the introduction of hard negatives that can confuse the reader and prevent the full utilization of long-context LLMs. For the other two datasets, it’s not straightforward to compare retrieval performance at different granularities since they are not extractive QA tasks. Therefore, we will directly discuss the final QA results in the next section.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Metrics</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">Retrieval performance is measured using Answer Recall (AR) and Recall (R). For NQ, we use only answer recall, while for HotpotQA, we use both metrics. Answer Recall is the recall of the answer string in all the retrieved documents that we plan to use in the reader. For example, if the retrieval unit is at the “passage” level and the number of retrieval units is 100, answer recall measures whether the answer string is present in these 100 passages. For HotpotQA, we compute AR only for questions with span answers, specifically the “bridge” type questions, while ignoring yes/no and comparison questions, following previous work <cite class="ltx_cite ltx_citemacro_citep">(Khalifa et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib29" title="">2022</a>)</cite>. Recall used for HotpotQA measures whether the two gold documents are present in all the retrieved results. For example, if the retrieval unit is at the “document” level and the number of retrieval units is 10, recall measures whether both gold documents are present among the 10 retrieval.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Experiment Setup</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">We leverage open-sourced dense retrieval toolkit, Tevatron <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib18" title="">2022</a>)</cite>, for all our retrieval experiments. The base embedding model we used is bge-large-en-v1.5, a general-purpose embeddings model that isn’t specifically trained on our test data.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:422.8pt;height:179.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.6pt,9.2pt) scale(0.907271763197026,0.907271763197026) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T2.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1.1">Retrieval Unit</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T2.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.2.1">Corpus Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T2.1.1.1.1.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.3.1">Num of Retrieval Units</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T2.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.4.1">Average Num of Tokens</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1.5" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.5.1">Answer Recall (AR)</span></th>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.1.1.2.2.1">Corpus</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.1.1.2.2.2">Test Set</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.3.1.1" rowspan="3"><span class="ltx_text" id="S3.T2.1.1.3.1.1.1">Passage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.3.1.2" rowspan="3"><span class="ltx_text" id="S3.T2.1.1.3.1.2.1">22M</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.3.1.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.4">120</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.5">130</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.1.1.3.1.6">52.24</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.1.1.4.2.1">100</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.2">12K</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4.2.3">14K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.1.1.4.2.4">89.92</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.1.1.5.3.1">200</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.2">24K</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5.3.3">28K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.1.1.5.3.4">91.30</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.6.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.6.4.1" rowspan="3"><span class="ltx_text" id="S3.T2.1.1.6.4.1.1">Document</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.6.4.2" rowspan="3"><span class="ltx_text" id="S3.T2.1.1.6.4.2.1">3M</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.6.4.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.6.4.4">820</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.6.4.5">4K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.1.1.6.4.6">69.45</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.7.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.1.1.7.5.1">5</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.7.5.2">4K</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.7.5.3">18K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.1.1.7.5.4">85.37</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.8.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.1.1.8.6.1">10</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.8.6.2">8K</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.8.6.3">34K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.1.1.8.6.4">88.12</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.9.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T2.1.1.9.7.1" rowspan="3"><span class="ltx_text" id="S3.T2.1.1.9.7.1.1">Grouped Documents</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T2.1.1.9.7.2" rowspan="3"><span class="ltx_text" id="S3.T2.1.1.9.7.2.1">600K</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.1.9.7.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.9.7.4">4K</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.9.7.5">6K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T2.1.1.9.7.6">71.69</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.10.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.1.1.10.8.1">4</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.2">16K</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.10.8.3">25K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T2.1.1.10.8.4">86.30</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.11.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S3.T2.1.1.11.9.1">8</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.2">32K</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.3">50K</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T2.1.1.11.9.4">88.53</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The table illustrates the retrieval performance on NQ. Employing a long-context retriever (with an average number of tokens for each retrieval unit up to 6K) compresses the corpus size by up to 30 times (from 22M to 600K), enhancing top-1 answer recall by approximately 20 points (from 52.24 to 71.69). Furthermore, long-context retriever requires significantly fewer retrieval units (10x fewer) to achieve comparable results. Therefore, integrating long-context retrieval significantly alleviates the burden of retriever.</figcaption>
</figure>
<figure class="ltx_table" id="S3.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.1" style="width:422.8pt;height:107.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.7pt,9.1pt) scale(0.855557432634291,0.855557432634291) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.1.1">Retrieval Unit</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.2.1">Corpus Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.1.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.3.1">Num of Retrieval Units</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.4.1">Average Num of Tokens</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.1.5" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.1.1.5.1">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.1.1.1.1.5.1.1">
<span class="ltx_tr" id="S3.T3.1.1.1.1.5.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.1.1.1.1.5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.5.1.1.1.1.1">Recall</span></span></span>
<span class="ltx_tr" id="S3.T3.1.1.1.1.5.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.1.1.1.1.5.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.5.1.1.2.1.1">(R)</span></span></span>
</span></span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.1.6" rowspan="2"><span class="ltx_text" id="S3.T3.1.1.1.1.6.1">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.1.1.1.1.6.1.1">
<span class="ltx_tr" id="S3.T3.1.1.1.1.6.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.1.1.1.1.6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.6.1.1.1.1.1">Answer Recall</span></span></span>
<span class="ltx_tr" id="S3.T3.1.1.1.1.6.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.1.1.1.1.6.1.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.6.1.1.2.1.1">(AR)</span></span></span>
</span></span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T3.1.1.2.2.1">Corpus</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T3.1.1.2.2.2">Test Set</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.1.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.1" rowspan="3"><span class="ltx_text" id="S3.T3.1.1.3.1.1.1">Document</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.2" rowspan="3"><span class="ltx_text" id="S3.T3.1.1.3.1.2.1">5.2M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.3">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.4">130</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.5">200</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.3.1.6">30.01</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.7">47.75</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.4.2">
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.1">100</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.2">6.5K</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.3">10K</td>
<td class="ltx_td ltx_align_left" id="S3.T3.1.1.4.2.4">74.84</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.1.1.4.2.5">84.67</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.5.3">
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.5.3.1">200</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.5.3.2">13K</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.5.3.3">20K</td>
<td class="ltx_td ltx_align_left" id="S3.T3.1.1.5.3.4">79.68</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.1.1.5.3.5">88.34</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.6.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T3.1.1.6.4.1" rowspan="3"><span class="ltx_text" id="S3.T3.1.1.6.4.1.1">Grouped Documents</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T3.1.1.6.4.2" rowspan="3"><span class="ltx_text" id="S3.T3.1.1.6.4.2.1">500K</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.6.4.3">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.6.4.4">1K</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.6.4.5">8K</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.1.6.4.6">56.30</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.1.1.6.4.7">72.49</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.7.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.7.5.1">8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.7.5.2">4K</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.7.5.3">29K</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.1.1.7.5.4">74.71</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T3.1.1.7.5.5">84.40</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The table illustrates the retrieval performance on HotpotQA. Similar to the findings on NQ, a long-context retrieval could significantly alleviate the burden on the retriever component.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T2" title="Table 2 ‣ Experiment Setup ‣ 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T3" title="Table 3 ‣ Experiment Setup ‣ 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">3</span></a> have shown the retrieval results on NQ and HotpotQA. In the NQ dataset, we utilize three different retrieval units, ranging from shorter to longer: passage, document, and grouped documents. In the table, we have mentioned two kinds of average number of tokens in each retrieval unit: one for the entire corpus and one for each test set. The retrieval units for each test case can sometimes be much longer than the average size across the whole corpus, as the corpus might include some Wikipedia pages with very few words, while the test cases may focus more on longer documents. Generally, our long-context retriever (at the document level and grouped document level) uses retrieval units containing an average of 6K tokens. By using longer retrieval units, there are several advantages: 1) It will significantly alleviate the burden on the retriever by compressing the corpus size by approximately 30 times, from 22M to 600K. The top-1 answer recall improves by about 20 points, from 52.24 to 71.69. We could use significantly fewer retrieval units to achieve comparable retrieval performance. For instance, 8 retrieval units at the grouped document level can achieve similar recall as 100 retrieval units at the passage level. 2) It could provide more comprehensive information to the reader. In the original passage-level RAG setup, information might be incomplete due to the chunking operation. In the HotpotQA dataset, we observe similar results. One notable difference is that in HotpotQA, the retrieval units are only at the document level and grouped document level, as HotpotQA uses only abstract paragraphs from each Wikipedia page.</p>
</div>
<figure class="ltx_table" id="S3.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.1"><span class="ltx_text" id="S3.T4.1.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.2"><span class="ltx_text" id="S3.T4.1.1.1.2.1" style="font-size:90%;">Granularity</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.3"><span class="ltx_text" id="S3.T4.1.1.1.3.1" style="font-size:90%;">AR@1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T4.1.2.1.1"><span class="ltx_text" id="S3.T4.1.2.1.1.1" style="font-size:90%;">BGE-Large</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T4.1.2.1.2"><span class="ltx_text" id="S3.T4.1.2.1.2.1" style="font-size:90%;">512-tokens chunk</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T4.1.2.1.3"><span class="ltx_text" id="S3.T4.1.2.1.3.1" style="font-size:90%;">71.7%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.3.2">
<td class="ltx_td ltx_align_left" id="S3.T4.1.3.2.1"><span class="ltx_text" id="S3.T4.1.3.2.1.1" style="font-size:90%;">E5-Mistral-7B</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.1.3.2.2"><span class="ltx_text" id="S3.T4.1.3.2.2.1" style="font-size:90%;">4000-tokens chunk</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.1.3.2.3"><span class="ltx_text" id="S3.T4.1.3.2.3.1" style="font-size:90%;">54.2%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.1.4.3.1"><span class="ltx_text" id="S3.T4.1.4.3.1.1" style="font-size:90%;">E5-Mistral-7B</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.1.4.3.2"><span class="ltx_text" id="S3.T4.1.4.3.2.1" style="font-size:90%;">entire grouped retrieval unit</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.1.4.3.3"><span class="ltx_text" id="S3.T4.1.4.3.3.1" style="font-size:90%;">23.4%</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Different methods to encode the long retrieval unit in the long retriever. Using a general embedding model and approximating by maximizing the similarity scores between the query and all chunks within the retrieval unit is better than using the existing long embedding model to encode the entire context.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Encode the long retrieval unit</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px3.p1.9">As discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S2.SS2" title="2.2 Long Reader ‣ 2 LongRAG ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">2.2</span></a>, it’s very challenging to employ an encoder, <math alttext="E_{C}(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px3.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px3.p1.1.m1.1.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.cmml"><msub id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.cmml"><mi id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.2.cmml">E</mi><mi id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.3" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.3.cmml">C</mi></msub><mo id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.1" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.3.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.cmml"><mo id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.cmml">(</mo><mo id="S3.SS2.SSS0.Px3.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">⋅</mo><mo id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2"><times id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.1"></times><apply id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.2">𝐸</ci><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.3.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.2.2.3">𝐶</ci></apply><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.1.m1.1c">E_{C}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math>, to map the retrieval unit <math alttext="g" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.2.m2.1"><semantics id="S3.SS2.SSS0.Px3.p1.2.m2.1a"><mi id="S3.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px3.p1.2.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.2.m2.1b"><ci id="S3.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.2.m2.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.2.m2.1c">g</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.2.m2.1d">italic_g</annotation></semantics></math> to a <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.3.m3.1"><semantics id="S3.SS2.SSS0.Px3.p1.3.m3.1a"><mi id="S3.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px3.p1.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.3.m3.1b"><ci id="S3.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.3.m3.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.3.m3.1d">italic_d</annotation></semantics></math>-dimensional vector when <math alttext="g" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.4.m4.1"><semantics id="S3.SS2.SSS0.Px3.p1.4.m4.1a"><mi id="S3.SS2.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px3.p1.4.m4.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.4.m4.1b"><ci id="S3.SS2.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.4.m4.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.4.m4.1c">g</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.4.m4.1d">italic_g</annotation></semantics></math> is very long. Therefore, we use an approximation in our proposed system. Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T4" title="Table 4 ‣ Experiment Setup ‣ 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates that our approximation, <math alttext="sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\approx\max_{g^{\prime}\subseteq g}(E_{Q}(q)^{T}E%
_{C}(g^{\prime}))" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.5.m5.7"><semantics id="S3.SS2.SSS0.Px3.p1.5.m5.7a"><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.cmml"><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.2.cmml">s</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1.cmml">⁢</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.3.cmml">i</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1a" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1.cmml">⁢</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.4" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.4.cmml">m</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1b" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1.cmml">⁢</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.1.cmml"><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.2.1" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.1.cmml">(</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.1.1.cmml">q</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.1.cmml">,</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.2.2.cmml">g</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.2.3" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.5" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.5.cmml">=</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.cmml"><msub id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.2.cmml">E</mi><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.3.cmml">Q</mi></msub><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1.cmml">⁢</mo><msup id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.cmml"><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.cmml"><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.2.2.1" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.cmml">(</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.3.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.3.3.cmml">q</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.2.2.2" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.cmml">)</mo></mrow><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.3.cmml">T</mi></msup><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1a" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1.cmml">⁢</mo><msub id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.2.cmml">E</mi><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.3.cmml">C</mi></msub><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1b" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1.cmml">⁢</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.5.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.cmml"><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.5.2.1" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.cmml">(</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.4.4" xref="S3.SS2.SSS0.Px3.p1.5.m5.4.4.cmml">g</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.5.2.2" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.7" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.7.cmml">≈</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.3.cmml"><msub id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.2.cmml">max</mi><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.cmml"><msup id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.2.cmml">g</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.3.cmml">′</mo></msup><mo id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.1.cmml">⊆</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.3.cmml">g</mi></mrow></msub><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2a" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.3.cmml">⁡</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.3.cmml"><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.2" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.3.cmml">(</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.cmml"><msub id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.2.cmml">E</mi><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.3.cmml">Q</mi></msub><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2.cmml">⁢</mo><msup id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.cmml"><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.2.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.cmml"><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.2.2.1" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.cmml">(</mo><mi id="S3.SS2.SSS0.Px3.p1.5.m5.5.5" xref="S3.SS2.SSS0.Px3.p1.5.m5.5.5.cmml">q</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.2.2.2" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.cmml">)</mo></mrow><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.3.cmml">T</mi></msup><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2a" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2.cmml">⁢</mo><msub id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.2.cmml">E</mi><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.3.cmml">C</mi></msub><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2b" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.cmml"><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.2" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.cmml">(</mo><msup id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.2" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.2.cmml">g</mi><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.3" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.3.cmml">′</mo></msup><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.3" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.3" stretchy="false" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.5.m5.7b"><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7"><and id="S3.SS2.SSS0.Px3.p1.5.m5.7.7a.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7"></and><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7b.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7"><eq id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.5.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.5"></eq><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4"><times id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.1"></times><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.2">𝑠</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.3">𝑖</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.4.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.4">𝑚</ci><interval closure="open" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.4.5.2"><ci id="S3.SS2.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.1.1">𝑞</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.2.2">𝑔</ci></interval></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6"><times id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.1"></times><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.2">𝐸</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.2.3">𝑄</ci></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.3.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.3.3">𝑞</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.3.3">𝑇</ci></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.2">𝐸</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.4.3">𝐶</ci></apply><ci id="S3.SS2.SSS0.Px3.p1.5.m5.4.4.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.4.4">𝑔</ci></apply></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7c.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7"><approx id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.7.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.7"></approx><share href="https://arxiv.org/html/2406.15319v3#S3.SS2.SSS0.Px3.p1.5.m5.7.7.6.cmml" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7d.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7"></share><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2"><apply id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1">subscript</csymbol><max id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.2"></max><apply id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3"><subset id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.1"></subset><apply id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.2">𝑔</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.2.3">′</ci></apply><ci id="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.6.6.1.1.1.3.3">𝑔</ci></apply></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1"><times id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.2"></times><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.2">𝐸</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.3.3">𝑄</ci></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.5.5.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.5.5">𝑞</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.4.3">𝑇</ci></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.2">𝐸</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.5.3">𝐶</ci></apply><apply id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.2">𝑔</ci><ci id="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.7.7.2.2.2.1.1.1.1.3">′</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.5.m5.7c">sim(q,g)=E_{Q}(q)^{T}E_{C}(g)\approx\max_{g^{\prime}\subseteq g}(E_{Q}(q)^{T}E%
_{C}(g^{\prime}))</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.5.m5.7d">italic_s italic_i italic_m ( italic_q , italic_g ) = italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g ) ≈ roman_max start_POSTSUBSCRIPT italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ⊆ italic_g end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) )</annotation></semantics></math>, is much more effective than encoding the entire long context directly.
We compare three methods: 1) Using the general embedding model “bge-large-en-v1.5” <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib53" title="">2023</a>)</cite>, with <math alttext="g^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.6.m6.1"><semantics id="S3.SS2.SSS0.Px3.p1.6.m6.1a"><msup id="S3.SS2.SSS0.Px3.p1.6.m6.1.1" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.6.m6.1.1.2" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1.2.cmml">g</mi><mo id="S3.SS2.SSS0.Px3.p1.6.m6.1.1.3" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.6.m6.1b"><apply id="S3.SS2.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.6.m6.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.6.m6.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1.2">𝑔</ci><ci id="S3.SS2.SSS0.Px3.p1.6.m6.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.6.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.6.m6.1c">g^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.6.m6.1d">italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> selected as text of 512-token size. 2) Using long embedding model “E5-Mistral-7B” <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib61" title="">2024a</a>)</cite>, with <math alttext="g^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.7.m7.1"><semantics id="S3.SS2.SSS0.Px3.p1.7.m7.1a"><msup id="S3.SS2.SSS0.Px3.p1.7.m7.1.1" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.7.m7.1.1.2" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1.2.cmml">g</mi><mo id="S3.SS2.SSS0.Px3.p1.7.m7.1.1.3" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.7.m7.1b"><apply id="S3.SS2.SSS0.Px3.p1.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.7.m7.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.7.m7.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1.2">𝑔</ci><ci id="S3.SS2.SSS0.Px3.p1.7.m7.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.7.m7.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.7.m7.1c">g^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.7.m7.1d">italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> selected as the whole document, which has an average size of 4K tokens. 3) Using long embeddings model “E5-Mistral-7B”, with no approximation, we encode the entire <math alttext="g" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.8.m8.1"><semantics id="S3.SS2.SSS0.Px3.p1.8.m8.1a"><mi id="S3.SS2.SSS0.Px3.p1.8.m8.1.1" xref="S3.SS2.SSS0.Px3.p1.8.m8.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.8.m8.1b"><ci id="S3.SS2.SSS0.Px3.p1.8.m8.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.8.m8.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.8.m8.1c">g</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.8.m8.1d">italic_g</annotation></semantics></math>, which is composed of multiple documents, directly. The average size of <math alttext="g" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.9.m9.1"><semantics id="S3.SS2.SSS0.Px3.p1.9.m9.1a"><mi id="S3.SS2.SSS0.Px3.p1.9.m9.1.1" xref="S3.SS2.SSS0.Px3.p1.9.m9.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.9.m9.1b"><ci id="S3.SS2.SSS0.Px3.p1.9.m9.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.9.m9.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.9.m9.1c">g</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p1.9.m9.1d">italic_g</annotation></semantics></math> is 6K tokens. We can notice from the table that our approximation by taking the maximum score between the query and each text piece from the long context produces much better results than encoding them directly using the long embedding model. We believe that future advancements in long embedding models, which focus on encoding long contexts or multiple documents, will further enhance our framework and reduce memory consumption.</p>
</div>
<figure class="ltx_table" id="S3.T5">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T5.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T5.1.2.1.1"><span class="ltx_text" id="S3.T5.1.2.1.1.1" style="font-size:90%;">NQ</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T5.1.2.1.2"><span class="ltx_text" id="S3.T5.1.2.1.2.1" style="font-size:90%;">EM</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="2" id="S3.T5.1.3.2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T5.1.3.2.1.1" style="font-size:90%;">Closed-Book</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.4.1.1">
<span class="ltx_text" id="S3.T5.1.4.1.1.1" style="font-size:90%;">GPT-4-Turbo </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.4.1.1.2.1" style="font-size:90%;">(</span>Achiam et al.<span class="ltx_text" id="S3.T5.1.4.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib1" title="">2023</a><span class="ltx_text" id="S3.T5.1.4.1.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.4.1.2"><span class="ltx_text" id="S3.T5.1.4.1.2.1" style="font-size:90%;">41.2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.5.2.1">
<span class="ltx_text" id="S3.T5.1.5.2.1.1" style="font-size:90%;">Gemini-1.5-Pro </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.5.2.1.2.1" style="font-size:90%;">(</span>Reid et al.<span class="ltx_text" id="S3.T5.1.5.2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib46" title="">2024</a><span class="ltx_text" id="S3.T5.1.5.2.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.5.2.2"><span class="ltx_text" id="S3.T5.1.5.2.2.1" style="font-size:90%;">47.8</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.6.3.1">
<span class="ltx_text" id="S3.T5.1.6.3.1.1" style="font-size:90%;">Claude-3-Opus </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.6.3.1.2.1" style="font-size:90%;">(</span>Anthropic<span class="ltx_text" id="S3.T5.1.6.3.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib3" title="">2024</a><span class="ltx_text" id="S3.T5.1.6.3.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.6.3.2"><span class="ltx_text" id="S3.T5.1.6.3.2.1" style="font-size:90%;">49.2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="2" id="S3.T5.1.7.4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T5.1.7.4.1.1" style="font-size:90%;">Fully-supervised RAG</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.1.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.8.5.1">
<span class="ltx_text" id="S3.T5.1.8.5.1.1" style="font-size:90%;">REALM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.8.5.1.2.1" style="font-size:90%;">(</span>Guu et al.<span class="ltx_text" id="S3.T5.1.8.5.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib20" title="">2020</a><span class="ltx_text" id="S3.T5.1.8.5.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.8.5.2"><span class="ltx_text" id="S3.T5.1.8.5.2.1" style="font-size:90%;">40.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.9.6.1">
<span class="ltx_text" id="S3.T5.1.9.6.1.1" style="font-size:90%;">DPR </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.9.6.1.2.1" style="font-size:90%;">(</span>Karpukhin et al.<span class="ltx_text" id="S3.T5.1.9.6.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib28" title="">2020</a><span class="ltx_text" id="S3.T5.1.9.6.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.9.6.2"><span class="ltx_text" id="S3.T5.1.9.6.2.1" style="font-size:90%;">41.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.10.7.1">
<span class="ltx_text" id="S3.T5.1.10.7.1.1" style="font-size:90%;">RAG </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.10.7.1.2.1" style="font-size:90%;">(</span>Lewis et al.<span class="ltx_text" id="S3.T5.1.10.7.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib33" title="">2020</a><span class="ltx_text" id="S3.T5.1.10.7.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.10.7.2"><span class="ltx_text" id="S3.T5.1.10.7.2.1" style="font-size:90%;">44.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.11.8.1">
<span class="ltx_text" id="S3.T5.1.11.8.1.1" style="font-size:90%;">RETRO </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.11.8.1.2.1" style="font-size:90%;">(</span>Borgeaud et al.<span class="ltx_text" id="S3.T5.1.11.8.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib6" title="">2022</a><span class="ltx_text" id="S3.T5.1.11.8.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.11.8.2"><span class="ltx_text" id="S3.T5.1.11.8.2.1" style="font-size:90%;">45.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.12.9.1">
<span class="ltx_text" id="S3.T5.1.12.9.1.1" style="font-size:90%;">RePAQ </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.12.9.1.2.1" style="font-size:90%;">(</span>Lewis et al.<span class="ltx_text" id="S3.T5.1.12.9.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib34" title="">2021</a><span class="ltx_text" id="S3.T5.1.12.9.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.12.9.2"><span class="ltx_text" id="S3.T5.1.12.9.2.1" style="font-size:90%;">47.8</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.13.10.1">
<span class="ltx_text" id="S3.T5.1.13.10.1.1" style="font-size:90%;">FID </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.13.10.1.2.1" style="font-size:90%;">(</span>Izacard &amp; Grave<span class="ltx_text" id="S3.T5.1.13.10.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib23" title="">2020b</a><span class="ltx_text" id="S3.T5.1.13.10.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.13.10.2"><span class="ltx_text" id="S3.T5.1.13.10.2.1" style="font-size:90%;">51.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.1.1">
<span class="ltx_text" id="S3.T5.1.1.1.1" style="font-size:90%;">EMDR</span><sup class="ltx_sup" id="S3.T5.1.1.1.2"><span class="ltx_text" id="S3.T5.1.1.1.2.1" style="font-size:90%;">2</span></sup><span class="ltx_text" id="S3.T5.1.1.1.3" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.1.1.4.1" style="font-size:90%;">(</span>Singh et al.<span class="ltx_text" id="S3.T5.1.1.1.5.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib49" title="">2021</a><span class="ltx_text" id="S3.T5.1.1.1.6.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.1.2"><span class="ltx_text" id="S3.T5.1.1.2.1" style="font-size:90%;">52.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.14.11.1">
<span class="ltx_text" id="S3.T5.1.14.11.1.1" style="font-size:90%;">FID-KD </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.14.11.1.2.1" style="font-size:90%;">(</span>Izacard &amp; Grave<span class="ltx_text" id="S3.T5.1.14.11.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib24" title="">2021</a><span class="ltx_text" id="S3.T5.1.14.11.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.14.11.2"><span class="ltx_text" id="S3.T5.1.14.11.2.1" style="font-size:90%;">54.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.15.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.15.12.1">
<span class="ltx_text" id="S3.T5.1.15.12.1.1" style="font-size:90%;">R2-D2 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.15.12.1.2.1" style="font-size:90%;">(</span>Fajcik et al.<span class="ltx_text" id="S3.T5.1.15.12.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib16" title="">2021</a><span class="ltx_text" id="S3.T5.1.15.12.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.15.12.2"><span class="ltx_text" id="S3.T5.1.15.12.2.1" style="font-size:90%;">55.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.16.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.16.13.1">
<span class="ltx_text" id="S3.T5.1.16.13.1.1" style="font-size:90%;">Atlas </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.16.13.1.2.1" style="font-size:90%;">(</span>Izacard et al.<span class="ltx_text" id="S3.T5.1.16.13.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib25" title="">2022</a><span class="ltx_text" id="S3.T5.1.16.13.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.16.13.2"><span class="ltx_text" id="S3.T5.1.16.13.2.1" style="font-size:90%;">64.0</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.17.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="2" id="S3.T5.1.17.14.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T5.1.17.14.1.1" style="font-size:90%;">No Fine-tuning RAG</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.1.18.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.18.15.1">
<span class="ltx_text" id="S3.T5.1.18.15.1.1" style="font-size:90%;">REPLUG </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.18.15.1.2.1" style="font-size:90%;">(</span>Shi et al.<span class="ltx_text" id="S3.T5.1.18.15.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib48" title="">2023</a><span class="ltx_text" id="S3.T5.1.18.15.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.18.15.2"><span class="ltx_text" id="S3.T5.1.18.15.2.1" style="font-size:90%;">44.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.19.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.19.16.1">
<span class="ltx_text" id="S3.T5.1.19.16.1.1" style="font-size:90%;">REPLUG + LSR </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.1.19.16.1.2.1" style="font-size:90%;">(</span>Shi et al.<span class="ltx_text" id="S3.T5.1.19.16.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib48" title="">2023</a><span class="ltx_text" id="S3.T5.1.19.16.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.19.16.2"><span class="ltx_text" id="S3.T5.1.19.16.2.1" style="font-size:90%;">45.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.20.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.1.20.17.1"><span class="ltx_text" id="S3.T5.1.20.17.1.1" style="font-size:90%;">LongRAG (Gemini-1.5-Pro; Recall 4 units)</span></th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.1.20.17.2"><span class="ltx_text" id="S3.T5.1.20.17.2.1" style="font-size:90%;">58.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.21.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T5.1.21.18.1"><span class="ltx_text" id="S3.T5.1.21.18.1.1" style="font-size:90%;">LongRAG (GPT-4o; Recall 4 units)</span></th>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T5.1.21.18.2"><span class="ltx_text ltx_font_bold" id="S3.T5.1.21.18.2.1" style="font-size:90%;">62.7</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="S3.T5.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T5.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T5.2.1.1.1"><span class="ltx_text" id="S3.T5.2.1.1.1.1" style="font-size:90%;">HotpotQA</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T5.2.1.1.2"><span class="ltx_text" id="S3.T5.2.1.1.2.1" style="font-size:90%;">EM</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="2" id="S3.T5.2.2.2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T5.2.2.2.1.1" style="font-size:90%;">Closed-Book</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.3.1.1">
<span class="ltx_text" id="S3.T5.2.3.1.1.1" style="font-size:90%;">Claude-3-Opus </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.3.1.1.2.1" style="font-size:90%;">(</span>Anthropic<span class="ltx_text" id="S3.T5.2.3.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib3" title="">2024</a><span class="ltx_text" id="S3.T5.2.3.1.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.3.1.2"><span class="ltx_text" id="S3.T5.2.3.1.2.1" style="font-size:90%;">32.8</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.4.2.1">
<span class="ltx_text" id="S3.T5.2.4.2.1.1" style="font-size:90%;">Gemini-1.5-Pro </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.4.2.1.2.1" style="font-size:90%;">(</span>Reid et al.<span class="ltx_text" id="S3.T5.2.4.2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib46" title="">2024</a><span class="ltx_text" id="S3.T5.2.4.2.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.4.2.2"><span class="ltx_text" id="S3.T5.2.4.2.2.1" style="font-size:90%;">33.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.5.3.1">
<span class="ltx_text" id="S3.T5.2.5.3.1.1" style="font-size:90%;">GPT-4-Turbo </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.5.3.1.2.1" style="font-size:90%;">(</span>Achiam et al.<span class="ltx_text" id="S3.T5.2.5.3.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib1" title="">2023</a><span class="ltx_text" id="S3.T5.2.5.3.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.5.3.2"><span class="ltx_text" id="S3.T5.2.5.3.2.1" style="font-size:90%;">42.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="2" id="S3.T5.2.6.4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T5.2.6.4.1.1" style="font-size:90%;">Fully-supervised RAG</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.7.5.1">
<span class="ltx_text" id="S3.T5.2.7.5.1.1" style="font-size:90%;">DrKIT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.7.5.1.2.1" style="font-size:90%;">(</span>Dhingra et al.<span class="ltx_text" id="S3.T5.2.7.5.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib15" title="">2020</a><span class="ltx_text" id="S3.T5.2.7.5.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.7.5.2"><span class="ltx_text" id="S3.T5.2.7.5.2.1" style="font-size:90%;">42.1</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.8.6.1">
<span class="ltx_text" id="S3.T5.2.8.6.1.1" style="font-size:90%;">Transformer-XH </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.8.6.1.2.1" style="font-size:90%;">(</span>Zhao et al.<span class="ltx_text" id="S3.T5.2.8.6.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib60" title="">2019</a><span class="ltx_text" id="S3.T5.2.8.6.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.8.6.2"><span class="ltx_text" id="S3.T5.2.8.6.2.1" style="font-size:90%;">51.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.9.7.1">
<span class="ltx_text" id="S3.T5.2.9.7.1.1" style="font-size:90%;">QAMAT+ </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.9.7.1.2.1" style="font-size:90%;">(</span>Chen et al.<span class="ltx_text" id="S3.T5.2.9.7.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib10" title="">2023b</a><span class="ltx_text" id="S3.T5.2.9.7.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.9.7.2"><span class="ltx_text" id="S3.T5.2.9.7.2.1" style="font-size:90%;">57.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.10.8.1">
<span class="ltx_text" id="S3.T5.2.10.8.1.1" style="font-size:90%;">HGN </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.10.8.1.2.1" style="font-size:90%;">(</span>Fang et al.<span class="ltx_text" id="S3.T5.2.10.8.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib17" title="">2019</a><span class="ltx_text" id="S3.T5.2.10.8.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.10.8.2"><span class="ltx_text" id="S3.T5.2.10.8.2.1" style="font-size:90%;">59.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.11.9.1">
<span class="ltx_text" id="S3.T5.2.11.9.1.1" style="font-size:90%;">PathRetriever </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.11.9.1.2.1" style="font-size:90%;">(</span>Asai et al.<span class="ltx_text" id="S3.T5.2.11.9.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib4" title="">2019</a><span class="ltx_text" id="S3.T5.2.11.9.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.11.9.2"><span class="ltx_text" id="S3.T5.2.11.9.2.1" style="font-size:90%;">60.0</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.12.10.1">
<span class="ltx_text" id="S3.T5.2.12.10.1.1" style="font-size:90%;">HopRetrieve </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.12.10.1.2.1" style="font-size:90%;">(</span>Li et al.<span class="ltx_text" id="S3.T5.2.12.10.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib35" title="">2021</a><span class="ltx_text" id="S3.T5.2.12.10.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.12.10.2"><span class="ltx_text" id="S3.T5.2.12.10.2.1" style="font-size:90%;">62.1</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.13.11.1">
<span class="ltx_text" id="S3.T5.2.13.11.1.1" style="font-size:90%;">MDR </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.13.11.1.2.1" style="font-size:90%;">(</span>Xiong et al.<span class="ltx_text" id="S3.T5.2.13.11.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib55" title="">2020b</a><span class="ltx_text" id="S3.T5.2.13.11.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.13.11.2"><span class="ltx_text" id="S3.T5.2.13.11.2.1" style="font-size:90%;">62.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.14.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.14.12.1">
<span class="ltx_text" id="S3.T5.2.14.12.1.1" style="font-size:90%;">HopRetrieve-plus </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.14.12.1.2.1" style="font-size:90%;">(</span>Li et al.<span class="ltx_text" id="S3.T5.2.14.12.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib35" title="">2021</a><span class="ltx_text" id="S3.T5.2.14.12.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.14.12.2"><span class="ltx_text" id="S3.T5.2.14.12.2.1" style="font-size:90%;">66.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.15.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.15.13.1">
<span class="ltx_text" id="S3.T5.2.15.13.1.1" style="font-size:90%;">AISO </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.15.13.1.2.1" style="font-size:90%;">(</span>Zhu et al.<span class="ltx_text" id="S3.T5.2.15.13.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib63" title="">2021</a><span class="ltx_text" id="S3.T5.2.15.13.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.15.13.2"><span class="ltx_text" id="S3.T5.2.15.13.2.1" style="font-size:90%;">68.1</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.16.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.16.14.1">
<span class="ltx_text" id="S3.T5.2.16.14.1.1" style="font-size:90%;">COS </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.16.14.1.2.1" style="font-size:90%;">(</span>Ma et al.<span class="ltx_text" id="S3.T5.2.16.14.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib37" title="">2023</a><span class="ltx_text" id="S3.T5.2.16.14.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.16.14.2"><span class="ltx_text" id="S3.T5.2.16.14.2.1" style="font-size:90%;">68.2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.17.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="2" id="S3.T5.2.17.15.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T5.2.17.15.1.1" style="font-size:90%;">No Fine-tuning RAG</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.2.18.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.18.16.1">
<span class="ltx_text" id="S3.T5.2.18.16.1.1" style="font-size:90%;">DSP </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.18.16.1.2.1" style="font-size:90%;">(</span>Khattab et al.<span class="ltx_text" id="S3.T5.2.18.16.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib31" title="">2022</a><span class="ltx_text" id="S3.T5.2.18.16.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.18.16.2"><span class="ltx_text" id="S3.T5.2.18.16.2.1" style="font-size:90%;">51.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.19.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.19.17.1">
<span class="ltx_text" id="S3.T5.2.19.17.1.1" style="font-size:90%;">PromptRank </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T5.2.19.17.1.2.1" style="font-size:90%;">(</span>Khalifa et al.<span class="ltx_text" id="S3.T5.2.19.17.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib30" title="">2023</a><span class="ltx_text" id="S3.T5.2.19.17.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.19.17.2"><span class="ltx_text" id="S3.T5.2.19.17.2.1" style="font-size:90%;">55.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.20.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.2.20.18.1"><span class="ltx_text" id="S3.T5.2.20.18.1.1" style="font-size:90%;">LongRAG (Gemini-1.5-Pro; Recall 8 units)</span></th>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T5.2.20.18.2"><span class="ltx_text" id="S3.T5.2.20.18.2.1" style="font-size:90%;">57.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.2.21.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T5.2.21.19.1"><span class="ltx_text" id="S3.T5.2.21.19.1.1" style="font-size:90%;">LongRAG (GPT-4o; Recall 8 units)</span></th>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T5.2.21.19.2"><span class="ltx_text ltx_font_bold" id="S3.T5.2.21.19.2.1" style="font-size:90%;">64.3</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>The tables show the QA results on the NQ test dataset (left) and Hotpot-QA dev set (right). We compare the results with three groups of baselines: closed-book, which involves directly prompting state-of-the-art LLMs with 16-shot in-context examples; fully-supervised RAG, where the RAG framework is used and the model is fully supervised and trained on the training data; and No Fine-tuning RAG, which employs the RAG framework without any tuning.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Full QA Performance on Wikipedia-based Datasets</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We leverage Gemini-1.5-Pro and GPT-4o as the reader in our LongRAG framework.
The prompt we use for our experiments are in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.T7" title="Table 7 ‣ A.1 Prompts Template for Long Context Reader ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">7</span></a>. For Wiki-based datasets, such as NQ and HotpotQA, which generate short answers typically less than 5 tokens, we use EM (Exact Match rate) as the evaluation metric. We also refine the standard exact match rate definition to more fairly evaluate LongRAG’s performance. More details can be found in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS2" title="A.2 Refined Metric ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">For NQ and HotpotQA, we compare our model with several groups of strong previous models as baselines. The first group is “<span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Closed-Book</span>”: These baselines mean that no retrieval component is used; instead, state-of-the-art LLMs are employed to directly obtain the final result. We evaluate our results on Gemini-1.5-pro <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib46" title="">2024</a>)</cite>, Claude-3-Opus <cite class="ltx_cite ltx_citemacro_citep">(Anthropic, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib3" title="">2024</a>)</cite> and GPT-4-Turbo <cite class="ltx_cite ltx_citemacro_citep">(Achiam et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib1" title="">2023</a>)</cite>. All models are evaluated on 16-shot in-context learning with direct prompting; The second group is “<span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.2">Fully-supervised RAG</span>”, and these baselines involve full-supervised fine-tuning on the training dataset. The third group is “<span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.3">No Fine-tuning RAG</span>”, and these baselines doesn’t involve any supervised fine-tuning. The QA results on NQ and HotpotQA are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T5" title="Table 5 ‣ Encode the long retrieval unit ‣ 3.2 Retrieval Performance ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">5</span></a>. On the NQ dataset, LongRAG achieves a 62.7 exact match rate, which is on par of the strongest fine-tuned RAG model like Atlas. On the HotpotQA dataset, LongRAG achieves a 64.3 exact match rate, which is also close to the SoTA fully-supervised RAG frameworks.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Full QA Performance on non-Wikipedia-based Datasets</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">For datasets that generate long answers, such as Qasper and MultifieldQA-en, we use the token-level F1 score (F1) as the evaluation metric. For Qasper and MultifieldQA-en, since we repurpose the datasets from single-document QA to a RAG task, we do not directly compare the results with previous models. Instead, we compare the performance of traditional RAG, which operates on 200-token passages, with our LongRAG, which operates on entire documents ranging from 4K to 6K tokens. The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.T6" title="Table 6 ‣ 3.4 Full QA Performance on non-Wikipedia-based Datasets ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">6</span></a>. We observe that using long retrieval units at the whole document level performs better than using hundreds of short chunked retrieval units. On the Qasper dataset, gathering 100 short retrieval units of 200 tokens each into the reader achieves a 22.6% F1 score, while using a single long retrieval unit of 5K tokens achieves a 26.3% F1 score. Similarly, on the MultifieldQA-en dataset, gathering 100 short retrieval units of 200 tokens each into the reader results in a 51.3% F1 score, whereas using five long retrieval units of 7K tokens each results in a 57.5% F1 score.</p>
</div>
<figure class="ltx_table" id="S3.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T6.1" style="width:281.9pt;height:161.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.3pt,0.2pt) scale(0.997983362824342,0.997983362824342) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T6.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.1.1" style="font-size:90%;">Retrieval Unit</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T6.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.2.1" style="font-size:90%;">Num of Retrieval Units</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.3.1" style="font-size:90%;">Qasper</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T6.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.4.1" style="font-size:90%;">MutilfieldQA-en</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T6.1.1.2.1.1" rowspan="4"><span class="ltx_text" id="S3.T6.1.1.2.1.1.1" style="font-size:90%;">Passage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T6.1.1.2.1.2"><span class="ltx_text" id="S3.T6.1.1.2.1.2.1" style="font-size:90%;">1</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.2.1.3"><span class="ltx_text" id="S3.T6.1.1.2.1.3.1" style="font-size:90%;">15.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T6.1.1.2.1.4"><span class="ltx_text" id="S3.T6.1.1.2.1.4.1" style="font-size:90%;">38.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T6.1.1.3.2.1"><span class="ltx_text" id="S3.T6.1.1.3.2.1.1" style="font-size:90%;">10</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.3.2.2"><span class="ltx_text" id="S3.T6.1.1.3.2.2.1" style="font-size:90%;">20.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T6.1.1.3.2.3"><span class="ltx_text" id="S3.T6.1.1.3.2.3.1" style="font-size:90%;">47.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T6.1.1.4.3.1"><span class="ltx_text" id="S3.T6.1.1.4.3.1.1" style="font-size:90%;">100</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.4.3.2"><span class="ltx_text" id="S3.T6.1.1.4.3.2.1" style="font-size:90%;">22.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T6.1.1.4.3.3"><span class="ltx_text" id="S3.T6.1.1.4.3.3.1" style="font-size:90%;">51.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T6.1.1.5.4.1"><span class="ltx_text" id="S3.T6.1.1.5.4.1.1" style="font-size:90%;">200</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.5.4.2"><span class="ltx_text" id="S3.T6.1.1.5.4.2.1" style="font-size:90%;">21.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T6.1.1.5.4.3"><span class="ltx_text" id="S3.T6.1.1.5.4.3.1" style="font-size:90%;">50.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T6.1.1.6.5.1" rowspan="4"><span class="ltx_text" id="S3.T6.1.1.6.5.1.1" style="font-size:90%;">Document</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T6.1.1.6.5.2"><span class="ltx_text" id="S3.T6.1.1.6.5.2.1" style="font-size:90%;">1</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.6.5.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.6.5.3.1" style="font-size:90%;">26.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T6.1.1.6.5.4"><span class="ltx_text" id="S3.T6.1.1.6.5.4.1" style="font-size:90%;">49.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T6.1.1.7.6.1"><span class="ltx_text" id="S3.T6.1.1.7.6.1.1" style="font-size:90%;">2</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.7.6.2"><span class="ltx_text" id="S3.T6.1.1.7.6.2.1" style="font-size:90%;">25.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T6.1.1.7.6.3"><span class="ltx_text" id="S3.T6.1.1.7.6.3.1" style="font-size:90%;">50.2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T6.1.1.8.7.1"><span class="ltx_text" id="S3.T6.1.1.8.7.1.1" style="font-size:90%;">5</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.8.7.2"><span class="ltx_text" id="S3.T6.1.1.8.7.2.1" style="font-size:90%;">23.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T6.1.1.8.7.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.8.7.3.1" style="font-size:90%;">57.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S3.T6.1.1.9.8.1"><span class="ltx_text" id="S3.T6.1.1.9.8.1.1" style="font-size:90%;">10</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.1.9.8.2"><span class="ltx_text" id="S3.T6.1.1.9.8.2.1" style="font-size:90%;">21.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T6.1.1.9.8.3"><span class="ltx_text" id="S3.T6.1.1.9.8.3.1" style="font-size:90%;">56.8</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>This table presents the QA results on two non-Wiki datasets: Qasper and MultifieldQA-en. The results are evaluated based on token-level F1. Both datasets contain long documents, averaging at least 4K tokens. The results demonstrate that our LongRAG, which operates on long retrieval units, achieves better performance compared to traditional RAG, which operates on short retrieval units.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Ablation Studies</h3>
<div class="ltx_para ltx_noindent" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">We perform several in-depth ablation to understand what are the important factors in our LongRAG system including “unit size” and “reader variant”.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="S3.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>This figure compares different settings of LongRAG, using 200 test cases from the test set to evaluate various retrieval unit selections, demonstrating the effectiveness of our LongRAG design. The upper part of the figure shows the NQ dataset, while the lower part displays the HotpotQA dataset. On the left, it illustrates how the overall performance changes with different settings of retrieval unit size and the number of units fed into the reader; on the right, it shows that the end performance does not increase monotonically with the recall score, and LongRAG is more robust to the influence of “hard negatives” as the context length of the reader increases. </figcaption>
</figure>
<section class="ltx_paragraph" id="S3.SS5.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Retrieval Unit Selection</h4>
<div class="ltx_para ltx_noindent" id="S3.SS5.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS5.SSS0.Px1.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.F3" title="Figure 3 ‣ 3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">3</span></a> compare different retrieval unit settings of LongRAG, specifically focusing on the selection of retrieval unit granularity and the optimal number of retrieval units used in the reader. We have two observations: First, regardless of which retrieval unit is selected, there will be a turning point where feeding more retrieval units into the reader becomes detrimental. This is due to the excessive burden placed on the reader, preventing it from effectively understanding and extracting relevant information from the long context. Taking NQ as an example: for passage-level retrieval units, the turning point occurs between 100 and 200; for document-level retrieval units, the turning point is between 5 and 10; and for grouped documents level, the turning point is between 4 and 8. In general, the most suitable context length fed into the reader is around 30K tokens. Second, using long retrieval units shows improved performance when comparing passage-level retrieval units with document-level or grouped document-level retrieval units.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="326" id="S3.F4.g1" src="x4.png" width="456"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>This figure compares different readers of LongRAG on the NQ dataset. This table leverages 200 test cases from the test set to help compare performance using different readers.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S3.SS5.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Recall vs. EM</h4>
<div class="ltx_para ltx_noindent" id="S3.SS5.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS5.SSS0.Px2.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.F3" title="Figure 3 ‣ 3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">3</span></a>, we compare the relationship between retrieval recall and end performance across varying context lengths for different retrieval unit selections. We observe that using fewer retrieval units in the reader with longer retrieval units design reduces the introduction of distractors or hard negatives under a given length budget. Consequently, the end performance does not increase monotonically with the recall score. In the future, with advancements in long embedding models and improved retrieval recall for long retrieval units, we can expect better end performance.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS5.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Reader Model</h4>
<div class="ltx_para ltx_noindent" id="S3.SS5.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS5.SSS0.Px3.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#S3.F4" title="Figure 4 ‣ Retrieval Unit Selection ‣ 3.5 Ablation Studies ‣ 3 Experiments ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">4</span></a>, we compare the performance of six different readers: Gemini-1.5-pro, GPT-4-Turbo, GPT-4o, Claude-3-Opus, Claude-3.5-Sonnet and DeepSeek-V2-Chat. The results indicate that GPT-4o achieves the highest exact match score on the 200 test questions of the NQ dataset among the three models. This suggests that GPT-4o is the most effective in the role of a long reader in the LongRAG framework. The enhanced performance of GPT-4o can be attributed to its superior ability to process and comprehend lengthy contexts, ensuring that crucial information is accurately extracted. Therefore, we mainly report the GPT-4o results in our main table.
Besides, Gemini-1.5-pro, GPT-4-Turbo, Claude-3-Opus, and Claude-3.5-Sonnet could achieve very similar results. These state-of-the-art black box LLMs are also effective readers within the LongRAG framework. Deepseek-V2-Chat is one of the best open-source LLMs, but its performance degrades significantly compared to the previous five black-box LLMs. The above experiments demonstrate that our current framework depends on the long-context understanding ability of LLMs, and we still have a long way to go in harnessing open-source LLMs within our framework.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Work</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Retrieval-Augmented Generation.</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Augmenting language models with information retrieved from large corpora has become a popular and effective approach for knowledge-intensive tasks, particularly open-domain question answering. The predominant architecture follows a retriever-reader style <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib7" title="">2017</a>; Guu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib20" title="">2020</a>)</cite>, where the input query retrieves information from a corpus, and a language model uses this information as additional context to make a final prediction. Recent work has focused on improving the retriever <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib28" title="">2020</a>; Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib54" title="">2020a</a>; Qu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib44" title="">2020</a>; Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib55" title="">2020b</a>; Khalifa et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib30" title="">2023</a>)</cite>, enhancing the reader <cite class="ltx_cite ltx_citemacro_citep">(Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib23" title="">2020b</a>; Cheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib11" title="">2021</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib57" title="">2021</a>; Borgeaud et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib6" title="">2022</a>)</cite>, fine-tuning the retriever and reader jointly <cite class="ltx_cite ltx_citemacro_citep">(Yu, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib58" title="">2022</a>; Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib25" title="">2022</a>; Singh et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib49" title="">2021</a>; Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib22" title="">2020a</a>)</cite>, and integrating the retriever with the black-box language model <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib59" title="">2023</a>; Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib48" title="">2023</a>; Trivedi et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib51" title="">2022</a>)</cite>. However, the impact of document granularity on the effectiveness and efficiency of the retrieval-augmented generation pipeline remains underexplored.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Long Context Large Language Models.</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The effectiveness of Transformer-based models is hindered by the quadratic increase in computational cost relative to sequence length, especially when dealing with long context inputs. In order to solve this issue, different approaches have been proposed to mitigate computational issues, including sliding memory window and chunk segmentation <cite class="ltx_cite ltx_citemacro_citep">(Hao et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib21" title="">2022</a>; Ratner et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib45" title="">2023</a>; Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib62" title="">2024b</a>)</cite>. FlashAttention <cite class="ltx_cite ltx_citemacro_citep">(Dao et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib13" title="">2022</a>)</cite> has also been a pivotal strategy to significantly reduce the memory footprint to almost linear w.r.t sequence length.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">To enable length extrapolation, RoPE <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib50" title="">2021</a>)</cite> and AliBI <cite class="ltx_cite ltx_citemacro_citep">(Press et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib43" title="">2021</a>)</cite> position encodings have shown potential to enable length extrapolation, which have been widely used in the literature. Recent endeavors have explored diverse strategies to tackle this challenge, which is mainly <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">Position reorganization</span> <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib26" title="">2024</a>; An et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib2" title="">2024</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">Position interpolation</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib9" title="">2023a</a>; Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib42" title="">2023</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib36" title="">2024</a>)</cite>. Furthermore, alternative architectures beyond the Transformer have been explored to handle long inputs more naturally. These diverse approaches claim that they can enhance the capabilities of LLMs in processing long context inputs more efficiently.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Long Context Embedding</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Recent efforts also increased the context length for embedding models, extending the supported text snippet length from a limit of 512 tokens to 32k tokens. Typically, the development of long-context embedding models involves first obtaining a long-context backbone model. This can be achieved either by pre-training with long inputs from scratch <cite class="ltx_cite ltx_citemacro_citep">(Günther et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib19" title="">2023</a>; Nussbaum et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib39" title="">2024</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib8" title="">2024</a>)</cite> or by utilizing existing large language models that support longer context <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib52" title="">2023</a>)</cite>.
Additionally, some works extend the capabilities of existing embedding models to handle long contexts by applying LLM content window extension methods on embedding models <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib61" title="">2024a</a>; Peng &amp; Quesnelle, <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib41" title="">2023</a>)</cite>, or by employing state-space encoder models <cite class="ltx_cite ltx_citemacro_citep">(Saad-Falcon et al., <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#bib.bib47" title="">2024</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we propose a new framework, LongRAG, to alleviate the imbalance between the burden of the retriever. The LongRAG framework consists of a “long retriever” and a “long reader” component on top of the 4K-token retrieval units. Our proposed framework can significantly reduce the corpus size, enabling strong retrieval recall using only a few top units, thereby minimizing noise from hard negatives. On the other hand, the long retrieval unit preserves the semantic integrity of each document. We test our framework on four end-to-end question answering tasks and demonstrate its superior performance without any training. We believe LongRAG can pave the road for the modern RAG system design.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An et al. (2024)</span>
<span class="ltx_bibblock">
Chenxin An, Fei Huang, Jun Zhang, Shansan Gong, Xipeng Qiu, Chang Zhou, and Lingpeng Kong.

</span>
<span class="ltx_bibblock">Training-free long-context scaling of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2402.17463</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2024)</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Introducing the next generation of claude.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. (2019)</span>
<span class="ltx_bibblock">
Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong.

</span>
<span class="ltx_bibblock">Learning to retrieve reasoning paths over wikipedia graph for question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:1911.10470</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, et al.

</span>
<span class="ltx_bibblock">Longbench: A bilingual, multitask benchmark for long context understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2308.14508</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud et al. (2022)</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al.

</span>
<span class="ltx_bibblock">Improving language models by retrieving from trillions of tokens.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International conference on machine learning</em>, pp.  2206–2240. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes.

</span>
<span class="ltx_bibblock">Reading wikipedia to answer open-domain questions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.  1870–1879, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu.

</span>
<span class="ltx_bibblock">Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2402.03216</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023a)</span>
<span class="ltx_bibblock">
Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Extending context window of large language models via positional interpolation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2306.15595</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023b)</span>
<span class="ltx_bibblock">
Wenhu Chen, Pat Verga, Michiel de Jong, John Wieting, and William Cohen.

</span>
<span class="ltx_bibblock">Augmenting pre-trained language models with qa-memory for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pp.  1597–1610, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2021)</span>
<span class="ltx_bibblock">
Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao.

</span>
<span class="ltx_bibblock">Unitedqa: A hybrid approach for open domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2101.00178</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai &amp; Callan (2019)</span>
<span class="ltx_bibblock">
Zhuyun Dai and Jamie Callan.

</span>
<span class="ltx_bibblock">Deeper text understanding for ir with contextual neural language modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval</em>, pp.  985–988, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao et al. (2022)</span>
<span class="ltx_bibblock">
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré.

</span>
<span class="ltx_bibblock">Flashattention: Fast and memory-efficient exact attention with io-awareness.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Advances in Neural Information Processing Systems</em>, 35:16344–16359, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dasigi et al. (2021)</span>
<span class="ltx_bibblock">
Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A Smith, and Matt Gardner.

</span>
<span class="ltx_bibblock">A dataset of information-seeking questions and answers anchored in research papers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2105.03011</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhingra et al. (2020)</span>
<span class="ltx_bibblock">
Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, and William W Cohen.

</span>
<span class="ltx_bibblock">Differentiable reasoning over a virtual knowledge base.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2002.10640</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fajcik et al. (2021)</span>
<span class="ltx_bibblock">
Martin Fajcik, Martin Docekal, Karel Ondrej, and Pavel Smrz.

</span>
<span class="ltx_bibblock">R2-d2: A modular baseline for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pp.  854–870, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. (2019)</span>
<span class="ltx_bibblock">
Yuwei Fang, Siqi Sun, Zhe Gan, Rohit Pillai, Shuohang Wang, and Jingjing Liu.

</span>
<span class="ltx_bibblock">Hierarchical graph network for multi-hop question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:1911.03631</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2022)</span>
<span class="ltx_bibblock">
Luyu Gao, Xueguang Ma, Jimmy J. Lin, and Jamie Callan.

</span>
<span class="ltx_bibblock">Tevatron: An efficient and flexible toolkit for dense retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">ArXiv</em>, abs/2203.05765, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Günther et al. (2023)</span>
<span class="ltx_bibblock">
Michael Günther, Jackmin Ong, Isabelle Mohr, Alaeddine Abdessalem, Tanguy Abel, Mohammad Kalim Akram, Susana Guzman, Georgios Mastrapas, Saba Sturua, Bo Wang, et al.

</span>
<span class="ltx_bibblock">Jina embeddings 2: 8192-token general-purpose text embeddings for long documents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2310.19923</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang.

</span>
<span class="ltx_bibblock">Retrieval augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">International conference on machine learning</em>, pp.  3929–3938. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. (2022)</span>
<span class="ltx_bibblock">
Yaru Hao, Yutao Sun, Li Dong, Zhixiong Han, Yuxian Gu, and Furu Wei.

</span>
<span class="ltx_bibblock">Structured prompting: Scaling in-context learning to 1, 000 examples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">ArXiv</em>, abs/2212.06713, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard &amp; Grave (2020a)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave.

</span>
<span class="ltx_bibblock">Distilling knowledge from reader to retriever for question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2012.04584</em>, 2020a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard &amp; Grave (2020b)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave.

</span>
<span class="ltx_bibblock">Leveraging passage retrieval with generative models for open domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2007.01282</em>, 2020b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard &amp; Grave (2021)</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave.

</span>
<span class="ltx_bibblock">Distilling knowledge from reader to retriever for question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">ICLR 2021-9th International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane A. Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave.

</span>
<span class="ltx_bibblock">Few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ArXiv</em>, abs/2208.03299, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2024)</span>
<span class="ltx_bibblock">
Hongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng Jiang, Zirui Liu, Chia-Yuan Chang, Huiyuan Chen, and Xia Hu.

</span>
<span class="ltx_bibblock">Llm maybe longlm: Self-extend llm context window without tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2401.01325</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. (2019)</span>
<span class="ltx_bibblock">
Jeff Johnson, Matthijs Douze, and Hervé Jégou.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with gpus.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">IEEE Transactions on Big Data</em>, 7(3):535–547, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2004.04906</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalifa et al. (2022)</span>
<span class="ltx_bibblock">
Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang.

</span>
<span class="ltx_bibblock">Few-shot reranking for multi-hop qa via language model prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2205.12650</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalifa et al. (2023)</span>
<span class="ltx_bibblock">
Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang.

</span>
<span class="ltx_bibblock">Few-shot reranking for multi-hop qa via language model prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2205.12650</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab et al. (2022)</span>
<span class="ltx_bibblock">
Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia.

</span>
<span class="ltx_bibblock">Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2212.14024</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Transactions of the Association for Computational Linguistics</em>, 7:453–466, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">ArXiv</em>, abs/2005.11401, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2021)</span>
<span class="ltx_bibblock">
Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich Küttler, Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Paq: 65 million probably-asked questions and what you can do with them.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Transactions of the Association for Computational Linguistics</em>, 9:1098–1115, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Shaobo Li, Xiaoguang Li, Lifeng Shang, Xin Jiang, Qun Liu, Chengjie Sun, Zhenzhou Ji, and Bingquan Liu.

</span>
<span class="ltx_bibblock">Hopretriever: Retrieve hops over wikipedia to answer complex questions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, volume 35, pp.  13279–13287, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen Zhang, Yu Zhang, Ge Zhang, Jiakai Wang, Haoran Que, Yukang Chen, Wenbo Su, et al.

</span>
<span class="ltx_bibblock">E^ 2-llm: Efficient and extreme length extension of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Findings of ACL 2024</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, and Jianfeng Gao.

</span>
<span class="ltx_bibblock">Chain-of-skills: A configurable model for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">The 61st Annual Meeting Of The Association For Computational Linguistics</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mialon et al. (2023)</span>
<span class="ltx_bibblock">
Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al.

</span>
<span class="ltx_bibblock">Augmented language models: a survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2302.07842</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nussbaum et al. (2024)</span>
<span class="ltx_bibblock">
Zach Nussbaum, John X Morris, Brandon Duderstadt, and Andriy Mulyar.

</span>
<span class="ltx_bibblock">Nomic embed: Training a reproducible long context text embedder.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2402.01613</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Hello gpt4-o.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng &amp; Quesnelle (2023)</span>
<span class="ltx_bibblock">
Bowen Peng and Jeffrey Quesnelle.

</span>
<span class="ltx_bibblock">Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have" title="">https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole.

</span>
<span class="ltx_bibblock">Yarn: Efficient context window extension of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2309.00071</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Press et al. (2021)</span>
<span class="ltx_bibblock">
Ofir Press, Noah Smith, and Mike Lewis.

</span>
<span class="ltx_bibblock">Train short, test long: Attention with linear biases enables input length extrapolation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al. (2020)</span>
<span class="ltx_bibblock">
Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang.

</span>
<span class="ltx_bibblock">Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2010.08191</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ratner et al. (2023)</span>
<span class="ltx_bibblock">
Nir Ratner, Yoav Levine, Yonatan Belinkov, Ori Ram, Inbal Magar, Omri Abend, Ehud Karpas, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.

</span>
<span class="ltx_bibblock">Parallel context windows for large language models.

</span>
<span class="ltx_bibblock">In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.  6383–6402, Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.acl-long.352</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reid et al. (2024)</span>
<span class="ltx_bibblock">
Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al.

</span>
<span class="ltx_bibblock">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2403.05530</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saad-Falcon et al. (2024)</span>
<span class="ltx_bibblock">
Jon Saad-Falcon, Daniel Y Fu, Simran Arora, Neel Guha, and Christopher Ré.

</span>
<span class="ltx_bibblock">Benchmarking and building long-context retrieval models with loco and m2-bert.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2402.07440</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">Replug: Retrieval-augmented black-box language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2301.12652</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. (2021)</span>
<span class="ltx_bibblock">
Devendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, and Dani Yogatama.

</span>
<span class="ltx_bibblock">End-to-end training of multi-document reader and retriever for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Advances in Neural Information Processing Systems</em>, 34:25968–25981, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2021)</span>
<span class="ltx_bibblock">
Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2104.09864</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trivedi et al. (2022)</span>
<span class="ltx_bibblock">
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2212.10509</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei.

</span>
<span class="ltx_bibblock">Improving text embeddings with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2401.00368</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. (2023)</span>
<span class="ltx_bibblock">
Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv:2309.07597</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al. (2020a)</span>
<span class="ltx_bibblock">
Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk.

</span>
<span class="ltx_bibblock">Approximate nearest neighbor negative contrastive learning for dense text retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2007.00808</em>, 2020a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al. (2020b)</span>
<span class="ltx_bibblock">
Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, et al.

</span>
<span class="ltx_bibblock">Answering complex open-domain questions with multi-hop dense retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2009.12756</em>, 2020b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2018)</span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning.

</span>
<span class="ltx_bibblock">Hotpotqa: A dataset for diverse, explainable multi-hop question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:1809.09600</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021)</span>
<span class="ltx_bibblock">
Donghan Yu, Chenguang Zhu, Yuwei Fang, Wenhao Yu, Shuohang Wang, Yichong Xu, Xiang Ren, Yiming Yang, and Michael Zeng.

</span>
<span class="ltx_bibblock">Kg-fid: Infusing knowledge graph in fusion-in-decoder for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2110.04330</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu (2022)</span>
<span class="ltx_bibblock">
Wenhao Yu.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation across heterogeneous knowledge.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop</em>, pp.  52–58, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023)</span>
<span class="ltx_bibblock">
Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Improving language models via plug-and-play retrieval feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2305.14002</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2019)</span>
<span class="ltx_bibblock">
Chen Zhao, Chenyan Xiong, Corby Rosset, Xia Song, Paul Bennett, and Saurabh Tiwary.

</span>
<span class="ltx_bibblock">Transformer-xh: Multi-evidence reasoning with extra hop attention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">International Conference on Learning Representations</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2024a)</span>
<span class="ltx_bibblock">
Dawei Zhu, Liang Wang, Nan Yang, Yifan Song, Wenhao Wu, Furu Wei, and Sujian Li.

</span>
<span class="ltx_bibblock">Longembed: Extending embedding models for long context retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">arXiv preprint arXiv:2404.12096</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2024b)</span>
<span class="ltx_bibblock">
Dawei Zhu, Nan Yang, Liang Wang, Yifan Song, Wenhao Wu, Furu Wei, and Sujian Li.

</span>
<span class="ltx_bibblock">PoSE: Efficient context window extension of LLMs via positional skip-wise training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">The Twelfth International Conference on Learning Representations</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng.

</span>
<span class="ltx_bibblock">Adaptive information seeking for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pp.  3615–3626, 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Prompts Template for Long Context Reader</h3>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">We have put out prompts used for the experiments in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.T7" title="Table 7 ‣ A.1 Prompts Template for Long Context Reader ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">7</span></a>. For the closed-book method, we use 16-shot in-context examples. For LongRAG, we use a two-turn approach to extract the final answer. In the first turn, the long retrieved context and the question are concatenated as input, and we do not use any in-context examples here due to the context being around 30K tokens. Empirically, we found it beneficial to let the reader generate a longer answer initially, typically ranging from a few words to a few sentences. In the second turn, we use 8-shot in-context examples to guide the reader in further extracting the most important part of the long answer as the short answer, which is typically just a few words.</p>
</div>
<figure class="ltx_table" id="A1.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T7.1.1.1">
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T7.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T7.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T7.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T7.1.1.1.2.1">Prompt</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T7.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T7.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.2.1.1.1">
<span class="ltx_p" id="A1.T7.1.2.1.1.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T7.1.2.1.1.1.1.1">Closed-Book</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T7.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.2.1.2.1">
<span class="ltx_p" id="A1.T7.1.2.1.2.1.1" style="width:341.4pt;">Here are some examples of questions and their corresponding answer, each with a “Question” field and an “Answer” field. Answer the question directly and don’t output other thing.

<br class="ltx_break"/>“Question”: …“Answer”: …
<br class="ltx_break"/>“Question”: …“Answer”: …
<br class="ltx_break"/>…
<br class="ltx_break"/>“Question”: …“Answer”: …
<br class="ltx_break"/>Answer the following question.

<br class="ltx_break"/>“Question”: who is the owner of reading football club “Answer”:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T7.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.3.2.1.1">
<span class="ltx_p" id="A1.T7.1.3.2.1.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T7.1.3.2.1.1.1.1">LongRAG</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T7.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.3.2.2.1">
<span class="ltx_p" id="A1.T7.1.3.2.2.1.1" style="width:341.4pt;"><span class="ltx_text ltx_font_bold" id="A1.T7.1.3.2.2.1.1.1">Turn 1:</span> Go through the following context and then answer the question. The context is a list of Wikipedia documents, ordered by title: ….

<br class="ltx_break"/>Each Wikipedia document contains a title field and a text field. The context is:

<br class="ltx_break"/>“Title”: …“Text”: …
<br class="ltx_break"/>“Title”: …“Text”: …
<br class="ltx_break"/>…
<br class="ltx_break"/>“Title”: …“Text”: …
<br class="ltx_break"/>Find the useful documents from the context, then answer the question: when did the philadelphia eagles play in the super bowl last.
Answer the question directly. Your response should be very concise.

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.T7.1.3.2.2.1.1.2">Turn 2</span>: You have been provided with a question and its long answer. Your task is to derive a very concise short answer from the given long answer. It’s important to ensure that the output short answer remains as simple as possible. Here a few examples:

<br class="ltx_break"/>“Question”: …“Long Answer”: …“Short Answer”: …
<br class="ltx_break"/>“Question”: …“Long Answer”: …“Short Answer”: …
<br class="ltx_break"/>…
<br class="ltx_break"/>“Question”: …“Long Answer”: …“Short Answer”: …
<br class="ltx_break"/>Extract the short answer of the following question and long answer:

<br class="ltx_break"/>“Question”: when did the philadelphia eagles play in the super bowl last “Long Answer”: The Philadelphia Eagles last played in the Super Bowl on February 4, 2018, in Super Bowl LII. “Short Answer”:</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Here are the prompts we used for all the experiments. For the closed-book method, we use 16-shot in-context examples. For LongRAG, we use a two-turn approach to extract the final answer. The first turn doesn’t require any in-context examples and generate a longer answer, typically ranging from a few words to a few sentences. In the second turn, we use 8-shot in-context examples to calibrate and extract the exact short answer, which is typically just a few words.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Refined Metric</h3>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">The most standard metric used in open-domain extractive question answering tasks is EM (Exact Match), since the correct answer must be a substring within the corpus. In our framework, since the long retrieved context, which contains multiple highly-related documents to the given query, is fed into the reader, there is a much higher possibility that an alias of the ground truth exists in the context and can be extracted by the reader. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.T8" title="Table 8 ‣ A.2 Refined Metric ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">8</span></a>, although LongRAG’s prediction doesn’t exactly match the ground truth, it’s obvious that LongRAG’s prediction is correct. To better and more fairly evaluate LongRAG’s performance, we have refined the EM metric slightly. We recognize it as an exact match if the prediction is less than five tokens (indicating that the short answer is successfully extracted as described in Section <a class="ltx_ref" href="https://arxiv.org/html/2406.15319v3#A1.SS1" title="A.1 Prompts Template for Long Context Reader ‣ Appendix A Appendix ‣ LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs"><span class="ltx_text ltx_ref_tag">A.1</span></a>) and the ground truth is a substring of the prediction or vice versa. We have also manually verified that this refined metric indeed captures aliases or other forms of the ground truth. For the fully-supervised RAG baselines used in our paper, given that they are fine-tuned on the training data and the retrieval unit is a small snippet, we believe that the difference won’t be significant when using the refined EM.</p>
</div>
<figure class="ltx_table" id="A1.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T8.1" style="width:469.8pt;height:89pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.5pt,0.5pt) scale(0.989303323111194,0.989303323111194) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T8.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T8.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T8.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T8.1.1.1.1.1.1">Question</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T8.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T8.1.1.1.1.2.1">Ground truth</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A1.T8.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T8.1.1.1.1.3.1">LongRAG prediction</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T8.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T8.1.1.2.1.1">where does the bob and tom show broadcast from</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T8.1.1.2.1.2">Indianapolis , Indiana</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="A1.T8.1.1.2.1.3">Indianapolis</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.1.3.2">
<td class="ltx_td ltx_align_left" id="A1.T8.1.1.3.2.1">who has given the theory of unbalanced economic growth</td>
<td class="ltx_td ltx_align_left" id="A1.T8.1.1.3.2.2">Hirschman</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A1.T8.1.1.3.2.3">Albert O. Hirschman</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.1.4.3">
<td class="ltx_td ltx_align_left" id="A1.T8.1.1.4.3.1">when does season 6 of the next step start</td>
<td class="ltx_td ltx_align_left" id="A1.T8.1.1.4.3.2">2018</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A1.T8.1.1.4.3.3">September 29, 2018</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T8.1.1.5.4.1">what was the precursor to the present day internet</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T8.1.1.5.4.2">the ARPANET project</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="A1.T8.1.1.5.4.3">ARPANET</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Some examples demonstrate that LongRAG has extracted aliases or different forms of the ground truth.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Group Documents Algorithm</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">In this section, we provide an example algorithm used to formulate long retrieval units by grouping multiple short documents, which we applied in the NQ and HotpotQA experiments in our paper. In the algorithm, whether two documents are related can be determined by any reasonable function, such as hyperlinks, word frequency, or structural information from the dataset. In the two Wikipedia-related question-answering tasks in our paper, NQ and HotpotQA, we use the hyperlinks embedded in the text to describe the relationships between documents.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Example Group Documents Algorithm</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_text ltx_font_bold" id="alg1.l1.1">Input:</span> <math alttext="S" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">italic_S</annotation></semantics></math> (max number of tokens per group), <math alttext="D" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><mi id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">italic_D</annotation></semantics></math> (list of documents), <math alttext="\text{adj}[d]" class="ltx_Math" display="inline" id="alg1.l1.m3.1"><semantics id="alg1.l1.m3.1a"><mrow id="alg1.l1.m3.1.2" xref="alg1.l1.m3.1.2.cmml"><mtext id="alg1.l1.m3.1.2.2" xref="alg1.l1.m3.1.2.2a.cmml">adj</mtext><mo id="alg1.l1.m3.1.2.1" xref="alg1.l1.m3.1.2.1.cmml">⁢</mo><mrow id="alg1.l1.m3.1.2.3.2" xref="alg1.l1.m3.1.2.3.1.cmml"><mo id="alg1.l1.m3.1.2.3.2.1" stretchy="false" xref="alg1.l1.m3.1.2.3.1.1.cmml">[</mo><mi id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">d</mi><mo id="alg1.l1.m3.1.2.3.2.2" stretchy="false" xref="alg1.l1.m3.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><apply id="alg1.l1.m3.1.2.cmml" xref="alg1.l1.m3.1.2"><times id="alg1.l1.m3.1.2.1.cmml" xref="alg1.l1.m3.1.2.1"></times><ci id="alg1.l1.m3.1.2.2a.cmml" xref="alg1.l1.m3.1.2.2"><mtext id="alg1.l1.m3.1.2.2.cmml" xref="alg1.l1.m3.1.2.2">adj</mtext></ci><apply id="alg1.l1.m3.1.2.3.1.cmml" xref="alg1.l1.m3.1.2.3.2"><csymbol cd="latexml" id="alg1.l1.m3.1.2.3.1.1.cmml" xref="alg1.l1.m3.1.2.3.2.1">delimited-[]</csymbol><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">\text{adj}[d]</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.1d">adj [ italic_d ]</annotation></semantics></math> (related documents for each document <math alttext="d" class="ltx_Math" display="inline" id="alg1.l1.m4.1"><semantics id="alg1.l1.m4.1a"><mi id="alg1.l1.m4.1.1" xref="alg1.l1.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.1b"><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m4.1d">italic_d</annotation></semantics></math>), <math alttext="\deg(d)" class="ltx_Math" display="inline" id="alg1.l1.m5.2"><semantics id="alg1.l1.m5.2a"><mrow id="alg1.l1.m5.2.3.2" xref="alg1.l1.m5.2.3.1.cmml"><mi id="alg1.l1.m5.1.1" xref="alg1.l1.m5.1.1.cmml">deg</mi><mo id="alg1.l1.m5.2.3.2a" xref="alg1.l1.m5.2.3.1.cmml">⁡</mo><mrow id="alg1.l1.m5.2.3.2.1" xref="alg1.l1.m5.2.3.1.cmml"><mo id="alg1.l1.m5.2.3.2.1.1" stretchy="false" xref="alg1.l1.m5.2.3.1.cmml">(</mo><mi id="alg1.l1.m5.2.2" xref="alg1.l1.m5.2.2.cmml">d</mi><mo id="alg1.l1.m5.2.3.2.1.2" stretchy="false" xref="alg1.l1.m5.2.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m5.2b"><apply id="alg1.l1.m5.2.3.1.cmml" xref="alg1.l1.m5.2.3.2"><csymbol cd="latexml" id="alg1.l1.m5.1.1.cmml" xref="alg1.l1.m5.1.1">degree</csymbol><ci id="alg1.l1.m5.2.2.cmml" xref="alg1.l1.m5.2.2">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m5.2c">\deg(d)</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m5.2d">roman_deg ( italic_d )</annotation></semantics></math> (number of related documents for each document <math alttext="d" class="ltx_Math" display="inline" id="alg1.l1.m6.1"><semantics id="alg1.l1.m6.1a"><mi id="alg1.l1.m6.1.1" xref="alg1.l1.m6.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m6.1b"><ci id="alg1.l1.m6.1.1.cmml" xref="alg1.l1.m6.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m6.1c">d</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m6.1d">italic_d</annotation></semantics></math>)

</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_text ltx_font_bold" id="alg1.l2.1">Output:</span> <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">caligraphic_G</annotation></semantics></math> (set of groups)

</div>
<div class="ltx_listingline" id="alg1.l3">Sort <math alttext="D" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">italic_D</annotation></semantics></math> from low degree to high degree based on <math alttext="\deg(d)" class="ltx_Math" display="inline" id="alg1.l3.m2.2"><semantics id="alg1.l3.m2.2a"><mrow id="alg1.l3.m2.2.3.2" xref="alg1.l3.m2.2.3.1.cmml"><mi id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">deg</mi><mo id="alg1.l3.m2.2.3.2a" xref="alg1.l3.m2.2.3.1.cmml">⁡</mo><mrow id="alg1.l3.m2.2.3.2.1" xref="alg1.l3.m2.2.3.1.cmml"><mo id="alg1.l3.m2.2.3.2.1.1" stretchy="false" xref="alg1.l3.m2.2.3.1.cmml">(</mo><mi id="alg1.l3.m2.2.2" xref="alg1.l3.m2.2.2.cmml">d</mi><mo id="alg1.l3.m2.2.3.2.1.2" stretchy="false" xref="alg1.l3.m2.2.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.2b"><apply id="alg1.l3.m2.2.3.1.cmml" xref="alg1.l3.m2.2.3.2"><csymbol cd="latexml" id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">degree</csymbol><ci id="alg1.l3.m2.2.2.cmml" xref="alg1.l3.m2.2.2">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.2c">\deg(d)</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.2d">roman_deg ( italic_d )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l4">Initialize an empty set of groups <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">caligraphic_G</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_text ltx_font_bold" id="alg1.l5.1">for</span> each document <math alttext="d" class="ltx_Math" display="inline" id="alg1.l5.m1.1"><semantics id="alg1.l5.m1.1a"><mi id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><ci id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.1d">italic_d</annotation></semantics></math> in <math alttext="D" class="ltx_Math" display="inline" id="alg1.l5.m2.1"><semantics id="alg1.l5.m2.1a"><mi id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><ci id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m2.1d">italic_D</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l5.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l6">     <math alttext="\text{related\_groups}\leftarrow\emptyset" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mtext id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2a.cmml">related_groups</mtext><mo id="alg1.l6.m1.1.1.1" stretchy="false" xref="alg1.l6.m1.1.1.1.cmml">←</mo><mi id="alg1.l6.m1.1.1.3" mathvariant="normal" xref="alg1.l6.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><ci id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1">←</ci><ci id="alg1.l6.m1.1.1.2a.cmml" xref="alg1.l6.m1.1.1.2"><mtext id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">related_groups</mtext></ci><emptyset id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\text{related\_groups}\leftarrow\emptyset</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">related_groups ← ∅</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l7">     <span class="ltx_text ltx_font_bold" id="alg1.l7.1">for</span> each related document <math alttext="r" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><mi id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">italic_r</annotation></semantics></math> in <math alttext="\text{adj}[d]" class="ltx_Math" display="inline" id="alg1.l7.m2.1"><semantics id="alg1.l7.m2.1a"><mrow id="alg1.l7.m2.1.2" xref="alg1.l7.m2.1.2.cmml"><mtext id="alg1.l7.m2.1.2.2" xref="alg1.l7.m2.1.2.2a.cmml">adj</mtext><mo id="alg1.l7.m2.1.2.1" xref="alg1.l7.m2.1.2.1.cmml">⁢</mo><mrow id="alg1.l7.m2.1.2.3.2" xref="alg1.l7.m2.1.2.3.1.cmml"><mo id="alg1.l7.m2.1.2.3.2.1" stretchy="false" xref="alg1.l7.m2.1.2.3.1.1.cmml">[</mo><mi id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml">d</mi><mo id="alg1.l7.m2.1.2.3.2.2" stretchy="false" xref="alg1.l7.m2.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><apply id="alg1.l7.m2.1.2.cmml" xref="alg1.l7.m2.1.2"><times id="alg1.l7.m2.1.2.1.cmml" xref="alg1.l7.m2.1.2.1"></times><ci id="alg1.l7.m2.1.2.2a.cmml" xref="alg1.l7.m2.1.2.2"><mtext id="alg1.l7.m2.1.2.2.cmml" xref="alg1.l7.m2.1.2.2">adj</mtext></ci><apply id="alg1.l7.m2.1.2.3.1.cmml" xref="alg1.l7.m2.1.2.3.2"><csymbol cd="latexml" id="alg1.l7.m2.1.2.3.1.1.cmml" xref="alg1.l7.m2.1.2.3.2.1">delimited-[]</csymbol><ci id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">\text{adj}[d]</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m2.1d">adj [ italic_d ]</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l7.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l8">         <span class="ltx_text ltx_font_bold" id="alg1.l8.1">for</span> each group <math alttext="g" class="ltx_Math" display="inline" id="alg1.l8.m1.1"><semantics id="alg1.l8.m1.1a"><mi id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><ci id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">g</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.1d">italic_g</annotation></semantics></math> in <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l8.m2.1"><semantics id="alg1.l8.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><ci id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m2.1d">caligraphic_G</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l8.2">do</span>
</div>
<div class="ltx_listingline" id="alg1.l9">              <span class="ltx_text ltx_font_bold" id="alg1.l9.1">if</span> <math alttext="r\in g" class="ltx_Math" display="inline" id="alg1.l9.m1.1"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><mi id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml">r</mi><mo id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">∈</mo><mi id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><in id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1"></in><ci id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2">𝑟</ci><ci id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">r\in g</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.1d">italic_r ∈ italic_g</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l9.2">then</span>
</div>
<div class="ltx_listingline" id="alg1.l10">                  <math alttext="\text{related\_groups}\leftarrow\text{related\_groups}\cup\{g\}" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><mrow id="alg1.l10.m1.1.2" xref="alg1.l10.m1.1.2.cmml"><mtext id="alg1.l10.m1.1.2.2" xref="alg1.l10.m1.1.2.2a.cmml">related_groups</mtext><mo id="alg1.l10.m1.1.2.1" stretchy="false" xref="alg1.l10.m1.1.2.1.cmml">←</mo><mrow id="alg1.l10.m1.1.2.3" xref="alg1.l10.m1.1.2.3.cmml"><mtext id="alg1.l10.m1.1.2.3.2" xref="alg1.l10.m1.1.2.3.2a.cmml">related_groups</mtext><mo id="alg1.l10.m1.1.2.3.1" xref="alg1.l10.m1.1.2.3.1.cmml">∪</mo><mrow id="alg1.l10.m1.1.2.3.3.2" xref="alg1.l10.m1.1.2.3.3.1.cmml"><mo id="alg1.l10.m1.1.2.3.3.2.1" stretchy="false" xref="alg1.l10.m1.1.2.3.3.1.cmml">{</mo><mi id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml">g</mi><mo id="alg1.l10.m1.1.2.3.3.2.2" stretchy="false" xref="alg1.l10.m1.1.2.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.2.cmml" xref="alg1.l10.m1.1.2"><ci id="alg1.l10.m1.1.2.1.cmml" xref="alg1.l10.m1.1.2.1">←</ci><ci id="alg1.l10.m1.1.2.2a.cmml" xref="alg1.l10.m1.1.2.2"><mtext id="alg1.l10.m1.1.2.2.cmml" xref="alg1.l10.m1.1.2.2">related_groups</mtext></ci><apply id="alg1.l10.m1.1.2.3.cmml" xref="alg1.l10.m1.1.2.3"><union id="alg1.l10.m1.1.2.3.1.cmml" xref="alg1.l10.m1.1.2.3.1"></union><ci id="alg1.l10.m1.1.2.3.2a.cmml" xref="alg1.l10.m1.1.2.3.2"><mtext id="alg1.l10.m1.1.2.3.2.cmml" xref="alg1.l10.m1.1.2.3.2">related_groups</mtext></ci><set id="alg1.l10.m1.1.2.3.3.1.cmml" xref="alg1.l10.m1.1.2.3.3.2"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">𝑔</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">\text{related\_groups}\leftarrow\text{related\_groups}\cup\{g\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.1d">related_groups ← related_groups ∪ { italic_g }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l11">              <span class="ltx_text ltx_font_bold" id="alg1.l11.1">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l11.2">if</span>
</div>
<div class="ltx_listingline" id="alg1.l12">         <span class="ltx_text ltx_font_bold" id="alg1.l12.1">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l12.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l13">     <span class="ltx_text ltx_font_bold" id="alg1.l13.1">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l13.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l14">     Create a new group <math alttext="g_{\text{new}}=\{d\}" class="ltx_Math" display="inline" id="alg1.l14.m1.1"><semantics id="alg1.l14.m1.1a"><mrow id="alg1.l14.m1.1.2" xref="alg1.l14.m1.1.2.cmml"><msub id="alg1.l14.m1.1.2.2" xref="alg1.l14.m1.1.2.2.cmml"><mi id="alg1.l14.m1.1.2.2.2" xref="alg1.l14.m1.1.2.2.2.cmml">g</mi><mtext id="alg1.l14.m1.1.2.2.3" xref="alg1.l14.m1.1.2.2.3a.cmml">new</mtext></msub><mo id="alg1.l14.m1.1.2.1" xref="alg1.l14.m1.1.2.1.cmml">=</mo><mrow id="alg1.l14.m1.1.2.3.2" xref="alg1.l14.m1.1.2.3.1.cmml"><mo id="alg1.l14.m1.1.2.3.2.1" stretchy="false" xref="alg1.l14.m1.1.2.3.1.cmml">{</mo><mi id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">d</mi><mo id="alg1.l14.m1.1.2.3.2.2" stretchy="false" xref="alg1.l14.m1.1.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><apply id="alg1.l14.m1.1.2.cmml" xref="alg1.l14.m1.1.2"><eq id="alg1.l14.m1.1.2.1.cmml" xref="alg1.l14.m1.1.2.1"></eq><apply id="alg1.l14.m1.1.2.2.cmml" xref="alg1.l14.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l14.m1.1.2.2.1.cmml" xref="alg1.l14.m1.1.2.2">subscript</csymbol><ci id="alg1.l14.m1.1.2.2.2.cmml" xref="alg1.l14.m1.1.2.2.2">𝑔</ci><ci id="alg1.l14.m1.1.2.2.3a.cmml" xref="alg1.l14.m1.1.2.2.3"><mtext id="alg1.l14.m1.1.2.2.3.cmml" mathsize="70%" xref="alg1.l14.m1.1.2.2.3">new</mtext></ci></apply><set id="alg1.l14.m1.1.2.3.1.cmml" xref="alg1.l14.m1.1.2.3.2"><ci id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">𝑑</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">g_{\text{new}}=\{d\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m1.1d">italic_g start_POSTSUBSCRIPT new end_POSTSUBSCRIPT = { italic_d }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l15">     Sort <span class="ltx_text ltx_markedasmath" id="alg1.l15.1">related_groups</span> by their size

</div>
<div class="ltx_listingline" id="alg1.l16">     <span class="ltx_text ltx_font_bold" id="alg1.l16.1">for</span> each group <math alttext="g" class="ltx_Math" display="inline" id="alg1.l16.m1.1"><semantics id="alg1.l16.m1.1a"><mi id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><ci id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">g</annotation><annotation encoding="application/x-llamapun" id="alg1.l16.m1.1d">italic_g</annotation></semantics></math> in <span class="ltx_text ltx_markedasmath" id="alg1.l16.2">related_groups</span> <span class="ltx_text ltx_font_bold" id="alg1.l16.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l17">         <span class="ltx_text ltx_font_bold" id="alg1.l17.1">if</span> <math alttext="|g_{\text{new}}|+|g|\leq S" class="ltx_Math" display="inline" id="alg1.l17.m1.2"><semantics id="alg1.l17.m1.2a"><mrow id="alg1.l17.m1.2.2" xref="alg1.l17.m1.2.2.cmml"><mrow id="alg1.l17.m1.2.2.1" xref="alg1.l17.m1.2.2.1.cmml"><mrow id="alg1.l17.m1.2.2.1.1.1" xref="alg1.l17.m1.2.2.1.1.2.cmml"><mo id="alg1.l17.m1.2.2.1.1.1.2" stretchy="false" xref="alg1.l17.m1.2.2.1.1.2.1.cmml">|</mo><msub id="alg1.l17.m1.2.2.1.1.1.1" xref="alg1.l17.m1.2.2.1.1.1.1.cmml"><mi id="alg1.l17.m1.2.2.1.1.1.1.2" xref="alg1.l17.m1.2.2.1.1.1.1.2.cmml">g</mi><mtext id="alg1.l17.m1.2.2.1.1.1.1.3" xref="alg1.l17.m1.2.2.1.1.1.1.3a.cmml">new</mtext></msub><mo id="alg1.l17.m1.2.2.1.1.1.3" stretchy="false" xref="alg1.l17.m1.2.2.1.1.2.1.cmml">|</mo></mrow><mo id="alg1.l17.m1.2.2.1.2" xref="alg1.l17.m1.2.2.1.2.cmml">+</mo><mrow id="alg1.l17.m1.2.2.1.3.2" xref="alg1.l17.m1.2.2.1.3.1.cmml"><mo id="alg1.l17.m1.2.2.1.3.2.1" stretchy="false" xref="alg1.l17.m1.2.2.1.3.1.1.cmml">|</mo><mi id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml">g</mi><mo id="alg1.l17.m1.2.2.1.3.2.2" stretchy="false" xref="alg1.l17.m1.2.2.1.3.1.1.cmml">|</mo></mrow></mrow><mo id="alg1.l17.m1.2.2.2" xref="alg1.l17.m1.2.2.2.cmml">≤</mo><mi id="alg1.l17.m1.2.2.3" xref="alg1.l17.m1.2.2.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.2b"><apply id="alg1.l17.m1.2.2.cmml" xref="alg1.l17.m1.2.2"><leq id="alg1.l17.m1.2.2.2.cmml" xref="alg1.l17.m1.2.2.2"></leq><apply id="alg1.l17.m1.2.2.1.cmml" xref="alg1.l17.m1.2.2.1"><plus id="alg1.l17.m1.2.2.1.2.cmml" xref="alg1.l17.m1.2.2.1.2"></plus><apply id="alg1.l17.m1.2.2.1.1.2.cmml" xref="alg1.l17.m1.2.2.1.1.1"><abs id="alg1.l17.m1.2.2.1.1.2.1.cmml" xref="alg1.l17.m1.2.2.1.1.1.2"></abs><apply id="alg1.l17.m1.2.2.1.1.1.1.cmml" xref="alg1.l17.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l17.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l17.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg1.l17.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l17.m1.2.2.1.1.1.1.2">𝑔</ci><ci id="alg1.l17.m1.2.2.1.1.1.1.3a.cmml" xref="alg1.l17.m1.2.2.1.1.1.1.3"><mtext id="alg1.l17.m1.2.2.1.1.1.1.3.cmml" mathsize="70%" xref="alg1.l17.m1.2.2.1.1.1.1.3">new</mtext></ci></apply></apply><apply id="alg1.l17.m1.2.2.1.3.1.cmml" xref="alg1.l17.m1.2.2.1.3.2"><abs id="alg1.l17.m1.2.2.1.3.1.1.cmml" xref="alg1.l17.m1.2.2.1.3.2.1"></abs><ci id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">𝑔</ci></apply></apply><ci id="alg1.l17.m1.2.2.3.cmml" xref="alg1.l17.m1.2.2.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.2c">|g_{\text{new}}|+|g|\leq S</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m1.2d">| italic_g start_POSTSUBSCRIPT new end_POSTSUBSCRIPT | + | italic_g | ≤ italic_S</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l17.2">then</span>
</div>
<div class="ltx_listingline" id="alg1.l18">              <math alttext="g_{\text{new}}\leftarrow g_{\text{new}}\cup g" class="ltx_Math" display="inline" id="alg1.l18.m1.1"><semantics id="alg1.l18.m1.1a"><mrow id="alg1.l18.m1.1.1" xref="alg1.l18.m1.1.1.cmml"><msub id="alg1.l18.m1.1.1.2" xref="alg1.l18.m1.1.1.2.cmml"><mi id="alg1.l18.m1.1.1.2.2" xref="alg1.l18.m1.1.1.2.2.cmml">g</mi><mtext id="alg1.l18.m1.1.1.2.3" xref="alg1.l18.m1.1.1.2.3a.cmml">new</mtext></msub><mo id="alg1.l18.m1.1.1.1" stretchy="false" xref="alg1.l18.m1.1.1.1.cmml">←</mo><mrow id="alg1.l18.m1.1.1.3" xref="alg1.l18.m1.1.1.3.cmml"><msub id="alg1.l18.m1.1.1.3.2" xref="alg1.l18.m1.1.1.3.2.cmml"><mi id="alg1.l18.m1.1.1.3.2.2" xref="alg1.l18.m1.1.1.3.2.2.cmml">g</mi><mtext id="alg1.l18.m1.1.1.3.2.3" xref="alg1.l18.m1.1.1.3.2.3a.cmml">new</mtext></msub><mo id="alg1.l18.m1.1.1.3.1" xref="alg1.l18.m1.1.1.3.1.cmml">∪</mo><mi id="alg1.l18.m1.1.1.3.3" xref="alg1.l18.m1.1.1.3.3.cmml">g</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.1b"><apply id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1"><ci id="alg1.l18.m1.1.1.1.cmml" xref="alg1.l18.m1.1.1.1">←</ci><apply id="alg1.l18.m1.1.1.2.cmml" xref="alg1.l18.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l18.m1.1.1.2.1.cmml" xref="alg1.l18.m1.1.1.2">subscript</csymbol><ci id="alg1.l18.m1.1.1.2.2.cmml" xref="alg1.l18.m1.1.1.2.2">𝑔</ci><ci id="alg1.l18.m1.1.1.2.3a.cmml" xref="alg1.l18.m1.1.1.2.3"><mtext id="alg1.l18.m1.1.1.2.3.cmml" mathsize="70%" xref="alg1.l18.m1.1.1.2.3">new</mtext></ci></apply><apply id="alg1.l18.m1.1.1.3.cmml" xref="alg1.l18.m1.1.1.3"><union id="alg1.l18.m1.1.1.3.1.cmml" xref="alg1.l18.m1.1.1.3.1"></union><apply id="alg1.l18.m1.1.1.3.2.cmml" xref="alg1.l18.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l18.m1.1.1.3.2.1.cmml" xref="alg1.l18.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l18.m1.1.1.3.2.2.cmml" xref="alg1.l18.m1.1.1.3.2.2">𝑔</ci><ci id="alg1.l18.m1.1.1.3.2.3a.cmml" xref="alg1.l18.m1.1.1.3.2.3"><mtext id="alg1.l18.m1.1.1.3.2.3.cmml" mathsize="70%" xref="alg1.l18.m1.1.1.3.2.3">new</mtext></ci></apply><ci id="alg1.l18.m1.1.1.3.3.cmml" xref="alg1.l18.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.1c">g_{\text{new}}\leftarrow g_{\text{new}}\cup g</annotation><annotation encoding="application/x-llamapun" id="alg1.l18.m1.1d">italic_g start_POSTSUBSCRIPT new end_POSTSUBSCRIPT ← italic_g start_POSTSUBSCRIPT new end_POSTSUBSCRIPT ∪ italic_g</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l19">              Remove <math alttext="g" class="ltx_Math" display="inline" id="alg1.l19.m1.1"><semantics id="alg1.l19.m1.1a"><mi id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><ci id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">g</annotation><annotation encoding="application/x-llamapun" id="alg1.l19.m1.1d">italic_g</annotation></semantics></math> from <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l19.m2.1"><semantics id="alg1.l19.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l19.m2.1.1" xref="alg1.l19.m2.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l19.m2.1b"><ci id="alg1.l19.m2.1.1.cmml" xref="alg1.l19.m2.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m2.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l19.m2.1d">caligraphic_G</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l20">         <span class="ltx_text ltx_font_bold" id="alg1.l20.1">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l20.2">if</span>
</div>
<div class="ltx_listingline" id="alg1.l21">     <span class="ltx_text ltx_font_bold" id="alg1.l21.1">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l21.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l22">     Add <math alttext="g_{\text{new}}" class="ltx_Math" display="inline" id="alg1.l22.m1.1"><semantics id="alg1.l22.m1.1a"><msub id="alg1.l22.m1.1.1" xref="alg1.l22.m1.1.1.cmml"><mi id="alg1.l22.m1.1.1.2" xref="alg1.l22.m1.1.1.2.cmml">g</mi><mtext id="alg1.l22.m1.1.1.3" xref="alg1.l22.m1.1.1.3a.cmml">new</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l22.m1.1b"><apply id="alg1.l22.m1.1.1.cmml" xref="alg1.l22.m1.1.1"><csymbol cd="ambiguous" id="alg1.l22.m1.1.1.1.cmml" xref="alg1.l22.m1.1.1">subscript</csymbol><ci id="alg1.l22.m1.1.1.2.cmml" xref="alg1.l22.m1.1.1.2">𝑔</ci><ci id="alg1.l22.m1.1.1.3a.cmml" xref="alg1.l22.m1.1.1.3"><mtext id="alg1.l22.m1.1.1.3.cmml" mathsize="70%" xref="alg1.l22.m1.1.1.3">new</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m1.1c">g_{\text{new}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m1.1d">italic_g start_POSTSUBSCRIPT new end_POSTSUBSCRIPT</annotation></semantics></math> to <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l22.m2.1"><semantics id="alg1.l22.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l22.m2.1.1" xref="alg1.l22.m2.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l22.m2.1b"><ci id="alg1.l22.m2.1.1.cmml" xref="alg1.l22.m2.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m2.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m2.1d">caligraphic_G</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l23">
<span class="ltx_text ltx_font_bold" id="alg1.l23.1">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l23.2">for</span>
</div>
<div class="ltx_listingline" id="alg1.l24">
<span class="ltx_text ltx_font_bold" id="alg1.l24.1">return</span> <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l24.m1.1"><semantics id="alg1.l24.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l24.m1.1.1" xref="alg1.l24.m1.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l24.m1.1b"><ci id="alg1.l24.m1.1.1.cmml" xref="alg1.l24.m1.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m1.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l24.m1.1d">caligraphic_G</annotation></semantics></math>
</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Dataset Examples</h3>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1">Here, we present a few examples from the four datasets we experiment with.</p>
</div>
<figure class="ltx_table" id="A1.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T9.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T9.1.1.1">
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T9.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A1.T9.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T9.1.1.1.2.1">Prompt</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T9.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T9.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.2.1.1.1">
<span class="ltx_p" id="A1.T9.1.2.1.1.1.1" style="width:85.4pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T9.1.2.1.1.1.1.1">NQ</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T9.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.2.1.2.1">
<span class="ltx_p" id="A1.T9.1.2.1.2.1.1" style="width:341.4pt;"><span class="ltx_text ltx_font_bold" id="A1.T9.1.2.1.2.1.1.1">Question:</span> how many episodes are in series 7 game of thrones

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.T9.1.2.1.2.1.1.2">Answer:</span> seven</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T9.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.3.2.1.1">
<span class="ltx_p" id="A1.T9.1.3.2.1.1.1" style="width:85.4pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T9.1.3.2.1.1.1.1">HotpotQA</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T9.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.3.2.2.1">
<span class="ltx_p" id="A1.T9.1.3.2.2.1.1" style="width:341.4pt;"><span class="ltx_text ltx_font_bold" id="A1.T9.1.3.2.2.1.1.1">Question:</span> What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.T9.1.3.2.2.1.1.2">Answer:</span> Chief of Protocol</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T9.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.4.3.1.1">
<span class="ltx_p" id="A1.T9.1.4.3.1.1.1" style="width:85.4pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T9.1.4.3.1.1.1.1">Qasper</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T9.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.4.3.2.1">
<span class="ltx_p" id="A1.T9.1.4.3.2.1.1" style="width:341.4pt;"><span class="ltx_text ltx_font_bold" id="A1.T9.1.4.3.2.1.1.1">Question:</span> In the paper ’End-to-End Trainable Non-Collaborative Dialog System’, How is intent annotated?

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.T9.1.4.3.2.1.1.2">Answer:</span> using a role-playing task on the Amazon Mechanical Turk platform and collecting typed conversations</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T9.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.5.4.1.1">
<span class="ltx_p" id="A1.T9.1.5.4.1.1.1" style="width:85.4pt;"><span class="ltx_text ltx_font_smallcaps" id="A1.T9.1.5.4.1.1.1.1">MultifieldQA-en</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T9.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.5.4.2.1">
<span class="ltx_p" id="A1.T9.1.5.4.2.1.1" style="width:341.4pt;"><span class="ltx_text ltx_font_bold" id="A1.T9.1.5.4.2.1.1.1">Question:</span> What is the name of the most active fan club?

<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="A1.T9.1.5.4.2.1.1.2">Answer:</span> South West Ultras fan club.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Here are some examples from the four datasets used in our experiments.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Sep  1 16:53:18 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
