<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models</title>
<!--Generated on Sat Oct  5 17:10:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
data exploration,  dataset search,  large language model,  retrieval-augmented generation.
" lang="en" name="keywords"/>
<base href="/html/2410.04231v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S1" title="In Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S2" title="In Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Studies</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S3" title="In Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">System Architecture and Data Modeling</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S3.SS1" title="In III System Architecture and Data Modeling ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Overview of the Data Exploration System</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S3.SS2" title="In III System Architecture and Data Modeling ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Data Modeling by Metadata</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4" title="In Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Settings</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS1" title="In IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Purpose</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS1.SSS1" title="In IV-A Purpose ‣ IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span>1 </span>Differential comparison of data similarity through description-based and variable-based similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS1.SSS2" title="In IV-A Purpose ‣ IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span>2 </span>Consideration of the possibility that different language models should be used for different tasks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS2" title="In IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Language Models and Vector DB</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS3" title="In IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Four Tasks and Evaluation Methods</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS4" title="In IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S4.SS5" title="In IV Experimental Settings ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-E</span> </span><span class="ltx_text ltx_font_italic">Prompt Generation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S5" title="In Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results and Discussion</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S5.SS1" title="In V Results and Discussion ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Evaluation on Similar Dataset Recommendation (Task 1)</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S5.SS2" title="In V Results and Discussion ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Evaluation of Combinable Dataset Recommendation (Task 2)</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S5.SS3" title="In V Results and Discussion ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Evaluation of Tag Estimation (Task 3)</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S5.SS4" title="In V Results and Discussion ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Evaluation of Variable Estimation (Task 4)</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S6" title="In Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Teruaki Hayashi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id1.1.id1">Department of Systems Innovation, School of Engineering</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id2.2.id2">The University of Tokyo
<br class="ltx_break"/></span>Tokyo, Japan 
<br class="ltx_break"/>hayashi@sys.t.u-tokyo.ac.jp
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hiroki Sakaji



 <span class="ltx_text" id="id3.1.id1"></span><span class="ltx_text" id="id4.2.id2"></span> <span class="ltx_ERROR undefined" id="id5.3.id3">{@IEEEauthorhalign}</span>
Jiayi Dai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id6.4.id1">Faculty of Information Science and Technology</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id7.5.id2">Hokkaido University
<br class="ltx_break"/></span>Hokkaido, Japan 
<br class="ltx_break"/>sakaji@ist.hokudai.ac.jp
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id8.6.id1">Alberta Machine Intelligence Institute</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id9.7.id2">University of Alberta
<br class="ltx_break"/></span>Edmonton, Canada 
<br class="ltx_break"/>dai1@ualberta.ca
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Randy Goebel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id10.1.id1">Alberta Machine Intelligence Institute</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id11.2.id2">University of Alberta
<br class="ltx_break"/></span>Edmonton, Canada 
<br class="ltx_break"/>rgoebel@ualberta.ca
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id12.id1">Developing the capacity to effectively search for requisite datasets is an urgent requirement to assist data users in identifying relevant datasets considering the very limited available metadata. For this challenge, the utilization of third-party data is emerging as a valuable source for improvement. Our research introduces a new architecture for data exploration which employs a form of Retrieval-Augmented Generation (RAG) to enhance metadata-based data discovery. The system integrates large language models (LLMs) with external vector databases to identify semantic relationships among diverse types of datasets. The proposed framework offers a new method for evaluating semantic similarity among heterogeneous data sources and for improving data exploration. Our study includes experimental results on four critical tasks: 1) recommending similar datasets, 2) suggesting combinable datasets, 3) estimating tags, and 4) predicting variables. Our results demonstrate that RAG can enhance the selection of relevant datasets, particularly from different categories, when compared to conventional metadata approaches. However, performance varied across tasks and models, which confirms the significance of selecting appropriate techniques based on specific use cases. The findings suggest that this approach holds promise for addressing challenges in data exploration and discovery, although further refinement is necessary for estimation tasks.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
data exploration, dataset search, large language model, retrieval-augmented generation.

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Despite growing interest in leveraging data sharing and collaboration for value creation, various obstacles hinder the use of data across different disciplines. A key challenge is locating data that aligns with specific interests. Currently, dataset retrieval often relies on basic query matching with metadata titles and dataset contents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib2" title="">2</a>]</cite>. However, due to the highly specialized terminology found in both datasets and metadata, traditional search methods like query matching typically fall significantly short for users lacking domain expertise. These individuals and groups struggle to articulate their interests using specialized terms, making it difficult for them to find the datasets of best value.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">This issue further extends to organizations whose mandate is to provide data. because the generation of metadata necessitates specialized knowledge of the specific data and field. To do so requires substantial effort and resources. Furthermore, data specifically created for third-party use is uncommon, and data providers often lack sufficient incentives to maintain metadata. Consequently, publicly available open data frequently had inadequate metadata <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib3" title="">3</a>]</cite>. The inadequacy of metadata maintenance is evident, as demonstrated by the metadata entry rates for approximately 3.6 million datasets in the Google Dataset Search dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib4" title="">4</a>]</cite>. While data URLs and titles exhibit an almost 100% entry rate, the <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">VariablesMeasured</span> field (variable information) is only 9% complete, and <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">measurementTechnique</span>, which indicates the data acquisition method, is less than 1% complete.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Although research has established that metadata quality directly influences search effectiveness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib5" title="">5</a>]</cite>, the provision of information regarding the origin and context of the data remains insufficient. Furthermore, data managed on particular platforms are acquired and stored by data providers for diverse purposes, and the development of data catalogs, a unified description format for metadata, and the dissemination of metadata schemas are inadequate, rendering systematic data organization and integration challenging.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Notably, due to the highly specialized and personalized nature of data, there is no comprehensive taxonomy system in place to provide curation guidance. Despite efforts to develop data catalog vocabularies, such as Data Vocabulary Catalog (DCAT) and Schema.org, sporadically updated and are not being used in a comprehensive manner. Enforcing a uniform format for all the data generated over time and submitted to the platform presents significant difficulties. These challenges exist across all data repository platforms, and impede users from efficiently identifying suitable datasets for data analysis. This results in critical delays in investment decisions and risk management. Moreover, in scholarly research, the precision and reliability of studies may be compromised by inadequate data or inappropriate data selection.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The capacity to accurately explore requisite datasets and evaluate their reliability would facilitate the provision of precise data to data users. Consequently, there is a pressing need for a methodology to identify relevant datasets, using whatever limited information is available as metadata as indicators. Based on the aforementioned discussions, the research question of our study is as follows: <span class="ltx_text ltx_font_italic" id="S1.p5.1.1">How can the semantic similarity among heterogeneous data be evaluated, and how can the accuracy of data discovery be enhanced while addressing insufficient metadata?</span> This research presents an architecture for data exploration that incorporates Retrieval-Augmented Generation (RAG) into traditional metadata-based evaluations of data similarity, context, and content, yielding results that align with user requirements. RAG enhances the text generation capabilities of Large-Language Models (LLMs) by integrating information from external knowledge bases, potentially mitigating hallucinations associated with standalone LLM use <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib6" title="">6</a>]</cite>. The proposed framework facilitates the identification of semantic relationships between diverse datasets, surpassing conventional string matching or basic metadata approaches. Moreover, when metadata is insufficient, the architecture can utilize domain knowledge from heterogeneous datasets as supplementary external information to address gaps in the data.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The contributions of this study can be summarized as follows.</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">This study represents the initial endeavor to quantitatively assess data similarity utilizing LLM and RAG for heterogeneous metadata retrieval.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">This study assessed the tasks of dataset recommendation and estimating data characteristics by diving metadata into textual information (description of the data outline) and structure (variables) as its constituent elements.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Our findings indicate that the optimal model and input method varied according to the type of estimation target and its features, underscoring the significance of selecting an appropriate model based on the specific characteristics of the task.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The subsequent sections of this paper are structured as follows. Section II presents related studies that use our methodological approach. In Section III, we delineate the system architecture and the data models employed for data exploration. Section IV presents the experimental details. In Section V, we show the results and engage in a critical discussion of the study’s limitations. Finally, conclusions are presented in Section VI.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Studies</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The analysis of dataset relationships can be classified as three primary approaches: 1) studies focusing on metadata, 2) use of actual data, and 3) external information to depict data connections. Metadata comprises summarized details about a dataset, including its name, summary, tags, and related attributes. The primary content of a dataset, referred to as actual data, is available in various formats such as CSV, JSON, images, texts, and other file types. Knowledge graphs that illustrate data relationships constitute external information.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Among the three approaches, there is general consensus that the one using metadata is the most cost-effective and accurate method for understanding the relationships between different datasets. Metadata typically exploits a unified description framework that is independent of the modality and domain of the dataset. In contrast to approaches based on the contents of actual datasets, metadata facilitates the evaluation of similarity between datasets with differing data structures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib8" title="">8</a>]</cite>. An additional advantage of using metadata is that metadata description items are typicall written in natural language, thus enabling the application of numerous NLP methods. Research using metadata-based similarity measures for datasets encompasses vector similarity between word embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib11" title="">11</a>]</cite> and graph distance between ontology concepts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib14" title="">14</a>]</cite>. This study will implement the comparison tasks, such as a similarity evaluation task, utilizing metadata, in accordance with the approach of previous methods.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Furthermore, embedding methods applied to actual datasets, particularly tabular data in instances where adequate metadata is not available, have been proposed in the field of data exploration. For instance, pre-trained models such as Table2Vec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib10" title="">10</a>]</cite>, TABBIE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib15" title="">15</a>]</cite>, or TAPAS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib16" title="">16</a>]</cite>, which are capable of converting tabular data into vector representations, have been introduced. Additionally, similarity evaluation using metadata descriptions and variables as data semantic expression extraction focusing on metadata <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib17" title="">17</a>]</cite> have been developed. However, unlike web articles, actual datasets contain limited textual information. To address this limitation, research has been proposed to employ large language models (LLMs) to facilitate data discovery and semantic understanding using the minimal information available <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib18" title="">18</a>]</cite>. Notably, the knowledge and tools required to maximize the potential of LLMs for dataset search have led to substantial advancements in data discovery and semantic understanding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib20" title="">20</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">As previously discussed, LLMs demonstrate significant potential for data exploration tasks, particularly when employing a metadata-based approach, due to their inherent language-processing capabilities. In this research, we propose a methodology to enhance LLM performance by prioritizing metadata analysis over raw data examination, and to augment domain-specific knowledge through the implementation of the RAG architecture.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">System Architecture and Data Modeling</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Overview of the Data Exploration System</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S3.F1" title="Figure 1 ‣ III-A Overview of the Data Exploration System ‣ III System Architecture and Data Modeling ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the comprehensive architecture of our RAG system, adjusted and adapted as the data exploration system proposed in this study. Our RAG architecture integrates an LLM with an external database to generate appropriate information for user queries. Initially, in the retrieval module depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#S3.F1" title="Figure 1 ‣ III-A Overview of the Data Exploration System ‣ III System Architecture and Data Modeling ‣ Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>) component labelled “(I),” a vector DB is established in advance as an external information source, comprising a vector of embedded metadata representations and the original metadata. The vectorization methodology is elucidated below in Section III-B. To facilitate dataset exploration, the system employs four sequential steps as follows:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p2.1.1">Step 1 (Query input and vectorization)</span>: To explore a dataset, a user enters a query to obtain information about a dataset that aligns with their interests. The query is formulated in natural language format, where “AAA” represents the name of the dataset. Subsequently, the vectorized query is generated using the same language model employed to create the embedded representation of a vector DB in process (a).</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p3.1.1">Step 2 (Related dataset search)</span>: The user’s vectorized query searches for related datasets from the vector DB and selects candidates. In this step, the top N metadata with high cosine similarity between vectors are obtained in (b).</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p4.1.1">Step 3 (Prompt creation)</span>: The dataset information retrieved from the Retrieval Module is subsequently incorporated into the Prompt module. At this juncture, the user’s query from Step 1 is used again. In this step, the query and associated metadata sets are inserted into a template (details are explained in Section IV) and transmitted to the Generation module at (d).</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p5.1.1">Step 4 (Answer generation)</span>: The prompts are entered into the LLM to generate responses and subsequently return them to the user in (e).</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<p class="ltx_p ltx_align_center" id="S3.F1.1"><span class="ltx_text" id="S3.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="281" id="S3.F1.1.1.g1" src="extracted/5904083/rag_architecture.png" width="296"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The proposed RAG system architecture for data exploration.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Data Modeling by Metadata</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The vector DB, which constitutes the foundation of RAG, is constructed from a set of embedded representations of information on datasets. Given the diverse formats in which data is represented, there is no universally applicable method to describe different types of datasets in a common format. As discussed in Section II, although embedded representations of datasets exist, they are specialized for tabular and graphical data. Therefore, this study calculates the similarity of data pairs based on the elements described in the metadata, which is the data about the data. Our data modeling by metadata is separated into two components: 1) the variable component, which is highly machine-readable, and 2) the description component, which is highly human-readable. Variables represent the attributes of the object that the data represent. Data names and summary descriptions are sentences that provide information about the data in natural language. Table I presents an example of the metadata for the Humanitarian Data Exchange (HDX) citehttps://data.humdata.org/ data utilized in this experiment.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">This study employs four language models for metadata items: BERT (bert-base-uncased), Sentence-BERT (intfloat/multilingual-e5-base), Word2Vec (noun), and OpenAI (text-embedding-3-small) to generate embedding representations (details of the models are provided in Section IV-B). This approach enables the computation of similarity between query vectors and metadata. Furthermore, the similarity of dataset pairs can be assessed using cosine similarity. For comparative purposes, this study also utilizes data similarity by variables using the Dice coefficient, referencing the conventional method instead of the embedded representation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib21" title="">21</a>]</cite>. The similarity calculation for a dataset pair using the Dice coefficient is as follows:</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Dice(V_{i},V_{j})=\frac{2|V_{i}\cap V_{j}|}{|V_{i}|+|V_{j}|}," class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml"><mi id="S3.E1.m1.4.4.1.1.2.4" xref="S3.E1.m1.4.4.1.1.2.4.cmml">D</mi><mo id="S3.E1.m1.4.4.1.1.2.3" xref="S3.E1.m1.4.4.1.1.2.3.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.2.5" xref="S3.E1.m1.4.4.1.1.2.5.cmml">i</mi><mo id="S3.E1.m1.4.4.1.1.2.3a" xref="S3.E1.m1.4.4.1.1.2.3.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.2.6" xref="S3.E1.m1.4.4.1.1.2.6.cmml">c</mi><mo id="S3.E1.m1.4.4.1.1.2.3b" xref="S3.E1.m1.4.4.1.1.2.3.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.2.7" xref="S3.E1.m1.4.4.1.1.2.7.cmml">e</mi><mo id="S3.E1.m1.4.4.1.1.2.3c" xref="S3.E1.m1.4.4.1.1.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.1.1.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml"><mo id="S3.E1.m1.4.4.1.1.2.2.2.3" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">(</mo><msub id="S3.E1.m1.4.4.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml">V</mi><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.4.4.1.1.2.2.2.4" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">,</mo><msub id="S3.E1.m1.4.4.1.1.2.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.2.cmml">V</mi><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.3" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.4.4.1.1.2.2.2.5" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml">=</mo><mfrac id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">2</mn><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.cmml">V</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">∩</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">V</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mrow id="S3.E1.m1.2.2.2.1.1" xref="S3.E1.m1.2.2.2.1.2.cmml"><mo id="S3.E1.m1.2.2.2.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.1.2.1.cmml">|</mo><msub id="S3.E1.m1.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.1.1.1.2.cmml">V</mi><mi id="S3.E1.m1.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.2.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.2.1.2.1.cmml">|</mo></mrow><mo id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">+</mo><mrow id="S3.E1.m1.3.3.3.2.1" xref="S3.E1.m1.3.3.3.2.2.cmml"><mo id="S3.E1.m1.3.3.3.2.1.2" stretchy="false" xref="S3.E1.m1.3.3.3.2.2.1.cmml">|</mo><msub id="S3.E1.m1.3.3.3.2.1.1" xref="S3.E1.m1.3.3.3.2.1.1.cmml"><mi id="S3.E1.m1.3.3.3.2.1.1.2" xref="S3.E1.m1.3.3.3.2.1.1.2.cmml">V</mi><mi id="S3.E1.m1.3.3.3.2.1.1.3" xref="S3.E1.m1.3.3.3.2.1.1.3.cmml">j</mi></msub><mo id="S3.E1.m1.3.3.3.2.1.3" stretchy="false" xref="S3.E1.m1.3.3.3.2.2.1.cmml">|</mo></mrow></mrow></mfrac></mrow><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1"><eq id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3"></eq><apply id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"><times id="S3.E1.m1.4.4.1.1.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.3"></times><ci id="S3.E1.m1.4.4.1.1.2.4.cmml" xref="S3.E1.m1.4.4.1.1.2.4">𝐷</ci><ci id="S3.E1.m1.4.4.1.1.2.5.cmml" xref="S3.E1.m1.4.4.1.1.2.5">𝑖</ci><ci id="S3.E1.m1.4.4.1.1.2.6.cmml" xref="S3.E1.m1.4.4.1.1.2.6">𝑐</ci><ci id="S3.E1.m1.4.4.1.1.2.7.cmml" xref="S3.E1.m1.4.4.1.1.2.7">𝑒</ci><interval closure="open" id="S3.E1.m1.4.4.1.1.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2"><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2">𝑉</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.2">𝑉</ci><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3">𝑗</ci></apply></interval></apply><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><divide id="S3.E1.m1.3.3.4.cmml" xref="S3.E1.m1.3.3"></divide><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><cn id="S3.E1.m1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.3">2</cn><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1"><abs id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></abs><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><intersect id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></intersect><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2">𝑉</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">𝑉</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">𝑗</ci></apply></apply></apply></apply><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><plus id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3"></plus><apply id="S3.E1.m1.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1"><abs id="S3.E1.m1.2.2.2.1.2.1.cmml" xref="S3.E1.m1.2.2.2.1.1.2"></abs><apply id="S3.E1.m1.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.2">𝑉</ci><ci id="S3.E1.m1.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E1.m1.3.3.3.2.2.cmml" xref="S3.E1.m1.3.3.3.2.1"><abs id="S3.E1.m1.3.3.3.2.2.1.cmml" xref="S3.E1.m1.3.3.3.2.1.2"></abs><apply id="S3.E1.m1.3.3.3.2.1.1.cmml" xref="S3.E1.m1.3.3.3.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.1.1.1.cmml" xref="S3.E1.m1.3.3.3.2.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.3.2.1.1.2.cmml" xref="S3.E1.m1.3.3.3.2.1.1.2">𝑉</ci><ci id="S3.E1.m1.3.3.3.2.1.1.3.cmml" xref="S3.E1.m1.3.3.3.2.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">Dice(V_{i},V_{j})=\frac{2|V_{i}\cap V_{j}|}{|V_{i}|+|V_{j}|},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">italic_D italic_i italic_c italic_e ( italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = divide start_ARG 2 | italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∩ italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | end_ARG start_ARG | italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | + | italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.4">where <math alttext="V_{i}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><msub id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">V</mi><mi id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">𝑉</ci><ci id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">V_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="V_{j}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><msub id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">V</mi><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝑉</ci><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">V_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> are the variables of the corresponding datasets <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_i</annotation></semantics></math> and <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">italic_j</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Example of HDX Metadata.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Item</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.2.1">
<span class="ltx_p" id="S3.T1.1.1.1.2.1.1" style="width:180.7pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1.1.1">Content</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.2.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Data name</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.1.2.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.1.2.1">
<span class="ltx_p" id="S3.T1.1.2.1.2.1.1" style="width:180.7pt;">Daily Summaries of Precipitation Indicators for Canada</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.3.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Data summary</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.1.3.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.2.2.1">
<span class="ltx_p" id="S3.T1.1.3.2.2.1.1" style="width:180.7pt;">This dataset contains the daily summaries on base stations across Canada. The four indicators included are: TPCP: Total precipitation MXSD: Maximum snow depth TSNW: Total snow fall EMXP: Extreme maximum daily precipitation Indicators are compiled by the National Centers for Environmental Information (NCEI), which is administrated by National oceanic and Atmospheric Administration (NoAA) an organization part of the United States government. NoAA has access to data collected from thousands of base stations around the world, which collect data periodically on weather and climate conditions. This dataset contains the latest 5 years of available data.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.1.4.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Variables</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.1.4.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.3.2.1">
<span class="ltx_p" id="S3.T1.1.4.3.2.1.1" style="width:180.7pt;">’indicator’, ’value’, ’station’, ’fl_cmiss’, ’date’, ’fl_miss’, ’datatype’, ’country’</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.1.5.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Tags</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S3.T1.1.5.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.4.2.1">
<span class="ltx_p" id="S3.T1.1.5.4.2.1.1" style="width:180.7pt;">’el nino’, ’rainfall - precipitation’, ’weather and climate’</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Settings</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Purpose</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our objective is to assess the efficacy of a customized RAG system for dataset exploration in data retrieval tasks metadata as a constrained source of information about data. Specifically, the evaluation will be conducted employing the following two approaches.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S4.SS1.SSS1.4.1.1">IV-A</span>1 </span>Differential comparison of data similarity through description-based and variable-based similarity</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">Four major language models are used to analyze relationships between data on a textual basis. Additionally, relationships between data will be analyzed on a variable basis. The data similarity across language models will be compared, and the differences and similarities between the models will be examined.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S4.SS1.SSS2.4.1.1">IV-A</span>2 </span>Consideration of the possibility that different language models should be used for different tasks</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">This study compares the efficacy of metadata items and language models across four distinct tasks: similar dataset recommendation, combinable dataset recommendation, tag estimation, and variable estimation. Furthermore, it examines the significance of task-specific selection of metadata items and language models.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Language Models and Vector DB</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Four language models are utilized in the creation of the vector DBs. The first model is BERT, a language model that has demonstrated exceptional performance across various language interpretation tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib22" title="">22</a>]</cite>. BERT is pre-trained on BookCorpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib23" title="">23</a>]</cite> and Wikipedia entries; if the number of tokens exceeds 512, subsequent tokens are truncated. The second model is Sentence-BERT (hereafter, SBERT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib24" title="">24</a>]</cite>. It vectorizes sentences, with the tokenizing functionality integrated into SBERT. The fundamental operation is analogous to vectorization in BERT; however, a model is employed in which the vector output is optimized for similar sentence determination. The vector length is 768 dimensions, and if it exceeds 512 tokens, the remainder are truncated. The third, OpenAI model, functions similarly to SBERT and obtains embedded representations from sentences. The internal model is not publicly accessible. The vector comprises 1,536 dimensions, and if it exceeds 8,191 tokens, the remainder are truncated. The fourth, Word2Vec (hereafter, W2V), is a method that represents words as vectors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib25" title="">25</a>]</cite>. In this experiment, only nouns are considered, and it derived from Reuters news articles spanning 2003 to 2018 is utilized. The vectors have 200 dimensions, generated with a 5-word window, and no token truncation is applied. The training algorithm employed was Continuous Bag of Words (CBOW).
In the word2vec vector, we calculate the average of word vectors for getting a sentence vector.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The following three categories of metadata elements were utilized as input to generate embeddings from the language models.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Description model (D): Data name, Summary, and Tags</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Variable model (V): Variables and Tags</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Description and Variable model (D+V): Data name, Summary, Variables, and Tags</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">In addition, we use ChromaDB<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://docs.trychroma.com/</span></span></span> for building vector DBs, which is efficient for vector search, and Llama 3.1<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.llama.com/</span></span></span> for LLM.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.4.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.5.2">Four Tasks and Evaluation Methods</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We implemented four tasks that are considered significant in dataset search. The first is a similar dataset recommendation task (Task 1). This task involves recommending datasets that are similar to a given dataset, and is considered the most fundamental task in dataset search, having been implemented in various studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib21" title="">21</a>]</cite>. The second is a combinable dataset recommendation task (Task 2). This task reflects the observation that, as demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib26" title="">26</a>]</cite>, multiple data sources are increasingly being combined for analysis, rather than relying on a single data source. The third is tag estimation (Task 3). There exist instances where metadata creators are uncertain about which tags to assign to their own data when providing their datasets. Additionally, metadata creation is considered burdensome. This task predicts the category to which the dataset in question belongs as tags. The fourth task is variable estimation (Task 4), which predicts potential variables within the dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04231v1#bib.bib27" title="">27</a>]</cite>. Data design generally incurs high rework costs, and it is beneficial to estimate variables from data summaries prior to data acquisition. Each task is presented as a query in natural language sentences as follows:</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.1">Task 1</span>: “Which datasets are similar to this dataset? Please select multiple candidates and rank them by relevance.”</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.1">Task 2</span>: “Which datasets would be suitable to combine with this dataset? Please select multiple candidates and rank them by their combinability.”</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.1">Task 3</span>: “What tags are associated with this dataset? Please select from the list below and sort the results by relevance.”</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1"><span class="ltx_text ltx_font_italic" id="S4.SS3.p5.1.1">Task 4</span>: “What variables are included in this dataset? Please select from the list below and sort the results by relevance.”</p>
</div>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.1">The query is vectorized by the language models and N related metadata are obtained from the vector DBs (N=10 in the experiment). The query, consisting of natural language sentences, and 10 metadata expressions are subsequently inserted into the prompt template to generate the results from LLM.</p>
</div>
<div class="ltx_para" id="S4.SS3.p7">
<p class="ltx_p" id="S4.SS3.p7.1">In Task 1, we assess the correspondence between the tags in the sample datasets (described in detail in Section IV-D) and those in the output datasets from the LLM. If the tags are congruent, the recommendation is classified as originating from the same category; if they are incongruent, the recommendation is categorized as arising from a different category. Subsequently, the similarity of the dataset pair is analyzed in terms of description and variables. As in Task 1, Task 2 is evaluated based on the correspondence between the tags in the sample dataset and those in the output datasets generated by LLM. It is important to note that dataset combinability is not necessarily advantageous even when the dataset pair originates from the same category. Given that the presence or absence of common variables, such as foreign keys, is crucial for data integration and combination, the combinability of datasets is assessed in terms of variable similarity. The variable model (V) generates a collection of variables and tags as metadata from the vector DB. However, the output of V lacks the data name information that uniquely identifies the relevant dataset. Consequently, we compare the outputs between D and D+V in Tasks 1 and 2.</p>
</div>
<div class="ltx_para" id="S4.SS3.p8">
<p class="ltx_p" id="S4.SS3.p8.1">Given that Tasks 3 and 4 are estimation tasks, we evaluate the Precision, Recall, and F1 scores of the output results from the LLM. For the three inputs D, V, and D+V, we analyze the differences in results with respect to the characteristics of each language model.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.4.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.5.2">Datasets</span>
</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Using the appropriate API, we extracted 9,630 datasets (provided in CSV format) from the HDX website<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://data.humdata.org/</span></span></span>. These datasets included information such as the data name, summary, variables, and associated tags. Table II presents the fundamental statistical features of these datasets.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>The Features of Variables and Tags.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T2.1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.1.1">
<span class="ltx_p" id="S4.T2.1.1.1.1.1.1" style="width:65.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1.1.1">Variable</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">Value</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T2.1.1.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.3.1">
<span class="ltx_p" id="S4.T2.1.1.1.3.1.1" style="width:65.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1.1.1">Tag</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1">Value</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.2.1.1">
<span class="ltx_p" id="S4.T2.1.2.2.1.1.1" style="width:65.0pt;"># of variables</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">149,582</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.2.3.1">
<span class="ltx_p" id="S4.T2.1.2.2.3.1.1" style="width:65.0pt;"># of tags</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">42,379</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.3.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.3.1.1">
<span class="ltx_p" id="S4.T2.1.3.3.1.1.1" style="width:65.0pt;"># of variable types</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.3.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">13,409</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.3.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.3.3.1">
<span class="ltx_p" id="S4.T2.1.3.3.3.1.1" style="width:65.0pt;"># of tag types</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">249</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.4.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.4.1.1">
<span class="ltx_p" id="S4.T2.1.4.4.1.1.1" style="width:65.0pt;">Max # of variables in a dataset</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.4.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">2,856</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.4.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.4.3.1">
<span class="ltx_p" id="S4.T2.1.4.4.3.1.1" style="width:65.0pt;">Max # of tags in a dataset</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">19</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T2.1.5.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.5.1.1">
<span class="ltx_p" id="S4.T2.1.5.5.1.1.1" style="width:65.0pt;">Min # of variables in a dataset</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T2.1.5.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T2.1.5.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.5.3.1">
<span class="ltx_p" id="S4.T2.1.5.5.3.1.1" style="width:65.0pt;">Min # of tags in a dataset</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.5.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">To evaluate the performance of the four tasks, a sample dataset was prepared, comprising complete data names, data summaries, variables, and tags. Five tags with high frequency of occurrence—education, economics, health, facilities and infrastructure, and weather and climate—were selected. Two datasets with each tag were extracted to ensure the tags did not overlap, resulting in a total of 10 datasets. Table III presents the sample datasets for validation.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">This methodology enables the tracking of discrepancies in input metadata items and similarities among the target data categories by tags. The evaluation of differences in the performance of the language model, similarity calculation method, and task will be feasible based on the type of question and the data categories covered by the sample dataset.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Sample Datasets.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.1.1.1">
<span class="ltx_p" id="S4.T3.1.1.1.1.1.1" style="width:50.6pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1.1.1">Category</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.1.2.1">
<span class="ltx_p" id="S4.T3.1.1.1.2.1.1" style="width:180.7pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.2.1.1.1">Data name</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.2.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.1.1.1">
<span class="ltx_p" id="S4.T3.1.2.1.1.1.1" style="width:50.6pt;">Education</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.2.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.1.2.1">
<span class="ltx_p" id="S4.T3.1.2.1.2.1.1" style="width:180.7pt;">
<span class="ltx_itemize" id="S4.I2">
<span class="ltx_item" id="S4.I2.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I2.i1.p1">
<span class="ltx_p" id="S4.I2.i1.p1.1">Compiled Reports of the Special Representative of the Secretary General for Children and Armed conflict of years 2015 through 2017</span>
</span></span>
<span class="ltx_item" id="S4.I2.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I2.i2.p1">
<span class="ltx_p" id="S4.I2.i2.p1.1">UNHCR’s populations of concern originating from the Democratic Republic of the Congo</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.3.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.2.1.1">
<span class="ltx_p" id="S4.T3.1.3.2.1.1.1" style="width:50.6pt;">Economics</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.3.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.2.2.1">
<span class="ltx_p" id="S4.T3.1.3.2.2.1.1" style="width:180.7pt;">
<span class="ltx_itemize" id="S4.I3">
<span class="ltx_item" id="S4.I3.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I3.i1.p1">
<span class="ltx_p" id="S4.I3.i1.p1.1">Japan - Social Development</span>
</span></span>
<span class="ltx_item" id="S4.I3.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I3.i2.p1">
<span class="ltx_p" id="S4.I3.i2.p1.1">Canada - Science and Technology</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.4.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.3.1.1">
<span class="ltx_p" id="S4.T3.1.4.3.1.1.1" style="width:50.6pt;">Health</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.4.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.3.2.1">
<span class="ltx_p" id="S4.T3.1.4.3.2.1.1" style="width:180.7pt;">
<span class="ltx_itemize" id="S4.I4">
<span class="ltx_item" id="S4.I4.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I4.i1.p1">
<span class="ltx_p" id="S4.I4.i1.p1.1">InterAction member activities in Greece</span>
</span></span>
<span class="ltx_item" id="S4.I4.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I4.i2.p1">
<span class="ltx_p" id="S4.I4.i2.p1.1">Airports in Cayman Islands</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.5.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.4.1.1">
<span class="ltx_p" id="S4.T3.1.5.4.1.1.1" style="width:50.6pt;">Facilities and infrastructure</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.5.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.4.2.1">
<span class="ltx_p" id="S4.T3.1.5.4.2.1.1" style="width:180.7pt;">
<span class="ltx_itemize" id="S4.I5">
<span class="ltx_item" id="S4.I5.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I5.i1.p1">
<span class="ltx_p" id="S4.I5.i1.p1.1">South Sudan 3W operational Presence (Jan - Apr-2016)</span>
</span></span>
<span class="ltx_item" id="S4.I5.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I5.i2.p1">
<span class="ltx_p" id="S4.I5.i2.p1.1">Current IATI aid activities in Guinea-Bissau</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.1.6.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.5.1.1">
<span class="ltx_p" id="S4.T3.1.6.5.1.1.1" style="width:50.6pt;">Weather and climate</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T3.1.6.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.5.2.1">
<span class="ltx_p" id="S4.T3.1.6.5.2.1.1" style="width:180.7pt;">
<span class="ltx_itemize" id="S4.I6">
<span class="ltx_item" id="S4.I6.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I6.i1.p1">
<span class="ltx_p" id="S4.I6.i1.p1.1">Japan - Economic, Social, Environmental, Health, Education, Development and Energy</span>
</span></span>
<span class="ltx_item" id="S4.I6.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I6.i2.p1">
<span class="ltx_p" id="S4.I6.i2.p1.1">Daily Summaries of Precipitation Indicators for Canada</span>
</span></span>
</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS5.4.1.1">IV-E</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS5.5.2">Prompt Generation</span>
</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.3">The method for generating a prompt for nput into the LLM comprises two steps: (1) retrieving the top <math alttext="N" class="ltx_Math" display="inline" id="S4.SS5.p1.1.m1.1"><semantics id="S4.SS5.p1.1.m1.1a"><mi id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><ci id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.1.m1.1d">italic_N</annotation></semantics></math> datasets (metadata) from the vector DB through a vectorized query, and (2) incorporating the query and the top <math alttext="N" class="ltx_Math" display="inline" id="S4.SS5.p1.2.m2.1"><semantics id="S4.SS5.p1.2.m2.1a"><mi id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><ci id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.2.m2.1d">italic_N</annotation></semantics></math> datasets into the predetermined template. The template structure is as follows, wherein {question} represents the query and {context} denotes the list of the top <math alttext="N" class="ltx_Math" display="inline" id="S4.SS5.p1.3.m3.1"><semantics id="S4.SS5.p1.3.m3.1a"><mi id="S4.SS5.p1.3.m3.1.1" xref="S4.SS5.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b"><ci id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.3.m3.1d">italic_N</annotation></semantics></math> datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p2">
<svg class="ltx_picture" height="91.21" id="S4.SS5.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,91.21) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 85.3 C 0 88.57 2.64 91.21 5.91 91.21 L 594.09 91.21 C 597.36 91.21 600 88.57 600 85.3 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 85.3 C 1.97 87.48 3.73 89.24 5.91 89.24 L 594.09 89.24 C 596.27 89.24 598.03 87.48 598.03 85.3 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="63.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S4.SS5.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S4.SS5.p2.pic1.1.1.1.1.1.1">You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don’t know the answer, just say that you don’t know. Use five sentences maximum and keep the answer concise.</span>
<span class="ltx_p" id="S4.SS5.p2.pic1.1.1.1.1.1.2">Question: {question}</span>
<span class="ltx_p" id="S4.SS5.p2.pic1.1.1.1.1.1.3">Context: {context}</span>
</span></foreignobject></g></g></svg>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results and Discussion</span>
</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.4.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.5.2">Evaluation on Similar Dataset Recommendation (Task 1)</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Figure 2 (a) shows the output results of similar dataset recommendation (Task 1) with four language models and two metadata input types. For each sample metadata, the vector DBs return 10 related metadata with queries across all models, totaling 100. The quantity was subsequently reduced by more than half, limited to those deemed most relevant by the LLM. Furthermore, some models incorporate a separate fictional dataset generated by the LLM itself.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Initially, we compare the number of dataset origins by model. For the OpenAI (D), it is observed that a greater number of datasets are generated by LLM compared to other models. Upon closer examination, it became apparent that the majority of the information was inaccurate, indicating the occurrence of hallucination. This false data originated from the health-tagged “InterAction member activities in Greece” dataset, despite the fact that the metadata sets retrieved from the vector DB produced 10 metadata showing high similarity to the query. Therefore, it does not necessarily indicate that the LLM with OpenAI model possesses the capability to generate more datasets than other models.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">A shared feature is evident across all four models. Model Ds exhibits a higher number of datasets from different categories compared to those from the same category as the sample datasets. Additionally, when contrasted with D, the quantity of recommendations by LLM decreases with adding variable information in D+V.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">With each LLM, we found that the datasets determined to be more similar were selected from the results by vector DBs. However, was any of the LLMs able to select more similar datasets? Figure 3 compares the mean similarity by Variable and Description before and after conducting selection by LLM. Common to all models is that the datasets recommended from the vector DBs before LLM perform relatively well in recommending datasets from the same category, but not well enough for recommending datasets from different categories. Notably, all models except W2V demonstrated an ability to suggest datasets with greater similarity in both variables and descriptions through an LLM. Of note is BERT (D+V), which successfully identified datasets with higher variable similarity from different categories using LLM. This trend was observed across other models, where LLM facilitated the selection of more similar datasets from categories different from the sample data. Although recommendations within the same category were not as effective as those from different categories, LLMs consistently identified datasets with higher similarity.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">In summary, in three models of D and D+V, except W2V, the variable similarity is improved by using an LLM. In particular, it is possible to select datasets with high variable similarity in datasets that belong to a different category from the sample data. The datasets in the same category do not differ greatly, but the average similarity is slightly improved. It may be that LLM may be superior in selecting datasets with high variable similarity that could not be picked up by the vector DB. This result also suggests that the influence of Description is significant in the similar dataset recommendation task. Therefore, in the same category, datasets with similar Descriptions tend to have similar variables, and as a result, datasets with high similarity are more likely to be recommended. On the other hand, in different categories, datasets with high similarity in Description tend to be recommended, but the result is that the variable similarity of such data is not necessarily high.</p>
</div>
<figure class="ltx_figure" id="S5.F2">
<p class="ltx_p ltx_align_center" id="S5.F2.1"><span class="ltx_text" id="S5.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="189" id="S5.F2.1.1.g1" src="extracted/5904083/task12_results3.png" width="598"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Output results of (a) similar dataset recommendation (Task 1) with four language models and three metadata input types and (b) combinable dataset recommendation (Task 2). The both bar graphs depict the sources of recommended datasets classified into three groups: “datasets from different categories (red),” “datasets from the same category (blue),” and “datasets generated by LLM (lightgreen).” The first two groups consist of actual datasets in HDX, while the third category comprises fictional datasets generated by LLM.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F3">
<p class="ltx_p ltx_align_center" id="S5.F3.1"><span class="ltx_text" id="S5.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="267" id="S5.F3.1.1.g1" src="extracted/5904083/task1_similarity.png" width="598"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Comparison of mean variable/description similarities of recommended datasets before and after via LLM in Task 1. The bar graphs depict the sources of recommended datasets classified into two groups: “datasets from different categories (red),” and “datasets from the same category (blue).” The error bars show the standard deviation.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.4.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.5.2">Evaluation of Combinable Dataset Recommendation (Task 2)</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Figure 2 (b) shows the output results of combinable dataset recommendation (Task 2) with four language models and two metadata input types. As with Task 1, the number of outputs has been reduced by more than half using LLM. If the number of LLM-generated datasets of OpenAI (D) in Task 1, in which are hallucination is excluded as noise, then there is an overall increase in the datasets generated by LLM in Task 2 (61) compared to that of Task 1 (32). This is likely due to the greater complexity of the combinable dataset recommendation task and the increased need to generate new data sets by LLM. This is especially true for inputs that include variable information with description in V+D, suggesting that LLM is attempting to make better recommendations by generating new combinations in addition to existing datasets.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Was the LLM able to select more combinable datasets? Figure 4 compares the mean similarity by Variable and Description before and after conducting selection by LLM. Common to all models is that the datasets recommended from the vector DBs before LLM perform relatively well in recommending datasets from the same category, but not well enough for recommending datasets from different categories. Notably, all models except W2V demonstrated an ability to suggest datasets with greater similarity in both variables and descriptions through LLM. Especially, BERT (D+V) successfully identified datasets with higher variable similarity from different categories using LLM. This trend was observed across other models, where LLM facilitated the selection of more similar datasets from categories different from the sample data. Although recommendations within the same category were not as effective as those from different categories, LLMs consistently identified datasets with higher similarity.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">How combinable are the recommended datasets with the sample dataset? Specifically, given that the integration of heterogeneous datasets typically occurs through shared variables, as exemplified by foreign keys, variable similarity is considered more crucial than description similarity. In recommendations from the same category using BERT and SBERT, datasets exhibiting high similarity to the sample dataset in both variables and descriptions were recommended from vector DBs. This indicates that datasets with high potential for combination are proposed without the need for LLM application. Conversely, in recommendations from different categories, the similarity of variables significantly improves through LLM in BERT (D+V), SBERT (D), and SBERT (D+V). This demonstrates that LLM selected datasets with more comparable variables. A similar trend is observed for OpenAI and W2V. These findings suggest that LLM may exhibit superior performance in identifying datasets that are more likely to be combined when recommending data from a different domain to be merged with the sample datasets.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">While LLM enhances the correlation between variables and descriptions in most of the models, it notably <span class="ltx_text ltx_font_italic" id="S5.SS2.p4.1.1">decreases</span> variable similarity within the same categories for W2V (D+V). This suggests that LLM might exclude certain combinable datasets. In Task 1, the W2V model underperformed compared to other models in D+V. Although W2V outperforms OpenAI in D, its performance declines when variable information is incorporated in D+V. This decline may be attributed to the noun-centric nature of W2V, which is highly customized for human understanding. Variable information, being more specialized for machine interpretation than human comprehension, likely becomes noise in the W2V model during the embedding process.</p>
</div>
<figure class="ltx_figure" id="S5.F4">
<p class="ltx_p ltx_align_center" id="S5.F4.1"><span class="ltx_text" id="S5.F4.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="268" id="S5.F4.1.1.g1" src="extracted/5904083/task2_similarity.png" width="598"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparison of mean variable/description similarities of recommended datasets before and after via LLM in Task 2. The bar graphs depict the sources of recommended datasets classified into two groups: “datasets from different categories (red),” and “datasets from the same category (blues).” The error bars show the standard deviation.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5">
<p class="ltx_p ltx_align_center" id="S5.F5.1"><span class="ltx_text" id="S5.F5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="142" id="S5.F5.1.1.g1" src="extracted/5904083/task23_2.png" width="598"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Mean F1 scores in (a) Task 3, and (b) Task 4. The bar graphs on the left of each model (orange) are the scores for the tags/variables contained in the metadata output from the vector DBs, and the ones on the right (green) are the scores for those selected via LLM.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.4.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.5.2">Evaluation of Tag Estimation (Task 3)</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The average F1 Scores for Task 3 are depicted in Fig. 5 (a). Models that us D alone or D+V demonstrated high performance, whereas those employing V embeddings exhibited extremely low performance. This discrepancy arises because tag information is contingent on the context and topic of the sample dataset, resulting in superior performance for text-based inputs (D and D+V). The incorporation of V in D+V models did not yield significant improvements compared to D alone, and in certain instances, scores actually declined. This suggests that variable information fails to serve as effective supplementary information for tag estimation. It appears that the variable information lacks sufficient determining characteristics representative of the data categories denoted by the tags, and instead functions as noise in the process. For tag estimation, BERT and SBERT’s D alone without LLM performs best. This result suggests that these models can most effectively use natural language text as input; BERT and SBERT were trained on a large amount of text data during pre-training, and thus have very high comprehension of the text with D.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">The introduction of LLM resulted in decreased scores or increased standard deviations across all models, suggesting performance instability. Examination of individual outputs revealed that the LLM excluded correct tags identified as relevant in the vector DBs. Furthermore, the LLM generated its own tags not present in the HDX tag list. The current LLM’s use in tag estimation tasks leads to unreliable results, indicating that its application should be carefully evaluated based on the specific task requirements.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.4.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.5.2">Evaluation of Variable Estimation (Task 4)</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Similar to Task 3, the output from Task 4 utilizing vector DB alone consistently yielded superior F1 scores across all models compared to using LLM (Fig. 5 (b)). An analysis of individual output results revealed that accurate variables identified by vector DBs were omitted during the LLM process, or the LLM generated distinct variables not present in the HDX variable sets. The application of current LLM for variable estimation tasks should be approached with caution.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">Interestingly, the combination of description and variable information (D+V) outperforms variable information alone (V) across all models. This suggests that, contrary to tag information, variable data is not extraneous in variable estimation, and its integration with descriptive content enables more accurate estimation of relevant variable sets. For instance, in the “Japan - Social Development” dataset, the correct variables are “value,” “indicator name,” “country iso3,” “year,” “indicator code,” and “country name.” The SBERT (V) model estimated a variable set including “value,” “origin,” “year,” and “country / territory of asylum/residence,” achieving partial correctness with an F1 score of 0.40. This partial match occurred because the query’s sample dataset description partially aligned with the variable information in the vector DB. In contrast, when using the complete metadata (description and variables), using the D+V model resulted in a higher similarity output for the dataset and its variables compared to using variables alone, yielding a perfect F1 score of 1.00. While the variable-only model demonstrates some estimation capability, incorporating descriptive information, which provides context for the variables, appears to have supplemented the variable data, leading to enhanced estimation performance.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">In summary, we found that enhancing variable estimation with description information is more effective than relying solely on variable information. Notably, despite variable estimation being more challenging than tag estimation, it generally achieves higher scores. This is unexpected, given that variable estimation involves 13,409 variables compared to 249 tags, and variables exhibit a longer-tailed frequency distribution. The superior performance of variable estimation may be attributed to the co-occurrence nature of variables. For instance, while “country / territory of asylum/residence” has moderate frequency, it frequently appears alongside high-frequency variables like “year” and “origin,” resulting in a high number of variable pair occurrences. This co-occurrence pattern, where low-frequency variables sometimes appear with high-frequency ones, is believed to boost variable estimation performance. Conversely, tags demonstrate different characteristics. As shown in Table II, datasets contain a maximum of 19 tags, with an average of 4.4 tags per dataset, resembling a Poisson distribution. Unlike variables, tags are independently assigned as representative topics for datasets, rather than co-occurring. This independence is thought to limit tag estimation performance.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The proposed RAG-based system demonstrated good performance in identifying similar and combinable datasets. Additionally, LLMs displayed proficiency in choosing datasets with greater variable and description similarities, particularly from diverse categories, surpassing the capabilities of vector DB retrieval alone. However, performance fluctuated across different tasks and models, emphasizing the necessity of carefully selecting appropriate techniques and metadata items based on specific use cases, and indicating that caution should be exercised when applying LLMs to these tasks. In essence, while LLMs enhanced results for similar and combinable dataset recommendations, vector DB retrieval might be more suitable for tag and variable estimation tasks.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Although this approach shows potential for tackling challenges in data exploration and discovery, further improvements are needed, especially for estimation tasks where LLMs introduced inconsistencies.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">To conclude, this research illustrates the potential of RAG-based systems to improve data exploration capabilities, particularly in identifying relationships between heterogeneous datasets. Nevertheless, the inconsistent performance across tasks underlines the importance of carefully considering model and input selection based on specific data discovery goals. For example, instead of relying on generic language models, more domain-specific models could be considered for better capturing the semantics of particular database inputs. In addition, deploying explainable AI methods that indicate what database features most influence similarity measures could provide insights on the knowledge captured by language models and the decision-making of the overall database retrieval architecture. Future research should concentrate on enhancing LLM applications for estimation tasks and investigating methods to more effectively combine the strengths of both vector DB retrieval and language models.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This study was supported by JST PRESTO Grant Number JPMJPR2369.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Chapman, E. Simperl, L. Koesten, G. Konstantinidis, L.-D. Ibáñez, E. Kacprzak, and P. Groth, “Dataset search: a survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">The VLDB Journal</em>, vol. 29, pp. 251–272, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R. J. Miller, F. Nargesian, E. Zhu, C. Christodoulakis, K. Q. Pu, and P. Andritsos, “Making open data transparent: Data discovery on open data,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Data Engineering Bulletin</em>, vol. 41, no. 2, pp. 59–70, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
P. Zezula, “Similarity searching for the big data,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Mobile Networks and Applications</em>, vol. 20, no. 4, p. 487–496, aug 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
D. Brickley, M. Burgess, and N. Noy, “Google dataset search: Building a search engine for datasets in an open web ecosystem,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">The World Wide Web Conference</em>, p. 1365–1375, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
L. M. Koesten, E. Kacprzak, J. F. A. Tennison, and E. Simperl, “The trials and tribulations of working with structured data: -a study on information seeking behaviour,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">CHI</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. tau Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-augmented generation for knowledge-intensive nlp tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">NeurIPS</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. Hayashi and Y. Ohsawa, “Understanding the structural characteristics of data platforms using metadata and a network approach,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">IEEE Access</em>, vol. 8, pp. 35 469–35 481, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. Sakaji, T. Hayashi, Y. Fukami, T. Shimizu, H. Matsushima, and K. Izumi, “Retrieving of data similarity using metadata on a data analysis competition platform,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Conference on Big Data</em>, pp. 3480–3485, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
D. Bernhauer, M. Nečaský, P. Škoda, J. Klímek, and T. Skopal, “Open dataset discovery using context-enhanced similarity search,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Knowledge and Information Systems</em>, vol. 64, p. 3265–3291, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
L. Zhang, S. Zhang, and K. Balog, “Table2vec: Neural word and entity embeddings for table population and retrieval,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">SIGIR</em>, p. 1029–1032, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Sakaji, T. Hayashi, K. Izumi, and Y. Ohsawa, “Verification of data similarity using metadata on a data exchange platform,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">International Conference on Big Data</em>, pp. 4467–4474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
X. Wang, Z. Huang, and F. van Harmelen, “Evaluating similarity measures for dataset search,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">International Conference on Web Information Systems Engineering</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
X. Wang, F. van Harmelen, and Z. Huang, “Biomedical dataset recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">10th International Conference on Data Science, Technology and Applications</em>, vol. 1, pp. 192–199, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
P. Škoda, J. Klímek, M. Nečaský, and T. Skopal, “Explainable similarity of datasets using knowledge graph,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International Conference on Similarity Search and Applications</em>, p. 103–110, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
H. Iida, D. Thai, V. Manjunatha, and M. Iyyer, “TABBIE: Pretrained representations of tabular data,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Conference of the North American Chapter of the Association for Computational Linguistics</em>, pp. 3446–3456, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Herzig, P. K. Nowak, T. Müller, F. Piccinno, and J. M. Eisenschlos, “Tapas: Weakly supervised table parsing via pre-training,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">58th Annual Meeting of the Association for Computational Linguistics</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
T. Hayashi, Y. Fujita, and M. Kuwahara, “Exploring the fundamental units of semantic representation of data using heterogeneous variable network in data ecosystems,” <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">International Conference on Big Data</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
H. Dong and Z. Wang, “Large language models for tabular data: Progresses and future directions,” <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">SIGIR</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y. Fujita, T. Hayashi, and M. Kuwahara, “Topic-based search: Dataset search without metadata and users’ knowledge about data,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. Nishio, H. Nonaka, N. Tsuchiya, A. Migita, Y. Banno, T. Hayashi, H. Sakaji, T. Sakumoto, and K. Watabe, “Extraction of research objectives, machine learning model names, and dataset names from academic papers and analysis of their interrelationships using llm and network analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">https://arxiv.org/abs/2408.12097</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
T. Sakumoto, T. Hayashi, H. Sakaji, and H. Nonaka, “Metadata-based clustering and selection of metadata items for similar dataset discovery and data combination tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">IEEE Access</em>, vol. 12, pp. 40 213–40 224, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">NAACL</em>, p. 4171–4186, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and S. Fidler, “Aligning books and movies: Towards story-like visual explanations by watching movies and reading books,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">The IEEE International Conference on Computer Vision (ICCV)</em>, December 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
N. Reimers and I. Gurevych, “Sentence-bert: Sentence embeddings using siamese bert-networks,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">EMNLP</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
T. Mikolov, K. Chen, G. S. Corrado, and J. Dean, “Efficient estimation of word representations in vector space,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">International Conference on Learning Representations</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T. Hayashi, H. Sakaji, Y. F. Hiroyasu Matsushima, T. Shimizu, and Y. Ohsawa, “Data combination for problem-solving: A case of an open data exchange platform,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">The Review of Socionetwork Strategies</em>, vol. 15, p. 521–534, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
T. Hayashi and Y. Ohsawa, “Matrix-based method for inferring variable labels using outlines of data in data jackets,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">PAKDD</em>, pp. 696–707, 2017.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Oct  5 17:10:15 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
