<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>CodeRAG-Bench: Can Retrieval Augment Code Generation?</title>
<!--Generated on Thu Jun 20 15:07:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.14497v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S1" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>The <span class="ltx_text ltx_font_smallcaps">CodeRAG-Bench</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS1" title="In 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Programming Problems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS2" title="In 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Retrieval Sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS3" title="In 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Canonical Document Annotation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS4" title="In 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Evaluation Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Canonical RACG: Experiments and Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS1" title="In 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS2" title="In 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Retrieval Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS3" title="In 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Generation with and without Canonical Documents</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS4" title="In 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Retrieval-Augmented Code Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS5" title="In 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>How Many Documents to Augment?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S4" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>RACG with Open Retrieval</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S4.SS1" title="In 4 RACG with Open Retrieval ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Can RACG Benefit Weaker Models?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S4.SS2" title="In 4 RACG with Open Retrieval ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Does RACG Help Stronger Models?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S5" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S6" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix: Datasheets for Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS1" title="In Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Access to <span class="ltx_text ltx_font_smallcaps">CodeRAG-Bench</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS1.SSS0.Px1" title="In A.1 Access to CodeRAG-Bench ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title">Author Statement</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS2" title="In Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Dataset Documentation and Intended Uses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS3" title="In Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS4" title="In Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Composition</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS4.SSS1" title="In A.4 Composition ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.1 </span>Collection Process</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS4.SSS2" title="In A.4 Composition ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.2 </span>Preprocessing/cleaning/labeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS4.SSS3" title="In A.4 Composition ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.3 </span>Uses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS4.SSS4" title="In A.4 Composition ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.4 </span>Distribution</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS4.SSS5" title="In A.4 Composition ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4.5 </span>Maintainence</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A2" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Example Illustrations</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A2.SS1" title="In Appendix B Example Illustrations ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Example with Canonical Documents</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A2.SS2" title="In Appendix B Example Illustrations ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>RACG with Helpful and Distracting Documents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A3" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional Details about Retrieval Efficiency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A4" title="In CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Result Reproduction</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\addauthor</span>
<p class="ltx_p" id="p1.2">gnmagenta
<span class="ltx_ERROR undefined" id="p1.2.1">\addauthor</span>zworange
<span class="ltx_ERROR undefined" id="p1.2.2">\addauthor</span>dfcyan
<span class="ltx_ERROR undefined" id="p1.2.3">\addauthor</span>vygreen
<span class="ltx_ERROR undefined" id="p1.2.4">\addauthor</span>yqblue
<span class="ltx_ERROR undefined" id="p1.2.5">\addauthor</span>fxyellow




</p>
</div>
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_smallcaps" id="id11.id1">CodeRAG-Bench</span>: 
<br class="ltx_break"/>Can Retrieval Augment Code Generation?</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zora Zhiruo Wang<sup class="ltx_sup" id="id12.11.id1"><span class="ltx_text ltx_font_italic" id="id12.11.id1.1">♠</span></sup>  Akari Asai<sup class="ltx_sup" id="id13.12.id2"><span class="ltx_text ltx_font_italic" id="id13.12.id2.1">♢∗</span></sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id3.3.1">Xinyan Velocity Yu<sup class="ltx_sup" id="id3.3.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id3.3.1.1.1">♡</span></sup></span>  <span class="ltx_text ltx_font_bold" id="id14.13.id3">Frank F. Xu</span> <sup class="ltx_sup" id="id15.14.id4"><span class="ltx_text ltx_font_italic" id="id15.14.id4.1">♠</span></sup>  <span class="ltx_text ltx_font_bold" id="id16.15.id5">Yiqing Xie</span> <sup class="ltx_sup" id="id17.16.id6"><span class="ltx_text ltx_font_italic" id="id17.16.id6.1">♠</span></sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id18.17.id7">Graham Neubig</span> <sup class="ltx_sup" id="id19.18.id8"><span class="ltx_text ltx_font_italic" id="id19.18.id8.1">♠</span></sup>  <span class="ltx_text ltx_font_bold" id="id20.19.id9">Daniel Fried</span> <sup class="ltx_sup" id="id21.20.id10"><span class="ltx_text ltx_font_italic" id="id21.20.id10.1">♠</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id22.21.id11"><span class="ltx_text ltx_font_italic" id="id22.21.id11.1">♠</span></sup>Carnegie Mellon University  <sup class="ltx_sup" id="id23.22.id12"><span class="ltx_text ltx_font_italic" id="id23.22.id12.1">♢</span></sup>University of Washington  <sup class="ltx_sup" id="id24.23.id13"><span class="ltx_text ltx_font_italic" id="id24.23.id13.1">♡</span></sup>University of Southern California 
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://code-rag-bench.github.io/" title="">https://code-rag-bench.github.io/</a>
</span><span class="ltx_author_notes">Equal contribution.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id25.id1">While language models (LMs) have proven remarkably adept at generating code, many programs are challenging for LMs to generate using their parametric knowledge alone.
Providing external contexts such as library documentation can facilitate generating accurate and functional code.
Despite the success of retrieval-augmented generation (RAG) in various text-oriented tasks, its potential for improving code generation remains under-explored.
In this work, we conduct a systematic, large-scale analysis by asking: <span class="ltx_text ltx_font_italic" id="id25.id1.1">in what scenarios can retrieval benefit code generation models?</span> and <span class="ltx_text ltx_font_italic" id="id25.id1.2">what challenges remain?</span>
We first curate a comprehensive evaluation benchmark, <span class="ltx_text ltx_font_smallcaps" id="id25.id1.3">CodeRAG-Bench</span>, encompassing three categories of code generation tasks, including basic programming, open-domain, and repository-level problems.
We aggregate documents from five sources for models to retrieve contexts: competition solutions, online tutorials, library documentation, StackOverflow posts, and GitHub repositories.
We examine top-performing models on <span class="ltx_text ltx_font_smallcaps" id="id25.id1.4">CodeRAG-Bench</span> by providing contexts retrieved from one or multiple sources.
While notable gains are made in final code generation by retrieving high-quality contexts across various settings, our analysis reveals room for improvement—current retrievers still struggle to fetch useful contexts especially with limited lexical overlap, and generators fail to improve with limited context lengths or abilities to integrate additional contexts.
We hope <span class="ltx_text ltx_font_smallcaps" id="id25.id1.5">CodeRAG-Bench</span> serves as an effective testbed to encourage further development of advanced code-oriented RAG methods.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The task of generating program code from natural language (NL) descriptions has rapidly advanced with language models (LMs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib34" title="">34</a>]</cite>.
While more advanced code generation models are constantly emerging <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib10" title="">10</a>]</cite>, most of these models employ an NL-to-code generation paradigm without the ability to integrate additional context.
However, it is often challenging to directly generate programs without additional information in many complex coding scenarios, e.g., when using unfamiliar libraries that models cannot easily memorize <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib15" title="">15</a>]</cite>.
Further, solely relying on parametric knowledge learned during training also makes it harder to adapt generation to new distributions during testing <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib2" title="">2</a>]</cite>. For example, models are unable to stay up-to-date with continuously-evolving public libraries <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib47" title="">47</a>]</cite>, or private code bases that are not included in the pre-training data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib15" title="">15</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib11" title="">11</a>]</cite> retrieves and incorporates relevant documents at inference time. RAG reduces the need to include all knowledge within model parameters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib2" title="">2</a>]</cite>, leading to accuracy improvements in various scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib13" title="">13</a>]</cite>, even without additional training <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib25" title="">25</a>]</cite>.
It also allows for flexible knowledge updates by swapping datastores—large-scale data used during inference.
Nevertheless, prior work often focuses on general-domain text-oriented generation tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib30" title="">30</a>]</cite> using a general datastore such as Wikipedia <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib2" title="">2</a>]</cite>.
While several works explore ways to incorporate library documents <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib37" title="">37</a>]</cite> or files within a repository <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib15" title="">15</a>]</cite>, retrieval-augmented approaches on other types of coding problems and diverse retrieval sources are still largely underexplored.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="430" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of <span class="ltx_text ltx_font_smallcaps" id="S1.F1.2.1">CodeRAG-Bench</span>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.2">We propose a new evaluation benchmark, <span class="ltx_text ltx_font_smallcaps" id="S1.p3.2.1">CodeRAG-Bench</span>, to fill the gap and facilitate research on an alternative paradigm—retrieval-augmented code generation (RACG; §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2" title="2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2</span></a>).
<span class="ltx_text ltx_font_smallcaps" id="S1.p3.2.2">CodeRAG-Bench</span> (depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">1</span></a>) integrates six programming tasks of four categories: basic programming, open-domain coding, repository-level, and code retrieval problems.
To analyze the effectiveness of diverse code-related datastores, we also collect a range of retrieval documents from five sources: programming solutions, tutorials from online platforms, Python library documentation, StackOverflow (SO) posts, and GitHub files.
Further, for each problem, we manually annotate ground-truth documents from their corresponding sources, as a reference for RACG.
In summary, <span class="ltx_text ltx_font_smallcaps" id="S1.p3.2.3">CodeRAG-Bench</span> gathers 9<math alttext="k" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_k</annotation></semantics></math> coding problems and 25<math alttext="M" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mi id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S1.p3.2.m2.1d">italic_M</annotation></semantics></math> retrieval documents, empowering experiments of various setups, and provides reproducible and reliable retrieval and end-to-end execution-based evaluations for RACG.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Based on this benchmark, we conduct holistic evaluations in retrieval, generation, and RACG scenarios (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3" title="3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3</span></a>).
Although code generation models can benefit from ground-truth documents in multiple scenarios, current retrieval models struggle with selecting accurate documents, especially for open-domain tasks. Meanwhile, many code generation models experience little gains due to their limited context capacity to consume retrieved documents, or limited ability to do RACG effectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Beyond canonical retrieval (i.e., from the ground-truth source), we also explore RACG with open retrieval, i.e., retrieving documents from various sources with different chunking strategies (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S4" title="4 RACG with Open Retrieval ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">4</span></a>).
We find that each type of coding task can benefit from functionally relevant snippets from certain sources, and chunking documents to 200–800 tokens often gives the best results.
We hope <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.1">CodeRAG-Bench</span> can serve as a testbed for future work exploring, analyzing, and improving RACG systems.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>The <span class="ltx_text ltx_font_smallcaps" id="S2.1.1">CodeRAG-Bench</span>
</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">For <span class="ltx_text ltx_font_smallcaps" id="S2.p1.1.1">CodeRAG-Bench</span> (Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">1</span></a>), the curation methodology is motivated by the following three factors: (i) <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">Diverse tasks</span>: Code generation involves versatile tasks that operate on different levels (line, function, repository) and various domains (closed, open). (ii) <span class="ltx_text ltx_font_bold" id="S2.p1.1.3">Rigorous and reproducible evaluation</span>: We provide high-quality annotation of ground-truth documents to enable retrieval evaluation, and execution-based evaluation for all code generation tasks to rigorously measure functional correctness. (iii) <span class="ltx_text ltx_font_bold" id="S2.p1.1.4">Unified interface</span>: While current datasets utilize heterogeneous pipelines, our codebase provides a unified interface for retrieval, augmented generation, and evaluation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In this section, we introduce the creation process of <span class="ltx_text ltx_font_smallcaps" id="S2.p2.1.1">CodeRAG-Bench</span>: programming problem integration (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS1" title="2.1 Programming Problems ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.1</span></a>), retrieval source collection (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS2" title="2.2 Retrieval Sources ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.2</span></a>), canonical document annotation (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS3" title="2.3 Canonical Document Annotation ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.3</span></a>), and the evaluation pipeline (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS4" title="2.4 Evaluation Metrics ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.4</span></a>).
Examples with canonical documents are available in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A2" title="Appendix B Example Illustrations ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Programming Problems</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">We categorize existing Python-based coding datasets into four types:<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In this work we focus on Python-related tasks because it is the most widely-used programming language for benchmarking code generation. We leave extensions to other programming languages for future work.</span></span></span> code retrieval, basic programming, open-domain problems, and repository-level problems.
To ensure the diversity of datasets, we choose and unify multiple frequently adopted datasets for each category, as listed in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S2.T1" title="Table 1 ‣ 2.1 Programming Problems ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 1</span></a>.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overview of the datasets in CodeRAG-Bench. CSN stands for CodeSearchNet.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.1" style="width:424.9pt;height:159.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-3.3pt,1.2pt) scale(0.984903721544705,0.984903721544705) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S2.T1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1">Type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S2.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.2.1">Dataset</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.3.1"># Examples</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.4.1">Ground-Truth Docs</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.5.1">Evaluation</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.1.2.2.1" rowspan="3"><span class="ltx_text" id="S2.T1.1.1.2.2.1.1">Basic programming</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T1.1.1.2.2.2">HumanEval</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.2.2.3">  164</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.2.2.4">program solutions</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.2.2.5">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.1.3.3.1">MBPP</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.3.3.2">  500</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.3.3.3">program solutions</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.3.3.4">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.1.4.4.1">LiveCodeBench</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.4.4.2">  400</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.4.4.3">-</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.4.4.4">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.1.5.5.1" rowspan="2"><span class="ltx_text" id="S2.T1.1.1.5.5.1.1">Open-domain</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T1.1.1.5.5.2">DS-1000</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.5.5.3">1000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.5.5.4">docs</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.5.5.5">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.1.6.6.1">ODEX</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.6.6.2">  945</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.6.6.3">docs, stackoverflow</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.6.6.4">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.1.7.7.1" rowspan="2"><span class="ltx_text" id="S2.T1.1.1.7.7.1.1">Repository-level</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S2.T1.1.1.7.7.2">RepoEval (function)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.7.7.3">  373</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.7.7.4">github repository</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.7.7.5">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S2.T1.1.1.8.8.1">SWE-bench-Lite</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.8.8.2">  300</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.8.8.3">github repository</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.8.8.4">execution</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.9.1">Code retrieval</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S2.T1.1.1.9.9.2">CodeSearchNet-Py</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.9.3">22177</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.9.4">CSN functions</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.9.5">ndcg@10</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">Basic programming problems</span>  This category include interview-style problems that mostly require Python built-in operations and pose algorithmic challenges.
We select the two most widely used datasets: HumanEval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib5" title="">5</a>]</cite> and MBPP <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib3" title="">3</a>]</cite>, which ask the model to complete a function from an NL problem description.
However, due to limited public knowledge about model training data, it is unclear whether models suffer from data contamination on HumanEval and MBPP <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib14" title="">14</a>]</cite>. Hence, we also include LiveCodeBench <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib14" title="">14</a>]</cite> with problems collected from coding websites after the training cutoff of LMs that we consider, to decrease the risk of contamination.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.1">Open-domain problems</span>  Open-domain coding problems require Python libraries beyond the standard libraries used in basic programming problems.
We adopt the DS-1000 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib17" title="">17</a>]</cite> and ODEX <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib42" title="">42</a>]</cite> datasets that cover data-science and general open-domain coding problems.
DS-1000 collects data science problems with programs using seven common data-related libraries such as <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p3.1.2">pandas</span> and <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p3.1.3">numpy</span>.
ODEX covers problems using a broader range of 79 libraries, such as web requests with <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p3.1.4">requests</span> and database operations with <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p3.1.5">sqlalchemy</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p4.1.1">Repository-level coding problems</span>  Beyond function-level coding, some problems require editing files in the context of an entire GitHub repository.
We thus adopt RepoEval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib46" title="">46</a>]</cite> and SWE-bench <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib15" title="">15</a>]</cite> for repository-level code generation and issue-solving tasks.
We integrate all three splits of RepoEval but only report its function split, as it is the only split supporting execution-based evaluation.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Two other splits (API and line completion) are evaluated by lexical measures that have been shown as ineffective in signifying functional correctness <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib42" title="">42</a>]</cite>.</span></span></span>
Notably, our codebase is the first to provide reproducible execution evaluation on RepoEval.
SWE-bench focuses on resolving GitHub issues by asking models to edit multiple files that pass the required test cases. However, due to reproducibility issues on the full dataset,<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/princeton-nlp/SWE-bench/issues" title="">https://github.com/princeton-nlp/SWE-bench/issues</a></span></span></span> we use SWE-bench-Lite,<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.swebench.com/lite.html" title="">https://www.swebench.com/lite.html</a></span></span></span> a 300-problem subset whose results can be reproduced, in addition to a packaged Docker container<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/OpenDevin/OpenDevin/tree/main/evaluation/swe_bench#opendevin-swe-bench-docker-image" title="">https://github.com/OpenDevin/OpenDevin/tree/main/evaluation/swe_bench#opendevin-swe-bench-docker-image</a></span></span></span> with the pre-populated evaluation environment setup.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p5.1.1">Code retrieval problems</span>  In addition to retrieval for augmenting generations, we adopt the Python split of CodeSearchNet (CSN) as a code retrieval task. CSN searches for the correct implementation of an NL query from a pool of functions collected from GitHub repositories.
Instead of monitoring how generation changes with various retrieval results, CSN can directly measure retrieval quality.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Retrieval Sources</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We collect retrieval documents from five commonly used resources for program developers, listed in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S2.T2" title="Table 2 ‣ 2.2 Retrieval Sources ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 2</span></a>.
<span class="ltx_text ltx_font_smallcaps" id="S2.SS2.p1.1.1">CodeRAG-Bench</span>  supports two retrieval setups: <span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.2">canonical retrieval</span>—retrieves documents from only the canonical datastore (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS3" title="2.3 Canonical Document Annotation ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.3</span></a>), and <span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.3">open retrieval</span>—retrieves documents from any datastore.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S2.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Five retrieval sources.</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T2.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.5.6.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.5.6.1.1.1">Resource</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T2.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S2.T2.5.6.1.2.1">Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T2.5.6.1.3"><span class="ltx_text ltx_font_bold" id="S2.T2.5.6.1.3.1">Length</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.1.1.2">Programming solutions</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.1">1.1<math alttext="k" class="ltx_Math" display="inline" id="S2.T2.1.1.1.m1.1"><semantics id="S2.T2.1.1.1.m1.1a"><mi id="S2.T2.1.1.1.m1.1.1" xref="S2.T2.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.m1.1b"><ci id="S2.T2.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.T2.1.1.1.m1.1d">italic_k</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.3">194.6</td>
</tr>
<tr class="ltx_tr" id="S2.T2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.2.2.2">Online tutorials</th>
<td class="ltx_td ltx_align_right" id="S2.T2.2.2.1">79.4<math alttext="k" class="ltx_Math" display="inline" id="S2.T2.2.2.1.m1.1"><semantics id="S2.T2.2.2.1.m1.1a"><mi id="S2.T2.2.2.1.m1.1.1" xref="S2.T2.2.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.1.m1.1b"><ci id="S2.T2.2.2.1.m1.1.1.cmml" xref="S2.T2.2.2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.T2.2.2.1.m1.1d">italic_k</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right" id="S2.T2.2.2.3">1502.5</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.3.3.2">Library documentation</th>
<td class="ltx_td ltx_align_right" id="S2.T2.3.3.1">34<math alttext="k" class="ltx_Math" display="inline" id="S2.T2.3.3.1.m1.1"><semantics id="S2.T2.3.3.1.m1.1a"><mi id="S2.T2.3.3.1.m1.1.1" xref="S2.T2.3.3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.1.m1.1b"><ci id="S2.T2.3.3.1.m1.1.1.cmml" xref="S2.T2.3.3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.T2.3.3.1.m1.1d">italic_k</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right" id="S2.T2.3.3.3">953.4</td>
</tr>
<tr class="ltx_tr" id="S2.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.4.4.2">StackOverflow posts</th>
<td class="ltx_td ltx_align_right" id="S2.T2.4.4.1">23.5<math alttext="M" class="ltx_Math" display="inline" id="S2.T2.4.4.1.m1.1"><semantics id="S2.T2.4.4.1.m1.1a"><mi id="S2.T2.4.4.1.m1.1.1" xref="S2.T2.4.4.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.T2.4.4.1.m1.1b"><ci id="S2.T2.4.4.1.m1.1.1.cmml" xref="S2.T2.4.4.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.4.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.T2.4.4.1.m1.1d">italic_M</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right" id="S2.T2.4.4.3">689.2</td>
</tr>
<tr class="ltx_tr" id="S2.T2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T2.5.5.2">Github files</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T2.5.5.1">1.7<math alttext="M" class="ltx_Math" display="inline" id="S2.T2.5.5.1.m1.1"><semantics id="S2.T2.5.5.1.m1.1a"><mi id="S2.T2.5.5.1.m1.1.1" xref="S2.T2.5.5.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.T2.5.5.1.m1.1b"><ci id="S2.T2.5.5.1.m1.1.1.cmml" xref="S2.T2.5.5.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.5.5.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.T2.5.5.1.m1.1d">italic_M</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T2.5.5.3">5135.4</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Programming solutions</span>  We create one document from each basic programming problems that have canonical solutions (i.e., HumanEval and MBPP), following <cite class="ltx_cite ltx_citemacro_citet">VoyageAI [<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib40" title="">40</a>]</cite>, by concatenating its NL problem and program solution.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">Online tutorials</span>  We collect tutorials from multiple websites including GeeksforGeeks, W3Schools, tutorialspoint, and Towards Data Science,<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://geeksforgeeks.org" title="">https://geeksforgeeks.org</a>; <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.w3schools.com/" title="">https://www.w3schools.com/</a>; <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.tutorialspoint.com/" title="">https://www.tutorialspoint.com/</a>; <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://towardsdatascience.com" title="">https://towardsdatascience.com</a></span></span></span> via the raw HTML pages obtained from ClueWeb22 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib29" title="">29</a>]</cite>, a large-scale crawled web corpus.
Each page contains code snippets and their text explanations, covering topics from basic programming techniques to advanced library usage.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p4.1.1">Library documentation</span>  We collect the official documentation provided by <a class="ltx_ref ltx_url ltx_font_typewriter" href="devdocs.io" title="">devdocs.io</a> for all Python libraries following <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib47" title="">47</a>]</cite>. These could be especially useful for open-domain and repository-level problems that use some library functions to realize complex setups.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p5.1.1">StackOverflow posts</span>  StackOverflow (SO) is among the most frequently visited sites for developers.
We collect all SO posts from the RedPajama-1T <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib7" title="">7</a>]</cite> <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p5.1.2">stackexchange</span> split. We treat each post as a retrievable document, that has a question description, code responses, and textual explanations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p6.1.1">GitHub repository</span>  Lastly, we collect high-quality repositories from GitHub, using the <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p6.1.2">github</span> split of RedPajama-1T <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib7" title="">7</a>]</cite>, as developers often refer to popular repositories when writing their own programs.
Following this practical paradigm, we enable LMs to retrieve files from other GitHub repositories as contexts to write the current program.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Canonical Document Annotation</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">To enable reliable retrieval evaluation and estimate the upper bound of a RACG system with a perfect retriever, it is crucial that all examples include <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.1">canonical documents</em>: the document(s) containing the supporting contexts needed to solve the programming problem.
However, because RACG is under-explored, most existing datasets do not provide these canonical documents.
Therefore, we annotate the canonical documents from their corresponding retrieval pool, as listed in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S2.T1" title="Table 1 ‣ 2.1 Programming Problems ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">Basic programming problems</span>  The canonical document for each example in HumanEval and MBPP is the document we created in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS2" title="2.2 Retrieval Sources ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.2</span></a> in the <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.2">programming solutions</span> pool.
Since LiveCodeBench does not provide solutions to its problems, we do not annotate canonical documents for it.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p3.1.1">Open-domain problems</span>  Since open-domain problems require libraries, we annotate the canonical <span class="ltx_text ltx_font_italic" id="S2.SS3.p3.1.2">library documentation</span> for DS-1000 and ODEX examples.
We first automatically parse out the library functions used in each program, and find their corresponding documentation entries. Then, we manually verify the functions and remove incorrect ones. This yields an average of 1.4 and 1.2 entries for DS-1000 and ODEX.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p4.1.1">Repository-level problems</span>  We adopt <em class="ltx_emph ltx_font_italic" id="S2.SS3.p4.1.2">canonical code</em> from the original dataset as our canonical documents: 20-line code snippets of the missing functions in RepoEval, and the ground-truth edited files in SWE-bench. We obtain these from the completed local repositories from the original datasets.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Evaluation Metrics</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">For retrieval, we evaluate NDCG, Precision and Recall <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib39" title="">39</a>]</cite> and use NDCG@10 percentage as our primary metric, following prior work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib12" title="">12</a>]</cite>.
We only evaluate the canonical retrieval setup.
For code generation, we adopt the pass@k metric <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib5" title="">5</a>]</cite> to measure the execution correctness of programs. We evaluate the final RAG performance both in canonical and open retrieval setups.</p>
</div>
<figure class="ltx_table" id="S2.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Retrieval performance (NDCG@10) on code generation datasets. We do not evaluate LiveCodeBench because no ground-truth solutions are provided. RepoEval is function level with 2k context tokens. The numbers next to the method names indicate their embedding dimension size. </figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T3.7.7" style="width:416.3pt;height:161.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.1pt,9.7pt) scale(0.892341570306142,0.892341570306142) ;">
<table class="ltx_tabular ltx_align_middle" id="S2.T3.7.7.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T3.7.7.7.8.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S2.T3.7.7.7.8.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T3.7.7.7.8.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S2.T3.7.7.7.8.1.2"><span class="ltx_text ltx_font_bold" id="S2.T3.7.7.7.8.1.2.1">Problem Solutions</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S2.T3.7.7.7.8.1.3"><span class="ltx_text ltx_font_bold" id="S2.T3.7.7.7.8.1.3.1">Library Docs</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S2.T3.7.7.7.8.1.4"><span class="ltx_text ltx_font_bold" id="S2.T3.7.7.7.8.1.4.1">In-Repository Files</span></td>
</tr>
<tr class="ltx_tr" id="S2.T3.7.7.7.9.2">
<td class="ltx_td ltx_align_center" id="S2.T3.7.7.7.9.2.1">HumanEval</td>
<td class="ltx_td ltx_align_center" id="S2.T3.7.7.7.9.2.2">MBPP</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.7.7.7.9.2.3">CSN</td>
<td class="ltx_td ltx_align_center" id="S2.T3.7.7.7.9.2.4">DS-1000</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.7.7.7.9.2.5">ODEX</td>
<td class="ltx_td ltx_align_center" id="S2.T3.7.7.7.9.2.6">RepoEval</td>
<td class="ltx_td ltx_align_center" id="S2.T3.7.7.7.9.2.7">SWE-bench-Lite</td>
</tr>
<tr class="ltx_tr" id="S2.T3.7.7.7.10.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.7.7.7.10.3.1">BM25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.7.7.7.10.3.2"><span class="ltx_text ltx_font_bold" id="S2.T3.7.7.7.10.3.2.1">100.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.7.7.7.10.3.3">98.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.7.7.7.10.3.4">89.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.7.7.7.10.3.5">5.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.7.7.7.10.3.6">6.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.7.7.7.10.3.7">93.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.7.7.7.10.3.8">43.0</td>
</tr>
<tr class="ltx_tr" id="S2.T3.1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.1.1.1.1.1">GIST-base (<math alttext="769" class="ltx_Math" display="inline" id="S2.T3.1.1.1.1.1.m1.1"><semantics id="S2.T3.1.1.1.1.1.m1.1a"><mn id="S2.T3.1.1.1.1.1.m1.1.1" xref="S2.T3.1.1.1.1.1.m1.1.1.cmml">769</mn><annotation-xml encoding="MathML-Content" id="S2.T3.1.1.1.1.1.m1.1b"><cn id="S2.T3.1.1.1.1.1.m1.1.1.cmml" type="integer" xref="S2.T3.1.1.1.1.1.m1.1.1">769</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.1.1.1.1.1.m1.1c">769</annotation><annotation encoding="application/x-llamapun" id="S2.T3.1.1.1.1.1.m1.1d">769</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.1.1.1.1.2">98.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.1.1.1.1.3">98.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.1.1.1.1.4">89.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.1.1.1.1.5">12.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.1.1.1.1.6">12.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.1.1.1.1.7">81.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.1.1.1.1.8">46.8</td>
</tr>
<tr class="ltx_tr" id="S2.T3.2.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.2.2.2.2.1">GIST-large (<math alttext="1024" class="ltx_Math" display="inline" id="S2.T3.2.2.2.2.1.m1.1"><semantics id="S2.T3.2.2.2.2.1.m1.1a"><mn id="S2.T3.2.2.2.2.1.m1.1.1" xref="S2.T3.2.2.2.2.1.m1.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S2.T3.2.2.2.2.1.m1.1b"><cn id="S2.T3.2.2.2.2.1.m1.1.1.cmml" type="integer" xref="S2.T3.2.2.2.2.1.m1.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.2.2.2.2.1.m1.1c">1024</annotation><annotation encoding="application/x-llamapun" id="S2.T3.2.2.2.2.1.m1.1d">1024</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S2.T3.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S2.T3.2.2.2.2.2.1">100.0</span></td>
<td class="ltx_td ltx_align_center" id="S2.T3.2.2.2.2.3">98.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.2.2.2.2.4">89.6</td>
<td class="ltx_td ltx_align_center" id="S2.T3.2.2.2.2.5">13.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.2.2.2.2.6">28.0</td>
<td class="ltx_td ltx_align_center" id="S2.T3.2.2.2.2.7">82.9</td>
<td class="ltx_td ltx_align_center" id="S2.T3.2.2.2.2.8">47.8</td>
</tr>
<tr class="ltx_tr" id="S2.T3.3.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.3.3.3.3.1">BGE-base (<math alttext="769" class="ltx_Math" display="inline" id="S2.T3.3.3.3.3.1.m1.1"><semantics id="S2.T3.3.3.3.3.1.m1.1a"><mn id="S2.T3.3.3.3.3.1.m1.1.1" xref="S2.T3.3.3.3.3.1.m1.1.1.cmml">769</mn><annotation-xml encoding="MathML-Content" id="S2.T3.3.3.3.3.1.m1.1b"><cn id="S2.T3.3.3.3.3.1.m1.1.1.cmml" type="integer" xref="S2.T3.3.3.3.3.1.m1.1.1">769</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.3.3.3.3.1.m1.1c">769</annotation><annotation encoding="application/x-llamapun" id="S2.T3.3.3.3.3.1.m1.1d">769</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S2.T3.3.3.3.3.2">99.7</td>
<td class="ltx_td ltx_align_center" id="S2.T3.3.3.3.3.3">98.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.3.3.3.3.4">90.0</td>
<td class="ltx_td ltx_align_center" id="S2.T3.3.3.3.3.5">10.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.3.3.3.3.6">22.0</td>
<td class="ltx_td ltx_align_center" id="S2.T3.3.3.3.3.7">77.5</td>
<td class="ltx_td ltx_align_center" id="S2.T3.3.3.3.3.8">44.9</td>
</tr>
<tr class="ltx_tr" id="S2.T3.4.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.4.4.4.4.1">BGE-large (<math alttext="1024" class="ltx_Math" display="inline" id="S2.T3.4.4.4.4.1.m1.1"><semantics id="S2.T3.4.4.4.4.1.m1.1a"><mn id="S2.T3.4.4.4.4.1.m1.1.1" xref="S2.T3.4.4.4.4.1.m1.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S2.T3.4.4.4.4.1.m1.1b"><cn id="S2.T3.4.4.4.4.1.m1.1.1.cmml" type="integer" xref="S2.T3.4.4.4.4.1.m1.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.4.4.4.4.1.m1.1c">1024</annotation><annotation encoding="application/x-llamapun" id="S2.T3.4.4.4.4.1.m1.1d">1024</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S2.T3.4.4.4.4.2">98.0</td>
<td class="ltx_td ltx_align_center" id="S2.T3.4.4.4.4.3"><span class="ltx_text ltx_font_bold" id="S2.T3.4.4.4.4.3.1">99.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="S2.T3.4.4.4.4.4.1">90.6</span></td>
<td class="ltx_td ltx_align_center" id="S2.T3.4.4.4.4.5">8.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.4.4.4.4.6">11.5</td>
<td class="ltx_td ltx_align_center" id="S2.T3.4.4.4.4.7">80.4</td>
<td class="ltx_td ltx_align_center" id="S2.T3.4.4.4.4.8">40.1</td>
</tr>
<tr class="ltx_tr" id="S2.T3.5.5.5.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.5.5.5.5.1">SFR-Mistral (<math alttext="4096" class="ltx_Math" display="inline" id="S2.T3.5.5.5.5.1.m1.1"><semantics id="S2.T3.5.5.5.5.1.m1.1a"><mn id="S2.T3.5.5.5.5.1.m1.1.1" xref="S2.T3.5.5.5.5.1.m1.1.1.cmml">4096</mn><annotation-xml encoding="MathML-Content" id="S2.T3.5.5.5.5.1.m1.1b"><cn id="S2.T3.5.5.5.5.1.m1.1.1.cmml" type="integer" xref="S2.T3.5.5.5.5.1.m1.1.1">4096</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.5.5.5.5.1.m1.1c">4096</annotation><annotation encoding="application/x-llamapun" id="S2.T3.5.5.5.5.1.m1.1d">4096</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center" id="S2.T3.5.5.5.5.2"><span class="ltx_text ltx_font_bold" id="S2.T3.5.5.5.5.2.1">100.0</span></td>
<td class="ltx_td ltx_align_center" id="S2.T3.5.5.5.5.3"><span class="ltx_text ltx_font_bold" id="S2.T3.5.5.5.5.3.1">99.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.5.5.5.5.4">-</td>
<td class="ltx_td ltx_align_center" id="S2.T3.5.5.5.5.5">19.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.5.5.5.5.6"><span class="ltx_text ltx_font_bold" id="S2.T3.5.5.5.5.6.1">37.1</span></td>
<td class="ltx_td ltx_align_center" id="S2.T3.5.5.5.5.7">83.8</td>
<td class="ltx_td ltx_align_center" id="S2.T3.5.5.5.5.8"><span class="ltx_text ltx_font_bold" id="S2.T3.5.5.5.5.8.1">62.7</span></td>
</tr>
<tr class="ltx_tr" id="S2.T3.6.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.6.6.6.6.1">Voyage-code (<math alttext="1536" class="ltx_Math" display="inline" id="S2.T3.6.6.6.6.1.m1.1"><semantics id="S2.T3.6.6.6.6.1.m1.1a"><mn id="S2.T3.6.6.6.6.1.m1.1.1" xref="S2.T3.6.6.6.6.1.m1.1.1.cmml">1536</mn><annotation-xml encoding="MathML-Content" id="S2.T3.6.6.6.6.1.m1.1b"><cn id="S2.T3.6.6.6.6.1.m1.1.1.cmml" type="integer" xref="S2.T3.6.6.6.6.1.m1.1.1">1536</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.6.6.6.6.1.m1.1c">1536</annotation><annotation encoding="application/x-llamapun" id="S2.T3.6.6.6.6.1.m1.1d">1536</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.6.6.6.6.2"><span class="ltx_text ltx_font_bold" id="S2.T3.6.6.6.6.2.1">100.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.6.6.6.6.3"><span class="ltx_text ltx_font_bold" id="S2.T3.6.6.6.6.3.1">99.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.6.6.6.6.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.6.6.6.6.5"><span class="ltx_text ltx_font_bold" id="S2.T3.6.6.6.6.5.1">33.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.6.6.6.6.6">26.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.6.6.6.6.7"><span class="ltx_text ltx_font_bold" id="S2.T3.6.6.6.6.7.1">94.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.6.6.6.6.8">29.1</td>
</tr>
<tr class="ltx_tr" id="S2.T3.7.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T3.7.7.7.7.1">OpenAI-03 (<math alttext="1536" class="ltx_Math" display="inline" id="S2.T3.7.7.7.7.1.m1.1"><semantics id="S2.T3.7.7.7.7.1.m1.1a"><mn id="S2.T3.7.7.7.7.1.m1.1.1" xref="S2.T3.7.7.7.7.1.m1.1.1.cmml">1536</mn><annotation-xml encoding="MathML-Content" id="S2.T3.7.7.7.7.1.m1.1b"><cn id="S2.T3.7.7.7.7.1.m1.1.1.cmml" type="integer" xref="S2.T3.7.7.7.7.1.m1.1.1">1536</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.7.7.7.7.1.m1.1c">1536</annotation><annotation encoding="application/x-llamapun" id="S2.T3.7.7.7.7.1.m1.1d">1536</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T3.7.7.7.7.2"><span class="ltx_text ltx_font_bold" id="S2.T3.7.7.7.7.2.1">100.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T3.7.7.7.7.3">98.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T3.7.7.7.7.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T3.7.7.7.7.5">18.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T3.7.7.7.7.6">16.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T3.7.7.7.7.7">93.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T3.7.7.7.7.8">43.3</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Canonical RACG: Experiments and Results</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We conduct baseline experiments with multiple top-performing retrieval and generation models on <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.1">CodeRAG-Bench</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS1" title="3.1 Experimental Setup ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.1</span></a>) using canonical data sources.
We report results of document retrieval (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS2" title="3.2 Retrieval Results ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.2</span></a>), direct NL-to-code generation (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS3" title="3.3 Generation with and without Canonical Documents ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.3</span></a>), and end-to-end RACG using retrieved context (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS4" title="3.4 Retrieval-Augmented Code Generation ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setup</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">Retrieval baselines</span>  We adopt top-performing retrievers from three categories: sparse retrievers, dense retrievers with open checkpoints, and proprietary APIs.
Concretely, we use BM25 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib33" title="">33</a>]</cite> to represent sparse retrievers that are often robust to domain adaptations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib39" title="">39</a>]</cite>.
We use dense retrievers of varying sizes, namely BGE-base/large <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib44" title="">44</a>]</cite>, GIST-base/large <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib35" title="">35</a>]</cite>, and SFR-Embedding-Mistral <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib26" title="">26</a>]</cite> which are among the top of the MTEB leaderboard <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib28" title="">28</a>]</cite>.
We use two proprietary retrieval APIs, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.2">voyage-code-2</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib40" title="">40</a>]</cite> and <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.3">openai-text-embedding-small-03</span>, which are the best options with reasonable cost in our preliminary study.
We also explore reranking with BGE-reranker-base <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib44" title="">44</a>]</cite>, which reranks the top-100 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.4">openai</span> retrieved documents before feeding into the generation models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Generation baselines</span>  We adopt both code-specific LMs and strong general text-oriented LMs.
For code-specific LMs, we use StarCoder2 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib23" title="">23</a>]</cite>, CodeGemma <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib38" title="">38</a>]</cite>, CodeLlama <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib34" title="">34</a>]</cite>, and DeepSeekCoder <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib10" title="">10</a>]</cite> in various sizes.
For general text LMs, we include three top-performing models: Llama3 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib27" title="">27</a>]</cite>, Command-R <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib6" title="">6</a>]</cite> specially optimized for RAG, and proprietary GPT models <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.2">gpt-3.5-turbo-0125</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.3">gpt-4</span>.
We use the instruct version of all generation models if available, since they often perform better than the base versions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.4"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.4.1">Experimental setup and hyper-parameters</span>  For retrieval, we implement BM25 retrievers using pyserini <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib21" title="">21</a>]</cite> with parameter <math alttext="k_{1}=1.2" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><msub id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.cmml">k</mi><mn id="S3.SS1.p3.1.m1.1.1.2.3" xref="S3.SS1.p3.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">1.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><eq id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></eq><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2">𝑘</ci><cn id="S3.SS1.p3.1.m1.1.1.2.3.cmml" type="integer" xref="S3.SS1.p3.1.m1.1.1.2.3">1</cn></apply><cn id="S3.SS1.p3.1.m1.1.1.3.cmml" type="float" xref="S3.SS1.p3.1.m1.1.1.3">1.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">k_{1}=1.2</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.2</annotation></semantics></math> and <math alttext="b=0.75" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mrow id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">b</mi><mo id="S3.SS1.p3.2.m2.1.1.1" xref="S3.SS1.p3.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><eq id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1.1"></eq><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝑏</ci><cn id="S3.SS1.p3.2.m2.1.1.3.cmml" type="float" xref="S3.SS1.p3.2.m2.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">b=0.75</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_b = 0.75</annotation></semantics></math>, and use sentence-transformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib32" title="">32</a>]</cite><span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sbert.net/" title="">https://sbert.net/</a></span></span></span> for all dense models with open checkpoints.
For code generation, we use temperature <math alttext="t=0.2" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mrow id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">t</mi><mo id="S3.SS1.p3.3.m3.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><eq id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1"></eq><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">𝑡</ci><cn id="S3.SS1.p3.3.m3.1.1.3.cmml" type="float" xref="S3.SS1.p3.3.m3.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">t=0.2</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_t = 0.2</annotation></semantics></math>, <math alttext="top\_p=0.95" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><mrow id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mrow id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2.2" xref="S3.SS1.p3.4.m4.1.1.2.2.cmml">t</mi><mo id="S3.SS1.p3.4.m4.1.1.2.1" xref="S3.SS1.p3.4.m4.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.p3.4.m4.1.1.2.3" xref="S3.SS1.p3.4.m4.1.1.2.3.cmml">o</mi><mo id="S3.SS1.p3.4.m4.1.1.2.1a" xref="S3.SS1.p3.4.m4.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.p3.4.m4.1.1.2.4" xref="S3.SS1.p3.4.m4.1.1.2.4.cmml">p</mi><mo id="S3.SS1.p3.4.m4.1.1.2.1b" xref="S3.SS1.p3.4.m4.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.p3.4.m4.1.1.2.5" mathvariant="normal" xref="S3.SS1.p3.4.m4.1.1.2.5.cmml">_</mi><mo id="S3.SS1.p3.4.m4.1.1.2.1c" xref="S3.SS1.p3.4.m4.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.p3.4.m4.1.1.2.6" xref="S3.SS1.p3.4.m4.1.1.2.6.cmml">p</mi></mrow><mo id="S3.SS1.p3.4.m4.1.1.1" xref="S3.SS1.p3.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><eq id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1.1"></eq><apply id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2"><times id="S3.SS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.p3.4.m4.1.1.2.1"></times><ci id="S3.SS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2.2">𝑡</ci><ci id="S3.SS1.p3.4.m4.1.1.2.3.cmml" xref="S3.SS1.p3.4.m4.1.1.2.3">𝑜</ci><ci id="S3.SS1.p3.4.m4.1.1.2.4.cmml" xref="S3.SS1.p3.4.m4.1.1.2.4">𝑝</ci><ci id="S3.SS1.p3.4.m4.1.1.2.5.cmml" xref="S3.SS1.p3.4.m4.1.1.2.5">_</ci><ci id="S3.SS1.p3.4.m4.1.1.2.6.cmml" xref="S3.SS1.p3.4.m4.1.1.2.6">𝑝</ci></apply><cn id="S3.SS1.p3.4.m4.1.1.3.cmml" type="float" xref="S3.SS1.p3.4.m4.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">top\_p=0.95</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_t italic_o italic_p _ italic_p = 0.95</annotation></semantics></math> and sample one response for all generations.
We prepend the top-5 retrieved documents to the original problems, and do not include other unnecessary contexts such as few-shot demonstrations.<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>For basic programming examples that have the exact answer in the canonical documents, we remove canonical solutions from retrieved documents to avoid disclosing the answer during generation.</span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Retrieval Results</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.T3" title="Table 3 ‣ 2.4 Evaluation Metrics ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3</span></a> shows diverse retrieval models’ performance across six tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Comparison of Lexical and Neural Retrievers</span>  BM25 has been widely used as a primary retrieval model in recent RACG work <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib15" title="">15</a>]</cite>, yet comprehensive comparisons against diverse retrieval systems are often under-explored.
While prior studies indicate that neural retrieval systems often underperform BM25 baselines in out-of-domain scenarios <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib39" title="">39</a>]</cite>,
our analysis of <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p2.1.2">CodeRAG-Bench</span> reveals that dense embedding models frequently surpass BM25.
We hypothesize that this is because many competitive retrieval models are trained on diverse tasks across various domains, including code data  <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib36" title="">36</a>]</cite>, enhancing their robustness in code retrieval setups.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.3.1">Do Larger Retrieval Models Perform Better?</span>  Among dense retrieval models, increasing model size often leads to better retrieval performance, similar to the trends observed in LMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib4" title="">4</a>]</cite>.
In particular, GIST-large (340<math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_M</annotation></semantics></math>) constantly outperforms GIST-base (110<math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_M</annotation></semantics></math>), and SFR-Mistral (7<math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_B</annotation></semantics></math>)
achieves the best performance among all open sparse and dense models on all tasks, surpassing OpenAI embedding on several tasks.
However, it is important to note that this model has the largest embedding dimension, likely exceeding those of proprietary retrieval systems with 1,536 hidden dimensions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Efficiency</span>  While larger retrieval models often outperform smaller ones, they often introduce significant costs. We analyze efficiency, focusing on (i) <span class="ltx_text ltx_font_italic" id="S3.SS2.p4.1.2">encoding latency</span>: latency to encode documents offline, and (ii) <span class="ltx_text ltx_font_italic" id="S3.SS2.p4.1.3">search latency</span>: latency to encode queries/documents and calculate their similarities, (iii) <span class="ltx_text ltx_font_italic" id="S3.SS2.p4.1.4">model storage requirements</span>, and (iv) <span class="ltx_text ltx_font_italic" id="S3.SS2.p4.1.5">index storage requirements</span>.
We conduct efficiency analysis on sampled CodeSearchNet Python data.<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>Due to the costs, we randomly sample 10k queries and 100k from CodeSearchNet Python split. For API models, we use a batch size of 64 for encoding.</span></span></span> See experimental details in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A3" title="Appendix C Additional Details about Retrieval Efficiency ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">C</span></a>. As shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S3.T4" title="Table 4 ‣ 3.2 Retrieval Results ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 4</span></a>,</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S3.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Efficiency analysis for document retrieval.</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T4.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.2.1">Encoding</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.3.1">Search</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.4.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T4.1.1.1.5.1">Index</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T4.1.2.1.1">BM25</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T4.1.2.1.2">0.15ms</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T4.1.2.1.3">0.02ms</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T4.1.2.1.4">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T4.1.2.1.5">141MB</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.3.2.1">GIST-base</th>
<td class="ltx_td ltx_align_right" id="S3.T4.1.3.2.2">3.7ms</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.3.2.3">9.7ms</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.3.2.4">440MB</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.3.2.5">307MB</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.4.3.1">GIST-large</th>
<td class="ltx_td ltx_align_right" id="S3.T4.1.4.3.2">13ms</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.4.3.3">18ms</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.4.3.4">1300MB</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.4.3.5">409MB</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.5.4.1">SFR-Mistral</th>
<td class="ltx_td ltx_align_right" id="S3.T4.1.5.4.2">316ms</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.5.4.3">113ms</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.5.4.4">14220MB</td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.5.4.5">1638 MB</td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.6.5" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T4.1.6.5.1"><span class="ltx_text" id="S3.T4.1.6.5.1.1" style="background-color:#E6E6E6;">Voyage-code</span></th>
<td class="ltx_td ltx_align_right" id="S3.T4.1.6.5.2"><span class="ltx_text" id="S3.T4.1.6.5.2.1" style="background-color:#E6E6E6;">22ms</span></td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.6.5.3"><span class="ltx_text" id="S3.T4.1.6.5.3.1" style="background-color:#E6E6E6;">40ms</span></td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.6.5.4"><span class="ltx_text" id="S3.T4.1.6.5.4.1" style="background-color:#E6E6E6;">-</span></td>
<td class="ltx_td ltx_align_right" id="S3.T4.1.6.5.5"><span class="ltx_text" id="S3.T4.1.6.5.5.1" style="background-color:#E6E6E6;">1172MB</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.1.7.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T4.1.7.6.1"><span class="ltx_text" id="S3.T4.1.7.6.1.1" style="background-color:#E6E6E6;">OpenAI-03</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T4.1.7.6.2"><span class="ltx_text" id="S3.T4.1.7.6.2.1" style="background-color:#E6E6E6;">31ms</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T4.1.7.6.3"><span class="ltx_text" id="S3.T4.1.7.6.3.1" style="background-color:#E6E6E6;">47ms</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T4.1.7.6.4"><span class="ltx_text" id="S3.T4.1.7.6.4.1" style="background-color:#E6E6E6;">-</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T4.1.7.6.5"><span class="ltx_text" id="S3.T4.1.7.6.5.1" style="background-color:#E6E6E6;">1172MB</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.2">BM25 indexing and searching takes only seconds to finish.
Compared to base-size GIST-base, the SFR-Mistral model is more powerful in retrieval, yet requires over 5<math alttext="\times" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mo id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><times id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">×</annotation></semantics></math> larger index storage, and adds nearly 100<math alttext="\times" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mo id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><times id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">×</annotation></semantics></math> latency to encode documents, suggesting that the efficiency aspect should also be carefully studied for RAG pipelines.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Generation with and without Canonical Documents</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">We first evaluate possible lower- and upper-bounds on RACG performance by testing generation (i) without any retrieval, and (ii) with ground-truth documents. We report both results in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S3.T5" title="Table 5 ‣ 3.3 Generation with and without Canonical Documents ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 5</span></a>.
Compared to the base generation without contexts, incorporating canonical contexts improves in most setups, and substantially so on <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">basic programming</span> problems.</p>
</div>
<figure class="ltx_table" id="S3.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Code generation pass@1 (i) without additional contexts (before the slash), and (ii) with ground-truth documents (after the slash). We only report (i) for LCB because LCB does not have ground-truth documents. We highlight results showing (ii) &gt; (i) with green (darker green when having 10+ increases), and otherwise with red.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T5.1" style="width:433.6pt;height:203.8pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-33.3pt,15.6pt) scale(0.866901277555647,0.866901277555647) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T5.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S3.T5.1.1.1.1.1" rowspan="3"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.1.1.1.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S3.T5.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.1.1.2.1">Basic Programming</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S3.T5.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.1.1.3.1">Open-Domain</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T5.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T5.1.1.1.1.4.1">Repo-Level</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.2.2">
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.2.2.1" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.2.2.1.1">HumanEval</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.2.2.2" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.2.2.2.1">MBPP</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.2.2.3" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.2.2.3.1">LCB</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.2.2.4" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.2.2.4.1">DS-1000</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.2.2.5" rowspan="2"><span class="ltx_text" id="S3.T5.1.1.2.2.5.1">ODEX</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.2.2.6">RepoEval</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.2.2.7">SWE-bench</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.3.3">
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.3.3.1">(function)</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.3.3.2">(Lite)</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T5.1.1.4.4.1">StarCoder2-7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.4.4.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.4.4.2.1" style="background-color:#E8F0CC;">31.7 / 94.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.4.4.3" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.4.4.3.1" style="background-color:#E8F0CC;">10.4 / 34.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.1.4.4.4">  1.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.4.4.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.4.4.5.1" style="background-color:#F4F8E6;">29.2 / 30.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.1.4.4.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.4.4.6.1" style="background-color:#F4F8E6;">14.6 / 17.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.4.4.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.4.4.7.1" style="background-color:#E8F0CC;">26.5 / 42.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.4.4.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.4.4.8.1" style="background-color:#F4F8E6;">0.0 / 0.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.5.5.1">CodeGemma-7B</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.5.5.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.5.5.2.1" style="background-color:#E8F0CC;">49.4 / 77.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.5.5.3" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.5.5.3.1" style="background-color:#F4F8E6;">48.0 / 52.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.5.5.4">21.5</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.5.5.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.5.5.5.1" style="background-color:#FFEBEB;">20.1 / 19.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.5.5.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.5.5.6.1" style="background-color:#FFEBEB;">18.9 / 18.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.5.5.7" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.5.5.7.1" style="background-color:#F4F8E6;">24.7 / 32.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.5.5.8">0.0 / 0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.6.6.1">CodeLlama-7B</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.6.6.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.6.6.2.1" style="background-color:#E8F0CC;">34.8 / 87.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.6.6.3" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.6.6.3.1" style="background-color:#E8F0CC;">23.8 / 42.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.6.6.4">13.5</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.6.6.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.6.6.5.1" style="background-color:#F4F8E6;">21.8 / 26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.6.6.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.6.6.6.1" style="background-color:#F4F8E6;">35.8 / 41.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.6.6.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.6.6.7.1" style="background-color:#E8F0CC;">24.1 / 38.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.6.6.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.6.6.8.1" style="background-color:#FFEBEB;">0.3 / 0.0</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.7.7.1">CodeLlama-34B</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.7.7.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.7.7.2.1" style="background-color:#E8F0CC;">42.7 / 84.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.7.7.3" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.7.7.3.1" style="background-color:#E8F0CC;">51.2 / 88.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.7.7.4">  5.8</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.7.7.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.7.7.5.1" style="background-color:#F4F8E6;">34.7 / 37.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.7.7.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.7.7.6.1" style="background-color:#F4F8E6;">34.9 / 38.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.7.7.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.7.7.7.1" style="background-color:#E8F0CC;">29.8 / 42.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.7.7.8">0.0 / 0.0</td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.8.8.1">DeepSeekCoder-7B</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.8.8.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.8.8.2.1" style="background-color:#E8F0CC;">70.1 / 87.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.8.8.3" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.8.8.3.1" style="background-color:#F4F8E6;">60.8 / 63.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.8.8.4">30.5</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.8.8.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.8.8.5.1" style="background-color:#F4F8E6;">41.4 / 43.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.8.8.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.8.8.6.1" style="background-color:#F4F8E6;">39.2 / 41.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.8.8.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.8.8.7.1" style="background-color:#E8F0CC;">28.2 / 43.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.8.8.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.8.8.8.1" style="background-color:#FFEBEB;">0.7 / 0.0</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.9.9.1">DeepSeekCoder-33B</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.9.9.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.9.9.2.1" style="background-color:#E8F0CC;">78.0 / 95.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.9.9.3" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.9.9.3.1" style="background-color:#E8F0CC;">61.0 / 92.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.9.9.4">33.8</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.9.9.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.9.9.5.1" style="background-color:#FFEBEB;">40.2 / 40.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.9.9.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.9.9.6.1" style="background-color:#F4F8E6;">28.0 / 28.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.9.9.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.9.9.7.1" style="background-color:#E8F0CC;">32.4 / 45.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.9.9.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.9.9.8.1" style="background-color:#F4F8E6;">0.3 / 0.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T5.1.1.10.10.1">Llama3-8B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.10.10.2" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.10.10.2.1" style="background-color:#F4F8E6;">57.9 / 65.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.10.10.3" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.10.10.3.1" style="background-color:#E8F0CC;">35.6 / 52.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.1.10.10.4">  2.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.10.10.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.10.10.5.1" style="background-color:#F4F8E6;">28.9 / 31.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T5.1.1.10.10.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.10.10.6.1" style="background-color:#FFEBEB;">37.4 / 33.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.10.10.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.10.10.7.1" style="background-color:#E8F0CC;">26.0 / 43.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T5.1.1.10.10.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.10.10.8.1" style="background-color:#FFEBEB;">0.7 / 0.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.11.11.1">Command-R</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.11.11.2" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.11.11.2.1" style="background-color:#F4F8E6;">43.3 / 51.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.11.11.3" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.11.11.3.1" style="background-color:#F4F8E6;">37.2 / 37.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.11.11.4">10.0</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.11.11.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.11.11.5.1" style="background-color:#F4F8E6;">25.8 / 28.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.11.11.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.11.11.6.1" style="background-color:#F4F8E6;">35.5 / 36.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.11.11.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.11.11.7.1" style="background-color:#E8F0CC;">23.9 / 37.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.11.11.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.11.11.8.1" style="background-color:#F4F8E6;">0.0 / 0.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T5.1.1.12.12.1">GPT-3.5-turbo</th>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.12.12.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.12.12.2.1" style="background-color:#E8F0CC;">72.6 / 91.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.12.12.3" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.12.12.3.1" style="background-color:#F4F8E6;">70.8 / 72.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.12.12.4">35.3</td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.12.12.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.12.12.5.1" style="background-color:#FFEBEB;">43.7 / 42.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T5.1.1.12.12.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.12.12.6.1" style="background-color:#FFEBEB;">41.7 / 40.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.12.12.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.12.12.7.1" style="background-color:#E8F0CC;">23.9 / 39.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.1.1.12.12.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.12.12.8.1" style="background-color:#F4F8E6;">0.7 / 2.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S3.T5.1.1.13.13.1">GPT-4</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.1.13.13.2" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.13.13.2.1" style="background-color:#E8F0CC;">75.6 / 92.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.1.13.13.3" style="background-color:#F4F8E6;"><span class="ltx_text" id="S3.T5.1.1.13.13.3.1" style="background-color:#F4F8E6;">79.4 / 81.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T5.1.1.13.13.4">43.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.1.13.13.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.13.13.5.1" style="background-color:#FFEBEB;">52.7 / 51.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T5.1.1.13.13.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S3.T5.1.1.13.13.6.1" style="background-color:#FFEBEB;">44.6 / 44.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.1.13.13.7" style="background-color:#E8F0CC;"><span class="ltx_text" id="S3.T5.1.1.13.13.7.1" style="background-color:#E8F0CC;">32.4 / 46.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.1.1.13.13.8">2.3 / 2.3</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">On open-domain problems</span>, most code-specific LMs experience increases of up to <math alttext="5.2" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mn id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">5.2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><cn id="S3.SS3.p2.1.m1.1.1.cmml" type="float" xref="S3.SS3.p2.1.m1.1.1">5.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">5.2</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">5.2</annotation></semantics></math> points, signifying that most models can effectively consume indirectly helpful documentation.
Among all general LMs, Command-R appears to be the only model benefiting from contexts for both datasets, consistent with its superior RAG ability.
However, the strongest GPT does not gain from contexts, likely due to its prior familiarity with these libraries, as well-trained models are known to memorize popular facts and benefit little from retrieval for them <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib16" title="">16</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.3"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.3.1">On repository-level problems</span>, all models increase by <math alttext="7.5" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mn id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">7.5</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><cn id="S3.SS3.p3.1.m1.1.1.cmml" type="float" xref="S3.SS3.p3.1.m1.1.1">7.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">7.5</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">7.5</annotation></semantics></math>–<math alttext="17.2" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mn id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">17.2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><cn id="S3.SS3.p3.2.m2.1.1.cmml" type="float" xref="S3.SS3.p3.2.m2.1.1">17.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">17.2</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">17.2</annotation></semantics></math> points from canonical snippets in RepoEval. SWE-bench Lite, however, is much harder, with even the strongest GPT model achieving only <math alttext="2.7\%" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mn id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">2.7</mn><mo id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="latexml" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1">percent</csymbol><cn id="S3.SS3.p3.3.m3.1.1.2.cmml" type="float" xref="S3.SS3.p3.3.m3.1.1.2">2.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">2.7\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">2.7 %</annotation></semantics></math> in the canonical setting.
We conjecture that the difficulty comes from both complex multi-file editing and long contexts that stress the limits of most models.
We leave the endeavor to integrate better inference-time strategies <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib45" title="">45</a>]</cite> with RAG to future work.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">Larger models gain as much as their smaller variants, showing that RACG generally helps models of varied capacities.
However, to unleash the full power of RACG, weaker LMs need to (i) extend their context lengths to take more documents, and (ii) further enhance their ability to consume contexts.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Retrieval-Augmented Code Generation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">We now experiment with top-performing retrieval and generation models in the full RACG setting, which requires both retrieve documents and generating conditioned on the documents.
We select the best retrieval models from each type: BM25, GIST-large, and OpenAI and Voyager embeddings.
For generation, we select (i) StarCoder2-7B: a weaker model that benefits the most from contexts; (ii) DeepSeekCoder-7B: one of the strongest open code LMs; and (iii) GPT-3.5-turbo: a top proprietary model.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>We use deepseek-coder-7b/gpt-3.5-turbo instead of deepseek-coder-33b/gpt-4 due to resource limitations.</span></span></span>
For each dataset, we retrieve the most relevant contexts from its canonical source marked in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S2.T1" title="Table 1 ‣ 2.1 Programming Problems ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 1</span></a>,<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>For HumanEval and MBPP, we exclude the canonical document for each query and retrieve top 5 documents.</span></span></span> and retrieve <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.1">programming solutions</span> for LiveCodeBench.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S3.T6" title="Table 6 ‣ 3.4 Retrieval-Augmented Code Generation ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 6</span></a> shows the results.</p>
</div>
<figure class="ltx_table" id="S3.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance of retrieval-augmented code generation, with top-performing retrieval and generation models. We bold-type the best RACG result for each dataset. LCB stands for LiveCodeBench.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T6.1" style="width:416.3pt;height:433.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-17.0pt,17.7pt) scale(0.92431901981503,0.92431901981503) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T6.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T6.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S3.T6.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.2.1">General</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S3.T6.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.3.1">Open-Domain</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S3.T6.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.1.1.4.1">Repo-Level</span></th>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.1.1.2.2.1">HumanEval</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.1.1.2.2.2">MBPP</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T6.1.1.2.2.3">LCB</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.1.1.2.2.4">DS-1000</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T6.1.1.2.2.5">ODEX</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.1.1.2.2.6">RepoEval</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T6.1.1.2.2.7">SWE-bench-Lite</th>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="8" id="S3.T6.1.1.3.3.1"><span class="ltx_text ltx_font_italic" id="S3.T6.1.1.3.3.1.1">w/ StarCoder2-7B</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T6.1.1.4.1" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T6.1.1.4.1.1"><span class="ltx_text" id="S3.T6.1.1.4.1.1.1" style="background-color:#E6E6E6;">None</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.4.1.2"><span class="ltx_text" id="S3.T6.1.1.4.1.2.1" style="background-color:#E6E6E6;">31.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.4.1.3"><span class="ltx_text" id="S3.T6.1.1.4.1.3.1" style="background-color:#E6E6E6;">2.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.1.4.1.4"><span class="ltx_text" id="S3.T6.1.1.4.1.4.1" style="background-color:#E6E6E6;">1.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.4.1.5"><span class="ltx_text" id="S3.T6.1.1.4.1.5.1" style="background-color:#E6E6E6;">29.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.1.4.1.6"><span class="ltx_text" id="S3.T6.1.1.4.1.6.1" style="background-color:#E6E6E6;">14.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.4.1.7"><span class="ltx_text" id="S3.T6.1.1.4.1.7.1" style="background-color:#E6E6E6;">26.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.4.1.8"><span class="ltx_text" id="S3.T6.1.1.4.1.8.1" style="background-color:#E6E6E6;">0.0</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.5.2.1">BM25</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.5.2.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.5.2.2.1">43.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.5.2.3">51.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.5.2.4">1.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.5.2.5"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.5.2.5.1">36.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.5.2.6">14.1</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.5.2.7">36.7</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.5.2.8">0.0</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.6.3.1">GIST-large</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.6.3.2">38.7</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.6.3.3">50.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.6.3.4">0.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.6.3.5">35.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.6.3.6"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.6.3.6.1">17.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.6.3.7">40.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.6.3.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.7.4.1">Voyage, code</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.7.4.2">39.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.7.4.3">52.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.7.4.4">0.3</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.7.4.5">36.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.7.4.6">15.3</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.7.4.7">45.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.7.4.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.8.5.1">OpenAI, small</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.8.5.2">39.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.8.5.3">52.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.8.5.4"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.8.5.4.1">1.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.8.5.5">35.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.8.5.6">15.9</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.8.5.7">51.2</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.8.5.8">0.0</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.9.6.1"><span class="ltx_text ltx_font_italic" id="S3.T6.1.1.9.6.1.1">OpenAI, rerank</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.9.6.2">34.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.9.6.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.9.6.3.1">53.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.9.6.4">0.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.9.6.5">33.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.9.6.6">14.1</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.9.6.7"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.9.6.7.1">53.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.9.6.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.10.7" style="background-color:#FFF4D1;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.10.7.1"><span class="ltx_text" id="S3.T6.1.1.10.7.1.1" style="background-color:#FFF4D1;">Gold</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.10.7.2"><span class="ltx_text" id="S3.T6.1.1.10.7.2.1" style="background-color:#FFF4D1;">94.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.10.7.3"><span class="ltx_text" id="S3.T6.1.1.10.7.3.1" style="background-color:#FFF4D1;">34.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.10.7.4"><span class="ltx_text" id="S3.T6.1.1.10.7.4.1" style="background-color:#FFF4D1;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.10.7.5"><span class="ltx_text" id="S3.T6.1.1.10.7.5.1" style="background-color:#FFF4D1;">30.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.10.7.6"><span class="ltx_text" id="S3.T6.1.1.10.7.6.1" style="background-color:#FFF4D1;">17.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.10.7.7"><span class="ltx_text" id="S3.T6.1.1.10.7.7.1" style="background-color:#FFF4D1;">42.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.10.7.8"><span class="ltx_text" id="S3.T6.1.1.10.7.8.1" style="background-color:#FFF4D1;">0.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.11.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="8" id="S3.T6.1.1.11.8.1"><span class="ltx_text ltx_font_italic" id="S3.T6.1.1.11.8.1.1">w/ DeepseekCoder-7B-instruct</span></th>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.12.9" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T6.1.1.12.9.1"><span class="ltx_text" id="S3.T6.1.1.12.9.1.1" style="background-color:#E6E6E6;">None</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.12.9.2"><span class="ltx_text" id="S3.T6.1.1.12.9.2.1" style="background-color:#E6E6E6;">70.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.12.9.3"><span class="ltx_text" id="S3.T6.1.1.12.9.3.1" style="background-color:#E6E6E6;">60.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.1.12.9.4"><span class="ltx_text" id="S3.T6.1.1.12.9.4.1" style="background-color:#E6E6E6;">30.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.12.9.5"><span class="ltx_text" id="S3.T6.1.1.12.9.5.1" style="background-color:#E6E6E6;">41.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.1.12.9.6"><span class="ltx_text" id="S3.T6.1.1.12.9.6.1" style="background-color:#E6E6E6;">39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.12.9.7"><span class="ltx_text" id="S3.T6.1.1.12.9.7.1" style="background-color:#E6E6E6;">28.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.12.9.8"><span class="ltx_text" id="S3.T6.1.1.12.9.8.1" style="background-color:#E6E6E6;">0.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.13.10.1">BM25</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.13.10.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.13.10.2.1">68.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.13.10.3">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.13.10.4">31.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.13.10.5"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.13.10.5.1">36.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.13.10.6">37.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.13.10.7">37.3</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.13.10.8">0.0</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.14.11.1">GIST-large</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.14.11.2">66.3</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.14.11.3">56.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.14.11.4"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.14.11.4.1">33.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.14.11.5">35.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.14.11.6">34.9</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.14.11.7">44.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.14.11.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.15.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.15.12.1">Voyage, code</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.15.12.2">66.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.15.12.3">56.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.15.12.4">31.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.15.12.5">35.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.15.12.6"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.15.12.6.1">39.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.15.12.7">46.6</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.15.12.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.16.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.16.13.1">OpenAI, small</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.16.13.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.16.13.2.1">68.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.16.13.3">58.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.16.13.4">32.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.16.13.5">35.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.16.13.6">37.1</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.16.13.7">55.2</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.16.13.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.17.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.17.14.1"><span class="ltx_text ltx_font_italic" id="S3.T6.1.1.17.14.1.1">OpenAI, rerank</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.17.14.2">53.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.17.14.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.17.14.3.1">60.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.17.14.4">31.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.17.14.5">36.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.17.14.6">37.1</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.17.14.7"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.17.14.7.1">55.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.17.14.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.18.15" style="background-color:#FFF4D1;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.18.15.1"><span class="ltx_text" id="S3.T6.1.1.18.15.1.1" style="background-color:#FFF4D1;">Gold</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.18.15.2"><span class="ltx_text" id="S3.T6.1.1.18.15.2.1" style="background-color:#FFF4D1;">87.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.18.15.3"><span class="ltx_text" id="S3.T6.1.1.18.15.3.1" style="background-color:#FFF4D1;">63.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.18.15.4"><span class="ltx_text" id="S3.T6.1.1.18.15.4.1" style="background-color:#FFF4D1;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.18.15.5"><span class="ltx_text" id="S3.T6.1.1.18.15.5.1" style="background-color:#FFF4D1;">43.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.18.15.6"><span class="ltx_text" id="S3.T6.1.1.18.15.6.1" style="background-color:#FFF4D1;">41.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.18.15.7"><span class="ltx_text" id="S3.T6.1.1.18.15.7.1" style="background-color:#FFF4D1;">48.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.18.15.8"><span class="ltx_text" id="S3.T6.1.1.18.15.8.1" style="background-color:#FFF4D1;">0.0</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.19.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="8" id="S3.T6.1.1.19.16.1"><span class="ltx_text ltx_font_italic" id="S3.T6.1.1.19.16.1.1">w/ GPT-3.5-turbo</span></th>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.20.17" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T6.1.1.20.17.1"><span class="ltx_text" id="S3.T6.1.1.20.17.1.1" style="background-color:#E6E6E6;">None</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.20.17.2"><span class="ltx_text" id="S3.T6.1.1.20.17.2.1" style="background-color:#E6E6E6;">72.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.20.17.3"><span class="ltx_text" id="S3.T6.1.1.20.17.3.1" style="background-color:#E6E6E6;">70.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.1.20.17.4"><span class="ltx_text" id="S3.T6.1.1.20.17.4.1" style="background-color:#E6E6E6;">35.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.20.17.5"><span class="ltx_text" id="S3.T6.1.1.20.17.5.1" style="background-color:#E6E6E6;">43.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T6.1.1.20.17.6"><span class="ltx_text" id="S3.T6.1.1.20.17.6.1" style="background-color:#E6E6E6;">41.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.20.17.7"><span class="ltx_text" id="S3.T6.1.1.20.17.7.1" style="background-color:#E6E6E6;">23.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T6.1.1.20.17.8"><span class="ltx_text" id="S3.T6.1.1.20.17.8.1" style="background-color:#E6E6E6;">0.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.21.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.21.18.1">BM25</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.21.18.2">73.2</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.21.18.3">72.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.21.18.4"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.21.18.4.1">35.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.21.18.5">36.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.21.18.6"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.21.18.6.1">41.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.21.18.7">30.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.21.18.8">1.0</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.22.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.22.19.1">GIST-large</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.22.19.2">73.2</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.22.19.3">68.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.22.19.4">34.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.22.19.5">36.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.22.19.6">36.2</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.22.19.7">38.3</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.22.19.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.23.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.23.20.1">Voyage, code</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.23.20.2"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.23.20.2.1">75.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.23.20.3">66.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.23.20.4">34.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.23.20.5"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.23.20.5.1">37.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.23.20.6"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.23.20.6.1">41.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.23.20.7">43.2</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.23.20.8">0.7</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.24.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.24.21.1">OpenAI, small</th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.24.21.2">73.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.24.21.3">68.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.24.21.4">35.8</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.24.21.5">36.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.24.21.6">40.3</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.24.21.7">48.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.24.21.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.25.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T6.1.1.25.22.1"><span class="ltx_text ltx_font_italic" id="S3.T6.1.1.25.22.1.1">OpenAI, rerank</span></th>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.25.22.2">64.0</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.25.22.3"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.25.22.3.1">72.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.25.22.4">33.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.25.22.5"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.25.22.5.1">37.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T6.1.1.25.22.6">40.5</td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.25.22.7"><span class="ltx_text ltx_font_bold" id="S3.T6.1.1.25.22.7.1">49.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T6.1.1.25.22.8">0.3</td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1.26.23" style="background-color:#FFF4D1;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S3.T6.1.1.26.23.1"><span class="ltx_text" id="S3.T6.1.1.26.23.1.1" style="background-color:#FFF4D1;">Gold</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.1.26.23.2"><span class="ltx_text" id="S3.T6.1.1.26.23.2.1" style="background-color:#FFF4D1;">91.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.1.26.23.3"><span class="ltx_text" id="S3.T6.1.1.26.23.3.1" style="background-color:#FFF4D1;">72.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T6.1.1.26.23.4"><span class="ltx_text" id="S3.T6.1.1.26.23.4.1" style="background-color:#FFF4D1;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.1.26.23.5"><span class="ltx_text" id="S3.T6.1.1.26.23.5.1" style="background-color:#FFF4D1;">42.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T6.1.1.26.23.6"><span class="ltx_text" id="S3.T6.1.1.26.23.6.1" style="background-color:#FFF4D1;">40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.1.26.23.7"><span class="ltx_text" id="S3.T6.1.1.26.23.7.1" style="background-color:#FFF4D1;">39.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T6.1.1.26.23.8"><span class="ltx_text" id="S3.T6.1.1.26.23.8.1" style="background-color:#FFF4D1;">2.7</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.2.1">Basic programming problems</span>  Most retrieved contexts can help StarCoder2 generations. On MBPP, RACG even outperforms canonical setup by <math alttext="15.6" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><mn id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">15.6</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><cn id="S3.SS4.p2.1.m1.1.1.cmml" type="float" xref="S3.SS4.p2.1.m1.1.1">15.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">15.6</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">15.6</annotation></semantics></math>–<math alttext="17.8" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.1"><semantics id="S3.SS4.p2.2.m2.1a"><mn id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">17.8</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><cn id="S3.SS4.p2.2.m2.1.1.cmml" type="float" xref="S3.SS4.p2.2.m2.1.1">17.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">17.8</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.1d">17.8</annotation></semantics></math>.
However, RACG does not improve DeepSeekCoder generations, which we observe is due to over-complicated and ungrammatically repetitive generations when having additional contexts. This may indicate that DeepSeekCoder is not robust enough to extra contexts, and hence produces undesired behaviors when receiving different inputs.
In comparison, GPT-3.5-turbo can effectively improve with added contexts, showing its better ability to leverage augmented contexts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">Open-domain problems</span>  StarCoder2 substantially benefits from retrieved library documentation on both datasets, while DeepSeekCoder only improves on ODEX, and GPT-3.5 on neither.
We hypothesize that <span class="ltx_text ltx_font_italic" id="S3.SS4.p3.1.2">the less familiar the model is with the domain</span>, the more the model benefits from retrieving documents.
Meanwhile, <span class="ltx_text ltx_font_italic" id="S3.SS4.p3.1.3">poor retrieval results</span> can also impair the effectiveness of RACG. For example, DeepSeekCoder benefits from ground-truth documents (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS3" title="3.3 Generation with and without Canonical Documents ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.3</span></a>), but not from presumably lower-quality model-retrieved documents, indicating the need for better code retrieval models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p4.1.1">Repository-level problems</span>  All models can benefit from retrieved code snippets on RepoEval, and RACG with <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p4.1.2">openai-embeddings</span> can often surpass the canonical setup.
While some files do not include solutions (as in the canonical documents) to the problem, they may contain function definitions or usage examples that benefit end generation, suggesting that <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p4.1.3">openai-embeddings</span> understands the repository well and thus is able to retrieve implicitly supporting contexts.
However, SWE-bench-lite is too complex and no RACG setups can get a non-trivial result.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>How Many Documents to Augment?</h3>
<div class="ltx_para ltx_noindent" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">Different models have varied context length limits and context utilization abilities. Therefore, we study how model performance varies when providing different numbers of documents in the context.
We experiment with one representative dataset for each task category: HumanEval since it is the most commonly used dataset, ODEX for its broad domain coverage, and RepoEval for its solvable difficulty.
We compare RACG performance when providing top-1, 2, 5, and 10 documents.
</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="231" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparing RACG performance with various numbers of documents.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.2">As shown by <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S3.F2" title="Figure 2 ‣ 3.5 How Many Documents to Augment? ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>, including five documents yields the best results in most settings, except for StarCoder2 on RepoEval which best uses 8 documents.
Despite the drastic difference in the context limit of StarCoder2 (16<math alttext="k" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.1"><semantics id="S3.SS5.p2.1.m1.1a"><mi id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><ci id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.1.m1.1d">italic_k</annotation></semantics></math>) and DeepseekCoder (4<math alttext="k" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.1"><semantics id="S3.SS5.p2.2.m2.1a"><mi id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><ci id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.2.m2.1d">italic_k</annotation></semantics></math>), the sweet spot is consistently top-5 documents. While adding a few documents may include helpful contexts, adding more low-ranked documents may introduce noise and deteriorate generation due to the imperfections of retrieval systems <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib41" title="">41</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>RACG with Open Retrieval</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Besides retrieving documents from the canonical source, we explore RACG with open retrieval from all sources (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS2" title="2.2 Retrieval Sources ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.2</span></a>).
We experiment with three category-representative datasets (HumanEval, ODEX, and RepoEval) as in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS5" title="3.5 How Many Documents to Augment? ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.5</span></a>.
We also experiment with <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">mixed</span> retrieval documents from all sources, where we aggregate the top-1 documents from all five sources as additional contexts.<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>For all experiments in this section, we only include the first 500 tokens of each retrieved document, which we show to be optimal on average in ablation studies in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S4" title="4 RACG with Open Retrieval ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">4</span></a>, and satisfies the context limits of all models.</span></span></span></p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Can RACG Benefit Weaker Models?</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We use the three top-performing retrievers and the StarCoder2 generation model, as in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS4" title="3.4 Retrieval-Augmented Code Generation ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.4</span></a>, to examine if RACG helps weaker code LMs.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S4.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Comparing five retrieval sources on HumanEval. We highlight results better than the no-retrieval baseline 31.7 with green, bold-type the best results for each source, and mark results with the canonical source in gray.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T7.1" style="width:247.2pt;height:58.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.7pt,6.6pt) scale(0.816703348208298,0.816703348208298) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T7.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.1.1.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T7.1.1.1.1.2.1" style="background-color:#E6E6E6;">Program</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.1.1.3">Tutorial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.1.1.4">Docs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.1.1.5">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T7.1.1.1.1.6">GitHub</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.1.1.7">All</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.2.1.1">BM25</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T7.1.1.2.1.2.1" style="background-color:#E6E6E6;">97.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.3">27.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.2.1.4.1">29.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.5" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T7.1.1.2.1.5.1" style="background-color:#E6EFC7;">32.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.1.1.2.1.6">30.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.7" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T7.1.1.2.1.7.1" style="background-color:#E6EFC7;">97.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.1.3.2.1">GIST-large</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T7.1.1.3.2.2.1" style="background-color:#E6E6E6;">67.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.3" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.3.2.3.1" style="background-color:#E6EFC7;">34.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.4">26.7</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.5" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T7.1.1.3.2.5.1" style="background-color:#E6EFC7;">32.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.1.1.3.2.6" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.3.2.6.1" style="background-color:#E6EFC7;">32.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.7">69.1</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T7.1.1.4.3.1">OpenAI</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.1.4.3.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T7.1.1.4.3.2.1" style="background-color:#E6E6E6;">97.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.1.4.3.3">29.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.1.4.3.4">24.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.1.4.3.5" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.4.3.5.1" style="background-color:#E6EFC7;">36.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T7.1.1.4.3.6">31.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.1.4.3.7" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T7.1.1.4.3.7.1" style="background-color:#E6EFC7;">97.6</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.3.1">General Programming: HumanEval</span>  Among all sources, SO posts can improve the results by <math alttext="1.8" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">1.8</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><cn id="S4.SS1.p2.1.m1.1.1.cmml" type="float" xref="S4.SS1.p2.1.m1.1.1">1.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">1.8</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">1.8</annotation></semantics></math>–<math alttext="4.3" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">4.3</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn id="S4.SS1.p2.2.m2.1.1.cmml" type="float" xref="S4.SS1.p2.2.m2.1.1">4.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">4.3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">4.3</annotation></semantics></math>, regardless of the choice of retrievers. Tutorials can improve results by <math alttext="2.1" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><mn id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">2.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><cn id="S4.SS1.p2.3.m3.1.1.cmml" type="float" xref="S4.SS1.p2.3.m3.1.1">2.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">2.1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">2.1</annotation></semantics></math> only with the GIST-large neural retriever, possibly due to its adaptability.
From manual examinations of the results, many retrieved posts and tutorials are <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.2">about the same programming problem</span> as the HumanEval example, with code and detailed textual explanations, hence could hint or disclose the answer.
Other retrieval sources do not often contain relevant contexts thus do not improve generation.
Surprisingly, generation with mixed documents performs as well as using the gold documents, suggesting that the model can <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.3.3">discern and integrate the most useful content</span> from a mixture of texts.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S4.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Open retrieval on ODEX; no-retrieval baseline 14.6.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T8.1" style="width:247.2pt;height:58.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.7pt,6.6pt) scale(0.816703348208298,0.816703348208298) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T8.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T8.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T8.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.1.1.1.2">Program</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.1.1.1.3">Tutorial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.1.1.1.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T8.1.1.1.1.4.1" style="background-color:#E6E6E6;">Docs</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.1.1.1.5">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T8.1.1.1.1.6">GitHub</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.1.1.1.1.7">All</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.1.1.2.1.1">BM25</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.1.1.2.1.2" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T8.1.1.2.1.2.1" style="background-color:#E6EFC7;">18.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.1.1.2.1.3">13.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.1.1.2.1.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T8.1.1.2.1.4.1" style="background-color:#E6E6E6;">14.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.1.1.2.1.5"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.2.1.5.1">11.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T8.1.1.2.1.6" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T8.1.1.2.1.6.1" style="background-color:#E6EFC7;">15.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.1.1.2.1.7" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T8.1.1.2.1.7.1" style="background-color:#E6EFC7;">16.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.1.1.3.2.1">GIST-large</th>
<td class="ltx_td ltx_align_center" id="S4.T8.1.1.3.2.2">14.6</td>
<td class="ltx_td ltx_align_center" id="S4.T8.1.1.3.2.3" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.3.2.3.1" style="background-color:#E6EFC7;">15.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.1.1.3.2.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.3.2.4.1" style="background-color:#E6E6E6;">17.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.1.1.3.2.5">11.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.1.1.3.2.6" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T8.1.1.3.2.6.1" style="background-color:#E6EFC7;">15.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.1.1.3.2.7"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.3.2.7.1">17.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T8.1.1.4.3.1">OpenAI</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.1.1.4.3.2" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.4.3.2.1" style="background-color:#E6EFC7;">18.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.1.1.4.3.3">14.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.1.1.4.3.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T8.1.1.4.3.4.1" style="background-color:#E6E6E6;">15.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.1.1.4.3.5">10.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T8.1.1.4.3.6" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T8.1.1.4.3.6.1" style="background-color:#E6EFC7;">16.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.1.1.4.3.7" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T8.1.1.4.3.7.1" style="background-color:#E6EFC7;">15.3</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.4"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.4.1">Open-Domain: ODEX</span>  Programming solutions are the most helpful source, bringing gains of <math alttext="3.8" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mn id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">3.8</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><cn id="S4.SS1.p3.1.m1.1.1.cmml" type="float" xref="S4.SS1.p3.1.m1.1.1">3.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">3.8</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">3.8</annotation></semantics></math>–<math alttext="4.3" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mn id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">4.3</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><cn id="S4.SS1.p3.2.m2.1.1.cmml" type="float" xref="S4.SS1.p3.2.m2.1.1">4.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">4.3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">4.3</annotation></semantics></math>; GitHub files also improve by <math alttext="0.9" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mn id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><cn id="S4.SS1.p3.3.m3.1.1.cmml" type="float" xref="S4.SS1.p3.3.m3.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">0.9</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">0.9</annotation></semantics></math>–<math alttext="2.3" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><mn id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml">2.3</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><cn id="S4.SS1.p3.4.m4.1.1.cmml" type="float" xref="S4.SS1.p3.4.m4.1.1">2.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">2.3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.1d">2.3</annotation></semantics></math> points.
Although the retrieved solutions/files are only sometimes functionally relevant to the ODEX examples, they can <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.4.2">demonstrate the correct usage</span> of libraries such as <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.4.3">regex</span> from solutions and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.4.4">requests</span> from GitHub files, thus guiding the generation to be more functionally correct.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">Similar to HumanEval, GIST-large is particularly good at retrieving tutorials, while BM25 and OpenAI embeddings find higher-quality program solutions, indicating their respective domain advantages.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S4.T9">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>RACG with open retrieval on RepoEval; no-retrieval baseline 26.5.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T9.1" style="width:325.2pt;height:61.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-26.4pt,5.0pt) scale(0.860292574609173,0.860292574609173) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T9.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T9.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T9.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T9.1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T9.1.1.1.1.2.1" style="background-color:#E6E6E6;">Local</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.3">Program</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.4">Tutorial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.5">Docs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.6">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T9.1.1.1.1.7">GitHub</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.8">Open</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.1.1.1.1.9">L+O</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T9.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T9.1.1.2.1.1">BM25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T9.1.1.2.1.2.1" style="background-color:#E6E6E6;">36.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.3">23.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.4">25.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.5">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.6">23.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T9.1.1.2.1.7">25.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.8">23.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.1.1.2.1.9" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T9.1.1.2.1.9.1" style="background-color:#E6EFC7;">31.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T9.1.1.3.2.1">GIST-large</td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T9.1.1.3.2.2.1" style="background-color:#E6E6E6;">40.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.3">24.1</td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.4">23.3</td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.5">21.7</td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.6">24.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.1.1.3.2.7">24.4</td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.8">24.1</td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.3.2.9" style="background-color:#E6EFC7;"><span class="ltx_text" id="S4.T9.1.1.3.2.9.1" style="background-color:#E6EFC7;">41.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T9.1.1.4.3.1">OpenAI</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T9.1.1.4.3.2.1" style="background-color:#E6E6E6;">51.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.3">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.4">24.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.5">24.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.6">23.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T9.1.1.4.3.7">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.8">24.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.1.1.4.3.9" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T9.1.1.4.3.9.1" style="background-color:#E6EFC7;">50.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p5.1.1">Repository-Level: RepoEval</span>  Open sources are less useful than using code snippets retrieved from the local repository. As the RepoEval task is code completion, it is crucial to understand the local code context, which cannot be obtained from external sources.
When using both local and open-source contexts (<span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.2">L+O</span>), models surpass the no-retrieval baseline, yet are still only comparable with <span class="ltx_text ltx_font_italic" id="S4.SS1.p5.1.3">Local</span>, suggesting more efforts to build systems that benefit from both sources.</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="235" id="S4.F3.g1" src="x3.png" width="324"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Performance variation with different chunking sizes.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.1">Exploring optimal chunking strategies</span>  Adding multiple documents may exceed model context limits hence imparing RACG. Therefore, we explore various chunking strategies to better include retrieved contexts.
Compared to the no-chunking baseline, we study (i) post-retrieval chunking that takes the first N-tokens of each document, (ii) post-retrieval with reranking using BGE-reranker-base (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3.SS1" title="3.1 Experimental Setup ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3.1</span></a>) to find the most relevant N-token chunk from each document, and (iii) pre-retrieval chunking that chunks documents beforehand and retrieves N-token pieces directly.<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>We do not chunk programming solutions since they are typically short (average ¡200 tokens as in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S2.T2" title="Table 2 ‣ 2.2 Retrieval Sources ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 2</span></a>).</span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">For (i), we compare using the first N-tokens for N from 200 to 1500. As in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S4.F3" title="Figure 3 ‣ 4.1 Can RACG Benefit Weaker Models? ‣ 4 RACG with Open Retrieval ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>, most sources are best represented by the first 800 tokens; SO posts perform best with the first 200 tokens.
We then perform (ii) reranking within this optimal range of 200–800 tokens, yet find it greatly degrades the results, showing the limited utility of current rerankers.
Lastly, <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S4.T10" title="Table 10 ‣ 4.1 Can RACG Benefit Weaker Models? ‣ 4 RACG with Open Retrieval ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 10</span></a> shows that (iii) pre-retrieval achieves the highest scores on almost all document sources.</p>
</div>
<figure class="ltx_table ltx_align_floatright" id="S4.T10">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span>Comparing different chunking strategies on HumanEval with <math alttext="N=500" class="ltx_Math" display="inline" id="S4.T10.2.m1.1"><semantics id="S4.T10.2.m1.1b"><mrow id="S4.T10.2.m1.1.1" xref="S4.T10.2.m1.1.1.cmml"><mi id="S4.T10.2.m1.1.1.2" xref="S4.T10.2.m1.1.1.2.cmml">N</mi><mo id="S4.T10.2.m1.1.1.1" xref="S4.T10.2.m1.1.1.1.cmml">=</mo><mn id="S4.T10.2.m1.1.1.3" xref="S4.T10.2.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T10.2.m1.1c"><apply id="S4.T10.2.m1.1.1.cmml" xref="S4.T10.2.m1.1.1"><eq id="S4.T10.2.m1.1.1.1.cmml" xref="S4.T10.2.m1.1.1.1"></eq><ci id="S4.T10.2.m1.1.1.2.cmml" xref="S4.T10.2.m1.1.1.2">𝑁</ci><cn id="S4.T10.2.m1.1.1.3.cmml" type="integer" xref="S4.T10.2.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.2.m1.1d">N=500</annotation><annotation encoding="application/x-llamapun" id="S4.T10.2.m1.1e">italic_N = 500</annotation></semantics></math>.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T10.3" style="width:212.5pt;height:81.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.3pt,4.3pt) scale(0.903671870817224,0.903671870817224) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T10.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T10.3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T10.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T10.3.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.3.1.1.1.2">Tutorials</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.3.1.1.1.3">Docs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.3.1.1.1.4">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.3.1.1.1.5">GitHub</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T10.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T10.3.1.2.1.1">Full text</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.3.1.2.1.2">  6.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.3.1.2.1.3">17.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.3.1.2.1.4">28.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.3.1.2.1.5">  3.7</td>
</tr>
<tr class="ltx_tr" id="S4.T10.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T10.3.1.3.2.1">First chunk</th>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.3.2.2">27.4</td>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.3.2.3">29.3</td>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.3.2.4">30.5</td>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.3.2.5"><span class="ltx_text ltx_font_bold" id="S4.T10.3.1.3.2.5.1">30.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T10.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T10.3.1.4.3.1">w/ reranking</th>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.4.3.2">  9.1</td>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.4.3.3">  9.1</td>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.4.3.4">14.0</td>
<td class="ltx_td ltx_align_center" id="S4.T10.3.1.4.3.5">13.4</td>
</tr>
<tr class="ltx_tr" id="S4.T10.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T10.3.1.5.4.1">Pre-retrieval</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T10.3.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S4.T10.3.1.5.4.2.1">31.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T10.3.1.5.4.3" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T10.3.1.5.4.3.1" style="background-color:#E6EFC7;">32.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T10.3.1.5.4.4" style="background-color:#E6EFC7;"><span class="ltx_text ltx_font_bold" id="S4.T10.3.1.5.4.4.1" style="background-color:#E6EFC7;">33.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T10.3.1.5.4.5">29.3</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Does RACG Help Stronger Models?</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We have shown that RACG with open retrieval improves a relatively weaker model, StarCoder2. To see if this improvement of RACG with open retrieval generalizes to stronger models, we experiment with a series of top-performing proprietary models:
GPT-4o, Claude-3-haiku/sonnet, and Gemini-1.5-flash/pro.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Basic programming: HumanEval</span>  RACG can consistently improve the performance of GPT-4 and Claude-3-sonnet when leveraging all sources of documents. However, for weaker models such as Claude-3-haiku and Gemini-1.5-flash, RACG only helps when aggregating multiple sources yet falls short when grounding on one source (even the canonical solution source).
Interestingly, the stronger Claude-3-sonnet performs worse than the weaker Claude-3-haiku, but can benefit from all retrieval sources and outperform haiku with documents from the canonical programming source, suggesting its potentially better RAG ability.
While the stronger Claude effectively benefits from additional contexts, the stronger Gemini-1.5-pro behaves similarly to its weaker counterpart and cannot do RACG effectively with non-canonical sources.</p>
</div>
<figure class="ltx_table" id="S4.T11">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11: </span>RACG on HumanEval with strong code LMs.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T11.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T11.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T11.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T11.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T11.1.1.1.2">Baseline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.1.1.1.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T11.1.1.1.3.1" style="background-color:#E6E6E6;">Program</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.1.1.1.4">Tutorial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.1.1.1.5">Docs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.1.1.1.6">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T11.1.1.1.7">GitHub</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.1.1.1.8">All</th>
</tr>
<tr class="ltx_tr" id="S4.T11.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.1.2.2.1">GPT-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.1.2.2.2">75.6</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T11.1.2.2.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T11.1.2.2.3.1" style="background-color:#E6E6E6;">94.5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T11.1.2.2.4" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T11.1.2.2.4.1" style="background-color:#E8F0CC;">90.2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T11.1.2.2.5" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T11.1.2.2.5.1" style="background-color:#E8F0CC;">90.9</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T11.1.2.2.6" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T11.1.2.2.6.1" style="background-color:#E8F0CC;">91.5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T11.1.2.2.7" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.2.2.7.1" style="background-color:#F4F8E6;">84.8</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T11.1.2.2.8" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T11.1.2.2.8.1" style="background-color:#E8F0CC;">95.1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T11.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.1.3.1.1">Claude-3-haiku</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.1.3.1.2">74.4</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.3.1.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T11.1.3.1.3.1" style="background-color:#E6E6E6;">77.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.3.1.4" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.3.1.4.1" style="background-color:#F4F8E6;">77.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.3.1.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.3.1.5.1" style="background-color:#FFEBEB;">71.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.3.1.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.3.1.6.1" style="background-color:#FFEBEB;">67.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T11.1.3.1.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.3.1.7.1" style="background-color:#FFEBEB;">73.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.3.1.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.3.1.8.1" style="background-color:#F4F8E6;">82.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T11.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T11.1.4.2.1">Claude-3-sonnet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T11.1.4.2.2">65.9</th>
<td class="ltx_td ltx_align_center" id="S4.T11.1.4.2.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T11.1.4.2.3.1" style="background-color:#E6E6E6;">78.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T11.1.4.2.4" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.4.2.4.1" style="background-color:#F4F8E6;">66.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T11.1.4.2.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.4.2.5.1" style="background-color:#F4F8E6;">68.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T11.1.4.2.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.4.2.6.1" style="background-color:#F4F8E6;">70.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T11.1.4.2.7" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.4.2.7.1" style="background-color:#F4F8E6;">73.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T11.1.4.2.8" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T11.1.4.2.8.1" style="background-color:#E8F0CC;">80.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T11.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.1.5.3.1">Gemini-1.5-flash</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.1.5.3.2">72.0</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.5.3.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T11.1.5.3.3.1" style="background-color:#E6E6E6;">91.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.5.3.4" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.5.3.4.1" style="background-color:#F4F8E6;">75.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.5.3.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.5.3.5.1" style="background-color:#FFEBEB;">70.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.5.3.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.5.3.6.1" style="background-color:#FFEBEB;">68.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T11.1.5.3.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.5.3.7.1" style="background-color:#FFEBEB;">68.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.1.5.3.8" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T11.1.5.3.8.1" style="background-color:#E8F0CC;">95.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T11.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T11.1.6.4.1">Gemini-1.5-pro</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T11.1.6.4.2">82.9</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T11.1.6.4.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T11.1.6.4.3.1" style="background-color:#E6E6E6;">95.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T11.1.6.4.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.6.4.4.1" style="background-color:#FFEBEB;">79.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T11.1.6.4.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.6.4.5.1" style="background-color:#FFEBEB;">77.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T11.1.6.4.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.6.4.6.1" style="background-color:#FFEBEB;">79.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T11.1.6.4.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T11.1.6.4.7.1" style="background-color:#FFEBEB;">80.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T11.1.6.4.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T11.1.6.4.8.1" style="background-color:#F4F8E6;">86.6</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Open domain: ODEX</span>  All models experience limited improvements by leveraging library documentation to complex the ODEX task, with the only exception that GPT-4o improves <math alttext="4.6" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">4.6</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><cn id="S4.SS2.p3.1.m1.1.1.cmml" type="float" xref="S4.SS2.p3.1.m1.1.1">4.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">4.6</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">4.6</annotation></semantics></math> points by incorporating programming solutions into the context.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">As results degrade in most cases, we conduct a manual analysis to examine when most models fail. We find that most models tend to copy functions in the context, sometimes even overwriting the function being queried, thus failing all the test cases specific to the queried function. Further, possibly affected by the plethora of programs in context, models tend to generate over-complicated programs which, however, do not often pass the test cases.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">In general, most models can be easily distracted or disturbed by additional contexts <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib41" title="">41</a>]</cite>, and fail to conduct the designated code generation task, indicating much room for improvement for RACG.</p>
</div>
<figure class="ltx_table" id="S4.T12">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 12: </span>RACG on ODEX with strong code LMs.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T12.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T12.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T12.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T12.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T12.1.1.1.2">Baseline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.1.1.1.3">Program</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.1.1.1.4">Tutorial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.1.1.1.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T12.1.1.1.5.1" style="background-color:#E6E6E6;">Docs</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.1.1.1.6">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T12.1.1.1.7">GitHub</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.1.1.1.8">All</th>
</tr>
<tr class="ltx_tr" id="S4.T12.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T12.1.2.2.1">GPT-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T12.1.2.2.2">44.6</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T12.1.2.2.3" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T12.1.2.2.3.1" style="background-color:#F4F8E6;">49.2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T12.1.2.2.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.2.2.4.1" style="background-color:#FFEBEB;">44.2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T12.1.2.2.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T12.1.2.2.5.1" style="background-color:#E6E6E6;">47.6</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T12.1.2.2.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.2.2.6.1" style="background-color:#FFEBEB;">40.3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T12.1.2.2.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.2.2.7.1" style="background-color:#FFEBEB;">39.4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T12.1.2.2.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.2.2.8.1" style="background-color:#FFEBEB;">39.6</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T12.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T12.1.3.1.1">Claude-3-haiku</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T12.1.3.1.2">48.5</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.3.1.3" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.3.1.3.1" style="background-color:#FFEBEB;">42.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.3.1.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.3.1.4.1" style="background-color:#FFEBEB;">39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.3.1.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T12.1.3.1.5.1" style="background-color:#E6E6E6;">44.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.3.1.6" style="background-color:#FFD6D6;"><span class="ltx_text" id="S4.T12.1.3.1.6.1" style="background-color:#FFD6D6;">33.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T12.1.3.1.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.3.1.7.1" style="background-color:#FFEBEB;">40.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.3.1.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.3.1.8.1" style="background-color:#FFEBEB;">35.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T12.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T12.1.4.2.1">Claude-3-sonnet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T12.1.4.2.2">41.0</th>
<td class="ltx_td ltx_align_center" id="S4.T12.1.4.2.3" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.4.2.3.1" style="background-color:#FFEBEB;">37.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T12.1.4.2.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.4.2.4.1" style="background-color:#FFEBEB;">35.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T12.1.4.2.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T12.1.4.2.5.1" style="background-color:#E6E6E6;">38.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T12.1.4.2.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.4.2.6.1" style="background-color:#FFEBEB;">34.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T12.1.4.2.7" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T12.1.4.2.7.1" style="background-color:#F4F8E6;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T12.1.4.2.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.4.2.8.1" style="background-color:#FFEBEB;">38.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T12.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T12.1.5.3.1">Gemini-1.5-flash</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T12.1.5.3.2">50.6</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.5.3.3" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.5.3.3.1" style="background-color:#FFEBEB;">48.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.5.3.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.5.3.4.1" style="background-color:#FFEBEB;">46.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.5.3.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T12.1.5.3.5.1" style="background-color:#E6E6E6;">46.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.5.3.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.5.3.6.1" style="background-color:#FFEBEB;">41.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T12.1.5.3.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.5.3.7.1" style="background-color:#FFEBEB;">44.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.1.5.3.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.5.3.8.1" style="background-color:#FFEBEB;">43.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T12.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T12.1.6.4.1">Gemini-1.5-pro</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T12.1.6.4.2">57.2</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.1.6.4.3" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T12.1.6.4.3.1" style="background-color:#FFEBEB;">54.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.1.6.4.4" style="background-color:#FFD6D6;"><span class="ltx_text" id="S4.T12.1.6.4.4.1" style="background-color:#FFD6D6;">45.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.1.6.4.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T12.1.6.4.5.1" style="background-color:#E6E6E6;">51.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.1.6.4.6" style="background-color:#FFD6D6;"><span class="ltx_text" id="S4.T12.1.6.4.6.1" style="background-color:#FFD6D6;">46.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T12.1.6.4.7" style="background-color:#FFD6D6;"><span class="ltx_text" id="S4.T12.1.6.4.7.1" style="background-color:#FFD6D6;">39.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.1.6.4.8" style="background-color:#FFD6D6;"><span class="ltx_text" id="S4.T12.1.6.4.8.1" style="background-color:#FFD6D6;">46.0</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p6.1.1">Repository level: RepoEval</span>  While GPT-4o can solve the RepoEval task with a reasonable success rate, all Claude models are challenged by the task and achieve less than 10% pass@1 for most scenarios. We find Claude models mostly respond with explanations of the incomplete input code, instead of the to-be-completed code even with proper instructions, possibly caused by some properties of the unknown training data.
Gemini-1.5-flash also barely solves the task and often generates textual explanations; however its stronger pro variant gets about 10–25 point improvements, demonstrating its stronger repository-level code completion abilities.</p>
</div>
<figure class="ltx_table" id="S4.T13">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 13: </span>RACG on RepoEval with strong code LMs.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T13.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T13.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T13.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T13.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.2">Baseline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T13.1.1.1.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T13.1.1.1.3.1" style="background-color:#E6E6E6;">Local</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.4">Program</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.5">Tutorial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.6">Docs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.7">SO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T13.1.1.1.8">GitHub</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.9">All</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T13.1.1.1.10">L+E</th>
</tr>
<tr class="ltx_tr" id="S4.T13.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T13.1.2.2.1">GPT-4o</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.2">32.4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T13.1.2.2.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T13.1.2.2.3.1" style="background-color:#E6E6E6;">62.2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.4" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.2.2.4.1" style="background-color:#F4F8E6;">35.4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.2.2.5.1" style="background-color:#FFEBEB;">28.7</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.2.2.6.1" style="background-color:#FFEBEB;">27.8</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.2.2.7.1" style="background-color:#FFEBEB;">29.0</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T13.1.2.2.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.2.2.8.1" style="background-color:#FFEBEB;">28.2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.9" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.2.2.9.1" style="background-color:#FFEBEB;">30.3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T13.1.2.2.10" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T13.1.2.2.10.1" style="background-color:#E8F0CC;">54.2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T13.1.3.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T13.1.3.1.1">Claude-3-haiku</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.2">  9.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T13.1.3.1.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T13.1.3.1.3.1" style="background-color:#E6E6E6;">  0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.4.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.5.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.6.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.7.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T13.1.3.1.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.8.1" style="background-color:#FFEBEB;">  0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.9" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.9.1" style="background-color:#FFEBEB;">  0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.3.1.10" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.3.1.10.1" style="background-color:#FFEBEB;">  0.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T13.1.4.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T13.1.4.2.1">Claude-3-sonnet</td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.2">  0.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T13.1.4.2.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T13.1.4.2.3.1" style="background-color:#E6E6E6;">  0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.4" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.4.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.5" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.5.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.6" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.6.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.7" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.7.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T13.1.4.2.8" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.8.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.9" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.9.1" style="background-color:#FFEBEB;">  0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T13.1.4.2.10" style="background-color:#FFEBEB;"><span class="ltx_text" id="S4.T13.1.4.2.10.1" style="background-color:#FFEBEB;">  0.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T13.1.5.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T13.1.5.3.1">Gemini-1.5-flash</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.2">  1.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T13.1.5.3.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T13.1.5.3.3.1" style="background-color:#E6E6E6;">16.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.4" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.5.3.4.1" style="background-color:#F4F8E6;">  4.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.5.3.5.1" style="background-color:#F4F8E6;">  2.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.5.3.6.1" style="background-color:#F4F8E6;">  3.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.7" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.5.3.7.1" style="background-color:#F4F8E6;">  2.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T13.1.5.3.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.5.3.8.1" style="background-color:#F4F8E6;">  3.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.9" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.5.3.9.1" style="background-color:#F4F8E6;">  2.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T13.1.5.3.10" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T13.1.5.3.10.1" style="background-color:#E8F0CC;">11.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T13.1.6.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T13.1.6.4.1">Gemini-1.5-pro</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.2">10.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T13.1.6.4.3" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T13.1.6.4.3.1" style="background-color:#E6E6E6;">39.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.4" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.6.4.4.1" style="background-color:#F4F8E6;">15.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.5" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.6.4.5.1" style="background-color:#F4F8E6;">13.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.6" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.6.4.6.1" style="background-color:#F4F8E6;">15.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.7" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.6.4.7.1" style="background-color:#F4F8E6;">15.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T13.1.6.4.8" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.6.4.8.1" style="background-color:#F4F8E6;">11.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.9" style="background-color:#F4F8E6;"><span class="ltx_text" id="S4.T13.1.6.4.9.1" style="background-color:#F4F8E6;">12.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T13.1.6.4.10" style="background-color:#E8F0CC;"><span class="ltx_text" id="S4.T13.1.6.4.10.1" style="background-color:#E8F0CC;">33.0</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">Code Generation</span>  Neural code generation has been an important task <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib24" title="">24</a>]</cite>, and increasingly strong code LMs have been created <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib38" title="">38</a>]</cite> to solve various tasks <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib15" title="">15</a>]</cite>.
However, most LMs generate code solely based on NL problems and model parametric knowledge, without using external programming sources (e.g., tutorials) or a RAG approach.
To fill in this gap and allow of systematic study of RACG, we orchestrate various datasets and retrieval sources to benchmark and analyze RACG systems.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Retrieval augmented generation (RAG)</span>  RAG has been widely used for knowledge-intensive tasks <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib11" title="">11</a>]</cite>.
While previous studies often train retrieval and generation components from scratch or sequentially <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib13" title="">13</a>]</cite>, recent work has demonstrated the effectiveness of retrieval-augmented approaches on top of off-the-shelf powerful LMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib25" title="">25</a>]</cite>.
However, most prior works focus on text-centric tasks using general domain corpora such as Wikipedia <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib2" title="">2</a>]</cite>.
Several prior works leverage programming context retrieved from repositories <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib45" title="">45</a>]</cite> or documentations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib47" title="">47</a>]</cite>, to our knowledge, there are no prior studies analyzing the effectiveness of RACG across different coding tasks and knowledge sources.
In text-centric tasks, unified benchmarks such as BEIR <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib39" title="">39</a>]</cite> and KILT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib30" title="">30</a>]</cite> have been proposed to aggregate several text retrieval and generation tasks, and facilitate rapid progress in this area <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib28" title="">28</a>]</cite>.
Yet, we currently lack a large-scale benchmark or analysis for RACG.
To provide a systematic analysis of coding tasks with various retrieval sources, we propose a unified benchmark and codebase to enable versatile analysis of RACG.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we propose <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.1">CodeRAG-Bench</span>, a benchmark for retrieval-augmented code generation with various coding tasks and retrieval sources. With our experiments with top-performing retrieval and generation models, we show that retrieving external documents can greatly benefit code generation. However, current retrieval models struggle to find accurately helpful documents, and generation models have limited context capacity and RAG abilities, both leading to suboptimal RACG results. We hope <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2">CodeRAG-Bench</span> can serve as a solid testbed to advance future endeavors in this direction.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank Shuyan Zhou and Xinran Zhao for the helpful discussions in the early stage of this project, and Saujas Vaduguru, Jing Yu Koh, Alex Xie, and Andy Liu for providing valuable feedback for the draft. Zora Zhiruo Wang is supported by Carnegie Mellon University Presidential Fellowship. Yiqing is supported by NSF grant DSES 2222762.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. [2023]</span>
<span class="ltx_bibblock">
A. Asai, T. Schick, P. Lewis, X. Chen, G. Izacard, S. Riedel, H. Hajishirzi, and W.-t. Yih.

</span>
<span class="ltx_bibblock">Task-aware retrieval with instructions.

</span>
<span class="ltx_bibblock">In A. Rogers, J. Boyd-Graber, and N. Okazaki, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 3650–3675, Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.findings-acl.225</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-acl.225" title="">https://aclanthology.org/2023.findings-acl.225</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. [2024]</span>
<span class="ltx_bibblock">
A. Asai, Z. Zhong, D. Chen, P. W. Koh, L. Zettlemoyer, H. Hajishirzi, and W.-t. Yih.

</span>
<span class="ltx_bibblock">Reliable, adaptable, and attributable language models with retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2403.03187</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Austin et al. [2021]</span>
<span class="ltx_bibblock">
J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, et al.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2108.07732</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. [2020]</span>
<span class="ltx_bibblock">
T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">ArXiv</em>, abs/2005.14165, 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:218971783" title="">https://api.semanticscholar.org/CorpusID:218971783</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2021]</span>
<span class="ltx_bibblock">
M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2107.03374</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">CohereAI [2024]</span>
<span class="ltx_bibblock">
CohereAI.

</span>
<span class="ltx_bibblock">Command r.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://docs.cohere.com/docs/command-r" title="">https://docs.cohere.com/docs/command-r</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Computer [2023]</span>
<span class="ltx_bibblock">
T. Computer.

</span>
<span class="ltx_bibblock">Redpajama: An open source recipe to reproduce llama training dataset, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/togethercomputer/RedPajama-Data" title="">https://github.com/togethercomputer/RedPajama-Data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. [2023]</span>
<span class="ltx_bibblock">
Y. Ding, Z. Wang, W. U. Ahmad, H. Ding, M. Tan, N. Jain, M. K. Ramanathan, R. Nallapati, P. Bhatia, D. Roth, and B. Xiang.

</span>
<span class="ltx_bibblock">Crosscodeeval: A diverse and multilingual benchmark for cross-file code completion.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=wgDcbBMSfh" title="">https://openreview.net/forum?id=wgDcbBMSfh</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et al. [2021]</span>
<span class="ltx_bibblock">
T. Gebru, J. Morgenstern, B. Vecchione, J. W. Vaughan, H. Wallach, H. D. Iii, and K. Crawford.

</span>
<span class="ltx_bibblock">Datasheets for datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Communications of the ACM</em>, 64(12):86–92, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. [2024]</span>
<span class="ltx_bibblock">
D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. Li, et al.

</span>
<span class="ltx_bibblock">Deepseek-coder: When the large language model meets programming–the rise of code intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2401.14196</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et al. [2020]</span>
<span class="ltx_bibblock">
K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang.

</span>
<span class="ltx_bibblock">Retrieval augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">International conference on machine learning</em>, pages 3929–3938. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. [2022a]</span>
<span class="ltx_bibblock">
G. Izacard, M. Caron, L. Hosseini, S. Riedel, P. Bojanowski, A. Joulin, and E. Grave.

</span>
<span class="ltx_bibblock">Unsupervised dense information retrieval with contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Transactions on Machine Learning Research</em>, 2022a.

</span>
<span class="ltx_bibblock">ISSN 2835-8856.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=jKN1pXi7b0" title="">https://openreview.net/forum?id=jKN1pXi7b0</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. [2022b]</span>
<span class="ltx_bibblock">
G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick, J. A. Yu, A. Joulin, S. Riedel, and E. Grave.

</span>
<span class="ltx_bibblock">Few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ArXiv</em>, abs/2208.03299, 2022b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:251371732" title="">https://api.semanticscholar.org/CorpusID:251371732</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. [2024]</span>
<span class="ltx_bibblock">
N. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.

</span>
<span class="ltx_bibblock">Livecodebench: Holistic and contamination free evaluation of large language models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2403.07974</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jimenez et al. [2024]</span>
<span class="ltx_bibblock">
C. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan.

</span>
<span class="ltx_bibblock">SWE-bench: Can language models resolve real-world github issues?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=VTF8yNQM66" title="">https://openreview.net/forum?id=VTF8yNQM66</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et al. [2023]</span>
<span class="ltx_bibblock">
N. Kandpal, H. Deng, A. Roberts, E. Wallace, and C. Raffel.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International Conference on Machine Learning</em>, pages 15696–15707. PMLR, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al. [2023]</span>
<span class="ltx_bibblock">
Y. Lai, C. Li, Y. Wang, T. Zhang, R. Zhong, L. Zettlemoyer, W.-t. Yih, D. Fried, S. Wang, and T. Yu.

</span>
<span class="ltx_bibblock">Ds-1000: a natural and reliable benchmark for data science code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, ICML’23. JMLR.org, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. [2020]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, and D. Kiela.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock">In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural Information Processing Systems</em>, volume 33, pages 9459–9474. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2023]</span>
<span class="ltx_bibblock">
R. Li, L. B. allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. LI, J. Chim, Q. Liu, E. Zheltonozhskii, T. Y. Zhuo, T. Wang, O. Dehaene, J. Lamy-Poirier, J. Monteiro, N. Gontier, M.-H. Yee, L. K. Umapathi, J. Zhu, B. Lipkin, M. Oblokulov, Z. Wang, R. Murthy, J. T. Stillerman, S. S. Patel, D. Abulkhanov, M. Zocca, M. Dey, Z. Zhang, U. Bhattacharyya, W. Yu, S. Luccioni, P. Villegas, F. Zhdanov, T. Lee, N. Timor, J. Ding, C. S. Schlesinger, H. Schoelkopf, J. Ebert, T. Dao, M. Mishra, A. Gu, C. J. Anderson, B. Dolan-Gavitt, D. Contractor, S. Reddy, D. Fried, D. Bahdanau, Y. Jernite, C. M. Ferrandis, S. Hughes, T. Wolf, A. Guha, L. V. Werra, and H. de Vries.

</span>
<span class="ltx_bibblock">Starcoder: may the source be with you!

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Transactions on Machine Learning Research</em>, 2023.

</span>
<span class="ltx_bibblock">ISSN 2835-8856.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=KoFOg41haE" title="">https://openreview.net/forum?id=KoFOg41haE</a>.

</span>
<span class="ltx_bibblock">Reproducibility Certification.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2022]</span>
<span class="ltx_bibblock">
Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. D. Lago, T. Hubert, P. Choy, C. de Masson d’Autume, I. Babuschkin, X. Chen, P.-S. Huang, J. Welbl, S. Gowal, A. Cherepanov, J. Molloy, D. J. Mankowitz, E. S. Robson, P. Kohli, N. de Freitas, K. Kavukcuoglu, and O. Vinyals.

</span>
<span class="ltx_bibblock">Competition-level code generation with alphacode.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Science</em>, 378(6624):1092–1097, 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1126/science.abq1158</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.science.org/doi/abs/10.1126/science.abq1158" title="">https://www.science.org/doi/abs/10.1126/science.abq1158</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. [2021]</span>
<span class="ltx_bibblock">
J. Lin, X. Ma, S.-C. Lin, J.-H. Yang, R. Pradeep, and R. Nogueira.

</span>
<span class="ltx_bibblock">Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dl.acm.org/doi/10.1145/3404835.3463238" title="">https://dl.acm.org/doi/10.1145/3404835.3463238</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023]</span>
<span class="ltx_bibblock">
J. Liu, C. S. Xia, Y. Wang, and L. Zhang.

</span>
<span class="ltx_bibblock">Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=1qvx610Cu7" title="">https://openreview.net/forum?id=1qvx610Cu7</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lozhkov et al. [2024]</span>
<span class="ltx_bibblock">
A. Lozhkov, R. Li, L. B. Allal, F. Cassano, J. Lamy-Poirier, N. Tazi, A. Tang, D. Pykhtar, J. Liu, Y. Wei, et al.

</span>
<span class="ltx_bibblock">Starcoder 2 and the stack v2: The next generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2402.19173</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2021]</span>
<span class="ltx_bibblock">
S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco, C. B. Clement, D. Drain, D. Jiang, D. Tang, G. Li, L. Zhou, L. Shou, L. Zhou, M. Tufano, M. Gong, M. Zhou, N. Duan, N. Sundaresan, S. K. Deng, S. Fu, and S. Liu.

</span>
<span class="ltx_bibblock">Codexglue: A machine learning benchmark dataset for code understanding and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">CoRR</em>, abs/2102.04664, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallen et al. [2023]</span>
<span class="ltx_bibblock">
A. Mallen, A. Asai, V. Zhong, R. Das, D. Khashabi, and H. Hajishirzi.

</span>
<span class="ltx_bibblock">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories.

</span>
<span class="ltx_bibblock">In A. Rogers, J. Boyd-Graber, and N. Okazaki, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 9802–9822, Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.acl-long.546</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.acl-long.546" title="">https://aclanthology.org/2023.acl-long.546</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al. [2024]</span>
<span class="ltx_bibblock">
R. Meng, Y. Liu, S. R. Joty, C. Xiong, Y. Zhou, and S. Yavuz.

</span>
<span class="ltx_bibblock">Sfr-embedding-mistral:enhance text retrieval with transfer learning, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blog.salesforceairesearch.com/sfr-embedded-mistral/" title="">https://blog.salesforceairesearch.com/sfr-embedded-mistral/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meta [2024]</span>
<span class="ltx_bibblock">
Meta.

</span>
<span class="ltx_bibblock">Introducing meta llama 3: The most capable openly available llm to date.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/blog/meta-llama-3/" title="">https://ai.meta.com/blog/meta-llama-3/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et al. [2022]</span>
<span class="ltx_bibblock">
N. Muennighoff, N. Tazi, L. Magne, and N. Reimers.

</span>
<span class="ltx_bibblock">Mteb: Massive text embedding benchmark.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2210.07316</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Overwijk et al. [2022]</span>
<span class="ltx_bibblock">
A. Overwijk, C. Xiong, X. Liu, C. VandenBerg, and J. Callan.

</span>
<span class="ltx_bibblock">Clueweb22: 10 billion web documents with visual and semantic information.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2211.15848</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et al. [2020]</span>
<span class="ltx_bibblock">
F. Petroni, A. Piktus, A. Fan, P. Lewis, M. Yazdani, N. De Cao, J. Thorne, Y. Jernite, V. Karpukhin, J. Maillard, et al.

</span>
<span class="ltx_bibblock">Kilt: a benchmark for knowledge intensive language tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2009.02252</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram et al. [2023]</span>
<span class="ltx_bibblock">
O. Ram, Y. Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-Brown, and Y. Shoham.

</span>
<span class="ltx_bibblock">In-context retrieval-augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Transactions of the Association for Computational Linguistics</em>, 11:1316–1331, 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00605</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.tacl-1.75" title="">https://aclanthology.org/2023.tacl-1.75</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych [2019]</span>
<span class="ltx_bibblock">
N. Reimers and I. Gurevych.

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics, 11 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1908.10084" title="">https://arxiv.org/abs/1908.10084</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson and Zaragoza [2009]</span>
<span class="ltx_bibblock">
S. E. Robertson and H. Zaragoza.

</span>
<span class="ltx_bibblock">The probabilistic relevance framework: Bm25 and beyond.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Found. Trends Inf. Retr.</em>, 3:333–389, 2009.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:207178704" title="">https://api.semanticscholar.org/CorpusID:207178704</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et al. [2023]</span>
<span class="ltx_bibblock">
B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin, et al.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2308.12950</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Solatorio [2024]</span>
<span class="ltx_bibblock">
A. V. Solatorio.

</span>
<span class="ltx_bibblock">Gistembed: Guided in-sample selection of training negatives for text embedding fine-tuning, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.16829" title="">https://arxiv.org/abs/2402.16829</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. [2023]</span>
<span class="ltx_bibblock">
H. Su, W. Shi, J. Kasai, Y. Wang, Y. Hu, M. Ostendorf, W.-t. Yih, N. A. Smith, L. Zettlemoyer, and T. Yu.

</span>
<span class="ltx_bibblock">One embedder, any task: Instruction-finetuned text embeddings.

</span>
<span class="ltx_bibblock">In A. Rogers, J. Boyd-Graber, and N. Okazaki, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 1102–1121, Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.findings-acl.71</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-acl.71" title="">https://aclanthology.org/2023.findings-acl.71</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. [2024]</span>
<span class="ltx_bibblock">
H. Su, S. Jiang, Y. Lai, H. Wu, B. Shi, C. Liu, Q. Liu, and T. Yu.

</span>
<span class="ltx_bibblock">Arks: Active retrieval in knowledge soup for code generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2402.12317</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team [2024]</span>
<span class="ltx_bibblock">
C. Team.

</span>
<span class="ltx_bibblock">Codegemma: Open code models based on gemma.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf" title="">https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et al. [2021]</span>
<span class="ltx_bibblock">
N. Thakur, N. Reimers, A. Rücklé, A. Srivastava, and I. Gurevych.

</span>
<span class="ltx_bibblock">BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=wCu6T5xFjeJ" title="">https://openreview.net/forum?id=wCu6T5xFjeJ</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">VoyageAI [2024]</span>
<span class="ltx_bibblock">
VoyageAI.

</span>
<span class="ltx_bibblock">voyage-code-2: Elevate your code retrieval.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blog.voyageai.com/2024/01/23/voyage-code-2-elevate-your-code-retrieval/" title="">https://blog.voyageai.com/2024/01/23/voyage-code-2-elevate-your-code-retrieval/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2023a]</span>
<span class="ltx_bibblock">
Z. Wang, J. Araki, Z. Jiang, M. R. Parvez, and G. Neubig.

</span>
<span class="ltx_bibblock">Learning to filter context for retrieval-augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2311.08377</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2023b]</span>
<span class="ltx_bibblock">
Z. Wang, S. Zhou, D. Fried, and G. Neubig.

</span>
<span class="ltx_bibblock">Execution-based evaluation for open-domain code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>. Association for Computational Linguistics, 2023b.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.findings-emnlp.89</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-emnlp.89" title="">https://aclanthology.org/2023.findings-emnlp.89</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. [2023]</span>
<span class="ltx_bibblock">
Y. Wei, Z. Wang, J. Liu, Y. Ding, and L. Zhang.

</span>
<span class="ltx_bibblock">Magicoder: Source code is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2312.02120</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. [2023]</span>
<span class="ltx_bibblock">
S. Xiao, Z. Liu, P. Zhang, and N. Muennighoff.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2309.07597" title="">https://arxiv.org/abs/2309.07597</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2024]</span>
<span class="ltx_bibblock">
J. Yang, C. E. Jimenez, A. Wettig, K. Lieret, S. Yao, K. Narasimhan, and O. Press.

</span>
<span class="ltx_bibblock">Swe-agent: Agent-computer interfaces enable automated software engineering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2405.15793</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023]</span>
<span class="ltx_bibblock">
F. Zhang, B. Chen, Y. Zhang, J. Keung, J. Liu, D. Zan, Y. Mao, J.-G. Lou, and W. Chen.

</span>
<span class="ltx_bibblock">Repocoder: Repository-level code completion through iterative retrieval and generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.151" title="">https://aclanthology.org/2023.emnlp-main.151</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. [2023]</span>
<span class="ltx_bibblock">
S. Zhou, U. Alon, F. F. Xu, Z. Jiang, and G. Neubig.

</span>
<span class="ltx_bibblock">Docprompting: Generating code by retrieving the docs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">The Eleventh International Conference on Learning Representations</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=ZTCxT2t2Ru" title="">https://openreview.net/forum?id=ZTCxT2t2Ru</a>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix: Datasheets for Datasets</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Access to <span class="ltx_text ltx_font_smallcaps" id="A1.SS1.1.1">CodeRAG-Bench</span>
</h3>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">We provide access to view and download all datasets with our additional ground-truth document annotation, as well as all documents from the five retrieval sources at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/code-rag-bench" title="">https://huggingface.co/code-rag-bench</a>.
For each dataset or retrieval source, the corresponding Croissant metadata can be found via a <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p1.1.1">Croissant</span> tag button on the dataset’s page.
All code generation datasets we build upon are permissively licensed. There is no noticeable chance that our data would contain personally identifiable or offensive content.
The codebase for our retrieval-augmented code generation framework can be found at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/code-rag-bench/code-rag-bench" title="">https://github.com/code-rag-bench/code-rag-bench</a>.
Overall, all necessary datasets, code, and evaluation procedures are accessible and documented by our main website <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://code-rag-bench.github.io/" title="">https://code-rag-bench.github.io/</a>.</p>
</div>
<section class="ltx_paragraph" id="A1.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Author Statement</h5>
<div class="ltx_para ltx_noindent" id="A1.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS1.SSS0.Px1.p1.1">The authors state that they bear all responsibility in case of violation of rights of the original datasets and retrieval sources. We confirm that the data is released under the CC-BY-SA 4.0 license.
The authors plan to host the dataset and codebase with the above sources on Huggingface and GitHub, and will continue to provide the necessary maintenance to both.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Dataset Documentation and Intended Uses</h3>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">We provide detailed dataset documentation and explanations for the intended uses, using the datasets for dataset <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib9" title="">9</a>]</cite> framework.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Motivation</h3>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.p1.1.1">For what purpose what the dataset created?</span>  We create <span class="ltx_text ltx_font_smallcaps" id="A1.SS3.p1.1.2">CodeRAG-Bench</span> to provide a unified benchmark for retrieval-augmented code generation, encompassing various code generation tasks and retrieval sources, to facilitate research in this direction.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.p2">
<p class="ltx_p" id="A1.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.p2.1.1">Who created the dataset and one behalf of which entity?</span>  Student researchers in Carnegie Mellon University, University of Washington, and University of Southern California created this dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.p3">
<p class="ltx_p" id="A1.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.p3.1.1">Who funded the creation of the dataset?</span>  Supervisors of this project, also professors at Carnegie Mellon University funded the creation of this dataset.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Composition</h3>
<div class="ltx_para ltx_noindent" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p1.1.1">What do the instance that comprise the dataset represent?</span>  The dataset represents (i) different programming tasks that reflect the job of software developers, and (ii) various reference sources for solving or guiding software programming.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p2">
<p class="ltx_p" id="A1.SS4.p2.2"><span class="ltx_text ltx_font_bold" id="A1.SS4.p2.2.1">How many instances are there in total?</span>  Our dataset comprises 9<math alttext="k" class="ltx_Math" display="inline" id="A1.SS4.p2.1.m1.1"><semantics id="A1.SS4.p2.1.m1.1a"><mi id="A1.SS4.p2.1.m1.1.1" xref="A1.SS4.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS4.p2.1.m1.1b"><ci id="A1.SS4.p2.1.m1.1.1.cmml" xref="A1.SS4.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.p2.1.m1.1d">italic_k</annotation></semantics></math> programming problems and 160<math alttext="k" class="ltx_Math" display="inline" id="A1.SS4.p2.2.m2.1"><semantics id="A1.SS4.p2.2.m2.1a"><mi id="A1.SS4.p2.2.m2.1.1" xref="A1.SS4.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS4.p2.2.m2.1b"><ci id="A1.SS4.p2.2.m2.1.1.cmml" xref="A1.SS4.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.SS4.p2.2.m2.1d">italic_k</annotation></semantics></math> retrieval documents in total.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p3">
<p class="ltx_p" id="A1.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p3.1.1">Does the dataset contain all possible instances or is it a sample of instances from a larger set?</span>  For code generation datasets, our <span class="ltx_text ltx_font_smallcaps" id="A1.SS4.p3.1.2">CodeRAG-Bench</span> contains all possible instances. For retrieval sources, our <span class="ltx_text ltx_font_smallcaps" id="A1.SS4.p3.1.3">CodeRAG-Bench</span> contains a subset of documents in high quality.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p4">
<p class="ltx_p" id="A1.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p4.1.1">What data does each instance consist of?</span>  Each example in code generation tasks consists of the problem statement, reference solution, executable test cases, and other necessary metadata specific to individual tasks.
Each example in retrieval documents contains the textual content and other optional metadata specific to individual sources. All fields in both types are represented by texts.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p5">
<p class="ltx_p" id="A1.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p5.1.1">Is there a label or target associated with each instance</span>  Each example in code generation tasks is associated with canonical test cases, which serve as the role of labels because model-generated programs need to be executed over and pass all test cases to verify the correctness.
Examples in retrieval documents do not have a label because they are collected for retrieval to augment contexts, instead of end evaluation purposes.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p6">
<p class="ltx_p" id="A1.SS4.p6.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p6.1.1">Is any information missing from individual instances?</span>  No, we did not remove any information collected throughout the process.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p7">
<p class="ltx_p" id="A1.SS4.p7.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p7.1.1">Are relationships between individual instances made explicit?</span>  Yes. We mark examples that are originated from each dataset or each retrieval sources, by putting them into different dataset splits.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p8">
<p class="ltx_p" id="A1.SS4.p8.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p8.1.1">Are there recommended data splits?</span>  Our <span class="ltx_text ltx_font_smallcaps" id="A1.SS4.p8.1.2">CodeRAG-Bench</span> is built for evaluation purposes and only has the test split, though we do not explicitly split to to ‘test’ since ‘train’ and ‘validation’ sets do not exist.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p9">
<p class="ltx_p" id="A1.SS4.p9.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p9.1.1">Are there any errors, sources of noise, or redundancies in the dataset?</span>  For code generation tasks, we build upon existing high-quality datasets and the authors conduct manual assessments of each dataset. We do not notice any noticeable errors among randomly sampled instances.
For retrieval sources, we apply several layers to clean the scraped texts, but they may not appear perfectly standard and noises are possible.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p10">
<p class="ltx_p" id="A1.SS4.p10.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p10.1.1">Is the dataset self-contained, or does it link to or otherwise rely on external resources?</span>  Our dataset is self-contained and do not rely on external resources.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p11">
<p class="ltx_p" id="A1.SS4.p11.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p11.1.1">Does the dataset contain data that might be considered confidential?</span>  No, we collect documents from permissively licensed sources.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p12">
<p class="ltx_p" id="A1.SS4.p12.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p12.1.1">Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?</span>  No, we collect programming data, which by default should not involve offensive languages.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p13">
<p class="ltx_p" id="A1.SS4.p13.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p13.1.1">Does the dataset identify any subpopulations?</span>  No, our dataset does not include metadata that are specifically related to any subpopulations (e.g., age, gender).</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p14">
<p class="ltx_p" id="A1.SS4.p14.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p14.1.1">Is it possible to identify individuals, either directly or indirectly, from the dataset?</span>  No, our dataset is unlikely to contain user-specific information such as name or other personally identifiable data.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p15">
<p class="ltx_p" id="A1.SS4.p15.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p15.1.1">Does the dataset contain data that might be considered sensitive in any way?</span>  No.</p>
</div>
<section class="ltx_subsubsection" id="A1.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.1 </span>Collection Process</h4>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS1.p1">
<p class="ltx_p" id="A1.SS4.SSS1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS1.p1.1.1">How was the data associated with each instance acquired?</span>  The data is derived from existing datasets and online resources.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS1.p2">
<p class="ltx_p" id="A1.SS4.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS1.p2.1.1">What mechanisms or procedures were used to collect the data?</span>  We first automatically collect retrieval sources to construct a large-scale document pool. We then iteratively conduct manual verification and content refinement to ensure the data quality.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS1.p3">
<p class="ltx_p" id="A1.SS4.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS1.p3.1.1">If the dataset is a sample from a larger set, what was the sampling strategy?</span>  Only the StackOverflow posts and GitHub repositories are sampled, randomly from the full set.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS1.p4">
<p class="ltx_p" id="A1.SS4.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS1.p4.1.1">Who was involved in the data collection process and how were they compensated?</span>  Graduate student researchers who authored this work were involved in the data collection process. The students were compensated by the authorship of this paper.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS1.p5">
<p class="ltx_p" id="A1.SS4.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS1.p5.1.1">Over what timeframe was the data collected?</span>  March 2024 to May 2024.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS1.p6">
<p class="ltx_p" id="A1.SS4.SSS1.p6.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS1.p6.1.1">Were any ethical review processes conducted?</span>  No. Because our benchmark does not involve human annotation and is mostly automatic, and the data collected are mainly about programming without raised ethical concerns, we did not find it necessary to conduct ethical reviews.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.2 </span>Preprocessing/cleaning/labeling</h4>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS2.p1">
<p class="ltx_p" id="A1.SS4.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS2.p1.1.1">Was any preprocessing/cleaning/labeling of the data done</span>  For code generation datasets, we perform manual labeling of the ground-truth documents.
For retrieval documents, we perform necessary cleaning to ensure the quality and clarity of these documents.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS2.p2">
<p class="ltx_p" id="A1.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS2.p2.1.1">Was the “raw” data saved in addition to the preprocessed/cleaned/labeled data?</span>  Yes, the raw data is accessible through its original sources, which we individually referenced in the main paper.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS2.p3">
<p class="ltx_p" id="A1.SS4.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS2.p3.1.1">Is the software that was used to preprocess/clean/label the data available?</span>  Yes, the software is provided by our codebase.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.3 </span>Uses</h4>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS3.p1">
<p class="ltx_p" id="A1.SS4.SSS3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS3.p1.1.1">Has the dataset been used for any tasks already?</span>  No.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS3.p2">
<p class="ltx_p" id="A1.SS4.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS3.p2.1.1">What (other) tasks could the dataset be used for?</span>  In addition to code generation and retrieval-augmented code generation tasks that we have experimented in this work, our dataset could be potentially extended to other programming tasks or programming document retrieval tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS3.p3">
<p class="ltx_p" id="A1.SS4.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS3.p3.1.1">Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses?</span>  Our dataset is centered around code generation tasks, but this paradigm could be further extended to other programming-related tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS3.p4">
<p class="ltx_p" id="A1.SS4.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS3.p4.1.1">Are there tasks for which the dataset should not be used?</span>  No.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS4.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.4 </span>Distribution</h4>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS4.p1">
<p class="ltx_p" id="A1.SS4.SSS4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS4.p1.1.1">Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created?</span>  No.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS4.p2">
<p class="ltx_p" id="A1.SS4.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS4.p2.1.1">How will the dataset will be distributed?</span>  By Huggingface and GitHub, see the URLs in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS1" title="A.1 Access to CodeRAG-Bench ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS4.p3">
<p class="ltx_p" id="A1.SS4.SSS4.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS4.p3.1.1">When will the dataset be distributed?</span>  The dataset will be distributed on Jun 6th, 2024.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS4.p4">
<p class="ltx_p" id="A1.SS4.SSS4.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS4.p4.1.1">Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?</span>  The dataset will be distributed under the Apache 2.0 license.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS4.p5">
<p class="ltx_p" id="A1.SS4.SSS4.p5.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS4.p5.1.1">Have any third parties imposed IP-based or other restrictions on the data associated with the instances?</span>  No.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS4.p6">
<p class="ltx_p" id="A1.SS4.SSS4.p6.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS4.p6.1.1">Do any export controls or other regulatory restrictions apply to the dataset or to individual instances? </span>  No.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS4.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.5 </span>Maintainence</h4>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS5.p1">
<p class="ltx_p" id="A1.SS4.SSS5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS5.p1.1.1">Who will be supporting/hosting/maintaining the dataset?</span>  The authors of this work will be supporting/hosting/maintaining the dataset. All of the URLs are available at §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#A1.SS1" title="A.1 Access to CodeRAG-Bench ‣ Appendix A Appendix: Datasheets for Datasets ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">A.1</span></a>.
<span class="ltx_text ltx_font_bold" id="A1.SS4.SSS5.p1.1.2">Is there an erratum?</span>  No.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS5.p2">
<p class="ltx_p" id="A1.SS4.SSS5.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS5.p2.1.1">Will the dataset be updated?</span>  No, at least no plans to do so at the submission time.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS5.p3">
<p class="ltx_p" id="A1.SS4.SSS5.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS5.p3.1.1">If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances?</span>  No, the dataset is not related to people.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS5.p4">
<p class="ltx_p" id="A1.SS4.SSS5.p4.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS5.p4.1.1">Will older versions of the dataset continue to be supported/hosted/maintained?</span>  We are not planning to update the dataset and will continue to host the current version.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS5.p5">
<p class="ltx_p" id="A1.SS4.SSS5.p5.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.SSS5.p5.1.1">If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?</span>  Yes, we will make our datasets and codebase publicly available, anyone in the community is welcome to contribute or leave comments.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Example Illustrations</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Example with Canonical Documents</h3>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">To present our canonical document annotation (§<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S2.SS3" title="2.3 Canonical Document Annotation ‣ 2 The CodeRAG-Bench ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">2.3</span></a>) more concretely, we illustrate examples with their annotated canonical documents.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#A2.F4" title="Figure 4 ‣ B.1 Example with Canonical Documents ‣ Appendix B Example Illustrations ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Figure 4</span></a> shows the general-programming examples, with one HumanEval and one MBPP example, respectively.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#A2.F5" title="Figure 5 ‣ B.1 Example with Canonical Documents ‣ Appendix B Example Illustrations ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Figure 5</span></a> shows two open-domain coding examples with canonical library documentation from DS-1000 and ODEX, respectively.</p>
</div>
<figure class="ltx_figure" id="A2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="500" id="A2.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>HumanEval (left) and MBPP (right) examples with annotated canonical solutions.</figcaption>
</figure>
<figure class="ltx_figure" id="A2.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="516" id="A2.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>DS-1000 (left) and ODEX (right) examples with annotated canonical library documentation.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>RACG with Helpful and Distracting Documents</h3>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">Beyond the numerical numbers reported in experiment sections, here we provide some concrete examples that: (i) benefit from RACG when relevant documents are retrieved, and (ii) distracted by irrelevant documents retrieved hence results in degraded performance.</p>
</div>
<figure class="ltx_figure" id="A2.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="391" id="A2.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>RACG helps with relevant contexts (left) and hurts with distracting contexts (right).</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional Details about Retrieval Efficiency</h2>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">For open access models, we use the same single A100 GPU with 80 GRAM, with a batch size of 64 for GIST base and large, and 8 for SFR-Mistral.
For proprietary models, we estimate their efficiency using a batch size of 64. We then average the time for each batch for each query and document. For Voyage-code, we apply a “dynamic-batching” technique that make sure the total tokens in the batch won’t exceed the token limit. For both open and proprietary models, we define the search efficiency as the time it takes to embed individual query and the time to calculate similarities. Note that the time for both can be optimized by tokenizing all documents and all queries, then taking the dot product.
The actual runtime for API models varies for each organization with different rate limits and the batch size.
For this experiment, we set the maximum context length to match the maximum length of the original models. This notably increases the encoding latency of SFR Mixtral, which has a longer maximum context window size than smaller embedding models.</p>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Result Reproduction</h2>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">In <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.14497v1#S3.T5" title="Table 5 ‣ 3.3 Generation with and without Canonical Documents ‣ 3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">Table 5</span></a> in §<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#S3" title="3 Canonical RACG: Experiments and Results ‣ CodeRAG-Bench: Can Retrieval Augment Code Generation?"><span class="ltx_text ltx_ref_tag">3</span></a>, we are able to reproduce most results reported in the original papers, but with minor variances. Here we explain the differences in implementation and (potential) reasons that lead to these small performance variances.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p2">
<p class="ltx_p" id="A4.p2.1"><span class="ltx_text ltx_font_bold" id="A4.p2.1.1">Our approach</span>  To keep a fair comparison among all models, we use the same prompt for each dataset when evaluating all models. Meanwhile, we use zero-shot prompts without any additional instructions, i.e., only input the original problem description of the example, to prevent unknown effects on the model performance when using different instructions and/or in-context examples.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p3">
<p class="ltx_p" id="A4.p3.1">According to this setup, we next describe the differences in prompts used by the original works and how they may affect the results.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p4">
<p class="ltx_p" id="A4.p4.1"><span class="ltx_text ltx_font_bold" id="A4.p4.1.1">StarCoder2</span>  The StarCoder2 technical report <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib23" title="">23</a>]</cite> reported results on the HumanEval, MBPP, and DS-1000 datasets.
On HumanEval, our reproduced results (31.7) is slightly lower than their number (35.4), possibly because the original paper additionally input the test cases as additional information in the prompt, whereas in our basic NL-to-code setup, no test cases are provided. This additional information may cause their results to be higher.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p5">
<p class="ltx_p" id="A4.p5.1">On MBPP dataset, they adopt a subset of MBPP, i.e., 399 out of 427 examples that have additional test cases populated by <cite class="ltx_cite ltx_citemacro_citet">Liu et al. [<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib22" title="">22</a>]</cite>. In contrast, we evaluate on the entire dataset, which is likely to cause the variance in results.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p6">
<p class="ltx_p" id="A4.p6.1">On DS-1000, the original paper samples 40 generations and report the pass@1 rate, while we only generate one program with greedy decoding. This difference in decoding strategy may cause slight variance in the results.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p7">
<p class="ltx_p" id="A4.p7.1"><span class="ltx_text ltx_font_bold" id="A4.p7.1.1">CodeGemma</span>  The CodeGemma technical report <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib38" title="">38</a>]</cite> reported results on HumanEval and MBPP datasets, but does not provide any details about the instructions, few-shot examples, or other parts of the prompt that they use. We were able to roughly reproduce their reported results, but with 3-5 points less in pass@1.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p8">
<p class="ltx_p" id="A4.p8.1"><span class="ltx_text ltx_font_bold" id="A4.p8.1.1">CodeLlama</span>  The CodeLlama technical report <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib34" title="">34</a>]</cite> reports results on HumanEval and MBPP datasets. We were able to perfectly reproduce their results on the HumanEval dataset under the zero-shot setting. However, for MBPP experiments, they use 3-shot prompting, which could potentially explain that our zero-shot results are 4 points lower in pass@1.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p9">
<p class="ltx_p" id="A4.p9.1"><span class="ltx_text ltx_font_bold" id="A4.p9.1.1">DeepSeekCoder</span>  The DeepSeekCoder technical report <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.14497v1#bib.bib10" title="">10</a>]</cite> reports results on HumanEval and MBPP for the 7B-instruct-v1.5 and the 33B-instruct models, the report additionally report DS1000 results for the 33B-instruct model.
We could reproduce the original results on HumanEval and DS-1000, but got slightly worse results on MBPP because they used few-shot prompting, which should outperform our zero-shot method.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p10">
<p class="ltx_p" id="A4.p10.1"><span class="ltx_text ltx_font_bold" id="A4.p10.1.1">Llama3</span>  Since there is no technical report available yet, the official blog post <span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/blog/meta-llama-3/" title="">https://ai.meta.com/blog/meta-llama-3/</a></span></span></span> report results on HumanEval, without any descriptions on prompting construction or the inference process. Our reproduced results are about 4 points lower than their original results.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jun 20 15:07:09 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
