<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LightRAG: Simple and Fast Retrieval-Augmented Generation</title>
<!--Generated on Tue Oct  8 07:58:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.05779v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S1" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S2" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Retrieval-Augmented Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S3" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>The LightRAG Architecture</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S3.SS1" title="In 3 The LightRAG Architecture ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Graph-based Text Indexing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S3.SS2" title="In 3 The LightRAG Architecture ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Dual-level Retrieval Paradigm</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S3.SS3" title="In 3 The LightRAG Architecture ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Retrieval-Augmented Answer Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S3.SS4" title="In 3 The LightRAG Architecture ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Complexity Analysis of the LightRAG Framework</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.SS1" title="In 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.SS2" title="In 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Comparison of LightRAGwith Existing RAG Methods (RQ1)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.SS3" title="In 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Ablation Studies (RQ2)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.SS4" title="In 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Case Study (RQ3)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.SS5" title="In 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Model Cost and Adaptability Analysis (RQ4)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S5" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S5.SS1" title="In 5 Related Work ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Retrieval-Augmented Generation with LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S5.SS2" title="In 5 Related Work ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Large Language Model for Graphs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S6" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7" title="In LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS1" title="In 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Experimental Data Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS2" title="In 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Case Example of Retrieval-Augmented Generation in LightRAG.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3" title="In 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Overview of the Prompts Used in LightRAG</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3.SSS1" title="In 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.1 </span>Prompts for Graph Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3.SSS2" title="In 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.2 </span>Prompts for Query Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3.SSS3" title="In 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.3 </span>Prompts for Keyword Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3.SSS4" title="In 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3.4 </span>Prompts for RAG Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS4" title="In 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.4 </span>Case Study: Comparison Between LightRAG and the Baseline NaiveRAG.</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">LightRAG: Simple and Fast 
<br class="ltx_break"/>Retrieval-Augmented Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zirui Guo<sup class="ltx_sup" id="id8.8.id1"><span class="ltx_text ltx_font_italic" id="id8.8.id1.1">1,2</span></sup>, Lianghao Xia<sup class="ltx_sup" id="id9.9.id2"><span class="ltx_text ltx_font_italic" id="id9.9.id2.1">2</span></sup>, Yanhua Yu<sup class="ltx_sup" id="id10.10.id3"><span class="ltx_text ltx_font_italic" id="id10.10.id3.1">1</span></sup>, Tu Ao<sup class="ltx_sup" id="id11.11.id4"><span class="ltx_text ltx_font_italic" id="id11.11.id4.1">1</span></sup>, <span class="ltx_text ltx_font_bold" id="id5.5.1">Chao Huang<sup class="ltx_sup" id="id5.5.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id5.5.1.1.1">2</span></sup></span>
<br class="ltx_break"/>Beijing University of Posts and Telecommunications<sup class="ltx_sup" id="id12.12.id5">1</sup>
<br class="ltx_break"/>University of Hong Kong<sup class="ltx_sup" id="id13.13.id6">2</sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id14.14.id7">zrguo101@hku.hk  aka_xia@foxmail.com  chaohuang75@gmail.com</span>
</span><span class="ltx_author_notes">Chao Huang is the corresponding author.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id15.id1"><span class="ltx_text" id="id15.id1.1">Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user needs. However, existing RAG systems have significant limitations, including reliance on flat data representations and inadequate contextual awareness, which can lead to fragmented answers that fail to capture complex inter-dependencies. To address these challenges, we propose LightRAG, which incorporates graph structures into text indexing and retrieval processes. This innovative framework employs a dual-level retrieval system that enhances comprehensive information retrieval from both low-level and high-level knowledge discovery. Additionally, the integration of graph structures with vector representations facilitates efficient retrieval of related entities and their relationships, significantly improving response times while maintaining contextual relevance. This capability is further enhanced by an incremental update algorithm that ensures the timely integration of new data, allowing the system to remain effective and responsive in rapidly changing data environments. Extensive experimental validation demonstrates considerable improvements in retrieval accuracy and efficiency compared to existing approaches. We have made our LightRAG open-source and available at the link: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/HKUDS/LightRAG" style="color:#0000FF;" title="">https://github.com/HKUDS/LightRAG</a>.</span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Retrieval-Augmented Generation (RAG) systems have been developed to enhance large language models (LLMs) by integrating external knowledge sources <cite class="ltx_cite ltx_citemacro_cite">Sudhi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib16" title="">2024</a>); Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib5" title="">2024</a>); Salemi &amp; Zamani (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib15" title="">2024</a>)</cite>. This innovative integration allows LLMs to generate more accurate and contextually relevant responses, significantly improving their utility in real-world applications. By adapting to specific domain knowledge <cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib18" title="">2024</a>)</cite>, RAG systems ensure that the information provided is not only pertinent but also tailored to the user’s needs. Furthermore, they offer access to up-to-date information <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib21" title="">2024</a>)</cite>, which is crucial in rapidly evolving fields. Chunking plays a vital role in facilitating the retrieval-augmented generation process <cite class="ltx_cite ltx_citemacro_cite">Lyu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib11" title="">2024</a>)</cite>. By breaking down a large external text corpus into smaller, more manageable segments, chunking significantly enhances the accuracy of information retrieval. This approach allows for more targeted similarity searches, ensuring that the retrieved content is directly relevant to user queries.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, existing RAG systems have key limitations that hinder their performance. <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">First</span>, many methods rely on flat data representations, restricting their ability to understand and retrieve information based on intricate relationships between entities. <span class="ltx_text ltx_font_bold" id="S1.p2.1.2">Second</span>, these systems often lack the contextual awareness needed to maintain coherence across various entities and their interrelations, resulting in responses that may not fully address user queries. For example, consider a user asking, “How does the rise of electric vehicles influence urban air quality and public transportation infrastructure?” Existing RAG methods might retrieve separate documents on electric vehicles, air pollution, and public transportation challenges but struggle to synthesize this information into a cohesive response. They may fail to explain how the adoption of electric vehicles can improve air quality, which in turn could affect public transportation planning. As a result, the user may receive a fragmented answer that does not adequately capture the complex inter-dependencies among these topics.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address these limitations, we propose incorporating graph structures into text indexing and relevant information retrieval. Graphs are particularly effective at representing the interdependencies among different entities <cite class="ltx_cite ltx_citemacro_cite">Rampášek et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib14" title="">2022</a>)</cite>, which enables a more nuanced understanding of relationships. The integration of graph-based knowledge structures facilitates the synthesis of information from multiple sources into coherent and contextually rich responses. Despite these advantages, developing a fast and scalable graph-empowered RAG system that efficiently handles varying query volumes is crucial. In this work, we achieve an effective and efficient RAG system by addressing three key challenges: i) <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Comprehensive Information Retrieval</span>. Ensuring comprehensive information retrieval that captures the full context of inter-dependent entities from all documents; ii) <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">Enhanced Retrieval Efficiency</span>. Improving retrieval efficiency over the graph-based knowledge structures to significantly reduce response times; iii) <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">Rapid Adaptation to New Data</span>. Enabling quick adaptation to new data updates, ensuring the system remains relevant in dynamic environments.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In response to the outlined challenges, we propose LightRAG, a model that seamlessly integrates a graph-based text indexing paradigm with a dual-level retrieval framework. This innovative approach enhances the system’s capacity to capture complex inter-dependencies among entities, resulting in more coherent and contextually rich responses. LightRAG employs efficient dual-level retrieval strategies: low-level retrieval, which focuses on precise information about specific entities and their relationships, and high-level retrieval, which encompasses broader topics and themes. By combining both detailed and conceptual retrieval, LightRAG effectively accommodates a diverse range of quries, ensuring that users receive relevant and comprehensive responses tailored to their specific needs. Additionally, by integrating graph structures with vector representations, our framework facilitates efficient retrieval of related entities and relations while enhancing the comprehensiveness of results through relevant structural information from the constructed knowledge graph.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In summary, the key contributions of this work are highlighted as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">General Aspect</span>. We emphasize the importance of developing a graph-empowered RAG system to overcome the limitations of existing methods. By integrating graph structures into text indexing, we can effectively represent complex interdependencies among entities, fostering a nuanced understanding of relationships and enabling coherent, contextually rich responses.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Methodologies</span>. To enable an efficient and adaptive RAG system, we propose LightRAG, which integrates a dual-level retrieval paradigm with graph-enhanced text indexing. This approach captures both low-level and high-level information for comprehensive, cost-effective retrieval. By eliminating the need to rebuild the entire index, LightRAG reduces computational costs and accelerates adaptation, while its incremental update algorithm ensures timely integration of new data, maintaining effectiveness in dynamic environments.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Experimental Findings</span>. Extensive experiments were conducted to evaluate the effectiveness of LightRAG in comparison to existing RAG models. These assessments focused on several key dimensions, including retrieval accuracy, model ablation, response efficiency, and adaptability to new information. The results demonstrated significant improvements over baseline methods.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Retrieval-Augmented Generation</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Retrieval-Augmented Generation (RAG) integrates user queries with a collection of pertinent documents sourced from an external knowledge database, incorporating two essential elements: the <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Retrieval Component</span> and the <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">Generation Component</span>. 1) The retrieval component is responsible for fetching relevant documents or information from the external knowledge database. It identifies and retrieves the most pertinent data based on the input query. 2) After the retrieval process, the generation component takes the retrieved information and generates coherent, contextually relevant responses. It leverages the capabilities of the language model to produce meaningful outputs.
Formally, this RAG framework, denoted as <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">caligraphic_M</annotation></semantics></math>, can be defined as follows:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx1">
<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{M}=\Big{(}\mathcal{G},\leavevmode\nobreak\ \leavevmode%
\nobreak\ \mathcal{R}=(\varphi,\psi)\Big{)},\leavevmode\nobreak\ \leavevmode%
\nobreak\ \leavevmode\nobreak\ \mathcal{M}(q;\mathcal{D})=\mathcal{G}\Big{(}q,%
\psi(q;\hat{\mathcal{D}})\Big{)},\leavevmode\nobreak\ \leavevmode\nobreak\ %
\leavevmode\nobreak\ \hat{\mathcal{D}}=\varphi(\mathcal{D})" class="ltx_Math" display="inline" id="S2.E1.m1.12"><semantics id="S2.E1.m1.12a"><mrow id="S2.E1.m1.12.12.2" xref="S2.E1.m1.12.12.3.cmml"><mrow id="S2.E1.m1.11.11.1.1" xref="S2.E1.m1.11.11.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.11.11.1.1.3" xref="S2.E1.m1.11.11.1.1.3.cmml">ℳ</mi><mo id="S2.E1.m1.11.11.1.1.2" xref="S2.E1.m1.11.11.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.11.11.1.1.1.1" xref="S2.E1.m1.11.11.1.1.1.1.1.cmml"><mo id="S2.E1.m1.11.11.1.1.1.1.2" maxsize="160%" minsize="160%" xref="S2.E1.m1.11.11.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.11.11.1.1.1.1.1" xref="S2.E1.m1.11.11.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.11.11.1.1.1.1.1.2.2" xref="S2.E1.m1.11.11.1.1.1.1.1.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">𝒢</mi><mo id="S2.E1.m1.11.11.1.1.1.1.1.2.2.1" rspace="1.167em" xref="S2.E1.m1.11.11.1.1.1.1.1.2.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">ℛ</mi></mrow><mo id="S2.E1.m1.11.11.1.1.1.1.1.1" xref="S2.E1.m1.11.11.1.1.1.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.11.11.1.1.1.1.1.3.2" xref="S2.E1.m1.11.11.1.1.1.1.1.3.1.cmml"><mo id="S2.E1.m1.11.11.1.1.1.1.1.3.2.1" stretchy="false" xref="S2.E1.m1.11.11.1.1.1.1.1.3.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">φ</mi><mo id="S2.E1.m1.11.11.1.1.1.1.1.3.2.2" xref="S2.E1.m1.11.11.1.1.1.1.1.3.1.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">ψ</mi><mo id="S2.E1.m1.11.11.1.1.1.1.1.3.2.3" stretchy="false" xref="S2.E1.m1.11.11.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.11.11.1.1.1.1.3" maxsize="160%" minsize="160%" xref="S2.E1.m1.11.11.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.12.12.2.3" rspace="1.667em" xref="S2.E1.m1.12.12.3a.cmml">,</mo><mrow id="S2.E1.m1.12.12.2.2.2" xref="S2.E1.m1.12.12.2.2.3.cmml"><mrow id="S2.E1.m1.12.12.2.2.1.1" xref="S2.E1.m1.12.12.2.2.1.1.cmml"><mrow id="S2.E1.m1.12.12.2.2.1.1.3" xref="S2.E1.m1.12.12.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.12.12.2.2.1.1.3.2" xref="S2.E1.m1.12.12.2.2.1.1.3.2.cmml">ℳ</mi><mo id="S2.E1.m1.12.12.2.2.1.1.3.1" xref="S2.E1.m1.12.12.2.2.1.1.3.1.cmml">⁢</mo><mrow id="S2.E1.m1.12.12.2.2.1.1.3.3.2" xref="S2.E1.m1.12.12.2.2.1.1.3.3.1.cmml"><mo id="S2.E1.m1.12.12.2.2.1.1.3.3.2.1" stretchy="false" xref="S2.E1.m1.12.12.2.2.1.1.3.3.1.cmml">(</mo><mi id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml">q</mi><mo id="S2.E1.m1.12.12.2.2.1.1.3.3.2.2" xref="S2.E1.m1.12.12.2.2.1.1.3.3.1.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.6.6" xref="S2.E1.m1.6.6.cmml">𝒟</mi><mo id="S2.E1.m1.12.12.2.2.1.1.3.3.2.3" stretchy="false" xref="S2.E1.m1.12.12.2.2.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.12.12.2.2.1.1.2" xref="S2.E1.m1.12.12.2.2.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.12.12.2.2.1.1.1" xref="S2.E1.m1.12.12.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.12.12.2.2.1.1.1.3" xref="S2.E1.m1.12.12.2.2.1.1.1.3.cmml">𝒢</mi><mo id="S2.E1.m1.12.12.2.2.1.1.1.2" xref="S2.E1.m1.12.12.2.2.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.12.12.2.2.1.1.1.1.1" xref="S2.E1.m1.12.12.2.2.1.1.1.1.2.cmml"><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.2" maxsize="160%" minsize="160%" xref="S2.E1.m1.12.12.2.2.1.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.9.9" xref="S2.E1.m1.9.9.cmml">q</mi><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.3" xref="S2.E1.m1.12.12.2.2.1.1.1.1.2.cmml">,</mo><mrow id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.2.cmml">ψ</mi><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.1" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.2" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.1.cmml"><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml">q</mi><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.2.2" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.1.cmml">;</mo><mover accent="true" id="S2.E1.m1.8.8" xref="S2.E1.m1.8.8.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.8.8.2" xref="S2.E1.m1.8.8.2.cmml">𝒟</mi><mo id="S2.E1.m1.8.8.1" xref="S2.E1.m1.8.8.1.cmml">^</mo></mover><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.2.3" stretchy="false" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.12.12.2.2.1.1.1.1.1.4" maxsize="160%" minsize="160%" xref="S2.E1.m1.12.12.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E1.m1.12.12.2.2.2.3" rspace="1.667em" xref="S2.E1.m1.12.12.2.2.3a.cmml">,</mo><mrow id="S2.E1.m1.12.12.2.2.2.2" xref="S2.E1.m1.12.12.2.2.2.2.cmml"><mover accent="true" id="S2.E1.m1.12.12.2.2.2.2.2" xref="S2.E1.m1.12.12.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.12.12.2.2.2.2.2.2" xref="S2.E1.m1.12.12.2.2.2.2.2.2.cmml">𝒟</mi><mo id="S2.E1.m1.12.12.2.2.2.2.2.1" xref="S2.E1.m1.12.12.2.2.2.2.2.1.cmml">^</mo></mover><mo id="S2.E1.m1.12.12.2.2.2.2.1" xref="S2.E1.m1.12.12.2.2.2.2.1.cmml">=</mo><mrow id="S2.E1.m1.12.12.2.2.2.2.3" xref="S2.E1.m1.12.12.2.2.2.2.3.cmml"><mi id="S2.E1.m1.12.12.2.2.2.2.3.2" xref="S2.E1.m1.12.12.2.2.2.2.3.2.cmml">φ</mi><mo id="S2.E1.m1.12.12.2.2.2.2.3.1" xref="S2.E1.m1.12.12.2.2.2.2.3.1.cmml">⁢</mo><mrow id="S2.E1.m1.12.12.2.2.2.2.3.3.2" xref="S2.E1.m1.12.12.2.2.2.2.3.cmml"><mo id="S2.E1.m1.12.12.2.2.2.2.3.3.2.1" stretchy="false" xref="S2.E1.m1.12.12.2.2.2.2.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.10.10" xref="S2.E1.m1.10.10.cmml">𝒟</mi><mo id="S2.E1.m1.12.12.2.2.2.2.3.3.2.2" stretchy="false" xref="S2.E1.m1.12.12.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.12b"><apply id="S2.E1.m1.12.12.3.cmml" xref="S2.E1.m1.12.12.2"><csymbol cd="ambiguous" id="S2.E1.m1.12.12.3a.cmml" xref="S2.E1.m1.12.12.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.11.11.1.1.cmml" xref="S2.E1.m1.11.11.1.1"><eq id="S2.E1.m1.11.11.1.1.2.cmml" xref="S2.E1.m1.11.11.1.1.2"></eq><ci id="S2.E1.m1.11.11.1.1.3.cmml" xref="S2.E1.m1.11.11.1.1.3">ℳ</ci><apply id="S2.E1.m1.11.11.1.1.1.1.1.cmml" xref="S2.E1.m1.11.11.1.1.1.1"><eq id="S2.E1.m1.11.11.1.1.1.1.1.1.cmml" xref="S2.E1.m1.11.11.1.1.1.1.1.1"></eq><list id="S2.E1.m1.11.11.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.11.11.1.1.1.1.1.2.2"><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝒢</ci><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ℛ</ci></list><interval closure="open" id="S2.E1.m1.11.11.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.11.11.1.1.1.1.1.3.2"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝜑</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝜓</ci></interval></apply></apply><apply id="S2.E1.m1.12.12.2.2.3.cmml" xref="S2.E1.m1.12.12.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.12.12.2.2.3a.cmml" xref="S2.E1.m1.12.12.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.12.12.2.2.1.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1"><eq id="S2.E1.m1.12.12.2.2.1.1.2.cmml" xref="S2.E1.m1.12.12.2.2.1.1.2"></eq><apply id="S2.E1.m1.12.12.2.2.1.1.3.cmml" xref="S2.E1.m1.12.12.2.2.1.1.3"><times id="S2.E1.m1.12.12.2.2.1.1.3.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1.3.1"></times><ci id="S2.E1.m1.12.12.2.2.1.1.3.2.cmml" xref="S2.E1.m1.12.12.2.2.1.1.3.2">ℳ</ci><list id="S2.E1.m1.12.12.2.2.1.1.3.3.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1.3.3.2"><ci id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">𝑞</ci><ci id="S2.E1.m1.6.6.cmml" xref="S2.E1.m1.6.6">𝒟</ci></list></apply><apply id="S2.E1.m1.12.12.2.2.1.1.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1"><times id="S2.E1.m1.12.12.2.2.1.1.1.2.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.2"></times><ci id="S2.E1.m1.12.12.2.2.1.1.1.3.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.3">𝒢</ci><interval closure="open" id="S2.E1.m1.12.12.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1"><ci id="S2.E1.m1.9.9.cmml" xref="S2.E1.m1.9.9">𝑞</ci><apply id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1"><times id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.1"></times><ci id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.2">𝜓</ci><list id="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.12.12.2.2.1.1.1.1.1.1.3.2"><ci id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7">𝑞</ci><apply id="S2.E1.m1.8.8.cmml" xref="S2.E1.m1.8.8"><ci id="S2.E1.m1.8.8.1.cmml" xref="S2.E1.m1.8.8.1">^</ci><ci id="S2.E1.m1.8.8.2.cmml" xref="S2.E1.m1.8.8.2">𝒟</ci></apply></list></apply></interval></apply></apply><apply id="S2.E1.m1.12.12.2.2.2.2.cmml" xref="S2.E1.m1.12.12.2.2.2.2"><eq id="S2.E1.m1.12.12.2.2.2.2.1.cmml" xref="S2.E1.m1.12.12.2.2.2.2.1"></eq><apply id="S2.E1.m1.12.12.2.2.2.2.2.cmml" xref="S2.E1.m1.12.12.2.2.2.2.2"><ci id="S2.E1.m1.12.12.2.2.2.2.2.1.cmml" xref="S2.E1.m1.12.12.2.2.2.2.2.1">^</ci><ci id="S2.E1.m1.12.12.2.2.2.2.2.2.cmml" xref="S2.E1.m1.12.12.2.2.2.2.2.2">𝒟</ci></apply><apply id="S2.E1.m1.12.12.2.2.2.2.3.cmml" xref="S2.E1.m1.12.12.2.2.2.2.3"><times id="S2.E1.m1.12.12.2.2.2.2.3.1.cmml" xref="S2.E1.m1.12.12.2.2.2.2.3.1"></times><ci id="S2.E1.m1.12.12.2.2.2.2.3.2.cmml" xref="S2.E1.m1.12.12.2.2.2.2.3.2">𝜑</ci><ci id="S2.E1.m1.10.10.cmml" xref="S2.E1.m1.10.10">𝒟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.12c">\displaystyle\mathcal{M}=\Big{(}\mathcal{G},\leavevmode\nobreak\ \leavevmode%
\nobreak\ \mathcal{R}=(\varphi,\psi)\Big{)},\leavevmode\nobreak\ \leavevmode%
\nobreak\ \leavevmode\nobreak\ \mathcal{M}(q;\mathcal{D})=\mathcal{G}\Big{(}q,%
\psi(q;\hat{\mathcal{D}})\Big{)},\leavevmode\nobreak\ \leavevmode\nobreak\ %
\leavevmode\nobreak\ \hat{\mathcal{D}}=\varphi(\mathcal{D})</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.12d">caligraphic_M = ( caligraphic_G , caligraphic_R = ( italic_φ , italic_ψ ) ) , caligraphic_M ( italic_q ; caligraphic_D ) = caligraphic_G ( italic_q , italic_ψ ( italic_q ; over^ start_ARG caligraphic_D end_ARG ) ) , over^ start_ARG caligraphic_D end_ARG = italic_φ ( caligraphic_D )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.p1.13">In this framework, <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="S2.p1.2.m1.1"><semantics id="S2.p1.2.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.2.m1.1.1" xref="S2.p1.2.m1.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m1.1b"><ci id="S2.p1.2.m1.1.1.cmml" xref="S2.p1.2.m1.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m1.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m1.1d">caligraphic_G</annotation></semantics></math> and <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.p1.3.m2.1"><semantics id="S2.p1.3.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.3.m2.1.1" xref="S2.p1.3.m2.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m2.1b"><ci id="S2.p1.3.m2.1.1.cmml" xref="S2.p1.3.m2.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m2.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m2.1d">caligraphic_R</annotation></semantics></math> represent the generation module and the retrieval module, respectively, while <math alttext="q" class="ltx_Math" display="inline" id="S2.p1.4.m3.1"><semantics id="S2.p1.4.m3.1a"><mi id="S2.p1.4.m3.1.1" xref="S2.p1.4.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.p1.4.m3.1b"><ci id="S2.p1.4.m3.1.1.cmml" xref="S2.p1.4.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m3.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m3.1d">italic_q</annotation></semantics></math> denotes the input query and <math alttext="D" class="ltx_Math" display="inline" id="S2.p1.5.m4.1"><semantics id="S2.p1.5.m4.1a"><mi id="S2.p1.5.m4.1.1" xref="S2.p1.5.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.p1.5.m4.1b"><ci id="S2.p1.5.m4.1.1.cmml" xref="S2.p1.5.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m4.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.p1.5.m4.1d">italic_D</annotation></semantics></math> refers to the external database. The retrieval module <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.p1.6.m5.1"><semantics id="S2.p1.6.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.6.m5.1.1" xref="S2.p1.6.m5.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.6.m5.1b"><ci id="S2.p1.6.m5.1.1.cmml" xref="S2.p1.6.m5.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m5.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.6.m5.1d">caligraphic_R</annotation></semantics></math> includes two key functionalities: i) <span class="ltx_text ltx_font_bold" id="S2.p1.13.1">Data Indexer</span> <math alttext="\varphi(\cdot)" class="ltx_Math" display="inline" id="S2.p1.7.m6.1"><semantics id="S2.p1.7.m6.1a"><mrow id="S2.p1.7.m6.1.2" xref="S2.p1.7.m6.1.2.cmml"><mi id="S2.p1.7.m6.1.2.2" xref="S2.p1.7.m6.1.2.2.cmml">φ</mi><mo id="S2.p1.7.m6.1.2.1" xref="S2.p1.7.m6.1.2.1.cmml">⁢</mo><mrow id="S2.p1.7.m6.1.2.3.2" xref="S2.p1.7.m6.1.2.cmml"><mo id="S2.p1.7.m6.1.2.3.2.1" stretchy="false" xref="S2.p1.7.m6.1.2.cmml">(</mo><mo id="S2.p1.7.m6.1.1" lspace="0em" rspace="0em" xref="S2.p1.7.m6.1.1.cmml">⋅</mo><mo id="S2.p1.7.m6.1.2.3.2.2" stretchy="false" xref="S2.p1.7.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.7.m6.1b"><apply id="S2.p1.7.m6.1.2.cmml" xref="S2.p1.7.m6.1.2"><times id="S2.p1.7.m6.1.2.1.cmml" xref="S2.p1.7.m6.1.2.1"></times><ci id="S2.p1.7.m6.1.2.2.cmml" xref="S2.p1.7.m6.1.2.2">𝜑</ci><ci id="S2.p1.7.m6.1.1.cmml" xref="S2.p1.7.m6.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m6.1c">\varphi(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.p1.7.m6.1d">italic_φ ( ⋅ )</annotation></semantics></math>: which involves building a specific data structure <math alttext="\hat{\mathcal{D}}" class="ltx_Math" display="inline" id="S2.p1.8.m7.1"><semantics id="S2.p1.8.m7.1a"><mover accent="true" id="S2.p1.8.m7.1.1" xref="S2.p1.8.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.8.m7.1.1.2" xref="S2.p1.8.m7.1.1.2.cmml">𝒟</mi><mo id="S2.p1.8.m7.1.1.1" xref="S2.p1.8.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.p1.8.m7.1b"><apply id="S2.p1.8.m7.1.1.cmml" xref="S2.p1.8.m7.1.1"><ci id="S2.p1.8.m7.1.1.1.cmml" xref="S2.p1.8.m7.1.1.1">^</ci><ci id="S2.p1.8.m7.1.1.2.cmml" xref="S2.p1.8.m7.1.1.2">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m7.1c">\hat{\mathcal{D}}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.8.m7.1d">over^ start_ARG caligraphic_D end_ARG</annotation></semantics></math> based on the external database <math alttext="D" class="ltx_Math" display="inline" id="S2.p1.9.m8.1"><semantics id="S2.p1.9.m8.1a"><mi id="S2.p1.9.m8.1.1" xref="S2.p1.9.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.p1.9.m8.1b"><ci id="S2.p1.9.m8.1.1.cmml" xref="S2.p1.9.m8.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m8.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.p1.9.m8.1d">italic_D</annotation></semantics></math>. ii) <span class="ltx_text ltx_font_bold" id="S2.p1.13.2">Data Retriever</span> <math alttext="\psi(\cdot)" class="ltx_Math" display="inline" id="S2.p1.10.m9.1"><semantics id="S2.p1.10.m9.1a"><mrow id="S2.p1.10.m9.1.2" xref="S2.p1.10.m9.1.2.cmml"><mi id="S2.p1.10.m9.1.2.2" xref="S2.p1.10.m9.1.2.2.cmml">ψ</mi><mo id="S2.p1.10.m9.1.2.1" xref="S2.p1.10.m9.1.2.1.cmml">⁢</mo><mrow id="S2.p1.10.m9.1.2.3.2" xref="S2.p1.10.m9.1.2.cmml"><mo id="S2.p1.10.m9.1.2.3.2.1" stretchy="false" xref="S2.p1.10.m9.1.2.cmml">(</mo><mo id="S2.p1.10.m9.1.1" lspace="0em" rspace="0em" xref="S2.p1.10.m9.1.1.cmml">⋅</mo><mo id="S2.p1.10.m9.1.2.3.2.2" stretchy="false" xref="S2.p1.10.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.10.m9.1b"><apply id="S2.p1.10.m9.1.2.cmml" xref="S2.p1.10.m9.1.2"><times id="S2.p1.10.m9.1.2.1.cmml" xref="S2.p1.10.m9.1.2.1"></times><ci id="S2.p1.10.m9.1.2.2.cmml" xref="S2.p1.10.m9.1.2.2">𝜓</ci><ci id="S2.p1.10.m9.1.1.cmml" xref="S2.p1.10.m9.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m9.1c">\psi(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.p1.10.m9.1d">italic_ψ ( ⋅ )</annotation></semantics></math>: The relevant documents are obtained by comparing the query against the indexed data, also denoted as “relevant documents”. By leveraging the information retrieved through <math alttext="\psi(\cdot)" class="ltx_Math" display="inline" id="S2.p1.11.m10.1"><semantics id="S2.p1.11.m10.1a"><mrow id="S2.p1.11.m10.1.2" xref="S2.p1.11.m10.1.2.cmml"><mi id="S2.p1.11.m10.1.2.2" xref="S2.p1.11.m10.1.2.2.cmml">ψ</mi><mo id="S2.p1.11.m10.1.2.1" xref="S2.p1.11.m10.1.2.1.cmml">⁢</mo><mrow id="S2.p1.11.m10.1.2.3.2" xref="S2.p1.11.m10.1.2.cmml"><mo id="S2.p1.11.m10.1.2.3.2.1" stretchy="false" xref="S2.p1.11.m10.1.2.cmml">(</mo><mo id="S2.p1.11.m10.1.1" lspace="0em" rspace="0em" xref="S2.p1.11.m10.1.1.cmml">⋅</mo><mo id="S2.p1.11.m10.1.2.3.2.2" stretchy="false" xref="S2.p1.11.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.11.m10.1b"><apply id="S2.p1.11.m10.1.2.cmml" xref="S2.p1.11.m10.1.2"><times id="S2.p1.11.m10.1.2.1.cmml" xref="S2.p1.11.m10.1.2.1"></times><ci id="S2.p1.11.m10.1.2.2.cmml" xref="S2.p1.11.m10.1.2.2">𝜓</ci><ci id="S2.p1.11.m10.1.1.cmml" xref="S2.p1.11.m10.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m10.1c">\psi(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.p1.11.m10.1d">italic_ψ ( ⋅ )</annotation></semantics></math> along with the initial query <math alttext="q" class="ltx_Math" display="inline" id="S2.p1.12.m11.1"><semantics id="S2.p1.12.m11.1a"><mi id="S2.p1.12.m11.1.1" xref="S2.p1.12.m11.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.p1.12.m11.1b"><ci id="S2.p1.12.m11.1.1.cmml" xref="S2.p1.12.m11.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.12.m11.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.p1.12.m11.1d">italic_q</annotation></semantics></math>, the generative model <math alttext="\mathcal{G}(\cdot)" class="ltx_Math" display="inline" id="S2.p1.13.m12.1"><semantics id="S2.p1.13.m12.1a"><mrow id="S2.p1.13.m12.1.2" xref="S2.p1.13.m12.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.13.m12.1.2.2" xref="S2.p1.13.m12.1.2.2.cmml">𝒢</mi><mo id="S2.p1.13.m12.1.2.1" xref="S2.p1.13.m12.1.2.1.cmml">⁢</mo><mrow id="S2.p1.13.m12.1.2.3.2" xref="S2.p1.13.m12.1.2.cmml"><mo id="S2.p1.13.m12.1.2.3.2.1" stretchy="false" xref="S2.p1.13.m12.1.2.cmml">(</mo><mo id="S2.p1.13.m12.1.1" lspace="0em" rspace="0em" xref="S2.p1.13.m12.1.1.cmml">⋅</mo><mo id="S2.p1.13.m12.1.2.3.2.2" stretchy="false" xref="S2.p1.13.m12.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.13.m12.1b"><apply id="S2.p1.13.m12.1.2.cmml" xref="S2.p1.13.m12.1.2"><times id="S2.p1.13.m12.1.2.1.cmml" xref="S2.p1.13.m12.1.2.1"></times><ci id="S2.p1.13.m12.1.2.2.cmml" xref="S2.p1.13.m12.1.2.2">𝒢</ci><ci id="S2.p1.13.m12.1.1.cmml" xref="S2.p1.13.m12.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.13.m12.1c">\mathcal{G}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.p1.13.m12.1d">caligraphic_G ( ⋅ )</annotation></semantics></math> efficiently produces high-quality, contextually relevant responses.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In this work, we target several key points essential for an efficient and effective Retrieval-Augmented Generation (RAG) system which are elaborated below:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Comprehensive Information Retrieval</span>: The indexing function <math alttext="\varphi(\cdot)" class="ltx_Math" display="inline" id="S2.I1.i1.p1.1.m1.1"><semantics id="S2.I1.i1.p1.1.m1.1a"><mrow id="S2.I1.i1.p1.1.m1.1.2" xref="S2.I1.i1.p1.1.m1.1.2.cmml"><mi id="S2.I1.i1.p1.1.m1.1.2.2" xref="S2.I1.i1.p1.1.m1.1.2.2.cmml">φ</mi><mo id="S2.I1.i1.p1.1.m1.1.2.1" xref="S2.I1.i1.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S2.I1.i1.p1.1.m1.1.2.3.2" xref="S2.I1.i1.p1.1.m1.1.2.cmml"><mo id="S2.I1.i1.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S2.I1.i1.p1.1.m1.1.2.cmml">(</mo><mo id="S2.I1.i1.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S2.I1.i1.p1.1.m1.1.1.cmml">⋅</mo><mo id="S2.I1.i1.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S2.I1.i1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.2"><times id="S2.I1.i1.p1.1.m1.1.2.1.cmml" xref="S2.I1.i1.p1.1.m1.1.2.1"></times><ci id="S2.I1.i1.p1.1.m1.1.2.2.cmml" xref="S2.I1.i1.p1.1.m1.1.2.2">𝜑</ci><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">\varphi(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.1.m1.1d">italic_φ ( ⋅ )</annotation></semantics></math> must be adept at extracting global information, as this is crucial for enhancing the model’s ability to answer queries effectively.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Efficient and Low-Cost Retrieval</span>: The indexed data structure <math alttext="\hat{\mathcal{D}}" class="ltx_Math" display="inline" id="S2.I1.i2.p1.1.m1.1"><semantics id="S2.I1.i2.p1.1.m1.1a"><mover accent="true" id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i2.p1.1.m1.1.1.2" xref="S2.I1.i2.p1.1.m1.1.1.2.cmml">𝒟</mi><mo id="S2.I1.i2.p1.1.m1.1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><ci id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1.1">^</ci><ci id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">\hat{\mathcal{D}}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i2.p1.1.m1.1d">over^ start_ARG caligraphic_D end_ARG</annotation></semantics></math> must enable rapid and cost-efficient retrieval to effectively handle a high volume of queries.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Fast Adaptation to Data Changes</span>: The ability to swiftly and efficiently adjust the data structure to incorporate new information from the external knowledge base, is crucial for ensuring that the system remains current and relevant in an ever-changing information landscape.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The LightRAG Architecture</h2>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S3.F1.g1" src="x1.png" width="761"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overall architecture of the proposed LightRAG framework.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Graph-based Text Indexing</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.3"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.3.1">Graph-Enhanced Entity and Relationship Extraction</span>. Our LightRAG enhances the retrieval system by segmenting documents into smaller, more manageable pieces. This strategy allows for quick identification and access to relevant information without analyzing entire documents. Next, we leverage LLMs to identify and extract various entities (e.g., names, dates, locations, and events) along with the relationships between them. The information collected through this process will be used to create a comprehensive knowledge graph that highlights the connections and insights across the entire collection of documents. We formally represent this graph generation module as follows:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx2">
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\hat{\mathcal{D}}=(\hat{\mathcal{V}},\hat{\mathcal{E}})=\text{%
Dedupe}\circ\text{Prof}(\mathcal{V},\mathcal{E}),\leavevmode\nobreak\ %
\leavevmode\nobreak\ \leavevmode\nobreak\ \mathcal{V},\mathcal{E}=\cup_{%
\mathcal{D}_{i}\in\mathcal{D}}\text{Recog}(\mathcal{D}_{i})" class="ltx_Math" display="inline" id="S3.E2.m1.8"><semantics id="S3.E2.m1.8a"><mrow id="S3.E2.m1.8.8.2" xref="S3.E2.m1.8.8.3.cmml"><mrow id="S3.E2.m1.7.7.1.1" xref="S3.E2.m1.7.7.1.1.cmml"><mover accent="true" id="S3.E2.m1.7.7.1.1.2" xref="S3.E2.m1.7.7.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.7.7.1.1.2.2" xref="S3.E2.m1.7.7.1.1.2.2.cmml">𝒟</mi><mo id="S3.E2.m1.7.7.1.1.2.1" xref="S3.E2.m1.7.7.1.1.2.1.cmml">^</mo></mover><mo id="S3.E2.m1.7.7.1.1.3" xref="S3.E2.m1.7.7.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.7.7.1.1.4.2" xref="S3.E2.m1.7.7.1.1.4.1.cmml"><mo id="S3.E2.m1.7.7.1.1.4.2.1" stretchy="false" xref="S3.E2.m1.7.7.1.1.4.1.cmml">(</mo><mover accent="true" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">𝒱</mi><mo id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml">^</mo></mover><mo id="S3.E2.m1.7.7.1.1.4.2.2" xref="S3.E2.m1.7.7.1.1.4.1.cmml">,</mo><mover accent="true" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml">ℰ</mi><mo id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.cmml">^</mo></mover><mo id="S3.E2.m1.7.7.1.1.4.2.3" stretchy="false" xref="S3.E2.m1.7.7.1.1.4.1.cmml">)</mo></mrow><mo id="S3.E2.m1.7.7.1.1.5" xref="S3.E2.m1.7.7.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.7.7.1.1.6" xref="S3.E2.m1.7.7.1.1.6.cmml"><mrow id="S3.E2.m1.7.7.1.1.6.2" xref="S3.E2.m1.7.7.1.1.6.2.cmml"><mtext id="S3.E2.m1.7.7.1.1.6.2.2" xref="S3.E2.m1.7.7.1.1.6.2.2a.cmml">Dedupe</mtext><mo id="S3.E2.m1.7.7.1.1.6.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.7.7.1.1.6.2.1.cmml">∘</mo><mtext id="S3.E2.m1.7.7.1.1.6.2.3" xref="S3.E2.m1.7.7.1.1.6.2.3a.cmml">Prof</mtext></mrow><mo id="S3.E2.m1.7.7.1.1.6.1" xref="S3.E2.m1.7.7.1.1.6.1.cmml">⁢</mo><mrow id="S3.E2.m1.7.7.1.1.6.3.2" xref="S3.E2.m1.7.7.1.1.6.3.1.cmml"><mo id="S3.E2.m1.7.7.1.1.6.3.2.1" stretchy="false" xref="S3.E2.m1.7.7.1.1.6.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">𝒱</mi><mo id="S3.E2.m1.7.7.1.1.6.3.2.2" xref="S3.E2.m1.7.7.1.1.6.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">ℰ</mi><mo id="S3.E2.m1.7.7.1.1.6.3.2.3" stretchy="false" xref="S3.E2.m1.7.7.1.1.6.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.8.8.2.3" rspace="1.667em" xref="S3.E2.m1.8.8.3a.cmml">,</mo><mrow id="S3.E2.m1.8.8.2.2" xref="S3.E2.m1.8.8.2.2.cmml"><mrow id="S3.E2.m1.8.8.2.2.3.2" xref="S3.E2.m1.8.8.2.2.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml">𝒱</mi><mo id="S3.E2.m1.8.8.2.2.3.2.1" xref="S3.E2.m1.8.8.2.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml">ℰ</mi></mrow><mo id="S3.E2.m1.8.8.2.2.2" rspace="0em" xref="S3.E2.m1.8.8.2.2.2.cmml">=</mo><mrow id="S3.E2.m1.8.8.2.2.1" xref="S3.E2.m1.8.8.2.2.1.cmml"><msub id="S3.E2.m1.8.8.2.2.1.2" xref="S3.E2.m1.8.8.2.2.1.2.cmml"><mo id="S3.E2.m1.8.8.2.2.1.2.2" lspace="0em" xref="S3.E2.m1.8.8.2.2.1.2.2.cmml">∪</mo><mrow id="S3.E2.m1.8.8.2.2.1.2.3" xref="S3.E2.m1.8.8.2.2.1.2.3.cmml"><msub id="S3.E2.m1.8.8.2.2.1.2.3.2" xref="S3.E2.m1.8.8.2.2.1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.8.8.2.2.1.2.3.2.2" xref="S3.E2.m1.8.8.2.2.1.2.3.2.2.cmml">𝒟</mi><mi id="S3.E2.m1.8.8.2.2.1.2.3.2.3" xref="S3.E2.m1.8.8.2.2.1.2.3.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.8.8.2.2.1.2.3.1" xref="S3.E2.m1.8.8.2.2.1.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.8.8.2.2.1.2.3.3" xref="S3.E2.m1.8.8.2.2.1.2.3.3.cmml">𝒟</mi></mrow></msub><mrow id="S3.E2.m1.8.8.2.2.1.1" xref="S3.E2.m1.8.8.2.2.1.1.cmml"><mtext id="S3.E2.m1.8.8.2.2.1.1.3" xref="S3.E2.m1.8.8.2.2.1.1.3a.cmml">Recog</mtext><mo id="S3.E2.m1.8.8.2.2.1.1.2" xref="S3.E2.m1.8.8.2.2.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.8.8.2.2.1.1.1.1" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.cmml"><mo id="S3.E2.m1.8.8.2.2.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.8.8.2.2.1.1.1.1.1" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.8.8.2.2.1.1.1.1.1.2" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.2.cmml">𝒟</mi><mi id="S3.E2.m1.8.8.2.2.1.1.1.1.1.3" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.8.8.2.2.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.8b"><apply id="S3.E2.m1.8.8.3.cmml" xref="S3.E2.m1.8.8.2"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.3a.cmml" xref="S3.E2.m1.8.8.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.7.7.1.1.cmml" xref="S3.E2.m1.7.7.1.1"><and id="S3.E2.m1.7.7.1.1a.cmml" xref="S3.E2.m1.7.7.1.1"></and><apply id="S3.E2.m1.7.7.1.1b.cmml" xref="S3.E2.m1.7.7.1.1"><eq id="S3.E2.m1.7.7.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.3"></eq><apply id="S3.E2.m1.7.7.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.2"><ci id="S3.E2.m1.7.7.1.1.2.1.cmml" xref="S3.E2.m1.7.7.1.1.2.1">^</ci><ci id="S3.E2.m1.7.7.1.1.2.2.cmml" xref="S3.E2.m1.7.7.1.1.2.2">𝒟</ci></apply><interval closure="open" id="S3.E2.m1.7.7.1.1.4.1.cmml" xref="S3.E2.m1.7.7.1.1.4.2"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><ci id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1">^</ci><ci id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2">𝒱</ci></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><ci id="S3.E2.m1.2.2.1.cmml" xref="S3.E2.m1.2.2.1">^</ci><ci id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2">ℰ</ci></apply></interval></apply><apply id="S3.E2.m1.7.7.1.1c.cmml" xref="S3.E2.m1.7.7.1.1"><eq id="S3.E2.m1.7.7.1.1.5.cmml" xref="S3.E2.m1.7.7.1.1.5"></eq><share href="https://arxiv.org/html/2410.05779v1#S3.E2.m1.7.7.1.1.4.cmml" id="S3.E2.m1.7.7.1.1d.cmml" xref="S3.E2.m1.7.7.1.1"></share><apply id="S3.E2.m1.7.7.1.1.6.cmml" xref="S3.E2.m1.7.7.1.1.6"><times id="S3.E2.m1.7.7.1.1.6.1.cmml" xref="S3.E2.m1.7.7.1.1.6.1"></times><apply id="S3.E2.m1.7.7.1.1.6.2.cmml" xref="S3.E2.m1.7.7.1.1.6.2"><compose id="S3.E2.m1.7.7.1.1.6.2.1.cmml" xref="S3.E2.m1.7.7.1.1.6.2.1"></compose><ci id="S3.E2.m1.7.7.1.1.6.2.2a.cmml" xref="S3.E2.m1.7.7.1.1.6.2.2"><mtext id="S3.E2.m1.7.7.1.1.6.2.2.cmml" xref="S3.E2.m1.7.7.1.1.6.2.2">Dedupe</mtext></ci><ci id="S3.E2.m1.7.7.1.1.6.2.3a.cmml" xref="S3.E2.m1.7.7.1.1.6.2.3"><mtext id="S3.E2.m1.7.7.1.1.6.2.3.cmml" xref="S3.E2.m1.7.7.1.1.6.2.3">Prof</mtext></ci></apply><interval closure="open" id="S3.E2.m1.7.7.1.1.6.3.1.cmml" xref="S3.E2.m1.7.7.1.1.6.3.2"><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝒱</ci><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">ℰ</ci></interval></apply></apply></apply><apply id="S3.E2.m1.8.8.2.2.cmml" xref="S3.E2.m1.8.8.2.2"><eq id="S3.E2.m1.8.8.2.2.2.cmml" xref="S3.E2.m1.8.8.2.2.2"></eq><list id="S3.E2.m1.8.8.2.2.3.1.cmml" xref="S3.E2.m1.8.8.2.2.3.2"><ci id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5">𝒱</ci><ci id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6">ℰ</ci></list><apply id="S3.E2.m1.8.8.2.2.1.cmml" xref="S3.E2.m1.8.8.2.2.1"><apply id="S3.E2.m1.8.8.2.2.1.2.cmml" xref="S3.E2.m1.8.8.2.2.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.2.2.1.2.1.cmml" xref="S3.E2.m1.8.8.2.2.1.2">subscript</csymbol><union id="S3.E2.m1.8.8.2.2.1.2.2.cmml" xref="S3.E2.m1.8.8.2.2.1.2.2"></union><apply id="S3.E2.m1.8.8.2.2.1.2.3.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3"><in id="S3.E2.m1.8.8.2.2.1.2.3.1.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3.1"></in><apply id="S3.E2.m1.8.8.2.2.1.2.3.2.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.2.2.1.2.3.2.1.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3.2">subscript</csymbol><ci id="S3.E2.m1.8.8.2.2.1.2.3.2.2.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3.2.2">𝒟</ci><ci id="S3.E2.m1.8.8.2.2.1.2.3.2.3.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3.2.3">𝑖</ci></apply><ci id="S3.E2.m1.8.8.2.2.1.2.3.3.cmml" xref="S3.E2.m1.8.8.2.2.1.2.3.3">𝒟</ci></apply></apply><apply id="S3.E2.m1.8.8.2.2.1.1.cmml" xref="S3.E2.m1.8.8.2.2.1.1"><times id="S3.E2.m1.8.8.2.2.1.1.2.cmml" xref="S3.E2.m1.8.8.2.2.1.1.2"></times><ci id="S3.E2.m1.8.8.2.2.1.1.3a.cmml" xref="S3.E2.m1.8.8.2.2.1.1.3"><mtext id="S3.E2.m1.8.8.2.2.1.1.3.cmml" xref="S3.E2.m1.8.8.2.2.1.1.3">Recog</mtext></ci><apply id="S3.E2.m1.8.8.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.8.8.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.8.8.2.2.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.8.8.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.2">𝒟</ci><ci id="S3.E2.m1.8.8.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.8.8.2.2.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.8c">\displaystyle\hat{\mathcal{D}}=(\hat{\mathcal{V}},\hat{\mathcal{E}})=\text{%
Dedupe}\circ\text{Prof}(\mathcal{V},\mathcal{E}),\leavevmode\nobreak\ %
\leavevmode\nobreak\ \leavevmode\nobreak\ \mathcal{V},\mathcal{E}=\cup_{%
\mathcal{D}_{i}\in\mathcal{D}}\text{Recog}(\mathcal{D}_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.8d">over^ start_ARG caligraphic_D end_ARG = ( over^ start_ARG caligraphic_V end_ARG , over^ start_ARG caligraphic_E end_ARG ) = Dedupe ∘ Prof ( caligraphic_V , caligraphic_E ) , caligraphic_V , caligraphic_E = ∪ start_POSTSUBSCRIPT caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_D end_POSTSUBSCRIPT Recog ( caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.2">where <math alttext="\hat{\mathcal{D}}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mover accent="true" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">𝒟</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><ci id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">^</ci><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\hat{\mathcal{D}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">over^ start_ARG caligraphic_D end_ARG</annotation></semantics></math> represents the resulting knowledge graphs. To generate this data, we apply three main processing steps to the raw text documents <math alttext="\mathcal{D}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">𝒟</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝒟</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{D}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. These steps utilize a LLM for text analysis and processing. Details about the prompt templates and specific settings for this part can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3.SSS2" title="7.3.2 Prompts for Query Generation ‣ 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">7.3.2</span></a>. The functions used in our graph-based text indexing paradigm are described as:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.3"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.3.1">Extracting Entities and Relationships</span>. <math alttext="\text{R}(\cdot)" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><mrow id="S3.I1.i1.p1.1.m1.1.2" xref="S3.I1.i1.p1.1.m1.1.2.cmml"><mtext id="S3.I1.i1.p1.1.m1.1.2.2" xref="S3.I1.i1.p1.1.m1.1.2.2a.cmml">R</mtext><mo id="S3.I1.i1.p1.1.m1.1.2.1" xref="S3.I1.i1.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.I1.i1.p1.1.m1.1.2.3.2" xref="S3.I1.i1.p1.1.m1.1.2.cmml"><mo id="S3.I1.i1.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.I1.i1.p1.1.m1.1.2.cmml">(</mo><mo id="S3.I1.i1.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S3.I1.i1.p1.1.m1.1.1.cmml">⋅</mo><mo id="S3.I1.i1.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.I1.i1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.2"><times id="S3.I1.i1.p1.1.m1.1.2.1.cmml" xref="S3.I1.i1.p1.1.m1.1.2.1"></times><ci id="S3.I1.i1.p1.1.m1.1.2.2a.cmml" xref="S3.I1.i1.p1.1.m1.1.2.2"><mtext id="S3.I1.i1.p1.1.m1.1.2.2.cmml" xref="S3.I1.i1.p1.1.m1.1.2.2">R</mtext></ci><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">\text{R}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">R ( ⋅ )</annotation></semantics></math>: This function prompts a LLM to identify entities (nodes) and their relationships (edges) within the text data. For instance, it can extract entities like "Cardiologists" and "Heart Disease," and relationships such as "Cardiologists diagnose Heart Disease" from the text: "Cardiologists assess symptoms to identify potential heart issues." To improve efficiency, the raw text <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.1"><semantics id="S3.I1.i1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.1d">caligraphic_D</annotation></semantics></math> is segmented into multiple chunks <math alttext="\mathcal{D}_{i}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.3.m3.1"><semantics id="S3.I1.i1.p1.3.m3.1a"><msub id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i1.p1.3.m3.1.1.2" xref="S3.I1.i1.p1.3.m3.1.1.2.cmml">𝒟</mi><mi id="S3.I1.i1.p1.3.m3.1.1.3" xref="S3.I1.i1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><apply id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.3.m3.1.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.3.m3.1.1.2.cmml" xref="S3.I1.i1.p1.3.m3.1.1.2">𝒟</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">\mathcal{D}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.5"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.5.1">LLM Profiling for Key-Value Pair Generation</span>. <math alttext="\text{P}(\cdot)" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.2" xref="S3.I1.i2.p1.1.m1.1.2.cmml"><mtext id="S3.I1.i2.p1.1.m1.1.2.2" xref="S3.I1.i2.p1.1.m1.1.2.2a.cmml">P</mtext><mo id="S3.I1.i2.p1.1.m1.1.2.1" xref="S3.I1.i2.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.I1.i2.p1.1.m1.1.2.3.2" xref="S3.I1.i2.p1.1.m1.1.2.cmml"><mo id="S3.I1.i2.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.I1.i2.p1.1.m1.1.2.cmml">(</mo><mo id="S3.I1.i2.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S3.I1.i2.p1.1.m1.1.1.cmml">⋅</mo><mo id="S3.I1.i2.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.I1.i2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.2"><times id="S3.I1.i2.p1.1.m1.1.2.1.cmml" xref="S3.I1.i2.p1.1.m1.1.2.1"></times><ci id="S3.I1.i2.p1.1.m1.1.2.2a.cmml" xref="S3.I1.i2.p1.1.m1.1.2.2"><mtext id="S3.I1.i2.p1.1.m1.1.2.2.cmml" xref="S3.I1.i2.p1.1.m1.1.2.2">P</mtext></ci><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">\text{P}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">P ( ⋅ )</annotation></semantics></math>: We employ a LLM-empowered profiling function, <math alttext="\text{P}(\cdot)" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mrow id="S3.I1.i2.p1.2.m2.1.2" xref="S3.I1.i2.p1.2.m2.1.2.cmml"><mtext id="S3.I1.i2.p1.2.m2.1.2.2" xref="S3.I1.i2.p1.2.m2.1.2.2a.cmml">P</mtext><mo id="S3.I1.i2.p1.2.m2.1.2.1" xref="S3.I1.i2.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.I1.i2.p1.2.m2.1.2.3.2" xref="S3.I1.i2.p1.2.m2.1.2.cmml"><mo id="S3.I1.i2.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S3.I1.i2.p1.2.m2.1.2.cmml">(</mo><mo id="S3.I1.i2.p1.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.I1.i2.p1.2.m2.1.1.cmml">⋅</mo><mo id="S3.I1.i2.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S3.I1.i2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><apply id="S3.I1.i2.p1.2.m2.1.2.cmml" xref="S3.I1.i2.p1.2.m2.1.2"><times id="S3.I1.i2.p1.2.m2.1.2.1.cmml" xref="S3.I1.i2.p1.2.m2.1.2.1"></times><ci id="S3.I1.i2.p1.2.m2.1.2.2a.cmml" xref="S3.I1.i2.p1.2.m2.1.2.2"><mtext id="S3.I1.i2.p1.2.m2.1.2.2.cmml" xref="S3.I1.i2.p1.2.m2.1.2.2">P</mtext></ci><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">\text{P}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">P ( ⋅ )</annotation></semantics></math>, to generate a text key-value pair <math alttext="(K,V)" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.2"><semantics id="S3.I1.i2.p1.3.m3.2a"><mrow id="S3.I1.i2.p1.3.m3.2.3.2" xref="S3.I1.i2.p1.3.m3.2.3.1.cmml"><mo id="S3.I1.i2.p1.3.m3.2.3.2.1" stretchy="false" xref="S3.I1.i2.p1.3.m3.2.3.1.cmml">(</mo><mi id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml">K</mi><mo id="S3.I1.i2.p1.3.m3.2.3.2.2" xref="S3.I1.i2.p1.3.m3.2.3.1.cmml">,</mo><mi id="S3.I1.i2.p1.3.m3.2.2" xref="S3.I1.i2.p1.3.m3.2.2.cmml">V</mi><mo id="S3.I1.i2.p1.3.m3.2.3.2.3" stretchy="false" xref="S3.I1.i2.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.2b"><interval closure="open" id="S3.I1.i2.p1.3.m3.2.3.1.cmml" xref="S3.I1.i2.p1.3.m3.2.3.2"><ci id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">𝐾</ci><ci id="S3.I1.i2.p1.3.m3.2.2.cmml" xref="S3.I1.i2.p1.3.m3.2.2">𝑉</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.2c">(K,V)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.2d">( italic_K , italic_V )</annotation></semantics></math> for each entity node in <math alttext="\mathcal{V}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.4.m4.1"><semantics id="S3.I1.i2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i2.p1.4.m4.1.1" xref="S3.I1.i2.p1.4.m4.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.4.m4.1b"><ci id="S3.I1.i2.p1.4.m4.1.1.cmml" xref="S3.I1.i2.p1.4.m4.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.4.m4.1c">\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.4.m4.1d">caligraphic_V</annotation></semantics></math> and relation edge in <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.5.m5.1"><semantics id="S3.I1.i2.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i2.p1.5.m5.1.1" xref="S3.I1.i2.p1.5.m5.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.5.m5.1b"><ci id="S3.I1.i2.p1.5.m5.1.1.cmml" xref="S3.I1.i2.p1.5.m5.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.5.m5.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.5.m5.1d">caligraphic_E</annotation></semantics></math>. Each index key is a word or short phrase that enables efficient retrieval, while the corresponding value is a text paragraph summarizing relevant snippets from external data to aid in text generation. Entities use their names as the sole index key, whereas relations may have multiple index keys derived from LLM enhancements that include global themes from connected entities.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.4"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.4.1">Deduplication to Optimize Graph Operations</span>. <math alttext="\text{D}(\cdot)" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mrow id="S3.I1.i3.p1.1.m1.1.2" xref="S3.I1.i3.p1.1.m1.1.2.cmml"><mtext id="S3.I1.i3.p1.1.m1.1.2.2" xref="S3.I1.i3.p1.1.m1.1.2.2a.cmml">D</mtext><mo id="S3.I1.i3.p1.1.m1.1.2.1" xref="S3.I1.i3.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.I1.i3.p1.1.m1.1.2.3.2" xref="S3.I1.i3.p1.1.m1.1.2.cmml"><mo id="S3.I1.i3.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.I1.i3.p1.1.m1.1.2.cmml">(</mo><mo id="S3.I1.i3.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S3.I1.i3.p1.1.m1.1.1.cmml">⋅</mo><mo id="S3.I1.i3.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.I1.i3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.p1.1.m1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.2"><times id="S3.I1.i3.p1.1.m1.1.2.1.cmml" xref="S3.I1.i3.p1.1.m1.1.2.1"></times><ci id="S3.I1.i3.p1.1.m1.1.2.2a.cmml" xref="S3.I1.i3.p1.1.m1.1.2.2"><mtext id="S3.I1.i3.p1.1.m1.1.2.2.cmml" xref="S3.I1.i3.p1.1.m1.1.2.2">D</mtext></ci><ci id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">\text{D}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">D ( ⋅ )</annotation></semantics></math>: Finally, we implement a deduplication function, <math alttext="\text{D}(\cdot)" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m2.1"><semantics id="S3.I1.i3.p1.2.m2.1a"><mrow id="S3.I1.i3.p1.2.m2.1.2" xref="S3.I1.i3.p1.2.m2.1.2.cmml"><mtext id="S3.I1.i3.p1.2.m2.1.2.2" xref="S3.I1.i3.p1.2.m2.1.2.2a.cmml">D</mtext><mo id="S3.I1.i3.p1.2.m2.1.2.1" xref="S3.I1.i3.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.I1.i3.p1.2.m2.1.2.3.2" xref="S3.I1.i3.p1.2.m2.1.2.cmml"><mo id="S3.I1.i3.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S3.I1.i3.p1.2.m2.1.2.cmml">(</mo><mo id="S3.I1.i3.p1.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.I1.i3.p1.2.m2.1.1.cmml">⋅</mo><mo id="S3.I1.i3.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S3.I1.i3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b"><apply id="S3.I1.i3.p1.2.m2.1.2.cmml" xref="S3.I1.i3.p1.2.m2.1.2"><times id="S3.I1.i3.p1.2.m2.1.2.1.cmml" xref="S3.I1.i3.p1.2.m2.1.2.1"></times><ci id="S3.I1.i3.p1.2.m2.1.2.2a.cmml" xref="S3.I1.i3.p1.2.m2.1.2.2"><mtext id="S3.I1.i3.p1.2.m2.1.2.2.cmml" xref="S3.I1.i3.p1.2.m2.1.2.2">D</mtext></ci><ci id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">\text{D}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m2.1d">D ( ⋅ )</annotation></semantics></math>, that identifies and merges identical entities and relations from different segments of the raw text <math alttext="\mathcal{D}_{i}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.3.m3.1"><semantics id="S3.I1.i3.p1.3.m3.1a"><msub id="S3.I1.i3.p1.3.m3.1.1" xref="S3.I1.i3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i3.p1.3.m3.1.1.2" xref="S3.I1.i3.p1.3.m3.1.1.2.cmml">𝒟</mi><mi id="S3.I1.i3.p1.3.m3.1.1.3" xref="S3.I1.i3.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.3.m3.1b"><apply id="S3.I1.i3.p1.3.m3.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.3.m3.1.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I1.i3.p1.3.m3.1.1.2.cmml" xref="S3.I1.i3.p1.3.m3.1.1.2">𝒟</ci><ci id="S3.I1.i3.p1.3.m3.1.1.3.cmml" xref="S3.I1.i3.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.3.m3.1c">\mathcal{D}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. This process effectively reduces the overhead associated with graph operations on <math alttext="\hat{\mathcal{D}}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.4.m4.1"><semantics id="S3.I1.i3.p1.4.m4.1a"><mover accent="true" id="S3.I1.i3.p1.4.m4.1.1" xref="S3.I1.i3.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I1.i3.p1.4.m4.1.1.2" xref="S3.I1.i3.p1.4.m4.1.1.2.cmml">𝒟</mi><mo id="S3.I1.i3.p1.4.m4.1.1.1" xref="S3.I1.i3.p1.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.4.m4.1b"><apply id="S3.I1.i3.p1.4.m4.1.1.cmml" xref="S3.I1.i3.p1.4.m4.1.1"><ci id="S3.I1.i3.p1.4.m4.1.1.1.cmml" xref="S3.I1.i3.p1.4.m4.1.1.1">^</ci><ci id="S3.I1.i3.p1.4.m4.1.1.2.cmml" xref="S3.I1.i3.p1.4.m4.1.1.2">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.4.m4.1c">\hat{\mathcal{D}}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.4.m4.1d">over^ start_ARG caligraphic_D end_ARG</annotation></semantics></math> by minimizing the graph’s size, leading to more efficient data processing.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Our LightRAG offers two advantages through its graph-based text indexing paradigm. <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.1">First</em>, <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.2">Comprehensive Information Understanding</span>. The constructed graph structures enable the extraction of global information from multi-hop subgraphs, greatly enhancing LightRAG’s ability to handle complex queries that span multiple document chunks. <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.3">Second</em>, <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.4">Enhanced Retrieval Performance</span>. the key-value data structures derived from the graph are optimized for rapid and precise retrieval. This provides a superior alternative to less accurate embedding matching methods <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib8" title="">2023</a>)</cite> and inefficient chunk traversal techniques <cite class="ltx_cite ltx_citemacro_citep">(Edge et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib4" title="">2024</a>)</cite> commonly used in existing approaches.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.7"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.7.1">Fast Adaptation to Incremental Knowledge Base</span>. To efficiently adapt to evolving data changes while ensuring accurate and relevant responses, our LightRAG incrementally updates the knowledge base without the need for complete reprocessing of the entire external database. For a new document <math alttext="\mathcal{D}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msup id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">𝒟</mi><mo id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">𝒟</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\mathcal{D}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">caligraphic_D start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, the incremental update algorithm processes it using the same graph-based indexing steps <math alttext="\varphi" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">φ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">𝜑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\varphi</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_φ</annotation></semantics></math> as before, resulting in <math alttext="\hat{\mathcal{D}}^{\prime}=(\hat{\mathcal{V}}^{\prime},\hat{\mathcal{E}}^{%
\prime})" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.2"><semantics id="S3.SS1.p4.3.m3.2a"><mrow id="S3.SS1.p4.3.m3.2.2" xref="S3.SS1.p4.3.m3.2.2.cmml"><msup id="S3.SS1.p4.3.m3.2.2.4" xref="S3.SS1.p4.3.m3.2.2.4.cmml"><mover accent="true" id="S3.SS1.p4.3.m3.2.2.4.2" xref="S3.SS1.p4.3.m3.2.2.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.3.m3.2.2.4.2.2" xref="S3.SS1.p4.3.m3.2.2.4.2.2.cmml">𝒟</mi><mo id="S3.SS1.p4.3.m3.2.2.4.2.1" xref="S3.SS1.p4.3.m3.2.2.4.2.1.cmml">^</mo></mover><mo id="S3.SS1.p4.3.m3.2.2.4.3" xref="S3.SS1.p4.3.m3.2.2.4.3.cmml">′</mo></msup><mo id="S3.SS1.p4.3.m3.2.2.3" xref="S3.SS1.p4.3.m3.2.2.3.cmml">=</mo><mrow id="S3.SS1.p4.3.m3.2.2.2.2" xref="S3.SS1.p4.3.m3.2.2.2.3.cmml"><mo id="S3.SS1.p4.3.m3.2.2.2.2.3" stretchy="false" xref="S3.SS1.p4.3.m3.2.2.2.3.cmml">(</mo><msup id="S3.SS1.p4.3.m3.1.1.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.1.1.cmml"><mover accent="true" id="S3.SS1.p4.3.m3.1.1.1.1.1.2" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.3.m3.1.1.1.1.1.2.2" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2.2.cmml">𝒱</mi><mo id="S3.SS1.p4.3.m3.1.1.1.1.1.2.1" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS1.p4.3.m3.1.1.1.1.1.3" xref="S3.SS1.p4.3.m3.1.1.1.1.1.3.cmml">′</mo></msup><mo id="S3.SS1.p4.3.m3.2.2.2.2.4" xref="S3.SS1.p4.3.m3.2.2.2.3.cmml">,</mo><msup id="S3.SS1.p4.3.m3.2.2.2.2.2" xref="S3.SS1.p4.3.m3.2.2.2.2.2.cmml"><mover accent="true" id="S3.SS1.p4.3.m3.2.2.2.2.2.2" xref="S3.SS1.p4.3.m3.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.3.m3.2.2.2.2.2.2.2" xref="S3.SS1.p4.3.m3.2.2.2.2.2.2.2.cmml">ℰ</mi><mo id="S3.SS1.p4.3.m3.2.2.2.2.2.2.1" xref="S3.SS1.p4.3.m3.2.2.2.2.2.2.1.cmml">^</mo></mover><mo id="S3.SS1.p4.3.m3.2.2.2.2.2.3" xref="S3.SS1.p4.3.m3.2.2.2.2.2.3.cmml">′</mo></msup><mo id="S3.SS1.p4.3.m3.2.2.2.2.5" stretchy="false" xref="S3.SS1.p4.3.m3.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.2b"><apply id="S3.SS1.p4.3.m3.2.2.cmml" xref="S3.SS1.p4.3.m3.2.2"><eq id="S3.SS1.p4.3.m3.2.2.3.cmml" xref="S3.SS1.p4.3.m3.2.2.3"></eq><apply id="S3.SS1.p4.3.m3.2.2.4.cmml" xref="S3.SS1.p4.3.m3.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.2.2.4.1.cmml" xref="S3.SS1.p4.3.m3.2.2.4">superscript</csymbol><apply id="S3.SS1.p4.3.m3.2.2.4.2.cmml" xref="S3.SS1.p4.3.m3.2.2.4.2"><ci id="S3.SS1.p4.3.m3.2.2.4.2.1.cmml" xref="S3.SS1.p4.3.m3.2.2.4.2.1">^</ci><ci id="S3.SS1.p4.3.m3.2.2.4.2.2.cmml" xref="S3.SS1.p4.3.m3.2.2.4.2.2">𝒟</ci></apply><ci id="S3.SS1.p4.3.m3.2.2.4.3.cmml" xref="S3.SS1.p4.3.m3.2.2.4.3">′</ci></apply><interval closure="open" id="S3.SS1.p4.3.m3.2.2.2.3.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2"><apply id="S3.SS1.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2"><ci id="S3.SS1.p4.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2.1">^</ci><ci id="S3.SS1.p4.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.2.2">𝒱</ci></apply><ci id="S3.SS1.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.1.3">′</ci></apply><apply id="S3.SS1.p4.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p4.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2.2.2"><ci id="S3.SS1.p4.3.m3.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2.2.2.1">^</ci><ci id="S3.SS1.p4.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2.2.2.2">ℰ</ci></apply><ci id="S3.SS1.p4.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS1.p4.3.m3.2.2.2.2.2.3">′</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.2c">\hat{\mathcal{D}}^{\prime}=(\hat{\mathcal{V}}^{\prime},\hat{\mathcal{E}}^{%
\prime})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.2d">over^ start_ARG caligraphic_D end_ARG start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( over^ start_ARG caligraphic_V end_ARG start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , over^ start_ARG caligraphic_E end_ARG start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT )</annotation></semantics></math>. Subsequently, LightRAGcombines the new graph data with the original by taking the union of the node sets <math alttext="\hat{\mathcal{V}}" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.1"><semantics id="S3.SS1.p4.4.m4.1a"><mover accent="true" id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml">𝒱</mi><mo id="S3.SS1.p4.4.m4.1.1.1" xref="S3.SS1.p4.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><ci id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1.1">^</ci><ci id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">𝒱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\hat{\mathcal{V}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.1d">over^ start_ARG caligraphic_V end_ARG</annotation></semantics></math> and <math alttext="\hat{\mathcal{V}}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m5.1"><semantics id="S3.SS1.p4.5.m5.1a"><msup id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><mover accent="true" id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.5.m5.1.1.2.2" xref="S3.SS1.p4.5.m5.1.1.2.2.cmml">𝒱</mi><mo id="S3.SS1.p4.5.m5.1.1.2.1" xref="S3.SS1.p4.5.m5.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">superscript</csymbol><apply id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2"><ci id="S3.SS1.p4.5.m5.1.1.2.1.cmml" xref="S3.SS1.p4.5.m5.1.1.2.1">^</ci><ci id="S3.SS1.p4.5.m5.1.1.2.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2.2">𝒱</ci></apply><ci id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">\hat{\mathcal{V}}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m5.1d">over^ start_ARG caligraphic_V end_ARG start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, as well as the edge sets <math alttext="\hat{\mathcal{E}}" class="ltx_Math" display="inline" id="S3.SS1.p4.6.m6.1"><semantics id="S3.SS1.p4.6.m6.1a"><mover accent="true" id="S3.SS1.p4.6.m6.1.1" xref="S3.SS1.p4.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.6.m6.1.1.2" xref="S3.SS1.p4.6.m6.1.1.2.cmml">ℰ</mi><mo id="S3.SS1.p4.6.m6.1.1.1" xref="S3.SS1.p4.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.1b"><apply id="S3.SS1.p4.6.m6.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1"><ci id="S3.SS1.p4.6.m6.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1.1">^</ci><ci id="S3.SS1.p4.6.m6.1.1.2.cmml" xref="S3.SS1.p4.6.m6.1.1.2">ℰ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.1c">\hat{\mathcal{E}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.6.m6.1d">over^ start_ARG caligraphic_E end_ARG</annotation></semantics></math> and <math alttext="\hat{\mathcal{E}}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p4.7.m7.1"><semantics id="S3.SS1.p4.7.m7.1a"><msup id="S3.SS1.p4.7.m7.1.1" xref="S3.SS1.p4.7.m7.1.1.cmml"><mover accent="true" id="S3.SS1.p4.7.m7.1.1.2" xref="S3.SS1.p4.7.m7.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.7.m7.1.1.2.2" xref="S3.SS1.p4.7.m7.1.1.2.2.cmml">ℰ</mi><mo id="S3.SS1.p4.7.m7.1.1.2.1" xref="S3.SS1.p4.7.m7.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS1.p4.7.m7.1.1.3" xref="S3.SS1.p4.7.m7.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.1b"><apply id="S3.SS1.p4.7.m7.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m7.1.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1">superscript</csymbol><apply id="S3.SS1.p4.7.m7.1.1.2.cmml" xref="S3.SS1.p4.7.m7.1.1.2"><ci id="S3.SS1.p4.7.m7.1.1.2.1.cmml" xref="S3.SS1.p4.7.m7.1.1.2.1">^</ci><ci id="S3.SS1.p4.7.m7.1.1.2.2.cmml" xref="S3.SS1.p4.7.m7.1.1.2.2">ℰ</ci></apply><ci id="S3.SS1.p4.7.m7.1.1.3.cmml" xref="S3.SS1.p4.7.m7.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.1c">\hat{\mathcal{E}}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.7.m7.1d">over^ start_ARG caligraphic_E end_ARG start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">Two key objectives guide our approach to fast adaptation for the incremental knowledge base: <span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Seamless Integration of New Data</span>. By applying a consistent methodology to new information, the incremental update module allows the LightRAG to integrate new external databases without disrupting the existing graph structure. This approach preserves the integrity of established connections, ensuring that historical data remains accessible while enriching the graph without conflicts or redundancies. <span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.2">Reducing Computational Overhead
</span>. By eliminating the need to rebuild the entire index graph, this method reduces computational overhead and facilitates the rapid assimilation of new data. Consequently, LightRAG maintains system accuracy, provides current information, and conserves resources, ensuring users receive timely updates and enhancing the overall RAG effectiveness.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Dual-level Retrieval Paradigm</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To retrieve relevant information from both specific document chunks and their complex inter-dependencies, our LightRAG proposes generating query keys at both detailed and abstract levels.</p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">Specific Queries</span>. These queries are detail-oriented and typically reference specific entities within the graph, requiring precise retrieval of information associated with particular nodes or edges. For example, a specific query might be, “Who wrote ’Pride and Prejudice’?”</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">Abstract Queries</span>. In contrast, abstract queries are more conceptual, encompassing broader topics, summaries, or overarching themes that are not directly tied to specific entities. An example of an abstract query is, “How does artificial intelligence influence modern education?”</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To accommodate diverse query types, the LightRAG employs two distinct retrieval strategies within the dual-level retrieval paradigm. This ensures that both specific and abstract inquiries are addressed effectively, allowing the system to deliver relevant responses tailored to user needs.</p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">Low-Level Retrieval</span>. This level is primarily focused on retrieving specific entities along with their associated attributes or relationships. Queries at this level are detail-oriented and aim to extract precise information about particular nodes or edges within the graph.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">High-Level Retrieval</span>. This level addresses broader topics and overarching themes. Queries at this level aggregate information across multiple related entities and relationships, providing insights into higher-level concepts and summaries rather than specific details.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Integrating Graph and Vectors for Efficient Retrieval</span>.
By combining graph structures with vector representations, the model gains a deeper insight into the interrelationships among entities. This synergy enables the retrieval algorithm to effectively utilize both local and global keywords, streamlining the search process and improving the relevance of results.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<ul class="ltx_itemize" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.3">(i) <span class="ltx_text ltx_font_bold" id="S3.I4.i1.p1.3.1">Query Keyword Extraction</span>. For a given query <math alttext="q" class="ltx_Math" display="inline" id="S3.I4.i1.p1.1.m1.1"><semantics id="S3.I4.i1.p1.1.m1.1a"><mi id="S3.I4.i1.p1.1.m1.1.1" xref="S3.I4.i1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.I4.i1.p1.1.m1.1b"><ci id="S3.I4.i1.p1.1.m1.1.1.cmml" xref="S3.I4.i1.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i1.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i1.p1.1.m1.1d">italic_q</annotation></semantics></math>, the retrieval algorithm of LightRAG begins by extracting both local query keywords <math alttext="k^{(l)}" class="ltx_Math" display="inline" id="S3.I4.i1.p1.2.m2.1"><semantics id="S3.I4.i1.p1.2.m2.1a"><msup id="S3.I4.i1.p1.2.m2.1.2" xref="S3.I4.i1.p1.2.m2.1.2.cmml"><mi id="S3.I4.i1.p1.2.m2.1.2.2" xref="S3.I4.i1.p1.2.m2.1.2.2.cmml">k</mi><mrow id="S3.I4.i1.p1.2.m2.1.1.1.3" xref="S3.I4.i1.p1.2.m2.1.2.cmml"><mo id="S3.I4.i1.p1.2.m2.1.1.1.3.1" stretchy="false" xref="S3.I4.i1.p1.2.m2.1.2.cmml">(</mo><mi id="S3.I4.i1.p1.2.m2.1.1.1.1" xref="S3.I4.i1.p1.2.m2.1.1.1.1.cmml">l</mi><mo id="S3.I4.i1.p1.2.m2.1.1.1.3.2" stretchy="false" xref="S3.I4.i1.p1.2.m2.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.I4.i1.p1.2.m2.1b"><apply id="S3.I4.i1.p1.2.m2.1.2.cmml" xref="S3.I4.i1.p1.2.m2.1.2"><csymbol cd="ambiguous" id="S3.I4.i1.p1.2.m2.1.2.1.cmml" xref="S3.I4.i1.p1.2.m2.1.2">superscript</csymbol><ci id="S3.I4.i1.p1.2.m2.1.2.2.cmml" xref="S3.I4.i1.p1.2.m2.1.2.2">𝑘</ci><ci id="S3.I4.i1.p1.2.m2.1.1.1.1.cmml" xref="S3.I4.i1.p1.2.m2.1.1.1.1">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i1.p1.2.m2.1c">k^{(l)}</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i1.p1.2.m2.1d">italic_k start_POSTSUPERSCRIPT ( italic_l ) end_POSTSUPERSCRIPT</annotation></semantics></math> and global query keywords <math alttext="k^{(g)}" class="ltx_Math" display="inline" id="S3.I4.i1.p1.3.m3.1"><semantics id="S3.I4.i1.p1.3.m3.1a"><msup id="S3.I4.i1.p1.3.m3.1.2" xref="S3.I4.i1.p1.3.m3.1.2.cmml"><mi id="S3.I4.i1.p1.3.m3.1.2.2" xref="S3.I4.i1.p1.3.m3.1.2.2.cmml">k</mi><mrow id="S3.I4.i1.p1.3.m3.1.1.1.3" xref="S3.I4.i1.p1.3.m3.1.2.cmml"><mo id="S3.I4.i1.p1.3.m3.1.1.1.3.1" stretchy="false" xref="S3.I4.i1.p1.3.m3.1.2.cmml">(</mo><mi id="S3.I4.i1.p1.3.m3.1.1.1.1" xref="S3.I4.i1.p1.3.m3.1.1.1.1.cmml">g</mi><mo id="S3.I4.i1.p1.3.m3.1.1.1.3.2" stretchy="false" xref="S3.I4.i1.p1.3.m3.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.I4.i1.p1.3.m3.1b"><apply id="S3.I4.i1.p1.3.m3.1.2.cmml" xref="S3.I4.i1.p1.3.m3.1.2"><csymbol cd="ambiguous" id="S3.I4.i1.p1.3.m3.1.2.1.cmml" xref="S3.I4.i1.p1.3.m3.1.2">superscript</csymbol><ci id="S3.I4.i1.p1.3.m3.1.2.2.cmml" xref="S3.I4.i1.p1.3.m3.1.2.2">𝑘</ci><ci id="S3.I4.i1.p1.3.m3.1.1.1.1.cmml" xref="S3.I4.i1.p1.3.m3.1.1.1.1">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i1.p1.3.m3.1c">k^{(g)}</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i1.p1.3.m3.1d">italic_k start_POSTSUPERSCRIPT ( italic_g ) end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1">(ii) <span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">Keyword Matching</span>. The algorithm uses an efficient vector database to match local query keywords with candidate entities and global query keywords with relations linked to global keys.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i3.p1">
<p class="ltx_p" id="S3.I4.i3.p1.5">(iii) <span class="ltx_text ltx_font_bold" id="S3.I4.i3.p1.5.1">Incorporating High-Order Relatedness</span>. To enhance the query with higher-order relatedness, LightRAGfurther gathers neighboring nodes within the local subgraphs of the retrieved graph elements. This process involves the set <math alttext="\{v_{i}|v_{i}\in\mathcal{V}\land(v_{i}\in\mathcal{N}_{v}\lor v_{i}\in\mathcal{%
N}_{e})\}" class="ltx_Math" display="inline" id="S3.I4.i3.p1.1.m1.2"><semantics id="S3.I4.i3.p1.1.m1.2a"><mrow id="S3.I4.i3.p1.1.m1.2.2.2" xref="S3.I4.i3.p1.1.m1.2.2.3.cmml"><mo id="S3.I4.i3.p1.1.m1.2.2.2.3" stretchy="false" xref="S3.I4.i3.p1.1.m1.2.2.3.1.cmml">{</mo><msub id="S3.I4.i3.p1.1.m1.1.1.1.1" xref="S3.I4.i3.p1.1.m1.1.1.1.1.cmml"><mi id="S3.I4.i3.p1.1.m1.1.1.1.1.2" xref="S3.I4.i3.p1.1.m1.1.1.1.1.2.cmml">v</mi><mi id="S3.I4.i3.p1.1.m1.1.1.1.1.3" xref="S3.I4.i3.p1.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.I4.i3.p1.1.m1.2.2.2.4" lspace="0em" rspace="0em" xref="S3.I4.i3.p1.1.m1.2.2.3.1.cmml">|</mo><mrow id="S3.I4.i3.p1.1.m1.2.2.2.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.cmml"><msub id="S3.I4.i3.p1.1.m1.2.2.2.2.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3.cmml"><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.3.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3.2.cmml">v</mi><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.3.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3.3.cmml">i</mi></msub><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.2.cmml">∈</mo><mrow id="S3.I4.i3.p1.1.m1.2.2.2.2.1" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.3.cmml">𝒱</mi><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.1.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.2.cmml">∧</mo><mrow id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.cmml"><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.2" stretchy="false" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.cmml"><msub id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.cmml"><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.2.cmml">v</mi><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.3.cmml">∈</mo><mrow id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.cmml"><msub id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.2.cmml">𝒩</mi><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.3.cmml">v</mi></msub><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.1" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.1.cmml">∨</mo><msub id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.cmml"><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.2.cmml">v</mi><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.3.cmml">i</mi></msub></mrow><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.5" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.5.cmml">∈</mo><msub id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.2" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.2.cmml">𝒩</mi><mi id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.3" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.3.cmml">e</mi></msub></mrow><mo id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.3" stretchy="false" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.I4.i3.p1.1.m1.2.2.2.5" stretchy="false" xref="S3.I4.i3.p1.1.m1.2.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I4.i3.p1.1.m1.2b"><apply id="S3.I4.i3.p1.1.m1.2.2.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2"><csymbol cd="latexml" id="S3.I4.i3.p1.1.m1.2.2.3.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.3">conditional-set</csymbol><apply id="S3.I4.i3.p1.1.m1.1.1.1.1.cmml" xref="S3.I4.i3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.I4.i3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.I4.i3.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.I4.i3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.I4.i3.p1.1.m1.1.1.1.1.2">𝑣</ci><ci id="S3.I4.i3.p1.1.m1.1.1.1.1.3.cmml" xref="S3.I4.i3.p1.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2"><in id="S3.I4.i3.p1.1.m1.2.2.2.2.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.2"></in><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.I4.i3.p1.1.m1.2.2.2.2.3.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3">subscript</csymbol><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.3.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3.2">𝑣</ci><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.3.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.3.3">𝑖</ci></apply><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1"><and id="S3.I4.i3.p1.1.m1.2.2.2.2.1.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.2"></and><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.3">𝒱</ci><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1"><and id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1a.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1"></and><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1b.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1"><in id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.3"></in><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.2">𝑣</ci><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4"><or id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.1"></or><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2">subscript</csymbol><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.2">𝒩</ci><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.2.3">𝑣</ci></apply><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3"><csymbol cd="ambiguous" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3">subscript</csymbol><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.2">𝑣</ci><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.3.3">𝑖</ci></apply></apply></apply><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1c.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1"><in id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.5.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.5"></in><share href="https://arxiv.org/html/2410.05779v1#S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.4.cmml" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1d.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1"></share><apply id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.1.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6">subscript</csymbol><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.2.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.2">𝒩</ci><ci id="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.3.cmml" xref="S3.I4.i3.p1.1.m1.2.2.2.2.1.1.1.1.6.3">𝑒</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i3.p1.1.m1.2c">\{v_{i}|v_{i}\in\mathcal{V}\land(v_{i}\in\mathcal{N}_{v}\lor v_{i}\in\mathcal{%
N}_{e})\}</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i3.p1.1.m1.2d">{ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_V ∧ ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_N start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ∨ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_N start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) }</annotation></semantics></math>, where <math alttext="\mathcal{N}_{v}" class="ltx_Math" display="inline" id="S3.I4.i3.p1.2.m2.1"><semantics id="S3.I4.i3.p1.2.m2.1a"><msub id="S3.I4.i3.p1.2.m2.1.1" xref="S3.I4.i3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I4.i3.p1.2.m2.1.1.2" xref="S3.I4.i3.p1.2.m2.1.1.2.cmml">𝒩</mi><mi id="S3.I4.i3.p1.2.m2.1.1.3" xref="S3.I4.i3.p1.2.m2.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I4.i3.p1.2.m2.1b"><apply id="S3.I4.i3.p1.2.m2.1.1.cmml" xref="S3.I4.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I4.i3.p1.2.m2.1.1.1.cmml" xref="S3.I4.i3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I4.i3.p1.2.m2.1.1.2.cmml" xref="S3.I4.i3.p1.2.m2.1.1.2">𝒩</ci><ci id="S3.I4.i3.p1.2.m2.1.1.3.cmml" xref="S3.I4.i3.p1.2.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i3.p1.2.m2.1c">\mathcal{N}_{v}</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i3.p1.2.m2.1d">caligraphic_N start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{N}_{e}" class="ltx_Math" display="inline" id="S3.I4.i3.p1.3.m3.1"><semantics id="S3.I4.i3.p1.3.m3.1a"><msub id="S3.I4.i3.p1.3.m3.1.1" xref="S3.I4.i3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.I4.i3.p1.3.m3.1.1.2" xref="S3.I4.i3.p1.3.m3.1.1.2.cmml">𝒩</mi><mi id="S3.I4.i3.p1.3.m3.1.1.3" xref="S3.I4.i3.p1.3.m3.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I4.i3.p1.3.m3.1b"><apply id="S3.I4.i3.p1.3.m3.1.1.cmml" xref="S3.I4.i3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I4.i3.p1.3.m3.1.1.1.cmml" xref="S3.I4.i3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I4.i3.p1.3.m3.1.1.2.cmml" xref="S3.I4.i3.p1.3.m3.1.1.2">𝒩</ci><ci id="S3.I4.i3.p1.3.m3.1.1.3.cmml" xref="S3.I4.i3.p1.3.m3.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i3.p1.3.m3.1c">\mathcal{N}_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i3.p1.3.m3.1d">caligraphic_N start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math> represent the one-hop neighboring nodes of the retrieved nodes <math alttext="v" class="ltx_Math" display="inline" id="S3.I4.i3.p1.4.m4.1"><semantics id="S3.I4.i3.p1.4.m4.1a"><mi id="S3.I4.i3.p1.4.m4.1.1" xref="S3.I4.i3.p1.4.m4.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.I4.i3.p1.4.m4.1b"><ci id="S3.I4.i3.p1.4.m4.1.1.cmml" xref="S3.I4.i3.p1.4.m4.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i3.p1.4.m4.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i3.p1.4.m4.1d">italic_v</annotation></semantics></math> and edges <math alttext="e" class="ltx_Math" display="inline" id="S3.I4.i3.p1.5.m5.1"><semantics id="S3.I4.i3.p1.5.m5.1a"><mi id="S3.I4.i3.p1.5.m5.1.1" xref="S3.I4.i3.p1.5.m5.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.I4.i3.p1.5.m5.1b"><ci id="S3.I4.i3.p1.5.m5.1.1.cmml" xref="S3.I4.i3.p1.5.m5.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I4.i3.p1.5.m5.1c">e</annotation><annotation encoding="application/x-llamapun" id="S3.I4.i3.p1.5.m5.1d">italic_e</annotation></semantics></math>, respectively.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">This dual-level retrieval paradigm not only facilitates efficient retrieval of related entities and relations through keyword matching, but also enhances the comprehensiveness of results by integrating relevant structural information from the constructed knowledge graph.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Retrieval-Augmented Answer Generation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.3"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.3.1">Utilization of Retrieved Information</span>. Utilizing the retrieved information <math alttext="\psi(q;\hat{\mathcal{D}})" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.2"><semantics id="S3.SS3.p1.1.m1.2a"><mrow id="S3.SS3.p1.1.m1.2.3" xref="S3.SS3.p1.1.m1.2.3.cmml"><mi id="S3.SS3.p1.1.m1.2.3.2" xref="S3.SS3.p1.1.m1.2.3.2.cmml">ψ</mi><mo id="S3.SS3.p1.1.m1.2.3.1" xref="S3.SS3.p1.1.m1.2.3.1.cmml">⁢</mo><mrow id="S3.SS3.p1.1.m1.2.3.3.2" xref="S3.SS3.p1.1.m1.2.3.3.1.cmml"><mo id="S3.SS3.p1.1.m1.2.3.3.2.1" stretchy="false" xref="S3.SS3.p1.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">q</mi><mo id="S3.SS3.p1.1.m1.2.3.3.2.2" xref="S3.SS3.p1.1.m1.2.3.3.1.cmml">;</mo><mover accent="true" id="S3.SS3.p1.1.m1.2.2" xref="S3.SS3.p1.1.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.2.2.2" xref="S3.SS3.p1.1.m1.2.2.2.cmml">𝒟</mi><mo id="S3.SS3.p1.1.m1.2.2.1" xref="S3.SS3.p1.1.m1.2.2.1.cmml">^</mo></mover><mo id="S3.SS3.p1.1.m1.2.3.3.2.3" stretchy="false" xref="S3.SS3.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.2b"><apply id="S3.SS3.p1.1.m1.2.3.cmml" xref="S3.SS3.p1.1.m1.2.3"><times id="S3.SS3.p1.1.m1.2.3.1.cmml" xref="S3.SS3.p1.1.m1.2.3.1"></times><ci id="S3.SS3.p1.1.m1.2.3.2.cmml" xref="S3.SS3.p1.1.m1.2.3.2">𝜓</ci><list id="S3.SS3.p1.1.m1.2.3.3.1.cmml" xref="S3.SS3.p1.1.m1.2.3.3.2"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑞</ci><apply id="S3.SS3.p1.1.m1.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2"><ci id="S3.SS3.p1.1.m1.2.2.1.cmml" xref="S3.SS3.p1.1.m1.2.2.1">^</ci><ci id="S3.SS3.p1.1.m1.2.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2.2">𝒟</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.2c">\psi(q;\hat{\mathcal{D}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.2d">italic_ψ ( italic_q ; over^ start_ARG caligraphic_D end_ARG )</annotation></semantics></math>, our LightRAG employs a general-purpose LLM to generate answers based on the collected data. This data comprises concatenated values <math alttext="V" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_V</annotation></semantics></math> from relevant entities and relations, produced by the profiling function <math alttext="\text{P}(\cdot)" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.2" xref="S3.SS3.p1.3.m3.1.2.cmml"><mtext id="S3.SS3.p1.3.m3.1.2.2" xref="S3.SS3.p1.3.m3.1.2.2a.cmml">P</mtext><mo id="S3.SS3.p1.3.m3.1.2.1" xref="S3.SS3.p1.3.m3.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p1.3.m3.1.2.3.2" xref="S3.SS3.p1.3.m3.1.2.cmml"><mo id="S3.SS3.p1.3.m3.1.2.3.2.1" stretchy="false" xref="S3.SS3.p1.3.m3.1.2.cmml">(</mo><mo id="S3.SS3.p1.3.m3.1.1" lspace="0em" rspace="0em" xref="S3.SS3.p1.3.m3.1.1.cmml">⋅</mo><mo id="S3.SS3.p1.3.m3.1.2.3.2.2" stretchy="false" xref="S3.SS3.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.2.cmml" xref="S3.SS3.p1.3.m3.1.2"><times id="S3.SS3.p1.3.m3.1.2.1.cmml" xref="S3.SS3.p1.3.m3.1.2.1"></times><ci id="S3.SS3.p1.3.m3.1.2.2a.cmml" xref="S3.SS3.p1.3.m3.1.2.2"><mtext id="S3.SS3.p1.3.m3.1.2.2.cmml" xref="S3.SS3.p1.3.m3.1.2.2">P</mtext></ci><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\text{P}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">P ( ⋅ )</annotation></semantics></math>. It includes names, descriptions of entities and relations, and excerpts from the original text.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Context Integration and Answer Generation</span>. By unifying the query with this multi-source text, the LLM generates informative answers tailored to the user’s needs, ensuring alignment with the query’s intent. This approach streamlines the answer generation process by integrating both context and query into the LLM model, as illustrated in detailed examples (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS2" title="7.2 Case Example of Retrieval-Augmented Generation in LightRAG. ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">7.2</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Complexity Analysis of the LightRAG Framework</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In this section, we analyze the complexity of our proposed LightRAG framework, which can be divided into two main parts. The first part is the graph-based Index phase. During this phase, we use the large language model (LLM) to extract entities and relationships from each chunk of text. As a result, the LLM needs to be called <math alttext="\frac{\text{total tokens}}{\text{chunk size}}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><mfrac id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mtext id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2a.cmml">total tokens</mtext><mtext id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3a.cmml">chunk size</mtext></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><divide id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"></divide><ci id="S3.SS4.p1.1.m1.1.1.2a.cmml" xref="S3.SS4.p1.1.m1.1.1.2"><mtext id="S3.SS4.p1.1.m1.1.1.2.cmml" mathsize="70%" xref="S3.SS4.p1.1.m1.1.1.2">total tokens</mtext></ci><ci id="S3.SS4.p1.1.m1.1.1.3a.cmml" xref="S3.SS4.p1.1.m1.1.1.3"><mtext id="S3.SS4.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS4.p1.1.m1.1.1.3">chunk size</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\frac{\text{total tokens}}{\text{chunk size}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">divide start_ARG total tokens end_ARG start_ARG chunk size end_ARG</annotation></semantics></math> times. Importantly, there is no additional overhead involved in this process, making our approach highly efficient in managing updates to new text.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The second part of the process involves the graph-based retrieval phase. For each query, we first utilize the large language model (LLM) to generate relevant keywords. Similar to current Retrieval-Augmented Generation (RAG) systems <cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib8" title="">2023</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib7" title="">2022</a>); Chan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib2" title="">2024</a>)</cite>, our retrieval mechanism relies on vector-based search. However, instead of retrieving chunks as in conventional RAG, we concentrate on retrieving entities and relationships. This approach markedly reduces retrieval overhead compared to the community-based traversal method used in GraphRAG.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.4">We conduct empirical evaluations on benchmark data to assess the effectiveness of the proposed LightRAG framework by addressing the following research questions: <math alttext="\bullet" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.p1.4.1">(RQ1)</span>: How does LightRAG compare to existing RAG baseline methods in terms of generation performance? <math alttext="\bullet" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mo id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.p1.4.2">(RQ2)</span>: How do dual-level retrieval and graph-based indexing enhance the generation quality of LightRAG? <math alttext="\bullet" class="ltx_Math" display="inline" id="S4.p1.3.m3.1"><semantics id="S4.p1.3.m3.1a"><mo id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><ci id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.p1.3.m3.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.p1.4.3">(RQ3)</span>: What specific advantages does LightRAG demonstrate through case examples in various scenarios? <math alttext="\bullet" class="ltx_Math" display="inline" id="S4.p1.4.m4.1"><semantics id="S4.p1.4.m4.1a"><mo id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><ci id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.p1.4.m4.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.p1.4.4">(RQ4)</span>: What are the costs associated with LightRAG, as well as its adaptability to data changes?</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Evaluation Datasets</span>.
To conduct a comprehensive analysis of LightRAG, we selected four datasets from the UltraDomain benchmark <cite class="ltx_cite ltx_citemacro_citep">(Qian et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib12" title="">2024</a>)</cite>. The UltraDomain data is sourced from 428 college textbooks and encompasses 18 distinct domains, including agriculture, social sciences, and humanities. From these, we chose the Agriculture, CS, Legal, and Mix datasets. Each dataset contains between 600,000 and 5,000,000 tokens, with detailed information provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.T4" title="Table 4 ‣ 7.1 Experimental Data Details ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a>. Below is a specific introduction to the four domains utilized in our experiments:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Agriculture</span>: This domain focuses on agricultural practices, covering a range of topics including beekeeping, hive management, crop production, and disease prevention.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">CS</span>: This domain focuses on computer science and encompasses key areas of data science and software engineering. It particularly highlights machine learning and big data processing, featuring content on recommendation systems, classification algorithms, and real-time analytics using Spark.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Legal</span>: This domain centers on corporate legal practices, addressing corporate restructuring, legal agreements, regulatory compliance, and governance, with a focus on the legal and financial sectors.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">Mixed</span>: This domain presents a rich variety of literary, biographical, and philosophical texts, spanning a broad spectrum of disciplines, including cultural, historical, and philosophical studies.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Question Generation</span>.
To evaluate the effectiveness of RAG systems for high-level sensemaking tasks, we consolidate all text content from each dataset as context and adopt the generation method outlined in <cite class="ltx_cite ltx_citemacro_cite">Edge et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib4" title="">2024</a>)</cite>. Specifically, we instruct an LLM to generate five RAG users, along with five tasks for each user. Each generated user is accompanied by a textual description detailing their expertise and traits that motivate their question-raising activities. Each user task is also described, emphasizing one of the user’s potential intentions when interacting with RAG systems. For each user-task combination, the LLM generates five questions that require an understanding of the entire corpus. In total, this process results in 125 questions for each dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Baselines</span>. LightRAG is compared against the following state-of-the-art methods across all datasets:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Naive RAG</span> <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib8" title="">2023</a>)</cite>: This model serves as a standard baseline in existing RAG systems. It segments raw texts into chunks and stores them in a vector database using text embeddings. For queries, Naive RAG generates vectorized representations to directly retrieve text chunks based on the highest similarity in their representations, ensuring efficient and straightforward matching.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">RQ-RAG</span> <cite class="ltx_cite ltx_citemacro_citep">(Chan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib2" title="">2024</a>)</cite>: This approach leverages the LLM to decompose the input query into multiple sub-queries. These sub-queries are designed to enhance search accuracy by utilizing explicit techniques such as rewriting, decomposition, and disambiguation.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">HyDE</span> <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib7" title="">2022</a>)</cite>: This method utilizes the LLM to generate a hypothetical document based on the input query. This generated document is then employed to retrieve relevant text chunks, which are subsequently used to formulate the final answer.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">GraphRAG</span> <cite class="ltx_cite ltx_citemacro_citep">(Edge et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib4" title="">2024</a>)</cite>: This is a graph-enhanced RAG system that utilizes an LLM to extract entities and relationships from the text, representing them as nodes and edges. It generates corresponding descriptions for these elements, aggregates nodes into communities, and produces a community report to capture global information. When handling high-level queries, GraphRAG retrieves more comprehensive information by traversing these communities.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Implementation and Evaluation Details</span>.
In our experiments, we utilize the <a class="ltx_ref ltx_href ltx_font_italic" href="https://github.com/gusye1234/nano-vectordb" title="">nano vector database</a> for vector data management and access. For all LLM-based operations in LightRAG, we default to using GPT-4o-mini. To ensure consistency, the chunk size is set to 1200 across all datasets. Additionally, the gleaning parameter is fixed at 1 for both GraphRAG and LightRAG.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">Defining ground truth for many RAG queries, particularly those involving complex high-level semantics, poses significant challenges. To address this, we build on existing work <cite class="ltx_cite ltx_citemacro_citep">(Edge et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib4" title="">2024</a>)</cite> and adopt an LLM-based multi-dimensional comparison method. We employ a robust LLM, specifically GPT-4o-mini, to rank each baseline against our LightRAG. The evaluation prompt we used is detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.SS3.SSS4" title="7.3.4 Prompts for RAG Evaluation ‣ 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">7.3.4</span></a>. In total, we utilize four evaluation dimensions, including:</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">i) <span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.1">Comprehensiveness</span>: How thoroughly does the answer address all aspects and details of the question? ii) <span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.2">Diversity</span>: How varied and rich is the answer in offering different perspectives and insights related to the question? iii) <span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.3">Empowerment</span>: How effectively does the answer enable the reader to understand the topic and make informed judgments? iv) <span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.4">Overall</span>: This dimension assesses the cumulative performance across the three preceding criteria to identify the best overall answer.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">The LLM directly compares two answers for each dimension and selects the superior response for each criterion. After identifying the winning answer for the three dimensions, the LLM combines the results to determine the overall better answer. To ensure a fair evaluation and mitigate the potential bias that could arise from the order in which the answers are presented in the prompt, we alternate the placement of each answer. We calculate win rates accordingly, ultimately leading to the final results.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparison of LightRAGwith Existing RAG Methods (RQ1)</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We compare LightRAG against each baseline across various evaluation dimensions and datasets. The results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.T1" title="Table 1 ‣ 4.2 Comparison of LightRAGwith Existing RAG Methods (RQ1) ‣ 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>. Based on these findings, we draw the following conclusions:</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Win rates (%) of baselines v.s. LightRAG across four datasets and four evaluation dimensions.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:397.5pt;height:262.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-87.8pt,57.9pt) scale(0.693522070960363,0.693522070960363) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T1.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.2.1">Agriculture</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.3.1">CS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.4.1">Legal</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.5.1">Mix</span></th>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.1.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.2">NaiveRAG</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.3.1">LightRAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.4">NaiveRAG</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.5.1">LightRAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.6">NaiveRAG</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.7.1">LightRAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.8">NaiveRAG</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.9.1">LightRAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.3.1.1">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.2">32.69%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.3.1.3.1">67.31%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.4">35.44%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.3.1.5.1">64.56%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.6">19.05%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.3.1.7.1">80.95%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.8">36.36%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.3.1.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.3.1.9.1">63.64%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.4.2.1">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.2">24.09%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.4.2.3.1">75.91%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.4">35.24%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.4.2.5.1">64.76%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.6">10.98%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.4.2.7.1">89.02%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.4.2.8">30.76%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.4.2.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.4.2.9.1">69.24%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.5.3.1">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.2">31.35%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.5.3.3.1">68.65%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.4">35.48%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.5.3.5.1">64.52%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.6">17.59%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.5.3.7.1">82.41%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.5.3.8">40.95%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.5.3.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.5.3.9.1">59.05%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.6.4.1">Overall</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.2">33.30%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.6.4.3.1">66.70%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.4">34.76%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.6.4.5.1">65.24%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.6">17.46%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.6.4.7.1">82.54%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.4.8">37.59%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.6.4.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.6.4.9.1">62.40%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.7.5">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.1.1.7.5.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.2">RQ-RAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.7.5.3.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.4">RQ-RAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.7.5.5.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.6">RQ-RAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.7"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.7.5.7.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.8">RQ-RAG</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.7.5.9"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.7.5.9.1">LightRAG</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.8.6.1">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.2">32.05%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.8.6.3.1">67.95%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.4">39.30%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.8.6.5.1">60.70%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.6">18.57%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.8.6.7.1">81.43%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.8">38.89%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.8.6.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.8.6.9.1">61.11%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.9.7.1">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.2">29.44%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.9.7.3.1">70.56%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.4">38.71%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.9.7.5.1">61.29%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.6">15.14%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.9.7.7.1">84.86%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.7.8">28.50%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.9.7.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.9.7.9.1">71.50%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.10.8.1">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.2">32.51%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.10.8.3.1">67.49%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.4">37.52%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.10.8.5.1">62.48%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.6">17.80%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.10.8.7.1">82.20%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.10.8.8">43.96%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.10.8.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.10.8.9.1">56.04%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.11.9.1">Overall</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.2">33.29%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.11.9.3.1">66.71%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.4">39.03%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.11.9.5.1">60.97%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.6">17.80%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.11.9.7.1">82.20%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.11.9.8">39.61%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.11.9.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.11.9.9.1">60.39%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.12.10">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.1.1.12.10.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.2">HyDE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.12.10.3.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.4">HyDE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.12.10.5.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.6">HyDE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.7"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.12.10.7.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.8">HyDE</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.12.10.9"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.12.10.9.1">LightRAG</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.13.11.1">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.2">24.39%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.13.11.3.1">75.61%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.4">36.49%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.13.11.5.1">63.51%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.6">27.68%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.13.11.7.1">72.32%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.8">42.17%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.13.11.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.13.11.9.1">57.83%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.14.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.14.12.1">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.2">24.96%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.14.12.3.1">75.34%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.4">37.41%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.14.12.5.1">62.59%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.6">18.79%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.14.12.7.1">81.21%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.14.12.8">30.88%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.14.12.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.14.12.9.1">69.12%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.15.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.15.13.1">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.2">24.89%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.15.13.3.1">75.11%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.4">34.99%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.15.13.5.1">65.01%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.6">26.99%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.15.13.7.1">73.01%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.15.13.8">45.61%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.15.13.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.15.13.9.1">54.39%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.16.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.16.14.1">Overall</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.2">23.17%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.16.14.3.1">76.83%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.4">35.67%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.16.14.5.1">64.33%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.6">27.68%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.16.14.7.1">72.32%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.16.14.8">42.72%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.16.14.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.16.14.9.1">57.28%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.17.15">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.1.1.17.15.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.2">GraphRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.17.15.3.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.4">GraphRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.17.15.5.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.6">GraphRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.7"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.17.15.7.1">LightRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.8">GraphRAG</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.17.15.9"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.17.15.9.1">LightRAG</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.18.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.18.16.1">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.2">45.56%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.18.16.3.1">54.44%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.4">45.98%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.18.16.5.1">54.02%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.6">47.13%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.18.16.7.1">52.87%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.18.16.8.1">51.86%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.1.1.18.16.9">48.14%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.19.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.19.17.1">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.2">19.65%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.19.17.3.1">80.35%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.4">39.64%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.19.17.5.1">60.36%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.6">25.55%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.19.17.7.1">74.45%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.19.17.8">35.87%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.19.17.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.19.17.9.1">64.13%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.20.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.20.18.1">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.2">36.69%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.20.18.3.1">63.31%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.4">45.09%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.20.18.5.1">54.91%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.6">42.81%</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.20.18.7.1">57.19%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.20.18.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.20.18.8.1">52.94%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.20.18.9">47.06%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.21.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.1.1.21.19.1">Overall</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.2">43.62%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.21.19.3.1">56.38%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.4">45.98%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.21.19.5.1">54.02%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.6">45.70%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.21.19.7.1">54.30%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T1.1.1.21.19.8.1">51.86%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.1.1.21.19.9">48.14%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">The Superiority of Graph-enhanced RAG Systems in Large-Scale Corpora</span>
When handling large token counts and complex queries that require a thorough understanding of the dataset’s context, graph-based RAG systems like LightRAG and GraphRAG consistently outperform purely chunk-based retrieval methods such as NaiveRAG, HyDE, and RQRAG. This performance gap becomes particularly pronounced as the dataset size increases. For instance, in the largest dataset (Legal), the disparity widens significantly, with baseline methods achieving only about 20% win rates compared to the dominance of LightRAG. This trend underscores the advantages of graph-enhanced RAG systems in capturing complex semantic dependencies within large-scale corpora, facilitating a more comprehensive understanding of knowledge and leading to improved generalization performance.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Enhancing Response Diversity with LightRAG</span>:
Compared to various baselines, LightRAG demonstrates a significant advantage in the Diversity metric, particularly within the larger Legal dataset. Its consistent lead in this area underscores LightRAG’s effectiveness in generating a wider range of responses, especially in scenarios where diverse content is essential. We attribute this advantage to LightRAG’s dual-level retrieval paradigm, which facilitates comprehensive information retrieval from both low-level and high-level dimensions. This approach effectively leverages graph-based text indexing to consistently capture the full context in response to queries.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">LightRAG’s Superiority over GraphRAG</span>:
While both LightRAG and GraphRAG use graph-based retrieval mechanisms, LightRAG consistently outperforms GraphRAG, particularly in larger datasets with complex language contexts. In the Agriculture, CS, and Legal datasets—each containing millions of tokens—LightRAG shows a clear advantage, significantly surpassing GraphRAG and highlighting its strength in comprehensive information understanding within diverse environments. <span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.2">Enhanced Response Variety</span>: By integrating low-level retrieval of specific entities with high-level retrieval of broader topics, LightRAG boosts response diversity. This dual-level mechanism effectively addresses both detailed and abstract queries, ensuring a thorough grasp of information. <span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.3">Complex Query Handling</span>: This approach is especially valuable in scenarios requiring diverse perspectives. By accessing both specific details and overarching themes, LightRAG adeptly responds to complex queries involving interconnected topics, providing contextually relevant answers.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Studies (RQ2)</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance of ablated versions of LightRAG, using NaiveRAG as reference.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:397.5pt;height:259.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-91.7pt,59.7pt) scale(0.684223973239552,0.684223973239552) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T2.1.1.1.1.1" style="padding-left:7.2pt;padding-right:7.2pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.1.2" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.2.1">Agriculture</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.1.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.3.1">CS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.1.4" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.4.1">Legal</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.1.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.5.1">Mix</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.1.2.2.1" style="padding-left:7.2pt;padding-right:7.2pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.2" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.3.1">LightRAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.4" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.5.1">LightRAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.6" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.7.1">LightRAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.8" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.9.1">LightRAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.1.3.1.1" style="padding-left:7.2pt;padding-right:7.2pt;">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.2" style="padding-left:7.2pt;padding-right:7.2pt;">32.69%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.3.1.3.1">67.31%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.4" style="padding-left:7.2pt;padding-right:7.2pt;">35.44%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.3.1.5.1">64.56%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.6" style="padding-left:7.2pt;padding-right:7.2pt;">19.05%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.3.1.7.1">80.95%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.8" style="padding-left:7.2pt;padding-right:7.2pt;">36.36%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.3.1.9.1">63.64%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.4.2.1" style="padding-left:7.2pt;padding-right:7.2pt;">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.2" style="padding-left:7.2pt;padding-right:7.2pt;">24.09%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.4.2.3.1">75.91%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.4" style="padding-left:7.2pt;padding-right:7.2pt;">35.24%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.4.2.5.1">64.76%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.6" style="padding-left:7.2pt;padding-right:7.2pt;">10.98%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.4.2.7.1">89.02%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.2.8" style="padding-left:7.2pt;padding-right:7.2pt;">30.76%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.4.2.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.4.2.9.1">69.24%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.5.3.1" style="padding-left:7.2pt;padding-right:7.2pt;">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.2" style="padding-left:7.2pt;padding-right:7.2pt;">31.35%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.5.3.3.1">68.65%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.4" style="padding-left:7.2pt;padding-right:7.2pt;">35.48%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.5.3.5.1">64.52%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.6" style="padding-left:7.2pt;padding-right:7.2pt;">17.59%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.5.3.7.1">82.41%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3.8" style="padding-left:7.2pt;padding-right:7.2pt;">40.95%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.5.3.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.5.3.9.1">59.05%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.6.4.1" style="padding-left:7.2pt;padding-right:7.2pt;">Overall</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.2" style="padding-left:7.2pt;padding-right:7.2pt;">33.30%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.6.4.3.1">66.70%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.4" style="padding-left:7.2pt;padding-right:7.2pt;">34.76%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.6.4.5.1">65.24%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.6" style="padding-left:7.2pt;padding-right:7.2pt;">17.46%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.6.4.7.1">82.54%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4.8" style="padding-left:7.2pt;padding-right:7.2pt;">37.59%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.6.4.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.6.4.9.1">62.40%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.7.5">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.1.7.5.1" style="padding-left:7.2pt;padding-right:7.2pt;"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.2" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.3.1">-High</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.4" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.5.1">-High</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.6" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.7.1">-High</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.8" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.7.5.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.9.1">-High</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.1.8.6.1" style="padding-left:7.2pt;padding-right:7.2pt;">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.2" style="padding-left:7.2pt;padding-right:7.2pt;">35.79%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.8.6.3.1">64.21%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.4" style="padding-left:7.2pt;padding-right:7.2pt;">42.98%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.8.6.5.1">57.02%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.6" style="padding-left:7.2pt;padding-right:7.2pt;">22.60%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.8.6.7.1">77.40%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.8" style="padding-left:7.2pt;padding-right:7.2pt;">40.69%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.8.6.9.1">59.31%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.9.7.1" style="padding-left:7.2pt;padding-right:7.2pt;">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.2" style="padding-left:7.2pt;padding-right:7.2pt;">26.86%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.9.7.3.1">73.14%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.4" style="padding-left:7.2pt;padding-right:7.2pt;">35.09%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.9.7.5.1">64.91%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.6" style="padding-left:7.2pt;padding-right:7.2pt;">16.09%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.9.7.7.1">83.91%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.7.8" style="padding-left:7.2pt;padding-right:7.2pt;">37.15%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.9.7.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.9.7.9.1">62.84%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.10.8.1" style="padding-left:7.2pt;padding-right:7.2pt;">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.2" style="padding-left:7.2pt;padding-right:7.2pt;">35.02%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.10.8.3.1">64.98%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.4" style="padding-left:7.2pt;padding-right:7.2pt;">42.98%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.10.8.5.1">57.02%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.6" style="padding-left:7.2pt;padding-right:7.2pt;">23.58%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.10.8.7.1">76.42%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.8.8" style="padding-left:7.2pt;padding-right:7.2pt;">48.26%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.10.8.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.10.8.9.1">51.74%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.11.9.1" style="padding-left:7.2pt;padding-right:7.2pt;">Overall</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.2" style="padding-left:7.2pt;padding-right:7.2pt;">35.33%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.11.9.3.1">64.67%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.4" style="padding-left:7.2pt;padding-right:7.2pt;">42.98%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.11.9.5.1">57.02%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.6" style="padding-left:7.2pt;padding-right:7.2pt;">21.92%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.11.9.7.1">78.08%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.9.8" style="padding-left:7.2pt;padding-right:7.2pt;">41.39%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.11.9.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.11.9.9.1">58.61%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.12.10">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.1.12.10.1" style="padding-left:7.2pt;padding-right:7.2pt;"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.2" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.10.3.1">-Low</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.4" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.10.5.1">-Low</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.6" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.10.7.1">-Low</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.8" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.12.10.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.12.10.9.1">-Low</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.1.13.11.1" style="padding-left:7.2pt;padding-right:7.2pt;">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.2" style="padding-left:7.2pt;padding-right:7.2pt;">36.31%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.13.11.3.1">63.69%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.4" style="padding-left:7.2pt;padding-right:7.2pt;">41.82%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.13.11.5.1">58.18%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.6" style="padding-left:7.2pt;padding-right:7.2pt;">18.92%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.13.11.7.1">81.08%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.8" style="padding-left:7.2pt;padding-right:7.2pt;">35.92%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.13.11.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.13.11.9.1">64.08%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.14.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.14.12.1" style="padding-left:7.2pt;padding-right:7.2pt;">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.2" style="padding-left:7.2pt;padding-right:7.2pt;">29.07%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.14.12.3.1">70.93%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.4" style="padding-left:7.2pt;padding-right:7.2pt;">40.29%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.14.12.5.1">59.71%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.6" style="padding-left:7.2pt;padding-right:7.2pt;">13.06%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.14.12.7.1">86.94%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.14.12.8" style="padding-left:7.2pt;padding-right:7.2pt;">32.34%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.14.12.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.14.12.9.1">67.66%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.15.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.15.13.1" style="padding-left:7.2pt;padding-right:7.2pt;">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.2" style="padding-left:7.2pt;padding-right:7.2pt;">34.87%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.15.13.3.1">65.13%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.4" style="padding-left:7.2pt;padding-right:7.2pt;">41.51%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.15.13.5.1">58.49%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.6" style="padding-left:7.2pt;padding-right:7.2pt;">17.73%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.15.13.7.1">82.27%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.15.13.8" style="padding-left:7.2pt;padding-right:7.2pt;">35.98%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.15.13.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.15.13.9.1">64.02%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.16.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.16.14.1" style="padding-left:7.2pt;padding-right:7.2pt;">Overall</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.2" style="padding-left:7.2pt;padding-right:7.2pt;">35.02%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.16.14.3.1">64.98%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.4" style="padding-left:7.2pt;padding-right:7.2pt;">42.00%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.16.14.5.1">58.00%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.6" style="padding-left:7.2pt;padding-right:7.2pt;">19.00%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.16.14.7.1">81.00%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.16.14.8" style="padding-left:7.2pt;padding-right:7.2pt;">35.92%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.16.14.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.16.14.9.1">64.08%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.17.15">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.1.17.15.1" style="padding-left:7.2pt;padding-right:7.2pt;"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.2" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.15.3.1">-Origin</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.4" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.15.5.1">-Origin</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.6" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.15.7.1">-Origin</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.8" style="padding-left:7.2pt;padding-right:7.2pt;">NaiveRAG</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.17.15.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.17.15.9.1">-Origin</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.18.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.1.18.16.1" style="padding-left:7.2pt;padding-right:7.2pt;">Comprehensiveness</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.2" style="padding-left:7.2pt;padding-right:7.2pt;">25.23%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.18.16.3.1">74.77%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.4" style="padding-left:7.2pt;padding-right:7.2pt;">40.20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.18.16.5.1">59.80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.6" style="padding-left:7.2pt;padding-right:7.2pt;">16.40%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.18.16.7.1">83.60%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.8" style="padding-left:7.2pt;padding-right:7.2pt;">44.00%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.1.18.16.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.18.16.9.1">56.00%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.19.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.19.17.1" style="padding-left:7.2pt;padding-right:7.2pt;">Diversity</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.2" style="padding-left:7.2pt;padding-right:7.2pt;">26.94%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.19.17.3.1">73.06%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.4" style="padding-left:7.2pt;padding-right:7.2pt;">45.36%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.19.17.5.1">54.64%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.6" style="padding-left:7.2pt;padding-right:7.2pt;">13.15%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.19.17.7.1">86.84%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.19.17.8" style="padding-left:7.2pt;padding-right:7.2pt;">26.00%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.19.17.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.19.17.9.1">74.00%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.20.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.1.20.18.1" style="padding-left:7.2pt;padding-right:7.2pt;">Empowerment</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.2" style="padding-left:7.2pt;padding-right:7.2pt;">31.01%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.20.18.3.1">68.99%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.4" style="padding-left:7.2pt;padding-right:7.2pt;">42.61%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.20.18.5.1">57.39%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.6" style="padding-left:7.2pt;padding-right:7.2pt;">18.55%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.20.18.7.1">81.45%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.20.18.8" style="padding-left:7.2pt;padding-right:7.2pt;">45.33%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.20.18.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.20.18.9.1">54.67%</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.21.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.1.1.21.19.1" style="padding-left:7.2pt;padding-right:7.2pt;">Overall</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.2" style="padding-left:7.2pt;padding-right:7.2pt;">25.51%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.3" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.21.19.3.1">74.49%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.4" style="padding-left:7.2pt;padding-right:7.2pt;">40.20%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.5" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.21.19.5.1">59.80%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.6" style="padding-left:7.2pt;padding-right:7.2pt;">17.12%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.7" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.21.19.7.1">82.88%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.8" style="padding-left:7.2pt;padding-right:7.2pt;">44.00%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T2.1.1.21.19.9" style="padding-left:7.2pt;padding-right:7.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.1.1.21.19.9.1">56.00%</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We also conduct ablation studies to evaluate the impact of our dual-level retrieval paradigm and the effectiveness of our graph-based text indexing in LightRAG. The results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.T2" title="Table 2 ‣ 4.3 Ablation Studies (RQ2) ‣ 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Effectiveness of Dual-level Retrieval Paradigm</span>.
We begin by analyzing the effects of low-level and high-level retrieval paradigms. We compare two ablated models—each omitting one module—against LightRAG across four datasets. Here are our key observations for the different variants:</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i1.p1.1.1">Low-level-only Retrieval</span>: The -High variant removes high-order retrieval, leading to a significant performance decline across nearly all datasets and metrics. This drop is mainly due to its emphasis on the specific information, which focuses excessively on entities and their immediate neighbors. While this approach enables deeper exploration of directly related entities, it struggles to gather information for complex queries that demand comprehensive insights.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i2.p1.1.1">High-level-only Retrieval</span>: The -Low variant prioritizes capturing a broader range of content by leveraging entity-wise relationships rather than focusing on specific entities. This approach offers a significant advantage in comprehensiveness, allowing it to gather more extensive and varied information. However, the trade-off is a reduced depth in examining specific entities, which can limit its ability to provide highly detailed insights. Consequently, this high-level-only retrieval method may struggle with tasks that require precise, detailed answers.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i3.p1.1.1">Hybrid Mode</span>: The hybrid mode, or the full version of LightRAG, combines the strengths of both low-level and high-level retrieval methods. It retrieves a broader set of relationships while simultaneously conducting an in-depth exploration of specific entities. This dual-level approach ensures both breadth in the retrieval process and depth in the analysis, providing a comprehensive view of the data. As a result, LightRAG achieves balanced performance across multiple dimensions.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">Semantic Graph Excels in RAG</span>.
We eliminated the use of original text in our retrieval process. Surprisingly, the resulting variant, -Origin, does not exhibit significant performance declines across all four datasets. In some cases, this variant even shows improvements (<span class="ltx_text ltx_font_italic" id="S4.SS3.p4.1.2">e.g.</span> in Agriculture and Mix). We attribute this phenomenon to the effective extraction of key information during the graph-based indexing process, which provides sufficient context for answering queries. Additionally, the original text often contains irrelevant information that can introduce noise in the response.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Case Study (RQ3)</h3>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">To provide a clear comparison between baseline methods and our LightRAG, we present specific case examples in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.T3" title="Table 3 ‣ 4.4 Case Study (RQ3) ‣ 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a>, which includes responses to a machine learning question from both the competitive baseline, GraphRAG, and our LightRAG framework. In this instance, LightRAG outperforms in all evaluation dimensions assessed by the LLM judge, including comprehensiveness, diversity, empowerment, and overall quality. Our key observations are as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">i) Comprehensiveness</span>. Notably, LightRAG covers a broader range of machine learning metrics, showcasing its comprehensiveness and ability to effectively discover relevant information. This highlights the strength of our graph-based indexing paradigm, which excels in precise entity and relation extraction as well as LLM profiling.
<span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.2">ii) Both Diversity and Empowerment</span>.
Furthermore, LightRAG not only offers a more diverse array of information but also delivers more empowering content. This success is due to LightRAG’s hierarchical retrieval paradigm, which combines in-depth explorations of related entities through low-level retrieval to enhance empowerment with broader explorations via high-level retrieval to improve answer diversity. Together, these approaches capture a comprehensive global perspective of the knowledge domain, contributing to better RAG performance.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Case Study: Comparison Between LightRAG and the Baseline Method GraphRAG.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:397.5pt;height:408.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-59.1pt,60.7pt) scale(0.770755754739574,0.770755754739574) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1.1">Query</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.1.1.2.1">
<span class="ltx_p" id="S4.T3.1.1.1.1.2.1.1" style="width:426.8pt;">Which methods can normalize the feature values for effective machine learning?</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.1.1">GraphRAG</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.2.1.2.1">
<span class="ltx_p" id="S4.T3.1.1.2.1.2.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.1">Key Metrics for Evaluating Movie Recommendation Systems</span>:
Evaluating the effectiveness of movie recommendation systems is crucial for ensuring user satisfaction and improving the overall performance of these systems. Several metrics are widely recognized for their ability to provide insights into how well a recommendation system performs. Below are the most informative metrics:
1. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.2">Precision</span> […]
2. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.3">Recall</span> […]
3. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.4">F1 Score</span> […]
4. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.5">Mean Average Precision (MAP)</span> […]
5. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.6">Root Mean Squared Error (RMSE)</span> […]
6. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.7">User Satisfaction Metrics</span> […]
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1.1.8">Conclusion</span>: In summary, metrics such as precision, recall, F1 score, MAP, RMSE, and user satisfaction are critical for evaluating the performance of movie recommendation systems. Each metric provides unique insights that can help developers and researchers refine their algorithms and enhance user experiences. By focusing on these metrics, stakeholders can ensure that their recommendation systems effectively meet user preferences and expectations.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.1.1">LightRAG</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T3.1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.3.2.2.1">
<span class="ltx_p" id="S4.T3.1.1.3.2.2.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.1">Key Metrics for Evaluating Movie Recommendation Systems</span>:
Evaluating movie recommendation systems involves multiple metrics that assess the effectiveness and accuracy of the recommendations provided to users. Below are some of the most informative metrics commonly used in this context, derived from the data and concepts surrounding recommendation systems.
1. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.2">Mean Average Precision at K (MAPK)</span> […]
2. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.3">Precision and Recall</span> […]
3. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.4">Root Mean Squared Error (RMSE) and Mean Squared Error (MSE)</span> […]
4. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.5">Area Under the Curve (AUC)</span> […]
5. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.6">F-Measure</span> […]
6. <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.7">User Engagement Metrics</span> […]
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.2.2.1.1.8">Conclusion</span>: A comprehensive evaluation of movie recommendation systems employs a range of metrics that capture both the accuracy of the recommendations and user satisfaction. By effectively leveraging these metrics, system designers can optimize recommendation engines to deliver more personalized and relevant experiences.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.3.1.1">LLM Decision</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.4.3.2.1">
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.3.2.1.1.1">Comprehensiveness</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.2">"Explanation": "Answer 2 provides a broader array of metrics including MAPK, AUC, and user engagement metrics alongside precision, recall, RMSE, and F-Measure. This gives a fuller view of how recommendation systems can be evaluated. Answer 1, while detailed, is more focused on traditional metrics and lacks the inclusion of engagement metrics which are crucial for understanding user interaction." 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.3.2.1.3.1">Diversity</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.4">"Explanation": "Answer 2 not only covers a wide variety of metrics but also includes nuanced explanations of how some metrics interrelate and differ from one another, like the inclusion of both RMSE and MSE, as well as the details behind AUC. In contrast, Answer 1 sticks primarily to standard metrics without much exploration of potential nuances." 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.3.2.1.5.1">Empowerment</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.6">"Explanation": "Answer 2 empowers the reader more effectively by detailing how each metric functions and its importance in evaluating recommendation systems. By providing context such as the trade-offs between precision and recall and emphasizing user engagement metrics, it enables readers to make more informed judgments and understand the implications of different metrics. Answer 1 is more straightforward but lacks the depth of insight regarding why these metrics matter." 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.3.2.1.7.1">Overall Winner</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S4.T3.1.1.4.3.2.1.8">"Explanation": "While Answer 1 is more direct and systematic, Answer 2 excels in comprehensiveness, diversity, and empowerment. It provides a richer exploration of the topic, including insights into user engagement and nuanced differences between metrics. This depth and breadth make it more informative for readers seeking to thoroughly understand the evaluation of movie recommendation systems."</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Model Cost and Adaptability Analysis (RQ4)</h3>
<figure class="ltx_figure" id="S4.F2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparison of Cost in Terms of Tokens and API Calls for GraphRAG and LightRAG on the Legal Dataset.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F2.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F2.8.9.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.F2.8.9.1.1" style="padding-left:0.9pt;padding-right:0.9pt;">Phase</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S4.F2.8.9.1.2" style="padding-left:0.9pt;padding-right:0.9pt;">Retrieval Phase</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S4.F2.8.9.1.3" style="padding-left:0.9pt;padding-right:0.9pt;">Incremental Text Update</td>
</tr>
<tr class="ltx_tr" id="S4.F2.8.10.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.F2.8.10.2.1" style="padding-left:0.9pt;padding-right:0.9pt;">Model</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.8.10.2.2" style="padding-left:0.9pt;padding-right:0.9pt;">GraphRAG</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.8.10.2.3" style="padding-left:0.9pt;padding-right:0.9pt;">Ours</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.8.10.2.4" style="padding-left:0.9pt;padding-right:0.9pt;">GraphRAG</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.8.10.2.5" style="padding-left:0.9pt;padding-right:0.9pt;">Ours</td>
</tr>
<tr class="ltx_tr" id="S4.F2.4.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.F2.4.4.5" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.4.4.5.1">Tokens</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.1.1.1" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.1.1.1.1"><math alttext="610\times 1{,}000" class="ltx_Math" display="inline" id="S4.F2.1.1.1.1.m1.2"><semantics id="S4.F2.1.1.1.1.m1.2a"><mrow id="S4.F2.1.1.1.1.m1.2.2.1" xref="S4.F2.1.1.1.1.m1.2.2.2.cmml"><mrow id="S4.F2.1.1.1.1.m1.2.2.1.1" xref="S4.F2.1.1.1.1.m1.2.2.1.1.cmml"><mn id="S4.F2.1.1.1.1.m1.2.2.1.1.2" xref="S4.F2.1.1.1.1.m1.2.2.1.1.2.cmml">610</mn><mo id="S4.F2.1.1.1.1.m1.2.2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.F2.1.1.1.1.m1.2.2.1.1.1.cmml">×</mo><mn id="S4.F2.1.1.1.1.m1.2.2.1.1.3" xref="S4.F2.1.1.1.1.m1.2.2.1.1.3.cmml">1</mn></mrow><mo id="S4.F2.1.1.1.1.m1.2.2.1.2" xref="S4.F2.1.1.1.1.m1.2.2.2.cmml">,</mo><mn id="S4.F2.1.1.1.1.m1.1.1" xref="S4.F2.1.1.1.1.m1.1.1.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.1.1.1.1.m1.2b"><list id="S4.F2.1.1.1.1.m1.2.2.2.cmml" xref="S4.F2.1.1.1.1.m1.2.2.1"><apply id="S4.F2.1.1.1.1.m1.2.2.1.1.cmml" xref="S4.F2.1.1.1.1.m1.2.2.1.1"><times id="S4.F2.1.1.1.1.m1.2.2.1.1.1.cmml" xref="S4.F2.1.1.1.1.m1.2.2.1.1.1"></times><cn id="S4.F2.1.1.1.1.m1.2.2.1.1.2.cmml" type="integer" xref="S4.F2.1.1.1.1.m1.2.2.1.1.2">610</cn><cn id="S4.F2.1.1.1.1.m1.2.2.1.1.3.cmml" type="integer" xref="S4.F2.1.1.1.1.m1.2.2.1.1.3">1</cn></apply><cn id="S4.F2.1.1.1.1.m1.1.1.cmml" type="integer" xref="S4.F2.1.1.1.1.m1.1.1">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.1.1.1.1.m1.2c">610\times 1{,}000</annotation><annotation encoding="application/x-llamapun" id="S4.F2.1.1.1.1.m1.2d">610 × 1 , 000</annotation></semantics></math></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.2.2.2" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.2.2.2.1"><math alttext="&lt;100" class="ltx_Math" display="inline" id="S4.F2.2.2.2.1.m1.1"><semantics id="S4.F2.2.2.2.1.m1.1a"><mrow id="S4.F2.2.2.2.1.m1.1.1" xref="S4.F2.2.2.2.1.m1.1.1.cmml"><mi id="S4.F2.2.2.2.1.m1.1.1.2" xref="S4.F2.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="S4.F2.2.2.2.1.m1.1.1.1" xref="S4.F2.2.2.2.1.m1.1.1.1.cmml">&lt;</mo><mn id="S4.F2.2.2.2.1.m1.1.1.3" xref="S4.F2.2.2.2.1.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.2.2.2.1.m1.1b"><apply id="S4.F2.2.2.2.1.m1.1.1.cmml" xref="S4.F2.2.2.2.1.m1.1.1"><lt id="S4.F2.2.2.2.1.m1.1.1.1.cmml" xref="S4.F2.2.2.2.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S4.F2.2.2.2.1.m1.1.1.2.cmml" xref="S4.F2.2.2.2.1.m1.1.1.2">absent</csymbol><cn id="S4.F2.2.2.2.1.m1.1.1.3.cmml" type="integer" xref="S4.F2.2.2.2.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.2.2.2.1.m1.1c">&lt;100</annotation><annotation encoding="application/x-llamapun" id="S4.F2.2.2.2.1.m1.1d">&lt; 100</annotation></semantics></math></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.3.3.3" style="padding-left:0.9pt;padding-right:0.9pt;"><math alttext="1{,}399\times 2\times 5{,}000" class="ltx_Math" display="inline" id="S4.F2.3.3.3.m1.3"><semantics id="S4.F2.3.3.3.m1.3a"><mrow id="S4.F2.3.3.3.m1.3.3.1" xref="S4.F2.3.3.3.m1.3.3.2.cmml"><mn id="S4.F2.3.3.3.m1.1.1" xref="S4.F2.3.3.3.m1.1.1.cmml">1</mn><mo id="S4.F2.3.3.3.m1.3.3.1.2" xref="S4.F2.3.3.3.m1.3.3.2.cmml">,</mo><mrow id="S4.F2.3.3.3.m1.3.3.1.1" xref="S4.F2.3.3.3.m1.3.3.1.1.cmml"><mn id="S4.F2.3.3.3.m1.3.3.1.1.2" xref="S4.F2.3.3.3.m1.3.3.1.1.2.cmml">399</mn><mo id="S4.F2.3.3.3.m1.3.3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.F2.3.3.3.m1.3.3.1.1.1.cmml">×</mo><mn id="S4.F2.3.3.3.m1.3.3.1.1.3" xref="S4.F2.3.3.3.m1.3.3.1.1.3.cmml">2</mn><mo id="S4.F2.3.3.3.m1.3.3.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S4.F2.3.3.3.m1.3.3.1.1.1.cmml">×</mo><mn id="S4.F2.3.3.3.m1.3.3.1.1.4" xref="S4.F2.3.3.3.m1.3.3.1.1.4.cmml">5</mn></mrow><mo id="S4.F2.3.3.3.m1.3.3.1.3" xref="S4.F2.3.3.3.m1.3.3.2.cmml">,</mo><mn id="S4.F2.3.3.3.m1.2.2" xref="S4.F2.3.3.3.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.3.3.3.m1.3b"><list id="S4.F2.3.3.3.m1.3.3.2.cmml" xref="S4.F2.3.3.3.m1.3.3.1"><cn id="S4.F2.3.3.3.m1.1.1.cmml" type="integer" xref="S4.F2.3.3.3.m1.1.1">1</cn><apply id="S4.F2.3.3.3.m1.3.3.1.1.cmml" xref="S4.F2.3.3.3.m1.3.3.1.1"><times id="S4.F2.3.3.3.m1.3.3.1.1.1.cmml" xref="S4.F2.3.3.3.m1.3.3.1.1.1"></times><cn id="S4.F2.3.3.3.m1.3.3.1.1.2.cmml" type="integer" xref="S4.F2.3.3.3.m1.3.3.1.1.2">399</cn><cn id="S4.F2.3.3.3.m1.3.3.1.1.3.cmml" type="integer" xref="S4.F2.3.3.3.m1.3.3.1.1.3">2</cn><cn id="S4.F2.3.3.3.m1.3.3.1.1.4.cmml" type="integer" xref="S4.F2.3.3.3.m1.3.3.1.1.4">5</cn></apply><cn id="S4.F2.3.3.3.m1.2.2.cmml" type="integer" xref="S4.F2.3.3.3.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.3.3.3.m1.3c">1{,}399\times 2\times 5{,}000</annotation><annotation encoding="application/x-llamapun" id="S4.F2.3.3.3.m1.3d">1 , 399 × 2 × 5 , 000</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.F2.4.4.4" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.4.4.4.1"><math alttext="T_{\text{extract}}" class="ltx_Math" display="inline" id="S4.F2.4.4.4.1.m1.1"><semantics id="S4.F2.4.4.4.1.m1.1a"><msub id="S4.F2.4.4.4.1.m1.1.1" xref="S4.F2.4.4.4.1.m1.1.1.cmml"><mi id="S4.F2.4.4.4.1.m1.1.1.2" xref="S4.F2.4.4.4.1.m1.1.1.2.cmml">T</mi><mtext id="S4.F2.4.4.4.1.m1.1.1.3" xref="S4.F2.4.4.4.1.m1.1.1.3a.cmml">extract</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F2.4.4.4.1.m1.1b"><apply id="S4.F2.4.4.4.1.m1.1.1.cmml" xref="S4.F2.4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F2.4.4.4.1.m1.1.1.1.cmml" xref="S4.F2.4.4.4.1.m1.1.1">subscript</csymbol><ci id="S4.F2.4.4.4.1.m1.1.1.2.cmml" xref="S4.F2.4.4.4.1.m1.1.1.2">𝑇</ci><ci id="S4.F2.4.4.4.1.m1.1.1.3a.cmml" xref="S4.F2.4.4.4.1.m1.1.1.3"><mtext id="S4.F2.4.4.4.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.F2.4.4.4.1.m1.1.1.3">extract</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.4.4.4.1.m1.1c">T_{\text{extract}}</annotation><annotation encoding="application/x-llamapun" id="S4.F2.4.4.4.1.m1.1d">italic_T start_POSTSUBSCRIPT extract end_POSTSUBSCRIPT</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.F2.5.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.F2.5.5.1" style="padding-left:0.9pt;padding-right:0.9pt;"><math alttext="+T_{\text{extract}}" class="ltx_Math" display="inline" id="S4.F2.5.5.1.m1.1"><semantics id="S4.F2.5.5.1.m1.1a"><mrow id="S4.F2.5.5.1.m1.1.1" xref="S4.F2.5.5.1.m1.1.1.cmml"><mo id="S4.F2.5.5.1.m1.1.1a" xref="S4.F2.5.5.1.m1.1.1.cmml">+</mo><msub id="S4.F2.5.5.1.m1.1.1.2" xref="S4.F2.5.5.1.m1.1.1.2.cmml"><mi id="S4.F2.5.5.1.m1.1.1.2.2" xref="S4.F2.5.5.1.m1.1.1.2.2.cmml">T</mi><mtext id="S4.F2.5.5.1.m1.1.1.2.3" xref="S4.F2.5.5.1.m1.1.1.2.3a.cmml">extract</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.5.5.1.m1.1b"><apply id="S4.F2.5.5.1.m1.1.1.cmml" xref="S4.F2.5.5.1.m1.1.1"><plus id="S4.F2.5.5.1.m1.1.1.1.cmml" xref="S4.F2.5.5.1.m1.1.1"></plus><apply id="S4.F2.5.5.1.m1.1.1.2.cmml" xref="S4.F2.5.5.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.F2.5.5.1.m1.1.1.2.1.cmml" xref="S4.F2.5.5.1.m1.1.1.2">subscript</csymbol><ci id="S4.F2.5.5.1.m1.1.1.2.2.cmml" xref="S4.F2.5.5.1.m1.1.1.2.2">𝑇</ci><ci id="S4.F2.5.5.1.m1.1.1.2.3a.cmml" xref="S4.F2.5.5.1.m1.1.1.2.3"><mtext id="S4.F2.5.5.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S4.F2.5.5.1.m1.1.1.2.3">extract</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.5.1.m1.1c">+T_{\text{extract}}</annotation><annotation encoding="application/x-llamapun" id="S4.F2.5.5.1.m1.1d">+ italic_T start_POSTSUBSCRIPT extract end_POSTSUBSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.F2.8.8">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.F2.8.8.4" style="padding-left:0.9pt;padding-right:0.9pt;">API</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.F2.6.6.1" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.6.6.1.1"><math alttext="\frac{610\times 1{,}000}{C_{\text{max}}}" class="ltx_Math" display="inline" id="S4.F2.6.6.1.1.m1.2"><semantics id="S4.F2.6.6.1.1.m1.2a"><mfrac id="S4.F2.6.6.1.1.m1.2.2" xref="S4.F2.6.6.1.1.m1.2.2.cmml"><mrow id="S4.F2.6.6.1.1.m1.2.2.2.2" xref="S4.F2.6.6.1.1.m1.2.2.2.3.cmml"><mrow id="S4.F2.6.6.1.1.m1.2.2.2.2.1" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.cmml"><mn id="S4.F2.6.6.1.1.m1.2.2.2.2.1.2" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.2.cmml">610</mn><mo id="S4.F2.6.6.1.1.m1.2.2.2.2.1.1" lspace="0.222em" rspace="0.222em" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.1.cmml">×</mo><mn id="S4.F2.6.6.1.1.m1.2.2.2.2.1.3" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="S4.F2.6.6.1.1.m1.2.2.2.2.2" xref="S4.F2.6.6.1.1.m1.2.2.2.3.cmml">,</mo><mn id="S4.F2.6.6.1.1.m1.1.1.1.1" xref="S4.F2.6.6.1.1.m1.1.1.1.1.cmml">000</mn></mrow><msub id="S4.F2.6.6.1.1.m1.2.2.4" xref="S4.F2.6.6.1.1.m1.2.2.4.cmml"><mi id="S4.F2.6.6.1.1.m1.2.2.4.2" xref="S4.F2.6.6.1.1.m1.2.2.4.2.cmml">C</mi><mtext id="S4.F2.6.6.1.1.m1.2.2.4.3" xref="S4.F2.6.6.1.1.m1.2.2.4.3a.cmml">max</mtext></msub></mfrac><annotation-xml encoding="MathML-Content" id="S4.F2.6.6.1.1.m1.2b"><apply id="S4.F2.6.6.1.1.m1.2.2.cmml" xref="S4.F2.6.6.1.1.m1.2.2"><divide id="S4.F2.6.6.1.1.m1.2.2.3.cmml" xref="S4.F2.6.6.1.1.m1.2.2"></divide><list id="S4.F2.6.6.1.1.m1.2.2.2.3.cmml" xref="S4.F2.6.6.1.1.m1.2.2.2.2"><apply id="S4.F2.6.6.1.1.m1.2.2.2.2.1.cmml" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1"><times id="S4.F2.6.6.1.1.m1.2.2.2.2.1.1.cmml" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.1"></times><cn id="S4.F2.6.6.1.1.m1.2.2.2.2.1.2.cmml" type="integer" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.2">610</cn><cn id="S4.F2.6.6.1.1.m1.2.2.2.2.1.3.cmml" type="integer" xref="S4.F2.6.6.1.1.m1.2.2.2.2.1.3">1</cn></apply><cn id="S4.F2.6.6.1.1.m1.1.1.1.1.cmml" type="integer" xref="S4.F2.6.6.1.1.m1.1.1.1.1">000</cn></list><apply id="S4.F2.6.6.1.1.m1.2.2.4.cmml" xref="S4.F2.6.6.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S4.F2.6.6.1.1.m1.2.2.4.1.cmml" xref="S4.F2.6.6.1.1.m1.2.2.4">subscript</csymbol><ci id="S4.F2.6.6.1.1.m1.2.2.4.2.cmml" xref="S4.F2.6.6.1.1.m1.2.2.4.2">𝐶</ci><ci id="S4.F2.6.6.1.1.m1.2.2.4.3a.cmml" xref="S4.F2.6.6.1.1.m1.2.2.4.3"><mtext id="S4.F2.6.6.1.1.m1.2.2.4.3.cmml" mathsize="50%" xref="S4.F2.6.6.1.1.m1.2.2.4.3">max</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.6.6.1.1.m1.2c">\frac{610\times 1{,}000}{C_{\text{max}}}</annotation><annotation encoding="application/x-llamapun" id="S4.F2.6.6.1.1.m1.2d">divide start_ARG 610 × 1 , 000 end_ARG start_ARG italic_C start_POSTSUBSCRIPT max end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.F2.8.8.5" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.8.8.5.1">1</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.F2.7.7.2" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.7.7.2.1"><math alttext="1{,}399\times 2+C_{\text{extract}}" class="ltx_Math" display="inline" id="S4.F2.7.7.2.1.m1.2"><semantics id="S4.F2.7.7.2.1.m1.2a"><mrow id="S4.F2.7.7.2.1.m1.2.2.1" xref="S4.F2.7.7.2.1.m1.2.2.2.cmml"><mn id="S4.F2.7.7.2.1.m1.1.1" xref="S4.F2.7.7.2.1.m1.1.1.cmml">1</mn><mo id="S4.F2.7.7.2.1.m1.2.2.1.2" xref="S4.F2.7.7.2.1.m1.2.2.2.cmml">,</mo><mrow id="S4.F2.7.7.2.1.m1.2.2.1.1" xref="S4.F2.7.7.2.1.m1.2.2.1.1.cmml"><mrow id="S4.F2.7.7.2.1.m1.2.2.1.1.2" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.cmml"><mn id="S4.F2.7.7.2.1.m1.2.2.1.1.2.2" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.2.cmml">399</mn><mo id="S4.F2.7.7.2.1.m1.2.2.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.1.cmml">×</mo><mn id="S4.F2.7.7.2.1.m1.2.2.1.1.2.3" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.3.cmml">2</mn></mrow><mo id="S4.F2.7.7.2.1.m1.2.2.1.1.1" xref="S4.F2.7.7.2.1.m1.2.2.1.1.1.cmml">+</mo><msub id="S4.F2.7.7.2.1.m1.2.2.1.1.3" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3.cmml"><mi id="S4.F2.7.7.2.1.m1.2.2.1.1.3.2" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3.2.cmml">C</mi><mtext id="S4.F2.7.7.2.1.m1.2.2.1.1.3.3" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3.3a.cmml">extract</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.7.7.2.1.m1.2b"><list id="S4.F2.7.7.2.1.m1.2.2.2.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1"><cn id="S4.F2.7.7.2.1.m1.1.1.cmml" type="integer" xref="S4.F2.7.7.2.1.m1.1.1">1</cn><apply id="S4.F2.7.7.2.1.m1.2.2.1.1.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1"><plus id="S4.F2.7.7.2.1.m1.2.2.1.1.1.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.1"></plus><apply id="S4.F2.7.7.2.1.m1.2.2.1.1.2.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2"><times id="S4.F2.7.7.2.1.m1.2.2.1.1.2.1.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.1"></times><cn id="S4.F2.7.7.2.1.m1.2.2.1.1.2.2.cmml" type="integer" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.2">399</cn><cn id="S4.F2.7.7.2.1.m1.2.2.1.1.2.3.cmml" type="integer" xref="S4.F2.7.7.2.1.m1.2.2.1.1.2.3">2</cn></apply><apply id="S4.F2.7.7.2.1.m1.2.2.1.1.3.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.F2.7.7.2.1.m1.2.2.1.1.3.1.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3">subscript</csymbol><ci id="S4.F2.7.7.2.1.m1.2.2.1.1.3.2.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3.2">𝐶</ci><ci id="S4.F2.7.7.2.1.m1.2.2.1.1.3.3a.cmml" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3.3"><mtext id="S4.F2.7.7.2.1.m1.2.2.1.1.3.3.cmml" mathsize="70%" xref="S4.F2.7.7.2.1.m1.2.2.1.1.3.3">extract</mtext></ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.7.7.2.1.m1.2c">1{,}399\times 2+C_{\text{extract}}</annotation><annotation encoding="application/x-llamapun" id="S4.F2.7.7.2.1.m1.2d">1 , 399 × 2 + italic_C start_POSTSUBSCRIPT extract end_POSTSUBSCRIPT</annotation></semantics></math></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.F2.8.8.3" rowspan="2" style="padding-left:0.9pt;padding-right:0.9pt;"><span class="ltx_text" id="S4.F2.8.8.3.1"><math alttext="C_{\text{extract}}" class="ltx_Math" display="inline" id="S4.F2.8.8.3.1.m1.1"><semantics id="S4.F2.8.8.3.1.m1.1a"><msub id="S4.F2.8.8.3.1.m1.1.1" xref="S4.F2.8.8.3.1.m1.1.1.cmml"><mi id="S4.F2.8.8.3.1.m1.1.1.2" xref="S4.F2.8.8.3.1.m1.1.1.2.cmml">C</mi><mtext id="S4.F2.8.8.3.1.m1.1.1.3" xref="S4.F2.8.8.3.1.m1.1.1.3a.cmml">extract</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F2.8.8.3.1.m1.1b"><apply id="S4.F2.8.8.3.1.m1.1.1.cmml" xref="S4.F2.8.8.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F2.8.8.3.1.m1.1.1.1.cmml" xref="S4.F2.8.8.3.1.m1.1.1">subscript</csymbol><ci id="S4.F2.8.8.3.1.m1.1.1.2.cmml" xref="S4.F2.8.8.3.1.m1.1.1.2">𝐶</ci><ci id="S4.F2.8.8.3.1.m1.1.1.3a.cmml" xref="S4.F2.8.8.3.1.m1.1.1.3"><mtext id="S4.F2.8.8.3.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.F2.8.8.3.1.m1.1.1.3">extract</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.8.8.3.1.m1.1c">C_{\text{extract}}</annotation><annotation encoding="application/x-llamapun" id="S4.F2.8.8.3.1.m1.1d">italic_C start_POSTSUBSCRIPT extract end_POSTSUBSCRIPT</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.F2.8.11.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r" id="S4.F2.8.11.3.1" style="padding-left:0.9pt;padding-right:0.9pt;">Calls</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.3">We compare the cost of our LightRAG with that of the top-performing baseline, GraphRAG, from two key perspectives. First, we examine the number of tokens and API calls during the indexing and retrieval processes. Second, we analyze these metrics in relation to handling data changes in dynamic environments. The results of this evaluation on the legal dataset are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S4.F2" title="Figure 2 ‣ 4.5 Model Cost and Adaptability Analysis (RQ4) ‣ 4 Evaluation ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>. In this context, <math alttext="T_{\text{extract}}" class="ltx_Math" display="inline" id="S4.SS5.p1.1.m1.1"><semantics id="S4.SS5.p1.1.m1.1a"><msub id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml"><mi id="S4.SS5.p1.1.m1.1.1.2" xref="S4.SS5.p1.1.m1.1.1.2.cmml">T</mi><mtext id="S4.SS5.p1.1.m1.1.1.3" xref="S4.SS5.p1.1.m1.1.1.3a.cmml">extract</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS5.p1.1.m1.1.1.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2">𝑇</ci><ci id="S4.SS5.p1.1.m1.1.1.3a.cmml" xref="S4.SS5.p1.1.m1.1.1.3"><mtext id="S4.SS5.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.SS5.p1.1.m1.1.1.3">extract</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">T_{\text{extract}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.1.m1.1d">italic_T start_POSTSUBSCRIPT extract end_POSTSUBSCRIPT</annotation></semantics></math> represents the token overhead for entity and relationship extraction, <math alttext="C_{\text{max}}" class="ltx_Math" display="inline" id="S4.SS5.p1.2.m2.1"><semantics id="S4.SS5.p1.2.m2.1a"><msub id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml"><mi id="S4.SS5.p1.2.m2.1.1.2" xref="S4.SS5.p1.2.m2.1.1.2.cmml">C</mi><mtext id="S4.SS5.p1.2.m2.1.1.3" xref="S4.SS5.p1.2.m2.1.1.3a.cmml">max</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><apply id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS5.p1.2.m2.1.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS5.p1.2.m2.1.1.2.cmml" xref="S4.SS5.p1.2.m2.1.1.2">𝐶</ci><ci id="S4.SS5.p1.2.m2.1.1.3a.cmml" xref="S4.SS5.p1.2.m2.1.1.3"><mtext id="S4.SS5.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS5.p1.2.m2.1.1.3">max</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">C_{\text{max}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.2.m2.1d">italic_C start_POSTSUBSCRIPT max end_POSTSUBSCRIPT</annotation></semantics></math> denotes the maximum number of tokens allowed per API call, and <math alttext="C_{\text{extract}}" class="ltx_Math" display="inline" id="S4.SS5.p1.3.m3.1"><semantics id="S4.SS5.p1.3.m3.1a"><msub id="S4.SS5.p1.3.m3.1.1" xref="S4.SS5.p1.3.m3.1.1.cmml"><mi id="S4.SS5.p1.3.m3.1.1.2" xref="S4.SS5.p1.3.m3.1.1.2.cmml">C</mi><mtext id="S4.SS5.p1.3.m3.1.1.3" xref="S4.SS5.p1.3.m3.1.1.3a.cmml">extract</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b"><apply id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS5.p1.3.m3.1.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS5.p1.3.m3.1.1.2.cmml" xref="S4.SS5.p1.3.m3.1.1.2">𝐶</ci><ci id="S4.SS5.p1.3.m3.1.1.3a.cmml" xref="S4.SS5.p1.3.m3.1.1.3"><mtext id="S4.SS5.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S4.SS5.p1.3.m3.1.1.3">extract</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">C_{\text{extract}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.3.m3.1d">italic_C start_POSTSUBSCRIPT extract end_POSTSUBSCRIPT</annotation></semantics></math> indicates the number of API calls required for extraction.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">In the retrieval phase, GraphRAG generates 1,399 communities, with 610 level-2 communities actively utilized for retrieval in this experiment. Each community report averages 1,000 tokens, resulting in a total token consumption of 610,000 tokens (610 communities <math alttext="\times" class="ltx_Math" display="inline" id="S4.SS5.p2.1.m1.1"><semantics id="S4.SS5.p2.1.m1.1a"><mo id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><times id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p2.1.m1.1d">×</annotation></semantics></math> 1,000 tokens per community). Additionally, GraphRAG’s requirement to traverse each community individually leads to hundreds of API calls, significantly increasing retrieval overhead. In contrast, LightRAG optimizes this process by using fewer than 100 tokens for keyword generation and retrieval, requiring only a single API call for the entire process. This efficiency is achieved through our retrieval mechanism, which seamlessly integrates graph structures and vectorized representations for information retrieval, thereby eliminating the need to process large volumes of information upfront.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">In the incremental data update phase, designed to address changes in dynamic real-world scenarios, both models exhibit similar overhead for entity and relationship extraction. However, GraphRAG shows significant inefficiency in managing newly added data. When a new dataset of the same size as the legal dataset is introduced, GraphRAG must dismantle its existing community structure to incorporate new entities and relationships, followed by complete regeneration. This process incurs a substantial token cost of approximately 5,000 tokens per community report. Given 1,399 communities, GraphRAG would require around 1,399 × 2 × 5,000 tokens to reconstruct both the original and new community reports—an exorbitant expense that underscores its inefficiency. In contrast, LightRAG seamlessly integrates newly extracted entities and relationships into the existing graph without the need for full reconstruction. This approach results in significantly lower overhead during incremental updates, demonstrating its superior efficiency and cost-effectiveness.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Retrieval-Augmented Generation with LLMs</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Retrieval-Augmented Generation (RAG) systems enhance LLM inputs by retrieving relevant information from external sources, grounding responses in factual, domain-specific knowledge <cite class="ltx_cite ltx_citemacro_cite">Ram et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib13" title="">2023</a>); Fan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib6" title="">2024</a>)</cite>. Current RAG approaches <cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib7" title="">2022</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib8" title="">2023</a>); Chan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib2" title="">2024</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib20" title="">2024</a>)</cite> typically embed queries in a vector space to find the nearest context vectors. However, many of these methods rely on fragmented text chunks and only retrieve the top-k contexts, limiting their ability to capture comprehensive global information needed for effective responses.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Although recent studies <cite class="ltx_cite ltx_citemacro_cite">Edge et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib4" title="">2024</a>)</cite> have explored using graph structures for knowledge representation, two key limitations persist. First, these approaches often lack the capability for dynamic updates and expansions of the knowledge graph, making it difficult to incorporate new information effectively. In contrast, our proposed model, LightRAG, addresses these challenges by enabling the RAG system to quickly adapt to new information, ensuring the model’s timeliness and accuracy. Additionally, existing methods often rely on brute-force searches for each generated community, which are inefficient for large-scale queries. Our LightRAG framework overcomes this limitation by facilitating rapid retrieval of relevant information from the graph through our proposed dual-level retrieval paradigm, significantly enhancing both retrieval efficiency and response speed.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Large Language Model for Graphs</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Graphs are a powerful framework for representing complex relationships and find applications in numerous fields. As Large Language Models (LLMs) continue to evolve, researchers have increasingly focused on enhancing their capability to interpret graph-structured data. This body of work can be divided into three primary categories: i) <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">GNNs as Prefix</span> where Graph Neural Networks (GNNs) are utilized as the initial processing layer for graph data, generating structure-aware tokens that LLMs can use during inference. Notable examples include GraphGPT <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib17" title="">2024</a>)</cite> and LLaGA <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib3" title="">2024</a>)</cite>. ii) <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">LLMs as Prefix</span> involves LLMs processing graph data enriched with textual information to produce node embeddings or labels, ultimately refining the training process for GNNs, as demonstrated in systems like GALM <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib19" title="">2023</a>)</cite> and OFA <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib10" title="">2024</a>)</cite>. iii) <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.3">LLMs-Graphs Integration</span> focuses on achieving a seamless interaction between LLMs and graph data, employing techniques such as fusion training and GNN alignment, and developing LLM-based agents capable of engaging with graph information directly <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib9" title="">2023</a>); Brannon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#bib.bib1" title="">2023</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This work introduces an advancement in Retrieval-Augmented Generation (RAG) through the integration of a graph-based indexing approach that enhances both efficiency and comprehension in information retrieval. LightRAG utilizes a comprehensive knowledge graph to facilitate rapid and relevant document retrieval, enabling a deeper understanding of complex queries. Its dual-level retrieval paradigm allows for the extraction of both specific and abstract information, catering to diverse user needs. Furthermore, LightRAG’s seamless incremental update capability ensures that the system remains current and responsive to new information, thereby maintaining its effectiveness over time. Overall, LightRAG excels in both efficiency and effectiveness, significantly improving the speed and quality of information retrieval and generation while reducing costs for LLM inference.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brannon et al. (2023)</span>
<span class="ltx_bibblock">
William Brannon, Suyash Fulay, Hang Jiang, Wonjune Kang, Brandon Roy, Jad Kabbara, and Deb Roy.

</span>
<span class="ltx_bibblock">Congrat: Self-supervised contrastive pretraining for joint graph and text embeddings.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2305.14321</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. (2024)</span>
<span class="ltx_bibblock">
Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, and Jie Fu.

</span>
<span class="ltx_bibblock">Rq-rag: Learning to refine queries for retrieval augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2404.00610</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Runjin Chen, Tong Zhao, AJAY KUMAR JAISWAL, Neil Shah, and Zhangyang Wang.

</span>
<span class="ltx_bibblock">Llaga: Large language and graph assistant.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">International Conference on Machine Learning (ICML)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edge et al. (2024)</span>
<span class="ltx_bibblock">
Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson.

</span>
<span class="ltx_bibblock">From local to global: A graph rag approach to query-focused summarization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2404.16130</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Es et al. (2024)</span>
<span class="ltx_bibblock">
Shahul Es, Jithin James, Luis Espinosa Anke, and Steven Schockaert.

</span>
<span class="ltx_bibblock">Ragas: Automated evaluation of retrieval augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">International Conference of the European Chapter of the Association for Computational Linguistics (EACL)</em>, pp.  150–158, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. (2024)</span>
<span class="ltx_bibblock">
Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li.

</span>
<span class="ltx_bibblock">A survey on rag meeting llms: Towards retrieval-augmented large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Conference on Knowledge Discovery and Data Mining (KDD)</em>, pp.  6491–6501, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2022)</span>
<span class="ltx_bibblock">
Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan.

</span>
<span class="ltx_bibblock">Precise zero-shot dense retrieval without relevance labels.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2212.10496</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2312.10997</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Yichuan Li, Kaize Ding, and Kyumin Lee.

</span>
<span class="ltx_bibblock">Grenade: Graph-centric language model for self-supervised representation learning on text-attributed graphs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">International Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pp.  2745–2757, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Hao Liu, Jiarui Feng, Lecheng Kong, Ningyue Liang, Dacheng Tao, Yixin Chen, and Muhan Zhang.

</span>
<span class="ltx_bibblock">One for all: Towards training one graph model for all classification tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">International Conference on Learning Representations (ICLR)</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al. (2024)</span>
<span class="ltx_bibblock">
Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, Bo Tang, Wenjin Wang, Hao Wu, Huanyong Liu, Tong Xu, and Enhong Chen.

</span>
<span class="ltx_bibblock">Crud-rag: A comprehensive chinese benchmark for retrieval-augmented generation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2401.17043</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian et al. (2024)</span>
<span class="ltx_bibblock">
Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao, and Zhicheng Dou.

</span>
<span class="ltx_bibblock">Memorag: Moving towards next-gen rag via memory-inspired knowledge discovery, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2409.05591" title="">https://arxiv.org/abs/2409.05591</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram et al. (2023)</span>
<span class="ltx_bibblock">
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.

</span>
<span class="ltx_bibblock">In-context retrieval-augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Transactions of the Association for Computational Linguistics (TACL)</em>, 11:1316–1331, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rampášek et al. (2022)</span>
<span class="ltx_bibblock">
Ladislav Rampášek, Michael Galkin, Vijay Prakash Dwivedi, Anh Tuan Luu, Guy Wolf, and Dominique Beaini.

</span>
<span class="ltx_bibblock">Recipe for a general, powerful, scalable graph transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International Conference on Neural Information Processing Systems (NeurIPS)</em>, 35:14501–14515, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salemi &amp; Zamani (2024)</span>
<span class="ltx_bibblock">
Alireza Salemi and Hamed Zamani.

</span>
<span class="ltx_bibblock">Evaluating retrieval quality in retrieval-augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">ACM International Conference on Research and Development in Information Retrieval (SIGIR)</em>, pp.  2395–2400, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sudhi et al. (2024)</span>
<span class="ltx_bibblock">
Viju Sudhi, Sinchana Ramakanth Bhat, Max Rudat, and Roman Teucher.

</span>
<span class="ltx_bibblock">Rag-ex: A generic framework for explaining retrieval augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">ACM International Conference on Research and Development in Information Retrieval (SIGIR)</em>, pp.  2776–2780, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2024)</span>
<span class="ltx_bibblock">
Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin, and Chao Huang.

</span>
<span class="ltx_bibblock">Graphgpt: Graph instruction tuning for large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">ACM International Conference on Research and Development in Information Retrieval (SIGIR)</em>, pp.  491–500, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al. (2024)</span>
<span class="ltx_bibblock">
Shangqing Tu, Yuanchun Wang, Jifan Yu, Yuyang Xie, Yaran Shi, Xiaozhi Wang, Jing Zhang, Lei Hou, and Juanzi Li.

</span>
<span class="ltx_bibblock">R-eval: A unified toolkit for evaluating domain knowledge of retrieval augmented large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International Conference on Knowledge Discovery and Data Mining (KDD)</em>, pp.  5813–5824, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2023)</span>
<span class="ltx_bibblock">
Han Xie, Da Zheng, Jun Ma, Houyu Zhang, Vassilis N Ioannidis, Xiang Song, Qing Ping, Sheng Wang, Carl Yang, Yi Xu, et al.

</span>
<span class="ltx_bibblock">Graph-aware language model pre-training on a large graph corpus can help multiple graph applications.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International Conference on Knowledge Discovery and Data Mining (KDD)</em>, pp.  5270–5281, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Yue Yu, Wei Ping, Zihan Liu, Boxin Wang, Jiaxuan You, Chao Zhang, Mohammad Shoeybi, and Bryan Catanzaro.

</span>
<span class="ltx_bibblock">Rankrag: Unifying context ranking with retrieval-augmented generation in llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2407.02485</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, and Bin Cui.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for ai-generated content: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2402.19473</em>, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Appendix</h2>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this section, we elaborate on the methodologies and experimental settings used in the LightRAG framework. It describes the specific steps for extracting entities and relationships from documents, detailing how large language models (LLMs) are utilized for this purpose. The section also specifies the prompt templates and configurations used in LLM operations, ensuring clarity in the experimental setup. Additionally, it outlines the evaluation criteria and dimensions used to assess the performance of LightRAG against baselines from various dimensions.</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Experimental Data Details</h3>
<figure class="ltx_table" id="S7.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Statistical information of the datasets.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S7.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S7.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.T4.1.1.1.1.1">Statistics</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S7.T4.1.1.1.2.1">Agriculture</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S7.T4.1.1.1.3.1">CS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S7.T4.1.1.1.4.1">Legal</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S7.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S7.T4.1.1.1.5.1">Mix</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T4.1.2.1.1">Total Documents</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.1.2.1.2">12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.1.2.1.3">10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.1.2.1.4">94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T4.1.2.1.5">61</td>
</tr>
<tr class="ltx_tr" id="S7.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T4.1.3.2.1">Total Tokens</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.1.3.2.2">2,017,886</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.1.3.2.3">2,306,535</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.1.3.2.4">5,081,069</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T4.1.3.2.5">619,009</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.T4" title="Table 4 ‣ 7.1 Experimental Data Details ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a> presents statistical information for four datasets: Agriculture, CS, Legal, and Mix. The Agriculture dataset consists of 12 documents totaling 2,017,886 tokens, while the CS dataset contains 10 documents with 2,306,535 tokens. The Legal dataset is the largest, comprising 94 documents and 5,081,069 tokens. Lastly, the Mix dataset includes 61 documents with a total of 619,009 tokens.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Case Example of Retrieval-Augmented Generation in LightRAG.</h3>
<figure class="ltx_figure" id="S7.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="411" id="S7.F3.g1" src="extracted/5908979/figs/retrieval_and_generation_example.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A retrieval and generation example.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.F3" title="Figure 3 ‣ 7.2 Case Example of Retrieval-Augmented Generation in LightRAG. ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a>, we illustrate the retrieve-and-generate process. When presented with the query, “What metrics are most informative for evaluating movie recommendation systems?”, the LLM first extracts both low-level and high-level keywords. These keywords guide the dual-level retrieval process on the generated knowledge graph, targeting relevant entities and relationships. The retrieved information is organized into three components: entities, relationships, and corresponding text chunks. This structured data is then fed into the LLM, enabling it to generate a comprehensive answer to the query.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Overview of the Prompts Used in LightRAG</h3>
<section class="ltx_subsubsection" id="S7.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.1 </span>Prompts for Graph Generation</h4>
<figure class="ltx_figure" id="S7.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="S7.F4.g1" src="extracted/5908979/figs/graph_construct_prompt.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Prompts for Graph Generation</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS3.SSS1.p1">
<p class="ltx_p" id="S7.SS3.SSS1.p1.1">The graph construction prompt outlined in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.F4" title="Figure 4 ‣ 7.3.1 Prompts for Graph Generation ‣ 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a> is designed to extract and structure entity-relationship information from a text document based on specified entity types. The process begins by identifying entities and categorizing them into types such as organization, person, location, and event. It then provides detailed descriptions of their attributes and activities. Next, the prompt identifies relationships between these entities, offering explanations, assigning strength scores, and summarizing the relationships using high-level keywords.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.2 </span>Prompts for Query Generation</h4>
<figure class="ltx_figure" id="S7.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="141" id="S7.F5.g1" src="extracted/5908979/figs/query_generate_prompt.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Prompts for Query Generation</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS3.SSS2.p1">
<p class="ltx_p" id="S7.SS3.SSS2.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.F5" title="Figure 5 ‣ 7.3.2 Prompts for Query Generation ‣ 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a>, the query generation prompt outlines a framework for identifying potential user roles (e.g., data scientist, finance analyst, and product manager) and their objectives for generating queries based on a specified dataset description. The prompt explains how to define five distinct users who would benefit from interacting with the dataset. For each user, it specifies five key tasks they would perform while working with the dataset. Additionally, for each (user, task) combination, five high-level questions are posed to ensure a thorough understanding of the dataset.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.3 </span>Prompts for Keyword Extraction</h4>
<figure class="ltx_figure" id="S7.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="S7.F6.g1" src="extracted/5908979/figs/Keywords_generate_prompt.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Prompts for Keyword Extraction</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS3.SSS3.p1">
<p class="ltx_p" id="S7.SS3.SSS3.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.F6" title="Figure 6 ‣ 7.3.3 Prompts for Keyword Extraction ‣ 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a>, the prompt describes a method for extracting keywords from a user’s query, distinguishing between high-level and low-level keywords. High-level keywords represent broad concepts or themes, while low-level keywords focus on specific entities and details. The extracted keywords are returned in JSON format, organized into two fields: “high_level_keywords” for overarching ideas and “low_level_keywords” for specific details.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S7.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.3.4 </span>Prompts for RAG Evaluation</h4>
<figure class="ltx_figure" id="S7.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="271" id="S7.F7.g1" src="extracted/5908979/figs/evaluation_prompt.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Prompts for RAG Evaluation</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS3.SSS4.p1">
<p class="ltx_p" id="S7.SS3.SSS4.p1.1">The evaluation prompt is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.F7" title="Figure 7 ‣ 7.3.4 Prompts for RAG Evaluation ‣ 7.3 Overview of the Prompts Used in LightRAG ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">7</span></a>. It introduces a comprehensive evaluation framework for comparing two answers to the same question based on three key criteria: Comprehensiveness, Diversity, and Empowerment. Its purpose is to guide the LLM through the process of selecting the better answer for each criterion, followed by an overall assessment. For each of the three criteria, the LLM must identify which answer performs better and provide a rationale for its choice. Ultimately, an overall winner is determined based on performance across all three dimensions, accompanied by a detailed summary that justifies the decision. The evaluation is structured in JSON format, ensuring clarity and consistency, and facilitating a systematic comparison between the two answers.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S7.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span>Case Study: Comparison Between LightRAG and the Baseline NaiveRAG.</h3>
<figure class="ltx_table" id="S7.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Case Study: Comparison Between LightRAG and the Baseline NaiveRAG.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T5.1" style="width:397.5pt;height:364pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-59.1pt,54.0pt) scale(0.770755754739574,0.770755754739574) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.1.1.1.1">Query</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S7.T5.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S7.T5.1.1.1.1.2.1">
<span class="ltx_p" id="S7.T5.1.1.1.1.2.1.1" style="width:426.8pt;">How do indigenous perspectives on ownership and collaboration influence corporate mergers in countries like Canada and Australia?</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T5.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.2.1.1.1">NaiveRAG</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S7.T5.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S7.T5.1.1.2.1.2.1">
<span class="ltx_p" id="S7.T5.1.1.2.1.2.1.1" style="width:426.8pt;">Indigenous perspectives on ownership and collaboration play a significant role in shaping corporate mergers in countries like Canada and Australia, particularly where resources and land rights intersect with Indigenous sovereignty and cultural values. These perspectives emphasize community engagement, respect for traditional land use, and a collaborative approach to resource management, influencing corporate strategies and outcomes.</span>
<span class="ltx_p" id="S7.T5.1.1.2.1.2.1.2">…</span>
<span class="ltx_p" id="S7.T5.1.1.2.1.2.1.3">Both nations illustrate that prioritizing Indigenous perspectives leads to more sustainable and equitable outcomes. Acknowledging Indigenous rights and fostering collaborative relationships can reduce conflicts and enhance corporate reputations. Ultimately, integrating Indigenous perspectives is a pathway to better business practices and community relations.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.1.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.3.2.1.1">LightRAG</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S7.T5.1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S7.T5.1.1.3.2.2.1">
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.3.2.2.1.1.1">Indigenous Perspectives on Ownership and Collaboration in Corporate Mergers</span></span>
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.2">Indigenous perspectives significantly influence corporate mergers in countries like Canada and Australia. These views emphasize communal rights to land and resources, spiritual connections to the environment, and the importance of collaboration over competition.</span>
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.3"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.3.2.2.1.3.1">Cultural Significance of Land Ownership</span> […]</span>
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.4"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.3.2.2.1.4.1">The Role of Collaboration</span> […]</span>
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.5"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.3.2.2.1.5.1">Legal and Regulatory Frameworks</span> […] 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.6"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.3.2.2.1.6.1">Conclusion</span></span>
<span class="ltx_p" id="S7.T5.1.1.3.2.2.1.7">Indigenous perspectives shape corporate mergers by emphasizing communal ownership and collaborative partnerships. Corporations must adopt respectful, inclusive practices that honor Indigenous cultural values and rights, paving the way for sustainable, mutually beneficial outcomes.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S7.T5.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S7.T5.1.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.4.3.1.1">LLM Decision</span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="S7.T5.1.1.4.3.2.1">
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.1" style="width:426.8pt;"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.4.3.2.1.1.1">Comprehensiveness</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.2">"Explanation": "Answer 2 provides a thorough exploration of the indigenous perspectives by discussing cultural significance, collaboration, and legal frameworks, including specific examples and detailed insights. In contrast, Answer 1, while informative, lacks the same depth in analyzing the various dimensions of the indigenous perspectives on ownership and collaboration." 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.3"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.4.3.2.1.3.1">Diversity</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.4">"Explanation": "Answer 2 presents a wider array of perspectives, focusing on the communal aspect of land ownership, spiritual connections, and practical examples of collaboration. It covers more ground by contrasting Indigenous views with Western notions, whereas Answer 1 primarily focuses on corporate strategies and outcomes with limited perspective." 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.5"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.4.3.2.1.5.1">Empowerment</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.6">"Explanation": "Answer 2 equips the reader with nuanced understanding and actionable insights by highlighting the importance of collaboration and the legal frameworks involved. It empowers corporations by illustrating how adopting an inclusive approach can facilitate better outcomes. Answer 1, while practical, does not emphasize the moral or ethical implications as strongly." 
<br class="ltx_break"/></span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.7"><span class="ltx_text ltx_font_bold" id="S7.T5.1.1.4.3.2.1.7.1">Overall Winner</span>:
"Winner": "Answer 2 (LightRAG)",</span>
<span class="ltx_p" id="S7.T5.1.1.4.3.2.1.8">"Explanation": "Answer 2 excels overall due to its comprehensive exploration, diversity of perspectives, and empowerment of the reader with actionable insights about indigenous perspectives and collaboration in corporate mergers. Although Answer 1 is more direct, the depth and breadth of Answer 2 make it the stronger response."</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS4.p1">
<p class="ltx_p" id="S7.SS4.p1.1">To further illustrate LightRAG’s superiority over baseline models in terms of comprehensiveness, empowerment, and diversity, we present a case study comparing LightRAG and NaiveRAG in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05779v1#S7.T5" title="Table 5 ‣ 7.4 Case Study: Comparison Between LightRAG and the Baseline NaiveRAG. ‣ 7 Appendix ‣ LightRAG: Simple and Fast Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a>. This study addresses a question regarding indigenous perspectives in the context of corporate mergers. Notably, LightRAG offers a more in-depth exploration of key themes related to indigenous perspectives, such as cultural significance, collaboration, and legal frameworks, supported by specific and illustrative examples. In contrast, while NaiveRAG provides informative responses, it lacks the depth needed to thoroughly examine the various dimensions of indigenous ownership and collaboration. The dual-level retrieval process employed by LightRAG enables a more comprehensive investigation of specific entities and their interrelationships, facilitating extensive searches that effectively capture overarching themes and complexities within the topic.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  8 07:58:44 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
