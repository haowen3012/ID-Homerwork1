<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization</title>
<!--Generated on Thu Oct  3 17:23:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Artificial Intelligence,  Retrieval Augmented Generation,  Knowledge Graph,  Natural Language Processing,  Non-Negative Tensor Factorization,  Topic Modeling,  Agents
" lang="en" name="keywords"/>
<base href="/html/2410.02721v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S1" title="In Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S2" title="In Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Works</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S2.SS1" title="In II Related Works ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">KGs in RAG Pipelines</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S2.SS2" title="In II Related Works ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">KG Development</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3" title="In Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methods</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.SS1" title="In III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Domain-Specific Dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.SS2" title="In III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Dimension Reduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.SS3" title="In III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Knowledge Graph Ontology</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.SS4" title="In III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Vector Store Assembly</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.SS5" title="In III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-E</span> </span><span class="ltx_text ltx_font_italic">Retrieval Augmented Generation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4" title="In Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.SS1" title="In IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic"> Dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.SS2" title="In IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic"> Extraction of Latent Features</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.SS3" title="In IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Vector Store</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.SS4" title="In IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic">Knowledge Graph</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.SS5" title="In IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-E</span> </span><span class="ltx_text ltx_font_italic">Question Answering Validation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S5" title="In Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\NewDocumentCommand</span><span class="ltx_ERROR undefined" id="p1.2">\vect</span>
<p class="ltx_p" id="p1.3">O O m <span class="ltx_text ltx_font_bold" id="p1.3.1">#3</span>^(#1)_#2
<span class="ltx_ERROR undefined" id="p1.3.2">\NewDocumentCommand</span><span class="ltx_ERROR undefined" id="p1.3.3">\mat</span> O O m <span class="ltx_text ltx_font_bold" id="p1.3.4">#3</span>^(#1)_#2
<span class="ltx_ERROR undefined" id="p1.3.5">\NewDocumentCommand</span><span class="ltx_ERROR undefined" id="p1.3.6">\ten</span> O O m <span class="ltx_text ltx_font_script ltx_font_bold" id="p1.3.7">#3</span>^(#1)_#2










</p>
</div>
<h1 class="ltx_title ltx_title_document">Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ryan C. Barron236,
Vesselin Grantcharov46,
Selma Wanna15,
Maksim E. Eren13,
<br class="ltx_break"/>Manish Bhattarai2,
Nicholas Solovyev2,
George Tompkins7,
<br class="ltx_break"/>Charles Nicholas31,
Kim Ø. Rasmussen2,
Cynthia Matuszek31,
and Boian S. Alexandrov2
</span><span class="ltx_author_notes">6The first two authors contributed equally to this work.U.S. Government work not protected by U.S. %copyright.
<span class="ltx_contact ltx_role_affiliation">
7Analytics, Intelligence and Technology Division, Los Alamos National Laboratory, Los Alamos, New Mexico, USA. 
<br class="ltx_break"/>4University of New Mexico.
5University of Texas at Austin.
3University of Maryland Baltimore County.
<br class="ltx_break"/>1Advanced Research in Cyber Systems, Los Alamos National Laboratory, New Mexico, USA. 
<br class="ltx_break"/>2Theoretical Division, Los Alamos National Laboratory, New Mexico, USA.

</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Large Language Models (LLMs) are pre-trained on large-scale corpora and excel in numerous general natural language processing (NLP) tasks, such as question answering (QA). Despite their advanced language capabilities, when it comes to domain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations, knowledge cut-offs, and lack of knowledge attributions. Additionally, fine tuning LLMs’ intrinsic knowledge to highly specific domains is an expensive and time consuming process. The retrieval-augmented generation (RAG) process has recently emerged as a method capable of optimization of LLM responses, by referencing them to a predetermined ontology. It was shown that using a Knowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into account relevant sub-graphs that preserve the information in a structured manner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM framework, that integrates RAG with KG and a vector store (VS) that store factual domain specific information. Importantly, to avoid hallucinations in the KG, we build these highly domain-specific KGs and VSs without the use of LLMs, but via NLP, data mining, and nonnegative tensor factorization with automatic model selection. Pairing our RAG with a domain-specific: (i) KG (containing structured information), and (ii) VS (containing unstructured information) enables the development of domain-specific chat-bots that attribute the source of information, mitigate hallucinations, lessen the need for fine-tuning, and excel in highly domain-specific question answering tasks. We pair SMART-SLIC with chain-of-thought prompting agents. The framework is designed to be generalizable to adapt to any specific or specialized domain. In this paper, we demonstrate the question answering capabilities of our framework on a corpus of scientific publications on malware analysis and anomaly detection.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Artificial Intelligence, Retrieval Augmented Generation, Knowledge Graph, Natural Language Processing, Non-Negative Tensor Factorization, Topic Modeling, Agents

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The expanding volumes of data across large databases and information collections necessitate the specialized extraction of pertinent knowledge, often without an in-depth understanding of the underlying database resources. Recent advancements in Large Language Models (LLMs) have facilitated developments that enable users to engage in dialogues with LLM-powered chat-bots to discover information. Despite these models’ impressive handling of general queries, their application in domain-specific tasks is hindered by several limitations. These include the production of factually incorrect responses (”hallucinations”) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib1" title="">1</a>]</cite>, unawareness of recent developments or events beyond their training data (”knowledge cutoff”) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib2" title="">2</a>]</cite>, failure to accurately attribute sources of information (”implicit knowledge”) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib3" title="">3</a>]</cite>, and a lack of specific technical knowledge required for specialized fields <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Fine-tuning is a common strategy employed to tailor these general models to specific domains. However, this approach is resource-intensive, demanding significant amounts of data, extensive computational power, and considerable time, which makes it impractical for many domain-specific applications. These limitations pose significant challenges in interpreting and validating the knowledge generated by LLMs, as well as in referencing their sources. Consequently, this reduces the trustworthiness of LLMs and limits their effectiveness in highly specialized scientific contexts where accuracy and reliability are paramount. The ongoing challenges underscore the need for more sophisticated solutions that can bridge the gap between general-purpose LLMs and the nuanced requirements of domain-specific applications.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Retrieval-Augmented Generation (RAG) with Knowledge Graphs (KGs) and vector stores (VS) significantly enhances the context of LLMs, mitigating the need to fine-tune these models to specific domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib6" title="">6</a>]</cite>. KGs provide a structured way to store factual information, making it easier to access and use, while VSs allow storing unstructured documents and preserving the semantics of the text. This integration allows LLMs to tap into both domain-specific and updated information, effectively addressing the traditional limitations of generative models.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Despite these improvements, challenges remain in the practical implementation of domain-specific RAG systems. Extracting accurate and representative domain-specific ontologies to build KGs and VSs is a complex task. Additionally, curating datasets with specific text data for constructing both KGs and VSs is equally demanding. These steps are critical for ensuring that the augmented LLMs can reliably produce high-quality, relevant responses across different domains.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper,
we introduce a framework designed for constructing domain-specific corpora of scientific articles through advanced techniques, including: text mining, information retrieval, dimension reduction, nonnegative tensor factorization, citation graphs, and human-in-the-loop strategies. We introduce a novel framework, which we call <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">SMART-SLIC</span>,
for developing KG’s ontologies, utilizing both metadata and full texts from open-source scientific publications, as well the latent structures of these corpora, extracted through nonnegative tensor factorization, enhanced with automatic model determination. <span class="ltx_text ltx_font_bold" id="S1.p5.1.2">SMART-SLIC</span> facilitates topic modeling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib7" title="">7</a>]</cite>,
and determination of the optimal number of topics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib9" title="">9</a>]</cite>
for effective document classification.
Our new framework underpins the creation of a precisely tailored corpus of domain-specific scientific articles, which is crucial for our AG approach and supports the development of a chat-bot adept at answering domain-specific technical inquiries. Further, the framework is versatile, allowing for its application to any domain of documents. In this paper, we illustrate the effectiveness of our framework, <span class="ltx_text ltx_font_bold" id="S1.p5.1.3">SMART-SLIC</span>, with a case study where we construct a domain-specific corpus, KG, and VS, focused on malware analysis and anomaly detection, and apply our enhanced question-answering framework for scientific queries related to this corpus. Our contributions are summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We detail the development of a framework for building domain-specific scientific corpora using a blend of text mining, information retrieval, artificial intelligence (AI), and human-in-the-loop techniques.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We describe the creation of a domain-specific KG <math alttext="\&amp;" class="ltx_Math" display="inline" id="S1.I1.i2.p1.1.m1.1"><semantics id="S1.I1.i2.p1.1.m1.1a"><mo id="S1.I1.i2.p1.1.m1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.1.m1.1b"><and id="S1.I1.i2.p1.1.m1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.1c">\&amp;</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i2.p1.1.m1.1d">&amp;</annotation></semantics></math> VS ontology that leverages both observable metadata, and full texts of the corpus of domain-specific open-source scientific articles, as well as its latent structure extracted by non-negative tensor/matrix factorization with automatic model selection.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrate the enhanced capabilities of <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">SMART-SLIC</span>’s, RAG-enhanced LLM system, which utilizes chain-of-thought prompting with LLM agents to proficiently address scientific questions.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Works</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Recent methods for building RAG-assisted <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib6" title="">6</a>]</cite> chatbot applications rely on unstructured text stored in vector databases for question answering (QA) tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib10" title="">10</a>]</cite>. Although the integration of knowledge graphs (KGs) in AI systems is not novel <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib11" title="">11</a>]</cite>, increasingly, researchers are leveraging them to improve LLM reasoning while simultaneously addressing the reliability issues discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S1" title="I Introduction ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">I</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib14" title="">14</a>]</cite>. Despite the benefits, integrating domain-specific knowledge into chatbots requires substantial effort. Here, we review the prior work for common chatbot designs, the integration of domain-knowledge in RAG pipelines, and the steps required for constructing KGs.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">KGs in RAG Pipelines</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Building a sophisticated chatbot requires the knowledge of a wide range of research fields; hence, rarely do prior works present a fully engineered system like ours. Instead, most efforts focus on improving specific aspects of RAG pipelines, e.g., retriever design <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib16" title="">16</a>]</cite>, query intent recognition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib17" title="">17</a>]</cite>, and KG reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib21" title="">21</a>]</cite>. Our approach resembles past methods which leverage chain-of-thought <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib22" title="">22</a>]</cite> prompting on KGs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib19" title="">19</a>]</cite>; in conjunction with LLM-agents to enhance reasoning capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib25" title="">25</a>]</cite>. In addition to incorporating these state-of-the-art techniques, we improve our RAG pipeline by modifying our retrieval method to use K-Nearest Neighbors with the Levenshtein metric instead of cosine distance as an entry point for context search. We also construct a “highly-specific” knowledge base for targeted QA tasks.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Although expensive and time-consuming, a handful of prior works incorporate domain-knowledge into their RAG pipelines <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib29" title="">29</a>]</cite>; however, the majority either use existing KGs built broadly on medical literature <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib28" title="">28</a>]</cite>; or do not disclose any details regarding their dataset construction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib29" title="">29</a>]</cite>. We emphasize that our method is “highly-specific” because it was driven by subject matter expertise which informed our dataset curation and cleaning techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib31" title="">31</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.5.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.6.2">KG Development</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">At a minimum, the development of knowledge graphs requires building a corpus, defining an ontology, and extracting the relevant entity-relation triplets from unstructured text.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Corpus Building.</span> Here we define the term “highly-specific” and explain our dataset collection method. A key feature of our dataset collection is the use of unsupervised methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib31" title="">31</a>]</cite> to decompose corpora into document clusters to finer specificity than the author-provided tags available on open access websites. This differs significantly from prior approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib33" title="">33</a>]</cite>. We leverage latent-topic information from our NMFk method to filter and select the best data for our knowledge base, and prune documents based on citation information and embedding distances. Our text cleaning pipeline is informed by subject matter experts (SME) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib34" title="">34</a>]</cite>, thus going beyond standard methods by incorporating expert-derived rules for document cleaning, e.g, acronym and entity standardization.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">KG Construction.</span> Our ontology is shaped by traditional methods, i.e., relying on SME design and capturing task-specific features. However, we innovate by incorporating latent information from our decomposition process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib31" title="">31</a>]</cite> into our KG as entities. For entity and relation extraction, we move beyond conventional learning-based techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib35" title="">35</a>]</cite>; and instead, leverage recent advancements which use LLM-agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib36" title="">36</a>]</cite> as opposed to other LLM prompting methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib40" title="">40</a>]</cite>. This approach yields non-sparse KGs, meaning, the average out-degree of entities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib42" title="">42</a>]</cite> is high. To our knowledge, no prior work integrates all of these methods into their knowledge graph construction process.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methods</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section outlines our framework, covering corpus extraction, KG ontology, VS construction, and the RAG process.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Domain-Specific Dataset</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Overview of of our system is summarized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.F1" title="Figure 1 ‣ III-A Domain-Specific Dataset ‣ III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">1</span></a>. To collect the dataset, we began with a set of core documents selected by subject matter experts (SMEs).
Here, these core documents represent the specific domain in which we want to built our corpus on. These core documents were used to build a citation and reference network, which allowed for the expansion of the dataset through the authorized APIs: SCOPUS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib43" title="">43</a>]</cite>, Semantic Scholar (S2) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib44" title="">44</a>]</cite>, and Office of Scientific and Technical Information (OSTI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib45" title="">45</a>]</cite>.</p>
</div>
<figure class="ltx_figure ltx_align_floatleft" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="431" id="S3.F1.g1" src="x1.png" width="414"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span> User query routing overview.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We also extract common bigrams from the core documents to query these APIs to search for relevant documents. As we expand on the the corpus starting from the core documents, it is possible to add documents that do not directly relate to the information in the core documents. To maintain the central quality and thematic coherence of the core dataset, we employed several pruning strategies to remove these irrelevant documents to preserve the speciality specific to the targeted domain. These strategies focused on removing documents that diverge from the central theme of the core. Pruning was performed through two methods from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib34" title="">34</a>]</cite>:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1" style="font-size:80%;">Human-in-the-Loop Pruning</span><span class="ltx_text" id="S3.I1.i1.p1.1.2" style="font-size:80%;">:
SMEs manually review and select a handful documents that align with the core theme. Here, we reduce the document’s TF-IDF matrix to two dimensions with UMAP and let the SME look at the documents that are at the centroids of the given clusters. SME can then select which documents to remove.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1" style="font-size:80%;">Automatic Pruning of Document Embeddings</span><span class="ltx_text" id="S3.I1.i2.p1.1.2" style="font-size:80%;">:
Based on the SME selections from the previous step, we next remove the document that are certain distance away from the selected and the core documents. Documents were transformed into embeddings with SCI-NCL </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.I1.i2.p1.1.3.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib46" title="">46</a><span class="ltx_text" id="S3.I1.i2.p1.1.4.2" style="font-size:80%;">]</span></cite><span class="ltx_text" id="S3.I1.i2.p1.1.5" style="font-size:80%;">, a BERT based model fine-tuned on scientific literature, to measure semantic similarity with core and SME selected documents. Those outside a set similarity threshold were removed, ensuring only the documents relevant to the core documents and SME selections remained.</span></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS1.p2.2">Although a human is in the loop, the system remains scalable by clustering documents. One review per cluster allows the operator to decide on all documents in the group, making it efficient even with large datasets without limit on cluster size.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Additionally, we applied pre-processing techniques
using a publicly available Python library, <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">T</span>ensor <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.2">E</span>xtraction of <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.3">L</span>atent <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.4">F</span>eatures (<span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.5">T-ELF</span>)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>T-ELF is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lanl/T-ELF" title="">https://github.com/lanl/T-ELF</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib31" title="">31</a>]</cite>. The cleaning procedures involved the following pre-processing steps:</p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text" id="S3.I2.i1.p1.1.1" style="font-size:80%;">Exclude non-English, copyrights, and non-essential elements: stop phrases, formulas, and email addresses.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text" id="S3.I2.i2.p1.1.1" style="font-size:80%;">Remove formatting artifacts like next-line markers, parentheses, brackets, accents, and special characters.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text" id="S3.I2.i3.p1.1.1" style="font-size:80%;">Filter out non-ASCII characters and boundaries, HTML tags, stop words, and standalone numbers.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p" id="S3.I2.i4.p1.1"><span class="ltx_text" id="S3.I2.i4.p1.1.1" style="font-size:80%;">Eliminate extra whitespace and words </span><math alttext="\leq 2" class="ltx_Math" display="inline" id="S3.I2.i4.p1.1.m1.1"><semantics id="S3.I2.i4.p1.1.m1.1a"><mrow id="S3.I2.i4.p1.1.m1.1.1" xref="S3.I2.i4.p1.1.m1.1.1.cmml"><mi id="S3.I2.i4.p1.1.m1.1.1.2" xref="S3.I2.i4.p1.1.m1.1.1.2.cmml"></mi><mo id="S3.I2.i4.p1.1.m1.1.1.1" mathsize="80%" xref="S3.I2.i4.p1.1.m1.1.1.1.cmml">≤</mo><mn id="S3.I2.i4.p1.1.m1.1.1.3" mathsize="80%" xref="S3.I2.i4.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i4.p1.1.m1.1b"><apply id="S3.I2.i4.p1.1.m1.1.1.cmml" xref="S3.I2.i4.p1.1.m1.1.1"><leq id="S3.I2.i4.p1.1.m1.1.1.1.cmml" xref="S3.I2.i4.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S3.I2.i4.p1.1.m1.1.1.2.cmml" xref="S3.I2.i4.p1.1.m1.1.1.2">absent</csymbol><cn id="S3.I2.i4.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.I2.i4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i4.p1.1.m1.1c">\leq 2</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i4.p1.1.m1.1d">≤ 2</annotation></semantics></math><span class="ltx_text" id="S3.I2.i4.p1.1.2" style="font-size:80%;"> characters.</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i5.p1">
<p class="ltx_p" id="S3.I2.i5.p1.1"><span class="ltx_text" id="S3.I2.i5.p1.1.1" style="font-size:80%;">Standardize punctuation variations, particularly hyphens.</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">These pre-processing cleaning and standardization efforts are essential for preparing the dataset for further analysis, thereby enhancing the quality and consistency of the data.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Dimension Reduction</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The extraction of the latent structure from the dataset is accomplished through the following approach. Initially, the data is prepared and the necessary computational framework is established through these steps:</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1">Creation of the TF-IDF matrix, <math alttext="\mathbf{X}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.1.m1.1"><semantics id="S3.I3.i1.p1.1.m1.1a"><mi id="S3.I3.i1.p1.1.m1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.1.m1.1b"><ci id="S3.I3.i1.p1.1.m1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.1.m1.1c">\mathbf{X}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.1.m1.1d">bold_X</annotation></semantics></math>, of the cleaned corpus</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><math alttext="\mathbf{X}" class="ltx_Math" display="inline" id="S3.I3.i2.p1.1.m1.1"><semantics id="S3.I3.i2.p1.1.m1.1a"><mi id="S3.I3.i2.p1.1.m1.1.1" xref="S3.I3.i2.p1.1.m1.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i2.p1.1.m1.1b"><ci id="S3.I3.i2.p1.1.m1.1.1.cmml" xref="S3.I3.i2.p1.1.m1.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i2.p1.1.m1.1c">\mathbf{X}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i2.p1.1.m1.1d">bold_X</annotation></semantics></math> is decomposed using nonnegative tensor factorization from <span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">T-ELF</span> enhanced with our new binary search strategy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib47" title="">47</a>]</cite>,
to classify document clusters.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.9"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.9.1">T-ELF</span> allows us to extract highly specific features from the data. This method identifies latent topics within the corpus, grouping documents into clusters based on shared themes. To avoid over/under-fitting, automatic model determination is used where the final cluster counts are determined by achieving the highest silhouette scores above a predetermined threshold using the Binary Bleed method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib47" title="">47</a>]</cite>.
This method employs a binary search strategy across <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_k</annotation></semantics></math> values, selectively skipping those <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_k</annotation></semantics></math> values that do not surpass the silhouette threshold. The search criterion for an optimal <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_k</annotation></semantics></math> is defined as <math alttext="k_{\text{optimal}}=\max\left\{k\in\{1,2,\ldots,K\}:S(f(k))&gt;T\right\}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.7"><semantics id="S3.SS2.p3.4.m4.7a"><mrow id="S3.SS2.p3.4.m4.7.7" xref="S3.SS2.p3.4.m4.7.7.cmml"><msub id="S3.SS2.p3.4.m4.7.7.3" xref="S3.SS2.p3.4.m4.7.7.3.cmml"><mi id="S3.SS2.p3.4.m4.7.7.3.2" xref="S3.SS2.p3.4.m4.7.7.3.2.cmml">k</mi><mtext id="S3.SS2.p3.4.m4.7.7.3.3" xref="S3.SS2.p3.4.m4.7.7.3.3a.cmml">optimal</mtext></msub><mo id="S3.SS2.p3.4.m4.7.7.2" xref="S3.SS2.p3.4.m4.7.7.2.cmml">=</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1" xref="S3.SS2.p3.4.m4.7.7.1.2.cmml"><mi id="S3.SS2.p3.4.m4.6.6" xref="S3.SS2.p3.4.m4.6.6.cmml">max</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1a" xref="S3.SS2.p3.4.m4.7.7.1.2.cmml">⁡</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.2.cmml"><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.2" xref="S3.SS2.p3.4.m4.7.7.1.2.cmml">{</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.cmml"><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.2.cmml">k</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.1.cmml">∈</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml"><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2.1" stretchy="false" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml">{</mo><mn id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">1</mn><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml">,</mo><mn id="S3.SS2.p3.4.m4.2.2" xref="S3.SS2.p3.4.m4.2.2.cmml">2</mn><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2.3" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml">,</mo><mi id="S3.SS2.p3.4.m4.3.3" mathvariant="normal" xref="S3.SS2.p3.4.m4.3.3.cmml">…</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2.4" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml">,</mo><mi id="S3.SS2.p3.4.m4.4.4" xref="S3.SS2.p3.4.m4.4.4.cmml">K</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2.5" rspace="0.278em" stretchy="false" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml">}</mo></mrow></mrow><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.2" rspace="0.278em" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.2.cmml">:</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.cmml"><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.3.cmml">S</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.2.cmml">f</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.3.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.SS2.p3.4.m4.5.5" xref="S3.SS2.p3.4.m4.5.5.cmml">k</mi><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.2.cmml">&gt;</mo><mi id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.3.cmml">T</mi></mrow></mrow><mo id="S3.SS2.p3.4.m4.7.7.1.1.1.3" xref="S3.SS2.p3.4.m4.7.7.1.2.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.7b"><apply id="S3.SS2.p3.4.m4.7.7.cmml" xref="S3.SS2.p3.4.m4.7.7"><eq id="S3.SS2.p3.4.m4.7.7.2.cmml" xref="S3.SS2.p3.4.m4.7.7.2"></eq><apply id="S3.SS2.p3.4.m4.7.7.3.cmml" xref="S3.SS2.p3.4.m4.7.7.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.7.7.3.1.cmml" xref="S3.SS2.p3.4.m4.7.7.3">subscript</csymbol><ci id="S3.SS2.p3.4.m4.7.7.3.2.cmml" xref="S3.SS2.p3.4.m4.7.7.3.2">𝑘</ci><ci id="S3.SS2.p3.4.m4.7.7.3.3a.cmml" xref="S3.SS2.p3.4.m4.7.7.3.3"><mtext id="S3.SS2.p3.4.m4.7.7.3.3.cmml" mathsize="70%" xref="S3.SS2.p3.4.m4.7.7.3.3">optimal</mtext></ci></apply><apply id="S3.SS2.p3.4.m4.7.7.1.2.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1"><max id="S3.SS2.p3.4.m4.6.6.cmml" xref="S3.SS2.p3.4.m4.6.6"></max><apply id="S3.SS2.p3.4.m4.7.7.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1"><ci id="S3.SS2.p3.4.m4.7.7.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.2">:</ci><apply id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3"><in id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.1"></in><ci id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.2">𝑘</ci><set id="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.3.3.2"><cn id="S3.SS2.p3.4.m4.1.1.cmml" type="integer" xref="S3.SS2.p3.4.m4.1.1">1</cn><cn id="S3.SS2.p3.4.m4.2.2.cmml" type="integer" xref="S3.SS2.p3.4.m4.2.2">2</cn><ci id="S3.SS2.p3.4.m4.3.3.cmml" xref="S3.SS2.p3.4.m4.3.3">…</ci><ci id="S3.SS2.p3.4.m4.4.4.cmml" xref="S3.SS2.p3.4.m4.4.4">𝐾</ci></set></apply><apply id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1"><gt id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.2"></gt><apply id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1"><times id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.2"></times><ci id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.3">𝑆</ci><apply id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1"><times id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.1.1.1.1.2">𝑓</ci><ci id="S3.SS2.p3.4.m4.5.5.cmml" xref="S3.SS2.p3.4.m4.5.5">𝑘</ci></apply></apply><ci id="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.7.7.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.7c">k_{\text{optimal}}=\max\left\{k\in\{1,2,\ldots,K\}:S(f(k))&gt;T\right\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.7d">italic_k start_POSTSUBSCRIPT optimal end_POSTSUBSCRIPT = roman_max { italic_k ∈ { 1 , 2 , … , italic_K } : italic_S ( italic_f ( italic_k ) ) &gt; italic_T }</annotation></semantics></math>, where <math alttext="S(f(k))" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.2"><semantics id="S3.SS2.p3.5.m5.2a"><mrow id="S3.SS2.p3.5.m5.2.2" xref="S3.SS2.p3.5.m5.2.2.cmml"><mi id="S3.SS2.p3.5.m5.2.2.3" xref="S3.SS2.p3.5.m5.2.2.3.cmml">S</mi><mo id="S3.SS2.p3.5.m5.2.2.2" xref="S3.SS2.p3.5.m5.2.2.2.cmml">⁢</mo><mrow id="S3.SS2.p3.5.m5.2.2.1.1" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml"><mo id="S3.SS2.p3.5.m5.2.2.1.1.2" stretchy="false" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.5.m5.2.2.1.1.1" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml"><mi id="S3.SS2.p3.5.m5.2.2.1.1.1.2" xref="S3.SS2.p3.5.m5.2.2.1.1.1.2.cmml">f</mi><mo id="S3.SS2.p3.5.m5.2.2.1.1.1.1" xref="S3.SS2.p3.5.m5.2.2.1.1.1.1.cmml">⁢</mo><mrow id="S3.SS2.p3.5.m5.2.2.1.1.1.3.2" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml"><mo id="S3.SS2.p3.5.m5.2.2.1.1.1.3.2.1" stretchy="false" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml">(</mo><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">k</mi><mo id="S3.SS2.p3.5.m5.2.2.1.1.1.3.2.2" stretchy="false" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.5.m5.2.2.1.1.3" stretchy="false" xref="S3.SS2.p3.5.m5.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.2b"><apply id="S3.SS2.p3.5.m5.2.2.cmml" xref="S3.SS2.p3.5.m5.2.2"><times id="S3.SS2.p3.5.m5.2.2.2.cmml" xref="S3.SS2.p3.5.m5.2.2.2"></times><ci id="S3.SS2.p3.5.m5.2.2.3.cmml" xref="S3.SS2.p3.5.m5.2.2.3">𝑆</ci><apply id="S3.SS2.p3.5.m5.2.2.1.1.1.cmml" xref="S3.SS2.p3.5.m5.2.2.1.1"><times id="S3.SS2.p3.5.m5.2.2.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.2.2.1.1.1.1"></times><ci id="S3.SS2.p3.5.m5.2.2.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.2.2.1.1.1.2">𝑓</ci><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.2c">S(f(k))</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.2d">italic_S ( italic_f ( italic_k ) )</annotation></semantics></math> denotes the silhouette score of the <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_k</annotation></semantics></math>-th configuration and <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_T</annotation></semantics></math> the threshold. Importantly, even after identifying an initial “optimal” <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m8.1"><semantics id="S3.SS2.p3.8.m8.1a"><mi id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><ci id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m8.1d">italic_k</annotation></semantics></math>, higher <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m9.1"><semantics id="S3.SS2.p3.9.m9.1a"><mi id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><ci id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m9.1d">italic_k</annotation></semantics></math> values are visited regardless to ensure no better configuration is overlooked.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.6">The factorization of <math alttext="\mathbf{X}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathbf{X}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">bold_X</annotation></semantics></math> yields two non-negative factor matrices <math alttext="\mathbf{W}\in\mathbb{R}^{m\times k}_{+}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">𝐖</mi><mo id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.cmml">∈</mo><msubsup id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2.2" xref="S3.SS2.p4.2.m2.1.1.3.2.2.cmml">ℝ</mi><mo id="S3.SS2.p4.2.m2.1.1.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.cmml">+</mo><mrow id="S3.SS2.p4.2.m2.1.1.3.2.3" xref="S3.SS2.p4.2.m2.1.1.3.2.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2.3.2" xref="S3.SS2.p4.2.m2.1.1.3.2.3.2.cmml">m</mi><mo id="S3.SS2.p4.2.m2.1.1.3.2.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p4.2.m2.1.1.3.2.3.1.cmml">×</mo><mi id="S3.SS2.p4.2.m2.1.1.3.2.3.3" xref="S3.SS2.p4.2.m2.1.1.3.2.3.3.cmml">k</mi></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><in id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1"></in><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝐖</ci><apply id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3">subscript</csymbol><apply id="S3.SS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.3.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.3.2.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2.2">ℝ</ci><apply id="S3.SS2.p4.2.m2.1.1.3.2.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2.3"><times id="S3.SS2.p4.2.m2.1.1.3.2.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2.3.1"></times><ci id="S3.SS2.p4.2.m2.1.1.3.2.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2.3.2">𝑚</ci><ci id="S3.SS2.p4.2.m2.1.1.3.2.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2.3.3">𝑘</ci></apply></apply><plus id="S3.SS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3"></plus></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">\mathbf{W}\in\mathbb{R}^{m\times k}_{+}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">bold_W ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{H}\in\mathbb{R}^{k\times n}_{+}" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mrow id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">𝐇</mi><mo id="S3.SS2.p4.3.m3.1.1.1" xref="S3.SS2.p4.3.m3.1.1.1.cmml">∈</mo><msubsup id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml"><mi id="S3.SS2.p4.3.m3.1.1.3.2.2" xref="S3.SS2.p4.3.m3.1.1.3.2.2.cmml">ℝ</mi><mo id="S3.SS2.p4.3.m3.1.1.3.3" xref="S3.SS2.p4.3.m3.1.1.3.3.cmml">+</mo><mrow id="S3.SS2.p4.3.m3.1.1.3.2.3" xref="S3.SS2.p4.3.m3.1.1.3.2.3.cmml"><mi id="S3.SS2.p4.3.m3.1.1.3.2.3.2" xref="S3.SS2.p4.3.m3.1.1.3.2.3.2.cmml">k</mi><mo id="S3.SS2.p4.3.m3.1.1.3.2.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p4.3.m3.1.1.3.2.3.1.cmml">×</mo><mi id="S3.SS2.p4.3.m3.1.1.3.2.3.3" xref="S3.SS2.p4.3.m3.1.1.3.2.3.3.cmml">n</mi></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><in id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1.1"></in><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">𝐇</ci><apply id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.3.1.cmml" xref="S3.SS2.p4.3.m3.1.1.3">subscript</csymbol><apply id="S3.SS2.p4.3.m3.1.1.3.2.cmml" xref="S3.SS2.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.3.2.1.cmml" xref="S3.SS2.p4.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.3.2.2.cmml" xref="S3.SS2.p4.3.m3.1.1.3.2.2">ℝ</ci><apply id="S3.SS2.p4.3.m3.1.1.3.2.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3.2.3"><times id="S3.SS2.p4.3.m3.1.1.3.2.3.1.cmml" xref="S3.SS2.p4.3.m3.1.1.3.2.3.1"></times><ci id="S3.SS2.p4.3.m3.1.1.3.2.3.2.cmml" xref="S3.SS2.p4.3.m3.1.1.3.2.3.2">𝑘</ci><ci id="S3.SS2.p4.3.m3.1.1.3.2.3.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3.2.3.3">𝑛</ci></apply></apply><plus id="S3.SS2.p4.3.m3.1.1.3.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3.3"></plus></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">\mathbf{H}\in\mathbb{R}^{k\times n}_{+}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">bold_H ∈ blackboard_R start_POSTSUPERSCRIPT italic_k × italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT</annotation></semantics></math>, ensuring <math alttext="X_{ij}\approx\sum_{s}W_{is}H_{sj}" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><mrow id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><msub id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2.2" xref="S3.SS2.p4.4.m4.1.1.2.2.cmml">X</mi><mrow id="S3.SS2.p4.4.m4.1.1.2.3" xref="S3.SS2.p4.4.m4.1.1.2.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2.3.2" xref="S3.SS2.p4.4.m4.1.1.2.3.2.cmml">i</mi><mo id="S3.SS2.p4.4.m4.1.1.2.3.1" xref="S3.SS2.p4.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.4.m4.1.1.2.3.3" xref="S3.SS2.p4.4.m4.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.SS2.p4.4.m4.1.1.1" rspace="0.111em" xref="S3.SS2.p4.4.m4.1.1.1.cmml">≈</mo><mrow id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml"><msub id="S3.SS2.p4.4.m4.1.1.3.1" xref="S3.SS2.p4.4.m4.1.1.3.1.cmml"><mo id="S3.SS2.p4.4.m4.1.1.3.1.2" xref="S3.SS2.p4.4.m4.1.1.3.1.2.cmml">∑</mo><mi id="S3.SS2.p4.4.m4.1.1.3.1.3" xref="S3.SS2.p4.4.m4.1.1.3.1.3.cmml">s</mi></msub><mrow id="S3.SS2.p4.4.m4.1.1.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.cmml"><msub id="S3.SS2.p4.4.m4.1.1.3.2.2" xref="S3.SS2.p4.4.m4.1.1.3.2.2.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.2.2.2" xref="S3.SS2.p4.4.m4.1.1.3.2.2.2.cmml">W</mi><mrow id="S3.SS2.p4.4.m4.1.1.3.2.2.3" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.2.2.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.2.cmml">i</mi><mo id="S3.SS2.p4.4.m4.1.1.3.2.2.3.1" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.4.m4.1.1.3.2.2.3.3" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.3.cmml">s</mi></mrow></msub><mo id="S3.SS2.p4.4.m4.1.1.3.2.1" xref="S3.SS2.p4.4.m4.1.1.3.2.1.cmml">⁢</mo><msub id="S3.SS2.p4.4.m4.1.1.3.2.3" xref="S3.SS2.p4.4.m4.1.1.3.2.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.2.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.3.2.cmml">H</mi><mrow id="S3.SS2.p4.4.m4.1.1.3.2.3.3" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.cmml"><mi id="S3.SS2.p4.4.m4.1.1.3.2.3.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.2.cmml">s</mi><mo id="S3.SS2.p4.4.m4.1.1.3.2.3.3.1" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.4.m4.1.1.3.2.3.3.3" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.3.cmml">j</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><approx id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1"></approx><apply id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2">𝑋</ci><apply id="S3.SS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3"><times id="S3.SS2.p4.4.m4.1.1.2.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3.1"></times><ci id="S3.SS2.p4.4.m4.1.1.2.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3.2">𝑖</ci><ci id="S3.SS2.p4.4.m4.1.1.2.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3"><apply id="S3.SS2.p4.4.m4.1.1.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.1"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.3.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.1">subscript</csymbol><sum id="S3.SS2.p4.4.m4.1.1.3.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.1.2"></sum><ci id="S3.SS2.p4.4.m4.1.1.3.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.1.3">𝑠</ci></apply><apply id="S3.SS2.p4.4.m4.1.1.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2"><times id="S3.SS2.p4.4.m4.1.1.3.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.1"></times><apply id="S3.SS2.p4.4.m4.1.1.3.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.3.2.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.3.2.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2.2">𝑊</ci><apply id="S3.SS2.p4.4.m4.1.1.3.2.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3"><times id="S3.SS2.p4.4.m4.1.1.3.2.2.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.1"></times><ci id="S3.SS2.p4.4.m4.1.1.3.2.2.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.2">𝑖</ci><ci id="S3.SS2.p4.4.m4.1.1.3.2.2.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.2.3.3">𝑠</ci></apply></apply><apply id="S3.SS2.p4.4.m4.1.1.3.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.3.2.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.3.2.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3.2">𝐻</ci><apply id="S3.SS2.p4.4.m4.1.1.3.2.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3"><times id="S3.SS2.p4.4.m4.1.1.3.2.3.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.1"></times><ci id="S3.SS2.p4.4.m4.1.1.3.2.3.3.2.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.2">𝑠</ci><ci id="S3.SS2.p4.4.m4.1.1.3.2.3.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.2.3.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">X_{ij}\approx\sum_{s}W_{is}H_{sj}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">italic_X start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ≈ ∑ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_i italic_s end_POSTSUBSCRIPT italic_H start_POSTSUBSCRIPT italic_s italic_j end_POSTSUBSCRIPT</annotation></semantics></math>. Distribution of words over topics are captured in <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m5.1"><semantics id="S3.SS2.p4.5.m5.1a"><mi id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><ci id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">\mathbf{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m5.1d">bold_W</annotation></semantics></math>. The matrix <math alttext="\mathbf{H}" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m6.1"><semantics id="S3.SS2.p4.6.m6.1a"><mi id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><ci id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">\mathbf{H}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m6.1d">bold_H</annotation></semantics></math> shows the topic distribution across documents, and is used to identify the predominant topic for each document in post-processing.
Full tensor and matrix factorization implementations of various algorithms are available in <span class="ltx_text ltx_font_bold" id="S3.SS2.p4.6.1">T-ELF</span> <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Several tensor and matrix factorization algorithms: 
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lanl/T-ELF/tree/main/TELF/factorization" title="">https://github.com/lanl/T-ELF/tree/main/TELF/factorization</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Knowledge Graph Ontology</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Features from <span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">T-ELF</span> and document metadata is mapped into series of head, entity, and tail relations, forming directional triplets, then injected into a Neo4j <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib48" title="">48</a>]</cite> KG.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">Our KG incorporates document metadata as well as the latent features. The primary source of information in the KG comes from documents, which are injected into the graph along with related attributes. Each document node contains information such as DOI, title, abstract, and source API document identifiers. Additional node labels include authors, publication year, Scopus category, affiliations, affiliation country, acronyms, publisher, topics, topic keywords, citations, references, and a subset of NER entities produced from spaCy’s NER labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib49" title="">49</a>]</cite>. These NER labels cover events, persons, locations, products, organizations, and geopolitical entities.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">The KG nodes represent documents and their associated metadata, while the edges capture the relationships between these entities, such as citations, co-authorships, and topic associations, enabling logical query and retrieval capabilities for the RAG.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.5.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.6.2">Vector Store Assembly</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">To augment the RAG, we introduced a vector database for the original documents using Milvus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib50" title="">50</a>]</cite>. Additionally, a subset of documents’ full texts were vectorized and incorporated into the vector store. Full texts, when available, are segmented into smaller paragraphs, each assigned an integer ID to indicate its position within the original document. These paragraphs are then vectorized through the into embeddings using OpenAI’s text-embedding-ada-002 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib51" title="">51</a>]</cite> model and imported to the vector store to support the RAG process.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The RAG application can query the vector store to find relevant paragraph chunks from these full texts.</p>
</div>
<figure class="ltx_figure ltx_align_floatleft" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="212" id="S3.F2.g1" src="x2.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> The RAG pipeline. Images generated with DALL·E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib52" title="">52</a>]</cite>. </figcaption>
</figure>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">If the retrieved text contains the needed information, the LLM can answer the posed question and include a citation of the document, precisely indicating the exact paragraph. If further related information is needed, the application can use document metadata (e.g., DOI, author) to expand its search through the KG. This approach allows us to preserve the semantics of the original documents and provide relevant responses.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS5.5.1.1">III-E</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS5.6.2">Retrieval Augmented Generation</span>
</h3>
<figure class="ltx_figure ltx_align_floatright" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="593" id="S3.F3.g1" src="x3.png" width="432"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span> User query routing overview.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">RAG is an NLP method that mixes retrieval and generation techniques to improve the accuracy and relevance of responses in generative AI. It works by first gathering information from an external knowledge base based on a user’s query. This retrieved information is then used to guide and enhance the outputs of the generative model, leading to more relevant and context-aware responses.
By integrating these tactics, RAG addresses the limitations of purely generative models and provides an adaptable framework suitable for applications demanding detailed and current information.</p>
</div>
<div class="ltx_para" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.F2" title="Figure 2 ‣ III-D Vector Store Assembly ‣ III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates the data pipeline operated throughout the work for RAG. The process begins with a user query, which the LLM then uses to query the knowledge graph. The LLM transforms the query into a vector embedding. This embedding is compared to existing texts to find the most similar text. The retrieved information is appended to the original query, and the LLM produces a relevant answer using this context. Finally, the LLM constructs a final answer in natural language to explain the answer to the user’s question.</p>
</div>
<div class="ltx_para" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.1">To optimally leverage RAG, accurately understanding the user’s question is crucial.
Our RAG approach includes multiple potential routes depending on a user’s question. The question routing pipeline may be a <span class="ltx_text ltx_font_bold" id="S3.SS5.p3.1.1">General Query</span>, which calls the <span class="ltx_text ltx_font_italic" id="S3.SS5.p3.1.2">ReAct Agent Process<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S3.SS5.p3.1.2.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib23" title="">23</a><span class="ltx_text ltx_font_upright" id="S3.SS5.p3.1.2.2.2">]</span></cite></span>, or a <span class="ltx_text ltx_font_bold" id="S3.SS5.p3.1.3">Specific Document Query</span>, which calls either a <span class="ltx_text ltx_font_italic" id="S3.SS5.p3.1.4">Retrieved Query</span> or a <span class="ltx_text ltx_font_italic" id="S3.SS5.p3.1.5">Synthesized Query</span>. Understanding the question directs the information to the appropriate toolset and subsequent process. The routing process overview, as described below, can be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.F3" title="Figure 3 ‣ III-E Retrieval Augmented Generation ‣ III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS5.p4">
<p class="ltx_p" id="S3.SS5.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS5.p4.1.1">Specific Document Query:</span> If a user’s question requires information from a specific document’s text (title + abstract), it is better suited for a traditional RAG application in which the LLM interacts with the VS to find the needed text. In our case, we use a ReAct agent where the VS search is the sole tool, allowing the LLM to make multiple search requests as required. Specifically, a ReAct agent means the LLM has distinct steps for reasoning and acting after determining the input meaning. We use langgraph <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib53" title="">53</a>]</cite> to define an execution graph with three nodes, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S3.F4" title="Figure 4 ‣ III-E Retrieval Augmented Generation ‣ III Methods ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">4</span></a>: (1) the ReAct agent, (2) the tool executor, and (3) the end.</p>
</div>
<div class="ltx_para" id="S3.SS5.p5">
<p class="ltx_p" id="S3.SS5.p5.1"><span class="ltx_text ltx_font_italic" id="S3.SS5.p5.1.1">ReAct Agent Process:</span> The agent node is the central part of the ReAct graph, where the LLM calls are encapsulated. The ReAct agent is responsible for collecting inputs, making actionable decisions, and explaining the results. The four prompt parts are:</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="207" id="S3.F4.g1" src="x4.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span> Nodes and tools of the ReAct agent. Images from DALL·E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib52" title="">52</a>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS5.p6">
<ol class="ltx_enumerate" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">a.</span>
<div class="ltx_para" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.1"><span class="ltx_text" id="S3.I4.i1.p1.1.1" style="font-size:80%;">Instructions</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">b.</span>
<div class="ltx_para" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1"><span class="ltx_text" id="S3.I4.i2.p1.1.1" style="font-size:80%;">User query</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">c.</span>
<div class="ltx_para" id="S3.I4.i3.p1">
<p class="ltx_p" id="S3.I4.i3.p1.1"><span class="ltx_text" id="S3.I4.i3.p1.1.1" style="font-size:80%;">Tool names, data</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">d.</span>
<div class="ltx_para" id="S3.I4.i4.p1">
<p class="ltx_p" id="S3.I4.i4.p1.1"><span class="ltx_text" id="S3.I4.i4.p1.1.1" style="font-size:80%;">Tool Scratchpad</span></p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS5.p7">
<p class="ltx_p" id="S3.SS5.p7.1">The agent is informed how to answer a user’s query from the instructions, including answer formulations and tool usage. The query aids tool selection or answer directly. The tools have specific descriptions and parameters required for their calls, including schemas if interacting with databases. The scratchpad serves as temporary storage for tool calls, responses, and the LLM’s reasoning, allowing the agent to iteratively solve complex problems.</p>
</div>
<div class="ltx_para" id="S3.SS5.p8">
<p class="ltx_p" id="S3.SS5.p8.1">The tool executor takes the tool name and input parameters from the agent node, routes to the corresponding function, and returns the output. It handles execution logistics, error handling, logging, and status updates.</p>
</div>
<div class="ltx_para" id="S3.SS5.p9">
<p class="ltx_p" id="S3.SS5.p9.1">The end node signals that the Reason-Act loop has completed. The final output from the LLM after the retrieval augmented generation is returned to the user.</p>
</div>
<div class="ltx_para" id="S3.SS5.p10">
<p class="ltx_p" id="S3.SS5.p10.1"><span class="ltx_text ltx_font_bold" id="S3.SS5.p10.1.1">General Query:</span> If the user asks a broader question, such as those about trends, the required information is found within the KG. In this route, we start with a preprocessing step in which the LLM performs NER to decouple specific data from the genericized question. After this, we send the genericized query to a smaller vector store containing pairs of cypher queries and descriptions of the information they return, with embedding vectors generated from the descriptions. From here, there are two possible subroutes.</p>
</div>
<div class="ltx_para" id="S3.SS5.p11">
<p class="ltx_p" id="S3.SS5.p11.1"><span class="ltx_text ltx_font_italic" id="S3.SS5.p11.1.1">Retrieved Query:</span> If a retrieved query is able to answer the question, we execute it’s cypher before making a final LLM call to return the result. If no existing queries are able to answer, we synthesize a new cypher query.</p>
</div>
<div class="ltx_para" id="S3.SS5.p12">
<p class="ltx_p" id="S3.SS5.p12.1"><span class="ltx_text ltx_font_italic" id="S3.SS5.p12.1.1">Synthesized Query:</span> If the LLM opts for “synthesis,” it generates a new cypher query using the graph’s schema and retrieved examples. For reliability, the LLM audits this generated query. First, we retrieve the query’s execution plan and profile by using the cypher keyword “PROFILE,” which lists the operators used on the knowledge graph. We also provide descriptions of the relevant low-level operators from Neo4j’s official documentation. Once we obtain the detailed execution plan, the LLM performs two steps: it translates the plan into plain language and assesses if it addresses the user’s question. Valid generations proceed as if retrieved queries.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Results</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we discuss identification of optimal clusters for tensor decomposition, vectorization of the dataset, construction of KG, and compare the system using the with GPT-4-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib51" title="">51</a>]</cite> as the operating model of <span class="ltx_text ltx_font_bold" id="S4.p1.1.1">SMART-SLIC</span> to answer research questions. The same model was used to answer without RAG as well. Our findings highlight the accuracy and reliability of the <span class="ltx_text ltx_font_bold" id="S4.p1.1.2">SMART-SLIC</span>’s RAG.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Labels for Topic Clusters</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.1.1">
<span class="ltx_p" id="S4.T1.1.1.1.1.1.1" style="width:8.7pt;">#</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.2.1">
<span class="ltx_p" id="S4.T1.1.1.1.2.1.1" style="width:242.8pt;">Label</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.3.1">
<span class="ltx_p" id="S4.T1.1.1.1.3.1.1" style="width:43.4pt;"># Docs.</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.1.1.4.1">
<span class="ltx_p" id="S4.T1.1.1.1.4.1.1" style="width:34.7pt;">Percent</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.2.1.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.1.1">
<span class="ltx_p" id="S4.T1.1.2.1.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.2.1.1.1.1.1" style="background-color:#E6FFE6;">0</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T1.1.2.1.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.2.1">
<span class="ltx_p" id="S4.T1.1.2.1.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.2.1.2.1.1.1" style="background-color:#E6FFE6;">Malware Behavioral Analysis</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T1.1.2.1.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.3.1">
<span class="ltx_p" id="S4.T1.1.2.1.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.2.1.3.1.1.1" style="background-color:#E6FFE6;">158</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T1.1.2.1.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.4.1">
<span class="ltx_p" id="S4.T1.1.2.1.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.2.1.4.1.1.1" style="background-color:#E6FFE6;">1.80</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.1.1">
<span class="ltx_p" id="S4.T1.1.3.2.1.1.1" style="width:8.7pt;">1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.2.1">
<span class="ltx_p" id="S4.T1.1.3.2.2.1.1" style="width:242.8pt;">Cybersecurity Challenges</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.3.1">
<span class="ltx_p" id="S4.T1.1.3.2.3.1.1" style="width:43.4pt;">305</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.2.4.1">
<span class="ltx_p" id="S4.T1.1.3.2.4.1.1" style="width:34.7pt;">3.47</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.4.3.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.1.1">
<span class="ltx_p" id="S4.T1.1.4.3.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.4.3.1.1.1.1" style="background-color:#E6FFE6;">2</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.4.3.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.2.1">
<span class="ltx_p" id="S4.T1.1.4.3.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.4.3.2.1.1.1" style="background-color:#E6FFE6;">Cybersecurity Research</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.4.3.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.3.1">
<span class="ltx_p" id="S4.T1.1.4.3.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.4.3.3.1.1.1" style="background-color:#E6FFE6;">114</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.4.3.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.3.4.1">
<span class="ltx_p" id="S4.T1.1.4.3.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.4.3.4.1.1.1" style="background-color:#E6FFE6;">1.30</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.1.1">
<span class="ltx_p" id="S4.T1.1.5.4.1.1.1" style="width:8.7pt;">3</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.2.1">
<span class="ltx_p" id="S4.T1.1.5.4.2.1.1" style="width:242.8pt;">Botnet Detection Techniques</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.3.1">
<span class="ltx_p" id="S4.T1.1.5.4.3.1.1" style="width:43.4pt;">142</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.5.4.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.4.4.1">
<span class="ltx_p" id="S4.T1.1.5.4.4.1.1" style="width:34.7pt;">1.62</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.6.5.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.6.5.1.1">
<span class="ltx_p" id="S4.T1.1.6.5.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.6.5.1.1.1.1" style="background-color:#E6FFE6;">4</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.6.5.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.6.5.2.1">
<span class="ltx_p" id="S4.T1.1.6.5.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.6.5.2.1.1.1" style="background-color:#E6FFE6;">Malware Feature Selection And Extraction</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.6.5.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.6.5.3.1">
<span class="ltx_p" id="S4.T1.1.6.5.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.6.5.3.1.1.1" style="background-color:#E6FFE6;">353</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.6.5.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.6.5.4.1">
<span class="ltx_p" id="S4.T1.1.6.5.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.6.5.4.1.1.1" style="background-color:#E6FFE6;">4.02</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.7.6.1.1">
<span class="ltx_p" id="S4.T1.1.7.6.1.1.1" style="width:8.7pt;">5</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.7.6.2.1">
<span class="ltx_p" id="S4.T1.1.7.6.2.1.1" style="width:242.8pt;">Network Intrusion Detection</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.7.6.3.1">
<span class="ltx_p" id="S4.T1.1.7.6.3.1.1" style="width:43.4pt;">134</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.7.6.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.7.6.4.1">
<span class="ltx_p" id="S4.T1.1.7.6.4.1.1" style="width:34.7pt;">1.52</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.8.7.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.8.7.1.1">
<span class="ltx_p" id="S4.T1.1.8.7.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.8.7.1.1.1.1" style="background-color:#E6FFE6;">6</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.8.7.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.8.7.2.1">
<span class="ltx_p" id="S4.T1.1.8.7.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.8.7.2.1.1.1" style="background-color:#E6FFE6;">Evaluation of Malware Classifiers</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.8.7.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.8.7.3.1">
<span class="ltx_p" id="S4.T1.1.8.7.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.8.7.3.1.1.1" style="background-color:#E6FFE6;">301</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.8.7.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.8.7.4.1">
<span class="ltx_p" id="S4.T1.1.8.7.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.8.7.4.1.1.1" style="background-color:#E6FFE6;">3.42</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.9.8.1.1">
<span class="ltx_p" id="S4.T1.1.9.8.1.1.1" style="width:8.7pt;">7</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.9.8.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.9.8.2.1">
<span class="ltx_p" id="S4.T1.1.9.8.2.1.1" style="width:242.8pt;">Malicious Code Analysis</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.9.8.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.9.8.3.1">
<span class="ltx_p" id="S4.T1.1.9.8.3.1.1" style="width:43.4pt;">827</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.9.8.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.9.8.4.1">
<span class="ltx_p" id="S4.T1.1.9.8.4.1.1" style="width:34.7pt;">9.41</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10.9">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.10.9.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.10.9.1.1">
<span class="ltx_p" id="S4.T1.1.10.9.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.10.9.1.1.1.1" style="background-color:#E6FFE6;">8</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.10.9.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.10.9.2.1">
<span class="ltx_p" id="S4.T1.1.10.9.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.10.9.2.1.1.1" style="background-color:#E6FFE6;">Artificial Intelligence for Malware</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.10.9.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.10.9.3.1">
<span class="ltx_p" id="S4.T1.1.10.9.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.10.9.3.1.1.1" style="background-color:#E6FFE6;">888</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.10.9.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.10.9.4.1">
<span class="ltx_p" id="S4.T1.1.10.9.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.10.9.4.1.1.1" style="background-color:#E6FFE6;">10.10</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11.10">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.11.10.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.11.10.1.1">
<span class="ltx_p" id="S4.T1.1.11.10.1.1.1" style="width:8.7pt;">9</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.11.10.2.1">
<span class="ltx_p" id="S4.T1.1.11.10.2.1.1" style="width:242.8pt;">Nonnegative Matrix Decomposition</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.11.10.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.11.10.3.1">
<span class="ltx_p" id="S4.T1.1.11.10.3.1.1" style="width:43.4pt;">520</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.11.10.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.11.10.4.1">
<span class="ltx_p" id="S4.T1.1.11.10.4.1.1" style="width:34.7pt;">5.92</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12.11">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.12.11.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.12.11.1.1">
<span class="ltx_p" id="S4.T1.1.12.11.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.12.11.1.1.1.1" style="background-color:#E6FFE6;">10</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.12.11.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.12.11.2.1">
<span class="ltx_p" id="S4.T1.1.12.11.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.12.11.2.1.1.1" style="background-color:#E6FFE6;">Security Threat Mitigation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.12.11.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.12.11.3.1">
<span class="ltx_p" id="S4.T1.1.12.11.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.12.11.3.1.1.1" style="background-color:#E6FFE6;">180</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.12.11.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.12.11.4.1">
<span class="ltx_p" id="S4.T1.1.12.11.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.12.11.4.1.1.1" style="background-color:#E6FFE6;">2.05</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.13.12">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.13.12.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.13.12.1.1">
<span class="ltx_p" id="S4.T1.1.13.12.1.1.1" style="width:8.7pt;">11</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.13.12.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.13.12.2.1">
<span class="ltx_p" id="S4.T1.1.13.12.2.1.1" style="width:242.8pt;">Deep Learning for Malware</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.13.12.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.13.12.3.1">
<span class="ltx_p" id="S4.T1.1.13.12.3.1.1" style="width:43.4pt;">113</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.13.12.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.13.12.4.1">
<span class="ltx_p" id="S4.T1.1.13.12.4.1.1" style="width:34.7pt;">1.29</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.14.13.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.14.13.1.1">
<span class="ltx_p" id="S4.T1.1.14.13.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.14.13.1.1.1.1" style="background-color:#E6FFE6;">12</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.14.13.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.14.13.2.1">
<span class="ltx_p" id="S4.T1.1.14.13.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.14.13.2.1.1.1" style="background-color:#E6FFE6;">Machine Learning Techniques</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.14.13.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.14.13.3.1">
<span class="ltx_p" id="S4.T1.1.14.13.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.14.13.3.1.1.1" style="background-color:#E6FFE6;">275</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.14.13.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.14.13.4.1">
<span class="ltx_p" id="S4.T1.1.14.13.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.14.13.4.1.1.1" style="background-color:#E6FFE6;">3.13</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.15.14">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.15.14.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.15.14.1.1">
<span class="ltx_p" id="S4.T1.1.15.14.1.1.1" style="width:8.7pt;">13</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.15.14.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.15.14.2.1">
<span class="ltx_p" id="S4.T1.1.15.14.2.1.1" style="width:242.8pt;">Education Technology</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.15.14.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.15.14.3.1">
<span class="ltx_p" id="S4.T1.1.15.14.3.1.1" style="width:43.4pt;">447</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.15.14.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.15.14.4.1">
<span class="ltx_p" id="S4.T1.1.15.14.4.1.1" style="width:34.7pt;">5.09</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.16.15">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.16.15.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.16.15.1.1">
<span class="ltx_p" id="S4.T1.1.16.15.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.16.15.1.1.1.1" style="background-color:#E6FFE6;">14</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.16.15.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.16.15.2.1">
<span class="ltx_p" id="S4.T1.1.16.15.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.16.15.2.1.1.1" style="background-color:#E6FFE6;">Unsupervised Anomaly Detection</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.16.15.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.16.15.3.1">
<span class="ltx_p" id="S4.T1.1.16.15.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.16.15.3.1.1.1" style="background-color:#E6FFE6;">372</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.16.15.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.16.15.4.1">
<span class="ltx_p" id="S4.T1.1.16.15.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.16.15.4.1.1.1" style="background-color:#E6FFE6;">4.23</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.17.16">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.17.16.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.17.16.1.1">
<span class="ltx_p" id="S4.T1.1.17.16.1.1.1" style="width:8.7pt;">15</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.17.16.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.17.16.2.1">
<span class="ltx_p" id="S4.T1.1.17.16.2.1.1" style="width:242.8pt;">Ransomware Prevention</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.17.16.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.17.16.3.1">
<span class="ltx_p" id="S4.T1.1.17.16.3.1.1" style="width:43.4pt;">147</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.17.16.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.17.16.4.1">
<span class="ltx_p" id="S4.T1.1.17.16.4.1.1" style="width:34.7pt;">1.67</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.18.17">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.18.17.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.18.17.1.1">
<span class="ltx_p" id="S4.T1.1.18.17.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.18.17.1.1.1.1" style="background-color:#E6FFE6;">16</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.18.17.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.18.17.2.1">
<span class="ltx_p" id="S4.T1.1.18.17.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.18.17.2.1.1.1" style="background-color:#E6FFE6;">Temporal Graph Forecast</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.18.17.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.18.17.3.1">
<span class="ltx_p" id="S4.T1.1.18.17.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.18.17.3.1.1.1" style="background-color:#E6FFE6;">307</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.18.17.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.18.17.4.1">
<span class="ltx_p" id="S4.T1.1.18.17.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.18.17.4.1.1.1" style="background-color:#E6FFE6;">3.49</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.19.18">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.19.18.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.19.18.1.1">
<span class="ltx_p" id="S4.T1.1.19.18.1.1.1" style="width:8.7pt;">17</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.19.18.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.19.18.2.1">
<span class="ltx_p" id="S4.T1.1.19.18.2.1.1" style="width:242.8pt;">Mobile Malware Detection</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.19.18.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.19.18.3.1">
<span class="ltx_p" id="S4.T1.1.19.18.3.1.1" style="width:43.4pt;">230</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.19.18.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.19.18.4.1">
<span class="ltx_p" id="S4.T1.1.19.18.4.1.1" style="width:34.7pt;">2.62</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.20.19">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.20.19.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.20.19.1.1">
<span class="ltx_p" id="S4.T1.1.20.19.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.20.19.1.1.1.1" style="background-color:#E6FFE6;">18</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.20.19.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.20.19.2.1">
<span class="ltx_p" id="S4.T1.1.20.19.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.20.19.2.1.1.1" style="background-color:#E6FFE6;">Adversarial Defense Strategy</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.20.19.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.20.19.3.1">
<span class="ltx_p" id="S4.T1.1.20.19.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.20.19.3.1.1.1" style="background-color:#E6FFE6;">358</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.20.19.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.20.19.4.1">
<span class="ltx_p" id="S4.T1.1.20.19.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.20.19.4.1.1.1" style="background-color:#E6FFE6;">4.07</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.21.20">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.21.20.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.21.20.1.1">
<span class="ltx_p" id="S4.T1.1.21.20.1.1.1" style="width:8.7pt;">19</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.21.20.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.21.20.2.1">
<span class="ltx_p" id="S4.T1.1.21.20.2.1.1" style="width:242.8pt;">IoT Security</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.21.20.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.21.20.3.1">
<span class="ltx_p" id="S4.T1.1.21.20.3.1.1" style="width:43.4pt;">238</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.21.20.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.21.20.4.1">
<span class="ltx_p" id="S4.T1.1.21.20.4.1.1" style="width:34.7pt;">2.71</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.22.21">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.22.21.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.22.21.1.1">
<span class="ltx_p" id="S4.T1.1.22.21.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.22.21.1.1.1.1" style="background-color:#E6FFE6;">20</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.22.21.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.22.21.2.1">
<span class="ltx_p" id="S4.T1.1.22.21.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.22.21.2.1.1.1" style="background-color:#E6FFE6;">Privacy Protection Challenge</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.22.21.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.22.21.3.1">
<span class="ltx_p" id="S4.T1.1.22.21.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.22.21.3.1.1.1" style="background-color:#E6FFE6;">628</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.22.21.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.22.21.4.1">
<span class="ltx_p" id="S4.T1.1.22.21.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.22.21.4.1.1.1" style="background-color:#E6FFE6;">7.14</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.23.22">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.23.22.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.23.22.1.1">
<span class="ltx_p" id="S4.T1.1.23.22.1.1.1" style="width:8.7pt;">21</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.23.22.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.23.22.2.1">
<span class="ltx_p" id="S4.T1.1.23.22.2.1.1" style="width:242.8pt;">Sparse Tensor Decomposition</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.23.22.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.23.22.3.1">
<span class="ltx_p" id="S4.T1.1.23.22.3.1.1" style="width:43.4pt;">212</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.23.22.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.23.22.4.1">
<span class="ltx_p" id="S4.T1.1.23.22.4.1.1" style="width:34.7pt;">2.41</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.24.23">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.24.23.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.24.23.1.1">
<span class="ltx_p" id="S4.T1.1.24.23.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.24.23.1.1.1.1" style="background-color:#E6FFE6;">22</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.24.23.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.24.23.2.1">
<span class="ltx_p" id="S4.T1.1.24.23.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.24.23.2.1.1.1" style="background-color:#E6FFE6;">Backdoor Detection</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.24.23.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.24.23.3.1">
<span class="ltx_p" id="S4.T1.1.24.23.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.24.23.3.1.1.1" style="background-color:#E6FFE6;">350</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.24.23.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.24.23.4.1">
<span class="ltx_p" id="S4.T1.1.24.23.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.24.23.4.1.1.1" style="background-color:#E6FFE6;">3.98</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.25.24">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S4.T1.1.25.24.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.25.24.1.1">
<span class="ltx_p" id="S4.T1.1.25.24.1.1.1" style="width:8.7pt;">23</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.25.24.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.25.24.2.1">
<span class="ltx_p" id="S4.T1.1.25.24.2.1.1" style="width:242.8pt;">Neural Network Architecture</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.25.24.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.25.24.3.1">
<span class="ltx_p" id="S4.T1.1.25.24.3.1.1" style="width:43.4pt;">581</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S4.T1.1.25.24.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.25.24.4.1">
<span class="ltx_p" id="S4.T1.1.25.24.4.1.1" style="width:34.7pt;">6.61</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.26.25">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S4.T1.1.26.25.1" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.26.25.1.1">
<span class="ltx_p" id="S4.T1.1.26.25.1.1.1" style="width:8.7pt;"><span class="ltx_text" id="S4.T1.1.26.25.1.1.1.1" style="background-color:#E6FFE6;">24</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="S4.T1.1.26.25.2" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.26.25.2.1">
<span class="ltx_p" id="S4.T1.1.26.25.2.1.1" style="width:242.8pt;"><span class="ltx_text" id="S4.T1.1.26.25.2.1.1.1" style="background-color:#E6FFE6;">Malware Analysis Techniques</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="S4.T1.1.26.25.3" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.26.25.3.1">
<span class="ltx_p" id="S4.T1.1.26.25.3.1.1" style="width:43.4pt;"><span class="ltx_text" id="S4.T1.1.26.25.3.1.1.1" style="background-color:#E6FFE6;">610</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" id="S4.T1.1.26.25.4" style="background-color:#E6FFE6;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.26.25.4.1">
<span class="ltx_p" id="S4.T1.1.26.25.4.1.1" style="width:34.7pt;"><span class="ltx_text" id="S4.T1.1.26.25.4.1.1.1" style="background-color:#E6FFE6;">6.94</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2"> Dataset</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Initially, 30 documents specializing on large-scale malware analysis and anomaly detection with tensor decomposition fields were selected by the SME as the core documents to construct the data. These documents were expanded along the citation/reference network 2 times. The final dataset was enumerated at 8,790 scientific publications. From the cleaned corpus, the tensor object was generated.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2"> Extraction of Latent Features</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">After setting up the tensor, the most coherent grouping is determined by iterating through a range of <math alttext="k=\{1,2,3,\ldots,45\}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.5"><semantics id="S4.SS2.p1.1.m1.5a"><mrow id="S4.SS2.p1.1.m1.5.6" xref="S4.SS2.p1.1.m1.5.6.cmml"><mi id="S4.SS2.p1.1.m1.5.6.2" xref="S4.SS2.p1.1.m1.5.6.2.cmml">k</mi><mo id="S4.SS2.p1.1.m1.5.6.1" xref="S4.SS2.p1.1.m1.5.6.1.cmml">=</mo><mrow id="S4.SS2.p1.1.m1.5.6.3.2" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml"><mo id="S4.SS2.p1.1.m1.5.6.3.2.1" stretchy="false" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml">{</mo><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">1</mn><mo id="S4.SS2.p1.1.m1.5.6.3.2.2" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="S4.SS2.p1.1.m1.2.2" xref="S4.SS2.p1.1.m1.2.2.cmml">2</mn><mo id="S4.SS2.p1.1.m1.5.6.3.2.3" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="S4.SS2.p1.1.m1.3.3" xref="S4.SS2.p1.1.m1.3.3.cmml">3</mn><mo id="S4.SS2.p1.1.m1.5.6.3.2.4" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml">,</mo><mi id="S4.SS2.p1.1.m1.4.4" mathvariant="normal" xref="S4.SS2.p1.1.m1.4.4.cmml">…</mi><mo id="S4.SS2.p1.1.m1.5.6.3.2.5" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="S4.SS2.p1.1.m1.5.5" xref="S4.SS2.p1.1.m1.5.5.cmml">45</mn><mo id="S4.SS2.p1.1.m1.5.6.3.2.6" stretchy="false" xref="S4.SS2.p1.1.m1.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.5b"><apply id="S4.SS2.p1.1.m1.5.6.cmml" xref="S4.SS2.p1.1.m1.5.6"><eq id="S4.SS2.p1.1.m1.5.6.1.cmml" xref="S4.SS2.p1.1.m1.5.6.1"></eq><ci id="S4.SS2.p1.1.m1.5.6.2.cmml" xref="S4.SS2.p1.1.m1.5.6.2">𝑘</ci><set id="S4.SS2.p1.1.m1.5.6.3.1.cmml" xref="S4.SS2.p1.1.m1.5.6.3.2"><cn id="S4.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1">1</cn><cn id="S4.SS2.p1.1.m1.2.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.2.2">2</cn><cn id="S4.SS2.p1.1.m1.3.3.cmml" type="integer" xref="S4.SS2.p1.1.m1.3.3">3</cn><ci id="S4.SS2.p1.1.m1.4.4.cmml" xref="S4.SS2.p1.1.m1.4.4">…</ci><cn id="S4.SS2.p1.1.m1.5.5.cmml" type="integer" xref="S4.SS2.p1.1.m1.5.5">45</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.5c">k=\{1,2,3,\ldots,45\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.5d">italic_k = { 1 , 2 , 3 , … , 45 }</annotation></semantics></math> clusters to decompose. Our analysis determined that 25 topic-clusters represented the optimal division across all evaluated <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_k</annotation></semantics></math> values. The decomposition itself was executed using <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.1">T-ELF</span> on high-performance computing resources, specifically two AMD EPYC 9454 48-Core Processors. This setup provided a total of 192 logical CPUs, enabling us to complete the entire decomposition process in approximately 2 hours. Following the decomposition, post-processing refined and defined clusters for the topics, which are listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.T1" title="TABLE I ‣ IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Vector Store</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The 8,790 documents were vectorized and ingested into the Milvus vector store. When questions are posed to the framework, they are also vectorized using this model. Of the total documents, 22% had full-texts available, which were vectorized into the Milvus. Each document and full-text had a DOI, with the full-texts also including paragraph identifiers.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="419" id="S4.F5.g1" src="x5.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span> The KG schema.
Images generated with DALL·E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib52" title="">52</a>]</cite>. </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.5.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.6.2">Knowledge Graph</span>
</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">From the 25 clusters output form <span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.1">T-ELF</span>, we formatted the the data into 1,457,534 triplets. Once injected into the knowledge graph, there were 321,122 nodes and 1,136,412 edge relationships. The nodes injected into the graph are represented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.F5" title="Figure 5 ‣ IV-C Vector Store ‣ IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">5</span></a>, where they are organized into 16 base categories, referred to as labels, that define the foundational classes for the injection process. Once the graph was built was directly queried for information as Structured Query Language (SQL) is directly queriable outside of an application. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.F6" title="Figure 6 ‣ IV-D Knowledge Graph ‣ IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">6</span></a>, the knowledge graph is queried for the SME keyword related to cybercrime. The query is structured as:</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<div class="ltx_listing ltx_lst_language_cypher2 ltx_lstlisting ltx_align_center ltx_listing" id="S4.SS4.p2.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,TUFUQ0ggIChrOktleXdvcmQpLVtyMV0tKGQ6RG9jdW1lbnQpLVtyMl0KLShhZmY6QWZmaWxpYXRpb24pLVtyM10tKGM6Q291bnRyeSApCldIRVJFIGsudGVybSBDT05UQUlOUyAnY3liZXJjcmltZScKUkVUVVJOIGsscjEsZCxyMixhZmYscjMsYw==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx1.1" style="font-size:80%;color:#0000FF;">MATCH</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.2" style="font-size:80%;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.3" style="font-size:80%;">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.4" style="font-size:80%;">k</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.5" style="font-size:80%;">:</span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx1.6" style="font-size:80%;color:#FF0000;">Keyword</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.7" style="font-size:80%;">)-[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.8" style="font-size:80%;">r1</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.9" style="font-size:80%;">]-(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.10" style="font-size:80%;">d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.11" style="font-size:80%;">:</span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx1.12" style="font-size:80%;color:#FF0000;">Document</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.13" style="font-size:80%;">)-[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.14" style="font-size:80%;">r2</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.15" style="font-size:80%;">]</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx2.1" style="font-size:80%;">-(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.2" style="font-size:80%;">aff</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.3" style="font-size:80%;">:</span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx2.4" style="font-size:80%;color:#FF0000;">Affiliation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.5" style="font-size:80%;">)-[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.6" style="font-size:80%;">r3</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.7" style="font-size:80%;">]-(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx2.8" style="font-size:80%;">c</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.9" style="font-size:80%;">:</span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx2.10" style="font-size:80%;color:#FF0000;">Country</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.11" style="font-size:80%;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.12" style="font-size:80%;">)</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx3.1" style="font-size:80%;color:#0000FF;">WHERE</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.2" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.3" style="font-size:80%;">k</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.4" style="font-size:80%;">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.5" style="font-size:80%;">term</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.6" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx3.7" style="font-size:80%;color:#0000FF;">CONTAINS</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.8" style="font-size:80%;"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.9" style="font-size:80%;">’</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.10" style="font-size:80%;">cybercrime</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.11" style="font-size:80%;">’</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx4.1" style="font-size:80%;color:#0000FF;">RETURN</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.2" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.3" style="font-size:80%;">k</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.4" style="font-size:80%;">,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.5" style="font-size:80%;">r1</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.6" style="font-size:80%;">,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.7" style="font-size:80%;">d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.8" style="font-size:80%;">,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.9" style="font-size:80%;">r2</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.10" style="font-size:80%;">,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.11" style="font-size:80%;">aff</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.12" style="font-size:80%;">,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.13" style="font-size:80%;">r3</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.14" style="font-size:80%;">,</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.15" style="font-size:80%;">c</span>
</div>
</div>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">To retrieve the country nodes from a keyword, several relationships were navigated. First, from the keyword to documents, then from documents to affiliations and finally from the affiliations to the countries. In the cypher query, these links are the denoted as an r with a following integer, where r is the relationship identifier. The syntax is ()-[]-()-[]-()-[]-(), where brackets are relations and parenthesis are nodes. In the first part of the “where” clause, the keyword label is further tailored to the keyword node, such that it must contain “cybercrime.” Overall this can answer the question, “which countries have published papers that mention cybercrime?” The question’s retrieved nodes in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.F6" title="Figure 6 ‣ IV-D Knowledge Graph ‣ IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">6</span></a> has 29 countries in red, 99 affiliated institutions in yellow, and 65 published documents in blue.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="413" id="S4.F6.g1" src="extracted/5897066/figures/RAG_IN_KG.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span> Keyword ’cybercrime’ graph search. A single keyword (green), along with linked documents (light blue) are returned. The documents also link affiliated institutions (yellow), and the country of the institutions (red). </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS5.5.1.1">IV-E</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS5.6.2">Question Answering Validation</span>
</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">The raw data collected was analyzed using document-specific questions in Zero-Shot Conditioning, including:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text" id="S4.I1.i1.p1.1.1" style="font-size:80%;">How many citations are there for </span><span class="ltx_text ltx_font_italic" id="S4.I1.i1.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i1.p1.1.3" style="font-size:80%;">?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text" id="S4.I1.i2.p1.1.1" style="font-size:80%;">How many references are there for </span><span class="ltx_text ltx_font_italic" id="S4.I1.i2.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i2.p1.1.3" style="font-size:80%;">?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text" id="S4.I1.i3.p1.1.1" style="font-size:80%;">How many authors are there for </span><span class="ltx_text ltx_font_italic" id="S4.I1.i3.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i3.p1.1.3" style="font-size:80%;">?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text" id="S4.I1.i4.p1.1.1" style="font-size:80%;">What year was </span><span class="ltx_text ltx_font_italic" id="S4.I1.i4.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i4.p1.1.3" style="font-size:80%;"> published?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text" id="S4.I1.i5.p1.1.1" style="font-size:80%;">Which publisher published </span><span class="ltx_text ltx_font_italic" id="S4.I1.i5.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i5.p1.1.3" style="font-size:80%;">?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i6.p1">
<p class="ltx_p" id="S4.I1.i6.p1.1"><span class="ltx_text" id="S4.I1.i6.p1.1.1" style="font-size:80%;">How many scopus categories are assigned to </span><span class="ltx_text ltx_font_italic" id="S4.I1.i6.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i6.p1.1.3" style="font-size:80%;">?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i7.p1">
<p class="ltx_p" id="S4.I1.i7.p1.1"><span class="ltx_text" id="S4.I1.i7.p1.1.1" style="font-size:80%;">What is the title of </span><span class="ltx_text ltx_font_italic" id="S4.I1.i7.p1.1.2" style="font-size:80%;">DOI</span><span class="ltx_text" id="S4.I1.i7.p1.1.3" style="font-size:80%;">?
</span></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS5.p1.2">After document specific questions, we then examined topic specific questions, which included year variations, as in:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text" id="S4.I2.i1.p1.1.1" style="font-size:80%;">How many papers are there on the topic of </span><span class="ltx_text ltx_font_italic" id="S4.I2.i1.p1.1.2" style="font-size:80%;">Topic</span><span class="ltx_text" id="S4.I2.i1.p1.1.3" style="font-size:80%;">?</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text" id="S4.I2.i2.p1.1.1" style="font-size:80%;">How many papers were written related to </span><span class="ltx_text ltx_font_italic" id="S4.I2.i2.p1.1.2" style="font-size:80%;">Topic</span><span class="ltx_text" id="S4.I2.i2.p1.1.3" style="font-size:80%;"> in </span><span class="ltx_text ltx_font_italic" id="S4.I2.i2.p1.1.4" style="font-size:80%;">Year</span><span class="ltx_text" id="S4.I2.i2.p1.1.5" style="font-size:80%;">?</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">In total, there were 200 questions in this set. Using these questions, in this study, we compare the performance of GPT-4-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#bib.bib51" title="">51</a>]</cite> with and without our RAG framework on both topic-specific and document metadata questions. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.02721v1#S4.F7" title="Figure 7 ‣ IV-E Question Answering Validation ‣ IV Results ‣ Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization"><span class="ltx_text ltx_ref_tag">7</span></a>, our findings indicate that GPT-4 with RAG answers all questions with a 97% accuracy rate. In contrast, without RAG, GPT-4 abstains from answering 40% of the questions, and the accuracy of the answered questions drops to 20%. A similar trend is observed for topic-based questions, where the specialized RAG significantly enhances the retrieval of correct answers. The topic questions attempted with RAG was also 100%, but without was only 36%. In consideration of only the attempted questions, the system with RAG answered the topic questions correctly 92%. Without RAG, the LLM answered the topic questions with 27.77% accuracy.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">Without RAG, several questions about years were answered incorrectly, with the system stating the year didn’t exist. The LLM also struggled with author and reference details, often asking for more information or recommending consulting a human expert. In some cases, it noted its lack of internet access but later suggested using Google Scholar, yet still provided inaccurate responses.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S4.F7.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span> Two question types, document and topic, showing LLM percent attempts and correct with <span class="ltx_text ltx_font_bold" id="S4.F7.2.1">SMART-SLIC</span> RAG and without RAG. </figcaption>
</figure>
<div class="ltx_para" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.1">The analysis highlights the effectiveness of <span class="ltx_text ltx_font_bold" id="S4.SS5.p4.1.1">SMART-SLIC</span> in accurately answering nearly all 200 research queries, covering both document-specific and topic-specific questions. In contrast, GPT-4-instruct without RAG struggled. <span class="ltx_text ltx_font_bold" id="S4.SS5.p4.1.2">SMART-SLIC</span> excelled in handling complex queries related to citations, references, authorship, and topical relevance, underscoring the advantages of integrating its methodologies for more reliable AI-driven research tools and improved information retrieval in scientific fields.</p>
</div>
<div class="ltx_para" id="S4.SS5.p5">
<p class="ltx_p" id="S4.SS5.p5.1">We then shifted to more complex questions requiring thorough searches through various retrieval methods, using GPT-4-instruct with and without RAG. The SME posed the following questions, and the responses are from the <span class="ltx_text ltx_font_bold" id="S4.SS5.p5.1.1">SMART-SLIC</span> RAG process, with DOI citations provided in square brackets:</p>
</div>
<div class="ltx_para" id="S4.SS5.p6">
<ol class="ltx_enumerate" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S4.I3.i1.p1.1.1" style="font-size:80%;">What challenge is associated with outlier detection in high-dimensional data?</span><span class="ltx_text" id="S4.I3.i1.p1.1.2" style="font-size:80%;">
</span><span class="ltx_text" id="S4.I3.i1.p1.1.3" style="font-size:80%;color:#0000FF;">The challenge associated with outlier detection in high-dimensional data is the “curse of dimensionality,” which makes it difficult to detect outliers in the full data space [10.1109/ICCC54389.2021.9674561].</span><span class="ltx_text" id="S4.I3.i1.p1.1.4" style="font-size:80%;"></span></p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S4.I3.i2.p1.1.1" style="font-size:80%;">Can tensor decomposition methods be leveraged to detect SCADA anomalies?</span><span class="ltx_text" id="S4.I3.i2.p1.1.2" style="font-size:80%;">
</span><span class="ltx_text" id="S4.I3.i2.p1.1.3" style="font-size:80%;color:#0000FF;">Yes, tensor decomposition methods can be leveraged to detect SCADA anomalies. The use of non-negative tensor decomposition, specifically the Canonical Polyadic Alternating Poisson Regression (CP-APR) method, has been applied to model the complex and multi-faceted activity details of SCADA events, improving the specificity and accuracy of identifying anomalies in electrical grid systems [10.1109/MILCOM58377.2023.10356348].</span><span class="ltx_text" id="S4.I3.i2.p1.1.4" style="font-size:80%;"></span></p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S4.I3.i3.p1.1.1" style="font-size:80%;">What does MADHAT stand for?</span><span class="ltx_text" id="S4.I3.i3.p1.1.2" style="font-size:80%;">
</span><span class="ltx_text" id="S4.I3.i3.p1.1.3" style="font-size:80%;color:#0000FF;">The acronym MADHAT stands for Multidimensional Anomaly Detection fusing HPC, Analytics, and Tensors [10.1109/HPEC.2019.8916559].</span><span class="ltx_text" id="S4.I3.i3.p1.1.4" style="font-size:80%;"></span></p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S4.I3.i4.p1">
<p class="ltx_p" id="S4.I3.i4.p1.1"><span class="ltx_text ltx_font_italic" id="S4.I3.i4.p1.1.1" style="font-size:80%;">What’s the most advanced anomaly detection method on the LANL Unified Host and Network Dataset?</span><span class="ltx_text" id="S4.I3.i4.p1.1.2" style="font-size:80%;">
</span><span class="ltx_text" id="S4.I3.i4.p1.1.3" style="font-size:80%;color:#0000FF;">The most advanced anomaly detection method on the Los Alamos National Laboratory Unified Host and Network Dataset is the tensor factorization model that exploits the multi-dimensional and sparse structure of user authentication logs for improved detection of penetration testing events [10.1109/ISI49825.2020.9280524].</span><span class="ltx_text" id="S4.I3.i4.p1.1.4" style="font-size:80%;"></span></p>
</div>
</li>
</ol>
<p class="ltx_p" id="S4.SS5.p6.1">For each response, the <span class="ltx_text ltx_font_bold" id="S4.SS5.p6.1.1">SMART-SLIC</span> agent selected DOIs that the SME also chose, demonstrating the agent’s accuracy in retrieving relevant sources. The consistency in DOI selections highlights the robustness of the retrieval mechanisms, ensuring reliable and pertinent information for the user’s questions.</p>
</div>
<div class="ltx_para" id="S4.SS5.p7">
<p class="ltx_p" id="S4.SS5.p7.1">The same questions were asked without RAG, and the results varied. The LLM answered the first general question accurately, but while the initial response to the second question was correct, its elaboration missed key details. The third and fourth responses were entirely wrong, with fabricated answers like ”Malware and Attack Detection Hunting and Analysis Team” and ”Long Short-Term Memory.” Additionally, none of the responses included DOI citations, reducing the credibility of the information by omitting source references.</p>
</div>
<div class="ltx_para" id="S4.SS5.p8">
<p class="ltx_p" id="S4.SS5.p8.1">The evaluation of <span class="ltx_text ltx_font_bold" id="S4.SS5.p8.1.1">SMART-SLIC</span> and GPT-4-instruct, with and without RAG, highlights the importance of retrieval systems for accurate research output. <span class="ltx_text ltx_font_bold" id="S4.SS5.p8.1.2">SMART-SLIC</span>’s RAG excelled in selecting relevant DOI citations for complex queries, while GPT-4-instruct struggled with fabrications, showing the need for advanced systems like <span class="ltx_text ltx_font_bold" id="S4.SS5.p8.1.3">SMART-SLIC</span>. Its strength lies in using high-quality, domain-specific corpora for strong performance in defined research areas, while also offering potential for further exploration in less-defined domains.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">SMART-SLIC</span> framework leverages advanced language models and specialized tools to effectively address user queries by categorizing them into Specific Document Queries and General Queries for efficient processing. The ReAct agent manages general inquiries, while NER and cypher query generation handle document-specific questions.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">LLMs excel in general NLP tasks but struggle in domain-specific areas due to hallucinations, knowledge cut-offs, and lack of attribution. Our system addresses this by integrating RAG with a domain-specific KG and VS, enhancing reliability without fine-tuning. Built using NLP, data mining, and non-negative tensor factorization, this setup enables accurate attributions, reduces hallucinations, and excels in domain-specific queries, as shown in malware analysis research.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">The framework significantly enhances query response accuracy and reliability, making it adaptable to various applications. Future work will expand the framework’s use across domains like robotics, materials science, legal cases, and quantum computing. Enhancements in graph completion, entity linking, and link prediction will further interconnect graphs, reveal hidden connections, and support LLMs in information clarification, keeping <span class="ltx_text ltx_font_bold" id="S5.p3.1.1">SMART-SLIC</span> at the forefront of intelligent information retrieval and generation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Y. A. Yadkori, I. Kuzborskij, A. György, and C. Szepesvári, “To believe or not to believe your llm,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2406.02543</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
N. Harvel, F. B. Haiek, A. Ankolekar, and D. J. Brunner, “Can llms answer investment banking questions? using domain-tuned functions to improve llm performance on knowledge-intensive analytical tasks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the AAAI Symposium Series</em>, vol. 3, no. 1, 2024, pp. 125–133.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
N. Zhang, Y. Yao, B. Tian, P. Wang, S. Deng, M. Wang, Z. Xi, S. Mao, J. Zhang, Y. Ni <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">et al.</em>, “A comprehensive study of knowledge editing for large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2">arXiv preprint arXiv:2401.01286</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. K. Freire, C. Wang, and E. Niforatos, “Chatbots in knowledge-intensive contexts: Comparing intent and llm-based systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2402.04955</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Bertsch, M. Ivgi, U. Alon, J. Berant, M. R. Gormley, and G. Neubig, “In-context learning with long-context models: An in-depth exploration,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2405.00200</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">et al.</em>, “Retrieval-augmented generation for knowledge-intensive nlp tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2">Advances in Neural Information Processing Systems</em>, vol. 33, pp. 9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
R. Vangara, E. Skau, G. Chennupati, H. Djidjev, T. Tierney, J. P. Smith, M. Bhattarai, V. G. Stanev, and B. S. Alexandrov, “Semantic nonnegative matrix factorization with automatic model determination for topic modeling,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)</em>, 2020, pp. 328–335.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
B. T. Nebgen, R. Vangara, M. A. Hombrados-Herrera, S. Kuksova, and B. S. Alexandrov, “A neural network for determination of latent dimensionality in non-negative matrix factorization,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Machine Learning: Science and Technology</em>, vol. 2, no. 2, p. 025012, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
R. Vangara, M. Bhattarai, E. Skau, G. Chennupati, H. Djidjev, T. Tierney, J. P. Smith, V. G. Stanev, and B. S. Alexandrov, “Finding the number of latent topics with semantic non-negative matrix factorization,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">IEEE access</em>, vol. 9, pp. 117 217–117 231, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Liu, “LlamaIndex,” 11 2022. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jerryjliu/llama_index" title="">https://github.com/jerryjliu/llama_index</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R. F. Simmons, “Natural language question-answering systems: 1969,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Commun. ACM</em>, vol. 13, no. 1, p. 15–30, jan 1970. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/361953.361963" title="">https://doi.org/10.1145/361953.361963</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu, “Unifying large language models and knowledge graphs: A roadmap,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE Transactions on Knowledge and Data Engineering</em>, vol. 36, no. 7, pp. 3580–3599, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. Pan, Y. Zheng, and Y. Liu, “Integrating graphs with large language models: Methods and prospects,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">IEEE Intelligent Systems</em>, vol. 39, no. 1, pp. 64–68, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Y. Li, Z. Li, P. Wang, J. Li, X. Sun, H. Cheng, and J. X. Yu, “A survey of graph meets large language model: Progress and future directions,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-234</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D. Chen, A. Fisch, J. Weston, and A. Bordes, “Reading Wikipedia to answer open-domain questions,” in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, R. Barzilay and M.-Y. Kan, Eds.   Vancouver, Canada: Association for Computational Linguistics, Jul. 2017, pp. 1870–1879. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/P17-1171" title="">https://aclanthology.org/P17-1171</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
V. Karpukhin, B. Oguz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen, and W.-t. Yih, “Dense passage retrieval for open-domain question answering,” in <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, B. Webber, T. Cohn, Y. He, and Y. Liu, Eds.   Online: Association for Computational Linguistics, Nov. 2020, pp. 6769–6781. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.emnlp-main.550" title="">https://aclanthology.org/2020.emnlp-main.550</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Tan, Z. Dou, Y. Zhu, P. Guo, K. Fang, and J.-R. Wen, “Small models, big insights: Leveraging slim proxy models to decide when and what to retrieve for llms,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>.   Bangkok, Thailand: Association for Computational Linguistics, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. Jiang, K. Zhou, X. Zhao, Y. Li, and J.-R. Wen, “ReasoningLM: Enabling structural subgraph reasoning in pre-trained language models for question answering over knowledge graph,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, H. Bouamor, J. Pino, and K. Bali, Eds.   Singapore: Association for Computational Linguistics, Dec. 2023, pp. 3721–3735. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.228" title="">https://aclanthology.org/2023.emnlp-main.228</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
L. LUO, Y.-F. Li, R. Haf, and S. Pan, “Reasoning on graphs: Faithful and interpretable large language model reasoning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">The Twelfth International Conference on Learning Representations</em>, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=ZGNWW7xZ6Q" title="">https://openreview.net/forum?id=ZGNWW7xZ6Q</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
B. Jin, C. Xie, J. Zhang, K. K. Roy, Y. Zhang, Z. Li, R. Li, X. Tang, S. Wang, Y. Meng, and J. Han, “Graph chain-of-thought: Augmenting large language models by reasoning on graphs,” 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.07103" title="">https://arxiv.org/abs/2404.07103</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. Li, H. Yang, Z. Liu, M. M. Alam, Ebrahim, H. Sack, and G. A. Gesese, “KGMistral: Towards boosting the performance of large language models for question answering with knowledge graph integration,” in <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Workshop on Deep Learning and Large Language Models for Knowledge Graphs</em>, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=JzL0qm3YA8" title="">https://openreview.net/forum?id=JzL0qm3YA8</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q. Le, and D. Zhou, “Chain-of-thought prompting elicits reasoning in large language models,” 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2201.11903" title="">https://arxiv.org/abs/2201.11903</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao, “React: Synergizing reasoning and acting in language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">The Eleventh International Conference on Learning Representations</em>, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=WE_vluYUL-X" title="">https://openreview.net/forum?id=WE_vluYUL-X</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. Lála, O. O’Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques, and A. D. White, “Paperqa: Retrieval-augmented generative agent for scientific research,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2312.07559</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D. Sanmartin, “Kg-rag: Bridging the gap between knowledge and creativity,” 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2405.12035" title="">https://arxiv.org/abs/2405.12035</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
K. Soman, P. W. Rose, J. H. Morris, R. E. Akbas, B. Smith, B. Peetoom, C. Villouta-Reyes, G. Cerono, Y. Shi, A. Rizk-Jackson <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">et al.</em>, “Biomedical knowledge graph-enhanced prompt generation for large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.2.2">arXiv preprint arXiv:2311.17330</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
C. Edwards, “Hybrid context retrieval augmented generation pipeline: Llm-augmented knowledge graphs and vector database for accreditation reporting assistance,” 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
N. Matsumoto, J. Moran, H. Choi, M. E. Hernandez, M. Venkatesan, P. Wang, and J. H. Moore, “KRAGEN: a knowledge graph-enhanced RAG framework for biomedical problem solving using large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Bioinformatics</em>, vol. 40, no. 6, p. btae353, 06 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1093/bioinformatics/btae353" title="">https://doi.org/10.1093/bioinformatics/btae353</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Z. Xu, M. J. Cruz, M. Guevara, T. Wang, M. Deshpande, X. Wang, and Z. Li, “Retrieval-augmented generation with knowledge graphs for customer service question answering,” in <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, ser. SIGIR ’24.   New York, NY, USA: Association for Computing Machinery, 2024, p. 2905–2909. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3626772.3661370" title="">https://doi.org/10.1145/3626772.3661370</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
N. Solovyev, R. Barron, M. E. Eren, K. O. Rasmussen, M. Bhattarai, I. D. Boureima, and B. S. Alexandrov, “Slic: Scientific leadership identification and characterization: Interactive distillation of large single-topic corpora of scientific papers,” DOE Data Days (D3) at Lawrence Livermore National Laboratory, LA-UR-23-30223, Tech. Rep., 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
M. Eren, N. Solovyev, R. Barron, M. Bhattarai, D. Truong, I. Boureima, E. Skau, K. O. Rasmussen, and B. Alexandrov, “Tensor Extraction of Latent Features (T-ELF),” Oct. 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lanl/T-ELF" title="">https://github.com/lanl/T-ELF</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B. Abu-Salih, “Domain-specific knowledge graphs: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Journal of Network and Computer Applications</em>, vol. 185, p. 103076, 2021. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/science/article/pii/S1084804521000990" title="">https://www.sciencedirect.com/science/article/pii/S1084804521000990</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
S. Yu, Z. Yuan, J. Xia, S. Luo, H. Ying, S. Zeng, J. Ren, H. Yuan, Z. Zhao, Y. Lin, K. Lu, J. Wang, Y. Xie, and H.-Y. Shum, “Bios: An algorithmically generated biomedical knowledge graph,” 2022. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2203.09975" title="">https://arxiv.org/abs/2203.09975</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
N. Solovyev, R. Barron, M. Bhattarai, M. E. Eren, K. O. Rasmussen, and B. S. Alexandrov, “Interactive distillation of large single-topic corpora of scientific papers,” in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">2023 International Conference on Machine Learning and Applications (ICMLA)</em>, 2023, pp. 1000–1005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
S. Ji, S. Pan, E. Cambria, P. Marttinen, and P. S. Yu, “A survey on knowledge graphs: Representation, acquisition, and applications,” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">IEEE Transactions on Neural Networks and Learning Systems</em>, vol. 33, no. 2, pp. 494–514, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
H. Ye, H. Gui, A. Zhang, T. Liu, W. Hua, and W. Jia, “Beyond isolation: Multi-agent synergy for improving knowledge graph construction,” 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2312.03022" title="">https://arxiv.org/abs/2312.03022</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
S. Wadhwa, S. Amir, and B. Wallace, “Revisiting relation extraction in the era of large language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, A. Rogers, J. Boyd-Graber, and N. Okazaki, Eds.   Toronto, Canada: Association for Computational Linguistics, Jul. 2023, pp. 15 566–15 589. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.acl-long.868" title="">https://aclanthology.org/2023.acl-long.868</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
M. Marinov, Y. Benkhedda, G. Nenadic, and R. Batista-Navarro, “Relation extraction for constructing knowledge graphs: Enhancing the searchability of community-generated digital content (CGDC) collections,” in <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Workshop on Deep Learning and Large Language Models for Knowledge Graphs</em>, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=ZOKivqqTjg" title="">https://openreview.net/forum?id=ZOKivqqTjg</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
V. Zavarella, J. C. Gamero, and S. Consoli, “A few-shot approach for relation extraction domain adaptation using large language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Workshop on Deep Learning and Large Language Models for Knowledge Graphs</em>, 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=rBUbEKOECY" title="">https://openreview.net/forum?id=rBUbEKOECY</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt, and J. Larson, “From local to global: A graph rag approach to query-focused summarization,” 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2404.16130" title="">https://arxiv.org/abs/2404.16130</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
X. Lv, X. Han, L. Hou, J. Li, Z. Liu, W. Zhang, Y. Zhang, H. Kong, and S. Wu, “Dynamic anticipation and completion for multi-hop reasoning over sparse knowledge graph,” in <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, B. Webber, T. Cohn, Y. He, and Y. Liu, Eds.   Online: Association for Computational Linguistics, Nov. 2020, pp. 5694–5703. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.emnlp-main.459" title="">https://aclanthology.org/2020.emnlp-main.459</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
W. Chen, Y. Cao, F. Feng, X. He, and Y. Zhang, “Hogrn: Explainable sparse knowledge graph completion via high-order graph reasoning network,” <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">IEEE Transactions on Knowledge and Data Engineering</em>, pp. 1–13, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Elsevier, “Scopus,” 2024, accessed: 2024-07-20. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.scopus.com" title="">https://www.scopus.com</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Allen Institute for AI, “Semantic scholar,” 2024, accessed: 2024-07-20. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.semanticscholar.org" title="">https://www.semanticscholar.org</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
U.S. Department of Energy, “Office of scientific and technical information (osti),” 2024, accessed: 2024-07-20. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.osti.gov" title="">https://www.osti.gov</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
M. Ostendorff, N. Rethmeier, I. Augenstein, B. Gipp, and G. Rehm, “Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings,” in <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)</em>.   Abu Dhabi: Association for Computational Linguistics, December 2022, 7-11 December 2022. Accepted for publication.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
R. Barron, M. E. Eren, M. Bhattarai, I. Boureima, C. Matuszek, and B. S. Alexandrov, “Binary bleed: Fast distributed and parallel method for automatic model selection,” 2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.19125" title="">https://arxiv.org/abs/2407.19125</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Neo4j, Inc., “Neo4j: The #1 platform for connected data,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://neo4j.com/" title="">https://neo4j.com/</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Explosion AI, “spacy english core web transformer model,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://spacy.io/models/en#en_core_web_trf" title="">https://spacy.io/models/en#en_core_web_trf</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
J. Wang, X. Yi, R. Guo, H. Jin, P. Xu, S. Li, X. Wang, X. Guo, C. Li, X. Xu <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">et al.</em>, “Milvus: A purpose-built vector data management system,” in <em class="ltx_emph ltx_font_italic" id="bib.bib50.2.2">Proceedings of the 2021 International Conference on Management of Data</em>, 2021, pp. 2614–2627.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
OpenAI, “Openai api,” 2024, accessed: 2024-07-28. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.openai.com/api/" title="">https://www.openai.com/api/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
OpenAI’s DALL·E, “Visual representations of llms, kg, &amp; rag concepts,” 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
L. Inc., “Langgraph: Building language agents as graphs,” <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://langchain-ai.github.io/langgraph/" title="">https://langchain-ai.github.io/langgraph/</a>, 2024, version 1.0.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct  3 17:23:28 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
