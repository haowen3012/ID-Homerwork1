<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining</title>
<!--Generated on Thu Jun  6 03:15:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.03714v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S1" title="In Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S2" title="In Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S2.SS1" title="In 2 Methodology ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>RAG-enhanced Prompt-based TTS</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S2.SS2" title="In 2 Methodology ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Context-Aware Contrastive Language-audio Pretraining (CA-CLAP)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S2.SS3" title="In 2 Methodology ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Prompt-based Text-to-Speech</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3" title="In Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.SS1" title="In 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Training Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.SS2" title="In 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Compared Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.SS3" title="In 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Objective Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.SS4" title="In 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Subjective Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.SS5" title="In 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Effects of Context Length</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.SS6" title="In 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6 </span>Effects of Speech Prompt Number</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S4" title="In Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S5" title="In Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Acknowledgements</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\interspeechcameraready</span><span class="ltx_ERROR undefined" id="p1.2">\name</span>
<p class="ltx_p" id="p1.3">[affiliation=†]JinlongXue
<span class="ltx_ERROR undefined" id="p1.3.1">\name</span>[affiliation=†]YayueDeng
<span class="ltx_ERROR undefined" id="p1.3.2">\name</span>[affiliation=]YingmingGao
<span class="ltx_ERROR undefined" id="p1.3.3">\name</span>[affiliation=*]YaLi




</p>
</div>
<h1 class="ltx_title ltx_title_document">Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Recent prompt-based text-to-speech (TTS) models can clone an unseen speaker using only a short speech prompt. They leverage a strong in-context ability to mimic the speech prompts, including speaker style, prosody, and emotion. Therefore, the selection of a speech prompt greatly influences the generated speech, akin to the importance of a prompt in large language models (LLMs). However, current prompt-based TTS models choose the speech prompt manually or simply at random. Hence, in this paper, we adapt retrieval augmented generation (RAG) from LLMs to prompt-based TTS. Unlike traditional RAG methods, we additionally consider contextual information during the retrieval process and present a Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model to extract context-aware, style-related features. The objective and subjective evaluations demonstrate that our proposed RAG method outperforms baselines, and our CA-CLAP achieves better results than text-only retrieval methods.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>text-to-speech synthesis, contrastive learning, retrieval augmentation
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span><math alttext="\dagger" class="ltx_Math" display="inline" id="footnotex1.m1.1"><semantics id="footnotex1.m1.1b"><mo id="footnotex1.m1.1.1" xref="footnotex1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="footnotex1.m1.1c"><ci id="footnotex1.m1.1.1.cmml" xref="footnotex1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="footnotex1.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="footnotex1.m1.1e">†</annotation></semantics></math> Equal Contribution. * Corresponding author.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Text-to-speech (TTS) synthesis aims to generate natural speech from text and has seen tremendous improvements due to the adoption of deep learning methods. Recently, the integration of Large Language Models (LLMs) with TTS synthesis technology has emerged as a new trend, garnering widespread attention. LLMs, through in-context learning (ICL), have shown significant advancements in learning from minimal prompts. This breakthrough, coupled with the use of neural audio codecs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib3" title="">3</a>]</cite> that convert continuous audio features into discrete tokens, has greatly propelled recent speech synthesis frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib5" title="">5</a>]</cite>, such as VALL-E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib6" title="">6</a>]</cite>, AudioLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib7" title="">7</a>]</cite>, NaturalSpeech2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib8" title="">8</a>]</cite>, and SPEAR-TTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib9" title="">9</a>]</cite>. These systems can generate high-quality, personalized speech from just a few seconds of unseen audio used as a speech prompt.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">VALL-E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib6" title="">6</a>]</cite>, a pioneering TTS framework, adopts RVQ-based audio codec Encodec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib2" title="">2</a>]</cite> and utilizes a language model as a prompt-based language modeling task. It can generate acoustic tokens based on the input of a only 3-second voice recording. AudioLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib7" title="">7</a>]</cite> uses a hierarchical sequence-to-sequence approach and adopts w2v-BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib10" title="">10</a>]</cite> and SoundStream <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib1" title="">1</a>]</cite> to extract semantic and acoustic tokens respectively. Therefore the speech prompt is used in both stages and extracted with different representations. SPEAR-TTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib9" title="">9</a>]</cite> has the same structure except for replacing the first stage with an encoder-decoder scheme. Compared with traditional TTS systems like FastSpeech2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib11" title="">11</a>]</cite> and Tacotron2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib12" title="">12</a>]</cite>, these recent models show great voice cloning ability by providing only a 3-second speech prompt and have natural prosody comparable with human speakers. This huge success can be attributed to in-context learning provided by GPT-like architecture, and adoption of audio codecs which enable TTS models to utilize vast, diverse, and noisy data instead of only recorded data. However, the generation in a GPT-like manner is highly dependent on previously predicted tokens. This means that the speech prompt has a substantial impact on the subsequent generation process, significantly influencing the generated speech and affecting aspects such as speaker timbre, prosody, and speaking style.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="243" id="S1.F1.g1" src="extracted/5647532/RAG3.png" width="568"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of our RAG-enhanced prompt-based TTS</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Hence, the selection of speech prompts is critically important, akin to the significance of prompts in the LLM domain, where the quality and clarity of prompts significantly influence the outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib14" title="">14</a>]</cite>. However, existing methods often randomly select speech prompts from the target speaker, resulting in a choice that is frequently inadequate for guiding the zero-shot TTS system to mimic the desired speaking style and target timbre effectively. The choice of speech prompt should vary given different texts. Furthermore, in TTS scenarios that incorporate context information, such as audiobook TTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib17" title="">17</a>]</cite> and conversational TTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib20" title="">20</a>]</cite>, the choice of a speech prompt should also take contextual information into account.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To address this challenge, the given audio prompt should coherent the style information with current text and context information. In LLM area, RAG methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib22" title="">22</a>]</cite> are recognized as a significant enhancement across a variety of tasks. Since LLMs cannot accurately memorize every piece of knowledge but they have strong in-context learning abilities, RAG methods find the most relevant information from external databases and use them as prompts. Retrieval augments the LLM’s ability to generate accurate, grounded responses, especially for queries demanding specialized domain knowledge.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Motivated by this insight, we adapt the RAG concept to the speech domain to tackle the challenge of selecting appropriate speech prompts. To this end, we introduce a novel framework that combines context-aware retrieval-augmented generation with a prompt-based TTS system. Furthermore, unlike traditional RAG methods that rely solely on textual data, our approach incorporates acoustic inputs during retrieval. This is because the acoustic modality offers richer information, including emotion and speaking style, enhancing the overall quality and relevance of the retrieved content. Specifically, our proposed framework incorporates an innovative Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model which is designed to extract context-aware, style-related textual features (STFs) under audio supervision. It employs an audio encoder for extracting style embeddings from speech and a text encoder for deriving STFs from both the text and its context. Additionally, we enhance context integration by implementing cross-attention mechanisms between textual and contextual features. Overall, our paper makes the following contributions: 1) We propose a RAG-enhanced prompt-based TTS framework to enhance audio prompt specialized selection. 2) We design a CA-CLAP model to extract textual and acoustic representations for retrieval. 3) We conduct extensive subjective and objective experiments and find that our proposed methods outperform baselines and our introduced CA-CLAP has better results than text-only embedding methods. Audio samples are available on the project page<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://happylittlecat2333.github.io/interspeech2024-RAG</span></span></span>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The details of our proposed RAG-enhanced method, along with the introduction of our CA-CLAP and the prompt-based TTS are described in the below sections.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>RAG-enhanced Prompt-based TTS</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">1</span></a>, our proposed method includes three components: indexing, retrieval, and generation. The indexing process is a crucial initial step that transfers all the possible audio prompts into style-related representations via the audio encoder of pretrained context-aware contrastive language-audio model (CA-CLAP) and subsequently constructs a speech embedding database. It serves as key similarity comparison during the retrieval phase. Then, in the retrieval process, the current text and context are encoded into the style-related text features (STFs) via the pretrained CA-CLAP text encoder. The generated context-aware text representations are served as query to compute the similarity scores with the vectorized audio prompts within the indexed speech embedding database. Then, the model prioritizes and retrieves the top K audio prompts that demonstrate the greatest similarity. Finally, in the generation process, we use the first P prompts and concatenate them as final audio prompts, to guide the pretrained prompt-based TTS system to generate suitable speech.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Context-Aware Contrastive Language-audio Pretraining (CA-CLAP)</h3>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="212" id="S2.F2.g1" src="extracted/5647532/model2.png" width="568"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Left: An Overview of Context-Aware CLAP. Right: An illustration of the inference process of Prompt-based TTS</figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In the indexing process of the RAG-enhanced prompt-based TTS structure, textual modality and acoustic modality inputs (text and audio) need to be embedded into a shared feature space to calculate the cosine similarity. Hence, inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib23" title="">23</a>]</cite>, we consider constructing a multi-modal feature extractor which can extract style-related embedding from both textual and acoustic inputs. We implement two encoders to separately process audio data and text data. Moreover, to fully utilize the additional contextual information, we enhance the current linguistic feature with contextual information via a cross-attention mechanism. The context definition and computation formula are as:</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="U_{con}=Concat(U_{i-l},U_{i-l+1},...,U_{i},...,U_{i+l-1},U_{i+l})" class="ltx_Math" display="block" id="S2.E1.m1.7"><semantics id="S2.E1.m1.7a"><mrow id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml"><msub id="S2.E1.m1.7.7.7" xref="S2.E1.m1.7.7.7.cmml"><mi id="S2.E1.m1.7.7.7.2" xref="S2.E1.m1.7.7.7.2.cmml">U</mi><mrow id="S2.E1.m1.7.7.7.3" xref="S2.E1.m1.7.7.7.3.cmml"><mi id="S2.E1.m1.7.7.7.3.2" xref="S2.E1.m1.7.7.7.3.2.cmml">c</mi><mo id="S2.E1.m1.7.7.7.3.1" xref="S2.E1.m1.7.7.7.3.1.cmml">⁢</mo><mi id="S2.E1.m1.7.7.7.3.3" xref="S2.E1.m1.7.7.7.3.3.cmml">o</mi><mo id="S2.E1.m1.7.7.7.3.1a" xref="S2.E1.m1.7.7.7.3.1.cmml">⁢</mo><mi id="S2.E1.m1.7.7.7.3.4" xref="S2.E1.m1.7.7.7.3.4.cmml">n</mi></mrow></msub><mo id="S2.E1.m1.7.7.6" xref="S2.E1.m1.7.7.6.cmml">=</mo><mrow id="S2.E1.m1.7.7.5" xref="S2.E1.m1.7.7.5.cmml"><mi id="S2.E1.m1.7.7.5.7" xref="S2.E1.m1.7.7.5.7.cmml">C</mi><mo id="S2.E1.m1.7.7.5.6" xref="S2.E1.m1.7.7.5.6.cmml">⁢</mo><mi id="S2.E1.m1.7.7.5.8" xref="S2.E1.m1.7.7.5.8.cmml">o</mi><mo id="S2.E1.m1.7.7.5.6a" xref="S2.E1.m1.7.7.5.6.cmml">⁢</mo><mi id="S2.E1.m1.7.7.5.9" xref="S2.E1.m1.7.7.5.9.cmml">n</mi><mo id="S2.E1.m1.7.7.5.6b" xref="S2.E1.m1.7.7.5.6.cmml">⁢</mo><mi id="S2.E1.m1.7.7.5.10" xref="S2.E1.m1.7.7.5.10.cmml">c</mi><mo id="S2.E1.m1.7.7.5.6c" xref="S2.E1.m1.7.7.5.6.cmml">⁢</mo><mi id="S2.E1.m1.7.7.5.11" xref="S2.E1.m1.7.7.5.11.cmml">a</mi><mo id="S2.E1.m1.7.7.5.6d" xref="S2.E1.m1.7.7.5.6.cmml">⁢</mo><mi id="S2.E1.m1.7.7.5.12" xref="S2.E1.m1.7.7.5.12.cmml">t</mi><mo id="S2.E1.m1.7.7.5.6e" xref="S2.E1.m1.7.7.5.6.cmml">⁢</mo><mrow id="S2.E1.m1.7.7.5.5.5" xref="S2.E1.m1.7.7.5.5.6.cmml"><mo id="S2.E1.m1.7.7.5.5.5.6" stretchy="false" xref="S2.E1.m1.7.7.5.5.6.cmml">(</mo><msub id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">U</mi><mrow id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.3.2" xref="S2.E1.m1.3.3.1.1.1.1.3.2.cmml">i</mi><mo id="S2.E1.m1.3.3.1.1.1.1.3.1" xref="S2.E1.m1.3.3.1.1.1.1.3.1.cmml">−</mo><mi id="S2.E1.m1.3.3.1.1.1.1.3.3" xref="S2.E1.m1.3.3.1.1.1.1.3.3.cmml">l</mi></mrow></msub><mo id="S2.E1.m1.7.7.5.5.5.7" xref="S2.E1.m1.7.7.5.5.6.cmml">,</mo><msub id="S2.E1.m1.4.4.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.2.cmml">U</mi><mrow id="S2.E1.m1.4.4.2.2.2.2.3" xref="S2.E1.m1.4.4.2.2.2.2.3.cmml"><mrow id="S2.E1.m1.4.4.2.2.2.2.3.2" xref="S2.E1.m1.4.4.2.2.2.2.3.2.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.3.2.2" xref="S2.E1.m1.4.4.2.2.2.2.3.2.2.cmml">i</mi><mo id="S2.E1.m1.4.4.2.2.2.2.3.2.1" xref="S2.E1.m1.4.4.2.2.2.2.3.2.1.cmml">−</mo><mi id="S2.E1.m1.4.4.2.2.2.2.3.2.3" xref="S2.E1.m1.4.4.2.2.2.2.3.2.3.cmml">l</mi></mrow><mo id="S2.E1.m1.4.4.2.2.2.2.3.1" xref="S2.E1.m1.4.4.2.2.2.2.3.1.cmml">+</mo><mn id="S2.E1.m1.4.4.2.2.2.2.3.3" xref="S2.E1.m1.4.4.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E1.m1.7.7.5.5.5.8" xref="S2.E1.m1.7.7.5.5.6.cmml">,</mo><mi id="S2.E1.m1.1.1" mathvariant="normal" xref="S2.E1.m1.1.1.cmml">…</mi><mo id="S2.E1.m1.7.7.5.5.5.9" xref="S2.E1.m1.7.7.5.5.6.cmml">,</mo><msub id="S2.E1.m1.5.5.3.3.3.3" xref="S2.E1.m1.5.5.3.3.3.3.cmml"><mi id="S2.E1.m1.5.5.3.3.3.3.2" xref="S2.E1.m1.5.5.3.3.3.3.2.cmml">U</mi><mi id="S2.E1.m1.5.5.3.3.3.3.3" xref="S2.E1.m1.5.5.3.3.3.3.3.cmml">i</mi></msub><mo id="S2.E1.m1.7.7.5.5.5.10" xref="S2.E1.m1.7.7.5.5.6.cmml">,</mo><mi id="S2.E1.m1.2.2" mathvariant="normal" xref="S2.E1.m1.2.2.cmml">…</mi><mo id="S2.E1.m1.7.7.5.5.5.11" xref="S2.E1.m1.7.7.5.5.6.cmml">,</mo><msub id="S2.E1.m1.6.6.4.4.4.4" xref="S2.E1.m1.6.6.4.4.4.4.cmml"><mi id="S2.E1.m1.6.6.4.4.4.4.2" xref="S2.E1.m1.6.6.4.4.4.4.2.cmml">U</mi><mrow id="S2.E1.m1.6.6.4.4.4.4.3" xref="S2.E1.m1.6.6.4.4.4.4.3.cmml"><mrow id="S2.E1.m1.6.6.4.4.4.4.3.2" xref="S2.E1.m1.6.6.4.4.4.4.3.2.cmml"><mi id="S2.E1.m1.6.6.4.4.4.4.3.2.2" xref="S2.E1.m1.6.6.4.4.4.4.3.2.2.cmml">i</mi><mo id="S2.E1.m1.6.6.4.4.4.4.3.2.1" xref="S2.E1.m1.6.6.4.4.4.4.3.2.1.cmml">+</mo><mi id="S2.E1.m1.6.6.4.4.4.4.3.2.3" xref="S2.E1.m1.6.6.4.4.4.4.3.2.3.cmml">l</mi></mrow><mo id="S2.E1.m1.6.6.4.4.4.4.3.1" xref="S2.E1.m1.6.6.4.4.4.4.3.1.cmml">−</mo><mn id="S2.E1.m1.6.6.4.4.4.4.3.3" xref="S2.E1.m1.6.6.4.4.4.4.3.3.cmml">1</mn></mrow></msub><mo id="S2.E1.m1.7.7.5.5.5.12" xref="S2.E1.m1.7.7.5.5.6.cmml">,</mo><msub id="S2.E1.m1.7.7.5.5.5.5" xref="S2.E1.m1.7.7.5.5.5.5.cmml"><mi id="S2.E1.m1.7.7.5.5.5.5.2" xref="S2.E1.m1.7.7.5.5.5.5.2.cmml">U</mi><mrow id="S2.E1.m1.7.7.5.5.5.5.3" xref="S2.E1.m1.7.7.5.5.5.5.3.cmml"><mi id="S2.E1.m1.7.7.5.5.5.5.3.2" xref="S2.E1.m1.7.7.5.5.5.5.3.2.cmml">i</mi><mo id="S2.E1.m1.7.7.5.5.5.5.3.1" xref="S2.E1.m1.7.7.5.5.5.5.3.1.cmml">+</mo><mi id="S2.E1.m1.7.7.5.5.5.5.3.3" xref="S2.E1.m1.7.7.5.5.5.5.3.3.cmml">l</mi></mrow></msub><mo id="S2.E1.m1.7.7.5.5.5.13" stretchy="false" xref="S2.E1.m1.7.7.5.5.6.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.7b"><apply id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7"><eq id="S2.E1.m1.7.7.6.cmml" xref="S2.E1.m1.7.7.6"></eq><apply id="S2.E1.m1.7.7.7.cmml" xref="S2.E1.m1.7.7.7"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.7.1.cmml" xref="S2.E1.m1.7.7.7">subscript</csymbol><ci id="S2.E1.m1.7.7.7.2.cmml" xref="S2.E1.m1.7.7.7.2">𝑈</ci><apply id="S2.E1.m1.7.7.7.3.cmml" xref="S2.E1.m1.7.7.7.3"><times id="S2.E1.m1.7.7.7.3.1.cmml" xref="S2.E1.m1.7.7.7.3.1"></times><ci id="S2.E1.m1.7.7.7.3.2.cmml" xref="S2.E1.m1.7.7.7.3.2">𝑐</ci><ci id="S2.E1.m1.7.7.7.3.3.cmml" xref="S2.E1.m1.7.7.7.3.3">𝑜</ci><ci id="S2.E1.m1.7.7.7.3.4.cmml" xref="S2.E1.m1.7.7.7.3.4">𝑛</ci></apply></apply><apply id="S2.E1.m1.7.7.5.cmml" xref="S2.E1.m1.7.7.5"><times id="S2.E1.m1.7.7.5.6.cmml" xref="S2.E1.m1.7.7.5.6"></times><ci id="S2.E1.m1.7.7.5.7.cmml" xref="S2.E1.m1.7.7.5.7">𝐶</ci><ci id="S2.E1.m1.7.7.5.8.cmml" xref="S2.E1.m1.7.7.5.8">𝑜</ci><ci id="S2.E1.m1.7.7.5.9.cmml" xref="S2.E1.m1.7.7.5.9">𝑛</ci><ci id="S2.E1.m1.7.7.5.10.cmml" xref="S2.E1.m1.7.7.5.10">𝑐</ci><ci id="S2.E1.m1.7.7.5.11.cmml" xref="S2.E1.m1.7.7.5.11">𝑎</ci><ci id="S2.E1.m1.7.7.5.12.cmml" xref="S2.E1.m1.7.7.5.12">𝑡</ci><vector id="S2.E1.m1.7.7.5.5.6.cmml" xref="S2.E1.m1.7.7.5.5.5"><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">𝑈</ci><apply id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3"><minus id="S2.E1.m1.3.3.1.1.1.1.3.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3.1"></minus><ci id="S2.E1.m1.3.3.1.1.1.1.3.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3.2">𝑖</ci><ci id="S2.E1.m1.3.3.1.1.1.1.3.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3.3">𝑙</ci></apply></apply><apply id="S2.E1.m1.4.4.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.2">𝑈</ci><apply id="S2.E1.m1.4.4.2.2.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3"><plus id="S2.E1.m1.4.4.2.2.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.1"></plus><apply id="S2.E1.m1.4.4.2.2.2.2.3.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2"><minus id="S2.E1.m1.4.4.2.2.2.2.3.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2.1"></minus><ci id="S2.E1.m1.4.4.2.2.2.2.3.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2.2">𝑖</ci><ci id="S2.E1.m1.4.4.2.2.2.2.3.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2.3">𝑙</ci></apply><cn id="S2.E1.m1.4.4.2.2.2.2.3.3.cmml" type="integer" xref="S2.E1.m1.4.4.2.2.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">…</ci><apply id="S2.E1.m1.5.5.3.3.3.3.cmml" xref="S2.E1.m1.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.3.3.3.3.1.cmml" xref="S2.E1.m1.5.5.3.3.3.3">subscript</csymbol><ci id="S2.E1.m1.5.5.3.3.3.3.2.cmml" xref="S2.E1.m1.5.5.3.3.3.3.2">𝑈</ci><ci id="S2.E1.m1.5.5.3.3.3.3.3.cmml" xref="S2.E1.m1.5.5.3.3.3.3.3">𝑖</ci></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">…</ci><apply id="S2.E1.m1.6.6.4.4.4.4.cmml" xref="S2.E1.m1.6.6.4.4.4.4"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.4.4.4.4.1.cmml" xref="S2.E1.m1.6.6.4.4.4.4">subscript</csymbol><ci id="S2.E1.m1.6.6.4.4.4.4.2.cmml" xref="S2.E1.m1.6.6.4.4.4.4.2">𝑈</ci><apply id="S2.E1.m1.6.6.4.4.4.4.3.cmml" xref="S2.E1.m1.6.6.4.4.4.4.3"><minus id="S2.E1.m1.6.6.4.4.4.4.3.1.cmml" xref="S2.E1.m1.6.6.4.4.4.4.3.1"></minus><apply id="S2.E1.m1.6.6.4.4.4.4.3.2.cmml" xref="S2.E1.m1.6.6.4.4.4.4.3.2"><plus id="S2.E1.m1.6.6.4.4.4.4.3.2.1.cmml" xref="S2.E1.m1.6.6.4.4.4.4.3.2.1"></plus><ci id="S2.E1.m1.6.6.4.4.4.4.3.2.2.cmml" xref="S2.E1.m1.6.6.4.4.4.4.3.2.2">𝑖</ci><ci id="S2.E1.m1.6.6.4.4.4.4.3.2.3.cmml" xref="S2.E1.m1.6.6.4.4.4.4.3.2.3">𝑙</ci></apply><cn id="S2.E1.m1.6.6.4.4.4.4.3.3.cmml" type="integer" xref="S2.E1.m1.6.6.4.4.4.4.3.3">1</cn></apply></apply><apply id="S2.E1.m1.7.7.5.5.5.5.cmml" xref="S2.E1.m1.7.7.5.5.5.5"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.5.5.5.5.1.cmml" xref="S2.E1.m1.7.7.5.5.5.5">subscript</csymbol><ci id="S2.E1.m1.7.7.5.5.5.5.2.cmml" xref="S2.E1.m1.7.7.5.5.5.5.2">𝑈</ci><apply id="S2.E1.m1.7.7.5.5.5.5.3.cmml" xref="S2.E1.m1.7.7.5.5.5.5.3"><plus id="S2.E1.m1.7.7.5.5.5.5.3.1.cmml" xref="S2.E1.m1.7.7.5.5.5.5.3.1"></plus><ci id="S2.E1.m1.7.7.5.5.5.5.3.2.cmml" xref="S2.E1.m1.7.7.5.5.5.5.3.2">𝑖</ci><ci id="S2.E1.m1.7.7.5.5.5.5.3.3.cmml" xref="S2.E1.m1.7.7.5.5.5.5.3.3">𝑙</ci></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.7c">U_{con}=Concat(U_{i-l},U_{i-l+1},...,U_{i},...,U_{i+l-1},U_{i+l})</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.7d">italic_U start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT = italic_C italic_o italic_n italic_c italic_a italic_t ( italic_U start_POSTSUBSCRIPT italic_i - italic_l end_POSTSUBSCRIPT , italic_U start_POSTSUBSCRIPT italic_i - italic_l + 1 end_POSTSUBSCRIPT , … , italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , … , italic_U start_POSTSUBSCRIPT italic_i + italic_l - 1 end_POSTSUBSCRIPT , italic_U start_POSTSUBSCRIPT italic_i + italic_l end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Q=W^{Q}E_{cur},\quad K=W^{K}E_{con},\quad V=W^{V}E_{con}" class="ltx_Math" display="block" id="S2.E2.m1.2"><semantics id="S2.E2.m1.2a"><mrow id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.3.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml">Q</mi><mo id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml"><msup id="S2.E2.m1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.3.2.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2.2" xref="S2.E2.m1.1.1.1.1.3.2.2.cmml">W</mi><mi id="S2.E2.m1.1.1.1.1.3.2.3" xref="S2.E2.m1.1.1.1.1.3.2.3.cmml">Q</mi></msup><mo id="S2.E2.m1.1.1.1.1.3.1" xref="S2.E2.m1.1.1.1.1.3.1.cmml">⁢</mo><msub id="S2.E2.m1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.2.cmml">E</mi><mrow id="S2.E2.m1.1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.1.3.3.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.3.3.2" xref="S2.E2.m1.1.1.1.1.3.3.3.2.cmml">c</mi><mo id="S2.E2.m1.1.1.1.1.3.3.3.1" xref="S2.E2.m1.1.1.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.1.1.1.1.3.3.3.3" xref="S2.E2.m1.1.1.1.1.3.3.3.3.cmml">u</mi><mo id="S2.E2.m1.1.1.1.1.3.3.3.1a" xref="S2.E2.m1.1.1.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.1.1.1.1.3.3.3.4" xref="S2.E2.m1.1.1.1.1.3.3.3.4.cmml">r</mi></mrow></msub></mrow></mrow><mo id="S2.E2.m1.2.2.2.3" rspace="1.167em" xref="S2.E2.m1.2.2.3a.cmml">,</mo><mrow id="S2.E2.m1.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.3.cmml"><mrow id="S2.E2.m1.2.2.2.2.1.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.2.cmml">K</mi><mo id="S2.E2.m1.2.2.2.2.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.2.2.2.2.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.3.cmml"><msup id="S2.E2.m1.2.2.2.2.1.1.3.2" xref="S2.E2.m1.2.2.2.2.1.1.3.2.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.3.2.2" xref="S2.E2.m1.2.2.2.2.1.1.3.2.2.cmml">W</mi><mi id="S2.E2.m1.2.2.2.2.1.1.3.2.3" xref="S2.E2.m1.2.2.2.2.1.1.3.2.3.cmml">K</mi></msup><mo id="S2.E2.m1.2.2.2.2.1.1.3.1" xref="S2.E2.m1.2.2.2.2.1.1.3.1.cmml">⁢</mo><msub id="S2.E2.m1.2.2.2.2.1.1.3.3" xref="S2.E2.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.3.3.2" xref="S2.E2.m1.2.2.2.2.1.1.3.3.2.cmml">E</mi><mrow id="S2.E2.m1.2.2.2.2.1.1.3.3.3" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.3.3.3.2" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.2.cmml">c</mi><mo id="S2.E2.m1.2.2.2.2.1.1.3.3.3.1" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.2.2.2.2.1.1.3.3.3.3" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.3.cmml">o</mi><mo id="S2.E2.m1.2.2.2.2.1.1.3.3.3.1a" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.2.2.2.2.1.1.3.3.3.4" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.4.cmml">n</mi></mrow></msub></mrow></mrow><mo id="S2.E2.m1.2.2.2.2.2.3" rspace="1.167em" xref="S2.E2.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S2.E2.m1.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.2.cmml"><mi id="S2.E2.m1.2.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.2.2.cmml">V</mi><mo id="S2.E2.m1.2.2.2.2.2.2.1" xref="S2.E2.m1.2.2.2.2.2.2.1.cmml">=</mo><mrow id="S2.E2.m1.2.2.2.2.2.2.3" xref="S2.E2.m1.2.2.2.2.2.2.3.cmml"><msup id="S2.E2.m1.2.2.2.2.2.2.3.2" xref="S2.E2.m1.2.2.2.2.2.2.3.2.cmml"><mi id="S2.E2.m1.2.2.2.2.2.2.3.2.2" xref="S2.E2.m1.2.2.2.2.2.2.3.2.2.cmml">W</mi><mi id="S2.E2.m1.2.2.2.2.2.2.3.2.3" xref="S2.E2.m1.2.2.2.2.2.2.3.2.3.cmml">V</mi></msup><mo id="S2.E2.m1.2.2.2.2.2.2.3.1" xref="S2.E2.m1.2.2.2.2.2.2.3.1.cmml">⁢</mo><msub id="S2.E2.m1.2.2.2.2.2.2.3.3" xref="S2.E2.m1.2.2.2.2.2.2.3.3.cmml"><mi id="S2.E2.m1.2.2.2.2.2.2.3.3.2" xref="S2.E2.m1.2.2.2.2.2.2.3.3.2.cmml">E</mi><mrow id="S2.E2.m1.2.2.2.2.2.2.3.3.3" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.cmml"><mi id="S2.E2.m1.2.2.2.2.2.2.3.3.3.2" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.2.cmml">c</mi><mo id="S2.E2.m1.2.2.2.2.2.2.3.3.3.1" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.2.2.2.2.2.2.3.3.3.3" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.3.cmml">o</mi><mo id="S2.E2.m1.2.2.2.2.2.2.3.3.3.1a" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.1.cmml">⁢</mo><mi id="S2.E2.m1.2.2.2.2.2.2.3.3.3.4" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.4.cmml">n</mi></mrow></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.2b"><apply id="S2.E2.m1.2.2.3.cmml" xref="S2.E2.m1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.3a.cmml" xref="S2.E2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1"><eq id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"></eq><ci id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2">𝑄</ci><apply id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"><times id="S2.E2.m1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1"></times><apply id="S2.E2.m1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2">𝑊</ci><ci id="S2.E2.m1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3">𝑄</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.2">𝐸</ci><apply id="S2.E2.m1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3"><times id="S2.E2.m1.1.1.1.1.3.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3.1"></times><ci id="S2.E2.m1.1.1.1.1.3.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3.2">𝑐</ci><ci id="S2.E2.m1.1.1.1.1.3.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3.3">𝑢</ci><ci id="S2.E2.m1.1.1.1.1.3.3.3.4.cmml" xref="S2.E2.m1.1.1.1.1.3.3.3.4">𝑟</ci></apply></apply></apply></apply><apply id="S2.E2.m1.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.3a.cmml" xref="S2.E2.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.2.2.2.2.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1"><eq id="S2.E2.m1.2.2.2.2.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1"></eq><ci id="S2.E2.m1.2.2.2.2.1.1.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2">𝐾</ci><apply id="S2.E2.m1.2.2.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3"><times id="S2.E2.m1.2.2.2.2.1.1.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.1"></times><apply id="S2.E2.m1.2.2.2.2.1.1.3.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.1.1.3.2.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.2">superscript</csymbol><ci id="S2.E2.m1.2.2.2.2.1.1.3.2.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.2.2">𝑊</ci><ci id="S2.E2.m1.2.2.2.2.1.1.3.2.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.2.3">𝐾</ci></apply><apply id="S2.E2.m1.2.2.2.2.1.1.3.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.2">𝐸</ci><apply id="S2.E2.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3"><times id="S2.E2.m1.2.2.2.2.1.1.3.3.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.1"></times><ci id="S2.E2.m1.2.2.2.2.1.1.3.3.3.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.2">𝑐</ci><ci id="S2.E2.m1.2.2.2.2.1.1.3.3.3.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.3">𝑜</ci><ci id="S2.E2.m1.2.2.2.2.1.1.3.3.3.4.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.3.4">𝑛</ci></apply></apply></apply></apply><apply id="S2.E2.m1.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2"><eq id="S2.E2.m1.2.2.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.1"></eq><ci id="S2.E2.m1.2.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.2">𝑉</ci><apply id="S2.E2.m1.2.2.2.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3"><times id="S2.E2.m1.2.2.2.2.2.2.3.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.1"></times><apply id="S2.E2.m1.2.2.2.2.2.2.3.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.2.2.3.2.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.2">superscript</csymbol><ci id="S2.E2.m1.2.2.2.2.2.2.3.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.2.2">𝑊</ci><ci id="S2.E2.m1.2.2.2.2.2.2.3.2.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.2.3">𝑉</ci></apply><apply id="S2.E2.m1.2.2.2.2.2.2.3.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.2.2.3.3.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.2.2.3.3.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3.2">𝐸</ci><apply id="S2.E2.m1.2.2.2.2.2.2.3.3.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3"><times id="S2.E2.m1.2.2.2.2.2.2.3.3.3.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.1"></times><ci id="S2.E2.m1.2.2.2.2.2.2.3.3.3.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.2">𝑐</ci><ci id="S2.E2.m1.2.2.2.2.2.2.3.3.3.3.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.3">𝑜</ci><ci id="S2.E2.m1.2.2.2.2.2.2.3.3.3.4.cmml" xref="S2.E2.m1.2.2.2.2.2.2.3.3.3.4">𝑛</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.2c">Q=W^{Q}E_{cur},\quad K=W^{K}E_{con},\quad V=W^{V}E_{con}</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.2d">italic_Q = italic_W start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT , italic_K = italic_W start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT , italic_V = italic_W start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="CrossAtt(E_{cur},E_{con})=Softmax(\frac{QK^{T}}{\sqrt{d}})\cdot V" class="ltx_Math" display="block" id="S2.E3.m1.3"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml"><mrow id="S2.E3.m1.3.3.2" xref="S2.E3.m1.3.3.2.cmml"><mi id="S2.E3.m1.3.3.2.4" xref="S2.E3.m1.3.3.2.4.cmml">C</mi><mo id="S2.E3.m1.3.3.2.3" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.5" xref="S2.E3.m1.3.3.2.5.cmml">r</mi><mo id="S2.E3.m1.3.3.2.3a" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.6" xref="S2.E3.m1.3.3.2.6.cmml">o</mi><mo id="S2.E3.m1.3.3.2.3b" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.7" xref="S2.E3.m1.3.3.2.7.cmml">s</mi><mo id="S2.E3.m1.3.3.2.3c" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.8" xref="S2.E3.m1.3.3.2.8.cmml">s</mi><mo id="S2.E3.m1.3.3.2.3d" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.9" xref="S2.E3.m1.3.3.2.9.cmml">A</mi><mo id="S2.E3.m1.3.3.2.3e" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.10" xref="S2.E3.m1.3.3.2.10.cmml">t</mi><mo id="S2.E3.m1.3.3.2.3f" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.11" xref="S2.E3.m1.3.3.2.11.cmml">t</mi><mo id="S2.E3.m1.3.3.2.3g" xref="S2.E3.m1.3.3.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.2.2.2" xref="S2.E3.m1.3.3.2.2.3.cmml"><mo id="S2.E3.m1.3.3.2.2.2.3" stretchy="false" xref="S2.E3.m1.3.3.2.2.3.cmml">(</mo><msub id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.2.cmml">E</mi><mrow id="S2.E3.m1.2.2.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.3.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.3.2" xref="S2.E3.m1.2.2.1.1.1.1.3.2.cmml">c</mi><mo id="S2.E3.m1.2.2.1.1.1.1.3.1" xref="S2.E3.m1.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S2.E3.m1.2.2.1.1.1.1.3.3" xref="S2.E3.m1.2.2.1.1.1.1.3.3.cmml">u</mi><mo id="S2.E3.m1.2.2.1.1.1.1.3.1a" xref="S2.E3.m1.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S2.E3.m1.2.2.1.1.1.1.3.4" xref="S2.E3.m1.2.2.1.1.1.1.3.4.cmml">r</mi></mrow></msub><mo id="S2.E3.m1.3.3.2.2.2.4" xref="S2.E3.m1.3.3.2.2.3.cmml">,</mo><msub id="S2.E3.m1.3.3.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.cmml"><mi id="S2.E3.m1.3.3.2.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.2.cmml">E</mi><mrow id="S2.E3.m1.3.3.2.2.2.2.3" xref="S2.E3.m1.3.3.2.2.2.2.3.cmml"><mi id="S2.E3.m1.3.3.2.2.2.2.3.2" xref="S2.E3.m1.3.3.2.2.2.2.3.2.cmml">c</mi><mo id="S2.E3.m1.3.3.2.2.2.2.3.1" xref="S2.E3.m1.3.3.2.2.2.2.3.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.2.2.2.3.3" xref="S2.E3.m1.3.3.2.2.2.2.3.3.cmml">o</mi><mo id="S2.E3.m1.3.3.2.2.2.2.3.1a" xref="S2.E3.m1.3.3.2.2.2.2.3.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.2.2.2.2.3.4" xref="S2.E3.m1.3.3.2.2.2.2.3.4.cmml">n</mi></mrow></msub><mo id="S2.E3.m1.3.3.2.2.2.5" stretchy="false" xref="S2.E3.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.3" xref="S2.E3.m1.3.3.3.cmml">=</mo><mrow id="S2.E3.m1.3.3.4" xref="S2.E3.m1.3.3.4.cmml"><mrow id="S2.E3.m1.3.3.4.2" xref="S2.E3.m1.3.3.4.2.cmml"><mi id="S2.E3.m1.3.3.4.2.2" xref="S2.E3.m1.3.3.4.2.2.cmml">S</mi><mo id="S2.E3.m1.3.3.4.2.1" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.4.2.3" xref="S2.E3.m1.3.3.4.2.3.cmml">o</mi><mo id="S2.E3.m1.3.3.4.2.1a" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.4.2.4" xref="S2.E3.m1.3.3.4.2.4.cmml">f</mi><mo id="S2.E3.m1.3.3.4.2.1b" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.4.2.5" xref="S2.E3.m1.3.3.4.2.5.cmml">t</mi><mo id="S2.E3.m1.3.3.4.2.1c" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.4.2.6" xref="S2.E3.m1.3.3.4.2.6.cmml">m</mi><mo id="S2.E3.m1.3.3.4.2.1d" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.4.2.7" xref="S2.E3.m1.3.3.4.2.7.cmml">a</mi><mo id="S2.E3.m1.3.3.4.2.1e" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mi id="S2.E3.m1.3.3.4.2.8" xref="S2.E3.m1.3.3.4.2.8.cmml">x</mi><mo id="S2.E3.m1.3.3.4.2.1f" xref="S2.E3.m1.3.3.4.2.1.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.4.2.9.2" xref="S2.E3.m1.1.1.cmml"><mo id="S2.E3.m1.3.3.4.2.9.2.1" stretchy="false" xref="S2.E3.m1.1.1.cmml">(</mo><mfrac id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml"><mrow id="S2.E3.m1.1.1.2" xref="S2.E3.m1.1.1.2.cmml"><mi id="S2.E3.m1.1.1.2.2" xref="S2.E3.m1.1.1.2.2.cmml">Q</mi><mo id="S2.E3.m1.1.1.2.1" xref="S2.E3.m1.1.1.2.1.cmml">⁢</mo><msup id="S2.E3.m1.1.1.2.3" xref="S2.E3.m1.1.1.2.3.cmml"><mi id="S2.E3.m1.1.1.2.3.2" xref="S2.E3.m1.1.1.2.3.2.cmml">K</mi><mi id="S2.E3.m1.1.1.2.3.3" xref="S2.E3.m1.1.1.2.3.3.cmml">T</mi></msup></mrow><msqrt id="S2.E3.m1.1.1.3" xref="S2.E3.m1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.3.2" xref="S2.E3.m1.1.1.3.2.cmml">d</mi></msqrt></mfrac><mo id="S2.E3.m1.3.3.4.2.9.2.2" rspace="0.055em" stretchy="false" xref="S2.E3.m1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.4.1" rspace="0.222em" xref="S2.E3.m1.3.3.4.1.cmml">⋅</mo><mi id="S2.E3.m1.3.3.4.3" xref="S2.E3.m1.3.3.4.3.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3"><eq id="S2.E3.m1.3.3.3.cmml" xref="S2.E3.m1.3.3.3"></eq><apply id="S2.E3.m1.3.3.2.cmml" xref="S2.E3.m1.3.3.2"><times id="S2.E3.m1.3.3.2.3.cmml" xref="S2.E3.m1.3.3.2.3"></times><ci id="S2.E3.m1.3.3.2.4.cmml" xref="S2.E3.m1.3.3.2.4">𝐶</ci><ci id="S2.E3.m1.3.3.2.5.cmml" xref="S2.E3.m1.3.3.2.5">𝑟</ci><ci id="S2.E3.m1.3.3.2.6.cmml" xref="S2.E3.m1.3.3.2.6">𝑜</ci><ci id="S2.E3.m1.3.3.2.7.cmml" xref="S2.E3.m1.3.3.2.7">𝑠</ci><ci id="S2.E3.m1.3.3.2.8.cmml" xref="S2.E3.m1.3.3.2.8">𝑠</ci><ci id="S2.E3.m1.3.3.2.9.cmml" xref="S2.E3.m1.3.3.2.9">𝐴</ci><ci id="S2.E3.m1.3.3.2.10.cmml" xref="S2.E3.m1.3.3.2.10">𝑡</ci><ci id="S2.E3.m1.3.3.2.11.cmml" xref="S2.E3.m1.3.3.2.11">𝑡</ci><interval closure="open" id="S2.E3.m1.3.3.2.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2"><apply id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2">𝐸</ci><apply id="S2.E3.m1.2.2.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3"><times id="S2.E3.m1.2.2.1.1.1.1.3.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3.1"></times><ci id="S2.E3.m1.2.2.1.1.1.1.3.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3.2">𝑐</ci><ci id="S2.E3.m1.2.2.1.1.1.1.3.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3.3">𝑢</ci><ci id="S2.E3.m1.2.2.1.1.1.1.3.4.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3.4">𝑟</ci></apply></apply><apply id="S2.E3.m1.3.3.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.2.2.2.1.cmml" xref="S2.E3.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S2.E3.m1.3.3.2.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2">𝐸</ci><apply id="S2.E3.m1.3.3.2.2.2.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2.2.3"><times id="S2.E3.m1.3.3.2.2.2.2.3.1.cmml" xref="S2.E3.m1.3.3.2.2.2.2.3.1"></times><ci id="S2.E3.m1.3.3.2.2.2.2.3.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2.3.2">𝑐</ci><ci id="S2.E3.m1.3.3.2.2.2.2.3.3.cmml" xref="S2.E3.m1.3.3.2.2.2.2.3.3">𝑜</ci><ci id="S2.E3.m1.3.3.2.2.2.2.3.4.cmml" xref="S2.E3.m1.3.3.2.2.2.2.3.4">𝑛</ci></apply></apply></interval></apply><apply id="S2.E3.m1.3.3.4.cmml" xref="S2.E3.m1.3.3.4"><ci id="S2.E3.m1.3.3.4.1.cmml" xref="S2.E3.m1.3.3.4.1">⋅</ci><apply id="S2.E3.m1.3.3.4.2.cmml" xref="S2.E3.m1.3.3.4.2"><times id="S2.E3.m1.3.3.4.2.1.cmml" xref="S2.E3.m1.3.3.4.2.1"></times><ci id="S2.E3.m1.3.3.4.2.2.cmml" xref="S2.E3.m1.3.3.4.2.2">𝑆</ci><ci id="S2.E3.m1.3.3.4.2.3.cmml" xref="S2.E3.m1.3.3.4.2.3">𝑜</ci><ci id="S2.E3.m1.3.3.4.2.4.cmml" xref="S2.E3.m1.3.3.4.2.4">𝑓</ci><ci id="S2.E3.m1.3.3.4.2.5.cmml" xref="S2.E3.m1.3.3.4.2.5">𝑡</ci><ci id="S2.E3.m1.3.3.4.2.6.cmml" xref="S2.E3.m1.3.3.4.2.6">𝑚</ci><ci id="S2.E3.m1.3.3.4.2.7.cmml" xref="S2.E3.m1.3.3.4.2.7">𝑎</ci><ci id="S2.E3.m1.3.3.4.2.8.cmml" xref="S2.E3.m1.3.3.4.2.8">𝑥</ci><apply id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.3.3.4.2.9.2"><divide id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.3.3.4.2.9.2"></divide><apply id="S2.E3.m1.1.1.2.cmml" xref="S2.E3.m1.1.1.2"><times id="S2.E3.m1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.2.1"></times><ci id="S2.E3.m1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.2.2">𝑄</ci><apply id="S2.E3.m1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.2.3.1.cmml" xref="S2.E3.m1.1.1.2.3">superscript</csymbol><ci id="S2.E3.m1.1.1.2.3.2.cmml" xref="S2.E3.m1.1.1.2.3.2">𝐾</ci><ci id="S2.E3.m1.1.1.2.3.3.cmml" xref="S2.E3.m1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.E3.m1.1.1.3.cmml" xref="S2.E3.m1.1.1.3"><root id="S2.E3.m1.1.1.3a.cmml" xref="S2.E3.m1.1.1.3"></root><ci id="S2.E3.m1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.3.2">𝑑</ci></apply></apply></apply><ci id="S2.E3.m1.3.3.4.3.cmml" xref="S2.E3.m1.3.3.4.3">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">CrossAtt(E_{cur},E_{con})=Softmax(\frac{QK^{T}}{\sqrt{d}})\cdot V</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.3d">italic_C italic_r italic_o italic_s italic_s italic_A italic_t italic_t ( italic_E start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT ) = italic_S italic_o italic_f italic_t italic_m italic_a italic_x ( divide start_ARG italic_Q italic_K start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT end_ARG start_ARG square-root start_ARG italic_d end_ARG end_ARG ) ⋅ italic_V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.13">where <math alttext="l" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mi id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">italic_l</annotation></semantics></math> is the context length, <math alttext="U_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><msub id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml"><mi id="S2.SS2.p3.2.m2.1.1.2" xref="S2.SS2.p3.2.m2.1.1.2.cmml">U</mi><mi id="S2.SS2.p3.2.m2.1.1.3" xref="S2.SS2.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><apply id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.1.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p3.2.m2.1.1.2.cmml" xref="S2.SS2.p3.2.m2.1.1.2">𝑈</ci><ci id="S2.SS2.p3.2.m2.1.1.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">U_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is current text and <math alttext="U_{con}" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m3.1"><semantics id="S2.SS2.p3.3.m3.1a"><msub id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml"><mi id="S2.SS2.p3.3.m3.1.1.2" xref="S2.SS2.p3.3.m3.1.1.2.cmml">U</mi><mrow id="S2.SS2.p3.3.m3.1.1.3" xref="S2.SS2.p3.3.m3.1.1.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.2" xref="S2.SS2.p3.3.m3.1.1.3.2.cmml">c</mi><mo id="S2.SS2.p3.3.m3.1.1.3.1" xref="S2.SS2.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.3.m3.1.1.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.cmml">o</mi><mo id="S2.SS2.p3.3.m3.1.1.3.1a" xref="S2.SS2.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.3.m3.1.1.3.4" xref="S2.SS2.p3.3.m3.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><apply id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2">𝑈</ci><apply id="S2.SS2.p3.3.m3.1.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3"><times id="S2.SS2.p3.3.m3.1.1.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.1"></times><ci id="S2.SS2.p3.3.m3.1.1.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2">𝑐</ci><ci id="S2.SS2.p3.3.m3.1.1.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3">𝑜</ci><ci id="S2.SS2.p3.3.m3.1.1.3.4.cmml" xref="S2.SS2.p3.3.m3.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">U_{con}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m3.1d">italic_U start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT</annotation></semantics></math> is context text. <math alttext="E_{cur}" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m4.1"><semantics id="S2.SS2.p3.4.m4.1a"><msub id="S2.SS2.p3.4.m4.1.1" xref="S2.SS2.p3.4.m4.1.1.cmml"><mi id="S2.SS2.p3.4.m4.1.1.2" xref="S2.SS2.p3.4.m4.1.1.2.cmml">E</mi><mrow id="S2.SS2.p3.4.m4.1.1.3" xref="S2.SS2.p3.4.m4.1.1.3.cmml"><mi id="S2.SS2.p3.4.m4.1.1.3.2" xref="S2.SS2.p3.4.m4.1.1.3.2.cmml">c</mi><mo id="S2.SS2.p3.4.m4.1.1.3.1" xref="S2.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.4.m4.1.1.3.3" xref="S2.SS2.p3.4.m4.1.1.3.3.cmml">u</mi><mo id="S2.SS2.p3.4.m4.1.1.3.1a" xref="S2.SS2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.4.m4.1.1.3.4" xref="S2.SS2.p3.4.m4.1.1.3.4.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.1b"><apply id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p3.4.m4.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.2">𝐸</ci><apply id="S2.SS2.p3.4.m4.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3"><times id="S2.SS2.p3.4.m4.1.1.3.1.cmml" xref="S2.SS2.p3.4.m4.1.1.3.1"></times><ci id="S2.SS2.p3.4.m4.1.1.3.2.cmml" xref="S2.SS2.p3.4.m4.1.1.3.2">𝑐</ci><ci id="S2.SS2.p3.4.m4.1.1.3.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3.3">𝑢</ci><ci id="S2.SS2.p3.4.m4.1.1.3.4.cmml" xref="S2.SS2.p3.4.m4.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.1c">E_{cur}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m4.1d">italic_E start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="E_{con}" class="ltx_Math" display="inline" id="S2.SS2.p3.5.m5.1"><semantics id="S2.SS2.p3.5.m5.1a"><msub id="S2.SS2.p3.5.m5.1.1" xref="S2.SS2.p3.5.m5.1.1.cmml"><mi id="S2.SS2.p3.5.m5.1.1.2" xref="S2.SS2.p3.5.m5.1.1.2.cmml">E</mi><mrow id="S2.SS2.p3.5.m5.1.1.3" xref="S2.SS2.p3.5.m5.1.1.3.cmml"><mi id="S2.SS2.p3.5.m5.1.1.3.2" xref="S2.SS2.p3.5.m5.1.1.3.2.cmml">c</mi><mo id="S2.SS2.p3.5.m5.1.1.3.1" xref="S2.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.5.m5.1.1.3.3" xref="S2.SS2.p3.5.m5.1.1.3.3.cmml">o</mi><mo id="S2.SS2.p3.5.m5.1.1.3.1a" xref="S2.SS2.p3.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.5.m5.1.1.3.4" xref="S2.SS2.p3.5.m5.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m5.1b"><apply id="S2.SS2.p3.5.m5.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.5.m5.1.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p3.5.m5.1.1.2.cmml" xref="S2.SS2.p3.5.m5.1.1.2">𝐸</ci><apply id="S2.SS2.p3.5.m5.1.1.3.cmml" xref="S2.SS2.p3.5.m5.1.1.3"><times id="S2.SS2.p3.5.m5.1.1.3.1.cmml" xref="S2.SS2.p3.5.m5.1.1.3.1"></times><ci id="S2.SS2.p3.5.m5.1.1.3.2.cmml" xref="S2.SS2.p3.5.m5.1.1.3.2">𝑐</ci><ci id="S2.SS2.p3.5.m5.1.1.3.3.cmml" xref="S2.SS2.p3.5.m5.1.1.3.3">𝑜</ci><ci id="S2.SS2.p3.5.m5.1.1.3.4.cmml" xref="S2.SS2.p3.5.m5.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m5.1c">E_{con}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.5.m5.1d">italic_E start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT</annotation></semantics></math> denote the SFTs from current text and context text respectively. <math alttext="W^{K}" class="ltx_Math" display="inline" id="S2.SS2.p3.6.m6.1"><semantics id="S2.SS2.p3.6.m6.1a"><msup id="S2.SS2.p3.6.m6.1.1" xref="S2.SS2.p3.6.m6.1.1.cmml"><mi id="S2.SS2.p3.6.m6.1.1.2" xref="S2.SS2.p3.6.m6.1.1.2.cmml">W</mi><mi id="S2.SS2.p3.6.m6.1.1.3" xref="S2.SS2.p3.6.m6.1.1.3.cmml">K</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m6.1b"><apply id="S2.SS2.p3.6.m6.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.6.m6.1.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1">superscript</csymbol><ci id="S2.SS2.p3.6.m6.1.1.2.cmml" xref="S2.SS2.p3.6.m6.1.1.2">𝑊</ci><ci id="S2.SS2.p3.6.m6.1.1.3.cmml" xref="S2.SS2.p3.6.m6.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m6.1c">W^{K}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.6.m6.1d">italic_W start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="W^{Q}" class="ltx_Math" display="inline" id="S2.SS2.p3.7.m7.1"><semantics id="S2.SS2.p3.7.m7.1a"><msup id="S2.SS2.p3.7.m7.1.1" xref="S2.SS2.p3.7.m7.1.1.cmml"><mi id="S2.SS2.p3.7.m7.1.1.2" xref="S2.SS2.p3.7.m7.1.1.2.cmml">W</mi><mi id="S2.SS2.p3.7.m7.1.1.3" xref="S2.SS2.p3.7.m7.1.1.3.cmml">Q</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m7.1b"><apply id="S2.SS2.p3.7.m7.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1">superscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.2.cmml" xref="S2.SS2.p3.7.m7.1.1.2">𝑊</ci><ci id="S2.SS2.p3.7.m7.1.1.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m7.1c">W^{Q}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.7.m7.1d">italic_W start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="W^{V}" class="ltx_Math" display="inline" id="S2.SS2.p3.8.m8.1"><semantics id="S2.SS2.p3.8.m8.1a"><msup id="S2.SS2.p3.8.m8.1.1" xref="S2.SS2.p3.8.m8.1.1.cmml"><mi id="S2.SS2.p3.8.m8.1.1.2" xref="S2.SS2.p3.8.m8.1.1.2.cmml">W</mi><mi id="S2.SS2.p3.8.m8.1.1.3" xref="S2.SS2.p3.8.m8.1.1.3.cmml">V</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.8.m8.1b"><apply id="S2.SS2.p3.8.m8.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.8.m8.1.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1">superscript</csymbol><ci id="S2.SS2.p3.8.m8.1.1.2.cmml" xref="S2.SS2.p3.8.m8.1.1.2">𝑊</ci><ci id="S2.SS2.p3.8.m8.1.1.3.cmml" xref="S2.SS2.p3.8.m8.1.1.3">𝑉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.8.m8.1c">W^{V}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.8.m8.1d">italic_W start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT</annotation></semantics></math> represent the weight matrix of attention key, query and value respectively. Our implementation adopts a shared text encoder for both current text and context text. The cross-attention mechanism is applied to the text encoder outputs with style-related text features (STFs) from current text <math alttext="E_{cur}" class="ltx_Math" display="inline" id="S2.SS2.p3.9.m9.1"><semantics id="S2.SS2.p3.9.m9.1a"><msub id="S2.SS2.p3.9.m9.1.1" xref="S2.SS2.p3.9.m9.1.1.cmml"><mi id="S2.SS2.p3.9.m9.1.1.2" xref="S2.SS2.p3.9.m9.1.1.2.cmml">E</mi><mrow id="S2.SS2.p3.9.m9.1.1.3" xref="S2.SS2.p3.9.m9.1.1.3.cmml"><mi id="S2.SS2.p3.9.m9.1.1.3.2" xref="S2.SS2.p3.9.m9.1.1.3.2.cmml">c</mi><mo id="S2.SS2.p3.9.m9.1.1.3.1" xref="S2.SS2.p3.9.m9.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.9.m9.1.1.3.3" xref="S2.SS2.p3.9.m9.1.1.3.3.cmml">u</mi><mo id="S2.SS2.p3.9.m9.1.1.3.1a" xref="S2.SS2.p3.9.m9.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.9.m9.1.1.3.4" xref="S2.SS2.p3.9.m9.1.1.3.4.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.9.m9.1b"><apply id="S2.SS2.p3.9.m9.1.1.cmml" xref="S2.SS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.9.m9.1.1.1.cmml" xref="S2.SS2.p3.9.m9.1.1">subscript</csymbol><ci id="S2.SS2.p3.9.m9.1.1.2.cmml" xref="S2.SS2.p3.9.m9.1.1.2">𝐸</ci><apply id="S2.SS2.p3.9.m9.1.1.3.cmml" xref="S2.SS2.p3.9.m9.1.1.3"><times id="S2.SS2.p3.9.m9.1.1.3.1.cmml" xref="S2.SS2.p3.9.m9.1.1.3.1"></times><ci id="S2.SS2.p3.9.m9.1.1.3.2.cmml" xref="S2.SS2.p3.9.m9.1.1.3.2">𝑐</ci><ci id="S2.SS2.p3.9.m9.1.1.3.3.cmml" xref="S2.SS2.p3.9.m9.1.1.3.3">𝑢</ci><ci id="S2.SS2.p3.9.m9.1.1.3.4.cmml" xref="S2.SS2.p3.9.m9.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.9.m9.1c">E_{cur}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.9.m9.1d">italic_E start_POSTSUBSCRIPT italic_c italic_u italic_r end_POSTSUBSCRIPT</annotation></semantics></math> as query <math alttext="Q" class="ltx_Math" display="inline" id="S2.SS2.p3.10.m10.1"><semantics id="S2.SS2.p3.10.m10.1a"><mi id="S2.SS2.p3.10.m10.1.1" xref="S2.SS2.p3.10.m10.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.10.m10.1b"><ci id="S2.SS2.p3.10.m10.1.1.cmml" xref="S2.SS2.p3.10.m10.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.10.m10.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.10.m10.1d">italic_Q</annotation></semantics></math> and STFs from context <math alttext="E_{con}" class="ltx_Math" display="inline" id="S2.SS2.p3.11.m11.1"><semantics id="S2.SS2.p3.11.m11.1a"><msub id="S2.SS2.p3.11.m11.1.1" xref="S2.SS2.p3.11.m11.1.1.cmml"><mi id="S2.SS2.p3.11.m11.1.1.2" xref="S2.SS2.p3.11.m11.1.1.2.cmml">E</mi><mrow id="S2.SS2.p3.11.m11.1.1.3" xref="S2.SS2.p3.11.m11.1.1.3.cmml"><mi id="S2.SS2.p3.11.m11.1.1.3.2" xref="S2.SS2.p3.11.m11.1.1.3.2.cmml">c</mi><mo id="S2.SS2.p3.11.m11.1.1.3.1" xref="S2.SS2.p3.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.11.m11.1.1.3.3" xref="S2.SS2.p3.11.m11.1.1.3.3.cmml">o</mi><mo id="S2.SS2.p3.11.m11.1.1.3.1a" xref="S2.SS2.p3.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S2.SS2.p3.11.m11.1.1.3.4" xref="S2.SS2.p3.11.m11.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.11.m11.1b"><apply id="S2.SS2.p3.11.m11.1.1.cmml" xref="S2.SS2.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.11.m11.1.1.1.cmml" xref="S2.SS2.p3.11.m11.1.1">subscript</csymbol><ci id="S2.SS2.p3.11.m11.1.1.2.cmml" xref="S2.SS2.p3.11.m11.1.1.2">𝐸</ci><apply id="S2.SS2.p3.11.m11.1.1.3.cmml" xref="S2.SS2.p3.11.m11.1.1.3"><times id="S2.SS2.p3.11.m11.1.1.3.1.cmml" xref="S2.SS2.p3.11.m11.1.1.3.1"></times><ci id="S2.SS2.p3.11.m11.1.1.3.2.cmml" xref="S2.SS2.p3.11.m11.1.1.3.2">𝑐</ci><ci id="S2.SS2.p3.11.m11.1.1.3.3.cmml" xref="S2.SS2.p3.11.m11.1.1.3.3">𝑜</ci><ci id="S2.SS2.p3.11.m11.1.1.3.4.cmml" xref="S2.SS2.p3.11.m11.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.11.m11.1c">E_{con}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.11.m11.1d">italic_E start_POSTSUBSCRIPT italic_c italic_o italic_n end_POSTSUBSCRIPT</annotation></semantics></math> as key <math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p3.12.m12.1"><semantics id="S2.SS2.p3.12.m12.1a"><mi id="S2.SS2.p3.12.m12.1.1" xref="S2.SS2.p3.12.m12.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.12.m12.1b"><ci id="S2.SS2.p3.12.m12.1.1.cmml" xref="S2.SS2.p3.12.m12.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.12.m12.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.12.m12.1d">italic_K</annotation></semantics></math> and value <math alttext="V" class="ltx_Math" display="inline" id="S2.SS2.p3.13.m13.1"><semantics id="S2.SS2.p3.13.m13.1a"><mi id="S2.SS2.p3.13.m13.1.1" xref="S2.SS2.p3.13.m13.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.13.m13.1b"><ci id="S2.SS2.p3.13.m13.1.1.cmml" xref="S2.SS2.p3.13.m13.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.13.m13.1c">V</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.13.m13.1d">italic_V</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">In short, the proposed CA-CLAP model serves as an encoding model during both indexing and retrieval phases of RAG, transferring multi-modal inputs into a shared feature space based on context-aware contrastive learning. Therefore context-aware SFTs can retrieve the relevant audios as speech prompts.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.9">During training, as illustrated in the left part of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S2.F2" title="Figure 2 ‣ 2.2 Context-Aware Contrastive Language-audio Pretraining (CA-CLAP) ‣ 2 Methodology ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">2</span></a>, given N (speech, text) pairs as input, CA-CLAP computes an <math alttext="N\times N" class="ltx_Math" display="inline" id="S2.SS2.p5.1.m1.1"><semantics id="S2.SS2.p5.1.m1.1a"><mrow id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml"><mi id="S2.SS2.p5.1.m1.1.1.2" xref="S2.SS2.p5.1.m1.1.1.2.cmml">N</mi><mo id="S2.SS2.p5.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS2.p5.1.m1.1.1.1.cmml">×</mo><mi id="S2.SS2.p5.1.m1.1.1.3" xref="S2.SS2.p5.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><apply id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1"><times id="S2.SS2.p5.1.m1.1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1.1"></times><ci id="S2.SS2.p5.1.m1.1.1.2.cmml" xref="S2.SS2.p5.1.m1.1.1.2">𝑁</ci><ci id="S2.SS2.p5.1.m1.1.1.3.cmml" xref="S2.SS2.p5.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">N\times N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.1.m1.1d">italic_N × italic_N</annotation></semantics></math> matrix M. The value at the <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p5.2.m2.1"><semantics id="S2.SS2.p5.2.m2.1a"><mi id="S2.SS2.p5.2.m2.1.1" xref="S2.SS2.p5.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.2.m2.1b"><ci id="S2.SS2.p5.2.m2.1.1.cmml" xref="S2.SS2.p5.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.2.m2.1d">italic_i</annotation></semantics></math>-th row and <math alttext="j" class="ltx_Math" display="inline" id="S2.SS2.p5.3.m3.1"><semantics id="S2.SS2.p5.3.m3.1a"><mi id="S2.SS2.p5.3.m3.1.1" xref="S2.SS2.p5.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.3.m3.1b"><ci id="S2.SS2.p5.3.m3.1.1.cmml" xref="S2.SS2.p5.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.3.m3.1d">italic_j</annotation></semantics></math>-th column represents the cosine similarity between the text embedding <math alttext="T_{i}" class="ltx_Math" display="inline" id="S2.SS2.p5.4.m4.1"><semantics id="S2.SS2.p5.4.m4.1a"><msub id="S2.SS2.p5.4.m4.1.1" xref="S2.SS2.p5.4.m4.1.1.cmml"><mi id="S2.SS2.p5.4.m4.1.1.2" xref="S2.SS2.p5.4.m4.1.1.2.cmml">T</mi><mi id="S2.SS2.p5.4.m4.1.1.3" xref="S2.SS2.p5.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.4.m4.1b"><apply id="S2.SS2.p5.4.m4.1.1.cmml" xref="S2.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p5.4.m4.1.1.1.cmml" xref="S2.SS2.p5.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p5.4.m4.1.1.2.cmml" xref="S2.SS2.p5.4.m4.1.1.2">𝑇</ci><ci id="S2.SS2.p5.4.m4.1.1.3.cmml" xref="S2.SS2.p5.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.4.m4.1c">T_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.4.m4.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> of the <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p5.5.m5.1"><semantics id="S2.SS2.p5.5.m5.1a"><mi id="S2.SS2.p5.5.m5.1.1" xref="S2.SS2.p5.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.5.m5.1b"><ci id="S2.SS2.p5.5.m5.1.1.cmml" xref="S2.SS2.p5.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.5.m5.1d">italic_i</annotation></semantics></math>-th text, obtained by the CA-CLAP text encoder, and the audio embedding <math alttext="A_{j}" class="ltx_Math" display="inline" id="S2.SS2.p5.6.m6.1"><semantics id="S2.SS2.p5.6.m6.1a"><msub id="S2.SS2.p5.6.m6.1.1" xref="S2.SS2.p5.6.m6.1.1.cmml"><mi id="S2.SS2.p5.6.m6.1.1.2" xref="S2.SS2.p5.6.m6.1.1.2.cmml">A</mi><mi id="S2.SS2.p5.6.m6.1.1.3" xref="S2.SS2.p5.6.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.6.m6.1b"><apply id="S2.SS2.p5.6.m6.1.1.cmml" xref="S2.SS2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p5.6.m6.1.1.1.cmml" xref="S2.SS2.p5.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p5.6.m6.1.1.2.cmml" xref="S2.SS2.p5.6.m6.1.1.2">𝐴</ci><ci id="S2.SS2.p5.6.m6.1.1.3.cmml" xref="S2.SS2.p5.6.m6.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.6.m6.1c">A_{j}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.6.m6.1d">italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> of the <math alttext="j" class="ltx_Math" display="inline" id="S2.SS2.p5.7.m7.1"><semantics id="S2.SS2.p5.7.m7.1a"><mi id="S2.SS2.p5.7.m7.1.1" xref="S2.SS2.p5.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.7.m7.1b"><ci id="S2.SS2.p5.7.m7.1.1.cmml" xref="S2.SS2.p5.7.m7.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.7.m7.1c">j</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.7.m7.1d">italic_j</annotation></semantics></math>-th speech, obtained by the CA-CLAP audio encoder. The text and audio encoders strive to maximize the cosine similarity for the <math alttext="N" class="ltx_Math" display="inline" id="S2.SS2.p5.8.m8.1"><semantics id="S2.SS2.p5.8.m8.1a"><mi id="S2.SS2.p5.8.m8.1.1" xref="S2.SS2.p5.8.m8.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.8.m8.1b"><ci id="S2.SS2.p5.8.m8.1.1.cmml" xref="S2.SS2.p5.8.m8.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.8.m8.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.8.m8.1d">italic_N</annotation></semantics></math> correct pairs in the batch and minimize it for the <math alttext="N^{2}-N" class="ltx_Math" display="inline" id="S2.SS2.p5.9.m9.1"><semantics id="S2.SS2.p5.9.m9.1a"><mrow id="S2.SS2.p5.9.m9.1.1" xref="S2.SS2.p5.9.m9.1.1.cmml"><msup id="S2.SS2.p5.9.m9.1.1.2" xref="S2.SS2.p5.9.m9.1.1.2.cmml"><mi id="S2.SS2.p5.9.m9.1.1.2.2" xref="S2.SS2.p5.9.m9.1.1.2.2.cmml">N</mi><mn id="S2.SS2.p5.9.m9.1.1.2.3" xref="S2.SS2.p5.9.m9.1.1.2.3.cmml">2</mn></msup><mo id="S2.SS2.p5.9.m9.1.1.1" xref="S2.SS2.p5.9.m9.1.1.1.cmml">−</mo><mi id="S2.SS2.p5.9.m9.1.1.3" xref="S2.SS2.p5.9.m9.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.9.m9.1b"><apply id="S2.SS2.p5.9.m9.1.1.cmml" xref="S2.SS2.p5.9.m9.1.1"><minus id="S2.SS2.p5.9.m9.1.1.1.cmml" xref="S2.SS2.p5.9.m9.1.1.1"></minus><apply id="S2.SS2.p5.9.m9.1.1.2.cmml" xref="S2.SS2.p5.9.m9.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p5.9.m9.1.1.2.1.cmml" xref="S2.SS2.p5.9.m9.1.1.2">superscript</csymbol><ci id="S2.SS2.p5.9.m9.1.1.2.2.cmml" xref="S2.SS2.p5.9.m9.1.1.2.2">𝑁</ci><cn id="S2.SS2.p5.9.m9.1.1.2.3.cmml" type="integer" xref="S2.SS2.p5.9.m9.1.1.2.3">2</cn></apply><ci id="S2.SS2.p5.9.m9.1.1.3.cmml" xref="S2.SS2.p5.9.m9.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.9.m9.1c">N^{2}-N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.9.m9.1d">italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_N</annotation></semantics></math> incorrect pairings.</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1">The model is trained with the contrastive learning paradigm between the audio and text embeddings in pairs, following the same loss function as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib23" title="">23</a>]</cite>:</p>
</div>
<div class="ltx_para" id="S2.SS2.p7">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx1">
<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle L=\frac{1}{2N}\sum_{i=1}^{N}(\log\frac{\exp(A_{i}\cdot T_{i}/%
\tau)}{\sum_{j=1}^{N}\exp(A_{i}\cdot T_{j}/\tau)}" class="ltx_math_unparsed" display="inline" id="S2.Ex1.m1.4"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4b"><mi id="S2.Ex1.m1.4.5" mathsize="80%">L</mi><mo id="S2.Ex1.m1.4.6" mathsize="80%">=</mo><mstyle displaystyle="true" id="S2.Ex1.m1.4.7"><mfrac id="S2.Ex1.m1.4.7a"><mn id="S2.Ex1.m1.4.7.2" mathsize="80%">1</mn><mrow id="S2.Ex1.m1.4.7.3"><mn id="S2.Ex1.m1.4.7.3.2" mathsize="80%">2</mn><mo id="S2.Ex1.m1.4.7.3.1">⁢</mo><mi id="S2.Ex1.m1.4.7.3.3" mathsize="80%">N</mi></mrow></mfrac></mstyle><mstyle displaystyle="true" id="S2.Ex1.m1.4.8"><munderover id="S2.Ex1.m1.4.8a"><mo id="S2.Ex1.m1.4.8.2.2" maxsize="80%" minsize="80%" movablelimits="false" stretchy="true">∑</mo><mrow id="S2.Ex1.m1.4.8.2.3"><mi id="S2.Ex1.m1.4.8.2.3.2" mathsize="80%">i</mi><mo id="S2.Ex1.m1.4.8.2.3.1" mathsize="80%">=</mo><mn id="S2.Ex1.m1.4.8.2.3.3" mathsize="80%">1</mn></mrow><mi id="S2.Ex1.m1.4.8.3" mathsize="80%">N</mi></munderover></mstyle><mrow id="S2.Ex1.m1.4.9"><mo id="S2.Ex1.m1.4.9.1" maxsize="80%" minsize="80%">(</mo><mi id="S2.Ex1.m1.4.9.2" mathsize="80%">log</mi><mstyle displaystyle="true" id="S2.Ex1.m1.4.4"><mfrac id="S2.Ex1.m1.4.4a"><mrow id="S2.Ex1.m1.2.2.2.2"><mi id="S2.Ex1.m1.1.1.1.1" mathsize="80%">exp</mi><mo id="S2.Ex1.m1.2.2.2.2a">⁡</mo><mrow id="S2.Ex1.m1.2.2.2.2.1"><mo id="S2.Ex1.m1.2.2.2.2.1.2" maxsize="80%" minsize="80%">(</mo><mrow id="S2.Ex1.m1.2.2.2.2.1.1"><mrow id="S2.Ex1.m1.2.2.2.2.1.1.2"><msub id="S2.Ex1.m1.2.2.2.2.1.1.2.2"><mi id="S2.Ex1.m1.2.2.2.2.1.1.2.2.2" mathsize="80%">A</mi><mi id="S2.Ex1.m1.2.2.2.2.1.1.2.2.3" mathsize="80%">i</mi></msub><mo id="S2.Ex1.m1.2.2.2.2.1.1.2.1" lspace="0.222em" mathsize="80%" rspace="0.222em">⋅</mo><msub id="S2.Ex1.m1.2.2.2.2.1.1.2.3"><mi id="S2.Ex1.m1.2.2.2.2.1.1.2.3.2" mathsize="80%">T</mi><mi id="S2.Ex1.m1.2.2.2.2.1.1.2.3.3" mathsize="80%">i</mi></msub></mrow><mo id="S2.Ex1.m1.2.2.2.2.1.1.1" maxsize="80%" minsize="80%" stretchy="true" symmetric="true">/</mo><mi id="S2.Ex1.m1.2.2.2.2.1.1.3" mathsize="80%">τ</mi></mrow><mo id="S2.Ex1.m1.2.2.2.2.1.3" maxsize="80%" minsize="80%">)</mo></mrow></mrow><mrow id="S2.Ex1.m1.4.4.4"><msubsup id="S2.Ex1.m1.4.4.4.3"><mo id="S2.Ex1.m1.4.4.4.3.2.2" maxsize="80%" minsize="80%" stretchy="true">∑</mo><mrow id="S2.Ex1.m1.4.4.4.3.2.3"><mi id="S2.Ex1.m1.4.4.4.3.2.3.2" mathsize="80%">j</mi><mo id="S2.Ex1.m1.4.4.4.3.2.3.1" mathsize="80%">=</mo><mn id="S2.Ex1.m1.4.4.4.3.2.3.3" mathsize="80%">1</mn></mrow><mi id="S2.Ex1.m1.4.4.4.3.3" mathsize="80%">N</mi></msubsup><mrow id="S2.Ex1.m1.4.4.4.2.1"><mi id="S2.Ex1.m1.3.3.3.1" mathsize="80%">exp</mi><mo id="S2.Ex1.m1.4.4.4.2.1a">⁡</mo><mrow id="S2.Ex1.m1.4.4.4.2.1.1"><mo id="S2.Ex1.m1.4.4.4.2.1.1.2" maxsize="80%" minsize="80%">(</mo><mrow id="S2.Ex1.m1.4.4.4.2.1.1.1"><mrow id="S2.Ex1.m1.4.4.4.2.1.1.1.2"><msub id="S2.Ex1.m1.4.4.4.2.1.1.1.2.2"><mi id="S2.Ex1.m1.4.4.4.2.1.1.1.2.2.2" mathsize="80%">A</mi><mi id="S2.Ex1.m1.4.4.4.2.1.1.1.2.2.3" mathsize="80%">i</mi></msub><mo id="S2.Ex1.m1.4.4.4.2.1.1.1.2.1" lspace="0.222em" mathsize="80%" rspace="0.222em">⋅</mo><msub id="S2.Ex1.m1.4.4.4.2.1.1.1.2.3"><mi id="S2.Ex1.m1.4.4.4.2.1.1.1.2.3.2" mathsize="80%">T</mi><mi id="S2.Ex1.m1.4.4.4.2.1.1.1.2.3.3" mathsize="80%">j</mi></msub></mrow><mo id="S2.Ex1.m1.4.4.4.2.1.1.1.1" maxsize="80%" minsize="80%" stretchy="true" symmetric="true">/</mo><mi id="S2.Ex1.m1.4.4.4.2.1.1.1.3" mathsize="80%">τ</mi></mrow><mo id="S2.Ex1.m1.4.4.4.2.1.1.3" maxsize="80%" minsize="80%">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\displaystyle L=\frac{1}{2N}\sum_{i=1}^{N}(\log\frac{\exp(A_{i}\cdot T_{i}/%
\tau)}{\sum_{j=1}^{N}\exp(A_{i}\cdot T_{j}/\tau)}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.4d">italic_L = divide start_ARG 1 end_ARG start_ARG 2 italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( roman_log divide start_ARG roman_exp ( italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_τ ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_exp ( italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT / italic_τ ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle+\log\frac{\exp(T_{i}\cdot A_{i}/\tau)}{\sum_{j=1}^{N}\exp(T_{i}%
\cdot A_{j}/\tau)})" class="ltx_math_unparsed" display="inline" id="S2.E4.m1.4"><semantics id="S2.E4.m1.4a"><mrow id="S2.E4.m1.4b"><mo id="S2.E4.m1.4.5" mathsize="80%">+</mo><mi id="S2.E4.m1.4.6" mathsize="80%">log</mi><mstyle displaystyle="true" id="S2.E4.m1.4.4"><mfrac id="S2.E4.m1.4.4a"><mrow id="S2.E4.m1.2.2.2.2"><mi id="S2.E4.m1.1.1.1.1" mathsize="80%">exp</mi><mo id="S2.E4.m1.2.2.2.2a">⁡</mo><mrow id="S2.E4.m1.2.2.2.2.1"><mo id="S2.E4.m1.2.2.2.2.1.2" maxsize="80%" minsize="80%">(</mo><mrow id="S2.E4.m1.2.2.2.2.1.1"><mrow id="S2.E4.m1.2.2.2.2.1.1.2"><msub id="S2.E4.m1.2.2.2.2.1.1.2.2"><mi id="S2.E4.m1.2.2.2.2.1.1.2.2.2" mathsize="80%">T</mi><mi id="S2.E4.m1.2.2.2.2.1.1.2.2.3" mathsize="80%">i</mi></msub><mo id="S2.E4.m1.2.2.2.2.1.1.2.1" lspace="0.222em" mathsize="80%" rspace="0.222em">⋅</mo><msub id="S2.E4.m1.2.2.2.2.1.1.2.3"><mi id="S2.E4.m1.2.2.2.2.1.1.2.3.2" mathsize="80%">A</mi><mi id="S2.E4.m1.2.2.2.2.1.1.2.3.3" mathsize="80%">i</mi></msub></mrow><mo id="S2.E4.m1.2.2.2.2.1.1.1" maxsize="80%" minsize="80%" stretchy="true" symmetric="true">/</mo><mi id="S2.E4.m1.2.2.2.2.1.1.3" mathsize="80%">τ</mi></mrow><mo id="S2.E4.m1.2.2.2.2.1.3" maxsize="80%" minsize="80%">)</mo></mrow></mrow><mrow id="S2.E4.m1.4.4.4"><msubsup id="S2.E4.m1.4.4.4.3"><mo id="S2.E4.m1.4.4.4.3.2.2" maxsize="80%" minsize="80%" stretchy="true">∑</mo><mrow id="S2.E4.m1.4.4.4.3.2.3"><mi id="S2.E4.m1.4.4.4.3.2.3.2" mathsize="80%">j</mi><mo id="S2.E4.m1.4.4.4.3.2.3.1" mathsize="80%">=</mo><mn id="S2.E4.m1.4.4.4.3.2.3.3" mathsize="80%">1</mn></mrow><mi id="S2.E4.m1.4.4.4.3.3" mathsize="80%">N</mi></msubsup><mrow id="S2.E4.m1.4.4.4.2.1"><mi id="S2.E4.m1.3.3.3.1" mathsize="80%">exp</mi><mo id="S2.E4.m1.4.4.4.2.1a">⁡</mo><mrow id="S2.E4.m1.4.4.4.2.1.1"><mo id="S2.E4.m1.4.4.4.2.1.1.2" maxsize="80%" minsize="80%">(</mo><mrow id="S2.E4.m1.4.4.4.2.1.1.1"><mrow id="S2.E4.m1.4.4.4.2.1.1.1.2"><msub id="S2.E4.m1.4.4.4.2.1.1.1.2.2"><mi id="S2.E4.m1.4.4.4.2.1.1.1.2.2.2" mathsize="80%">T</mi><mi id="S2.E4.m1.4.4.4.2.1.1.1.2.2.3" mathsize="80%">i</mi></msub><mo id="S2.E4.m1.4.4.4.2.1.1.1.2.1" lspace="0.222em" mathsize="80%" rspace="0.222em">⋅</mo><msub id="S2.E4.m1.4.4.4.2.1.1.1.2.3"><mi id="S2.E4.m1.4.4.4.2.1.1.1.2.3.2" mathsize="80%">A</mi><mi id="S2.E4.m1.4.4.4.2.1.1.1.2.3.3" mathsize="80%">j</mi></msub></mrow><mo id="S2.E4.m1.4.4.4.2.1.1.1.1" maxsize="80%" minsize="80%" stretchy="true" symmetric="true">/</mo><mi id="S2.E4.m1.4.4.4.2.1.1.1.3" mathsize="80%">τ</mi></mrow><mo id="S2.E4.m1.4.4.4.2.1.1.3" maxsize="80%" minsize="80%">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo id="S2.E4.m1.4.7" maxsize="80%" minsize="80%">)</mo></mrow><annotation encoding="application/x-tex" id="S2.E4.m1.4c">\displaystyle+\log\frac{\exp(T_{i}\cdot A_{i}/\tau)}{\sum_{j=1}^{N}\exp(T_{i}%
\cdot A_{j}/\tau)})</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.4d">+ roman_log divide start_ARG roman_exp ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_τ ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_exp ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT / italic_τ ) end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p8">
<p class="ltx_p" id="S2.SS2.p8.2">where <math alttext="\tau" class="ltx_Math" display="inline" id="S2.SS2.p8.1.m1.1"><semantics id="S2.SS2.p8.1.m1.1a"><mi id="S2.SS2.p8.1.m1.1.1" xref="S2.SS2.p8.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p8.1.m1.1b"><ci id="S2.SS2.p8.1.m1.1.1.cmml" xref="S2.SS2.p8.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p8.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p8.1.m1.1d">italic_τ</annotation></semantics></math> is a learnable temperature parameter for scaling the loss. Two logarithmic terms consider either audio-to-text logits or text-to-audio logits. <math alttext="N" class="ltx_Math" display="inline" id="S2.SS2.p8.2.m2.1"><semantics id="S2.SS2.p8.2.m2.1a"><mi id="S2.SS2.p8.2.m2.1.1" xref="S2.SS2.p8.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p8.2.m2.1b"><ci id="S2.SS2.p8.2.m2.1.1.cmml" xref="S2.SS2.p8.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p8.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p8.2.m2.1d">italic_N</annotation></semantics></math> is used as the batch size. The relevance of text-audio pair embeddings is scored by the cosine distance calculation.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Prompt-based Text-to-Speech</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The backbone of the prompt-based speech synthesis model we employ is GPT-SoVITS, as shown in the right part of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S2.F2" title="Figure 2 ‣ 2.2 Context-Aware Contrastive Language-audio Pretraining (CA-CLAP) ‣ 2 Methodology ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">2</span></a>. It uses discrete semantic tokens as an intermediate feature between the VITS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib24" title="">24</a>]</cite> decoder and the text-to-semantic model. The model leverages a self-supervised learning (SSL) model HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib3" title="">3</a>]</cite> to extract discrete semantic tokens. Additionally, it incorporates a reference encoder from TransferTTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib25" title="">25</a>]</cite> to extract speaker embeddings.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">The training process is divided into two stages. In the first stage, the VITS decoder and the vector quantization (VQ) model are jointly trained with VITS loss and VQ commitment loss. In the second stage, utilizing the well-trained VQ model from the first stage and the pretrained HuBERT model, the text-to-semantic model is trained in a GPT-like manner to predict the next semantic token.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Training Setup</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To train our proposed CA-CLAP model, we collect 3254 Chinese audiobooks from Internet, including 616 hours. We first separate the background music and split the whole speech into utterances, then we use Paraformer<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/alibaba-damo-academy/FunASR</span></span></span> to transcribe the audio. We split our collected dataset with 100 audiobooks including 9K text-audio pairs for test and 10 audiobooks for validation, and other 3144 audiobooks including 285K text-audio pairs for training. We use the previous and following 5 sentences of the current text as the corresponding contextual content. We use RoBERTa<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://huggingface.co/hfl/chinese-roberta-wwm-ext</span></span></span> as text encoder and HTSAT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib26" title="">26</a>]</cite> as audio encoder. We train our CA-CLAP model for 10 epochs on one NVIDIA A6000 GPU with a batch size of 120.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">To effectively evaluate our proposed RAG method, we additionally collect 48 audiobooks that have at least 500 utterances to ensure there are sufficient samples to retrieve. We use the last 100 utterances for test and use the other utterances in the same book for retrieval. Therefore, we have 4800 utterances for evaluation. We adopt the well-performed prompt-based TTS model GPT-SoVITS<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://github.com/RVC-Boss/GPT-SoVITS</span></span></span> as our TTS backbone and use retrieved prompt text-audio pairs to provide prosody and speaker timbre.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Objective and subjective experiments comparing zero-shot TTS performance across various retrieval methods. ‘Text’ and ‘Audio’ indicate the modalities utilized for retrieval. We evaluate the 95% confidence intervals for NMOS and SMOS.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.21" style="width:388.4pt;height:123.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.3pt,10.8pt) scale(0.85,0.85) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.21.21">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.21.21.22.1">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.21.21.22.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S3.T1.21.21.22.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.22.1.2.1">Retrieval</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" id="S3.T1.21.21.22.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.22.1.3.1">Objective</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T1.21.21.22.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.22.1.4.1">Subjective</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.6.7"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.6.7.1">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.6.6.6.8">Text</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.6.6.6.9">Audio</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1">Energy<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.2.2.2">F0<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.2.2.2.2.m1.1"><semantics id="S3.T1.2.2.2.2.m1.1a"><mo id="S3.T1.2.2.2.2.m1.1.1" stretchy="false" xref="S3.T1.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.1b"><ci id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.2.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.3.3.3">MCD<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.3.3.3.3.m1.1"><semantics id="S3.T1.3.3.3.3.m1.1a"><mo id="S3.T1.3.3.3.3.m1.1.1" stretchy="false" xref="S3.T1.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.3.m1.1b"><ci id="S3.T1.3.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.4.4.4.4">SECS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.4.4.4.4.m1.1"><semantics id="S3.T1.4.4.4.4.m1.1a"><mo id="S3.T1.4.4.4.4.m1.1.1" stretchy="false" xref="S3.T1.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.4.m1.1b"><ci id="S3.T1.4.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.4.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.5.5.5.5">NMOS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.5.5.5.5.m1.1"><semantics id="S3.T1.5.5.5.5.m1.1a"><mo id="S3.T1.5.5.5.5.m1.1.1" stretchy="false" xref="S3.T1.5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.5.m1.1b"><ci id="S3.T1.5.5.5.5.m1.1.1.cmml" xref="S3.T1.5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.5.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.6.6.6">SMOS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.6.6.6.6.m1.1"><semantics id="S3.T1.6.6.6.6.m1.1a"><mo id="S3.T1.6.6.6.6.m1.1.1" stretchy="false" xref="S3.T1.6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.6.m1.1b"><ci id="S3.T1.6.6.6.6.m1.1.1.cmml" xref="S3.T1.6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.6.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.7.7.7.2">Groundtruth</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.7.1">4.408 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.7.7.7.1.m1.1"><semantics id="S3.T1.7.7.7.1.m1.1a"><mo id="S3.T1.7.7.7.1.m1.1.1" xref="S3.T1.7.7.7.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S3.T1.7.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.7.1.m1.1d">±</annotation></semantics></math> 0.089</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.7.7.7.9">-</td>
</tr>
<tr class="ltx_tr" id="S3.T1.9.9.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.9.9.9.3">Self</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.6">15.144</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.7">46.785</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.8">5.664</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.9.9.9.9">0.806</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.8.8.8.1">4.110 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.8.8.8.1.m1.1"><semantics id="S3.T1.8.8.8.1.m1.1a"><mo id="S3.T1.8.8.8.1.m1.1.1" xref="S3.T1.8.8.8.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.1.m1.1b"><csymbol cd="latexml" id="S3.T1.8.8.8.1.m1.1.1.cmml" xref="S3.T1.8.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.8.1.m1.1d">±</annotation></semantics></math> 0.058</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.9.2">4.002 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.9.9.9.2.m1.1"><semantics id="S3.T1.9.9.9.2.m1.1a"><mo id="S3.T1.9.9.9.2.m1.1.1" xref="S3.T1.9.9.9.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.2.m1.1b"><csymbol cd="latexml" id="S3.T1.9.9.9.2.m1.1.1.cmml" xref="S3.T1.9.9.9.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.9.2.m1.1d">±</annotation></semantics></math> 0.072</td>
</tr>
<tr class="ltx_tr" id="S3.T1.13.13.13">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.13.13.13.5">Random</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.10.10.10.1"><math alttext="\times" class="ltx_Math" display="inline" id="S3.T1.10.10.10.1.m1.1"><semantics id="S3.T1.10.10.10.1.m1.1a"><mo id="S3.T1.10.10.10.1.m1.1.1" xref="S3.T1.10.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.1.m1.1b"><times id="S3.T1.10.10.10.1.m1.1.1.cmml" xref="S3.T1.10.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.10.1.m1.1d">×</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.11.11.11.2"><math alttext="\times" class="ltx_Math" display="inline" id="S3.T1.11.11.11.2.m1.1"><semantics id="S3.T1.11.11.11.2.m1.1a"><mo id="S3.T1.11.11.11.2.m1.1.1" xref="S3.T1.11.11.11.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.2.m1.1b"><times id="S3.T1.11.11.11.2.m1.1.1.cmml" xref="S3.T1.11.11.11.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.11.2.m1.1d">×</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.13.13.13.6">17.877</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.13.13.13.7">59.007</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.13.13.13.8">6.689</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.13.13.13.9">0.724</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.12.12.12.3">3.624 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.12.12.12.3.m1.1"><semantics id="S3.T1.12.12.12.3.m1.1a"><mo id="S3.T1.12.12.12.3.m1.1.1" xref="S3.T1.12.12.12.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.3.m1.1b"><csymbol cd="latexml" id="S3.T1.12.12.12.3.m1.1.1.cmml" xref="S3.T1.12.12.12.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.12.12.12.3.m1.1d">±</annotation></semantics></math> 0.082</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.13.13.13.4">3.314 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.13.13.13.4.m1.1"><semantics id="S3.T1.13.13.13.4.m1.1a"><mo id="S3.T1.13.13.13.4.m1.1.1" xref="S3.T1.13.13.13.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.4.m1.1b"><csymbol cd="latexml" id="S3.T1.13.13.13.4.m1.1.1.cmml" xref="S3.T1.13.13.13.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.13.13.13.4.m1.1d">±</annotation></semantics></math> 0.077</td>
</tr>
<tr class="ltx_tr" id="S3.T1.16.16.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.16.16.16.4">MiniLM</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.16.16.16.5">✓</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.14.14.14.1"><math alttext="\times" class="ltx_Math" display="inline" id="S3.T1.14.14.14.1.m1.1"><semantics id="S3.T1.14.14.14.1.m1.1a"><mo id="S3.T1.14.14.14.1.m1.1.1" xref="S3.T1.14.14.14.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.1.m1.1b"><times id="S3.T1.14.14.14.1.m1.1.1.cmml" xref="S3.T1.14.14.14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T1.14.14.14.1.m1.1d">×</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.16.16.16.6">17.612</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.16.16.16.7">58.271</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.16.16.16.8">6.583</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.16.16.16.9">0.730</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.15.15.15.2">3.681 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.15.15.15.2.m1.1"><semantics id="S3.T1.15.15.15.2.m1.1a"><mo id="S3.T1.15.15.15.2.m1.1.1" xref="S3.T1.15.15.15.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.2.m1.1b"><csymbol cd="latexml" id="S3.T1.15.15.15.2.m1.1.1.cmml" xref="S3.T1.15.15.15.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.15.15.15.2.m1.1d">±</annotation></semantics></math> 0.119</td>
<td class="ltx_td ltx_align_center" id="S3.T1.16.16.16.3">3.525 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.16.16.16.3.m1.1"><semantics id="S3.T1.16.16.16.3.m1.1a"><mo id="S3.T1.16.16.16.3.m1.1.1" xref="S3.T1.16.16.16.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.3.m1.1b"><csymbol cd="latexml" id="S3.T1.16.16.16.3.m1.1.1.cmml" xref="S3.T1.16.16.16.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.16.16.16.3.m1.1d">±</annotation></semantics></math> 0.082</td>
</tr>
<tr class="ltx_tr" id="S3.T1.19.19.19">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.19.19.19.4">CoROM</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.19.19.19.5">✓</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.17.17.17.1"><math alttext="\times" class="ltx_Math" display="inline" id="S3.T1.17.17.17.1.m1.1"><semantics id="S3.T1.17.17.17.1.m1.1a"><mo id="S3.T1.17.17.17.1.m1.1.1" xref="S3.T1.17.17.17.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.T1.17.17.17.1.m1.1b"><times id="S3.T1.17.17.17.1.m1.1.1.cmml" xref="S3.T1.17.17.17.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.17.17.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.T1.17.17.17.1.m1.1d">×</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.19.19.19.6">17.605</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.19.19.19.7">57.930</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.19.19.19.8">6.577</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.19.19.19.9">0.731</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.18.18.18.2">3.766 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.18.18.18.2.m1.1"><semantics id="S3.T1.18.18.18.2.m1.1a"><mo id="S3.T1.18.18.18.2.m1.1.1" xref="S3.T1.18.18.18.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.18.18.18.2.m1.1b"><csymbol cd="latexml" id="S3.T1.18.18.18.2.m1.1.1.cmml" xref="S3.T1.18.18.18.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.18.18.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.18.18.18.2.m1.1d">±</annotation></semantics></math> 0.068</td>
<td class="ltx_td ltx_align_center" id="S3.T1.19.19.19.3">3.455 <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.19.19.19.3.m1.1"><semantics id="S3.T1.19.19.19.3.m1.1a"><mo id="S3.T1.19.19.19.3.m1.1.1" xref="S3.T1.19.19.19.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.19.19.19.3.m1.1b"><csymbol cd="latexml" id="S3.T1.19.19.19.3.m1.1.1.cmml" xref="S3.T1.19.19.19.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.19.19.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.19.19.19.3.m1.1d">±</annotation></semantics></math> 0.109</td>
</tr>
<tr class="ltx_tr" id="S3.T1.21.21.21">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.3">Proposed</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.4">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.5">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.6"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.21.6.1">17.333</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.7"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.21.7.1">57.678</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.8"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.21.8.1">6.507</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.21.21.21.9"><span class="ltx_text ltx_font_bold" id="S3.T1.21.21.21.9.1">0.734</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.20.20.20.1">
<span class="ltx_text ltx_font_bold" id="S3.T1.20.20.20.1.1">3.922</span> <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.20.20.20.1.m1.1"><semantics id="S3.T1.20.20.20.1.m1.1a"><mo id="S3.T1.20.20.20.1.m1.1.1" xref="S3.T1.20.20.20.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.20.20.20.1.m1.1b"><csymbol cd="latexml" id="S3.T1.20.20.20.1.m1.1.1.cmml" xref="S3.T1.20.20.20.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.20.20.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.20.20.20.1.m1.1d">±</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.T1.20.20.20.1.2">0.068</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.21.21.21.2">
<span class="ltx_text ltx_font_bold" id="S3.T1.21.21.21.2.1">3.778</span> <math alttext="\pm" class="ltx_Math" display="inline" id="S3.T1.21.21.21.2.m1.1"><semantics id="S3.T1.21.21.21.2.m1.1a"><mo id="S3.T1.21.21.21.2.m1.1.1" xref="S3.T1.21.21.21.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.21.21.21.2.m1.1b"><csymbol cd="latexml" id="S3.T1.21.21.21.2.m1.1.1.cmml" xref="S3.T1.21.21.21.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.21.21.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S3.T1.21.21.21.2.m1.1d">±</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.T1.21.21.21.2.2">0.075</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Impact of context length in CA-CLAP retrieval results. The last line randomly chooses 5 utterances before and after the current text as context input of the text encoder.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.5" style="width:225.9pt;height:115.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.2pt,14.4pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.5.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T2.5.5.5.6">Context Len</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1">SIM<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.2.2.2.2">R@1<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.2.m1.1a"><mo id="S3.T2.2.2.2.2.m1.1.1" stretchy="false" xref="S3.T2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.3.3.3.3">R@5<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.3.3.3.3.m1.1"><semantics id="S3.T2.3.3.3.3.m1.1a"><mo id="S3.T2.3.3.3.3.m1.1.1" stretchy="false" xref="S3.T2.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.3.m1.1b"><ci id="S3.T2.3.3.3.3.m1.1.1.cmml" xref="S3.T2.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.4.4.4.4">R@10<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.4.4.4.4.m1.1"><semantics id="S3.T2.4.4.4.4.m1.1a"><mo id="S3.T2.4.4.4.4.m1.1.1" stretchy="false" xref="S3.T2.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.4.m1.1b"><ci id="S3.T2.4.4.4.4.m1.1.1.cmml" xref="S3.T2.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.4.4.4.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.5.5.5.5">mAP@10<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.5.5.5.5.m1.1"><semantics id="S3.T2.5.5.5.5.m1.1a"><mo id="S3.T2.5.5.5.5.m1.1.1" stretchy="false" xref="S3.T2.5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.5.m1.1b"><ci id="S3.T2.5.5.5.5.m1.1.1.cmml" xref="S3.T2.5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.5.5.5.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.5.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T2.5.5.6.1.1">0</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.5.6.1.2">0.517</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.5.6.1.3">0.574</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.5.6.1.4">0.822</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.5.6.1.5">0.890</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.5.5.6.1.6">0.680</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5.7.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.5.5.7.2.1">1</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.7.2.2">0.561</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.7.2.3">0.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.7.2.4">0.834</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.7.2.5">0.904</td>
<td class="ltx_td ltx_align_center" id="S3.T2.5.5.7.2.6">0.695</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5.8.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.5.5.8.3.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.8.3.2">0.579</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.8.3.3">0.614</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.8.3.4">0.848</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.8.3.5">0.915</td>
<td class="ltx_td ltx_align_center" id="S3.T2.5.5.8.3.6">0.715</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5.9.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.5.5.9.4.1">5</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.9.4.2"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.9.4.2.1">0.589</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.9.4.3"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.9.4.3.1">0.641</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.9.4.4"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.9.4.4.1">0.865</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.9.4.5"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.9.4.5.1">0.927</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.5.5.9.4.6"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.9.4.6.1">0.738</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5.10.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.5.5.10.5.1">7</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.10.5.2">0.550</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.10.5.3">0.493</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.10.5.4">0.761</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.10.5.5">0.847</td>
<td class="ltx_td ltx_align_center" id="S3.T2.5.5.10.5.6">0.607</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5.11.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T2.5.5.11.6.1">10</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.11.6.2">0.499</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.11.6.3">0.345</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.11.6.4">0.622</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.5.5.11.6.5">0.736</td>
<td class="ltx_td ltx_align_center" id="S3.T2.5.5.11.6.6">0.464</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5.12.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T2.5.5.12.7.1">random 5</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T2.5.5.12.7.2">0.508</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T2.5.5.12.7.3">0.468</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T2.5.5.12.7.4">0.713</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S3.T2.5.5.12.7.5">0.794</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.5.5.12.7.6">0.572</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Effects of speech prompt number for zero-shot TTS. Num denotes the number of speech prompts. Rand denotes random selection and Text refers to the text-only model MiniLM.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.3" style="width:231.1pt;height:94.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.5pt,20.2pt) scale(0.7,0.7) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T3.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.3.3.3">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T3.3.3.3.4"></th>
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S3.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.1">Energy<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T3.1.1.1.1.1.m1.1"><semantics id="S3.T3.1.1.1.1.1.m1.1a"><mo id="S3.T3.1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T3.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.1.m1.1b"><ci id="S3.T3.1.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.1.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S3.T3.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S3.T3.2.2.2.2.1">MCD<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T3.2.2.2.2.1.m1.1"><semantics id="S3.T3.2.2.2.2.1.m1.1a"><mo id="S3.T3.2.2.2.2.1.m1.1.1" stretchy="false" xref="S3.T3.2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.2.1.m1.1b"><ci id="S3.T3.2.2.2.2.1.m1.1.1.cmml" xref="S3.T3.2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.2.2.2.2.1.m1.1d">↓</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S3.T3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.3.3.1">SECS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.3.3.3.3.1.m1.1"><semantics id="S3.T3.3.3.3.3.1.m1.1a"><mo id="S3.T3.3.3.3.3.1.m1.1.1" stretchy="false" xref="S3.T3.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.3.1.m1.1b"><ci id="S3.T3.3.3.3.3.1.m1.1.1.cmml" xref="S3.T3.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.3.3.3.3.1.m1.1d">↑</annotation></semantics></math></span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.4.1.1">Num</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.2.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.2.1.1" style="width:19.9pt;">Rand</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.3.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.3.1.1" style="width:19.9pt;">Text</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T3.3.3.4.1.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.4.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.4.1.1" style="width:22.8pt;">Ours</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.5.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.5.1.1" style="width:19.9pt;">Rand</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.6.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.6.1.1" style="width:19.9pt;">Text</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T3.3.3.4.1.7">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.7.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.7.1.1" style="width:19.9pt;">Ours</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.8">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.8.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.8.1.1" style="width:19.9pt;">Rand</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.9">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.9.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.9.1.1" style="width:19.9pt;">Text</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S3.T3.3.3.4.1.10">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.4.1.10.1">
<span class="ltx_p" id="S3.T3.3.3.4.1.10.1.1" style="width:19.9pt;">Ours</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.3.3.5.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T3.3.3.5.1.1">1</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.2.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.2.1.1" style="width:19.9pt;">17.817</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.3.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.3.1.1" style="width:19.9pt;">17.612</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T3.3.3.5.1.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.4.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.4.1.1" style="width:22.8pt;">17.333</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.5.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.5.1.1" style="width:19.9pt;">6.655</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.6.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.6.1.1" style="width:19.9pt;">6.583</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T3.3.3.5.1.7">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.7.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.7.1.1" style="width:19.9pt;">6.507</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.8">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.8.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.8.1.1" style="width:19.9pt;">0.726</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.9">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.9.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.9.1.1" style="width:19.9pt;">0.730</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T3.3.3.5.1.10">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.5.1.10.1">
<span class="ltx_p" id="S3.T3.3.3.5.1.10.1.1" style="width:19.9pt;">0.734</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.6.2.1">2</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.2.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.2.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.6.2.2.1.1.1">17.375</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.3.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.3.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.6.2.3.1.1.1">17.380</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T3.3.3.6.2.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.4.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.4.1.1" style="width:22.8pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.6.2.4.1.1.1">16.988</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.5.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.5.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.6.2.5.1.1.1">6.507</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.6.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.6.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.6.2.6.1.1.1">6.460</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T3.3.3.6.2.7">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.7.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.7.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.6.2.7.1.1.1">6.390</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.8">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.8.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.8.1.1" style="width:19.9pt;">0.743</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.9">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.9.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.9.1.1" style="width:19.9pt;">0.746</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.6.2.10">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.6.2.10.1">
<span class="ltx_p" id="S3.T3.3.3.6.2.10.1.1" style="width:19.9pt;">0.748</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3.7.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S3.T3.3.3.7.3.1">3</th>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.2.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.2.1.1" style="width:19.9pt;">17.493</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.3.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.3.1.1" style="width:19.9pt;">17.425</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T3.3.3.7.3.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.4.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.4.1.1" style="width:22.8pt;">17.194</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.5.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.5.1.1" style="width:19.9pt;">6.509</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.6.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.6.1.1" style="width:19.9pt;">6.463</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" id="S3.T3.3.3.7.3.7">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.7.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.7.1.1" style="width:19.9pt;">6.408</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.8">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.8.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.8.1.1" style="width:19.9pt;">0.749</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.9">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.9.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.9.1.1" style="width:19.9pt;">0.751</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T3.3.3.7.3.10">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.7.3.10.1">
<span class="ltx_p" id="S3.T3.3.3.7.3.10.1.1" style="width:19.9pt;">0.754</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3.8.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S3.T3.3.3.8.4.1">4</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.2.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.2.1.1" style="width:19.9pt;">17.571</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.3">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.3.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.3.1.1" style="width:19.9pt;">17.762</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r" id="S3.T3.3.3.8.4.4">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.4.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.4.1.1" style="width:22.8pt;">17.460</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.5">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.5.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.5.1.1" style="width:19.9pt;">6.546</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.6">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.6.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.6.1.1" style="width:19.9pt;">6.516</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r" id="S3.T3.3.3.8.4.7">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.7.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.7.1.1" style="width:19.9pt;">6.462</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.8">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.8.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.8.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.8.4.8.1.1.1">0.752</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.9">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.9.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.9.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.8.4.9.1.1.1">0.753</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S3.T3.3.3.8.4.10">
<span class="ltx_inline-block ltx_align_top" id="S3.T3.3.3.8.4.10.1">
<span class="ltx_p" id="S3.T3.3.3.8.4.10.1.1" style="width:19.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.3.3.8.4.10.1.1.1">0.756</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Compared Methods</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To evaluate proposed model’s performance, we compare the following retrieval methods for prompt-based TTS.</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Self</span>: use the same text-audio pair in evaluation. This serves as upper bound of prompt-based TTS performance.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Random</span>: randomly select one text-audio pair in the same audiobook as prompt text and prompt speech.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Text-only embedding models</span>: adopt text-only embedding model instead of contrastive multi-modal model to index and query the text-audio pairs. We use the same embedding model in stage indexing and retrieval, and adopt the current text to retrieve.
For comparison, we adopt the widely used sentence embedding models all-MiniLM-L6-v2<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2</span></span></span> and coROM-base<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://www.modelscope.cn/models/iic/nlp_corom_sentence-embedding_chinese-base</span></span></span>, denoted as <span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.2">MiniLM</span> and <span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.3">CoROM</span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Objective Evaluation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To evaluate the effectiveness of our proposed method in terms of naturalness, speaker similarity, and prosodic accuracy, we utilize four metrics including energy, F0, mel-cepstral distortion (MCD), and Speaker Encoder Cosine Similarity (SECS). Noted that we utilize Dynamic Time Warping (DTW) to align generated audio and groundtruth audio before calculation. For assessing speaker similarity, we employ speaker encoder model Resemblyzer<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://github.com/resemble-ai/Resemblyzer</span></span></span> to compute the SECS between the original and generated speech. The objective evaluation results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.T1" title="Table 1 ‣ 3.1 Training Setup ‣ 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">The results are in line with our expectations: 1) Using the same target speech as the speech prompt yields the best results, as prompt-based TTS can easily replicate the semantic tokens of the prompt. 2) Randomly selecting speech prompts results in the poorest performance across all evaluation metrics, illustrating that choosing a prompt without considering its relevance of desired speaking style can hinder the generation process. 3) Methods using the RAG paradigm can improve generative performance in speaker similarity, prosody, and speaking style compared to non-RAG methods. Moreover, our model, which incorporates context-aware contrastive-based multi-modal embedding, outperforms text-only embedding models (such as MiniLM and CoROM). This suggests that the context-aware style-related embedding generated by the pretrained CA-CLAP model can more precisely match speech prompts with the appropriate speaking style for the desired audio, taking context into account.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Subjective Evaluation</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">We conduct two mean opinion score (MOS) subjective tests including naturalness MOS (NMOS) test to evaluate the naturalness and audio quality, and similarity MOS (SMOS) test to compare the speaking prosody and timbre between groundtruth speech and synthesized speech. We randomly select 30 samples from different audiobooks in the test set. We ask 10 native listeners to rate the NMOS and SMOS on a scale from 1 to 5 with 0.5 point interval. The subjective evaluation results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.T1" title="Table 1 ‣ 3.1 Training Setup ‣ 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">1</span></a>. The results are consistent with our objective findings, and our proposed method outperforms all the baselines in both NMOS and SMOS. This indicates that the combination of RAG method and context-aware contrastive-based multi-modal embedding extracted from CA-CLAP can match the best speech prompt with suitable speaking style.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Effects of Context Length</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">To assess the effectiveness of context information and the impact of context length in the CA-CLAP retrieval process, we adjust context length <math alttext="l" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mi id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">italic_l</annotation></semantics></math> from 0 to 10, and evaluate the retrieval results including similarity, recall (R@1 to R@10) and mean average precision (mAP@10) following evaluation in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#bib.bib23" title="">23</a>]</cite>. The performance of our CA-CLAP is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.T2" title="Table 2 ‣ 3.1 Training Setup ‣ 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">2</span></a>. We find that the performance first increases from 0 to 5 context length, and decreases when context length is longer than 5. We believe that an appropriate length of context can help with text comprehension, but excessively long context has redundant information which hinders understanding. Moreover, we randomly choose 5 utterances before and after the current text as context and find that it has inferior performance, suggesting that context is indeed helpful in understanding the current text, while incorrect context worsens the performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Effects of Speech Prompt Number</h3>
<div class="ltx_para" id="S3.SS6.p1">
<p class="ltx_p" id="S3.SS6.p1.1">To assess the impact of speech prompt numbers on prompt-based TTS with different RAG methods, we conduct this ablation study, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.03714v1#S3.T3" title="Table 3 ‣ 3.1 Training Setup ‣ 3 Experiments ‣ Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining"><span class="ltx_text ltx_ref_tag">3</span></a>. We find that as the prompt number increases, the speaker similarity also gradually increases. This is because the prompt-based TTS tries to clone the speaker timbre and a longer prompt provides more acoustic information. However, the results of energy and MCD show that the performance peaks at a prompt length of 2, and weakens with longer prompts. We believe longer inconsistent content from different prompts may prevent prompt-based TTS from generating coherent speech.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this paper, we present a novel RAG-enhanced prompt-based TTS framework that incorporates a context-aware contrastive language-audio pretraining model. To our knowledge, this is the pioneering zero-shot, prompt-based TTS framework that effectively employs the RAG paradigm and multi-modal context enhancement to refine speech prompt selection and ensure stable generation. To verify the effectiveness of our model, we conduct evaluations on both retrieval and zero-shot TTS. The results indicate that our model outperforms other baselines and can effectively match suitable speech prompts to generate more coherent speech with a context-appropriate speaking style. Additionally, we investigate the impact of context length and the number of speech prompts on our model’s performance.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgements</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The work was supported by the National Natural Science Foundation of China (NSFC) (No. 62271083), the Key Project of the National Language Commission (No. ZDI145-81), and the Fundamental Research Funds for the Central Universities (No. 2023RC73, 2023RC13).</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
N. Zeghidour, A. Luebs, A. Omran, J. Skoglund, and M. Tagliasacchi, “Soundstream: An end-to-end neural audio codec,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">IEEE ACM Trans. Audio Speech Lang. Process.</em>, vol. 30, pp. 495–507, 2022. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TASLP.2021.3129994" title="">https://doi.org/10.1109/TASLP.2021.3129994</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Défossez, J. Copet, G. Synnaeve, and Y. Adi, “High fidelity neural audio compression,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2210.13438</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
W. Hsu, B. Bolte, Y. H. Tsai, K. Lakhotia, R. Salakhutdinov, and A. Mohamed, “Hubert: Self-supervised speech representation learning by masked prediction of hidden units,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IEEE ACM Trans. Audio Speech Lang. Process.</em>, vol. 29, pp. 3451–3460, 2021. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/TASLP.2021.3122291" title="">https://doi.org/10.1109/TASLP.2021.3122291</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Z. Jiang, Y. Ren, Z. Ye, J. Liu, C. Zhang, Q. Yang, S. Ji, R. Huang, C. Wang, X. Yin, Z. Ma, and Z. Zhao, “Mega-tts: Zero-shot text-to-speech at scale with intrinsic inductive bias,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">CoRR</em>, vol. abs/2306.03509, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2306.03509" title="">https://doi.org/10.48550/arXiv.2306.03509</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Z. Jiang, J. Liu, Y. Ren, J. He, C. Zhang, Z. Ye, P. Wei, C. Wang, X. Yin, Z. Ma, and Z. Zhao, “Mega-tts 2: Zero-shot text-to-speech with arbitrary length speech prompts,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">CoRR</em>, vol. abs/2307.07218, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2307.07218" title="">https://doi.org/10.48550/arXiv.2307.07218</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C. Wang, S. Chen, Y. Wu, Z. Zhang, L. Zhou, S. Liu, Z. Chen, Y. Liu, H. Wang, J. Li <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">et al.</em>, “Neural codec language models are zero-shot text to speech synthesizers,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2">arXiv preprint arXiv:2301.02111</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Z. Borsos, R. Marinier, D. Vincent, E. Kharitonov, O. Pietquin, M. Sharifi, D. Roblek, O. Teboul, D. Grangier, M. Tagliasacchi <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">et al.</em>, “Audiolm: a language modeling approach to audio generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.2.2">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
K. Shen, Z. Ju, X. Tan, Y. Liu, Y. Leng, L. He, T. Qin, S. Zhao, and J. Bian, “Naturalspeech 2: Latent diffusion models are natural and zero-shot speech and singing synthesizers,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">CoRR</em>, vol. abs/2304.09116, 2023. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2304.09116" title="">https://doi.org/10.48550/arXiv.2304.09116</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
E. Kharitonov, D. Vincent, Z. Borsos, R. Marinier, S. Girgin, O. Pietquin, M. Sharifi, M. Tagliasacchi, and N. Zeghidour, “Speak, read and prompt: High-fidelity text-to-speech with minimal supervision,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2302.03540</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.-A. Chung, Y. Zhang, W. Han, C.-C. Chiu, J. Qin, R. Pang, and Y. Wu, “W2v-bert: Combining contrastive learning and masked language modeling for self-supervised speech pre-training,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>.   IEEE, 2021, pp. 244–250.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y. Ren, C. Hu, X. Tan, T. Qin, S. Zhao, Z. Zhao, and T.-Y. Liu, “Fastspeech 2: Fast and high-quality end-to-end text to speech,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2006.04558</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y. Wang, R. Skerry-Ryan, D. Stanton, Y. Wu, R. J. Weiss, N. Jaitly, Z. Yang, Y. Xiao, Z. Chen, S. Bengio <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">et al.</em>, “Tacotron: Towards end-to-end speech synthesis,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.2.2">arXiv preprint arXiv:1703.10135</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">et al.</em>, “Chain-of-thought prompting elicits reasoning in large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.2.2">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 24 824–24 837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large language models are zero-shot reasoners,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Advances in neural information processing systems</em>, vol. 35, pp. 22 199–22 213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
L. Xue, F. K. Soong, S. Zhang, and L. Xie, “Paratts: Learning linguistic and prosodic cross-sentence information in paragraph-based tts,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 30, pp. 2854–2864, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
X. Chen, S. Lei, Z. Wu, D. Xu, W. Zhao, and H. Meng, “Unsupervised multi-scale expressive speaking style modeling with hierarchical context information for audiobook speech synthesis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 29th International Conference on Computational Linguistics</em>, 2022, pp. 7193–7202.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
X. Chen, X. Wang, S. Zhang, L. He, Z. Wu, X. Wu, and H. Meng, “Stylespeech: Self-supervised style enhancing with vq-vae-based pre-training for expressive audiobook speech synthesis,” <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2312.12181</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. Xue, Y. Deng, F. Wang, Y. Li, Y. Gao, J. Tao, J. Sun, and J. Liang, “M2-ctts: End-to-end multi-scale multi-modal conversational text-to-speech synthesis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2023, pp. 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y. Deng, J. Xue, F. Wang, Y. Gao, and Y. Li, “Cmcu-css: Enhancing naturalness via commonsense-based multi-modal context understanding in conversational speech synthesis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 31st ACM International Conference on Multimedia</em>, 2023, pp. 6081–6089.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y. Deng, J. Xue, Y. Jia, Q. Li, Y. Han, F. Wang, Y. Gao, D. Ke, and Y. Li, “Concss: Contrastive-based context comprehension for dialogue-appropriate prosody in conversational speech synthesis,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2312.10358</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-augmented generation for knowledge-intensive NLP tasks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, Eds., 2020. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="">https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, “Retrieval augmented language model pre-training,” in <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event</em>, ser. Proceedings of Machine Learning Research, vol. 119.   PMLR, 2020, pp. 3929–3938. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v119/guu20a.html" title="">http://proceedings.mlr.press/v119/guu20a.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y. Wu, K. Chen, T. Zhang, Y. Hui, T. Berg-Kirkpatrick, and S. Dubnov, “Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">IEEE International Conference on Acoustics, Speech and Signal Processing ICASSP 2023, Rhodes Island, Greece, June 4-10, 2023</em>.   IEEE, 2023, pp. 1–5. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICASSP49357.2023.10095969" title="">https://doi.org/10.1109/ICASSP49357.2023.10095969</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. Kim, J. Kong, and J. Son, “Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech,” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event</em>, ser. Proceedings of Machine Learning Research, M. Meila and T. Zhang, Eds., vol. 139.   PMLR, 2021, pp. 5530–5540. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://proceedings.mlr.press/v139/kim21f.html" title="">http://proceedings.mlr.press/v139/kim21f.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M. Kim, M. Jeong, B. J. Choi, S. Ahn, J. Y. Lee, and N. S. Kim, “Transfer learning framework for low-resource text-to-speech using a large-scale unlabeled speech corpus,” in <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Interspeech 2022, 23rd Annual Conference of the International Speech Communication Association, Incheon, Korea, 18-22 September 2022</em>, H. Ko and J. H. L. Hansen, Eds.   ISCA, 2022, pp. 788–792. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.21437/Interspeech.2022-225" title="">https://doi.org/10.21437/Interspeech.2022-225</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
K. Chen, X. Du, B. Zhu, Z. Ma, T. Berg-Kirkpatrick, and S. Dubnov, “Hts-at: A hierarchical token-semantic audio transformer for sound classification and detection,” in <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2022, pp. 646–650.

</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" content="{Under review}" property="dcterms:title"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jun  6 03:15:38 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
