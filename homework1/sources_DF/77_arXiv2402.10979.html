<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs</title>
<!--Generated on Sun Jun 16 06:41:28 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2402.10979v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S1" title="In SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S2" title="In SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3" title="In SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>The <span class="ltx_text ltx_font_typewriter">SportsMetrics</span> Benchmark</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS1" title="In 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Long-Form Game Narratives</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS2" title="In 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>The Impact of Changing Game Rules</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS2.SSS0.Px1" title="In 3.2 The Impact of Changing Game Rules ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title">New Scoring Rules</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS2.SSS0.Px2" title="In 3.2 The Impact of Changing Game Rules ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title">Player Swapping</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS3" title="In 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Robustness Against Noise</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS3.SSS0.Px1" title="In 3.3 Robustness Against Noise ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title">Shuffling Play-by-Plays</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.SS4" title="In 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Planning for Complex Data Queries</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S4" title="In SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S5" title="In SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S6" title="In SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_typewriter" id="id11.id1">SportsMetrics</span>: Blending Text and Numerical Data to Understand Information Fusion in LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yebowen Hu,<sup class="ltx_sup" id="id12.11.id1">†</sup> Kaiqiang Song,<sup class="ltx_sup" id="id13.12.id2">‡</sup> Sangwoo Cho,<sup class="ltx_sup" id="id14.13.id3">‡</sup> Xiaoyang Wang,<sup class="ltx_sup" id="id15.14.id4">‡</sup>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id7.7.3">Hassan Foroosh,<sup class="ltx_sup" id="id7.7.3.1"><span class="ltx_text ltx_font_medium" id="id7.7.3.1.1">†</span></sup> Dong Yu,<sup class="ltx_sup" id="id7.7.3.2"><span class="ltx_text ltx_font_medium" id="id7.7.3.2.1">‡</span></sup> Fei Liu<sup class="ltx_sup" id="id7.7.3.3"><span class="ltx_text ltx_font_medium" id="id7.7.3.3.1">§</span></sup>
<br class="ltx_break"/></span>
<sup class="ltx_sup" id="id16.15.id5">†</sup>University of Central Florida  
<sup class="ltx_sup" id="id17.16.id6">‡</sup>Tencent AI Lab, Bellevue, WA  
<sup class="ltx_sup" id="id18.17.id7">§</sup>Emory University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id19.18.id8">{yebowen.hu, hassan.foroosh}@ucf.edu
<br class="ltx_break"/> {riversong, swcho, shawnxywang, dyu}@global.tencent.com fei.liu@emory.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id20.id1">Large language models hold significant potential for integrating various data types, such as text documents and database records, for advanced analytics. However, blending text and numerical data presents substantial challenges. LLMs need to process and cross-reference entities and numbers, handle data inconsistencies and redundancies, and develop planning capabilities such as building a working memory for managing complex data queries. In this paper, we introduce four novel tasks centered around sports data analytics to evaluate the numerical reasoning and information fusion capabilities of LLMs. These tasks involve providing LLMs with detailed, play-by-play sports game descriptions, then challenging them with adversarial scenarios such as new game rules, longer durations, scrambled narratives, and analyzing key statistics in game summaries. We conduct extensive experiments on NBA and NFL games to assess the performance of LLMs on these tasks. Our benchmark, <span class="ltx_text ltx_font_typewriter" id="id20.id1.1">SportsMetrics</span>, introduces a new mechanism for assessing LLMs’ numerical reasoning and fusion skills.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.10">
<p class="ltx_p" id="p1.10.11"><span class="ltx_text ltx_font_typewriter" id="p1.10.11.1">SportsMetrics</span><span class="ltx_text ltx_font_bold" id="p1.10.11.2">: Blending Text and Numerical Data to Understand Information Fusion in LLMs</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.10.10" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.10.10.10" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.10.10.10.10">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.4.4.4.4.4">
<span class="ltx_td ltx_align_center" id="p1.4.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="p1.4.4.4.4.4.4.4">Yebowen Hu,<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.1"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.1.1">†</span></sup> Kaiqiang Song,<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.2"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.2.1">‡</span></sup> Sangwoo Cho,<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.3"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.3.1">‡</span></sup> Xiaoyang Wang,<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.4"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.4.1">‡</span></sup></span></span></span>
<span class="ltx_tr" id="p1.7.7.7.7.7">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.7.3" style="padding-bottom:5.0pt;"><span class="ltx_text ltx_font_bold" id="p1.7.7.7.7.7.3.3">Hassan Foroosh,<sup class="ltx_sup" id="p1.7.7.7.7.7.3.3.1"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.3.3.1.1">†</span></sup> Dong Yu,<sup class="ltx_sup" id="p1.7.7.7.7.7.3.3.2"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.3.3.2.1">‡</span></sup> Fei Liu<sup class="ltx_sup" id="p1.7.7.7.7.7.3.3.3"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.3.3.3.1">§</span></sup></span></span></span>
<span class="ltx_tr" id="p1.10.10.10.10.10">
<span class="ltx_td ltx_align_center" id="p1.10.10.10.10.10.3"><sup class="ltx_sup" id="p1.10.10.10.10.10.3.1">†</sup>University of Central Florida  
<sup class="ltx_sup" id="p1.10.10.10.10.10.3.2">‡</sup>Tencent AI Lab, Bellevue, WA  
<sup class="ltx_sup" id="p1.10.10.10.10.10.3.3">§</sup>Emory University</span></span>
<span class="ltx_tr" id="p1.10.10.10.10.11.1">
<span class="ltx_td ltx_align_center" id="p1.10.10.10.10.11.1.1"><span class="ltx_text ltx_font_typewriter" id="p1.10.10.10.10.11.1.1.1">{yebowen.hu, hassan.foroosh}@ucf.edu</span></span></span>
<span class="ltx_tr" id="p1.10.10.10.10.12.2">
<span class="ltx_td ltx_align_center" id="p1.10.10.10.10.12.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.10.10.10.10.12.2.1.1"> {riversong, swcho, shawnxywang, dyu}@global.tencent.com fei.liu@emory.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="454" id="S1.F1.g1" src="x1.png" width="385"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Play-by-plays of an NBA game. We include timestamps, player actions, team affiliations and a game recap. Total points for both teams are indicated in dotted circles and are withheld from LLMs.
</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) are more powerful than ever. OpenAI’s GPT-4 Turbo <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib46" title="">2023</a>)</cite> features a 128k context window, allowing it to process over 300 pages of text in a single prompt. Claude v2.1 <cite class="ltx_cite ltx_citemacro_cite">Anthropic (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib4" title="">2023</a>)</cite> steps it up with a 200k token window, equivalent to roughly 150,000 words or more than 500 pages. Mistral AI <cite class="ltx_cite ltx_citemacro_cite">MistralAI (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib45" title="">2023</a>)</cite> has created a sparse mixture of experts model capable of processing up to 32k tokens. The developments suggest language models can now engage with vast amounts of text content and data, opening doors to exciting new applications in various domains.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">One of the most promising uses of LLMs is in handling a combination of unstructured texts and structured data. For example, determining if a patient can be discharged from the hospital may involve reviewing doctor notes, radiology and pathology reports, lab results, and other records that blend text and structured data <cite class="ltx_cite ltx_citemacro_cite">Adams et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib1" title="">2021</a>); Bardhan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib5" title="">2022</a>); Cai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib13" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib14" title="">2023</a>); Veen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib54" title="">2023</a>); Ben Abacha et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib7" title="">2023</a>)</cite>; LLM Assistants for online shopping need to process product catalogs, sales transactions, and customer queries <cite class="ltx_cite ltx_citemacro_cite">Brynjolfsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib11" title="">2023</a>); Loten (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib40" title="">2023</a>)</cite>. Yet, summarizing key details from a mix of unstructured and structured sources remains a considerable challenge. An LLM must navigate text descriptions, link entities, aggregate numbers, handle discrepancies, and beyond.</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S1.F2.g1" src="x2.png" width="872"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
(<span class="ltx_text ltx_font_smallcaps" id="S1.F2.4.1">Top Left</span>) We examine the impact of changing game rules on final scores. For basketball, scoring events such as free throws, three-pointers, field goals, vary from 1 to 3 points. We ask LLMs to maintain these scoring events but under a new rule where each is worth only 1 point. (<span class="ltx_text ltx_font_smallcaps" id="S1.F2.5.2">Bottom Left</span>) We randomly swapped player team affiliations in the table without altering the game’s play-by-play records. (<span class="ltx_text ltx_font_smallcaps" id="S1.F2.6.3">Right</span>) LLMs are provided with detailed play-by-play descriptions of a sports game and player team affiliations. Their job is to use this information to update key game statistics in a JSON format.
</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Information fusion focuses on synthesizing information from multiple textual sources to derive meaningful conclusions <cite class="ltx_cite ltx_citemacro_cite">Barzilay et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib6" title="">1999</a>)</cite>. Current approaches involve summarizing multiple text documents, providing concise answers to user queries, and integrating summarization with natural language inference to deduce information <cite class="ltx_cite ltx_citemacro_cite">Bhaskar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib8" title="">2023</a>); Caciularu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib12" title="">2023</a>); Sprague et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib51" title="">2022</a>); Bostrom et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib9" title="">2022</a>)</cite>. The output is often a short text summary, the quality of which is difficult to evaluate <cite class="ltx_cite ltx_citemacro_cite">Deutsch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib18" title="">2021</a>)</cite>. In contrast, our approach emphasizes the numerical aspect of information fusion <cite class="ltx_cite ltx_citemacro_cite">Geva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib21" title="">2020</a>); Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib65" title="">2021</a>); Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib63" title="">2023</a>); Reddy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib49" title="">2024</a>)</cite>. We enable the LLM to navigate through lengthy texts, gather crucial statistics, and develop a working memory to manage complex data queries.</p>
</div>
<figure class="ltx_figure" id="S1.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="282" id="S1.F3.g1" src="x3.png" width="872"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>We adopt the NBA’s <em class="ltx_emph ltx_font_italic" id="S1.F3.3.1">Game Score</em>, originally designed for player evaluation, to measure a team’s overall efficiency. For American football, we apply NCAA’s <em class="ltx_emph ltx_font_italic" id="S1.F3.4.2">Passing Efficiency</em> formula.</figcaption>
</figure>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We introduce <span class="ltx_text ltx_font_typewriter" id="S1.p4.1.1">SportsMetrics</span>, a benchmark designed to assess LLMs’ abilities in numerical reasoning and data fusion. This benchmark provides LLMs with detailed, play-by-play descriptions of sports games, including timestamps, player actions, and team affiliations, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>. We focus on four novel tasks to evaluate LLMs in adversarial scenarios: (a) <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">adapting to new game rules</em>, (b) <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">handling lengthy game descriptions</em>, (c) <em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">managing scrambled game narratives</em>, and (d) <em class="ltx_emph ltx_font_italic" id="S1.p4.1.5">analyzing critical statistics in game summaries</em>. E.g., an LLM might be asked to complete a basketball game recap by inserting missing key statistics, which requires the development of a working memory for game stats and reasoning skills.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.1">SportsMetrics</span> benchmark presents three main benefits. First, it leverages sports data, including team-player affiliations and play-by-play details; they are dynamic narratives that LLMs cannot easily memorize. Second, it allows us to evaluate LLMs’ ability to track key statistics such as team points, assists, blocks, steals, and more, while also offering an overall game efficiency score for direct LLM comparison. Lastly, its use of widely understood sports terminology makes it more accessible to researchers than specialized medical language, making it an ideal benchmarking tool. While our current focus is on English, <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.2">SportsMetrics</span> also holds promise for multilingual applications.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">There is a growing need for a benchmark to evaluate LLMs’ <em class="ltx_emph ltx_font_italic" id="S2.p1.1.1">information fusion</em> capabilities, which offers clear, quantitative scores for comparing various LLMs. For example, Chatbot Arena <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib64" title="">2023</a>)</cite> utilizes Elo ratings <cite class="ltx_cite ltx_citemacro_cite">Boubdir et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib10" title="">2023</a>)</cite>, MT-Bench comprises of 80 multi-turn questions, and MMLU focuses on a model’s multitask accuracy across 57 tasks <cite class="ltx_cite ltx_citemacro_cite">Hendrycks et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib24" title="">2021</a>)</cite>. Multi-document summarization offers a promising benchmark <cite class="ltx_cite ltx_citemacro_cite">Lebanoff et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib33" title="">2021</a>); Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib27" title="">2021</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib55" title="">2022</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib59" title="">2023</a>)</cite>. However, developing a summary scoring system poses challenges due to variables such as summary length, content coverage, and faithfulness <cite class="ltx_cite ltx_citemacro_cite">Cao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib15" title="">2022</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib38" title="">2023c</a>); Krishna et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib31" title="">2023</a>); Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib25" title="">2023</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib34" title="">2023</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib58" title="">2024</a>); Joseph et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib28" title="">2024</a>)</cite>.
Sports data, which combines static knowledge with player dynamics, presents an untapped opportunity for benchmarking LLMs.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Combining information from a blend of textual and numerical records poses a significant challenge. In traditional multi-document summarization, the system creates a concise summary from a set of topically related documents. Giorgi et al. <cite class="ltx_cite ltx_citemacro_cite">Giorgi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib22" title="">2023</a>)</cite> show that this task remains difficult in an “open-domain” setting, where the document set is generated by a retriever and may include irrelevant information. With the growing popularity of retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib29" title="">2020</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib36" title="">2022</a>)</cite>, there is an increasing need to accurately fuse information from various sources. We explore information fusion by examining how LLMs cross-reference players and actions, and aggregate data across play-by-play descriptions to compile key game statistics.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Our work relates to numerical reasoning, which uses arithmetic reasoning to tackle mathematical word problems. Prior datasets in this area include MathQA <cite class="ltx_cite ltx_citemacro_cite">Amini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib2" title="">2019</a>)</cite>, GSM8k <cite class="ltx_cite ltx_citemacro_cite">Cobbe et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib17" title="">2021</a>)</cite>, SVAMP <cite class="ltx_cite ltx_citemacro_cite">Patel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib47" title="">2021</a>)</cite>, TAT-QA <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib65" title="">2021</a>)</cite>, FinQA <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib16" title="">2022</a>)</cite>, MATH <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib39" title="">2023d</a>)</cite>, DocMath-Eval <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib63" title="">2023</a>)</cite>, TABMWP <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib41" title="">2023</a>)</cite> and more, many allowing models to generate answer explanations. The problems typically have brief descriptions, with the challenge lying in creating an expression tree and applying arithmetic knowledge. In contrast, our approach focuses on assessing LLMs’ ability to track key statistics across extremely long contexts.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Sports data has been utilized in various natural language tasks, including data-to-text generation for sports games <cite class="ltx_cite ltx_citemacro_cite">Lareau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib32" title="">2011</a>); Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib62" title="">2016</a>); Wiseman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib56" title="">2017</a>); van der Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib53" title="">2017</a>); Puduppully et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib48" title="">2019</a>)</cite>, real-time game summarization from live commentaries <cite class="ltx_cite ltx_citemacro_cite">Edouard et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib19" title="">2017</a>); Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib26" title="">2020</a>)</cite>; and other aspects such as sports commentator bias <cite class="ltx_cite ltx_citemacro_cite">Merullo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib44" title="">2019</a>)</cite>. Beyond sports, there’s significant interest in annotating and analyzing large-scale game-related corpora, such as reviews and gameplay logs, and summarizing gameplay commentaries <cite class="ltx_cite ltx_citemacro_cite">Lukin (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib42" title="">2020</a>); Kicikoglu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib30" title="">2020</a>); Gu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib23" title="">2022</a>); Furman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib20" title="">2022</a>)</cite>. We anticipate that insights from our <span class="ltx_text ltx_font_typewriter" id="S2.p4.1.1">SportsMetrics</span> benchmark will benefit these areas, enhancing our understanding of game narratives and player dynamics.</p>
</div>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="459" id="S2.F4.g1" src="x4.png" width="872"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An LLM fills in missing key statistics in game summaries through a three-step process. Initially, the LLM creates an internal JSON object as its memory. It then enriches this memory by adding necessary game or player statistics, where all values are set to null, and further reflects on whether this memory is sufficient to accomplish the task. Lastly, the LLM uses detailed play-by-play and team-player data to update the JSON object’s values; it finally utilizes this updated memory to fill in the blanks in the game summary.
</figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The <span class="ltx_text ltx_font_typewriter" id="S3.1.1">SportsMetrics</span> Benchmark</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We collect NBA and NFL play-by-play data from ESPN.com. The descriptions capture the essence of each game. They are typically written by ESPN’s sports journalists, who are experts in their respective sports. We reached out to ESPN as necessary to ensure adherence to their data policies. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>, we use “<em class="ltx_emph ltx_font_italic" id="S3.p1.1.1">time</em>” to indicate the exact moment of each action on the game clock, while “<em class="ltx_emph ltx_font_italic" id="S3.p1.1.2">play</em>” details the actions occurring at those times. Scoring actions, which change the game’s score, are identified but not disclosed to LLMs during our experiments, as are team points. Additionally, we collect data on players’ team affiliations and the game’s box scores for our analysis.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Our task requires LLMs to track key stats across thousands of play-by-play records, which is a non-trivial effort. An ideal LLM needs to associate each action with the right player and their team in order to calculate team-level statistics. It must also monitor multiple key statistics simultaneously, such as field goals, free throws, rebounds, assists, blocks, steals, personal fouls, and turnovers in a basketball game. We believe an LLM’s ability to summarize key details and fill in the missing statistics in game summaries demonstrates its capabilities in data fusion and numerical reasoning.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">We need a comprehensive scoring metric to evaluate LLMs’ ability to monitor key game statistics. Simply reporting individual metrics such as team points, rebounds, assists, and blocks for each team is inefficient and does not provide a holistic view of game analysis. To address this, we employ expert-developed team statistics formulas, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S1.F3" title="Figure 3 ‣ 1 Introduction ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">3</span></a>. We adopt the NBA’s “<em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.p3.1.1">Game Score</em>” by John Hollinger, originally for player evaluation, to measure a team’s overall effectiveness in basketball. It considers both positive (points, rebounds, assists) and negative (missed shots, turnovers) factors. For American football, we apply NCAA’s “<em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.p3.1.2">Passing Efficiency</em>” formula, as the NFL rule is more complex.
In the following sections, we evaluate LLMs under different adversarial scenarios to assess their robustness.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Long-Form Game Narratives</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We begin by examining LLMs’ ability to reason over long contexts. For example, Liu et al. <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib37" title="">2023b</a>)</cite> introduced two tasks, multi-document QA and key-value retrieval, which require the model to identify relevant information within long contexts. They found that LLMs’ performance significantly deteriorates when they have to access relevant information in the middle of long contexts. Our study goes a step further, requiring LLMs to not only identify relevant actions but also accurately track statistics throughout long-form game narratives.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">In this task, each LLM is provided detailed play-by-play descriptions of a sports game, including timestamps and specific actions. The players’ team affiliations are listed in two rows, representing each team. The LLM’s task is to use the play-by-plays to update key game statistics within a JSON object, initially filled with null values. For long-context LLMs such as GPT-4 Turbo, Claude 2.1, and Gemini Pro <cite class="ltx_cite ltx_citemacro_cite">Anil et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib3" title="">2023</a>)</cite>, we provide the entire game’s data at once for processing. For LLMs with 4k or 8k tokens context, we break the game down into four quarters. The LLM gathers statistics quarter by quarter. It generates a JSON object that holds values from each quarter. These are then added up to derive game-level statistics.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S3.T1.1.1.1.1" style="padding-left:8.0pt;padding-right:8.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T1.1.1.1.2" style="padding-left:8.0pt;padding-right:8.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Release Date</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T1.1.1.1.3" style="padding-left:8.0pt;padding-right:8.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">Context Len</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S3.T1.1.1.1.4" style="padding-left:8.0pt;padding-right:8.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.4.1">Input</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S3.T1.1.1.1.5" style="padding-left:8.0pt;padding-right:8.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.5.1">Output</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T1.1.1.1.6" style="padding-left:8.0pt;padding-right:8.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.6.1">Organization</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.2.1.1" style="padding-left:8.0pt;padding-right:8.0pt;">Claude-2.1</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.2.1.2" style="padding-left:8.0pt;padding-right:8.0pt;">11.21.2023</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.2.1.3" style="padding-left:8.0pt;padding-right:8.0pt;">200,000</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.2.1.4" style="padding-left:8.0pt;padding-right:8.0pt;">$.008</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.2.1.5" style="padding-left:8.0pt;padding-right:8.0pt;">$.024</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.2.1.6" style="padding-left:8.0pt;padding-right:8.0pt;">Anthropic</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<td class="ltx_td ltx_align_left" id="S3.T1.1.3.2.1" style="padding-left:8.0pt;padding-right:8.0pt;">GPT-4-1106-preview</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.2.2" style="padding-left:8.0pt;padding-right:8.0pt;">11.06.2023</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.2.3" style="padding-left:8.0pt;padding-right:8.0pt;">128,000</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.3.2.4" style="padding-left:8.0pt;padding-right:8.0pt;">$.01</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.3.2.5" style="padding-left:8.0pt;padding-right:8.0pt;">$.03</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.2.6" style="padding-left:8.0pt;padding-right:8.0pt;">OpenAI</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<td class="ltx_td ltx_align_left" id="S3.T1.1.4.3.1" style="padding-left:8.0pt;padding-right:8.0pt;">Gemini-Pro</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.3.2" style="padding-left:8.0pt;padding-right:8.0pt;">12.06.2023</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.3.3" style="padding-left:8.0pt;padding-right:8.0pt;">32,000</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.4.3.4" style="padding-left:8.0pt;padding-right:8.0pt;">$.001</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.4.3.5" style="padding-left:8.0pt;padding-right:8.0pt;">$.002</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.3.6" style="padding-left:8.0pt;padding-right:8.0pt;">Deepmind</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<td class="ltx_td ltx_align_left" id="S3.T1.1.5.4.1" style="padding-left:8.0pt;padding-right:8.0pt;">GPT-3.5-Turbo-1106</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.4.2" style="padding-left:8.0pt;padding-right:8.0pt;">11.06.2023</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.4.3" style="padding-left:8.0pt;padding-right:8.0pt;">16,385</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.5.4.4" style="padding-left:8.0pt;padding-right:8.0pt;">$.001</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.5.4.5" style="padding-left:8.0pt;padding-right:8.0pt;">$.002</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.4.6" style="padding-left:8.0pt;padding-right:8.0pt;">OpenAI</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<td class="ltx_td ltx_align_left" id="S3.T1.1.6.5.1" style="padding-left:8.0pt;padding-right:8.0pt;">Mistral-7B-Instruct-v0.1</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.6.5.2" style="padding-left:8.0pt;padding-right:8.0pt;">09.27.2023</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.6.5.3" style="padding-left:8.0pt;padding-right:8.0pt;">8,000</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.6.5.4" style="padding-left:8.0pt;padding-right:8.0pt;">—</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.6.5.5" style="padding-left:8.0pt;padding-right:8.0pt;">—</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.6.5.6" style="padding-left:8.0pt;padding-right:8.0pt;">Mistral</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<td class="ltx_td ltx_align_left" id="S3.T1.1.7.6.1" style="padding-left:8.0pt;padding-right:8.0pt;">GPT-3.5-Turbo-0613</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.7.6.2" style="padding-left:8.0pt;padding-right:8.0pt;">06.13.2023</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.7.6.3" style="padding-left:8.0pt;padding-right:8.0pt;">4,096</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.7.6.4" style="padding-left:8.0pt;padding-right:8.0pt;">$.0015</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.7.6.5" style="padding-left:8.0pt;padding-right:8.0pt;">$.0015</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.7.6.6" style="padding-left:8.0pt;padding-right:8.0pt;">OpenAI</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.1.8.7.1" style="padding-left:8.0pt;padding-right:8.0pt;">Llama-2-13B-Chat</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.8.7.2" style="padding-left:8.0pt;padding-right:8.0pt;">07.18.2023</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.8.7.3" style="padding-left:8.0pt;padding-right:8.0pt;">4,096</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.1.8.7.4" style="padding-left:8.0pt;padding-right:8.0pt;">—</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.1.8.7.5" style="padding-left:8.0pt;padding-right:8.0pt;">—</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.8.7.6" style="padding-left:8.0pt;padding-right:8.0pt;">Meta</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>LLMs used in this study. Prices are per 1,000 tokens. Llama-2 and Mistral-7B are free and open-source.
</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We use comprehensive, expert-devised formulas to evaluate LLMs in tracking game statistics.
For NBA games, we monitor 11 key statistics: <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.1">team points</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.2">field goals made</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.3">field goals attempted</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.4">free throws made</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.5">free throws attempted</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.6">offensive rebounds</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.7">defensive rebounds</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.8">steals</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.9">assists</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.10">blocks</em>, and <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.11">personal fouls</em>.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We exclude <em class="ltx_emph ltx_font_italic" id="footnote1.1">turnovers</em> from tracking due to limitations in the data. Play-by-play descriptions may not capture every turnover, making it difficult for the model to track them accurately. When necessary, we rely on the ground-truth Turnover count from the box score to calculate the Game Score.</span></span></span> Moreover, we calculate ‘Game Score’ to measure a team’s overall effectiveness in basketball. For NFL games, we track <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.12">passing yards</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.13">touchdowns</em>, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.14">interceptions</em>, and <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.15">pass completions</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.16">attempts</em>. These additional stats allow for the computation of ‘Passing Efficiency.’</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>The Impact of Changing Game Rules</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">It is important to understand LLMs’ ability to make decisions under changing world rules. LLMs possess extensive knowledge from pretraining on the Internet, books, and other texts. This knowledge, held in their parametric memory, might not always align with the external evidence given to the model. Therefore, LLMs need to adjust to changing rules. Xie et al. <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib57" title="">2023</a>)</cite> highlight the importance of knowing when to trust a model’s own knowledge. Meng et al. <cite class="ltx_cite ltx_citemacro_cite">Meng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib43" title="">2023</a>)</cite> explored finetuning LLMs to alter specific knowledge, but such changes are often irreversible. Here, we propose two tasks to evaluate LLMs’ abilities in adapting to new game rules.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">New Scoring Rules</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">We examine the impact of changing game rules on final scores. For basketball, scoring events such as free throws, three-pointers, field goals, vary from 1 to 3 points. We ask LLMs to maintain these scoring events but under a new rule where each action is worth only 1 point. This contradicts LLMs’ existing knowledge, challenging them to recalibrate game scores accordingly. Ground-truth scores under this rule are obtained by counting the total number of scoring actions to determine each team’s total points.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Player Swapping</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">We randomly swapped player team affiliations in the table without changing the game’s play-by-play records, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>. Ground-truth team scores for this task are calculated by summing individual player scores under their new affiliations. This task allows us to vary the degree of conflict between the model’s existing knowledge and the provided evidence. Swapping more players increases the task’s difficulty.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.5.5">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T2.5.5.6" style="padding-left:5.3pt;padding-right:5.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S3.T2.5.5.7" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.7.1">System</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T2.1.1.1" style="padding-left:5.3pt;padding-right:5.3pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.m1.1a"><mi id="S3.T2.1.1.1.m1.1.1" mathvariant="normal" xref="S3.T2.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1">GScore</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T2.2.2.2" style="padding-left:5.3pt;padding-right:5.3pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.m1.1a"><mi id="S3.T2.2.2.2.m1.1.1" mathvariant="normal" xref="S3.T2.2.2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.1">Points</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T2.3.3.3" style="padding-left:5.3pt;padding-right:5.3pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.3.3.3.m1.1"><semantics id="S3.T2.3.3.3.m1.1a"><mi id="S3.T2.3.3.3.m1.1.1" mathvariant="normal" xref="S3.T2.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.m1.1b"><ci id="S3.T2.3.3.3.m1.1.1.cmml" xref="S3.T2.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.3.3.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.3.1">NewRule</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T2.4.4.4" style="padding-left:5.3pt;padding-right:5.3pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.4.4.4.m1.1"><semantics id="S3.T2.4.4.4.m1.1a"><mi id="S3.T2.4.4.4.m1.1.1" mathvariant="normal" xref="S3.T2.4.4.4.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.m1.1b"><ci id="S3.T2.4.4.4.m1.1.1.cmml" xref="S3.T2.4.4.4.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.4.4.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.4.1">Swap</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S3.T2.5.5.5" style="padding-left:5.3pt;padding-right:5.3pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.5.5.5.m1.1"><semantics id="S3.T2.5.5.5.m1.1a"><mi id="S3.T2.5.5.5.m1.1.1" mathvariant="normal" xref="S3.T2.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.m1.1b"><ci id="S3.T2.5.5.5.m1.1.1.cmml" xref="S3.T2.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.5.5.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.5.1">Shuffle</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T2.5.6.1.1" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.6.1.1.1">Long-Context</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T2.5.6.1.2" style="padding-left:5.3pt;padding-right:5.3pt;">GPT-3.5-Turbo-1106</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.5.6.1.3" style="padding-left:5.3pt;padding-right:5.3pt;">33.50</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.5.6.1.4" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.6.1.4.1">9.45</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.5.6.1.5" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.6.1.5.1">14.10</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.5.6.1.6" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.6.1.6.1">13.53</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.5.6.1.7" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.6.1.7.1">9.89</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.5.7.2.1" style="padding-left:5.3pt;padding-right:5.3pt;">(16k+ Tokens)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.5.7.2.2" style="padding-left:5.3pt;padding-right:5.3pt;">Gemini-Pro</th>
<td class="ltx_td ltx_align_right" id="S3.T2.5.7.2.3" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.7.2.3.1">32.30</span></td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.7.2.4" style="padding-left:5.3pt;padding-right:5.3pt;">17.62</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.7.2.5" style="padding-left:5.3pt;padding-right:5.3pt;">25.99</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.7.2.6" style="padding-left:5.3pt;padding-right:5.3pt;">17.78</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.7.2.7" style="padding-left:5.3pt;padding-right:5.3pt;">14.85</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.8.3">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T2.5.8.3.1" style="padding-left:5.3pt;padding-right:5.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.5.8.3.2" style="padding-left:5.3pt;padding-right:5.3pt;">GPT-4-1106-preview</th>
<td class="ltx_td ltx_align_right" id="S3.T2.5.8.3.3" style="padding-left:5.3pt;padding-right:5.3pt;">51.97</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.8.3.4" style="padding-left:5.3pt;padding-right:5.3pt;">25.17</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.8.3.5" style="padding-left:5.3pt;padding-right:5.3pt;">14.55</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.8.3.6" style="padding-left:5.3pt;padding-right:5.3pt;">39.91</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.8.3.7" style="padding-left:5.3pt;padding-right:5.3pt;">49.57</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.9.4">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T2.5.9.4.1" style="padding-left:5.3pt;padding-right:5.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.5.9.4.2" style="padding-left:5.3pt;padding-right:5.3pt;">Claude-2.1</th>
<td class="ltx_td ltx_align_right" id="S3.T2.5.9.4.3" style="padding-left:5.3pt;padding-right:5.3pt;">55.16</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.9.4.4" style="padding-left:5.3pt;padding-right:5.3pt;">21.73</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.9.4.5" style="padding-left:5.3pt;padding-right:5.3pt;">22.28</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.9.4.6" style="padding-left:5.3pt;padding-right:5.3pt;">17.12</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.9.4.7" style="padding-left:5.3pt;padding-right:5.3pt;">31.11</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.5.10.5.1" style="padding-left:5.3pt;padding-right:5.3pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.10.5.1.1">Standard</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.5.10.5.2" style="padding-left:5.3pt;padding-right:5.3pt;">GPT-3.5-Turbo-0613</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.5.10.5.3" style="padding-left:5.3pt;padding-right:5.3pt;">114.28</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.5.10.5.4" style="padding-left:5.3pt;padding-right:5.3pt;">94.34</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.5.10.5.5" style="padding-left:5.3pt;padding-right:5.3pt;">18.22</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.5.10.5.6" style="padding-left:5.3pt;padding-right:5.3pt;">88.25</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.5.10.5.7" style="padding-left:5.3pt;padding-right:5.3pt;">89.11</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.5.11.6.1" style="padding-left:5.3pt;padding-right:5.3pt;">(4k to 8k Tokens)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.5.11.6.2" style="padding-left:5.3pt;padding-right:5.3pt;">Mistral-7B-Instuct</th>
<td class="ltx_td ltx_align_right" id="S3.T2.5.11.6.3" style="padding-left:5.3pt;padding-right:5.3pt;">123.49</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.11.6.4" style="padding-left:5.3pt;padding-right:5.3pt;">73.53</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.11.6.5" style="padding-left:5.3pt;padding-right:5.3pt;">26.79</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.11.6.6" style="padding-left:5.3pt;padding-right:5.3pt;">70.69</td>
<td class="ltx_td ltx_align_right" id="S3.T2.5.11.6.7" style="padding-left:5.3pt;padding-right:5.3pt;">103.24</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.12.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S3.T2.5.12.7.1" style="padding-left:5.3pt;padding-right:5.3pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T2.5.12.7.2" style="padding-left:5.3pt;padding-right:5.3pt;">Llama-2-13B-Chat</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.5.12.7.3" style="padding-left:5.3pt;padding-right:5.3pt;">110.69</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.5.12.7.4" style="padding-left:5.3pt;padding-right:5.3pt;">70.77</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.5.12.7.5" style="padding-left:5.3pt;padding-right:5.3pt;">83.04</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.5.12.7.6" style="padding-left:5.3pt;padding-right:5.3pt;">53.98</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.5.12.7.7" style="padding-left:5.3pt;padding-right:5.3pt;">81.09</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Average absolute difference between model predictions and the actual scores on NBA data for tracking a team’s total points (<span class="ltx_text ltx_font_bold" id="S3.T2.17.1">Points</span>) and all key game statistics (<span class="ltx_text ltx_font_bold" id="S3.T2.18.2">GScore</span>). Moreover, we evaluate LLMs’ performance in three adversarial scenarios: <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.9.m1.1"><semantics id="S3.T2.9.m1.1b"><mi id="S3.T2.9.m1.1.1" mathvariant="normal" xref="S3.T2.9.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.9.m1.1c"><ci id="S3.T2.9.m1.1.1.cmml" xref="S3.T2.9.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.9.m1.1e">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.19.3">NewRule</span>, <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.10.m2.1"><semantics id="S3.T2.10.m2.1b"><mi id="S3.T2.10.m2.1.1" mathvariant="normal" xref="S3.T2.10.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.10.m2.1c"><ci id="S3.T2.10.m2.1.1.cmml" xref="S3.T2.10.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.10.m2.1e">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.20.4">Swap</span> and <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.11.m3.1"><semantics id="S3.T2.11.m3.1b"><mi id="S3.T2.11.m3.1.1" mathvariant="normal" xref="S3.T2.11.m3.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.11.m3.1c"><ci id="S3.T2.11.m3.1.1.cmml" xref="S3.T2.11.m3.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.m3.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.11.m3.1e">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S3.T2.21.5">Shuffle</span>.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Robustness Against Noise</h3>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Shuffling Play-by-Plays</h4>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">We present an adversarial challenge where we shuffle basketball game play-by-play descriptions and then ask LLMs to track the total points of each team. We choose basketball because adjacent actions in this context do not show strong causal relationships. Changing the sequence of scoring actions does not affect the teams’ total points. We anticipate that long-context LLMs will produce consistent or similar final game scores. To avoid confusing the model, we maintain the original order of timestamps.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p2.1">We can also adjust the frequency of scoring plays in a game, making it more or less challenging for LLMs to process the narrative. By choosing a probability <math alttext="p" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS3.SSS0.Px1.p2.1.m1.1a"><mi id="S3.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.1.m1.1b"><ci id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.1.m1.1d">italic_p</annotation></semantics></math> from a set of values {-50%, -20%, 0, +20%, +50%}, we can either duplicate non-scoring plays (thereby decreasing scoring play density and extending the game narrative) or remove them (increasing scoring play density). Further, to test the LLM’s inherent knowledge, we randomly select players from each team in NFL games and assign them new names, such as characters from science fictions. This approach evaluates the model’s ability to adapt to changes in player identities. These alterations do not introduce new players or change the total points scored in the game; it simply varies the narrative’s complexity.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="243" id="S3.F5.g1" src="x5.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Effective working memory is key in this task.
The variance in memory structure arises because we allowed each LLM to generate its JSON object as working memory, without enforcing a uniform schema. This step allows us to explore how each model organizes its memory to complete the task.
Note that Claude’s ‘null’ values represent an initial state rather than an inability to aggregate information.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Planning for Complex Data Queries</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In this task, LLMs fill in missing key statistics from game summaries (e.g., from ESPN). The process unfolds in three steps, illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S2.F4" title="Figure 4 ‣ 2 Related Work ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">4</span></a>. First, the LLM creates an internal JSON object memory, initially with placeholders for team points. Next, it enriches this memory by adding crucial game or player statistics. During a self-reflection phase, the LLM evaluates if its JSON memory can accurately complete the missing statistics for the given game recap. If it can, it responds with this memory; if not, it further refines the memory structure. Finally, using the detailed play-by-play and team-player data, the LLM updates the key statistics in the JSON format, then uses this information to fill in the blanks in the game summary. Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.F5" title="Figure 5 ‣ Shuffling Play-by-Plays ‣ 3.3 Robustness Against Noise ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates various LLM attempts building a memory.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">Our task is inspired by several studies on LLM planning. Unlike LLM+P which uses the Planning Domain Definition Language (PDDL) for problem-solving <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib35" title="">2023a</a>)</cite>, we simplify the process by requiring only a valid JSON object for working memory. Relevant studies such as Reflexion <cite class="ltx_cite ltx_citemacro_cite">Shinn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib50" title="">2023</a>)</cite>, ReAct <cite class="ltx_cite ltx_citemacro_cite">Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib61" title="">2023b</a>)</cite>, and Tree-of-thought <cite class="ltx_cite ltx_citemacro_cite">Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib60" title="">2023a</a>)</cite> have also influenced our approach. Sumers et al. <cite class="ltx_cite ltx_citemacro_cite">Sumers et al. (<a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#bib.bib52" title="">2023</a>)</cite> have developed a framework for integrating planning into LLM agents. Prior studies have focused on ALFWorld’s interactive TextWorld environments. Our method are focused on sports, which involves masking key statistics in game recaps by sports journalists, then converting them into task data points for LLMs. We assess LLMs by their accuracy in filling in missing key statistics from game summaries.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.6.6">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T3.6.6.7" style="padding-left:5.0pt;padding-right:5.0pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T3.6.6.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.8.1">System</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.m1.1.1" mathvariant="normal" xref="S4.T3.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1">Yards</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"> <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.m1.1a"><mi id="S4.T3.2.2.2.m1.1.1" mathvariant="normal" xref="S4.T3.2.2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.1">ATT</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.m1.1a"><mi id="S4.T3.3.3.3.m1.1.1" mathvariant="normal" xref="S4.T3.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.1">COMP</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"> <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.4.4.4.m1.1"><semantics id="S4.T3.4.4.4.m1.1a"><mi id="S4.T3.4.4.4.m1.1.1" mathvariant="normal" xref="S4.T3.4.4.4.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><ci id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.1">TD</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.5.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.5.5.5.m1.1"><semantics id="S4.T3.5.5.5.m1.1a"><mi id="S4.T3.5.5.5.m1.1.1" mathvariant="normal" xref="S4.T3.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><ci id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.1">INT</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.6.6.6" style="padding-left:5.0pt;padding-right:5.0pt;"> <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T3.6.6.6.m1.1"><semantics id="S4.T3.6.6.6.m1.1a"><mi id="S4.T3.6.6.6.m1.1.1" mathvariant="normal" xref="S4.T3.6.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><ci id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.1">PE</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T3.6.7.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.1.1">Long-Context</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T3.6.7.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">GPT-4-1106-Preview</th>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.6.7.1.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.3.1">34.77</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.6.7.1.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.4.1">4.44</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.6.7.1.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.5.1">2.96</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.6.7.1.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.6.1">0.17</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.6.7.1.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.7.1">0.13</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S4.T3.6.7.1.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.8.1">14.33</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.8.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.8.2.1" style="padding-left:5.0pt;padding-right:5.0pt;">(16k+ Tokens)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.8.2.2" style="padding-left:5.0pt;padding-right:5.0pt;">Claude-2.1</th>
<td class="ltx_td ltx_align_right" id="S4.T3.6.8.2.3" style="padding-left:5.0pt;padding-right:5.0pt;">52.53</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.8.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">5.43</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.8.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">3.75</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.8.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">0.29</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.8.2.7" style="padding-left:5.0pt;padding-right:5.0pt;">0.22</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.8.2.8" style="padding-left:5.0pt;padding-right:5.0pt;">17.53</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.9.3">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T3.6.9.3.1" style="padding-left:5.0pt;padding-right:5.0pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.9.3.2" style="padding-left:5.0pt;padding-right:5.0pt;">GPT-3.5-Turbo-1106</th>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">64.87</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">7.80</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">4.73</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">0.49</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.3.7" style="padding-left:5.0pt;padding-right:5.0pt;">0.30</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.3.8" style="padding-left:5.0pt;padding-right:5.0pt;">18.43</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.10.4">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T3.6.10.4.1" style="padding-left:5.0pt;padding-right:5.0pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.10.4.2" style="padding-left:5.0pt;padding-right:5.0pt;">Gemini-Pro</th>
<td class="ltx_td ltx_align_right" id="S4.T3.6.10.4.3" style="padding-left:5.0pt;padding-right:5.0pt;">85.14</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.10.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">12.68</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.10.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">6.87</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.10.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">0.83</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.10.4.7" style="padding-left:5.0pt;padding-right:5.0pt;">0.52</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.10.4.8" style="padding-left:5.0pt;padding-right:5.0pt;">26.17</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.11.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.6.11.5.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.11.5.1.1">Standard</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.6.11.5.2" style="padding-left:5.0pt;padding-right:5.0pt;">GPT-3.5-0613</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.11.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">105.68</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.11.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">24.11</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.11.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">15.80</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.11.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">1.09</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.11.5.7" style="padding-left:5.0pt;padding-right:5.0pt;">0.60</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.11.5.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.6.11.5.8.1">89.56</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.12.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.12.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">(4k to 8k Tokens)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.12.6.2" style="padding-left:5.0pt;padding-right:5.0pt;">Llama-2-13B-Chat</th>
<td class="ltx_td ltx_align_right" id="S4.T3.6.12.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">244.48</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.12.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">22.37</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.12.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">19.66</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.12.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">1.47</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.12.6.7" style="padding-left:5.0pt;padding-right:5.0pt;">1.03</td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.12.6.8" style="padding-left:5.0pt;padding-right:5.0pt;">191.76</td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.13.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S4.T3.6.13.7.1" style="padding-left:5.0pt;padding-right:5.0pt;"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.6.13.7.2" style="padding-left:5.0pt;padding-right:5.0pt;">Mistral-7B-Instuct</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.6.13.7.3" style="padding-left:5.0pt;padding-right:5.0pt;">119.31</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.6.13.7.4" style="padding-left:5.0pt;padding-right:5.0pt;">17.64</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.6.13.7.5" style="padding-left:5.0pt;padding-right:5.0pt;">9.05</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.6.13.7.6" style="padding-left:5.0pt;padding-right:5.0pt;">1.23</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.6.13.7.7" style="padding-left:5.0pt;padding-right:5.0pt;">0.69</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.6.13.7.8" style="padding-left:5.0pt;padding-right:5.0pt;">202.07</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>
Discrepancies between model predictions and actual scores on NFL stats, including yards (<span class="ltx_text ltx_font_bold" id="S4.T3.13.1">Yards</span>), attempts (<span class="ltx_text ltx_font_bold" id="S4.T3.14.2">ATT</span>), completions (<span class="ltx_text ltx_font_bold" id="S4.T3.15.3">COMP</span>), touchdowns (<span class="ltx_text ltx_font_bold" id="S4.T3.16.4">TD</span>), interceptions (<span class="ltx_text ltx_font_bold" id="S4.T3.17.5">INT</span>) and passing efficiency (<span class="ltx_text ltx_font_bold" id="S4.T3.18.6">PE</span>).
</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">We evaluate various LLMs in our <span class="ltx_text ltx_font_typewriter" id="S4.p1.2.1">SportsMetrics</span> benchmark. These models are listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.T1" title="Table 1 ‣ 3.1 Long-Form Game Narratives ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">1</span></a> and split into two categories: long-context LLMs, capable of processing over 16k tokens, and standard LLMs, handling 4k to 8k tokens. Our evaluation focuses on their ability to accurately track a team’s total points (<span class="ltx_text ltx_font_bold" id="S4.p1.2.2">Points</span>) and all key game statistics (<span class="ltx_text ltx_font_bold" id="S4.p1.2.3">GameScore</span>). We measure the average absolute difference (deviation) between the models’ predictions and the actual box scores, denoted as <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" mathvariant="normal" xref="S4.p1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">roman_Δ</annotation></semantics></math>Points and <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" mathvariant="normal" xref="S4.p1.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">roman_Δ</annotation></semantics></math>GScore, respectively.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><math alttext="\Delta" class="ltx_Math" display="inline" id="footnote2.m1.1"><semantics id="footnote2.m1.1b"><mi id="footnote2.m1.1.1" mathvariant="normal" xref="footnote2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><ci id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="footnote2.m1.1e">roman_Δ</annotation></semantics></math>GScore consistently shows higher values compared to <math alttext="\Delta" class="ltx_Math" display="inline" id="footnote2.m2.1"><semantics id="footnote2.m2.1b"><mi id="footnote2.m2.1.1" mathvariant="normal" xref="footnote2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="footnote2.m2.1e">roman_Δ</annotation></semantics></math>Points because it goes beyond counting a team’s points. It offers a full game analysis by requiring the LLM to consolidate key statistics such as points, rebounds, steals, assists and more into an overall score. Considering only team points is insufficient, especially in sports like soccer where scoring is rare. When necessary, we can convert GameScore to points by zeroing out other stats.</span></span></span></p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Our dataset comprises 28,492 NBA games and 5,867 NFL games spanning two decades from 2002 to 2023, available through ESPN’s archives. We randomly selected 100 games from each sport for our test set. On average, NBA games contain 466 plays and NFL games 173 plays. An average NBA game includes 6,229 tokens, while an NFL game has 6,166 tokens, with maximum lengths reaching 7,322 and 7,659 tokens, respectively.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.4">LLMs’ ability to integrate information is tested under three adversarial scenarios: (a) ‘<span class="ltx_text ltx_font_bold" id="S4.p3.4.1">NewRule</span>,’ which assigns every scoring action just one point, regardless of the move, (b) ‘<span class="ltx_text ltx_font_bold" id="S4.p3.4.2">Swap</span>’ which randomly selects two players from each team to swap their affiliations in the team-player table, (c) ‘<span class="ltx_text ltx_font_bold" id="S4.p3.4.3">Shuffle</span>,’ which duplicates any non-scoring action with a 20% chance (<math alttext="p" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_p</annotation></semantics></math>=0.2) before shuffling the play-by-plays. We assess LLMs’ performance in these scenarios and report the deviation of predicted team points from actual scores as <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p3.2.m2.1"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" mathvariant="normal" xref="S4.p3.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.1d">roman_Δ</annotation></semantics></math>NewRule, <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p3.3.m3.1"><semantics id="S4.p3.3.m3.1a"><mi id="S4.p3.3.m3.1.1" mathvariant="normal" xref="S4.p3.3.m3.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><ci id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p3.3.m3.1d">roman_Δ</annotation></semantics></math>Swap and <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p3.4.m4.1"><semantics id="S4.p3.4.m4.1a"><mi id="S4.p3.4.m4.1.1" mathvariant="normal" xref="S4.p3.4.m4.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><ci id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p3.4.m4.1d">roman_Δ</annotation></semantics></math>Shuffle.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.2">In Table <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.T2" title="Table 2 ‣ Player Swapping ‣ 3.2 The Impact of Changing Game Rules ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>, we present our findings from the NBA section of our dataset. With <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p4.1.m1.1"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" mathvariant="normal" xref="S4.p4.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p4.1.m1.1d">roman_Δ</annotation></semantics></math> representing the gap between predictions and actual scores, smaller values are preferable. We find that long-context LLMs significantly outperform standard LLMs across all tasks. GPT-3.5-Turbo-1106 leads in performance in every task except for <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p4.2.m2.1"><semantics id="S4.p4.2.m2.1a"><mi id="S4.p4.2.m2.1.1" mathvariant="normal" xref="S4.p4.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><ci id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p4.2.m2.1d">roman_Δ</annotation></semantics></math>GScore, where Gemini-Pro has a slight edge. Long-context models have been released recently in late 2023. These results demonstrate their remarkable ability in identifying relevant actions from game play-by-plays, attributing each action to the right player and team, and aggregating numerical data to compute final team points and GameScore.
This requires a level of numerical reasoning that humans are adept at but it is still new territory for LLMs.</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S4.F6" title="Figure 6 ‣ 4 Experiments ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">6</span></a>, we organize games based on the length (number of tokens) of their play-by-play descriptions, with the x-axis showing the games and the y-axis the deviation scores from various LLMs, where lower scores indicate better performance. We perform a regression analysis to demonstrate each LLM’s trend in handling games of increasing length. GPT-3.5-Turbo-1106 and Gemini-Pro stand out, maintaining nearly flat curves, which corresponds with their superior performance as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.T2" title="Table 2 ‣ Player Swapping ‣ 3.2 The Impact of Changing Game Rules ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>. By contrast, GPT-4-1106-Preview does well in shorter games but face difficulties in aggregating key statistics for longer games. Additionally, 79% its returned JSON objects contain zeros or null values, contributing to its unsatisfying performance on this task.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="325" id="S4.F6.g1" src="x6.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>We organize games based on the length of their play-by-plays, with the x-axis showing the games and the y-axis the deviation scores; lower scores indicate better performance. GPT-3.5-Turbo-1106 and Gemini-Pro stand out here, maintaining nearly flat curves.
</figcaption>
</figure>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1">We note that basketball teams typically score between 100 to 120 points. Our findings show that the smallest prediction gap for <math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p6.1.m1.1"><semantics id="S4.p6.1.m1.1a"><mi id="S4.p6.1.m1.1.1" mathvariant="normal" xref="S4.p6.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.1b"><ci id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p6.1.m1.1d">roman_Δ</annotation></semantics></math>Points is 9.45, while the largest can exceed 100. This indicates the difficulty in accurately tracking key game statistics over long contexts, as <em class="ltx_emph ltx_font_italic" id="S4.p6.1.1">standard LLMs can produce predictions significantly off from actual scores due to hallucinations.</em> Among the three adversarial scenarios, the New Rule is relatively simpler as it requires LLMs to assign one point to every scoring action, focusing on counting these actions instead of distinguishing between types (3-pointers vs. free throws) and adding them up for a team’s score. In this scenario, Llama-2-13B-Chat scores lower than all other LLMs.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="306" id="S4.F7.g1" src="x7.png" width="858"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>
(<span class="ltx_text ltx_font_smallcaps" id="S4.F7.8.1">Left</span>) We adjust the difficulty of identifying scoring events by either removing or duplicating non-scoring events. Moreover, we randomly swapped <math alttext="n" class="ltx_Math" display="inline" id="S4.F7.3.m1.1"><semantics id="S4.F7.3.m1.1b"><mi id="S4.F7.3.m1.1.1" xref="S4.F7.3.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.F7.3.m1.1c"><ci id="S4.F7.3.m1.1.1.cmml" xref="S4.F7.3.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.3.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="S4.F7.3.m1.1e">italic_n</annotation></semantics></math> players’ affiliations in the team-player table (<span class="ltx_text ltx_font_smallcaps" id="S4.F7.9.2">Middle</span>) and replaced <math alttext="n" class="ltx_Math" display="inline" id="S4.F7.4.m2.1"><semantics id="S4.F7.4.m2.1b"><mi id="S4.F7.4.m2.1.1" xref="S4.F7.4.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.F7.4.m2.1c"><ci id="S4.F7.4.m2.1.1.cmml" xref="S4.F7.4.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.m2.1d">n</annotation><annotation encoding="application/x-llamapun" id="S4.F7.4.m2.1e">italic_n</annotation></semantics></math> players’ names with science fiction characters (<span class="ltx_text ltx_font_smallcaps" id="S4.F7.10.3">Right</span>), all without changing the play-by-play texts.
</figcaption>
</figure>
<div class="ltx_para" id="S4.p7">
<p class="ltx_p" id="S4.p7.6">In Table <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S4.T3" title="Table 3 ‣ 4 Experiments ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">3</span></a>, we present NFL data findings. American football’s play-by-plays have demonstrated a sequential nature, we cannot apply tests like New Rule, Swap, or Shuffle as with basketball games. Instead, we measure how model predictions deviate from actual scores on key game statistics, including yards (<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p7.1.m1.1"><semantics id="S4.p7.1.m1.1a"><mi id="S4.p7.1.m1.1.1" mathvariant="normal" xref="S4.p7.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.1.m1.1b"><ci id="S4.p7.1.m1.1.1.cmml" xref="S4.p7.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p7.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.p7.6.1">Yards</span>), attempts (<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p7.2.m2.1"><semantics id="S4.p7.2.m2.1a"><mi id="S4.p7.2.m2.1.1" mathvariant="normal" xref="S4.p7.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.2.m2.1b"><ci id="S4.p7.2.m2.1.1.cmml" xref="S4.p7.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p7.2.m2.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.p7.6.2">ATT</span>), completions (<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p7.3.m3.1"><semantics id="S4.p7.3.m3.1a"><mi id="S4.p7.3.m3.1.1" mathvariant="normal" xref="S4.p7.3.m3.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.3.m3.1b"><ci id="S4.p7.3.m3.1.1.cmml" xref="S4.p7.3.m3.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.3.m3.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p7.3.m3.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.p7.6.3">COMP</span>), touchdowns (<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p7.4.m4.1"><semantics id="S4.p7.4.m4.1a"><mi id="S4.p7.4.m4.1.1" mathvariant="normal" xref="S4.p7.4.m4.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.4.m4.1b"><ci id="S4.p7.4.m4.1.1.cmml" xref="S4.p7.4.m4.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.4.m4.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p7.4.m4.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.p7.6.4">TD</span>), and interceptions (<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p7.5.m5.1"><semantics id="S4.p7.5.m5.1a"><mi id="S4.p7.5.m5.1.1" mathvariant="normal" xref="S4.p7.5.m5.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.5.m5.1b"><ci id="S4.p7.5.m5.1.1.cmml" xref="S4.p7.5.m5.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.5.m5.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p7.5.m5.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.p7.6.5">INT</span>). We also combine them into Passing Efficiency (<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.p7.6.m6.1"><semantics id="S4.p7.6.m6.1a"><mi id="S4.p7.6.m6.1.1" mathvariant="normal" xref="S4.p7.6.m6.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.6.m6.1b"><ci id="S4.p7.6.m6.1.1.cmml" xref="S4.p7.6.m6.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.6.m6.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.p7.6.m6.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.p7.6.6">PE</span>) for a holistic game analysis. Our results suggest that long-context LLMs greatly surpass standard models, with GPT-4-1106-Preview taking the lead, followed by Claude-2.1 and GPT-3.5-Turbo-1106.</p>
</div>
<div class="ltx_para" id="S4.p8">
<p class="ltx_p" id="S4.p8.1">Particularly, passing yards are vital in the NFL games, often leading to scoring opportunities like touchdowns and field goals. On average, NFL teams average 200 to 250 passing yards per game. We find that the top model, GPT-4-1106-Preview, exhibits a 34.77-yard discrepancy in passing yards prediction, while the open-source Llama-2-13B-Chat lags significantly in comparison. This highlights the difficulty of tracking passing yards, a task even more challenging than summarizing basketball points, with most models struggling to accurately aggregate such data.</p>
</div>
<div class="ltx_para" id="S4.p9">
<p class="ltx_p" id="S4.p9.1">Our results suggest that the difference in performance between GPT-3.5-Turbo-1106 and GPT-4 across basketball and football games stems from the scoring frequency in each sport. Basketball’s frequent scoring presents a challenge for GPT-4-1106-Preview to track all actions, while football, with less frequent scoring, is somewhat easier for the model to track. GPT-4-1106-Preview is optimized for handling extremely long contexts and it is less accurate in tracking frequent scoring. This distinct characteristic accounts for the varied performance of both models.</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="304" id="S4.F8.g1" src="x8.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Accuracy of various LLMs in filling missing key statistics from basketball game recaps. Claude-2.1 shows strong performance, while Mistral-7B-Instruct achieves the highest accuracy among standard LLMs. </figcaption>
</figure>
<div class="ltx_para" id="S4.p10">
<p class="ltx_p" id="S4.p10.2">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S4.F7" title="Figure 7 ‣ 4 Experiments ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">7</span></a>, we test LLMs’ robustness against adversarial conditions. In the left subfigure, we vary the difficulty of identifying scoring events by either dropping or duplicating non-scoring events. E.g., at probability <math alttext="p" class="ltx_Math" display="inline" id="S4.p10.1.m1.1"><semantics id="S4.p10.1.m1.1a"><mi id="S4.p10.1.m1.1.1" xref="S4.p10.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.p10.1.m1.1b"><ci id="S4.p10.1.m1.1.1.cmml" xref="S4.p10.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S4.p10.1.m1.1d">italic_p</annotation></semantics></math>=-0.5, we eliminate any non-scoring event with a 50% chance; at <math alttext="p" class="ltx_Math" display="inline" id="S4.p10.2.m2.1"><semantics id="S4.p10.2.m2.1a"><mi id="S4.p10.2.m2.1.1" xref="S4.p10.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.p10.2.m2.1b"><ci id="S4.p10.2.m2.1.1.cmml" xref="S4.p10.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S4.p10.2.m2.1d">italic_p</annotation></semantics></math>=0.2, we duplicate any non-scoring event with a 20% chance, before shuffling the entire game description. The y-axis measures the deviation from the actual box score, with smaller values indicating better model performance. We observe that <em class="ltx_emph ltx_font_italic" id="S4.p10.2.1">GPT-3.5-Turbo-1106 and Gemini-Pro perform the best, whose curves are quite flat, indicating their robustness to a varying level of noise in the play-by-plays.</em> Overall, LLMs perform well when non-scoring events are removed, yet their performance drops as more non-scoring events are added, akin to searching for a needle in a larger haystack.</p>
</div>
<div class="ltx_para" id="S4.p11">
<p class="ltx_p" id="S4.p11.2">Further, we randomly swapped <math alttext="n" class="ltx_Math" display="inline" id="S4.p11.1.m1.1"><semantics id="S4.p11.1.m1.1a"><mi id="S4.p11.1.m1.1.1" xref="S4.p11.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p11.1.m1.1b"><ci id="S4.p11.1.m1.1.1.cmml" xref="S4.p11.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p11.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p11.1.m1.1d">italic_n</annotation></semantics></math> players’ affiliations in the team-player table and replaced <math alttext="n" class="ltx_Math" display="inline" id="S4.p11.2.m2.1"><semantics id="S4.p11.2.m2.1a"><mi id="S4.p11.2.m2.1.1" xref="S4.p11.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p11.2.m2.1b"><ci id="S4.p11.2.m2.1.1.cmml" xref="S4.p11.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p11.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p11.2.m2.1d">italic_n</annotation></semantics></math> players’ names with science fiction characters, all without changing the play-by-play texts. Our findings are shown in the middle and right subfigures. We find that Claude-2.1, Gemini-Pro, and GPT-3.5-Turbo-1106 are the top performers. Interestingly, <em class="ltx_emph ltx_font_italic" id="S4.p11.2.1">renaming players significantly decreases all models’ performance. This suggests LLMs may use familiar basketball player names from their pretraining to guess team scores, rather than analyzing the actual play-by-plays.</em> GPT-4-1106-Preview is the least adaptable to these adversarial conditions among the long-context LLMs. We also observe a notable performance disparity exists between open-source and proprietary LLMs.</p>
</div>
<div class="ltx_para" id="S4.p12">
<p class="ltx_p" id="S4.p12.1">We assess the accuracy of various LLMs in completing missing key statistics from basketball game recaps. The types of missing data include a player’s total points, team scores, assists, rebounds, and other stats. An LLM must understand the recap’s context to precisely estimate the missing statistic. To do this, LLMs create a JSON object as its working memory. They then calculate the needed statistics using play-by-play and team-player data and use this memory object to fill in the blanks.</p>
</div>
<div class="ltx_para" id="S4.p13">
<p class="ltx_p" id="S4.p13.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S4.F8" title="Figure 8 ‣ 4 Experiments ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">8</span></a> presents the results of this task. Claude-2.1 shows strong performance, while Mistral-7B-Instruct achieves the highest accuracy among standard LLMs. This task requires that LLMs possess strong instruction-following capabilities to build an effective working memory. Figure <a class="ltx_ref" href="https://arxiv.org/html/2402.10979v2#S3.F5" title="Figure 5 ‣ Shuffling Play-by-Plays ‣ 3.3 Robustness Against Noise ‣ 3 The SportsMetrics Benchmark ‣ SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs"><span class="ltx_text ltx_ref_tag">5</span></a> provides sample working memories from various LLMs. Although complex structures are possible, they increase the risk of errors when populating values. Models such as GPT-4-1106-Preview and Llama-2-13B-Chat face difficulties in creating a working memory. They hallucinate field values or fail to accurately fill fields with aggregated values from play-by-play data. By contrast, Claude-2.1’s memory structure is the best in terms of efficiency, focusing on essential game statistics. Our task crucially evaluates LLMs’ memory management skills when handling complex data queries.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We introduce <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.1">SportsMetrics</span>, a novel benchmark designed to evaluate LLMs in sports data analytics. It assess LLMs’ numerical reasoning and fusion abilities through challenges such as new game rules, lengthy descriptions, scrambled narratives and key stats analysis in game summaries. <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.2">SportsMetrics</span> highlights LLMs’ potential in fields such as multiplayer gaming and collaborative workspaces.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our research focuses on NBA and NFL games, which are major sports with rich datasets. We are interested in exploring the generalizability of our findings to other sports. For example, soccer and cricket have distinct play styles and rules, which might challenge LLMs in unique ways. Our study has explored multiple adversarial scenarios, such as new game rules and scrambled game narratives. Such drastic changes might be uncommon in real-world conditions, and the models’ ability to handle these scenarios might not translate to improved performance in other analytical tasks. Finally, our scoring system’s effectiveness in assessing LLMs’ numerical reasoning capabilities in different contexts, such as multiplayer online gaming or collaborative workspaces, remains to be validated. This study explores LLMs’ potential in sports analytics. It is important to recognize these limitations when applying our findings to broader contexts.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We are grateful to the reviewers for their insightful feedback, which has helped enhance the quality of our paper. This research has been partially supported by the NSF CAREER award, #2303655.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adams et al. (2021)</span>
<span class="ltx_bibblock">
Griffin Adams, Emily Alsentzer, Mert Ketenci, Jason Zucker, and Noémie Elhadad. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.382" title="">What’s in a summary? laying the groundwork for advances in hospital-course summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 4794–4811, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et al. (2019)</span>
<span class="ltx_bibblock">
Aida Amini, Saadia Gabriel, Peter Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1905.13319" title="">Mathqa: Towards interpretable math word problem solving with operation-based formalisms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, and Emily Pitler. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2312.11805" title="">Gemini: A family of highly capable multimodal models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2023)</span>
<span class="ltx_bibblock">
Anthropic. 2023.

</span>
<span class="ltx_bibblock">Introducing Claude 2.1.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/index/claude-2-1" title="">https://www.anthropic.com/index/claude-2-1</a>.

</span>
<span class="ltx_bibblock">Accessed on: Nov 21, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardhan et al. (2022)</span>
<span class="ltx_bibblock">
Jayetri Bardhan, Anthony Colas, Kirk Roberts, and Daisy Zhe Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.lrec-1.117" title="">DrugEHRQA: A question answering dataset on structured and unstructured electronic health records for medicine related queries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Thirteenth Language Resources and Evaluation Conference</em>, pages 1083–1097, Marseille, France. European Language Resources Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barzilay et al. (1999)</span>
<span class="ltx_bibblock">
Regina Barzilay, Kathleen R. McKeown, and Michael Elhadad. 1999.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1034678.1034760" title="">Information fusion in the context of multi-document summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</em>, pages 550–557, College Park, Maryland, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben Abacha et al. (2023)</span>
<span class="ltx_bibblock">
Asma Ben Abacha, Wen-wai Yim, Yadan Fan, and Thomas Lin. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eacl-main.168" title="">An empirical study of clinical note generation from doctor-patient encounters</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pages 2291–2302, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhaskar et al. (2023)</span>
<span class="ltx_bibblock">
Adithya Bhaskar, Alex Fabbri, and Greg Durrett. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.591" title="">Prompted opinion summarization with GPT-3.5</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 9282–9300, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bostrom et al. (2022)</span>
<span class="ltx_bibblock">
Kaj Bostrom, Zayne Sprague, Swarat Chaudhuri, and Greg Durrett. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-emnlp.358" title="">Natural language deduction through search over statement compositions</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 4871–4883, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boubdir et al. (2023)</span>
<span class="ltx_bibblock">
Meriem Boubdir, Edward Kim, Beyza Ermis, Sara Hooker, and Marzieh Fadaee. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.17295" title="">Elo uncovered: Robustness and best practices in language model evaluation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brynjolfsson et al. (2023)</span>
<span class="ltx_bibblock">
Erik Brynjolfsson, Danielle Li, and Lindsey Raymond. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.11771" title="">Generative ai at work</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caciularu et al. (2023)</span>
<span class="ltx_bibblock">
Avi Caciularu, Matthew Peters, Jacob Goldberger, Ido Dagan, and Arman Cohan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.110" title="">Peek across: Improving multi-document modeling via cross-document question-answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1970–1989, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2022)</span>
<span class="ltx_bibblock">
Pengshan Cai, Fei Liu, Adarsha Bajracharya, Joe Sills, Alok Kapoor, Weisong Liu, Dan Berlowitz, David Levy, Richeek Pradhan, and Hong Yu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.coling-1.544" title="">Generation of patient after-visit summaries to support physicians</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 29th International Conference on Computational Linguistics</em>, pages 6234–6247, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2023)</span>
<span class="ltx_bibblock">
Pengshan Cai, Zonghai Yao, Fei Liu, Dakuo Wang, Meghan Reilly, Huixue Zhou, Lingxi Li, Yi Cao, Alok Kapoor, Adarsha Bajracharya, Dan Berlowitz, and Hong Yu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2308.03253" title="">Paniniqa: Enhancing patient education through interactive question answering</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. (2022)</span>
<span class="ltx_bibblock">
Meng Cao, Yue Dong, and Jackie Cheung. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.236" title="">Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3340–3354, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, and William Yang Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2109.00122" title="">Finqa: A dataset of numerical reasoning over financial data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al. (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2110.14168" title="">Training verifiers to solve math word problems</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deutsch et al. (2021)</span>
<span class="ltx_bibblock">
Daniel Deutsch, Rotem Dror, and Dan Roth. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00417" title="">A statistical analysis of summarization evaluation metrics using resampling methods</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Transactions of the Association for Computational Linguistics</em>, 9:1132–1146.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edouard et al. (2017)</span>
<span class="ltx_bibblock">
Amosse Edouard, Elena Cabrio, Sara Tonelli, and Nhan Le-Thanh. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.26615/978-954-452-049-6_030" title="">You’ll never tweet alone: Building sports match timelines from microblog posts</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017</em>, pages 214–221, Varna, Bulgaria. INCOMA Ltd.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Furman et al. (2022)</span>
<span class="ltx_bibblock">
Gregory Furman, Edan Toledo, Jonathan Shock, and Jan Buys. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.wordplay-1.4" title="">A sequence modelling approach to question answering in text-based games</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 3rd Wordplay: When Language Meets Games Workshop (Wordplay 2022)</em>, pages 44–58, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et al. (2020)</span>
<span class="ltx_bibblock">
Mor Geva, Ankit Gupta, and Jonathan Berant. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.89" title="">Injecting numerical reasoning skills into language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 946–958, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giorgi et al. (2023)</span>
<span class="ltx_bibblock">
John Giorgi, Luca Soldaini, Bo Wang, Gary Bader, Kyle Lo, Lucy Wang, and Arman Cohan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.findings-emnlp.549" title="">Open domain multi-document summarization: A comprehensive study of model brittleness under retrieval</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 8177–8199, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2022)</span>
<span class="ltx_bibblock">
Yi Gu, Shunyu Yao, Chuang Gan, Josh Tenenbaum, and Mo Yu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.findings-emnlp.510" title="">Revisiting the roles of “text” in text games</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 6867–6876, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2009.03300" title="">Measuring massive multitask language understanding</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2023)</span>
<span class="ltx_bibblock">
Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh, and Fei Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.519" title="">DecipherPref: Analyzing influential factors in human preference judgments via GPT-4</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 8344–8357, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2020)</span>
<span class="ltx_bibblock">
Kuan-Hao Huang, Chen Li, and Kai-Wei Chang. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.aacl-main.61" title="">Generating sports news from live commentary: A Chinese dataset for sports game summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</em>, pages 609–615, Suzhou, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2021)</span>
<span class="ltx_bibblock">
Luyang Huang, Shuyang Cao, Nikolaus Parulian, Heng Ji, and Lu Wang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.112" title="">Efficient attentions for long document summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 1419–1436, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joseph et al. (2024)</span>
<span class="ltx_bibblock">
Sebastian Antony Joseph, Lily Chen, Jan Trienes, Hannah Louisa Göke, Monika Coers, Wei Xu, Byron C Wallace, and Junyi Jessy Li. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.11456" title="">Factpico: Factuality evaluation for plain language summarization of medical evidence</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.550" title="">Dense passage retrieval for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 6769–6781, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kicikoglu et al. (2020)</span>
<span class="ltx_bibblock">
Osman Doruk Kicikoglu, Richard Bartle, Jon Chamberlain, Silviu Paun, and Massimo Poesio. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.gamnlp-1.11" title="">Aggregation driven progression system for GWAPs</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Workshop on Games and Natural Language Processing</em>, pages 79–84, Marseille, France. European Language Resources Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna et al. (2023)</span>
<span class="ltx_bibblock">
Kalpesh Krishna, Erin Bransom, Bailey Kuehl, Mohit Iyyer, Pradeep Dasigi, Arman Cohan, and Kyle Lo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eacl-main.121" title="">LongEval: Guidelines for human evaluation of faithfulness in long-form summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pages 1650–1669, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lareau et al. (2011)</span>
<span class="ltx_bibblock">
François Lareau, Mark Dras, and Robert Dale. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W11-2828" title="">Detecting interesting event sequences for sports reporting</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 13th European Workshop on Natural Language Generation</em>, pages 200–205, Nancy, France. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lebanoff et al. (2021)</span>
<span class="ltx_bibblock">
Logan Lebanoff, Bingqing Wang, Zhe Feng, and Fei Liu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.newsum-1.13" title="">Modeling endorsement for multi-document abstractive summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the Third Workshop on New Frontiers in Summarization</em>, pages 119–130, Online and in Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Sha Li, Chi Han, Pengfei Yu, Carl Edwards, Manling Li, Xingyao Wang, Yi Fung, Charles Yu, Joel Tetreault, Eduard Hovy, and Heng Ji. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.findings-emnlp.799" title="">Defining a new NLP playground</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 11932–11951, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.11477" title="">Llm+p: Empowering large language models with optimal planning proficiency</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Linqing Liu, Patrick Lewis, Sebastian Riedel, and Pontus Stenetorp. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-naacl.155" title="">Challenges in generalization in open domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Findings of the Association for Computational Linguistics: NAACL 2022</em>, pages 2014–2029, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.03172" title="">Lost in the middle: How language models use long contexts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023c)</span>
<span class="ltx_bibblock">
Yixin Liu, Alexander R. Fabbri, Jiawen Chen, Yilun Zhao, Simeng Han, Shafiq Joty, Pengfei Liu, Dragomir Radev, Chien-Sheng Wu, and Arman Cohan. 2023c.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.09184" title="">Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023d)</span>
<span class="ltx_bibblock">
Yixin Liu, Avi Singh, C. Daniel Freeman, John D. Co-Reyes, and Peter J. Liu. 2023d.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.10047" title="">Improving large language model fine-tuning for solving math problems</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loten (2023)</span>
<span class="ltx_bibblock">
Angus Loten. 2023.

</span>
<span class="ltx_bibblock">Wendy’s, Google train next-generation order taker: an AI Chatbot.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.wsj.com/articles/wendys-google" title="">https://www.wsj.com/articles/wendys-google</a> <a class="ltx_ref ltx_url ltx_font_typewriter" href="-train-next-generation-order-taker-an-ai-" title="">-train-next-generation-order-taker-an-ai-</a> <a class="ltx_ref ltx_url ltx_font_typewriter" href="chatbot-968ff865" title="">chatbot-968ff865</a>.

</span>
<span class="ltx_bibblock">Accessed on: May 9, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2023)</span>
<span class="ltx_bibblock">
Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, and Ashwin Kalyan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2209.14610" title="">Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lukin (2020)</span>
<span class="ltx_bibblock">
Stephanie M. Lukin, editor. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.gamnlp-1.0" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1.1">Workshop on Games and Natural Language Processing</em></a>. European Language Resources Association, Marseille, France.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al. (2023)</span>
<span class="ltx_bibblock">
Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2210.07229" title="">Mass-editing memory in a transformer</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merullo et al. (2019)</span>
<span class="ltx_bibblock">
Jack Merullo, Luke Yeh, Abram Handler, Alvin Grissom II, Brendan O’Connor, and Mohit Iyyer. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-1666" title="">Investigating sports commentator bias within a large corpus of American football broadcasts</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pages 6355–6361, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MistralAI (2023)</span>
<span class="ltx_bibblock">
MistralAI. 2023.

</span>
<span class="ltx_bibblock">Mixtral of experts.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://mistral.ai/news/mixtral-of-experts/" title="">https://mistral.ai/news/mixtral-of-experts/</a>.

</span>
<span class="ltx_bibblock">Accessed on: December 11, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">New models and developer products announced at DevDay.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/new-models-and-developer-products-announced" title="">https://openai.com/blog/new-models-and-developer-products-announced</a> <a class="ltx_ref ltx_url ltx_font_typewriter" href="-at-devday" title="">-at-devday</a>.

</span>
<span class="ltx_bibblock">Accessed on: November 6, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patel et al. (2021)</span>
<span class="ltx_bibblock">
Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2103.07191" title="">Are nlp models really able to solve simple math word problems?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puduppully et al. (2019)</span>
<span class="ltx_bibblock">
Ratish Puduppully, Li Dong, and Mirella Lapata. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1195" title="">Data-to-text generation with entity modeling</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 2023–2035, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddy et al. (2024)</span>
<span class="ltx_bibblock">
Varshini Reddy, Rik Koncel-Kedziorski, Viet Dac Lai, Michael Krumdick, Charles Lovering, and Chris Tanner. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.06915" title="">Docfinqa: A long-context financial reasoning dataset</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn et al. (2023)</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.11366" title="">Reflexion: Language agents with verbal reinforcement learning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sprague et al. (2022)</span>
<span class="ltx_bibblock">
Zayne Sprague, Kaj Bostrom, Swarat Chaudhuri, and Greg Durrett. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.564" title="">Natural language deduction with incomplete information</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 8230–8258, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sumers et al. (2023)</span>
<span class="ltx_bibblock">
Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.02427" title="">Cognitive architectures for language agents</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">van der Lee et al. (2017)</span>
<span class="ltx_bibblock">
Chris van der Lee, Emiel Krahmer, and Sander Wubben. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W17-3513" title="">PASS: A Dutch data-to-text system for soccer, targeted towards specific audiences</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Proceedings of the 10th International Conference on Natural Language Generation</em>, pages 95–104, Santiago de Compostela, Spain. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veen et al. (2023)</span>
<span class="ltx_bibblock">
Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis, Anna Seehofnerova, Nidhi Rohatgi, Poonam Hosamani, William Collins, Neera Ahuja, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, John Pauly, and Akshay S. Chaudhari. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.07430" title="">Clinical text summarization: Adapting large language models can outperform human experts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Alex Wang, Richard Yuanzhe Pang, Angelica Chen, Jason Phang, and Samuel R. Bowman. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.75" title="">SQuALITY: Building a long-document summarization dataset the hard way</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 1139–1156, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiseman et al. (2017)</span>
<span class="ltx_bibblock">
Sam Wiseman, Stuart Shieber, and Alexander Rush. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D17-1239" title="">Challenges in data-to-document generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, pages 2253–2263, Copenhagen, Denmark. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2023)</span>
<span class="ltx_bibblock">
Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and Yu Su. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.13300" title="">Adaptive chameleon or stubborn sloth: Revealing the behavior of large language models in knowledge conflicts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024)</span>
<span class="ltx_bibblock">
Liyan Xu, Zhenlin Su, Mo Yu, Jin Xu, Jinho D. Choi, Jie Zhou, and Fei Liu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.12821" title="">Identifying factual inconsistency in summaries: Towards effective utilization of large language model</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
Ruochen Xu, Song Wang, Yang Liu, Shuohang Wang, Yichong Xu, Dan Iter, Pengcheng He, Chenguang Zhu, and Michael Zeng. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.findings-emnlp.984" title="">LMGQS: A large-scale dataset for query-focused summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 14764–14776, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2023a)</span>
<span class="ltx_bibblock">
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.10601" title="">Tree of thoughts: Deliberate problem solving with large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2023b)</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2210.03629" title="">React: Synergizing reasoning and acting in language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2016)</span>
<span class="ltx_bibblock">
Jianmin Zhang, Jin-ge Yao, and Xiaojun Wan. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P16-1129" title="">Towards constructing sports news from live text commentary</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1361–1371, Berlin, Germany. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Yilun Zhao, Yitao Long, Hongjun Liu, Linyong Nan, Lyuhao Chen, Ryo Kamoi, Yixin Liu, Xiangru Tang, Rui Zhang, and Arman Cohan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.09805" title="">Docmath-eval: Evaluating numerical reasoning capabilities of llms in understanding long documents with tabular data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.05685" title="">Judging llm-as-a-judge with mt-bench and chatbot arena</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2105.07624" title="">Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance</a>.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Jun 16 06:41:28 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
