<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications</title>
<!--Generated on Tue Jul  2 05:00:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.01953v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S1" title="In CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S2" title="In CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Shared Task Description</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S3" title="In CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proposed Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4" title="In CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.SS1" title="In 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experiment Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.SS2" title="In 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experiment Results on Validation Set</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.SS2.SSS1" title="In 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Task 1</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.SS2.SSS2" title="In 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Task 2</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.SS2.SSS3" title="In 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Task 3</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.SS3" title="In 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Experiment Results on Test Set</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S5" title="In CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yupeng Cao*, 
Zhiyuan Yao*, 
Zhi Chen*, 
Zhiyang Deng*
<br class="ltx_break"/>*Equal Contribution
<br class="ltx_break"/>Stevens Institute of Technology, Hoboken, NJ
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{ycao33,zyao9,zchen100,zdeng10}@stevens.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">The integration of Large Language Models (LLMs) into financial analysis has garnered significant attention in the NLP community. This paper presents our solution to IJCAI-2024 FinLLM challenge, investigating the capabilities of LLMs within three critical areas of financial tasks: financial classification, financial text summarization, and single stock trading. We adopted Llama3-8B and Mistral-7B as base models, fine-tuning them through Parameter Efficient Fine-Tuning (PEFT) and Low-Rank Adaptation (LoRA) approaches. To enhance model performance, we combine datasets from task 1 and task 2 for data fusion. Our approach aims to tackle these diverse tasks in a comprehensive and integrated manner, showcasing LLMs’ capacity to address diverse and complex financial tasks with improved accuracy and decision-making capabilities.</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_ERROR undefined" id="p1.2.2">\ul</span></p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<div class="ltx_block ltx_align_bottom" id="p2.1">
<p class="ltx_p" id="p2.1.1"><span class="ltx_text ltx_font_bold" id="p2.1.1.1">CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p2.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p2.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p2.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p2.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p2.1.2.1.1.1.1.1.1">Yupeng Cao*, 
Zhiyuan Yao*, 
Zhi Chen*, 
Zhiyang Deng*</span></span></span>
<span class="ltx_tr" id="p2.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.2.2.1">*Equal Contribution</span></span>
<span class="ltx_tr" id="p2.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.3.3.1">Stevens Institute of Technology, Hoboken, NJ</span></span>
<span class="ltx_tr" id="p2.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.4.4.1"><span class="ltx_text ltx_font_typewriter" id="p2.1.2.1.1.4.4.1.1">{ycao33,zyao9,zchen100,zdeng10}@stevens.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In recent years, FinTech research has increasingly focused on using textual information to aid investment decisions by analyzing various financial textual data <cite class="ltx_cite ltx_citemacro_cite">Allen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib3" title="">2021</a>)</cite>. However, the complexity of financial documents makes it difficult to classify and summarize market information. Additionally, the intricate and volatile nature of financial markets poses significant challenges for making informed, sequential investment decisions. To address these challenges, advanced natural language processing techniques and models are necessary to process and interpret vast amounts of financial data accurately <cite class="ltx_cite ltx_citemacro_cite">Fisher et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib5" title="">2016</a>)</cite>. Lately, Large Language Models (LLMs) have demonstrated impressive capabilities in the field of finance <cite class="ltx_cite ltx_citemacro_cite">Bubeck et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib4" title="">2023</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib10" title="">2023</a>)</cite>. These models excel in understanding and generating human-like text, making them ideal candidates for tackling complex financial tasks.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Although LLMs demonstrate significant promise in the financial sector, their efficacy in specific financial tasks requires deeper investigation. The FinLLM challenge @ IJCAI-2024 initiative, as introduced in <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib15" title="">2024</a>)</cite>, seeks to investigate the potential of LLMs in analyzing financial documents and enhancing decision-making processes. By leveraging the power of LLMs, the initiative aims to improve the accuracy and efficiency of financial information processing, ultimately aiding in improved investment strategies and a better market understanding.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This paper describes our technical solution for three diverse tasks provided by the FinLLM challenge: financial classification <cite class="ltx_cite ltx_citemacro_cite">Sy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib13" title="">2023</a>)</cite>, text summarization <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib17" title="">2021</a>)</cite>, and single stock trading <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib16" title="">2024</a>)</cite>. The classification task involves distinguishing between claims and premises in financial texts, the summarization task aims to distill extensive financial narratives into succinct summaries, and the trading task focuses on formulating predictive trading decisions based on algorithmic insights.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The core idea of our solution is to fine-tune pre-trained LLMs using PEFT <cite class="ltx_cite ltx_citemacro_cite">Mangrulkar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib11" title="">2022</a>)</cite> and LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib6" title="">2021</a>)</cite> techniques, leveraging data fusion strategy on the provided datasets from task 1 &amp; 2 in the FinLLM challenge. Specifically, we select Llama3-8B <cite class="ltx_cite ltx_citemacro_cite">AI@Meta (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib2" title="">2024</a>)</cite> and Mistral-7B <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib9" title="">2023</a>)</cite> as the pre-trained base models due to their large number of parameters, which enable them to capture complex patterns and nuances in financial text data—essential for the three tasks in the challenge. Additionally, these models are pre-trained on vast and diverse datasets, providing a broad understanding of language that can be fine-tuned for financial domains, enhancing their versatility and adaptability to specific financial tasks. Furthermore, both models support PEFT and LoRA techniques, allowing efficient and effective specialization for the financial domain, even with limited labeled data.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our extensive experiments conducted on the three shared tasks have yielded significant findings: 1) Mistral-7B outperforms Llama3-8B in terms of both overall performance and its ability to generate well-structured outputs; 2) the fine-tuned model by using the fused data, showed enhanced results on Task 1 and Task 2; 3) however, this fine-tuned model did not demonstrate improvement in the more complex single-stock trading task (Task 3). For this, we do a more detailed analysis of the results in Section 4.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Shared Task Description</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The FinLLM challenge consists of three shared tasks: financial classification (task 1), text summarization (task 2), and single stock trading (task 3). Datasets description can be found in: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/TheFinAI/flare-finarg-ecc-auc_test" title="">https://huggingface.co/datasets/TheFinAI/flare-finarg-ecc-auc_test</a> and <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/TheFinAI/flare-edtsum_test" title="">https://huggingface.co/datasets/TheFinAI/flare-edtsum_test</a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Task 1</span> in the FinLLM challenge focuses on the <span class="ltx_text ltx_font_bold" id="S2.p2.1.2">financial classification</span>, specifically categorizing sentences within financial documents as either claims or premises. A claim is a statement that asserts a point of view or opinion, while a premise provides the supporting information or evidence for that claim. This task is fundamental for understanding and analyzing financial narratives, as it helps in structuring the information into coherent arguments, which is essential for various downstream applications such as sentiment analysis, risk assessment, and investment decision-making. The evaluation metric for Task 1 is the <span class="ltx_text ltx_font_bold" id="S2.p2.1.3">F1 score</span>, which provides a balanced measure of the model’s precision and recall.
<br class="ltx_break"/> 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p2.1.4">Task 2</span> in the FinLLM challenge focuses on <span class="ltx_text ltx_font_bold" id="S2.p2.1.5">financial texts summarization</span>. The objective is to condense lengthy financial documents into concise summaries that capture the essential information and key insights while omitting redundant or less important details. This task is crucial for enabling quick and effective information processing, allowing stakeholders to make informed decisions without wading through extensive reports. Task 2 utilizes three metrics, namely ROUGE (1, 2, and L) and BERTScore, to evaluate generated summaries in terms of relevance, with the <span class="ltx_text ltx_font_bold" id="S2.p2.1.6">ROUGE-1 score</span> serving as the final ranking metric.
<br class="ltx_break"/> 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p2.1.7">Task 3</span> in the FinLLM challenge focuses on the application of LLMs to <span class="ltx_text ltx_font_bold" id="S2.p2.1.8">single stock trading</span>, aiming to make informed and predictive trading decisions. The primary goal of this task is to develop a model that can analyze various financial texts and other relevant data to predict the future price movements of a single stock and make trading decisions based on these predictions. The evaluation metric includes Sharpe Ratio (SR), Cumulative Return (CR), Daily (DV) and Annualized Volatility (AV), and Maximum Drawdown (MD), with the <span class="ltx_text ltx_font_bold" id="S2.p2.1.9">Sharpe Ratio (SR)</span> used as the final ranking metric.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The success of large language models like GPT-4 <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib1" title="">2023</a>)</cite> and Llama3 demonstrates the benefits of integrating diverse data sources during pre-training, enhancing their capabilities and generalizability across various real-world applications. This approach not only broadens the model’s understanding of different data forms but also significantly boosts performance on specialized tasks through fine-tuning <cite class="ltx_cite ltx_citemacro_cite">Nguyen-Mau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib12" title="">2024</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib7" title="">2024</a>)</cite>. Inspired by these advancements, our work employs a cross-task data fusion strategy for LLM fine-tuning, aiming to enhance the model’s effectiveness by combining insights from different financial tasks. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S3.F1" title="Figure 1 ‣ 3 Proposed Method ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the proposed fine-tuning method.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="204" id="S3.F1.g1" src="extracted/5704387/img/diagram.png" width="568"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Schematic of proposed fine-tuning method.</figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We curated and preprocessed a robust training set from two tasks: financial text classification and financial text summarization, to cover a wide range of real-world financial scenarios. We excluded the dataset for task 3, which focuses on texts related to three specific stocks, due to its narrow company-specific content. This selective integration forms the basis for fine-tuning a pre-trained LLM, equipping it to effectively understand and generate nuanced financial texts. After fine-tuning, we applied the enhanced model to each of the three tasks to evaluate its practical utility and performance across various financial applications.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment and Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we present technical details of our implementation and numerical results of our fine-tuned models on tasks 1, 2, and 3. We also compare the performance of these models on different tasks and present our observations on discrepancies between the two base models.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Setup</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Mistral-7B and Llama3-8B are employed as the base LLM in this study. Due to the limit of computational resources, we perform fine-tuning using Low-Rank Adaptation (LoRA, <cite class="ltx_cite ltx_citemacro_citet">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib6" title="">2021</a>)</cite>) with LoRA-<math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_α</annotation></semantics></math> 16 and 4-bit quantization <cite class="ltx_cite ltx_citemacro_cite">Jacob et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib8" title="">2018</a>)</cite> to reduce the usage of GPU memory and to accelerate training. The models were trained and inferenced on two NVIDIA RTX-A6000 GPUs (each has 48GB DRAM) with one epoch. Our implementation employs PEFT, Quantization libraries and other pipelines provided in Huggingface<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://huggingface.co/</span></span></span>.
We divided the training set portion of the validation set in the ratio of 80:20 for performance evaluation. The models are further tested and compared using the provided testing data sets.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experiment Results on Validation Set</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In preliminary experiments, we observed a significant difference in performance between the fine-tuned Mistral-7B and Llama3-8B models. Mistral-7B demonstrated superior predictive capabilities and produced well-formatted outputs that could be easily parsed to yield final predictions. In contrast, Llama3-8B required additional processing of its outputs through specific prompting, which could potentially alter the original outputs. Consequently, we decided to conduct all subsequent experiments using Mistral-7B.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Task 1</h4>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">Dataset</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">ACC</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">F1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.1.1">No Fine-tune</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.2.2.2">0.4997</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.2.2.3">0.1581</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.3.3.1.1">Task 1</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.3.3.2">0.3490</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.3.3.3">0.3913</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.4.4.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.4.4.1.1">Task 1 + Task 2</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.4.4.2">
<span class="ltx_ERROR undefined" id="S4.T1.1.4.4.2.1">\ul</span>0.6259</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.4.4.3">
<span class="ltx_ERROR undefined" id="S4.T1.1.4.4.3.1">\ul</span>0.5634</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The performance for two models tasked with classifying sentences as either "premise" or "claim". It includes two key metrics: Accuracy (ACC) and F1 Score (F1). Model "Task 1" was fine-tuned using only the dataset from Task 1, while Model Task 1 + Task 2 used datasets from both Task 1 and Task 2 for fine-tuning.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.T1" title="Table 1 ‣ 4.2.1 Task 1 ‣ 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates that the fine-tuned LLMs have significantly improved reasoning for downstream-specific tasks. Furthermore, the LLMs, fine-tuned using the fused dataset, exhibit significant performance enhancements, where it achieves a 0.5634 F1 score. This evidence supports the notion that integrating different tasks can substantially enhance the reasoning capabilities of LLMs.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Task 2</h4>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">Rouge-1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">Rouge-2</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1">BertScore</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.1.1">Task 1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.2.2">0.4847</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.2.3">0.2921</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.2.2.4">0.6904</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.3.1.1">Task 1 + Task 2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.3.3.2">
<span class="ltx_ERROR undefined" id="S4.T2.1.3.3.2.1">\ul</span>0.4920</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.3.3.3">
<span class="ltx_ERROR undefined" id="S4.T2.1.3.3.3.1">\ul</span>0.3015</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.3.3.4">
<span class="ltx_ERROR undefined" id="S4.T2.1.3.3.4.1">\ul</span>0.6946</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The performance results for two models tasked with summarizing. It includes metrics for evaluating summarization: Rouge and Bert Score. Model "Task 1" was fine-tuned using only the dataset from Task 1, while Model Task 1 + Task 2 used datasets from both Task 1 and Task 2 for fine-tuning. </figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.T2" title="Table 2 ‣ 4.2.2 Task 2 ‣ 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_tag">2</span></a> also demonstrates that the fine-tuned LLMs,by using the fused dataset, achieved significant performance gains in the text summarization task. This reinforces the idea that integrating various tasks can notably enhance the generalization capabilities of LLMs across different applications.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Task 3</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">We compare the three fine-tuned models based on Mistral-7B in Task 3. We exclude the models fine-tuned from Llama3-8B in this comparison because Llama3-based models cannot consistently produce trading decisions in the correct format. We fine-tuned three models:</p>
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Model 1 is fined-tuned only using the training data from Task 1,</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Model 2 is fined-tuned only using the training data from Task 2,</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Model 3 is fined-tuned using the training data from Task 1 and Task 2.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S4.SS2.SSS3.p1.2">The three models are implemented in the FinMem framework as described in <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib16" title="">2024</a>)</cite> to generate trading decisions.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S4.F2.sf1.g1" src="extracted/5704387/img/jnj.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>JNJ</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S4.F2.sf2.g1" src="extracted/5704387/img/form.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>FORM</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S4.F2.sf3.g1" src="extracted/5704387/img/msft.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>MSFT</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S4.F2.sf4.g1" src="extracted/5704387/img/driv.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>DRIV</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparison of Cumulative Returns in 4 Stocks</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<p class="ltx_p ltx_align_center" id="S4.T3.5"><span class="ltx_text ltx_inline-block" id="S4.T3.5.5" style="width:433.6pt;">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T3.5.5.5.5" style="width:608.6pt;height:127pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T3.5.5.5.5.5"><span class="ltx_text" id="S4.T3.5.5.5.5.5.5">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.5.5.5.5.5.5.5">
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T3.5.5.5.5.5.5.5.6.1">
<span class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2" id="S4.T3.5.5.5.5.5.5.5.6.1.1"></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S4.T3.5.5.5.5.5.5.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.6.1.2.1">FORM</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S4.T3.5.5.5.5.5.5.5.6.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.6.1.3.1">JNJ</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S4.T3.5.5.5.5.5.5.5.6.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.6.1.4.1">MSFT</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t ltx_colspan ltx_colspan_3" id="S4.T3.5.5.5.5.5.5.5.6.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.6.1.5.1">DRIV</span></span></span>
<span class="ltx_tr" id="S4.T3.5.5.5.5.5.5.5.7.2">
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.1.1">Model 1</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.2.1">Model 2</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.3.1">Model 3</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.4.1">Model 1</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.5.1">Model 2</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.6"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.6.1">Model 3</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.7"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.7.1">Model 1</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.8"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.8.1">Model 2</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.9"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.9.1">Model 3</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.10"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.10.1">Model 1</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.11"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.11.1">Model 2</span></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.7.2.12"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.7.2.12.1">Model 3</span></span></span>
<span class="ltx_tr" id="S4.T3.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1.1.1.1.1.1">CR</span> <svg class="ltx_picture" height="15.28" id="S4.T3.1.1.1.1.1.1.1.1.1.pic1" overflow="visible" version="1.1" width="2.71"><g fill="#000000" stroke="#000000" transform="translate(0,15.28) matrix(1 0 0 -1 0 0) translate(2.16,0) translate(0,7.64)"><g stroke-width="0.8pt"><path d="M 0 -7.09 L 0 6.1" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 1.0 -1.0 0.0 0 6.1)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g></g></svg></span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.2">0.038</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.3">-0.054</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.4">0.012</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.5">0.045</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.6">0.035</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.7">-0.021</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.8">0.092</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.9">0.032</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.10">0.024</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.11">-0.086</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.12">-0.039</span>
<span class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.1.1.1.1.1.1.13">-0.130</span></span>
<span class="ltx_tr" id="S4.T3.2.2.2.2.2.2.2.2">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.2.2.2.2.2.1.1">SR</span>  <svg class="ltx_picture" height="15.28" id="S4.T3.2.2.2.2.2.2.2.2.1.pic1" overflow="visible" version="1.1" width="1.11"><g fill="#000000" stroke="#000000" transform="translate(0,15.28) matrix(1 0 0 -1 0 0) translate(0.55,0) translate(0,7.64)"><g stroke-width="0.8pt"><path d="M 0 -7.09 L 0 6.1" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 1.0 -1.0 0.0 0 6.1)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g></g></svg></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.2">0.440</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.3">-0.574</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.4">0.176</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.5">0.927</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.6">0.898</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.7">-0.506</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.8">1.594</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.9">0.564</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.10">0.418</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.11">-2.139</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.12">-0.834</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.2.2.2.2.2.2.13">-2.291</span></span>
<span class="ltx_tr" id="S4.T3.3.3.3.3.3.3.3.3">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.1"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.3.3.3.3.3.1.1">SD</span>  <svg class="ltx_picture" height="15.28" id="S4.T3.3.3.3.3.3.3.3.3.1.pic1" overflow="visible" version="1.1" width="1.11"><g fill="#000000" stroke="#000000" transform="translate(0,15.28) matrix(1 0 0 -1 0 0) translate(0.55,0) translate(0,7.64)"><g stroke-width="0.8pt"><path d="M 0 7.09 L 0 -6.1" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -6.1)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g></g></svg></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.2">0.014</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.3">0.015</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.4">0.010</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.5">0.006</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.6">0.006</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.7">0.009</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.8">0.009</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.9">0.009</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.10">0.009</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.11">0.006</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.12">0.007</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.3.3.3.3.3.3.3.3.13">0.009</span></span>
<span class="ltx_tr" id="S4.T3.4.4.4.4.4.4.4.4">
<span class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.1"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.4.4.4.4.4.1.1">AV</span>  <svg class="ltx_picture" height="15.28" id="S4.T3.4.4.4.4.4.4.4.4.1.pic1" overflow="visible" version="1.1" width="1.11"><g fill="#000000" stroke="#000000" transform="translate(0,15.28) matrix(1 0 0 -1 0 0) translate(0.55,0) translate(0,7.64)"><g stroke-width="0.8pt"><path d="M 0 7.09 L 0 -6.1" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -6.1)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g></g></svg></span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.2">0.217</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.3">0.237</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.4">0.165</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.5">0.101</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.6">0.097</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.7">0.102</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.8">0.144</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.9">0.143</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.10">0.144</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.11">0.101</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.12">0.116</span>
<span class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.4.4.4.4.4.4.4.13">0.142</span></span>
<span class="ltx_tr" id="S4.T3.5.5.5.5.5.5.5.5">
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.1"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.5.5.5.5.5.1.1">MD</span>  <svg class="ltx_picture" height="15.28" id="S4.T3.5.5.5.5.5.5.5.5.1.pic1" overflow="visible" version="1.1" width="1.11"><g fill="#000000" stroke="#000000" transform="translate(0,15.28) matrix(1 0 0 -1 0 0) translate(0.55,0) translate(0,7.64)"><g stroke-width="0.8pt"><path d="M 0 7.09 L 0 -6.1" style="fill:none"></path></g><g stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.64pt" transform="matrix(0.0 -1.0 1.0 0.0 0 -6.1)"><path d="M -2.16 2.88 C -1.98 1.8 0 0.18 0.54 0 C 0 -0.18 -1.98 -1.8 -2.16 -2.88" style="fill:none"></path></g></g></svg></span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.2">0.084</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.3">0.175</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.4">0.046</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.5">0.084</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.6">0.059</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.7">0.144</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.8">0.056</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.9">0.074</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.10">0.104</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.11">0.084</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.12">0.059</span>
<span class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.5.5.5.5.5.5.5.5.13">0.144</span></span>
</span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance Metrics Comparison Across Different Models and Datasets.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS3.p2">
<p class="ltx_p" id="S4.SS2.SSS3.p2.1">We are interested in the performance discrepancies of these models trained on different datasets. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.F2" title="Figure 2 ‣ 4.2.3 Task 3 ‣ 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_tag">2</span></a> shows the return changes of the three models across four stocks during the testing period. Table <a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#S4.T3" title="Table 3 ‣ 4.2.3 Task 3 ‣ 4.2 Experiment Results on Validation Set ‣ 4 Experiment and Discussion ‣ CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications"><span class="ltx_text ltx_ref_tag">3</span></a> details the performance metrics of the models on different stocks. The models generate distinct strategies for all four assets, indicating sensitivity to the fine-tuning datasets. However, none of the models consistently produce profitable strategies. The Mistral-7B model is relatively small compared to state-of-the-art LLMs like OpenAI GPT-4 <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib1" title="">2023</a>)</cite> and Google Gemini <cite class="ltx_cite ltx_citemacro_cite">Team et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib14" title="">2023</a>)</cite>, limiting its ability to solve complex tasks such as trading decisions. This aligns with the reported performance of other LLMs in <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.01953v1#bib.bib15" title="">2024</a>)</cite>. Additionally, Model 3, trained on both datasets, does not outperform the models trained on each dataset individually. This could be due to the introduction of noise or conflicting information from combining datasets. Given that tasks 1 and 2 are not directly related to trading, it is reasonable that all three models perform poorly in this task.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Experiment Results on Test Set</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Based on the above analysis, we selected the Mistral-7B model, fine-tuned through data fusion, for the final challenge testing. In Task 1, the model achieved an ACC of 0.711, an F1 score of 0.4199, and a Matthews correlation coefficient (MCC) of 0.6818. In Task 3, the integrated Sharp Ratio (SR) was -0.6199. These results are consistent with those observed in our validation set.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we fine-tuned LLMs using datasets that span multiple tasks, resulting in performance improvements in classification and summarization tasks. However, our approach did not yield positive results for the stock trading task. This outcome suggests that more complex financial tasks may require advanced data fusion steps. Furthermore, it underscores the need to explore the impact of incorporating larger datasets on the model’s performance after fine-tuning.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitation</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Our work relies on the pre-trained large language model at 7B/8B level with 4-bit quantization, we have not considered other parameter-level pre-trained models like Llama3-70B which will be explored in the future.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta (2024)</span>
<span class="ltx_bibblock">
AI@Meta. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" title="">Llama 3 model card</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allen et al. (2021)</span>
<span class="ltx_bibblock">
Franklin Allen, Xian Gu, and Julapa Jagtiani. 2021.

</span>
<span class="ltx_bibblock">A survey of fintech research and policy discussion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Review of Corporate Finance</em>, 1:259–339.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bubeck et al. (2023)</span>
<span class="ltx_bibblock">
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023.

</span>
<span class="ltx_bibblock">Sparks of artificial general intelligence: Early experiments with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2303.12712</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fisher et al. (2016)</span>
<span class="ltx_bibblock">
Ingrid E Fisher, Margaret R Garnsey, and Mark E Hughes. 2016.

</span>
<span class="ltx_bibblock">Natural language processing in accounting, auditing and finance: A synthesis of the literature with a roadmap for future research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Intelligent Systems in Accounting, Finance and Management</em>, 23(3):157–214.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2106.09685</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024)</span>
<span class="ltx_bibblock">
Hui Huang, Bing Xu, Xinnian Liang, Kehai Chen, Muyun Yang, Tiejun Zhao, and Conghui Zhu. 2024.

</span>
<span class="ltx_bibblock">Multi-view fusion for instruction mining of large language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Information Fusion</em>, page 102480.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jacob et al. (2018)</span>
<span class="ltx_bibblock">
Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko. 2018.

</span>
<span class="ltx_bibblock">Quantization and training of neural networks for efficient integer-arithmetic-only inference.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 2704–2713.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2310.06825</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Yinheng Li, Shaofei Wang, Han Ding, and Hang Chen. 2023.

</span>
<span class="ltx_bibblock">Large language models in finance: A survey.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the Fourth ACM International Conference on AI in Finance</em>, pages 374–382.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mangrulkar et al. (2022)</span>
<span class="ltx_bibblock">
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan. 2022.

</span>
<span class="ltx_bibblock">Peft: State-of-the-art parameter-efficient fine-tuning methods.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/peft" title="">https://github.com/huggingface/peft</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen-Mau et al. (2024)</span>
<span class="ltx_bibblock">
Toan Nguyen-Mau, Anh-Cuong Le, Duc-Hong Pham, and Van-Nam Huynh. 2024.

</span>
<span class="ltx_bibblock">An information fusion based approach to context-based fine-tuning of gpt models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Information Fusion</em>, 104:102202.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sy et al. (2023)</span>
<span class="ltx_bibblock">
Eugene Sy, Tzu-Cheng Peng, Shih-Hsuan Huang, Heng-Yu Lin, and Yung-Chun Chang. 2023.

</span>
<span class="ltx_bibblock">Fine-grained argument understanding with bert ensemble techniques: A deep dive into financial sentiment analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 35th Conference on Computational Linguistics and Speech Processing (ROCLING 2023)</em>, pages 242–249.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2023)</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2024)</span>
<span class="ltx_bibblock">
Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang, Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, et al. 2024.

</span>
<span class="ltx_bibblock">The finben: An holistic financial benchmark for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2402.12659</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong Liu, Jordan W Suchow, and Khaldoun Khashanah. 2024.

</span>
<span class="ltx_bibblock">Finmem: A performance-enhanced llm trading agent with layered memory and character design.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the AAAI Symposium Series</em>, volume 3, pages 595–597.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2021)</span>
<span class="ltx_bibblock">
Zhihan Zhou, Liqian Ma, and Han Liu. 2021.

</span>
<span class="ltx_bibblock">Trade the event: Corporate events detection for news-based event-driven trading.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2105.12825</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul  2 05:00:52 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
