<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home</title>
<!--Generated on Wed Dec 27 19:25:59 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="smart home,  internet of things,  data fusion,  sensor network,  system" lang="en" name="keywords"/>
<base href="/html/2312.16697v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1. Introduction ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S2" title="2. Related Work ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS1" title="2.1. The Construction of Multi-channel Sensor Networks ‣ 2. Related Work ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>The Construction of Multi-channel Sensor Networks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS2" title="2.2. Multi-channel Data Fusion ‣ 2. Related Work ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Multi-channel Data Fusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS3" title="2.3. Technology Mediation ‣ 2. Related Work ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Technology Mediation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S3" title="3. Multi-channel Sensor Network Construction for Smart Home ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Multi-channel Sensor Network Construction for Smart Home</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS1" title="3.1. Hardware, Data Collection and Synchronization System ‣ 3. Multi-channel Sensor Network Construction for Smart Home ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Hardware, Data Collection and Synchronization System</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S4" title="4. Multi-channel Sensor Networks: Smart Home Data Fusion Model ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Multi-channel Sensor Networks: Smart Home Data Fusion Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S5" title="5. Further Discussion ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Further Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S6" title="6. Future Work ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S7" title="7. Conclusion ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="#A1" title="Appendix A APPENDICESx ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>APPENDICESx</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div aria-label="”Conversion" been="" class="package-alerts ltx_document" errors="" found”="" have="" role="“status”">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: doclicense</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2312.16697v1 [cs.HC] 27 Dec 2023</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">He Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-8169-1653" title="ORCID identifier">0000-0002-8169-1653</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:hpz5211@psu.edu">hpz5211@psu.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">The Future Laboratory, Tsinghua University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id2.2.id2">No. 160 Chengfu Road</span><span class="ltx_text ltx_affiliation_city" id="id3.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">P.R.C.</span><span class="ltx_text ltx_affiliation_postcode" id="id5.5.id5">100084</span>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.6.id1">Pennsylvania State University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id7.7.id2">Westgate Building</span><span class="ltx_text ltx_affiliation_city" id="id8.8.id3">University Park</span><span class="ltx_text ltx_affiliation_state" id="id9.9.id4">Pennsylvania</span><span class="ltx_text ltx_affiliation_country" id="id10.10.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id11.11.id6">16801</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Robin Ananda
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-7126-1302" title="ORCID identifier">0000-0001-7126-1302</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ylb18@mails.tsinghua.edu.cn">ylb18@mails.tsinghua.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id12.1.id1">Academy of Arts &amp; Design, Tsinghua University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id13.2.id2">Tsinghua University</span><span class="ltx_text ltx_affiliation_city" id="id14.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id15.4.id4">P.R.C.</span><span class="ltx_text ltx_affiliation_postcode" id="id16.5.id5">100084</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xinyi Fu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-6927-0111" title="ORCID identifier">0000-0001-6927-0111</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:fuxy@mail.tsinghua.edu.cn">fuxy@mail.tsinghua.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id17.1.id1">The Future Laboratory, Tsinghua University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id18.2.id2">No. 160 Chengfu Road</span><span class="ltx_text ltx_affiliation_city" id="id19.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id20.4.id4">P.R.C.</span><span class="ltx_text ltx_affiliation_postcode" id="id21.5.id5">100084</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhe Sun
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-4821-2366" title="ORCID identifier">0000-0002-4821-2366</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:sunz15@tsinghua.org.cn">sunz15@tsinghua.org.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id22.1.id1">Academy of Arts &amp; Design, Tsinghua University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id23.2.id2">Tsinghua University</span><span class="ltx_text ltx_affiliation_city" id="id24.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id25.4.id4">P.R.C.</span><span class="ltx_text ltx_affiliation_postcode" id="id26.5.id5">100084</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaoyu Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0007-6812-7031" title="ORCID identifier">0009-0007-6812-7031</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:1800017830@pku.edu.cn">1800017830@pku.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id27.1.id1">Yuanpei College, Peking University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id28.2.id2">NO.5 Yiheyuan Road</span><span class="ltx_text ltx_affiliation_city" id="id29.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id30.4.id4">P.R.C</span><span class="ltx_text ltx_affiliation_postcode" id="id31.5.id5">100871</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Keqi Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-9383-9910" title="ORCID identifier">0000-0001-9383-9910</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:keqi001@e.ntu.edu.sg">keqi001@e.ntu.edu.sg</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id32.1.id1">Nanyang Technological University</span><span class="ltx_text ltx_affiliation_country" id="id33.2.id2">Singapore</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">John M. Carroll
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-5189-337X" title="ORCID identifier">0000-0001-5189-337X</a></span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jmc56@psu.edu">jmc56@psu.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id34.1.id1">Pennsylvania State University</span><span class="ltx_text ltx_affiliation_streetaddress" id="id35.2.id2">Westgate Building</span><span class="ltx_text ltx_affiliation_city" id="id36.3.id3">University Park</span><span class="ltx_text ltx_affiliation_state" id="id37.4.id4">Pennsylvania</span><span class="ltx_text ltx_affiliation_country" id="id38.5.id5">USA</span><span class="ltx_text ltx_affiliation_postcode" id="id39.6.id6">16801</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id40.id1">Both sensor networks and data fusion are essential foundations for developing the smart home Internet of Things (IoT) and related fields. We proposed a multi-channel sensor network construction method involving hardware, acquisition, and synchronization in the smart home environment and a smart home data fusion method (SHDFM) for multi-modal data (position, gait, voice, pose, facial expression, temperature, and humidity) generated in the smart home environment to address the configuration of a multi-channel sensor network, improve the quality and efficiency of various human activities and environmental data collection, and reduce the difficulty of multi-modal data fusion in the smart home. SHDFM contains 5 levels, with inputs and outputs as criteria to provide recommendations for multi-modal data fusion strategies in the smart home. We built a real experimental environment using the proposed method in this paper. To validate our method, we created a real experimental environment — a physical setup in a home-like scenario where the multi-channel sensor network and data fusion techniques were deployed and evaluated. The acceptance and testing results show that the proposed construction and data fusion methods can be applied to the examples with high robustness, replicability, and scalability. Besides, we discuss how smart homes with multi-channel sensor networks can support digital twins.</p>
</div>
<div class="ltx_keywords">smart home, internet of things, data fusion, sensor network, system
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Chinese CHI 2023; November 13–16, 2023; Denpasar, Bali, Indonesia</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>Chinese CHI 2023 (CHCHI 2023), November 13–16, 2023, Denpasar, Bali, Indonesia</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3629606.3629638</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-1645-4/23/11</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing HCI design and evaluation methods</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Empirical studies in HCI</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Information systems applications</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id10"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Hardware Communication hardware, interfaces and storage</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id11"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Hardware Sensor devices and platforms</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">With the improvement of sensor technology, the development of artificial intelligence, the popularization of high-speed Internet, and the application of the concept of smart home Internet of Things, the concept of the smart home is being accepted by more and more people. At the same time, with the popularity of consumer-grade smart home products and the increase in human society’s demand, the smart home market has a certain scale and is growing rapidly. Statista states that the global smart home market could reach $182.45 billion by 2025 <cite class="ltx_cite ltx_citemacro_citep">(Lasquety-Reyes, <a class="ltx_ref" href="#bib.bib28" title="">2019</a>)</cite>. According to the scenario-based needs of users, a smart home mainly involves several key areas such as device control and linkage <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib49" title="">2017</a>)</cite>, scene atmosphere <cite class="ltx_cite ltx_citemacro_citep">(Eggen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib11" title="">2003</a>)</cite>, entertainment and leisure <cite class="ltx_cite ltx_citemacro_citep">(Kim et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib23" title="">2018</a>)</cite>, intelligent security <cite class="ltx_cite ltx_citemacro_citep">(Touqeer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib45" title="">2021</a>)</cite>, energy management <cite class="ltx_cite ltx_citemacro_citep">(Badar and Anvari-Moghaddam, <a class="ltx_ref" href="#bib.bib3" title="">2022</a>)</cite>, intelligent applications <cite class="ltx_cite ltx_citemacro_citep">(Kornyshova et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib26" title="">2022</a>)</cite>, and design for specific people or needs <cite class="ltx_cite ltx_citemacro_citep">(Jamwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib20" title="">2022</a>; Schak et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib40" title="">2022</a>; Radha, <a class="ltx_ref" href="#bib.bib38" title="">2022</a>)</cite>. On the one hand, there is a growing demand for smarter and more efficient smart homes and related products, and the various needs, motivations, goals, and implementation methods of using smart homes in smart home scenarios are repeatedly emphasized <cite class="ltx_cite ltx_citemacro_citep">(Marikyan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib34" title="">2019</a>; Hargreaves et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib17" title="">2018</a>)</cite>. Among them, data and sensor networks are one of the most important foundations for studying smart home problems. On the other hand, traditional interaction methods have been found to have a number of interactivity problems that still affect the interaction experience, such as intrusiveness <cite class="ltx_cite ltx_citemacro_citep">(Benlian et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib4" title="">2020</a>)</cite>, fatigue <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib32" title="">2020</a>)</cite>, and interaction with specific groups of people <cite class="ltx_cite ltx_citemacro_citep">(Kim and Choudhury, <a class="ltx_ref" href="#bib.bib24" title="">2021</a>)</cite>. The sensor network construction and data fusion application are the preconditions to help solve the above problems. In addition, humans have moved into the information society, where more and more interactions are moving from physical to virtual. Highly informative and virtualized interactions are gradually accepted and taken for granted. The diversity of data collected through multi-channel sensor networks significantly impacts future interaction methods, especially for further smart home digital twins.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">There is currently no comprehensive summary of sensor network construction methods in the smart home. The main problems are the following two: (1) There are few comprehensive, integrated application and sensor network construction methods covering the whole smart home. Most of the existing studies are sensor networks built for specific studies, which are characterized by using only a small number of channels, a relatively single type, and a single purpose of sensors. Although similar sensor networks are still somewhat usable for specific research problems, with the further diversification of scenarios and requirements in smart homes, a series of unpredictable cross-influences on the research problems in real smart home environments cannot be effectively addressed or planned; (2) Existing studies rarely mention the specific implementation problems encountered in the construction of sensor networks, especially the configuration of hardware, acquisition, and synchronization in multi-channel sensor networks. The smart home is a significant research sub-field in human-computer interaction (HCI) and even in the interdisciplinary intersection. There are a lot of research problems related to people’s livelihoods that can be explored <cite class="ltx_cite ltx_citemacro_citep">(FU et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib14" title="">2023</a>)</cite>. At the same time, the a priori skills of researchers and technologies are likely to be limited in the interdisciplinary field, which limits further research.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">With the development of sensor technologies and the growing demand for HCI, ubiquitous computing <cite class="ltx_cite ltx_citemacro_citep">(Mehrotra et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib35" title="">2021</a>)</cite> and data-driven <cite class="ltx_cite ltx_citemacro_citep">(Sarker, <a class="ltx_ref" href="#bib.bib39" title="">2021</a>)</cite> approaches have received significant attention from researchers. The processing and fusion methods of the large amount of multimodal data generated in the smart home environment directly affect the effectiveness of the relevant models. The data fusion mentioned in this paper refers to the process of fusing real data from multiple sources, where disparate data are fused into usable integrated data. Traditional data fusion has certain challenges, mainly regarding uncertainty, integrity, and consistency after fusion [9]. In addition to the conventional challenges, data fusion solutions for smart homes also face the following new challenges:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Existing data fusion solutions are not applicable to smart home problems.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Multimodal data fusion has limitations in terms of the types and numbers of modalities involved.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Only specific problems are addressed without global considerations, and portability is insufficient.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Based on the above background and challenges, this paper firstly introduces the current situation, development trend, problems, and difficulties of multi-channel sensor network construction and data fusion and related research, and then proposes a multi-sensor network construction method applied to the smart home environment in conjunction with the development trend of smart home, future research-ability, sensor availability and related environment construction problems, and thus proposes a data fusion scheme in the smart home environment. Concurrently, the proposed methods for constructing the sensor network and the data fusion scheme were preliminarily tested through real scenario assessments on the comprehensive experimental platform we’ve built. </p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>The Construction of Multi-channel Sensor Networks</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The sensor network consists of multiple sensor nodes deployed in the smart home, forming a multi-hop self-organizing network using wireless communication. Liang et al. <cite class="ltx_cite ltx_citemacro_citep">(Liang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib30" title="">2021</a>)</cite> built a wireless sensor network for the smart home security system based on ZigBee protocol and other IoT technologies. Their proposed sensor network mainly consists of a digital access control system(hub) and sensor nodes. The sensor nodes mainly focus on detecting intrusion and indoor environmental information, including PIR, water level, smoke, and reed switch sensors. Ramson and Moni <cite class="ltx_cite ltx_citemacro_citep">(Jino Ramson and Moni, <a class="ltx_ref" href="#bib.bib21" title="">2017</a>)</cite> reviewed various applications of wireless sensor networks, and the examples cited in their study regarding environmental monitoring, healthcare, and smart building categories are highly relevant to smart homes. Liu et al. <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib33" title="">2023</a>)</cite> described the types of multi-channel sensors that may be used in smart environments and their uses.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Multi-device synchronization in multi-channel sensor networks poses significant challenges. While the widely used Network Time Protocol (NTP) <cite class="ltx_cite ltx_citemacro_citep">(Mills et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib36" title="">2010</a>)</cite> offers universal time coordination, it lacks precision (its time accuracy is low, providing 1-50ms time accuracy and relying on real-time network load), which may result in substantial errors in systems requiring high-frequency data, such as multi-camera video sensors. Additionally, to ensure the smooth functioning of the sensor network, a smart home system often requires a robust control base station, data acquisition, data processing, wireless communication, and power supply systems <cite class="ltx_cite ltx_citemacro_citep">(Shaikh and Zeadally, <a class="ltx_ref" href="#bib.bib42" title="">2016</a>)</cite>. While various studies <cite class="ltx_cite ltx_citemacro_citep">(Intille et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib19" title="">2005</a>; Seo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib41" title="">2021</a>)</cite> have made valuable contributions to multi-channel sensor networks in smart homes, we aim to extend this research further. We aim to develop a system that integrates a broader array of channels with a more diverse range of sensors and smart home devices. Our proposed construction route is designed to be comprehensive, enhancing the system’s overall quality. In our ongoing work, we strive for a system that excels in terms of wholeness, accessibility, robustness, reproducibility, and intelligence.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Multi-channel Data Fusion</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Researchers have widely discussed data fusion and related techniques. The underlying logic is to combine different types, dimensions, and qualities of data from multiple sources and use them for any parameter estimation <cite class="ltx_cite ltx_citemacro_citep">(Castanedo, <a class="ltx_ref" href="#bib.bib5" title="">2013</a>)</cite>. In related studies <cite class="ltx_cite ltx_citemacro_citep">(Ming-Hao and Jian-Hua, <a class="ltx_ref" href="#bib.bib37" title="">2019</a>; Sun and Deng, <a class="ltx_ref" href="#bib.bib44" title="">2009</a>)</cite>, the conceptual terms of multimodal data fusion, multi-channel data fusion, and multisensor data fusion are often substitutable. Hall and Linas <cite class="ltx_cite ltx_citemacro_citep">(Hall and Llinas, <a class="ltx_ref" href="#bib.bib16" title="">1997</a>)</cite> proposed a definition of data fusion in which data from multiple sources are processed and combined based on relevant information to obtain higher accuracy and greater interpretability than single-source data. On the one hand, researchers have conducted a large number of studies related to multimodal data fusion, involving fusion strategies <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite>, data processing methods <cite class="ltx_cite ltx_citemacro_citep">(Azcarate et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib2" title="">2021</a>)</cite>, multisensor data fusion <cite class="ltx_cite ltx_citemacro_citep">(Hall and Llinas, <a class="ltx_ref" href="#bib.bib16" title="">1997</a>)</cite>, information fusion <cite class="ltx_cite ltx_citemacro_citep">(Leung et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib29" title="">2019</a>)</cite>, and data fusion applications <cite class="ltx_cite ltx_citemacro_citep">(King et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib25" title="">2017</a>)</cite>, etc. Meanwhile, some technical engineering and methodological guidelines on data fusion are provided in related studies <cite class="ltx_cite ltx_citemacro_citep">(Liggins II et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib31" title="">2017</a>; Esteban et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib12" title="">2005</a>)</cite>. On the other hand, researchers have continuously reviewed and organized techniques and fusion methods related to data fusion <cite class="ltx_cite ltx_citemacro_citep">(Castanedo, <a class="ltx_ref" href="#bib.bib5" title="">2013</a>; Esteban et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib12" title="">2005</a>; Durrant-Whyte and Henderson, <a class="ltx_ref" href="#bib.bib9" title="">2016</a>; Khaleghi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib22" title="">2013</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">The data fusion architecture system proposed by Dasarathy <cite class="ltx_cite ltx_citemacro_citep">(Dasarathy, <a class="ltx_ref" href="#bib.bib7" title="">1997</a>)</cite> is one of the most famous data fusion methods, and its system consists of five categories based on input and output conditions, which are (1) Data In-Data Out (DAI-DAO): this method is the most basic data fusion method, where the raw data is fused, and the data itself is output directly after the sensor acquires the data; (2)Data In-Feature Out (DAI-FEO): Combine the sensors’ original data and output the fused data’s features; (3)Feature In-Feature Out (FEI-FEO): Both input and output are data features that are suitable for multi-source data with different data structures; (4) Feature In-Decision Out (FEI- DEO): Goal-oriented by inputting features and deriving decision labels based on a priori knowledge or pre-trained models. This category is often referred to as feature fusion; (5) Decision In-Decision Out (DEI- DEO): Both input and output are decisions, and this category is often referred to as decision fusion. All the five fusion strategies proposed in the method have some limitations. Among them, methods (1) to (4) are the common fusion methods, while method (5) has higher technical configuration requirements, especially for the deployment and configuration of full sensor networks. However, (5) has a good scope for development and is more suitable for the development trend in the context of artificial intelligence and machine learning. Based on this data fusion architecture, Fawzy et al. <cite class="ltx_cite ltx_citemacro_citep">(Fawzy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib13" title="">2021</a>)</cite> proposed a spatiotemporal data fusion (STDF) method for low-level data input-output fusion for real-time spatial IoT resource aggregation by k-mean clustering for spatial clustering and tiny AG-gregation (TAG) for temporal aggregation, which reduced the data size by 95% and saved 80% of the processing time with 90% accuracy.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Joint Directors of Laboratories (JDL) <cite class="ltx_cite ltx_citemacro_citep">(White, <a class="ltx_ref" href="#bib.bib47" title="">1991</a>)</cite>, although originating from the military domain, is currently the most popular data fusion model <cite class="ltx_cite ltx_citemacro_citep">(Khaleghi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib22" title="">2013</a>)</cite>, which is based on a data fusion process divided into five levels and includes an associated information database and an information channel for connecting the five levels, the database, the management system and the user interface.
</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Technology Mediation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The use of information technology to create new ”virtual spaces” is no longer just an idea but has become a happening today. Creations using virtual reality (VR) <cite class="ltx_cite ltx_citemacro_citep">(Eckstein et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib10" title="">2019</a>)</cite>, augmented reality (AR) <cite class="ltx_cite ltx_citemacro_citep">(Ullah et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib46" title="">2012</a>)</cite>, and mixed reality (MR) <cite class="ltx_cite ltx_citemacro_citep">(Speicher et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib43" title="">2019</a>)</cite> technologies are beginning to blur the boundaries of the world. Dourish’s <cite class="ltx_cite ltx_citemacro_citep">(Dourish, <a class="ltx_ref" href="#bib.bib8" title="">2006</a>)</cite> concept of relying on data and technology and developing new practices, new responses, and new environmental perceptions from everyday real-world experiences has been integrated into and become part of human society. The impact of data on the digital twin and the future of interaction is now widely recognized by academia. In the Smart Home domain, many possible devices and concept prototypes are made possible through data support. For example, the ”Smart Home Virtual Tour” created by Kučera and Haffner et al. <cite class="ltx_cite ltx_citemacro_citep">(Kučera et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib27" title="">2018</a>)</cite> uses multiple sensors connected to an Arduino microcontroller to enable virtual tours and events to react to each other. Hu and Mao et al. <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib18" title="">2022</a>)</cite> proposed a digital twin and mixed reality based remote collaboration system for smart homes (RCSSH) in which cameras, environmental sensors (for temperature, harmful gas, smoke/fire), weight sensors, audio sensors (by headphones), and infrared sensors are deployed. Remote assistance is provided to users by collecting data from sensors in a mixed reality environment. Gopinath and Srija et al. <cite class="ltx_cite ltx_citemacro_citep">(Gopinath et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib15" title="">2019</a>)</cite> proposed a solution for redesigning the smart home using the digital twin, which relies on continuous connection and data transfer between sensors and virtual models and applications to enable real-time tracking and visualization of the smart home in a digital twin environment. However, there are few digital twins for the entire smart home environment.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Multi-channel Sensor Network Construction for Smart Home</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This paper proposes the whole sensor network system consists of four subsystems covering sensor acquisition, data processing, data transmission, database maintenance management, and automation functions, namely: (1) hardware system, (2) acquisition system, (3) synchronization system, and (4) robustness system.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Hardware, Data Collection and Synchronization System</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The hardware system of the smart home multi-channel sensor network contains (1) multi-channel sensors for collecting various activities and environmental data in the smart home environment; (2) Interprocess communication (IPC) system components for handling the data acquisition process; (3) Synchronization control system components for solving multi-channel sensor synchronization acquisition problems; (4) Network attached storage (NAS). Common types of sensors include multi-camera systems, microphone arrays, pressure sensors, electronic nose, gas sensors, sensors attached to furniture and home appliances, etc. The hardware system determines the upper limit of the quality of the collected data. It is recommended to focus on the sensor type, deployment location, synchronization method, and feasibility of the hardware system.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The multi-channel sensor network, as outlined in our real-time hardware model, has been deployed in a real-life smart home integrated experiment platform spread over approximately 60m<math alttext="{}^{2}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msup id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1a" xref="S3.SS1.p2.1.m1.1.1.cmml"></mi><mn id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><cn id="S3.SS1.p2.1.m1.1.1.1.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>. The setup comprises multiple FLIR cameras, connected to an Industrial PC (IPC) via a 10 GigE network, generating about 6.7TB of data daily, excluding bedrooms and bathrooms to maintain privacy. Microphones, olfactory, environmental, and specific device sensors, such as pressure and infrared, are positioned strategically. These sensors relay data to the IPC system using data cables, Bluetooth, or WiFi. The synchronized data is pre-processed and stored on a dedicated server for future use.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Multi-channel Sensor Networks: Smart Home Data Fusion Model</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">After the multi-channel sensor network system is built, human activity data and environmental data will be collected in the smart home environment. We propose a data fusion model for a multi-channel sensor network in smart home environments based on the JDL model in Figure <a class="ltx_ref" href="#S4.F1" title="Figure 1 ‣ 4. Multi-channel Sensor Networks: Smart Home Data Fusion Model ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_tag">1</span></a>, called Smart Home Data Fusion Model (SHDFM).
</p>
</div>
<figure class="ltx_figure" id="S4.F1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Smart Home Data Fusion Model (SHDFM): Human activity in the smart home environment directly influences the Resources of Data, Sensors, Database, and Prior knowledge on the left side of the diagram, which is processed through the information channel for smart home data fusion and then acts on smart home devices through data sources alignment, data cleaning feature extraction, advanced behavioral feature extraction, complex decision-making to influence human behavior. In addition, the data will also be used in smart cities through external resources after complex decisions have been made and through process optimization using virtual interactions to influence human behavioral activities. The final result is a Scenario and end-user task-based design and application.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S4.F1.g1" src="extracted/5315481/samples/images/SHDFM.png" width="598"/></div>
<div class="ltx_flex_cell">
<p class="ltx_p ltx_align_center" id="S4.F1.2">SHDFM</p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Smart Home Data Fusion Model (SHDFM): Human activity in the smart home environment directly influences the Resources of Data, Sensors, Database, and Prior knowledge on the left side of the diagram, which is processed through the information channel for smart home data fusion and then acts on smart home devices through data sources alignment, data cleaning feature extraction, advanced behavioral feature extraction, complex decision-making to influence human behavior. In addition, the data will also be used in smart cities through external resources after complex decisions have been made and through process optimization using virtual interactions to influence human behavioral activities. The final result is a Scenario and end-user task-based design and application.</figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">Level 0</span>
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1">This level implements the most basic data fusion, but unlike the traditional JDL model, the focus of this level is on multi-source data alignment, where the input is data from separate timelines and the output is data with the same timestamp. The synchronization components and timestamp alignment methods mentioned above are applied to align the multi-modal data in time units. At this level, the other modal data sizes can be aligned to the primary modal by specifying a few primary modalities. In the example, the amount of information contained in the images and audio is taken as a reference. The high-frequency data, such as the data of the multi-camera and microphone system, are chosen as the primary modality for alignment, considering the large amount of semantic information contained in the images and audio, but not in the sensors, such as environment and usage.
</p>
</div>
<div class="ltx_para" id="S4.I1.ix1.p2">
<p class="ltx_p" id="S4.I1.ix1.p2.1">This level addresses the critical limitation of mismatched timestamps often found in traditional data fusion methods. Here, rather than just fusing data, we lay emphasis on multi-source data alignment. The input comprises data from disparate timelines, and the output synchronizes them to have identical timestamps. By aligning high-frequency data, such as images and audio from multi-camera and microphone systems, which carry significant semantic information, to a primary modality, this level establishes a foundational solution for subsequent levels.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">Level 1</span>
<div class="ltx_para" id="S4.I1.ix2.p1">
<p class="ltx_p" id="S4.I1.ix2.p1.1">At this level, multi-model data sources are used for data filtering and labeling. For example, in a smart home environment using a multi-camera system, camera data is aligned at a specific frame rate. Main cameras are identified, unoccupied frames removed via person detection algorithms, and relevant frames are calibrated or deleted based on comparison with voice data. Building on the alignment achieved in Level 0, this level harnesses multi-modal data sources for data filtering and labeling. In practical scenarios like a smart home, this helps eliminate redundancy and enhances accuracy.</p>
</div>
<div class="ltx_para" id="S4.I1.ix2.p2">
<p class="ltx_p" id="S4.I1.ix2.p2.1">Data from multi-channel sensors is fused to extract more useful data and features. Using the multi-camera system again as an example, a spatial coordinate system is established. Each camera’s relative spatial coordinates are calibrated, and skeletal point coordinates are extracted and reconstructed in 3D, improving data accuracy. This, combined with aligned floor data, helps obtain the subject’s movements and position in the room.</p>
</div>
<div class="ltx_para" id="S4.I1.ix2.p3">
<p class="ltx_p" id="S4.I1.ix2.p3.1">Ideally, the processes of these initial stages can feed into and optimize the outputs of further stages.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">Level 2</span>
<div class="ltx_para" id="S4.I1.ix3.p1">
<p class="ltx_p" id="S4.I1.ix3.p1.1">This level involves further extraction of data features and high-level states, such as types of activities, emotions, health conditions, and interactions between objects. Here, the labeling results are more complex, influenced by prior knowledge and human factors. Also, the fusion process goes through cycles for optimization, knowledge updates, and expansion of dynamic variable influence on the output. Studies at this level focus on advanced state behavior recognition, multi-modal emotion detection, and specific interaction studies. For instance, in ongoing research, researchers are trying to identify thirteen advanced states of occupants based on camera and floor sensor data (see example in the Figure <a class="ltx_ref" href="#A1.F2.sf1" title="2(a) ‣ Figure 2 ‣ Appendix A APPENDICESx ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_tag">2(a)</span></a>). Furthermore, they performed emotion recognition based on gait and speech information, categorizing the multi-modal data into nine emotional states.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">Level 3</span>
<div class="ltx_para" id="S4.I1.ix4.p1">
<p class="ltx_p" id="S4.I1.ix4.p1.1">Complex Decision Making: The advanced tags, such as various human activities, emotions, events, and behaviors in the smart home environment obtained in the previous level, are fused and combined with environmental data for complex decision-making or higher-level activity recognition. Compared to level 2, level 3 has more uncertainty in the output but more personalization. Also, from this level onwards, there will be interactions initiated by things to people, such as active recommendation systems and emotional interventions. Therefore, from this level, intelligent interactive devices within the smart home system are invoked.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">Level 4.1</span>
<div class="ltx_para" id="S4.I1.ix5.p1">
<p class="ltx_p" id="S4.I1.ix5.p1.1">Smart City Access: External resources beyond the limits of the smart home begin to be called upon, such as big data and more shared data beyond the scope of the smart home. This level can result from quantitative changes, such as independent smart home networks accessing the broader smart city. At the core of this is the fact that sensor channels and coverage areas reach a sizable scale in a given area of human activity, and data sharing is no longer bound by space and time
, and the data can support multiple events and context awareness.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">Level 4.2</span>
<div class="ltx_para" id="S4.I1.ix6.p1">
<p class="ltx_p" id="S4.I1.ix6.p1.1">Virtual Smart Home: it represents an untapped yet promising avenue parallel to level 4.1. It encompasses the virtualization of a smart home, achieved through continuous data feature interaction, extraction, recognition, fusion, and decision-making. The integral processes of this level and level 4.1 mutually influence each other without a hierarchical relationship. The multi-channel sensor network data can be rendered into a virtual space through digital twins, establishing a connection between actions within the virtual space and the real world. This virtual smart home transcends traditional notions of space and time, entirely supported by the underlying data infrastructure.
</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">SHDFM weaves the smart home environment with a multi-channel sensor network in a dynamic, adaptable architecture. As we climb the SHDFM ladder, requirements and resources evolve, becoming more intricate. Interestingly, as the complexity increases, the volume of output data decreases, a testament to the refined processes at play. While each level has the flexibility for self-iteration and influences across levels, they all present vast research potential.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">Presently, extensive research efforts are directed toward levels 0 to 3, and with technological advancements, level 4 is also being explored. Moving forward, we anticipate continued improvements across levels 0 to 3, potentially in a non-linear fashion. Moreover, we foresee the exploration of levels 4.1 and 4.2 as the focus of future work, provided the resource ceiling is lifted. However, delving into these advanced levels may bring ethical considerations into sharper focus.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Further Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The smart home environment introduces unique challenges that conventional data fusion methods often need to be equipped to tackle. Traditional solutions need to improve in the face of smart homes’ dynamic nature, diversity of data, and the pivotal role of privacy and security.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Smart homes are characterized by the simultaneous evolution of numerous factors, including residents’ behaviors, varied ambient conditions, and the status of interconnected smart devices. These homes generate vast data types, requiring a flexible fusion strategy to manage disparate data scales efficiently. Additionally, a high emphasis on privacy and security becomes necessary, which isn’t typically a primary concern in other data fusion scenarios.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">SHDFM is designed to address these specific challenges, utilizing a non-unidirectional flow architecture that permits dynamic adjustments and iterative optimization across various layers. This novel approach facilitates the model’s adept adaptation to the dynamic nature of smart homes.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Conventional data fusion methods, founded on a linear or unidirectional data processing flow, need help to adapt efficiently to smart homes’ dynamism and diverse data types. Furthermore, they may need more mechanisms to ensure adequate privacy and security protections. While these methods could be modified to a degree, they may not offer robust or optimal solutions in the smart home context.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">Our proposed SHDFM, with its structured yet adaptable approach, confronts these challenges head-on while vigilantly maintaining user privacy and security. As we continue to refine this model, we anticipate it is playing a transformative role in advancing the capabilities and user-friendliness of future smart home systems.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Future Work</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">One of our ongoing works focuses on advancing the application of Digital Twin technology in our smart home system. We are striving to optimize the multi-modal data collection from our network of over 100 IoT devices and enhance the accuracy of our smart home virtual representation. In parallel, we enrich our understanding of human-centric data through our multi-channel sensor network, emphasizing capturing and interpreting behavioral and cognitive insights. The ultimate goal is to extend our capabilities to virtually map human interactions within the smart home, providing a comprehensive picture of user behavior.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The prototype (Figure <a class="ltx_ref" href="#A1.F2.sf2" title="2(b) ‣ Figure 2 ‣ Appendix A APPENDICESx ‣ Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home"><span class="ltx_text ltx_ref_tag">2(b)</span></a>) we’ve created is a detailed replication of a real-world smart home environment, capturing key elements such as furniture, devices, and sensor placements. Its objective is to provide an extensive visual interpretation of the smart home setup. Our next step involves upgrading the prototype to allow interaction with specific devices within this virtual space, driven by data from the actual smart home. This enhancement would be possible through further improvements in the prototype’s capabilities.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Additionally, we are progressing with a project that leverages the SHDFM to analyze and synthesize primary behavioral data along with environmental data. The goal of this project is to extract high-level semantic information like human emotion, intent, and cognition <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="#bib.bib48" title="">2023</a>)</cite>. For a more thorough digital twin, we gather human data through multi-channel sensors, which aid in affective analysis.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This paper delves into the research landscape of smart homes, scrutinizes multi-channel sensor networks and data fusion literature specific to this realm, and pinpoints existing challenges. We propose a robust method for constructing multi-channel sensor networks and present a comprehensive example as a reference for researchers, particularly those venturing into interdisciplinary fields. We further introduce a modified version of the JDL data fusion model, dubbed the SHDFM, to establish a blueprint for smart home data fusion studies. To date, we have accomplished Level 0 and 1, along with aspects of Level 3 and 4.2, with the remaining levels slated for future work.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Key areas of focus for next-generation smart home sensor networks include amplifying network transmission rates and incorporating snap-in sensors that are simpler to install. The emphasis on Level 4 of the SHDFM is apparent and poised to grow. Overcoming technical obstacles while addressing ethical concerns affiliated with smart homes remains paramount. Furthering our understanding of user psychology and needs will allow for more targeted and practical frameworks and platforms.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Our proposed framework and methodology are designed to aid in constructing smart home research platforms, underpin theoretical research on sensor networks and data fusion, and guide the development of smart home products. By providing examples of smart home platforms built on the foundation of this framework and theory, we aim to streamline subsequent research. Looking forward, the creation of advanced smart home experimental platforms, incorporating comprehensive sensor networks and data fusion, will stand as a crucial focus for our future endeavors in HCI studies.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work was supported by the National Natural Science Foundation of China (Grant No. 62172252)

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Azcarate et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Silvana M Azcarate,
Rocío Ríos-Reina, José M
Amigo, and Héctor C Goicoechea.
2021.

</span>
<span class="ltx_bibblock">Data handling in data fusion: methodologies and
applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">TrAC Trends in Analytical Chemistry</em>
143 (2021), 116355.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.trac.2021.116355" title="">https://doi.org/10.1016/j.trac.2021.116355</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badar and Anvari-Moghaddam (2022)</span>
<span class="ltx_bibblock">
Altaf QH Badar and Amjad
Anvari-Moghaddam. 2022.

</span>
<span class="ltx_bibblock">Smart home energy management system–a review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Advances in Building Energy Research</em>
16, 1 (2022),
118–143.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/17512549.2020.1806925" title="">https://doi.org/10.1080/17512549.2020.1806925</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benlian et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Alexander Benlian,
Johannes Klumpe, and Oliver Hinz.
2020.

</span>
<span class="ltx_bibblock">Mitigating the intrusive effects of smart home
assistants by using anthropomorphic design features: A multimethod
investigation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Information Systems Journal</em>
30, 6 (2020),
1010–1042.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1111/isj.12243" title="">https://doi.org/10.1111/isj.12243</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Castanedo (2013)</span>
<span class="ltx_bibblock">
Federico Castanedo.
2013.

</span>
<span class="ltx_bibblock">A review of data fusion techniques.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">The scientific world journal</em>
2013 (2013), 1–19.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1155/2013/704504" title="">https://doi.org/10.1155/2013/704504</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Guo Chen, Zhigui Liu,
Guang Yu, and Jianhong Liang.
2021.

</span>
<span class="ltx_bibblock">A New View of Multisensor Data Fusion: Research on
Generalized Fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Mathematical Problems in Engineering</em>
2021 (2021), 1–21.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1155/2021/5471242" title="">https://doi.org/10.1155/2021/5471242</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dasarathy (1997)</span>
<span class="ltx_bibblock">
B.V. Dasarathy.
1997.

</span>
<span class="ltx_bibblock">Sensor fusion potential exploitation-innovative
architectures and illustrative applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proc. IEEE</em> 85,
1 (1997), 24–38.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/5.554206" title="">https://doi.org/10.1109/5.554206</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dourish (2006)</span>
<span class="ltx_bibblock">
Paul Dourish.
2006.

</span>
<span class="ltx_bibblock">Re-Space-Ing Place: ”Place” and ”Space” Ten Years
On. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2006 20th Anniversary
Conference on Computer Supported Cooperative Work</em> (Banff, Alberta, Canada)
<em class="ltx_emph ltx_font_italic" id="bib.bib8.2.2">(CSCW ’06)</em>. Association for
Computing Machinery, New York, NY, USA,
299–308.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1180875.1180921" title="">https://doi.org/10.1145/1180875.1180921</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Durrant-Whyte and Henderson (2016)</span>
<span class="ltx_bibblock">
Hugh Durrant-Whyte and
Thomas C Henderson. 2016.

</span>
<span class="ltx_bibblock">Multisensor data fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Springer handbook of robotics</em>
(2016), 867–896.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-319-32552-1_35" title="">https://doi.org/10.1007/978-3-319-32552-1_35</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eckstein et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Benjamin Eckstein, Eva
Krapp, Anne Elsässer, and Birgit
Lugrin. 2019.

</span>
<span class="ltx_bibblock">Smart substitutional reality: Integrating the smart
home into virtual reality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Entertainment Computing</em>
31 (2019), 100306.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.entcom.2019.100306" title="">https://doi.org/10.1016/j.entcom.2019.100306</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eggen et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2003)</span>
<span class="ltx_bibblock">
Berry Eggen, Gerard
Hollemans, and Richard van de Sluis.
2003.

</span>
<span class="ltx_bibblock">Exploring and enhancing the home experience.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Cognition, Technology &amp; Work</em>
5, 1 (2003),
44–54.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10111-002-0114-7" title="">https://doi.org/10.1007/s10111-002-0114-7</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esteban et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Jaime Esteban, Andrew
Starr, Robert Willetts, Paul Hannah,
and Peter Bryanston-Cross.
2005.

</span>
<span class="ltx_bibblock">A review of data fusion models and architectures:
towards engineering guidelines.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Neural Computing &amp; Applications</em>
14, 4 (2005),
273–281.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s00521-004-0463-7" title="">https://doi.org/10.1007/s00521-004-0463-7</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fawzy et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Dina Fawzy, Sherin
Moussa, and Nagwa Badr.
2021.

</span>
<span class="ltx_bibblock">The Spatiotemporal Data Fusion (STDF) approach:
IoT-based data fusion using big data analytics.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Sensors</em> 21,
21 (2021), 7035.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/s21217035" title="">https://doi.org/10.3390/s21217035</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">FU et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xinyi FU, He ZHANG,
Cheng XUE, and Tongxin SUN.
2023.

</span>
<span class="ltx_bibblock">A review of the frontier research on future smart
home.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Science &amp; Technology Review</em>
41, 8, Article 36
(2023), 16 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3981/j.issn.1000-7857.2023.08.004" title="">https://doi.org/10.3981/j.issn.1000-7857.2023.08.004</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gopinath et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
V Gopinath, A Srija,
and C Neethu Sravanthi. 2019.

</span>
<span class="ltx_bibblock">Re-design of smart homes with digital twins. In
<em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Journal of Physics: Conference Series</em>,
Vol. 1228. IOP Publishing, 012031.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1088/1742-6596/1228/1/012031" title="">https://doi.org/10.1088/1742-6596/1228/1/012031</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hall and Llinas (1997)</span>
<span class="ltx_bibblock">
D.L. Hall and J.
Llinas. 1997.

</span>
<span class="ltx_bibblock">An introduction to multisensor data fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proc. IEEE</em> 85,
1 (1997), 6–23.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/5.554205" title="">https://doi.org/10.1109/5.554205</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hargreaves et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Tom Hargreaves, Charlie
Wilson, and Richard Hauxwell-Baldwin.
2018.

</span>
<span class="ltx_bibblock">Learning to live in a smart home.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Building Research &amp; Information</em>
46, 1 (2018),
127–139.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/09613218.2017.1286882" title="">https://doi.org/10.1080/09613218.2017.1286882</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Guosheng Hu, Yu’ao Wang,
Mengyuan Mao, and Yi Zhao.
2022.

</span>
<span class="ltx_bibblock">Remote Care and Collaboration for Empty Nest
Family: Smart Home, Digital Twin and Mixed Reality. In
<em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">2022 8th International Conference on Virtual
Reality (ICVR)</em>. IEEE, 126–134.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICVR55215.2022.9847779" title="">https://doi.org/10.1109/ICVR55215.2022.9847779</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Intille et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2005)</span>
<span class="ltx_bibblock">
Stephen S Intille, Kent
Larson, J Beaudin, E Munguia Tapia,
Pallavi Kaushik, Jason Nawyn, and
Thomas J McLeish. 2005.

</span>
<span class="ltx_bibblock">The PlaceLab: A live-in laboratory for pervasive
computing research (video).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of PERVASIVE 2005 Video Program</em>
(2005).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jamwal et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Rebecca Jamwal, Hannah K
Jarman, Eve Roseingrave, Jacinta
Douglas, and Dianne Winkler.
2022.

</span>
<span class="ltx_bibblock">Smart home and communication technology for people
with disability: a scoping review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Disability and Rehabilitation: Assistive
Technology</em> 17, 6
(2022), 624–644.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/17483107.2020.1818138" title="">https://doi.org/10.1080/17483107.2020.1818138</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jino Ramson and Moni (2017)</span>
<span class="ltx_bibblock">
S. R. Jino Ramson and
D. Jackuline Moni. 2017.

</span>
<span class="ltx_bibblock">Applications of wireless sensor networks — A
survey. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">2017 International Conference on
Innovations in Electrical, Electronics, Instrumentation and Media Technology
(ICEEIMT)</em>. IEEE, 325–329.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICIEEIMT.2017.8116858" title="">https://doi.org/10.1109/ICIEEIMT.2017.8116858</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khaleghi et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Bahador Khaleghi, Alaa
Khamis, Fakhreddine O Karray, and
Saiedeh N Razavi. 2013.

</span>
<span class="ltx_bibblock">Multisensor data fusion: A review of the
state-of-the-art.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Information fusion</em> 14,
1 (2013), 28–44.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.inffus.2011.08.001" title="">https://doi.org/10.1016/j.inffus.2011.08.001</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Cheonshik Kim, Bryan Kim,
Joel JPC Rodrigues, and James CN Yang.
2018.

</span>
<span class="ltx_bibblock">Advanced technology for smart home automation and
entertainment.

</span>
<span class="ltx_bibblock">, 2 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s00779-017-1102-5" title="">https://doi.org/10.1007/s00779-017-1102-5</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim and Choudhury (2021)</span>
<span class="ltx_bibblock">
Sunyoung Kim and
Abhishek Choudhury. 2021.

</span>
<span class="ltx_bibblock">Exploring older adults’ perception and use of
smart speaker-based voice assistants: A longitudinal study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Computers in Human Behavior</em>
124 (2021), 106914.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.chb.2021.106914" title="">https://doi.org/10.1016/j.chb.2021.106914</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">King et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Rachel C King, Emma
Villeneuve, Ruth J White, R Simon
Sherratt, William Holderbaum, and
William S Harwin. 2017.

</span>
<span class="ltx_bibblock">Application of data fusion techniques and
technologies for wearable health monitoring.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Medical engineering &amp; physics</em>
42 (2017), 1–12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kornyshova et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Elena Kornyshova, Rebecca
Deneckere, Kaoutar Sadouki, Eric
Gressier-Soudan, and Sjaak Brinkkemper.
2022.

</span>
<span class="ltx_bibblock">Smart Life: Review of the Contemporary Smart
Applications. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">International Conference on
Research Challenges in Information Science</em>. Springer,
302–318.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-031-05760-1_18" title="">https://doi.org/10.1007/978-3-031-05760-1_18</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kučera et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Erik Kučera, Oto
Haffner, and Štefan Kozák.
2018.

</span>
<span class="ltx_bibblock">Connection between 3D engine unity and
microcontroller arduino: A virtual smart house. In
<em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">2018 Cybernetics &amp; Informatics (K&amp;I)</em>.
1–8.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/CYBERI.2018.8337531" title="">https://doi.org/10.1109/CYBERI.2018.8337531</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lasquety-Reyes (2019)</span>
<span class="ltx_bibblock">
Jeremiah Lasquety-Reyes.
2019.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Smart Home Report 2021</em>.

</span>
<span class="ltx_bibblock">
Retrieved October 19, 2022 from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.statista.com/study/42112/smart-home-report/" title="">https://www.statista.com/study/42112/smart-home-report/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leung et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Carson K Leung, Peter
Braun, and Alfredo Cuzzocrea.
2019.

</span>
<span class="ltx_bibblock">AI-based sensor information fusion for supporting
deep supervised learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Sensors</em> 19,
6 (2019), 1345.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/s19061345" title="">https://doi.org/10.3390/s19061345</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Chua Boon Liang, Mujahid
Tabassum, Saad Bin Abul Kashem, Zulfiqar
Zama, P Suresh, and U Saravanakumar.
2021.

</span>
<span class="ltx_bibblock">Smart home security system based on Zigbee.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Advances in Smart System Technologies</em>.
Springer, 827–836.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-981-15-5029-4_71" title="">https://doi.org/10.1007/978-981-15-5029-4_71</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liggins II et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Martin Liggins II, David
Hall, and James Llinas.
2017.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Handbook of multisensor data fusion: theory
and practice</em>.

</span>
<span class="ltx_bibblock">CRC press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Haipeng Liu, Yuheng Wang,
Anfu Zhou, Hanyue He,
Wei Wang, Kunpeng Wang,
Peilin Pan, Yixuan Lu,
Liang Liu, and Huadong Ma.
2020.

</span>
<span class="ltx_bibblock">Real-Time Arm Gesture Recognition in Smart Home
Scenarios via Millimeter Wave Sensing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proc. ACM Interact. Mob. Wearable Ubiquitous
Technol.</em> 4, 4, Article
140 (dec 2020),
28 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3432235" title="">https://doi.org/10.1145/3432235</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jie Liu, Dan Luo,
Xinyi Fu, Qi Lu, and
Karen Yixin Kang. 2023.

</span>
<span class="ltx_bibblock">Design Strategy of Multimodal Perception System for
Smart Environment.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Internet of Things for Smart
Environments</em>. Springer, 93–115.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-031-09729-4_6" title="">https://doi.org/10.1007/978-3-031-09729-4_6</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marikyan et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Davit Marikyan, Savvas
Papagiannidis, and Eleftherios Alamanos.
2019.

</span>
<span class="ltx_bibblock">A systematic review of the smart home literature: A
user perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">Technological Forecasting and Social Change</em>
138 (2019), 139–154.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.techfore.2018.08.015" title="">https://doi.org/10.1016/j.techfore.2018.08.015</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrotra et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Shashi Mehrotra, Shweta
Sinha, and Sudhir Kumar Sharma.
2021.

</span>
<span class="ltx_bibblock">Overview of the Internet of Things and Ubiquitous
Computing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Blockchain Technology for Data Privacy
Management</em>. CRC Press, 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mills et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
David Mills, Jim Martin,
Jack Burbank, and William Kasch.
2010.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Network time protocol version 4: Protocol
and algorithms specification</em>.

</span>
<span class="ltx_bibblock">Technical Report.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.rfc-editor.org/info/rfc5905" title="">http://www.rfc-editor.org/info/rfc5905</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ming-Hao and Jian-Hua (2019)</span>
<span class="ltx_bibblock">
YANG Ming-Hao and TAO
Jian-Hua. 2019.

</span>
<span class="ltx_bibblock">Data fusion methods in multimodal human computer
dialog.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Virtual Reality &amp; Intelligent Hardware</em>
1, 1 (2019),
21–38.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3724/SP.J.2096-5796.2018.0010" title="">https://doi.org/10.3724/SP.J.2096-5796.2018.0010</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radha (2022)</span>
<span class="ltx_bibblock">
Raz Kamaran Radha.
2022.

</span>
<span class="ltx_bibblock">Flexible smart home design: Case study to design
future smart home prototypes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Ain Shams Engineering Journal</em>
13, 1 (2022),
101513.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.asej.2021.05.027" title="">https://doi.org/10.1016/j.asej.2021.05.027</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarker (2021)</span>
<span class="ltx_bibblock">
Iqbal H Sarker.
2021.

</span>
<span class="ltx_bibblock">Data science and analytics: an overview from
data-driven smart computing, decision-making and applications perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">SN Computer Science</em> 2,
5 (2021), 1–22.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s42979-021-00765-8" title="">https://doi.org/10.1007/s42979-021-00765-8</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schak et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Monika Schak, Rainer
Blum, and Birgit Bomsdorf.
2022.

</span>
<span class="ltx_bibblock">Smart Home for the Elderly-A Survey of Desires,
Needs, and Problems. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">International Conference
on Human-Computer Interaction</em>. Springer, 107–121.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-031-05654-3_7" title="">https://doi.org/10.1007/978-3-031-05654-3_7</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seo et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Eugene Seo, Sihwa Bae,
Hyunchul Choi, and Donghyeog Choi.
2021.

</span>
<span class="ltx_bibblock">Preference and usability of smart-home services and
items-a focus on the smart-home living-lab-.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Journal of Asian Architecture and Building
Engineering</em> 20, 6
(2021), 650–662.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/13467581.2020.1812397" title="">https://doi.org/10.1080/13467581.2020.1812397</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shaikh and Zeadally (2016)</span>
<span class="ltx_bibblock">
Faisal Karim Shaikh and
Sherali Zeadally. 2016.

</span>
<span class="ltx_bibblock">Energy harvesting in wireless sensor networks: A
comprehensive review.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Renewable and Sustainable Energy Reviews</em>
55 (2016), 1041–1054.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.rser.2015.11.010" title="">https://doi.org/10.1016/j.rser.2015.11.010</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Speicher et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Maximilian Speicher,
Brian D. Hall, and Michael Nebeling.
2019.

</span>
<span class="ltx_bibblock">What is Mixed Reality?. In
<em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems</em> (Glasgow, Scotland Uk)
<em class="ltx_emph ltx_font_italic" id="bib.bib43.4.2">(CHI ’19)</em>. Association for
Computing Machinery, New York, NY, USA,
1–15.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3290605.3300767" title="">https://doi.org/10.1145/3290605.3300767</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun and Deng (2009)</span>
<span class="ltx_bibblock">
X-J Sun and Z-L Deng.
2009.

</span>
<span class="ltx_bibblock">Information fusion Wiener filter for the
multisensor multichannel ARMA signals with time-delayed measurements.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">IET Signal Processing</em> 3,
5 (2009), 403–415.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1049/iet-spr.2008.0096" title="">https://doi.org/10.1049/iet-spr.2008.0096</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touqeer et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Haseeb Touqeer, Shakir
Zaman, Rashid Amin, Mudassar Hussain,
Fadi Al-Turjman, and Muhammad Bilal.
2021.

</span>
<span class="ltx_bibblock">Smart home security: challenges, issues and
solutions at different IoT layers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">The Journal of Supercomputing</em>
77, 12 (2021),
14053–14089.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s11227-021-03825-1" title="">https://doi.org/10.1007/s11227-021-03825-1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ullah et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Ahmed Mohmmad Ullah,
Md. Rashedul Islam, Sayeda Farzana Aktar,
and S K Alamgir Hossain.
2012.

</span>
<span class="ltx_bibblock">Remote-touch: Augmented reality based marker
tracking for smart home control. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">2012 15th
International Conference on Computer and Information Technology (ICCIT)</em>.
IEEE, 473–477.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICCITechn.2012.6509774" title="">https://doi.org/10.1109/ICCITechn.2012.6509774</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">White (1991)</span>
<span class="ltx_bibblock">
Franklin E White.
1991.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Data fusion lexicon</em>.

</span>
<span class="ltx_bibblock">Technical Report. Joint
Directors of Labs Washington DC.

</span>
<span class="ltx_bibblock">
Retrieved May 31, 2023 from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://apps.dtic.mil/sti/citations/ADA529661" title="">https://apps.dtic.mil/sti/citations/ADA529661</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
He Zhang, Xinyang Li,
Christine Qiu, and Xinyi Fu.
2023.

</span>
<span class="ltx_bibblock">Decoding Fear: Exploring User Experiences in Virtual
Reality Horror Games.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/abs/2312.15582" title="">https://doi.org/abs/2312.15582</a>
arXiv:2312.15582 [cs.HC]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Song Zheng, Qi Zhang,
Rong Zheng, Bi-Qin Huang,
Yi-Lin Song, and Xin-Chu Chen.
2017.

</span>
<span class="ltx_bibblock">Combining a multi-agent system and communication
middleware for smart home control: A universal control platform
architecture.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Sensors</em> 17,
9 (2017), 2135.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/s17092135" title="">https://doi.org/10.3390/s17092135</a>
</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>APPENDICESx</h2>
<figure class="ltx_figure" id="A1.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_flex_size_1 ltx_align_center" id="A1.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="272" id="A1.F2.sf1.g1" src="extracted/5315481/samples/images/gesturesample.png" width="479"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F2.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A1.F2.sf1.3.2" style="font-size:80%;">Example of behavior-posture annotation. The pose estimation diagram with background is shown in the upper left corner. The upper right corner shows the pose estimation without background. The lower left corner shows the gesture estimation with background, including hand gestures. The lower right corner shows the gesture estimation with no background and hand gestures.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_flex_size_1 ltx_align_center" id="A1.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="389" id="A1.F2.sf2.g1" src="extracted/5315481/samples/images/digital_twin_sensors_network.png" width="479"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F2.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A1.F2.sf2.3.2" style="font-size:80%;">Smart Home Digital Twin Prototype. The prototype shows an overview of the entire smart home environment and the deployment status of the multi-channel sensor. The diagram includes the house space content, furniture, devices, and sensors deployment.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Example of Behavior-posture Annotation and Smart Home Digital Twin Prototype.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Dec 27 19:25:59 2023 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
