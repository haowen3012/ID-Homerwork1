<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era</title>
<!--Generated on Sun Jun  2 16:59:58 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.12278v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S1" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S2" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S2.SS1" title="In 2 Background ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Current Data Fusion Model: DFGI Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S2.SS2" title="In 2 Background ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>The Integration of the Cross-Industry Standard Process for Data Mining (CRISP-DM)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS1" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Level 0 - Data Assessment:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS2" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Level 1 - Object Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS3" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Level 2 - Situation Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS4" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Level 3 - Impact Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS5" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Level 4 - Process Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS6" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6 </span>Level 5 - User Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS7" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7 </span>Level 6 - Mission Management</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.SS8" title="In 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8 </span>Level 7 - Bias Assessment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S4" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Addressing Bias in the DF-DM Model</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S4.SS1" title="In 4 Addressing Bias in the DF-DM Model ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Data Bias</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S4.SS2" title="In 4 Addressing Bias in the DF-DM Model ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Model Bias</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S4.SS3" title="In 4 Addressing Bias in the DF-DM Model ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Decision-Making Bias</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Use Cases</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS1" title="In 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Use case 1: Diabetic Retinopathy</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS1.SSS1" title="In 5.1 Use case 1: Diabetic Retinopathy ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Exploratory Data Analysis and Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS1.SSS2" title="In 5.1 Use case 1: Diabetic Retinopathy ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS1.SSS3" title="In 5.1 Use case 1: Diabetic Retinopathy ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Disentangled Dense Fusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS1.SSS4" title="In 5.1 Use case 1: Diabetic Retinopathy ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.4 </span>Overfitting Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS2" title="In 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS2.SSS1" title="In 5.2 Results ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Potential Biases and Limitations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3" title="In 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Use case 2: Domestic Violence Prediction Using Open Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3.SSS1" title="In 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>Dataset Description and Data Collection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3.SSS2" title="In 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>Exploratory Data Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3.SSS3" title="In 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.3 </span>Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3.SSS4" title="In 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.4 </span>Disentangled Dense Fusion for Time Series</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3.SSS5" title="In 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.5 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS3.SSS6" title="In 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.6 </span>Bias Consideration</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS4" title="In 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS4.SSS1" title="In 5.4 Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.1 </span>Dataset Description and Data Collection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS4.SSS2" title="In 5.4 Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.2 </span>Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS4.SSS3" title="In 5.4 Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.3 </span>Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS4.SSS4" title="In 5.4 Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.SS4.SSS5" title="In 5.4 Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.5 </span>Bias Consideration</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS1" title="In 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Advantages of the Proposed Framework</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS2" title="In 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Comparison with Existing Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS3" title="In 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Dense Mutual Information Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS4" title="In 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Use Cases</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS4.SSS1" title="In 6.4 Use Cases ‣ 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4.1 </span>Use case 1: Diabetic Retinopathy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS4.SSS2" title="In 6.4 Use Cases ‣ 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4.2 </span>Use case 2: Domestic Violence Prediction Using Open Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS4.SSS3" title="In 6.4 Use Cases ‣ 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4.3 </span>Use case 3: MIMIC CXR Clinical notes and x-ray images</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS4.SSS4" title="In 6.4 Use Cases ‣ 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4.4 </span>General Comments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S6.SS5" title="In 6 Discussion ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>Limitations and Future Directions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S7" title="In DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">[1,2]<span class="ltx_ERROR undefined" id="p1.1.1">\fnm</span>David <span class="ltx_ERROR undefined" id="p1.1.2">\sur</span>Restrepo<span class="ltx_ERROR undefined" id="p1.1.3">\equalcont</span>These authors contributed equally to this work.</p>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\equalcont</span>
<p class="ltx_p" id="p2.2">These authors contributed equally to this work.</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">1]<span class="ltx_ERROR undefined" id="p3.1.1">\orgdiv</span>Laboratory for Computational Physiology, <span class="ltx_ERROR undefined" id="p3.1.2">\orgname</span>Massachusetts Institute of Technology, <span class="ltx_ERROR undefined" id="p3.1.3">\orgaddress</span><span class="ltx_ERROR undefined" id="p3.1.4">\city</span>Cambridge, <span class="ltx_ERROR undefined" id="p3.1.5">\state</span>Massachusetts, <span class="ltx_ERROR undefined" id="p3.1.6">\country</span>United States of America</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">2]<span class="ltx_ERROR undefined" id="p4.1.1">\orgdiv</span>Departamento de Telemática, <span class="ltx_ERROR undefined" id="p4.1.2">\orgname</span>Universidad del Cauca, <span class="ltx_ERROR undefined" id="p4.1.3">\orgaddress</span><span class="ltx_ERROR undefined" id="p4.1.4">\city</span>Popayán, <span class="ltx_ERROR undefined" id="p4.1.5">\state</span>Cauca, <span class="ltx_ERROR undefined" id="p4.1.6">\country</span>Colombia</p>
</div>
<div class="ltx_para" id="p5">
<p class="ltx_p" id="p5.1">3]<span class="ltx_ERROR undefined" id="p5.1.1">\orgdiv</span>Department of Electrical Engineering and Computer Science, <span class="ltx_ERROR undefined" id="p5.1.2">\orgname</span>University of Michigan, <span class="ltx_ERROR undefined" id="p5.1.3">\orgaddress</span> <span class="ltx_ERROR undefined" id="p5.1.4">\city</span>Ann Arbor, <span class="ltx_ERROR undefined" id="p5.1.5">\state</span>Michigan, <span class="ltx_ERROR undefined" id="p5.1.6">\country</span>United States of America</p>
</div>
<div class="ltx_para" id="p6">
<p class="ltx_p" id="p6.1">4]<span class="ltx_ERROR undefined" id="p6.1.1">\orgdiv</span>Scientific Image Analysis Lab, <span class="ltx_ERROR undefined" id="p6.1.2">\orgname</span>Universidad de Chile, <span class="ltx_ERROR undefined" id="p6.1.3">\orgaddress</span> <span class="ltx_ERROR undefined" id="p6.1.4">\city</span>Santiago, <span class="ltx_ERROR undefined" id="p6.1.5">\state</span>Santiago, <span class="ltx_ERROR undefined" id="p6.1.6">\country</span>Chile</p>
</div>
<div class="ltx_para" id="p7">
<p class="ltx_p" id="p7.1">5]<span class="ltx_ERROR undefined" id="p7.1.1">\orgdiv</span>Department of Ophthalmology, <span class="ltx_ERROR undefined" id="p7.1.2">\orgname</span>São Paulo Federal University, <span class="ltx_ERROR undefined" id="p7.1.3">\orgaddress</span> <span class="ltx_ERROR undefined" id="p7.1.4">\city</span>São Paulo, <span class="ltx_ERROR undefined" id="p7.1.5">\state</span>São Paulo, <span class="ltx_ERROR undefined" id="p7.1.6">\country</span>Brazil</p>
</div>
<div class="ltx_para" id="p8">
<p class="ltx_p" id="p8.1">6]<span class="ltx_ERROR undefined" id="p8.1.1">\orgdiv</span>Department of Biostatistics, <span class="ltx_ERROR undefined" id="p8.1.2">\orgname</span>Harvard TH Chan School of Public Health, <span class="ltx_ERROR undefined" id="p8.1.3">\orgaddress</span> <span class="ltx_ERROR undefined" id="p8.1.4">\city</span>Boston, <span class="ltx_ERROR undefined" id="p8.1.5">\state</span>Massachusetts, <span class="ltx_ERROR undefined" id="p8.1.6">\country</span>United States of America</p>
</div>
<div class="ltx_para" id="p9">
<p class="ltx_p" id="p9.1">7]<span class="ltx_ERROR undefined" id="p9.1.1">\orgdiv</span>Department of Medicine, <span class="ltx_ERROR undefined" id="p9.1.2">\orgname</span>Beth Israel Deaconess Medical Center, <span class="ltx_ERROR undefined" id="p9.1.3">\orgaddress</span> <span class="ltx_ERROR undefined" id="p9.1.4">\city</span>Boston, <span class="ltx_ERROR undefined" id="p9.1.5">\state</span>Massachusetts, <span class="ltx_ERROR undefined" id="p9.1.6">\country</span>United States of America</p>
</div>
<h1 class="ltx_title ltx_title_document">DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:davidres@mit.edu">davidres@mit.edu</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id1.1.id1">\fnm</span>Chenwei <span class="ltx_ERROR undefined" id="id2.2.id2">\sur</span>Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:chenweiw@umich.edu">chenweiw@umich.edu</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id3.1.id1">\fnm</span>Constanza <span class="ltx_ERROR undefined" id="id4.2.id2">\sur</span>Vásquez-Venegas
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:covasquezv@inf.udec.cl">covasquezv@inf.udec.cl</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id5.1.id1">\fnm</span>Luis Filipe <span class="ltx_ERROR undefined" id="id6.2.id2">\sur</span>Nakayama
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:luisnaka@mit.edu">luisnaka@mit.edu</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id7.1.id1">\fnm</span>Leo Anthony <span class="ltx_ERROR undefined" id="id8.2.id2">\sur</span>Celi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:lceli@mit.edu">lceli@mit.edu</a>
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id9.1.id1">\fnm</span>Diego M <span class="ltx_ERROR undefined" id="id10.2.id2">\sur</span>López
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dmlopez@unicauca.edu.co">dmlopez@unicauca.edu.co</a>
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.id1">In the big data era, integrating diverse data modalities poses significant challenges, particularly in complex fields like healthcare. This paper introduces a new process model for multimodal Data Fusion for Data Mining, integrating embeddings and the Cross-Industry Standard Process for Data Mining with the existing Data Fusion Information Group model. Our model aims to decrease computational costs, complexity, and bias while improving efficiency and reliability. We also propose ”disentangled dense fusion,” a novel embedding fusion method designed to optimize mutual information and facilitate dense inter-modality feature interaction, thereby minimizing redundant information.</p>
<p class="ltx_p" id="id12.id2">We demonstrate the model’s efficacy through three use cases: predicting diabetic retinopathy using retinal images and patient metadata, domestic violence prediction employing satellite imagery, internet, and census data, and identifying clinical and demographic features from radiography images and clinical notes. The model achieved a Macro F1 score of 0.92 in diabetic retinopathy prediction, an R-squared of 0.854 and sMAPE of 24.868 in domestic violence prediction, and a macro AUC of 0.92 and 0.99 for disease prediction and sex classification, respectively, in radiological analysis.</p>
<p class="ltx_p" id="id13.id3">These results underscore the Data Fusion for Data Mining model’s potential to significantly impact multimodal data processing, promoting its adoption in diverse, resource-constrained settings.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Data Fusion, foundation Models, Embeddings, Multimodal Data
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In this era, vast amounts of data and information are generated in different settings, fields, formats, and modalities. According to the International Data Corporation (IDC), 7.5ZB are expected to be generated every year <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib1" title="">1</a>]</cite>, and the ability to process this information and extract knowledge has never been more important <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib3" title="">3</a>]</cite>. This data can come from diverse sources such as wearable devices, laboratory tests, Electronic Health Records (EHR), among many others, and modalities, such as medical images, clinical notes, and vital signs. The integration of data from different modalities is on the rise in Artificial Intelligence (AI) fields, such as Machine Learning (ML) and Deep Learning (DL), known as multimodal data fusion. This research area, with applications integrating areas from natural language processing to computer vision and beyond, has driven applications in healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib5" title="">5</a>]</cite>, integrating EHRs with medical images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib13" title="">13</a>]</cite> or signals from wearable devices <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib15" title="">15</a>]</cite>. Multimodal fusion has also led to applications such as autonomous driving <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib17" title="">17</a>]</cite>, environmental sciences applications combining different sensors and satellite data<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib19" title="">19</a>]</cite>, as well as many other Internet of Things (IoT) applications and system improvements<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib24" title="">24</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recent advances in the DL field, mainly driven by the proposal of the transformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib25" title="">25</a>]</cite>, have seen breakthroughs in the analysis of different modalities, such as text with models like BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib26" title="">26</a>]</cite> or GPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib27" title="">27</a>]</cite> or images with models like Vision Transformers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib28" title="">28</a>]</cite>. These models have been a revolution also in specific fields such as medicine with impressive performances in medical applications such as medical tests or diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib31" title="">31</a>]</cite>. However, some of the limitations of working with these data modalities and these specialized DL models are, the high dimensionality of the data, the heterogeneity of the diverse data modalities and formats, and the amount of data and computational resources required to train robust models for these specific modalities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib34" title="">34</a>]</cite>. Embeddings are low-dimensional numerical vectors learned during DL model training that preserve the original data’s most relevant features. Embeddings provide a common format that can solve data extraction and model development in environments where computational resources are scarce. Furthermore, their simplicity gives embeddings a possible way to unify the different data modalities and an efficient and generalizable solution for building multimodal models.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Since embedding is proposed as a potential solution to data heterogeneity, and computational resource constraints, the DL models used to extract these embeddings must be extremely robust models trained on large amounts of data. In this context, we discuss open-source foundation models, such as Dino v2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib35" title="">35</a>]</cite> for general images or Llama 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib36" title="">36</a>]</cite> for general text. Foundation models may also be available for specific tasks such as clinical notes with examples like Med-Bert <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib37" title="">37</a>]</cite>, Bio-Bert <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib38" title="">38</a>]</cite>, or medical images like Retfound for retinal images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib39" title="">39</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">However, having data and making a prediction is not enough and can cause harm if not done correctly. Adopting robust and reproducible practice is the most important characteristic of any data-related process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib40" title="">40</a>]</cite>. Using AI techniques irresponsibly will lead to poor model performance in bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib44" title="">44</a>]</cite>, robustness, and fairness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib47" title="">47</a>]</cite>. Acknowledging and addressing potential biases inherent in the data sources and models employed is pivotal.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">There are already previous frameworks for data fusion, starting with the best-known Joint Directors of Laboratories (JDL) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib48" title="">48</a>]</cite> and its multiple updates that led to the Data Fusion Information Group (DFIG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib49" title="">49</a>]</cite> model with its most recent version that integrates AI techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib50" title="">50</a>]</cite>. However, these models do not leverage foundation models and DL nor incorporate best practices for reducing bias and improving the model’s robustness, and have a focus only on applications such as industry and the military, leaving out use cases in environments such as healthcare.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this paper, we delve into a foundational approach for multimodal data fusion, centering the framework on the use of foundation models, vector embeddings, and good practices for data mining. Our work draws inspiration from established frameworks such as the JDL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib48" title="">48</a>]</cite> and DFIG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib49" title="">49</a>]</cite>. We emphasize the role of embeddings in providing flexibility and improving efficiency, robustness, and fairness, which is even more crucial in low-resource settings where errors and bias are relatively more impactful <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib51" title="">51</a>]</cite>. We also showed the model’s performance in three healthcare use cases: diabetic retinopathy diagnosis using fundus retinal images and EHR data, domestic violence prediction using open data from satellite images and internet data such as online news, and medical diagnosis and gender extraction using radiological images and clinical notes.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">To succinctly encapsulate the contributions of this paper, we propose the following bullet points that highlight the primary advancements and demonstrations provided by our research:</p>
</div>
<div class="ltx_para" id="S1.p8">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Introduction of a Novel Data Fusion Model:</span> We have developed an innovative process model for multimodal data fusion, rooted in the principles of foundation models and embeddings. This model is designed to efficiently address the challenges of big data’s high dimensionality and heterogeneity, making it particularly suitable for complex environments like healthcare.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Disentangled Dense Fusion Method:</span> Our work introduces a deep fusion alignment method that leverages mutual multimodal embedding information. This technique decouples entangled multimodal pairs into compact distinct components: modality-common features and modality-specific knowledge features, reducing the inter-modal redundancy while keeping expressiveness of modality-specific information. We also combine our mutual information decomposition with dense fusion to capture richer modality interactions.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Three Demonstrative Use Cases:</span> The efficacy and versatility of our process model and embedding alignment method are showcased through three distinct use cases. These include the prediction of diabetic retinopathy using retinal fundus images and patient metadata, domestic violence prediction through the fusion of satellite images, internet data, and census data, and the detection of clinical and demographic characteristics via radiography images and clinical notes.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Data fusion models and frameworks have historically been a great field of research due to the need to take advantage of all the available information. The first model to be proposed and the most widely used is the data fusion model proposed by the JDL, which was introduced in 1987 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib52" title="">52</a>]</cite>. The JDL model, mainly created for multi-sensor applications, defined data fusion as combining data to refine state estimates and predictions from a low level (sensor data) to a high level (processes). Subsequent works, such as the revision of the JDL model in 1999 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib53" title="">53</a>]</cite>, formalized and refined the JDL model by defining a 0-4 levels model, being the labels: Level 0 - Data Assessment, Level 1 - Object Assessment, level 2 - Situation Assessment, Level 3 - Impact Assessment, and Level 4 - Process Refinement.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Some improvements were proposed during the following years, such as introducing adaptive generalized closed-loop data fusion processes and the perceptual reasoning system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib54" title="">54</a>]</cite>. Eventually, a second revision of the JDL model (JDL II) to align with Department of Defense (DoD) priorities, improve quality control, reliability, and consistency, and empathize with the need for co-processing of inferencing processes was proposed in 2004 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib55" title="">55</a>]</cite>. Also in that year, due to the shortcomings of the model, mainly related to the lack of clarity of human participation and feedback, the DFIG model was created, adding two levels (Level 5 - User Refinement, Level 6 - Mission Management) to the JDL model [40].
However, other adaptations and updates were proposed to the JDL model during the following years, mainly focusing on the optimization and reliability of the model by proposing communication across the JDL levels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib56" title="">56</a>]</cite> or implementing different techniques such as game theory <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib58" title="">58</a>]</cite>, fuzzy logic <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib59" title="">59</a>]</cite>, ontologies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib60" title="">60</a>]</cite> and other mathematical modeling approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib63" title="">63</a>]</cite>. Other revisions focused on the fusion, impact, and communication between hard data (machine or environmental data) and soft data (human data). Changes in specific levels such as Levels 1 and 2 incorporating the human in the fusion and preprocessing levels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib64" title="">64</a>]</cite>, subsequently in Levels 4 and 5 through hybrid-sensing and hybrid-cognition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib65" title="">65</a>]</cite>, or even the incorporating a management network in parallel to the JDL model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib67" title="">67</a>]</cite> were proposed.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Finally, in response to the popularity and flexibility of new techniques impulsed by AI and ML, two papers proposed updates to the JDL and DFGI models. An adaptation of the JDL proposing using conversational agents to improve the human-machine interface at Level 5 (User Refinement) was proposed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib68" title="">68</a>]</cite>. Subsequently, an adaptation of the DFIG model to incorporate AI, ML, and DL techniques was also presented <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib50" title="">50</a>]</cite>. The study suggests using ML and DL techniques to model data from different Levels 2 and 3 modalities. The model also proposes using Active Learning (AL) to get human feedback in Levels 5 and 6 and Reinforcement Learning (RL) to improve the system in Level 4. This is the most up-to-date model and will be used as a reference for our proposed model.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">The proposed Data Fusion for Data Mining (DF-DM) model is a foundational process model for multimodal data fusion based on DFGI and CRISP-DM. The following sections will introduce the most up-to-date data fusion model (DFGI) with the adaptation for ML and AI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib50" title="">50</a>]</cite>, integrate the Cross-Industry Standard Process for Data Mining (CRISP-DM) process model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib69" title="">69</a>]</cite>, and present some modifications to implement foundation models and embeddings in the DFGI model. Finally we’ll provide three use cases to show the flexibility and adaptability of our model, as well as usability.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Current Data Fusion Model: DFGI Model</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The most up-to-date data fusion model is the one proposed by the DFIG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib49" title="">49</a>]</cite> and its AI and ML update <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib50" title="">50</a>]</cite>. This model comprises seven levels, from 0 to 6, that offer a comprehensive framework for data fusion while incorporating AI and ML techniques at different levels, as seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S2.F1" title="Figure 1 ‣ 2.1 Current Data Fusion Model: DFGI Model ‣ 2 Background ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">1</span></a>. To understand this model, let’s analyze each one of the levels with an example of data fusion in the healthcare domain:</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Level 0 - Data Assessment:</span> This level is primarily where data acquisition and preprocessing are. For example, this level can involve collecting various patient data, including electronic health records (EHRs), medical images, wearable device data, and lab reports and their preparation.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Level 1 - Object Assessment:</span> It centers on estimating the states of individual parameters and data types. AI and ML techniques are proposed at this level due to their role in predictive tasks such as classification and regression. At this level, the model estimates and predicts the states of individual health parameters, such as vital signs, medical conditions, and medication history. At this point, there is still no data fusion, only individual analysis of each modality/data source.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Level 2 - Situation Assessment:</span> At this stage, the model predicts relationships between entities. At this point, data from different modalities and/or sources is finally fused. An example is the measurement of the impact of medications on vital signs or the correlation between lab results and disease progression.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">Level 3 - Impact Assessment:</span> Level 3 estimates the effects of planned or estimated actions on situations. We can, for example, measure the impact of different medical interventions on the patient’s health. Performance evaluation techniques are used here.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">Level 4 - Process Refinement:</span> This level focuses on enhancing data collection and processing through adaptive data acquisition and processing. At this level, Reinforcement Learning is proposed to improve the model automatically. For example, sensor management can collect data from wearable devices to support real-time patient monitoring and intervention.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i6.p1">
<p class="ltx_p" id="S2.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i6.p1.1.1">Level 5 - User Refinement:</span> Level 5 involves adaptively determining who can access information, aiding in cognitive decision-making and actions, especially in human-computer interfaces. AL is proposed to introduce humans into the loop at this level. For example, it can support a clinician in making informed decisions by providing relevant patient diagnoses and predictions.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i7.p1">
<p class="ltx_p" id="S2.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i7.p1.1.1">Level 6 - Mission Management:</span> Level 6 focuses on the adaptive control of resources to support decision-making. The example involves the control of healthcare resources, such as hospital beds, operating rooms, and healthcare personnel.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="641" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>DFGI Data Fusion model proposed, including AI and ML from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib50" title="">50</a>]</cite>. The Levels where AI and ML techniques are proposed can be seen in red. The original DFGI model can be seen in blue.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>The Integration of the Cross-Industry Standard Process for Data Mining (CRISP-DM)</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">CRISP-DM was selected to support the DF-DM model because it is considered an industry standard process to guide machine learning and data mining projects <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib70" title="">70</a>]</cite>. The CRISP-DM model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib69" title="">69</a>]</cite> consists of 6 phases:</p>
<ol class="ltx_enumerate" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p" id="S2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">Business Understanding:</span> Define the problem, objectives, and constraints from a business perspective.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p" id="S2.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">Data Understanding:</span> Collect and explore the data, gaining insights into its quality and characteristics.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S2.I2.i3.p1">
<p class="ltx_p" id="S2.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i3.p1.1.1">Data Preparation:</span> Clean, transform, and preprocess the data to make it suitable for analysis.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S2.I2.i4.p1">
<p class="ltx_p" id="S2.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i4.p1.1.1">Modeling:</span> Select and apply appropriate predictive models.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S2.I2.i5.p1">
<p class="ltx_p" id="S2.I2.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i5.p1.1.1">Evaluation:</span> Assess the model’s performance and its alignment with business goals.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="S2.I2.i6.p1">
<p class="ltx_p" id="S2.I2.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i6.p1.1.1">Deployment:</span> Integrate the model into the business process and create a plan for monitoring and maintenance.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">One of the greatest advantages of the CRISP-DM model is its flexibility, given that it is not a cascade model. The model allows previous phases to be revisited, thus avoiding the loss of time and resources by having to complete an entire cycle to return to a previous phase. The efficacy and flexibility of CRISP-DM has been shown even in medical settings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib71" title="">71</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib72" title="">72</a>]</cite>.
Although the DFGI and CRISP-DM models were developed for different purposes, the DFGI model has remained stuck in an architecture that is still too old for cutting-edge technologies such as ML and DL techniques.
Below, we describe some of the shortcomings of the DFGI model and how they can be addressed by taking components from the CRISP-DM model.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<ul class="ltx_itemize" id="S2.I3">
<li class="ltx_item" id="S2.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i1.p1">
<p class="ltx_p" id="S2.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I3.i1.p1.1.1">A closed loop model:</span> One of the areas for improvement in the DFGI model is the need for more opportunities to revisit the immediately preceding level (this relationship only occurs between Levels 3 and 5). This makes it impossible to act quickly on problems presented in the initial levels, such as 0 or 1. This implies a very large loss of resources and time.</p>
</div>
</li>
<li class="ltx_item" id="S2.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i2.p1">
<p class="ltx_p" id="S2.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I3.i2.p1.1.1">Do we understand the data?:</span> One of the most important phases of the CRISP-DM model is understanding the data because it is the primary source of information. If the data is not good enough, no matter how powerful our model is, more is needed. Understanding the nature and quality of multimodal data is important.</p>
</div>
</li>
<li class="ltx_item" id="S2.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i3.p1">
<p class="ltx_p" id="S2.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I3.i3.p1.1.1">Do we understand the problem?:</span> A missing aspect in the DFGI model is business understanding. The business understanding phase should be an important feature for all the levels of the DFIG model.</p>
</div>
</li>
<li class="ltx_item" id="S2.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i4.p1">
<p class="ltx_p" id="S2.I3.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I3.i4.p1.1.1">Correlation or Causality:</span> At Level 3, we propose to use ML techniques to measure impact. Although traditional ML and/or DL techniques can be effective in many situations, to measure the impact, the integration of a causal analysis is proposed to avoid bias.</p>
</div>
</li>
<li class="ltx_item" id="S2.I3.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i5.p1">
<p class="ltx_p" id="S2.I3.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I3.i5.p1.1.1">Many modalities, many costs:</span> The use of multimodal data, although one of the most efficient ways to integrate and take advantage of data, also becomes very expensive when discussing high-dimensional data such as text or images. Given this, we propose using newer techniques and models for dimensionality reduction, such as extracting embeddings from foundation models or using foundation models directly for zero-shot learning tasks.</p>
</div>
</li>
<li class="ltx_item" id="S2.I3.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I3.i6.p1">
<p class="ltx_p" id="S2.I3.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I3.i6.p1.1.1">Reinforcement Learning:</span> Although Reinforcement Learning is an effective proposal with many applications, it is only effective in military and industrial environments where rapid simulations or experiments can be performed. However, the use of Reinforcement Learning in environments such as health sciences is a method that takes more time and resources, making it impractical.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In the era of AI-driven analytics, the integration of data mining and data fusion stands as a paramount challenge, primarily due to the heterogeneity of data and the constraints of computational resources. To address these challenges, we introduce an innovative methodology within our Data Fusion for Data Mining (DF-DM) model (Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.F2" title="Figure 2 ‣ 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">2</span></a>), which extends the existing DFGI model by integrating the model with the best practices of the CRISP-DM process model. Additionally our model leverages the use of foundation models and vector embeddings simplifies the processing of diverse data types but also significantly reduces the computational overhead, making advanced data analytics more accessible and efficient.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="641" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The proposed Data Fusion for Data Mining Model (DF-DM). The model is based on the DFGI model, integrating AI and ML but adding other functionalities vital for data mining tasks in orange. </figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The rationale behind the DF-DM model’s design is twofold. Firstly, by incorporating the CRISP-DM process, we aim to adhere to a proven, structured approach for data mining that emphasizes business understanding, data understanding, bias, and a cyclical process for model refinement. This ensures that our model is not only technically sound but also closely aligned with practical, real-world applications. Secondly, the decision to utilize embeddings and foundation models stems from their ability to reduce high-dimensional data into more manageable, lower-dimensional vectors. This significantly alleviates computational demands and facilitates more effective integration of diverse data types, crucial for addressing the complex challenges of multimodal data fusion in healthcare and beyond.
Before delving into the methodology, it is pertinent to clarify two pivotal concepts:</p>
</div>
<div class="ltx_para" id="S3.p3">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">foundation models:</span> foundation models are at the heart of our methodology. These are extensive, pre-trained models that have been developed to capture a wide array of features across specific data modalities, such as text or images. By understanding the general characteristics inherent to each modality, these models can generate useful representations of new, unseen data. This ability is crucial for extracting relevant features without necessitating additional, computationally expensive training phases for each new dataset.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.8"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.8.1">Embeddings:</span> Embeddings are also a pivotal role in our methodology, transforming high-dimensional data into a more manageable, lower-dimensional space. Formally, given an input data point <math alttext="x\in\mathbb{R}^{n}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml">x</mi><mo id="S3.I1.i2.p1.1.m1.1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.3.2" xref="S3.I1.i2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S3.I1.i2.p1.1.m1.1.1.3.3" xref="S3.I1.i2.p1.1.m1.1.1.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><in id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.1"></in><ci id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">𝑥</ci><apply id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.2">ℝ</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">x\in\mathbb{R}^{n}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="n" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">italic_n</annotation></semantics></math> is the dimensionality of the raw data in a high-dimensional space. We seek to find its embedding <math alttext="E\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.1"><semantics id="S3.I1.i2.p1.3.m3.1a"><mrow id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.2" xref="S3.I1.i2.p1.3.m3.1.1.2.cmml">E</mi><mo id="S3.I1.i2.p1.3.m3.1.1.1" xref="S3.I1.i2.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S3.I1.i2.p1.3.m3.1.1.3" xref="S3.I1.i2.p1.3.m3.1.1.3.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.3.2" xref="S3.I1.i2.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S3.I1.i2.p1.3.m3.1.1.3.3" xref="S3.I1.i2.p1.3.m3.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><apply id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1"><in id="S3.I1.i2.p1.3.m3.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1"></in><ci id="S3.I1.i2.p1.3.m3.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.2">𝐸</ci><apply id="S3.I1.i2.p1.3.m3.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i2.p1.3.m3.1.1.3.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.I1.i2.p1.3.m3.1.1.3.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3.2">ℝ</ci><ci id="S3.I1.i2.p1.3.m3.1.1.3.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">E\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.1d">italic_E ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> in a d-dimensional vector space where <math alttext="d" class="ltx_Math" display="inline" id="S3.I1.i2.p1.4.m4.1"><semantics id="S3.I1.i2.p1.4.m4.1a"><mi id="S3.I1.i2.p1.4.m4.1.1" xref="S3.I1.i2.p1.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.4.m4.1b"><ci id="S3.I1.i2.p1.4.m4.1.1.cmml" xref="S3.I1.i2.p1.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.4.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.4.m4.1d">italic_d</annotation></semantics></math> is the dimension of the embedding vector and <math alttext="d&lt;&lt;n" class="ltx_Math" display="inline" id="S3.I1.i2.p1.5.m5.1"><semantics id="S3.I1.i2.p1.5.m5.1a"><mrow id="S3.I1.i2.p1.5.m5.1.1" xref="S3.I1.i2.p1.5.m5.1.1.cmml"><mi id="S3.I1.i2.p1.5.m5.1.1.2" xref="S3.I1.i2.p1.5.m5.1.1.2.cmml">d</mi><mo id="S3.I1.i2.p1.5.m5.1.1.1" xref="S3.I1.i2.p1.5.m5.1.1.1.cmml">&lt;&lt;</mo><mi id="S3.I1.i2.p1.5.m5.1.1.3" xref="S3.I1.i2.p1.5.m5.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.5.m5.1b"><apply id="S3.I1.i2.p1.5.m5.1.1.cmml" xref="S3.I1.i2.p1.5.m5.1.1"><csymbol cd="latexml" id="S3.I1.i2.p1.5.m5.1.1.1.cmml" xref="S3.I1.i2.p1.5.m5.1.1.1">much-less-than</csymbol><ci id="S3.I1.i2.p1.5.m5.1.1.2.cmml" xref="S3.I1.i2.p1.5.m5.1.1.2">𝑑</ci><ci id="S3.I1.i2.p1.5.m5.1.1.3.cmml" xref="S3.I1.i2.p1.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.5.m5.1c">d&lt;&lt;n</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.5.m5.1d">italic_d &lt; &lt; italic_n</annotation></semantics></math>. The embedding is generated given the transformation <math alttext="E=f(x)" class="ltx_Math" display="inline" id="S3.I1.i2.p1.6.m6.1"><semantics id="S3.I1.i2.p1.6.m6.1a"><mrow id="S3.I1.i2.p1.6.m6.1.2" xref="S3.I1.i2.p1.6.m6.1.2.cmml"><mi id="S3.I1.i2.p1.6.m6.1.2.2" xref="S3.I1.i2.p1.6.m6.1.2.2.cmml">E</mi><mo id="S3.I1.i2.p1.6.m6.1.2.1" xref="S3.I1.i2.p1.6.m6.1.2.1.cmml">=</mo><mrow id="S3.I1.i2.p1.6.m6.1.2.3" xref="S3.I1.i2.p1.6.m6.1.2.3.cmml"><mi id="S3.I1.i2.p1.6.m6.1.2.3.2" xref="S3.I1.i2.p1.6.m6.1.2.3.2.cmml">f</mi><mo id="S3.I1.i2.p1.6.m6.1.2.3.1" xref="S3.I1.i2.p1.6.m6.1.2.3.1.cmml">⁢</mo><mrow id="S3.I1.i2.p1.6.m6.1.2.3.3.2" xref="S3.I1.i2.p1.6.m6.1.2.3.cmml"><mo id="S3.I1.i2.p1.6.m6.1.2.3.3.2.1" stretchy="false" xref="S3.I1.i2.p1.6.m6.1.2.3.cmml">(</mo><mi id="S3.I1.i2.p1.6.m6.1.1" xref="S3.I1.i2.p1.6.m6.1.1.cmml">x</mi><mo id="S3.I1.i2.p1.6.m6.1.2.3.3.2.2" stretchy="false" xref="S3.I1.i2.p1.6.m6.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.6.m6.1b"><apply id="S3.I1.i2.p1.6.m6.1.2.cmml" xref="S3.I1.i2.p1.6.m6.1.2"><eq id="S3.I1.i2.p1.6.m6.1.2.1.cmml" xref="S3.I1.i2.p1.6.m6.1.2.1"></eq><ci id="S3.I1.i2.p1.6.m6.1.2.2.cmml" xref="S3.I1.i2.p1.6.m6.1.2.2">𝐸</ci><apply id="S3.I1.i2.p1.6.m6.1.2.3.cmml" xref="S3.I1.i2.p1.6.m6.1.2.3"><times id="S3.I1.i2.p1.6.m6.1.2.3.1.cmml" xref="S3.I1.i2.p1.6.m6.1.2.3.1"></times><ci id="S3.I1.i2.p1.6.m6.1.2.3.2.cmml" xref="S3.I1.i2.p1.6.m6.1.2.3.2">𝑓</ci><ci id="S3.I1.i2.p1.6.m6.1.1.cmml" xref="S3.I1.i2.p1.6.m6.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.6.m6.1c">E=f(x)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.6.m6.1d">italic_E = italic_f ( italic_x )</annotation></semantics></math>, where <math alttext="f" class="ltx_Math" display="inline" id="S3.I1.i2.p1.7.m7.1"><semantics id="S3.I1.i2.p1.7.m7.1a"><mi id="S3.I1.i2.p1.7.m7.1.1" xref="S3.I1.i2.p1.7.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.7.m7.1b"><ci id="S3.I1.i2.p1.7.m7.1.1.cmml" xref="S3.I1.i2.p1.7.m7.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.7.m7.1c">f</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.7.m7.1d">italic_f</annotation></semantics></math> denotes the transformation function derived from the foundation model. This process significantly reduces dimensionality, with <math alttext="d&lt;&lt;dim(X)" class="ltx_Math" display="inline" id="S3.I1.i2.p1.8.m8.1"><semantics id="S3.I1.i2.p1.8.m8.1a"><mrow id="S3.I1.i2.p1.8.m8.1.2" xref="S3.I1.i2.p1.8.m8.1.2.cmml"><mi id="S3.I1.i2.p1.8.m8.1.2.2" xref="S3.I1.i2.p1.8.m8.1.2.2.cmml">d</mi><mo id="S3.I1.i2.p1.8.m8.1.2.1" xref="S3.I1.i2.p1.8.m8.1.2.1.cmml">&lt;&lt;</mo><mrow id="S3.I1.i2.p1.8.m8.1.2.3" xref="S3.I1.i2.p1.8.m8.1.2.3.cmml"><mi id="S3.I1.i2.p1.8.m8.1.2.3.2" xref="S3.I1.i2.p1.8.m8.1.2.3.2.cmml">d</mi><mo id="S3.I1.i2.p1.8.m8.1.2.3.1" xref="S3.I1.i2.p1.8.m8.1.2.3.1.cmml">⁢</mo><mi id="S3.I1.i2.p1.8.m8.1.2.3.3" xref="S3.I1.i2.p1.8.m8.1.2.3.3.cmml">i</mi><mo id="S3.I1.i2.p1.8.m8.1.2.3.1a" xref="S3.I1.i2.p1.8.m8.1.2.3.1.cmml">⁢</mo><mi id="S3.I1.i2.p1.8.m8.1.2.3.4" xref="S3.I1.i2.p1.8.m8.1.2.3.4.cmml">m</mi><mo id="S3.I1.i2.p1.8.m8.1.2.3.1b" xref="S3.I1.i2.p1.8.m8.1.2.3.1.cmml">⁢</mo><mrow id="S3.I1.i2.p1.8.m8.1.2.3.5.2" xref="S3.I1.i2.p1.8.m8.1.2.3.cmml"><mo id="S3.I1.i2.p1.8.m8.1.2.3.5.2.1" stretchy="false" xref="S3.I1.i2.p1.8.m8.1.2.3.cmml">(</mo><mi id="S3.I1.i2.p1.8.m8.1.1" xref="S3.I1.i2.p1.8.m8.1.1.cmml">X</mi><mo id="S3.I1.i2.p1.8.m8.1.2.3.5.2.2" stretchy="false" xref="S3.I1.i2.p1.8.m8.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.8.m8.1b"><apply id="S3.I1.i2.p1.8.m8.1.2.cmml" xref="S3.I1.i2.p1.8.m8.1.2"><csymbol cd="latexml" id="S3.I1.i2.p1.8.m8.1.2.1.cmml" xref="S3.I1.i2.p1.8.m8.1.2.1">much-less-than</csymbol><ci id="S3.I1.i2.p1.8.m8.1.2.2.cmml" xref="S3.I1.i2.p1.8.m8.1.2.2">𝑑</ci><apply id="S3.I1.i2.p1.8.m8.1.2.3.cmml" xref="S3.I1.i2.p1.8.m8.1.2.3"><times id="S3.I1.i2.p1.8.m8.1.2.3.1.cmml" xref="S3.I1.i2.p1.8.m8.1.2.3.1"></times><ci id="S3.I1.i2.p1.8.m8.1.2.3.2.cmml" xref="S3.I1.i2.p1.8.m8.1.2.3.2">𝑑</ci><ci id="S3.I1.i2.p1.8.m8.1.2.3.3.cmml" xref="S3.I1.i2.p1.8.m8.1.2.3.3">𝑖</ci><ci id="S3.I1.i2.p1.8.m8.1.2.3.4.cmml" xref="S3.I1.i2.p1.8.m8.1.2.3.4">𝑚</ci><ci id="S3.I1.i2.p1.8.m8.1.1.cmml" xref="S3.I1.i2.p1.8.m8.1.1">𝑋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.8.m8.1c">d&lt;&lt;dim(X)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.8.m8.1d">italic_d &lt; &lt; italic_d italic_i italic_m ( italic_X )</annotation></semantics></math>, facilitating more efficient data analysis.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">The proposed model introduces changes to improve the efficiency of the current DFGI model while making the model more reliable and presenting the most recent AI techniques. The Levels offered in the DF-DM model are:</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Level 0 - Data Assessment:</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">This is the lowest level of the model DF-DM. This level consists of 2 steps:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">Data Understanding:</span> In this step, visualization and assessment of the data quality are essential to creating clear and informative data representations. This section involves selecting appropriate visualization techniques that best convey the patterns and relationships in the data. Pay attention to labeling, scaling, and color choices to ensure the visualizations are easily interpreted. Missing data measures and descriptive statistics are also important.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">Data preprocessing:</span> Data preprocessing involves cleaning, transformation, normalization, encoding, reduction, and formatting, making it a critical step in the overall DF-DM model. In this step, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.F3" title="Figure 3 ‣ 3.8 Level 7 - Bias Assessment ‣ 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">3</span></a>, using embeddings and foundation models is crucial for generating latent representations and extracting meaningful information from high-dimensional data such as images or text. Techniques such as zero-shot learning or embedding extraction are the key elements in this approach to extract features in low-resource settings. This approach significantly reduces computational costs and storage requirements and creates a unified format that facilitates multimodal data fusion.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">To facilitate direct communication with Level 5 - User Refinement, we implement a bi-directional interface allowing for real-time feedback and adjustments. This interface could take the form of an interactive dashboard where users can flag issues or suggest refinements, thus enabling a dynamic and responsive system.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">This section also includes direct communication with the Level 5 - User Refinement. It allows human users to communicate through a user interface from this initial level, enabling fast error detection in the earliest stages and providing a comprehensive pipeline. For example, if we receive patient data, such as electronic health records (EHRs), medical images, and lab reports. At this stage, we can present information such as keywords or alerts of abnormal values to the clinician. We can also generate text embeddings from the clinical notes in the EHRs, for example, using Llama 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib36" title="">36</a>]</cite> and image embeddings of the medical image using DINO V2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib35" title="">35</a>]</cite>. The embeddings are vector representations that store all the information and the tabular data in a CSV file.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Level 1 - Object Assessment</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In Level 1, since the data received from Level 0 are embeddings or features extracted from the foundation models, the data is already in a lower dimensionality and a common format, facilitating different ML and AI techniques. As seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S3.F3" title="Figure 3 ‣ 3.8 Level 7 - Bias Assessment ‣ 3 Integrating Data Mining and Data Fusion in the AI era by Introducing the Fusion Model for Data Mining DF-DM ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">3</span></a>, Option 2, using embeddings, reduces the complexity and dimensionality of the data, making it easy and inexpensive to do the ML modeling because we can use simple models such as linear models. The data resulting from embedding extraction is methodically divided based on data modality (e.g., text, images). This separation enables targeted model training for each data type, enhancing specificity and accuracy. Integration of these segmented models is achieved through a comprehensive analysis framework, allowing for nuanced insights across modalities. For example, using the data from Level 0 in a CSV format due to the embedding extraction, the CSV file can be split for each modality to train a predictive model per modality. ML models can be trained to separately measure the impact of clinical notes, medical images, and tabular data in a given condition.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Level 2 - Situation Assessment</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In this level, the modalities can be used to model complex relations across multiple modalities. The outputs of the modalities created in Level 1 can be aggregated in a late fusion approach, or all the features in the CSV file from Level 0 can be concatenated to train a single ML model using an early fusion approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib73" title="">73</a>]</cite>. The choice between late and early fusion approaches is guided by the specific objectives and the nature of the data. Early fusion is preferred when a unified model of all modalities can provide deeper insights, while late fusion is selected for preserving modality-specific characteristics until the final aggregation stage. For example, using the CSV generated in Level 0 with all the modalities as input of a single ML model will measure the influence of all the modalities together over a specific medical condition.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Level 3 - Impact Assessment</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In Level 3, the effect of specific actions or situations in the data is planned and/or estimated. Causal inference can be used to estimate the effect of a particular feature. In this level, for example, causal inference can be used to estimate the effect of a change in a variable, a medication, over a specific outcome.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Level 4 - Process Refinement</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">This level controls the data retrieval, preprocessing, and analysis strategies based on techniques such as adaptive data acquisition. Adaptive data acquisition is informed by ongoing assessments of data source effectiveness and feedback from Level 5. This includes a systematic evaluation of data quality and relevance, with less valuable sources being phased out or replaced to optimize the data fusion process. At this level, it is important to understand the problem and the business objectives from Level 6 to improve the use of the data, data analysis techniques, and outputs of the data fusion process. At this level, an evaluation of the business understanding and business objectives is performed. For example, Level 5 informs that a data source is generating a lot of noise and wrong measurements, and then Level 4 decides to stop using that variable as part of the data fusion process. This adaptive approach ensures that the data used in the subsequent stages aligns with the desired precision and reliability, contributing to a more effective overall data fusion process.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Level 5 - User Refinement</h3>
<div class="ltx_para" id="S3.SS6.p1">
<p class="ltx_p" id="S3.SS6.p1.1">In this model, the User Refinement is the connection between all the machine levels (0-3) and humans. At this level, specific actions to improve the system can be applied. Here, we communicate with low and high levels to access information and control in each phase. Integration of human insights is facilitated through mechanisms such as feedback loops and supervised learning adjustments, where user inputs directly influence model refinement and data processing strategies. AL is proposed to introduce humans into the machine-learning loop. For example, the data from Level 0 with visualization and statistics can support information to the clinician about which modalities to use or which outcome should be analyzed in Level 2 or 3, making the system more dynamic and robust.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Level 6 - Mission Management</h3>
<div class="ltx_para" id="S3.SS7.p1">
<p class="ltx_p" id="S3.SS7.p1.1">Level 6 focuses on business objectives and business understanding. At this level, we define the main goals of the business and expected outcomes for decision-making. For example, this level involves selecting the specific healthcare workers and sensors that will be used to measure patient data.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.8 </span>Level 7 - Bias Assessment</h3>
<div class="ltx_para" id="S3.SS8.p1">
<p class="ltx_p" id="S3.SS8.p1.1">Bias assessment should influence all the levels of the DF-DM model. Including a dedicated level for Bias Assessment (Level 7) is crucial to address and mitigate potential biases in the multimodal data fusion process. Due to its importance, this level will be explained in a separate section.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="901" id="S3.F3.g1" src="x3.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustrative Framework for Utilizing foundation models in Various Tasks. The figure assumes an initial foundation model for a general task and 3 different options. Option 1 is Zero-shot learning using the foundation model directly for a downstream task. Option 2 suggests the use of embedding, where embeddings of the original data are extracted and used for downstream task training. Option 3 means fine-tuning the full model for a specific task. The resulting model can also be used for embedding extraction.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Addressing Bias in the DF-DM Model</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">While the proposed Data Fusion for Data Mining (DF-DM) model offers significant advantages for multimodal data fusion, it is not immune to the challenges related to bias, which can be present at every level of the data fusion process. As proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib74" title="">74</a>]</cite>, bias can manifest in various forms, such as data bias, model bias, or decision-making bias, and it is essential to address these concerns to ensure the reliability and fairness of the model’s outcomes.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data Bias</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Data bias can arise from imbalanced datasets or the underrepresentation of certain groups, leading to biased predictions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib77" title="">77</a>]</cite>. In healthcare, for example, if the training data predominantly represents a specific demographic group, the model may not perform equally well for other groups. To address data bias in the DF-DM model, we propose the following strategies:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Data Collection and Sampling:</span> Ensure that the data collected for the model is diverse and representative of the target population. Stratified sampling techniques can be used to balance data from different groups.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Bias Detection:</span> Implement bias detection techniques at different levels of the model to identify and measure bias. Methods like fairness audits and bias indicators should be designed and implemented.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Data Preprocessing:</span> Apply preprocessing techniques to mitigate bias, such as re-sampling to ensure fair representation.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model Bias</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Model bias can occur when the model’s architecture or training data introduces inherent bias. For example, if the foundation models used for embedding extraction have been trained on biased datasets, this bias can propagate into the DF-DM model. To address model bias, we suggest considering the following:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Bias Analysis of foundation models:</span> Before embedding extraction, thoroughly analyze the foundation models to identify and mitigate potential bias. Analyze the current model available and the best option for your use case. Characteristics of the foundation models, such as the source of training data, the original objective of the model, training method, and evaluation metrics, among other characteristics, must be analyzed when choosing the model.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Causal Inference:</span> DL approaches are not always enough in all cases. Causal inference, or linear methods as predictive methods, should be used to allow interpretability of the results and relations in the data.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Decision-Making Bias</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Bias can also emerge in decision-making, especially when human experts are involved. Human decision-makers may unintentionally (or intentionally) introduce bias based on their personal perspectives<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib78" title="">78</a>]</cite>. To mitigate decision-making bias, we suggest:</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i1.p1.1.1">Bias Awareness Training:</span> Train human decision-makers involved in the process to make them aware of potential biases and encourage fair and objective decision-making.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I3.i2.p1.1.1">Introduce Audits or Peer Review:</span> Introduce more than one human in the loop. Having more perspectives helps to have a controlled environment and improves transparency and information sharing.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS3.p2.1">We aim to promote fairness, equity, and reliability in multimodal data fusion by addressing these aspects of bias in the DF-DM model. The biases mentioned in this section are not the only types of bias that exist, and each type of bias must be examined independently depending on the case study. We recognize that bias is an ongoing challenge and an active area of research that is nearly impossible to eliminate but should be mitigated.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Use Cases</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">To showcase the usefulness of our DF-DM model, we provide three case studies of multimodal data fusion using in three healthcare applications:</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Use case 1: Diabetic Retinopathy</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">In this use case, we apply the DF-DM model to predict Diabetic Retinopathy (DR) using the open Brazilian ophthalmological dataset (BRSET)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib79" title="">79</a>]</cite> leveraging a multimodal approach. BRSET consists of 16,266 fundus images of 8,524 patients, each image, along with demographic and clinical metadata. This section details the exploratory data analysis, preprocessing steps, modality-specific models, the fusion model, and the evaluation of the model’s performance and potential bias and limitations.
To assess diabetic retinopathy classification tasks, a 5-class grouping according to the International Clinic Diabetic Retinopathy (ICDR) classification was conducted. To distinguish between cases requiring closer ophthalmological care, these were grouped into three classes: no diabetic retinopathy, non-proliferative, and proliferative. A division was made into two classes for detecting normal and abnormal classes, indicating the presence or absence of diabetic retinopathy.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Exploratory Data Analysis and Preprocessing</h4>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">The first phase of this use case involved an exploratory data analysis (EDA) of a dataset comprising 16,266 images from Brazilian patients. The EDA focused on assessing the dataset’s quality, identifying potential biases, and analyzing the distribution of variables such as gender and age. Key findings include a higher prevalence of female patients (62%), a significant number of images with missing age data (34%), and a high imbalance in the county variable, where 100% of the population in the dataset is from Brazil. The diabetic retinopathy variable presents 5 classes based on the International Clinic Diabetic Retinopathy (ICDR) schema <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib80" title="">80</a>]</cite>. It is also highly unbalanced, presenting: 15,210 patients with ICDR 0 (94 %), 162 patients with ICDR 1 (1%), 310 patients with ICDR 2 (2%), 190 patients with ICDR 3 (1%), and 394 patients with ICDR 4 (2%).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Preprocessing</h4>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">The preprocessing phase was multifaceted:</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Image Data: Vector embeddings were extracted from images using the Dino V2-Large model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib35" title="">35</a>]</cite>, a foundation computer vision model, and stored in a CSV file alongside image IDs.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.2">Labels: The dataset’s diabetic retinopathy classifications, were restructured into three classification tasks for the analysis given the imbalance: the original 5-class grouping, a 3-class grouping (normal (ICDR score of 0), non-proliferative (ICDR score between 1 and 3), and proliferative (<math alttext="ICDRscore=1" class="ltx_Math" display="inline" id="S5.I1.i2.p1.1.m1.1"><semantics id="S5.I1.i2.p1.1.m1.1a"><mrow id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml"><mrow id="S5.I1.i2.p1.1.m1.1.1.2" xref="S5.I1.i2.p1.1.m1.1.1.2.cmml"><mi id="S5.I1.i2.p1.1.m1.1.1.2.2" xref="S5.I1.i2.p1.1.m1.1.1.2.2.cmml">I</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.3" xref="S5.I1.i2.p1.1.m1.1.1.2.3.cmml">C</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1a" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.4" xref="S5.I1.i2.p1.1.m1.1.1.2.4.cmml">D</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1b" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.5" xref="S5.I1.i2.p1.1.m1.1.1.2.5.cmml">R</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1c" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.6" xref="S5.I1.i2.p1.1.m1.1.1.2.6.cmml">s</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1d" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.7" xref="S5.I1.i2.p1.1.m1.1.1.2.7.cmml">c</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1e" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.8" xref="S5.I1.i2.p1.1.m1.1.1.2.8.cmml">o</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1f" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.9" xref="S5.I1.i2.p1.1.m1.1.1.2.9.cmml">r</mi><mo id="S5.I1.i2.p1.1.m1.1.1.2.1g" xref="S5.I1.i2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.1.m1.1.1.2.10" xref="S5.I1.i2.p1.1.m1.1.1.2.10.cmml">e</mi></mrow><mo id="S5.I1.i2.p1.1.m1.1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S5.I1.i2.p1.1.m1.1.1.3" xref="S5.I1.i2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b"><apply id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1"><eq id="S5.I1.i2.p1.1.m1.1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1.1"></eq><apply id="S5.I1.i2.p1.1.m1.1.1.2.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2"><times id="S5.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.1"></times><ci id="S5.I1.i2.p1.1.m1.1.1.2.2.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.2">𝐼</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.3.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.3">𝐶</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.4.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.4">𝐷</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.5.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.5">𝑅</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.6.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.6">𝑠</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.7.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.7">𝑐</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.8.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.8">𝑜</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.9.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.9">𝑟</ci><ci id="S5.I1.i2.p1.1.m1.1.1.2.10.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2.10">𝑒</ci></apply><cn id="S5.I1.i2.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.I1.i2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">ICDRscore=1</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i2.p1.1.m1.1d">italic_I italic_C italic_D italic_R italic_s italic_c italic_o italic_r italic_e = 1</annotation></semantics></math>), and a binary classification (normal vs. diabetic retinopathy (<math alttext="ICDRscore\geq 1" class="ltx_Math" display="inline" id="S5.I1.i2.p1.2.m2.1"><semantics id="S5.I1.i2.p1.2.m2.1a"><mrow id="S5.I1.i2.p1.2.m2.1.1" xref="S5.I1.i2.p1.2.m2.1.1.cmml"><mrow id="S5.I1.i2.p1.2.m2.1.1.2" xref="S5.I1.i2.p1.2.m2.1.1.2.cmml"><mi id="S5.I1.i2.p1.2.m2.1.1.2.2" xref="S5.I1.i2.p1.2.m2.1.1.2.2.cmml">I</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.3" xref="S5.I1.i2.p1.2.m2.1.1.2.3.cmml">C</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1a" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.4" xref="S5.I1.i2.p1.2.m2.1.1.2.4.cmml">D</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1b" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.5" xref="S5.I1.i2.p1.2.m2.1.1.2.5.cmml">R</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1c" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.6" xref="S5.I1.i2.p1.2.m2.1.1.2.6.cmml">s</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1d" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.7" xref="S5.I1.i2.p1.2.m2.1.1.2.7.cmml">c</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1e" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.8" xref="S5.I1.i2.p1.2.m2.1.1.2.8.cmml">o</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1f" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.9" xref="S5.I1.i2.p1.2.m2.1.1.2.9.cmml">r</mi><mo id="S5.I1.i2.p1.2.m2.1.1.2.1g" xref="S5.I1.i2.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S5.I1.i2.p1.2.m2.1.1.2.10" xref="S5.I1.i2.p1.2.m2.1.1.2.10.cmml">e</mi></mrow><mo id="S5.I1.i2.p1.2.m2.1.1.1" xref="S5.I1.i2.p1.2.m2.1.1.1.cmml">≥</mo><mn id="S5.I1.i2.p1.2.m2.1.1.3" xref="S5.I1.i2.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.2.m2.1b"><apply id="S5.I1.i2.p1.2.m2.1.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1"><geq id="S5.I1.i2.p1.2.m2.1.1.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1.1"></geq><apply id="S5.I1.i2.p1.2.m2.1.1.2.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2"><times id="S5.I1.i2.p1.2.m2.1.1.2.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.1"></times><ci id="S5.I1.i2.p1.2.m2.1.1.2.2.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.2">𝐼</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.3.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.3">𝐶</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.4.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.4">𝐷</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.5.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.5">𝑅</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.6.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.6">𝑠</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.7.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.7">𝑐</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.8.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.8">𝑜</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.9.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.9">𝑟</ci><ci id="S5.I1.i2.p1.2.m2.1.1.2.10.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2.10">𝑒</ci></apply><cn id="S5.I1.i2.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.I1.i2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.2.m2.1c">ICDRscore\geq 1</annotation><annotation encoding="application/x-llamapun" id="S5.I1.i2.p1.2.m2.1d">italic_I italic_C italic_D italic_R italic_s italic_c italic_o italic_r italic_e ≥ 1</annotation></semantics></math>)).</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Metadata: Variables with over 40% missing data and variables that can introduce data leakage were dropped. Categorical variables were transformed into a one-hot encoding format. A decision tree classifier was employed to select relevant features, followed by cost complexity pruning. Variables with non-zero feature importance were retained for further analysis (as detailed in Table 1).</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Metadata Features Selected for Prediction Tasks</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.1">Feature</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1.2">Description</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.2.1.1">macula</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S5.T1.1.2.1.2">Macula status (1 for normal and 2 for abnormal)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.2">
<td class="ltx_td ltx_align_left" id="S5.T1.1.3.2.1">diabetes</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.3.2.2">Indicator for self-reported diabetes mellitus (1 for yes and 0 for no)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.3">
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.3.1">patient_age</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.4.3.2">Age of the patient in years</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.4">
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.4.1">drusens</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.5.4.2">Presence of drusens (1 for present and 0 for absent)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.6.5">
<td class="ltx_td ltx_align_left" id="S5.T1.1.6.5.1">macular_edema</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.6.5.2">Presence of macular edema (1 for present and 0 for absent)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.7.6">
<td class="ltx_td ltx_align_left" id="S5.T1.1.7.6.1">vessels</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.7.6.2">Vessel status (1 for normal and 2 for abnormal)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.8.7">
<td class="ltx_td ltx_align_left" id="S5.T1.1.8.7.1">camera_Canon CR</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.8.7.2">Indicator for Canon Retinal Camera (1 for yes and 0 for no)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.9.8">
<td class="ltx_td ltx_align_left" id="S5.T1.1.9.8.1">myopic_fundus</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.9.8.2">Presence of myopic fundus (1 for present and 0 for absent)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.10.9">
<td class="ltx_td ltx_align_left" id="S5.T1.1.10.9.1">camera_NIKON NF5050</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.10.9.2">Indicator for Nikon Retinal Camera (1 for yes and 0 for no)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.11.10">
<td class="ltx_td ltx_align_left" id="S5.T1.1.11.10.1">focus</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.11.10.2">Focus status (1 for normal and 2 for abnormal)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.12.11">
<td class="ltx_td ltx_align_left" id="S5.T1.1.12.11.1">other</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.12.11.2">Presence of other abnormalities (1 for present and 0 for absent)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.13.12">
<td class="ltx_td ltx_align_left" id="S5.T1.1.13.12.1">amd</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.13.12.2">Presence of age-related macular degeneration (1 for present and 0 for absent)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.14.13">
<td class="ltx_td ltx_align_left" id="S5.T1.1.14.13.1">patient_sex</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.14.13.2">Gender of the patient (1 for male and 2 for female)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.15.14">
<td class="ltx_td ltx_align_left" id="S5.T1.1.15.14.1">scar</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S5.T1.1.15.14.2">Presence of scars (1 for present and 0 for absent)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.16.15">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.16.15.1">vascular_occlusion</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S5.T1.1.16.15.2">Presence of vascular occlusion (1 for present and 0 for absent)</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Disentangled Dense Fusion</h4>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="358" id="S5.F4.g1" src="x4.png" width="997"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Disentangled dense data fusion model for classification tasks.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.SSS3.p1">
<p class="ltx_p" id="S5.SS1.SSS3.p1.17">A significant challenge in fusing information from different types of data, like images and text, is determining how to efficiently combine the overlapping yet critical information that both share, known as the ”inter-modal redundancy” issue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib81" title="">81</a>]</cite>. This overlap often contains duplicate data that can make it harder to extract useful insights because each type of data (or modality) has its own ratio of useful information to noise <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib81" title="">81</a>]</cite>. By separating out the unique factors, we can improve the quality of the features we use for analysis while removing unnecessary data. To achieve this, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.F4" title="Figure 4 ‣ 5.1.3 Disentangled Dense Fusion ‣ 5.1 Use case 1: Diabetic Retinopathy ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">4</span></a>, we utilize a disentangled transformer architecture to decouple the shared and specific representations, eliminating the redundant information and facilitating the fusion model learning. We hope to decompose entangled multimodal data into ideally independent modality-common features <math alttext="S_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.1.m1.1"><semantics id="S5.SS1.SSS3.p1.1.m1.1a"><msub id="S5.SS1.SSS3.p1.1.m1.1.1" xref="S5.SS1.SSS3.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS3.p1.1.m1.1.1.2" xref="S5.SS1.SSS3.p1.1.m1.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.1.m1.1.1.3" xref="S5.SS1.SSS3.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.1.m1.1b"><apply id="S5.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.1.m1.1.1.3.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.1.m1.1c">S_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.1.m1.1d">italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> and modality-specific features <math alttext="S_{a}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.2.m2.1"><semantics id="S5.SS1.SSS3.p1.2.m2.1a"><msub id="S5.SS1.SSS3.p1.2.m2.1.1" xref="S5.SS1.SSS3.p1.2.m2.1.1.cmml"><mi id="S5.SS1.SSS3.p1.2.m2.1.1.2" xref="S5.SS1.SSS3.p1.2.m2.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.2.m2.1.1.3" xref="S5.SS1.SSS3.p1.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.2.m2.1b"><apply id="S5.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.2.m2.1.1.1.cmml" xref="S5.SS1.SSS3.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.2.m2.1.1.2.cmml" xref="S5.SS1.SSS3.p1.2.m2.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.2.m2.1.1.3.cmml" xref="S5.SS1.SSS3.p1.2.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.2.m2.1c">S_{a}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.2.m2.1d">italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="S_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.3.m3.1"><semantics id="S5.SS1.SSS3.p1.3.m3.1a"><msub id="S5.SS1.SSS3.p1.3.m3.1.1" xref="S5.SS1.SSS3.p1.3.m3.1.1.cmml"><mi id="S5.SS1.SSS3.p1.3.m3.1.1.2" xref="S5.SS1.SSS3.p1.3.m3.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.3.m3.1.1.3" xref="S5.SS1.SSS3.p1.3.m3.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.3.m3.1b"><apply id="S5.SS1.SSS3.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS3.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.3.m3.1.1.2.cmml" xref="S5.SS1.SSS3.p1.3.m3.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.3.m3.1.1.3.cmml" xref="S5.SS1.SSS3.p1.3.m3.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.3.m3.1c">S_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.3.m3.1d">italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math>. Features from each modality are first multiplied by the Kronecker product to approximate a joint distribution. This layer performs an outer product of the modalities’ features, <math alttext="C=A\bigotimes B\in\mathbb{R}^{(m\times(a)\times(b))}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.4.m4.3"><semantics id="S5.SS1.SSS3.p1.4.m4.3a"><mrow id="S5.SS1.SSS3.p1.4.m4.3.4" xref="S5.SS1.SSS3.p1.4.m4.3.4.cmml"><mi id="S5.SS1.SSS3.p1.4.m4.3.4.2" xref="S5.SS1.SSS3.p1.4.m4.3.4.2.cmml">C</mi><mo id="S5.SS1.SSS3.p1.4.m4.3.4.3" xref="S5.SS1.SSS3.p1.4.m4.3.4.3.cmml">=</mo><mrow id="S5.SS1.SSS3.p1.4.m4.3.4.4" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.cmml"><mi id="S5.SS1.SSS3.p1.4.m4.3.4.4.2" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.2.cmml">A</mi><mo id="S5.SS1.SSS3.p1.4.m4.3.4.4.1" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.1.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p1.4.m4.3.4.4.3" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.3.cmml"><mo id="S5.SS1.SSS3.p1.4.m4.3.4.4.3.1" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.3.1.cmml">⨂</mo><mi id="S5.SS1.SSS3.p1.4.m4.3.4.4.3.2" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.3.2.cmml">B</mi></mrow></mrow><mo id="S5.SS1.SSS3.p1.4.m4.3.4.5" xref="S5.SS1.SSS3.p1.4.m4.3.4.5.cmml">∈</mo><msup id="S5.SS1.SSS3.p1.4.m4.3.4.6" xref="S5.SS1.SSS3.p1.4.m4.3.4.6.cmml"><mi id="S5.SS1.SSS3.p1.4.m4.3.4.6.2" xref="S5.SS1.SSS3.p1.4.m4.3.4.6.2.cmml">ℝ</mi><mrow id="S5.SS1.SSS3.p1.4.m4.3.3.3.3" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml"><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.2" stretchy="false" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml">(</mo><mrow id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml"><mi id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.2" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.2.cmml">m</mi><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.1" lspace="0.222em" rspace="0.222em" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.1.cmml">×</mo><mrow id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.3.2" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml"><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.3.2.1" stretchy="false" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml">(</mo><mi id="S5.SS1.SSS3.p1.4.m4.1.1.1.1" xref="S5.SS1.SSS3.p1.4.m4.1.1.1.1.cmml">a</mi><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.3.2.2" rspace="0.055em" stretchy="false" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml">)</mo></mrow><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.1a" rspace="0.222em" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.1.cmml">×</mo><mrow id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.4.2" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml"><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.4.2.1" stretchy="false" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml">(</mo><mi id="S5.SS1.SSS3.p1.4.m4.2.2.2.2" xref="S5.SS1.SSS3.p1.4.m4.2.2.2.2.cmml">b</mi><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.4.2.2" stretchy="false" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml">)</mo></mrow></mrow><mo id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.3" stretchy="false" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.4.m4.3b"><apply id="S5.SS1.SSS3.p1.4.m4.3.4.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4"><and id="S5.SS1.SSS3.p1.4.m4.3.4a.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4"></and><apply id="S5.SS1.SSS3.p1.4.m4.3.4b.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4"><eq id="S5.SS1.SSS3.p1.4.m4.3.4.3.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.3"></eq><ci id="S5.SS1.SSS3.p1.4.m4.3.4.2.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.2">𝐶</ci><apply id="S5.SS1.SSS3.p1.4.m4.3.4.4.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.4"><times id="S5.SS1.SSS3.p1.4.m4.3.4.4.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.1"></times><ci id="S5.SS1.SSS3.p1.4.m4.3.4.4.2.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.2">𝐴</ci><apply id="S5.SS1.SSS3.p1.4.m4.3.4.4.3.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.3"><csymbol cd="latexml" id="S5.SS1.SSS3.p1.4.m4.3.4.4.3.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.3.1">tensor-product</csymbol><ci id="S5.SS1.SSS3.p1.4.m4.3.4.4.3.2.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.4.3.2">𝐵</ci></apply></apply></apply><apply id="S5.SS1.SSS3.p1.4.m4.3.4c.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4"><in id="S5.SS1.SSS3.p1.4.m4.3.4.5.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.5"></in><share href="https://arxiv.org/html/2404.12278v2#S5.SS1.SSS3.p1.4.m4.3.4.4.cmml" id="S5.SS1.SSS3.p1.4.m4.3.4d.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4"></share><apply id="S5.SS1.SSS3.p1.4.m4.3.4.6.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.6"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.4.m4.3.4.6.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.6">superscript</csymbol><ci id="S5.SS1.SSS3.p1.4.m4.3.4.6.2.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.4.6.2">ℝ</ci><apply id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3"><times id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.1"></times><ci id="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.2.cmml" xref="S5.SS1.SSS3.p1.4.m4.3.3.3.3.1.2">𝑚</ci><ci id="S5.SS1.SSS3.p1.4.m4.1.1.1.1.cmml" xref="S5.SS1.SSS3.p1.4.m4.1.1.1.1">𝑎</ci><ci id="S5.SS1.SSS3.p1.4.m4.2.2.2.2.cmml" xref="S5.SS1.SSS3.p1.4.m4.2.2.2.2">𝑏</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.4.m4.3c">C=A\bigotimes B\in\mathbb{R}^{(m\times(a)\times(b))}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.4.m4.3d">italic_C = italic_A ⨂ italic_B ∈ blackboard_R start_POSTSUPERSCRIPT ( italic_m × ( italic_a ) × ( italic_b ) ) end_POSTSUPERSCRIPT</annotation></semantics></math>, effectively capturing the pairwise interactions between features from different modalities. We apply self-attention to <math alttext="Z_{a}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.5.m5.1"><semantics id="S5.SS1.SSS3.p1.5.m5.1a"><msub id="S5.SS1.SSS3.p1.5.m5.1.1" xref="S5.SS1.SSS3.p1.5.m5.1.1.cmml"><mi id="S5.SS1.SSS3.p1.5.m5.1.1.2" xref="S5.SS1.SSS3.p1.5.m5.1.1.2.cmml">Z</mi><mi id="S5.SS1.SSS3.p1.5.m5.1.1.3" xref="S5.SS1.SSS3.p1.5.m5.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.5.m5.1b"><apply id="S5.SS1.SSS3.p1.5.m5.1.1.cmml" xref="S5.SS1.SSS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.5.m5.1.1.1.cmml" xref="S5.SS1.SSS3.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.5.m5.1.1.2.cmml" xref="S5.SS1.SSS3.p1.5.m5.1.1.2">𝑍</ci><ci id="S5.SS1.SSS3.p1.5.m5.1.1.3.cmml" xref="S5.SS1.SSS3.p1.5.m5.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.5.m5.1c">Z_{a}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.5.m5.1d">italic_Z start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="Z_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.6.m6.1"><semantics id="S5.SS1.SSS3.p1.6.m6.1a"><msub id="S5.SS1.SSS3.p1.6.m6.1.1" xref="S5.SS1.SSS3.p1.6.m6.1.1.cmml"><mi id="S5.SS1.SSS3.p1.6.m6.1.1.2" xref="S5.SS1.SSS3.p1.6.m6.1.1.2.cmml">Z</mi><mi id="S5.SS1.SSS3.p1.6.m6.1.1.3" xref="S5.SS1.SSS3.p1.6.m6.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.6.m6.1b"><apply id="S5.SS1.SSS3.p1.6.m6.1.1.cmml" xref="S5.SS1.SSS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.6.m6.1.1.1.cmml" xref="S5.SS1.SSS3.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.6.m6.1.1.2.cmml" xref="S5.SS1.SSS3.p1.6.m6.1.1.2">𝑍</ci><ci id="S5.SS1.SSS3.p1.6.m6.1.1.3.cmml" xref="S5.SS1.SSS3.p1.6.m6.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.6.m6.1c">Z_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.6.m6.1d">italic_Z start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> to obtain <math alttext="S_{a}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.7.m7.1"><semantics id="S5.SS1.SSS3.p1.7.m7.1a"><msub id="S5.SS1.SSS3.p1.7.m7.1.1" xref="S5.SS1.SSS3.p1.7.m7.1.1.cmml"><mi id="S5.SS1.SSS3.p1.7.m7.1.1.2" xref="S5.SS1.SSS3.p1.7.m7.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.7.m7.1.1.3" xref="S5.SS1.SSS3.p1.7.m7.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.7.m7.1b"><apply id="S5.SS1.SSS3.p1.7.m7.1.1.cmml" xref="S5.SS1.SSS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.7.m7.1.1.1.cmml" xref="S5.SS1.SSS3.p1.7.m7.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.7.m7.1.1.2.cmml" xref="S5.SS1.SSS3.p1.7.m7.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.7.m7.1.1.3.cmml" xref="S5.SS1.SSS3.p1.7.m7.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.7.m7.1c">S_{a}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.7.m7.1d">italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="S_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.8.m8.1"><semantics id="S5.SS1.SSS3.p1.8.m8.1a"><msub id="S5.SS1.SSS3.p1.8.m8.1.1" xref="S5.SS1.SSS3.p1.8.m8.1.1.cmml"><mi id="S5.SS1.SSS3.p1.8.m8.1.1.2" xref="S5.SS1.SSS3.p1.8.m8.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.8.m8.1.1.3" xref="S5.SS1.SSS3.p1.8.m8.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.8.m8.1b"><apply id="S5.SS1.SSS3.p1.8.m8.1.1.cmml" xref="S5.SS1.SSS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.8.m8.1.1.1.cmml" xref="S5.SS1.SSS3.p1.8.m8.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.8.m8.1.1.2.cmml" xref="S5.SS1.SSS3.p1.8.m8.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.8.m8.1.1.3.cmml" xref="S5.SS1.SSS3.p1.8.m8.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.8.m8.1c">S_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.8.m8.1d">italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math>, controlling the expressivity of each modality and preventing noisy features. Then we extract the common information of the joint distribution via cross attention of <math alttext="Q_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.9.m9.1"><semantics id="S5.SS1.SSS3.p1.9.m9.1a"><msub id="S5.SS1.SSS3.p1.9.m9.1.1" xref="S5.SS1.SSS3.p1.9.m9.1.1.cmml"><mi id="S5.SS1.SSS3.p1.9.m9.1.1.2" xref="S5.SS1.SSS3.p1.9.m9.1.1.2.cmml">Q</mi><mi id="S5.SS1.SSS3.p1.9.m9.1.1.3" xref="S5.SS1.SSS3.p1.9.m9.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.9.m9.1b"><apply id="S5.SS1.SSS3.p1.9.m9.1.1.cmml" xref="S5.SS1.SSS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.9.m9.1.1.1.cmml" xref="S5.SS1.SSS3.p1.9.m9.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.9.m9.1.1.2.cmml" xref="S5.SS1.SSS3.p1.9.m9.1.1.2">𝑄</ci><ci id="S5.SS1.SSS3.p1.9.m9.1.1.3.cmml" xref="S5.SS1.SSS3.p1.9.m9.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.9.m9.1c">Q_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.9.m9.1d">italic_Q start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="K_{c}+K_{a}+K_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.10.m10.1"><semantics id="S5.SS1.SSS3.p1.10.m10.1a"><mrow id="S5.SS1.SSS3.p1.10.m10.1.1" xref="S5.SS1.SSS3.p1.10.m10.1.1.cmml"><msub id="S5.SS1.SSS3.p1.10.m10.1.1.2" xref="S5.SS1.SSS3.p1.10.m10.1.1.2.cmml"><mi id="S5.SS1.SSS3.p1.10.m10.1.1.2.2" xref="S5.SS1.SSS3.p1.10.m10.1.1.2.2.cmml">K</mi><mi id="S5.SS1.SSS3.p1.10.m10.1.1.2.3" xref="S5.SS1.SSS3.p1.10.m10.1.1.2.3.cmml">c</mi></msub><mo id="S5.SS1.SSS3.p1.10.m10.1.1.1" xref="S5.SS1.SSS3.p1.10.m10.1.1.1.cmml">+</mo><msub id="S5.SS1.SSS3.p1.10.m10.1.1.3" xref="S5.SS1.SSS3.p1.10.m10.1.1.3.cmml"><mi id="S5.SS1.SSS3.p1.10.m10.1.1.3.2" xref="S5.SS1.SSS3.p1.10.m10.1.1.3.2.cmml">K</mi><mi id="S5.SS1.SSS3.p1.10.m10.1.1.3.3" xref="S5.SS1.SSS3.p1.10.m10.1.1.3.3.cmml">a</mi></msub><mo id="S5.SS1.SSS3.p1.10.m10.1.1.1a" xref="S5.SS1.SSS3.p1.10.m10.1.1.1.cmml">+</mo><msub id="S5.SS1.SSS3.p1.10.m10.1.1.4" xref="S5.SS1.SSS3.p1.10.m10.1.1.4.cmml"><mi id="S5.SS1.SSS3.p1.10.m10.1.1.4.2" xref="S5.SS1.SSS3.p1.10.m10.1.1.4.2.cmml">K</mi><mi id="S5.SS1.SSS3.p1.10.m10.1.1.4.3" xref="S5.SS1.SSS3.p1.10.m10.1.1.4.3.cmml">b</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.10.m10.1b"><apply id="S5.SS1.SSS3.p1.10.m10.1.1.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1"><plus id="S5.SS1.SSS3.p1.10.m10.1.1.1.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.1"></plus><apply id="S5.SS1.SSS3.p1.10.m10.1.1.2.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.10.m10.1.1.2.1.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.2">subscript</csymbol><ci id="S5.SS1.SSS3.p1.10.m10.1.1.2.2.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.2.2">𝐾</ci><ci id="S5.SS1.SSS3.p1.10.m10.1.1.2.3.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.2.3">𝑐</ci></apply><apply id="S5.SS1.SSS3.p1.10.m10.1.1.3.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.10.m10.1.1.3.1.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p1.10.m10.1.1.3.2.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.3.2">𝐾</ci><ci id="S5.SS1.SSS3.p1.10.m10.1.1.3.3.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.3.3">𝑎</ci></apply><apply id="S5.SS1.SSS3.p1.10.m10.1.1.4.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.4"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.10.m10.1.1.4.1.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.4">subscript</csymbol><ci id="S5.SS1.SSS3.p1.10.m10.1.1.4.2.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.4.2">𝐾</ci><ci id="S5.SS1.SSS3.p1.10.m10.1.1.4.3.cmml" xref="S5.SS1.SSS3.p1.10.m10.1.1.4.3">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.10.m10.1c">K_{c}+K_{a}+K_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.10.m10.1d">italic_K start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_K start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT + italic_K start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="V_{c}+V_{a}+V_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.11.m11.1"><semantics id="S5.SS1.SSS3.p1.11.m11.1a"><mrow id="S5.SS1.SSS3.p1.11.m11.1.1" xref="S5.SS1.SSS3.p1.11.m11.1.1.cmml"><msub id="S5.SS1.SSS3.p1.11.m11.1.1.2" xref="S5.SS1.SSS3.p1.11.m11.1.1.2.cmml"><mi id="S5.SS1.SSS3.p1.11.m11.1.1.2.2" xref="S5.SS1.SSS3.p1.11.m11.1.1.2.2.cmml">V</mi><mi id="S5.SS1.SSS3.p1.11.m11.1.1.2.3" xref="S5.SS1.SSS3.p1.11.m11.1.1.2.3.cmml">c</mi></msub><mo id="S5.SS1.SSS3.p1.11.m11.1.1.1" xref="S5.SS1.SSS3.p1.11.m11.1.1.1.cmml">+</mo><msub id="S5.SS1.SSS3.p1.11.m11.1.1.3" xref="S5.SS1.SSS3.p1.11.m11.1.1.3.cmml"><mi id="S5.SS1.SSS3.p1.11.m11.1.1.3.2" xref="S5.SS1.SSS3.p1.11.m11.1.1.3.2.cmml">V</mi><mi id="S5.SS1.SSS3.p1.11.m11.1.1.3.3" xref="S5.SS1.SSS3.p1.11.m11.1.1.3.3.cmml">a</mi></msub><mo id="S5.SS1.SSS3.p1.11.m11.1.1.1a" xref="S5.SS1.SSS3.p1.11.m11.1.1.1.cmml">+</mo><msub id="S5.SS1.SSS3.p1.11.m11.1.1.4" xref="S5.SS1.SSS3.p1.11.m11.1.1.4.cmml"><mi id="S5.SS1.SSS3.p1.11.m11.1.1.4.2" xref="S5.SS1.SSS3.p1.11.m11.1.1.4.2.cmml">V</mi><mi id="S5.SS1.SSS3.p1.11.m11.1.1.4.3" xref="S5.SS1.SSS3.p1.11.m11.1.1.4.3.cmml">b</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.11.m11.1b"><apply id="S5.SS1.SSS3.p1.11.m11.1.1.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1"><plus id="S5.SS1.SSS3.p1.11.m11.1.1.1.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.1"></plus><apply id="S5.SS1.SSS3.p1.11.m11.1.1.2.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.11.m11.1.1.2.1.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.2">subscript</csymbol><ci id="S5.SS1.SSS3.p1.11.m11.1.1.2.2.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.2.2">𝑉</ci><ci id="S5.SS1.SSS3.p1.11.m11.1.1.2.3.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.2.3">𝑐</ci></apply><apply id="S5.SS1.SSS3.p1.11.m11.1.1.3.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.11.m11.1.1.3.1.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p1.11.m11.1.1.3.2.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.3.2">𝑉</ci><ci id="S5.SS1.SSS3.p1.11.m11.1.1.3.3.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.3.3">𝑎</ci></apply><apply id="S5.SS1.SSS3.p1.11.m11.1.1.4.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.4"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.11.m11.1.1.4.1.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.4">subscript</csymbol><ci id="S5.SS1.SSS3.p1.11.m11.1.1.4.2.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.4.2">𝑉</ci><ci id="S5.SS1.SSS3.p1.11.m11.1.1.4.3.cmml" xref="S5.SS1.SSS3.p1.11.m11.1.1.4.3">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.11.m11.1c">V_{c}+V_{a}+V_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.11.m11.1d">italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_V start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT + italic_V start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> to model modality-common features <math alttext="S_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.12.m12.1"><semantics id="S5.SS1.SSS3.p1.12.m12.1a"><msub id="S5.SS1.SSS3.p1.12.m12.1.1" xref="S5.SS1.SSS3.p1.12.m12.1.1.cmml"><mi id="S5.SS1.SSS3.p1.12.m12.1.1.2" xref="S5.SS1.SSS3.p1.12.m12.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.12.m12.1.1.3" xref="S5.SS1.SSS3.p1.12.m12.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.12.m12.1b"><apply id="S5.SS1.SSS3.p1.12.m12.1.1.cmml" xref="S5.SS1.SSS3.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.12.m12.1.1.1.cmml" xref="S5.SS1.SSS3.p1.12.m12.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.12.m12.1.1.2.cmml" xref="S5.SS1.SSS3.p1.12.m12.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.12.m12.1.1.3.cmml" xref="S5.SS1.SSS3.p1.12.m12.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.12.m12.1c">S_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.12.m12.1d">italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. We minimize the Mutual Information (MI) loss between concatenated <math alttext="S_{a}+S_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.13.m13.1"><semantics id="S5.SS1.SSS3.p1.13.m13.1a"><mrow id="S5.SS1.SSS3.p1.13.m13.1.1" xref="S5.SS1.SSS3.p1.13.m13.1.1.cmml"><msub id="S5.SS1.SSS3.p1.13.m13.1.1.2" xref="S5.SS1.SSS3.p1.13.m13.1.1.2.cmml"><mi id="S5.SS1.SSS3.p1.13.m13.1.1.2.2" xref="S5.SS1.SSS3.p1.13.m13.1.1.2.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.13.m13.1.1.2.3" xref="S5.SS1.SSS3.p1.13.m13.1.1.2.3.cmml">a</mi></msub><mo id="S5.SS1.SSS3.p1.13.m13.1.1.1" xref="S5.SS1.SSS3.p1.13.m13.1.1.1.cmml">+</mo><msub id="S5.SS1.SSS3.p1.13.m13.1.1.3" xref="S5.SS1.SSS3.p1.13.m13.1.1.3.cmml"><mi id="S5.SS1.SSS3.p1.13.m13.1.1.3.2" xref="S5.SS1.SSS3.p1.13.m13.1.1.3.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.13.m13.1.1.3.3" xref="S5.SS1.SSS3.p1.13.m13.1.1.3.3.cmml">b</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.13.m13.1b"><apply id="S5.SS1.SSS3.p1.13.m13.1.1.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1"><plus id="S5.SS1.SSS3.p1.13.m13.1.1.1.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.1"></plus><apply id="S5.SS1.SSS3.p1.13.m13.1.1.2.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.13.m13.1.1.2.1.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.2">subscript</csymbol><ci id="S5.SS1.SSS3.p1.13.m13.1.1.2.2.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.2.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.13.m13.1.1.2.3.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.2.3">𝑎</ci></apply><apply id="S5.SS1.SSS3.p1.13.m13.1.1.3.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.13.m13.1.1.3.1.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p1.13.m13.1.1.3.2.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.3.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.13.m13.1.1.3.3.cmml" xref="S5.SS1.SSS3.p1.13.m13.1.1.3.3">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.13.m13.1c">S_{a}+S_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.13.m13.1d">italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT + italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="S_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.14.m14.1"><semantics id="S5.SS1.SSS3.p1.14.m14.1a"><msub id="S5.SS1.SSS3.p1.14.m14.1.1" xref="S5.SS1.SSS3.p1.14.m14.1.1.cmml"><mi id="S5.SS1.SSS3.p1.14.m14.1.1.2" xref="S5.SS1.SSS3.p1.14.m14.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p1.14.m14.1.1.3" xref="S5.SS1.SSS3.p1.14.m14.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.14.m14.1b"><apply id="S5.SS1.SSS3.p1.14.m14.1.1.cmml" xref="S5.SS1.SSS3.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.14.m14.1.1.1.cmml" xref="S5.SS1.SSS3.p1.14.m14.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.14.m14.1.1.2.cmml" xref="S5.SS1.SSS3.p1.14.m14.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p1.14.m14.1.1.3.cmml" xref="S5.SS1.SSS3.p1.14.m14.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.14.m14.1c">S_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.14.m14.1d">italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> to preserve modality-specific information. Since the computation of mutual information is intractable, we calculate a variational upper bound called contrastive log-ratio upper bound (vCLUB) [72] as an MI estimator to accomplish MI minimization. Given two variables <math alttext="a" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.15.m15.1"><semantics id="S5.SS1.SSS3.p1.15.m15.1a"><mi id="S5.SS1.SSS3.p1.15.m15.1.1" xref="S5.SS1.SSS3.p1.15.m15.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.15.m15.1b"><ci id="S5.SS1.SSS3.p1.15.m15.1.1.cmml" xref="S5.SS1.SSS3.p1.15.m15.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.15.m15.1c">a</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.15.m15.1d">italic_a</annotation></semantics></math> and <math alttext="b" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.16.m16.1"><semantics id="S5.SS1.SSS3.p1.16.m16.1a"><mi id="S5.SS1.SSS3.p1.16.m16.1.1" xref="S5.SS1.SSS3.p1.16.m16.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.16.m16.1b"><ci id="S5.SS1.SSS3.p1.16.m16.1.1.cmml" xref="S5.SS1.SSS3.p1.16.m16.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.16.m16.1c">b</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.16.m16.1d">italic_b</annotation></semantics></math>, the <math alttext="L_{v}CLUB(a,b)" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.17.m17.2"><semantics id="S5.SS1.SSS3.p1.17.m17.2a"><mrow id="S5.SS1.SSS3.p1.17.m17.2.3" xref="S5.SS1.SSS3.p1.17.m17.2.3.cmml"><msub id="S5.SS1.SSS3.p1.17.m17.2.3.2" xref="S5.SS1.SSS3.p1.17.m17.2.3.2.cmml"><mi id="S5.SS1.SSS3.p1.17.m17.2.3.2.2" xref="S5.SS1.SSS3.p1.17.m17.2.3.2.2.cmml">L</mi><mi id="S5.SS1.SSS3.p1.17.m17.2.3.2.3" xref="S5.SS1.SSS3.p1.17.m17.2.3.2.3.cmml">v</mi></msub><mo id="S5.SS1.SSS3.p1.17.m17.2.3.1" xref="S5.SS1.SSS3.p1.17.m17.2.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p1.17.m17.2.3.3" xref="S5.SS1.SSS3.p1.17.m17.2.3.3.cmml">C</mi><mo id="S5.SS1.SSS3.p1.17.m17.2.3.1a" xref="S5.SS1.SSS3.p1.17.m17.2.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p1.17.m17.2.3.4" xref="S5.SS1.SSS3.p1.17.m17.2.3.4.cmml">L</mi><mo id="S5.SS1.SSS3.p1.17.m17.2.3.1b" xref="S5.SS1.SSS3.p1.17.m17.2.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p1.17.m17.2.3.5" xref="S5.SS1.SSS3.p1.17.m17.2.3.5.cmml">U</mi><mo id="S5.SS1.SSS3.p1.17.m17.2.3.1c" xref="S5.SS1.SSS3.p1.17.m17.2.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p1.17.m17.2.3.6" xref="S5.SS1.SSS3.p1.17.m17.2.3.6.cmml">B</mi><mo id="S5.SS1.SSS3.p1.17.m17.2.3.1d" xref="S5.SS1.SSS3.p1.17.m17.2.3.1.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p1.17.m17.2.3.7.2" xref="S5.SS1.SSS3.p1.17.m17.2.3.7.1.cmml"><mo id="S5.SS1.SSS3.p1.17.m17.2.3.7.2.1" stretchy="false" xref="S5.SS1.SSS3.p1.17.m17.2.3.7.1.cmml">(</mo><mi id="S5.SS1.SSS3.p1.17.m17.1.1" xref="S5.SS1.SSS3.p1.17.m17.1.1.cmml">a</mi><mo id="S5.SS1.SSS3.p1.17.m17.2.3.7.2.2" xref="S5.SS1.SSS3.p1.17.m17.2.3.7.1.cmml">,</mo><mi id="S5.SS1.SSS3.p1.17.m17.2.2" xref="S5.SS1.SSS3.p1.17.m17.2.2.cmml">b</mi><mo id="S5.SS1.SSS3.p1.17.m17.2.3.7.2.3" stretchy="false" xref="S5.SS1.SSS3.p1.17.m17.2.3.7.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.17.m17.2b"><apply id="S5.SS1.SSS3.p1.17.m17.2.3.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3"><times id="S5.SS1.SSS3.p1.17.m17.2.3.1.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.1"></times><apply id="S5.SS1.SSS3.p1.17.m17.2.3.2.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.2"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.17.m17.2.3.2.1.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.2">subscript</csymbol><ci id="S5.SS1.SSS3.p1.17.m17.2.3.2.2.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.2.2">𝐿</ci><ci id="S5.SS1.SSS3.p1.17.m17.2.3.2.3.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.2.3">𝑣</ci></apply><ci id="S5.SS1.SSS3.p1.17.m17.2.3.3.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.3">𝐶</ci><ci id="S5.SS1.SSS3.p1.17.m17.2.3.4.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.4">𝐿</ci><ci id="S5.SS1.SSS3.p1.17.m17.2.3.5.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.5">𝑈</ci><ci id="S5.SS1.SSS3.p1.17.m17.2.3.6.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.6">𝐵</ci><interval closure="open" id="S5.SS1.SSS3.p1.17.m17.2.3.7.1.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.3.7.2"><ci id="S5.SS1.SSS3.p1.17.m17.1.1.cmml" xref="S5.SS1.SSS3.p1.17.m17.1.1">𝑎</ci><ci id="S5.SS1.SSS3.p1.17.m17.2.2.cmml" xref="S5.SS1.SSS3.p1.17.m17.2.2">𝑏</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.17.m17.2c">L_{v}CLUB(a,b)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p1.17.m17.2d">italic_L start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT italic_C italic_L italic_U italic_B ( italic_a , italic_b )</annotation></semantics></math> is calculated as follows (equation 1)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib82" title="">82</a>]</cite>:</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx1">
<tbody id="S5.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle L_{v}^{CLUB}(a,b)" class="ltx_Math" display="inline" id="S5.Ex1.m1.2"><semantics id="S5.Ex1.m1.2a"><mrow id="S5.Ex1.m1.2.3" xref="S5.Ex1.m1.2.3.cmml"><msubsup id="S5.Ex1.m1.2.3.2" xref="S5.Ex1.m1.2.3.2.cmml"><mi id="S5.Ex1.m1.2.3.2.2.2" xref="S5.Ex1.m1.2.3.2.2.2.cmml">L</mi><mi id="S5.Ex1.m1.2.3.2.2.3" xref="S5.Ex1.m1.2.3.2.2.3.cmml">v</mi><mrow id="S5.Ex1.m1.2.3.2.3" xref="S5.Ex1.m1.2.3.2.3.cmml"><mi id="S5.Ex1.m1.2.3.2.3.2" xref="S5.Ex1.m1.2.3.2.3.2.cmml">C</mi><mo id="S5.Ex1.m1.2.3.2.3.1" xref="S5.Ex1.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S5.Ex1.m1.2.3.2.3.3" xref="S5.Ex1.m1.2.3.2.3.3.cmml">L</mi><mo id="S5.Ex1.m1.2.3.2.3.1a" xref="S5.Ex1.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S5.Ex1.m1.2.3.2.3.4" xref="S5.Ex1.m1.2.3.2.3.4.cmml">U</mi><mo id="S5.Ex1.m1.2.3.2.3.1b" xref="S5.Ex1.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S5.Ex1.m1.2.3.2.3.5" xref="S5.Ex1.m1.2.3.2.3.5.cmml">B</mi></mrow></msubsup><mo id="S5.Ex1.m1.2.3.1" xref="S5.Ex1.m1.2.3.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.2.3.3.2" xref="S5.Ex1.m1.2.3.3.1.cmml"><mo id="S5.Ex1.m1.2.3.3.2.1" stretchy="false" xref="S5.Ex1.m1.2.3.3.1.cmml">(</mo><mi id="S5.Ex1.m1.1.1" xref="S5.Ex1.m1.1.1.cmml">a</mi><mo id="S5.Ex1.m1.2.3.3.2.2" xref="S5.Ex1.m1.2.3.3.1.cmml">,</mo><mi id="S5.Ex1.m1.2.2" xref="S5.Ex1.m1.2.2.cmml">b</mi><mo id="S5.Ex1.m1.2.3.3.2.3" stretchy="false" xref="S5.Ex1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m1.2b"><apply id="S5.Ex1.m1.2.3.cmml" xref="S5.Ex1.m1.2.3"><times id="S5.Ex1.m1.2.3.1.cmml" xref="S5.Ex1.m1.2.3.1"></times><apply id="S5.Ex1.m1.2.3.2.cmml" xref="S5.Ex1.m1.2.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.2.3.2.1.cmml" xref="S5.Ex1.m1.2.3.2">superscript</csymbol><apply id="S5.Ex1.m1.2.3.2.2.cmml" xref="S5.Ex1.m1.2.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.2.3.2.2.1.cmml" xref="S5.Ex1.m1.2.3.2">subscript</csymbol><ci id="S5.Ex1.m1.2.3.2.2.2.cmml" xref="S5.Ex1.m1.2.3.2.2.2">𝐿</ci><ci id="S5.Ex1.m1.2.3.2.2.3.cmml" xref="S5.Ex1.m1.2.3.2.2.3">𝑣</ci></apply><apply id="S5.Ex1.m1.2.3.2.3.cmml" xref="S5.Ex1.m1.2.3.2.3"><times id="S5.Ex1.m1.2.3.2.3.1.cmml" xref="S5.Ex1.m1.2.3.2.3.1"></times><ci id="S5.Ex1.m1.2.3.2.3.2.cmml" xref="S5.Ex1.m1.2.3.2.3.2">𝐶</ci><ci id="S5.Ex1.m1.2.3.2.3.3.cmml" xref="S5.Ex1.m1.2.3.2.3.3">𝐿</ci><ci id="S5.Ex1.m1.2.3.2.3.4.cmml" xref="S5.Ex1.m1.2.3.2.3.4">𝑈</ci><ci id="S5.Ex1.m1.2.3.2.3.5.cmml" xref="S5.Ex1.m1.2.3.2.3.5">𝐵</ci></apply></apply><interval closure="open" id="S5.Ex1.m1.2.3.3.1.cmml" xref="S5.Ex1.m1.2.3.3.2"><ci id="S5.Ex1.m1.1.1.cmml" xref="S5.Ex1.m1.1.1">𝑎</ci><ci id="S5.Ex1.m1.2.2.cmml" xref="S5.Ex1.m1.2.2">𝑏</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m1.2c">\displaystyle L_{v}^{CLUB}(a,b)</annotation><annotation encoding="application/x-llamapun" id="S5.Ex1.m1.2d">italic_L start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C italic_L italic_U italic_B end_POSTSUPERSCRIPT ( italic_a , italic_b )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\mathbb{E}_{p}(a,b)\left[\log q_{\theta}(b|a)\right]-\mathbb{E}_%
{p}(a)\mathbb{E}_{p}(b)\left[\log q_{\theta}(b|a)\right]" class="ltx_Math" display="inline" id="S5.Ex1.m2.6"><semantics id="S5.Ex1.m2.6a"><mrow id="S5.Ex1.m2.6.6" xref="S5.Ex1.m2.6.6.cmml"><mi id="S5.Ex1.m2.6.6.4" xref="S5.Ex1.m2.6.6.4.cmml"></mi><mo id="S5.Ex1.m2.6.6.3" xref="S5.Ex1.m2.6.6.3.cmml">=</mo><mrow id="S5.Ex1.m2.6.6.2" xref="S5.Ex1.m2.6.6.2.cmml"><mrow id="S5.Ex1.m2.5.5.1.1" xref="S5.Ex1.m2.5.5.1.1.cmml"><msub id="S5.Ex1.m2.5.5.1.1.3" xref="S5.Ex1.m2.5.5.1.1.3.cmml"><mi id="S5.Ex1.m2.5.5.1.1.3.2" xref="S5.Ex1.m2.5.5.1.1.3.2.cmml">𝔼</mi><mi id="S5.Ex1.m2.5.5.1.1.3.3" xref="S5.Ex1.m2.5.5.1.1.3.3.cmml">p</mi></msub><mo id="S5.Ex1.m2.5.5.1.1.2" xref="S5.Ex1.m2.5.5.1.1.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.5.5.1.1.4.2" xref="S5.Ex1.m2.5.5.1.1.4.1.cmml"><mo id="S5.Ex1.m2.5.5.1.1.4.2.1" stretchy="false" xref="S5.Ex1.m2.5.5.1.1.4.1.cmml">(</mo><mi id="S5.Ex1.m2.1.1" xref="S5.Ex1.m2.1.1.cmml">a</mi><mo id="S5.Ex1.m2.5.5.1.1.4.2.2" xref="S5.Ex1.m2.5.5.1.1.4.1.cmml">,</mo><mi id="S5.Ex1.m2.2.2" xref="S5.Ex1.m2.2.2.cmml">b</mi><mo id="S5.Ex1.m2.5.5.1.1.4.2.3" stretchy="false" xref="S5.Ex1.m2.5.5.1.1.4.1.cmml">)</mo></mrow><mo id="S5.Ex1.m2.5.5.1.1.2a" xref="S5.Ex1.m2.5.5.1.1.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.5.5.1.1.1.1" xref="S5.Ex1.m2.5.5.1.1.1.2.cmml"><mo id="S5.Ex1.m2.5.5.1.1.1.1.2" xref="S5.Ex1.m2.5.5.1.1.1.2.1.cmml">[</mo><mrow id="S5.Ex1.m2.5.5.1.1.1.1.1" xref="S5.Ex1.m2.5.5.1.1.1.1.1.cmml"><mrow id="S5.Ex1.m2.5.5.1.1.1.1.1.3" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.cmml"><mi id="S5.Ex1.m2.5.5.1.1.1.1.1.3.1" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.1.cmml">log</mi><mo id="S5.Ex1.m2.5.5.1.1.1.1.1.3a" lspace="0.167em" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.cmml">⁡</mo><msub id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.cmml"><mi id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.2" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.2.cmml">q</mi><mi id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.3" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="S5.Ex1.m2.5.5.1.1.1.1.1.2" xref="S5.Ex1.m2.5.5.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.cmml"><mo id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.cmml"><mi id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.2" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.2.cmml">b</mi><mo fence="false" id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.1" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.3" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.3.cmml">a</mi></mrow><mo id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m2.5.5.1.1.1.1.3" xref="S5.Ex1.m2.5.5.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S5.Ex1.m2.6.6.2.3" xref="S5.Ex1.m2.6.6.2.3.cmml">−</mo><mrow id="S5.Ex1.m2.6.6.2.2" xref="S5.Ex1.m2.6.6.2.2.cmml"><msub id="S5.Ex1.m2.6.6.2.2.3" xref="S5.Ex1.m2.6.6.2.2.3.cmml"><mi id="S5.Ex1.m2.6.6.2.2.3.2" xref="S5.Ex1.m2.6.6.2.2.3.2.cmml">𝔼</mi><mi id="S5.Ex1.m2.6.6.2.2.3.3" xref="S5.Ex1.m2.6.6.2.2.3.3.cmml">p</mi></msub><mo id="S5.Ex1.m2.6.6.2.2.2" xref="S5.Ex1.m2.6.6.2.2.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.6.6.2.2.4.2" xref="S5.Ex1.m2.6.6.2.2.cmml"><mo id="S5.Ex1.m2.6.6.2.2.4.2.1" stretchy="false" xref="S5.Ex1.m2.6.6.2.2.cmml">(</mo><mi id="S5.Ex1.m2.3.3" xref="S5.Ex1.m2.3.3.cmml">a</mi><mo id="S5.Ex1.m2.6.6.2.2.4.2.2" stretchy="false" xref="S5.Ex1.m2.6.6.2.2.cmml">)</mo></mrow><mo id="S5.Ex1.m2.6.6.2.2.2a" xref="S5.Ex1.m2.6.6.2.2.2.cmml">⁢</mo><msub id="S5.Ex1.m2.6.6.2.2.5" xref="S5.Ex1.m2.6.6.2.2.5.cmml"><mi id="S5.Ex1.m2.6.6.2.2.5.2" xref="S5.Ex1.m2.6.6.2.2.5.2.cmml">𝔼</mi><mi id="S5.Ex1.m2.6.6.2.2.5.3" xref="S5.Ex1.m2.6.6.2.2.5.3.cmml">p</mi></msub><mo id="S5.Ex1.m2.6.6.2.2.2b" xref="S5.Ex1.m2.6.6.2.2.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.6.6.2.2.6.2" xref="S5.Ex1.m2.6.6.2.2.cmml"><mo id="S5.Ex1.m2.6.6.2.2.6.2.1" stretchy="false" xref="S5.Ex1.m2.6.6.2.2.cmml">(</mo><mi id="S5.Ex1.m2.4.4" xref="S5.Ex1.m2.4.4.cmml">b</mi><mo id="S5.Ex1.m2.6.6.2.2.6.2.2" stretchy="false" xref="S5.Ex1.m2.6.6.2.2.cmml">)</mo></mrow><mo id="S5.Ex1.m2.6.6.2.2.2c" xref="S5.Ex1.m2.6.6.2.2.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.6.6.2.2.1.1" xref="S5.Ex1.m2.6.6.2.2.1.2.cmml"><mo id="S5.Ex1.m2.6.6.2.2.1.1.2" xref="S5.Ex1.m2.6.6.2.2.1.2.1.cmml">[</mo><mrow id="S5.Ex1.m2.6.6.2.2.1.1.1" xref="S5.Ex1.m2.6.6.2.2.1.1.1.cmml"><mrow id="S5.Ex1.m2.6.6.2.2.1.1.1.3" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.cmml"><mi id="S5.Ex1.m2.6.6.2.2.1.1.1.3.1" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.1.cmml">log</mi><mo id="S5.Ex1.m2.6.6.2.2.1.1.1.3a" lspace="0.167em" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.cmml">⁡</mo><msub id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.cmml"><mi id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.2" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.2.cmml">q</mi><mi id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.3" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="S5.Ex1.m2.6.6.2.2.1.1.1.2" xref="S5.Ex1.m2.6.6.2.2.1.1.1.2.cmml">⁢</mo><mrow id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.cmml"><mo id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.2" stretchy="false" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.cmml"><mi id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.2" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.2.cmml">b</mi><mo fence="false" id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.1" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.3" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.3.cmml">a</mi></mrow><mo id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.3" stretchy="false" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m2.6.6.2.2.1.1.3" xref="S5.Ex1.m2.6.6.2.2.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m2.6b"><apply id="S5.Ex1.m2.6.6.cmml" xref="S5.Ex1.m2.6.6"><eq id="S5.Ex1.m2.6.6.3.cmml" xref="S5.Ex1.m2.6.6.3"></eq><csymbol cd="latexml" id="S5.Ex1.m2.6.6.4.cmml" xref="S5.Ex1.m2.6.6.4">absent</csymbol><apply id="S5.Ex1.m2.6.6.2.cmml" xref="S5.Ex1.m2.6.6.2"><minus id="S5.Ex1.m2.6.6.2.3.cmml" xref="S5.Ex1.m2.6.6.2.3"></minus><apply id="S5.Ex1.m2.5.5.1.1.cmml" xref="S5.Ex1.m2.5.5.1.1"><times id="S5.Ex1.m2.5.5.1.1.2.cmml" xref="S5.Ex1.m2.5.5.1.1.2"></times><apply id="S5.Ex1.m2.5.5.1.1.3.cmml" xref="S5.Ex1.m2.5.5.1.1.3"><csymbol cd="ambiguous" id="S5.Ex1.m2.5.5.1.1.3.1.cmml" xref="S5.Ex1.m2.5.5.1.1.3">subscript</csymbol><ci id="S5.Ex1.m2.5.5.1.1.3.2.cmml" xref="S5.Ex1.m2.5.5.1.1.3.2">𝔼</ci><ci id="S5.Ex1.m2.5.5.1.1.3.3.cmml" xref="S5.Ex1.m2.5.5.1.1.3.3">𝑝</ci></apply><interval closure="open" id="S5.Ex1.m2.5.5.1.1.4.1.cmml" xref="S5.Ex1.m2.5.5.1.1.4.2"><ci id="S5.Ex1.m2.1.1.cmml" xref="S5.Ex1.m2.1.1">𝑎</ci><ci id="S5.Ex1.m2.2.2.cmml" xref="S5.Ex1.m2.2.2">𝑏</ci></interval><apply id="S5.Ex1.m2.5.5.1.1.1.2.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1"><csymbol cd="latexml" id="S5.Ex1.m2.5.5.1.1.1.2.1.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.2">delimited-[]</csymbol><apply id="S5.Ex1.m2.5.5.1.1.1.1.1.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1"><times id="S5.Ex1.m2.5.5.1.1.1.1.1.2.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.2"></times><apply id="S5.Ex1.m2.5.5.1.1.1.1.1.3.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3"><log id="S5.Ex1.m2.5.5.1.1.1.1.1.3.1.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.1"></log><apply id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.1.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2">subscript</csymbol><ci id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.2.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.2">𝑞</ci><ci id="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.3.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.1.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.2.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.2">𝑏</ci><ci id="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S5.Ex1.m2.5.5.1.1.1.1.1.1.1.1.3">𝑎</ci></apply></apply></apply></apply><apply id="S5.Ex1.m2.6.6.2.2.cmml" xref="S5.Ex1.m2.6.6.2.2"><times id="S5.Ex1.m2.6.6.2.2.2.cmml" xref="S5.Ex1.m2.6.6.2.2.2"></times><apply id="S5.Ex1.m2.6.6.2.2.3.cmml" xref="S5.Ex1.m2.6.6.2.2.3"><csymbol cd="ambiguous" id="S5.Ex1.m2.6.6.2.2.3.1.cmml" xref="S5.Ex1.m2.6.6.2.2.3">subscript</csymbol><ci id="S5.Ex1.m2.6.6.2.2.3.2.cmml" xref="S5.Ex1.m2.6.6.2.2.3.2">𝔼</ci><ci id="S5.Ex1.m2.6.6.2.2.3.3.cmml" xref="S5.Ex1.m2.6.6.2.2.3.3">𝑝</ci></apply><ci id="S5.Ex1.m2.3.3.cmml" xref="S5.Ex1.m2.3.3">𝑎</ci><apply id="S5.Ex1.m2.6.6.2.2.5.cmml" xref="S5.Ex1.m2.6.6.2.2.5"><csymbol cd="ambiguous" id="S5.Ex1.m2.6.6.2.2.5.1.cmml" xref="S5.Ex1.m2.6.6.2.2.5">subscript</csymbol><ci id="S5.Ex1.m2.6.6.2.2.5.2.cmml" xref="S5.Ex1.m2.6.6.2.2.5.2">𝔼</ci><ci id="S5.Ex1.m2.6.6.2.2.5.3.cmml" xref="S5.Ex1.m2.6.6.2.2.5.3">𝑝</ci></apply><ci id="S5.Ex1.m2.4.4.cmml" xref="S5.Ex1.m2.4.4">𝑏</ci><apply id="S5.Ex1.m2.6.6.2.2.1.2.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1"><csymbol cd="latexml" id="S5.Ex1.m2.6.6.2.2.1.2.1.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.2">delimited-[]</csymbol><apply id="S5.Ex1.m2.6.6.2.2.1.1.1.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1"><times id="S5.Ex1.m2.6.6.2.2.1.1.1.2.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.2"></times><apply id="S5.Ex1.m2.6.6.2.2.1.1.1.3.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3"><log id="S5.Ex1.m2.6.6.2.2.1.1.1.3.1.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.1"></log><apply id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.1.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2">subscript</csymbol><ci id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.2.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.2">𝑞</ci><ci id="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.3.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.1.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.2.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.2">𝑏</ci><ci id="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.3.cmml" xref="S5.Ex1.m2.6.6.2.2.1.1.1.1.1.1.3">𝑎</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m2.6c">\displaystyle=\mathbb{E}_{p}(a,b)\left[\log q_{\theta}(b|a)\right]-\mathbb{E}_%
{p}(a)\mathbb{E}_{p}(b)\left[\log q_{\theta}(b|a)\right]</annotation><annotation encoding="application/x-llamapun" id="S5.Ex1.m2.6d">= blackboard_E start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_a , italic_b ) [ roman_log italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b | italic_a ) ] - blackboard_E start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_a ) blackboard_E start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_b ) [ roman_log italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b | italic_a ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
</tr></tbody>
<tbody id="S5.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{1}{N^{2}}\sum_{i=1}^{N}\sum_{j=1}^{N}\left[\log q_{\theta}%
(b_{i}|a_{i})-\log q_{\theta}(b_{j}|a_{i})\right]" class="ltx_Math" display="inline" id="S5.E1.m1.1"><semantics id="S5.E1.m1.1a"><mrow id="S5.E1.m1.1.1" xref="S5.E1.m1.1.1.cmml"><mi id="S5.E1.m1.1.1.3" xref="S5.E1.m1.1.1.3.cmml"></mi><mo id="S5.E1.m1.1.1.2" xref="S5.E1.m1.1.1.2.cmml">=</mo><mrow id="S5.E1.m1.1.1.1" xref="S5.E1.m1.1.1.1.cmml"><mstyle displaystyle="true" id="S5.E1.m1.1.1.1.3" xref="S5.E1.m1.1.1.1.3.cmml"><mfrac id="S5.E1.m1.1.1.1.3a" xref="S5.E1.m1.1.1.1.3.cmml"><mn id="S5.E1.m1.1.1.1.3.2" xref="S5.E1.m1.1.1.1.3.2.cmml">1</mn><msup id="S5.E1.m1.1.1.1.3.3" xref="S5.E1.m1.1.1.1.3.3.cmml"><mi id="S5.E1.m1.1.1.1.3.3.2" xref="S5.E1.m1.1.1.1.3.3.2.cmml">N</mi><mn id="S5.E1.m1.1.1.1.3.3.3" xref="S5.E1.m1.1.1.1.3.3.3.cmml">2</mn></msup></mfrac></mstyle><mo id="S5.E1.m1.1.1.1.2" xref="S5.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E1.m1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S5.E1.m1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.2.cmml"><munderover id="S5.E1.m1.1.1.1.1.2a" xref="S5.E1.m1.1.1.1.1.2.cmml"><mo id="S5.E1.m1.1.1.1.1.2.2.2" movablelimits="false" xref="S5.E1.m1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E1.m1.1.1.1.1.2.2.3" xref="S5.E1.m1.1.1.1.1.2.2.3.cmml"><mi id="S5.E1.m1.1.1.1.1.2.2.3.2" xref="S5.E1.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E1.m1.1.1.1.1.2.2.3.1" xref="S5.E1.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E1.m1.1.1.1.1.2.2.3.3" xref="S5.E1.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E1.m1.1.1.1.1.2.3" xref="S5.E1.m1.1.1.1.1.2.3.cmml">N</mi></munderover></mstyle><mrow id="S5.E1.m1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S5.E1.m1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.2.cmml"><munderover id="S5.E1.m1.1.1.1.1.1.2a" xref="S5.E1.m1.1.1.1.1.1.2.cmml"><mo id="S5.E1.m1.1.1.1.1.1.2.2.2" movablelimits="false" xref="S5.E1.m1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E1.m1.1.1.1.1.1.2.2.3" xref="S5.E1.m1.1.1.1.1.1.2.2.3.cmml"><mi id="S5.E1.m1.1.1.1.1.1.2.2.3.2" xref="S5.E1.m1.1.1.1.1.1.2.2.3.2.cmml">j</mi><mo id="S5.E1.m1.1.1.1.1.1.2.2.3.1" xref="S5.E1.m1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E1.m1.1.1.1.1.1.2.2.3.3" xref="S5.E1.m1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E1.m1.1.1.1.1.1.2.3" xref="S5.E1.m1.1.1.1.1.1.2.3.cmml">N</mi></munderover></mstyle><mrow id="S5.E1.m1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.2.cmml"><mo id="S5.E1.m1.1.1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3a" lspace="0.167em" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">q</mi><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">b</mi><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">a</mi><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">log</mi><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3a" lspace="0.167em" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">⁡</mo><msub id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">q</mi><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml">θ</mi></msub></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.2" stretchy="false" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><msub id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.2.cmml">b</mi><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.3.cmml">j</mi></msub><mo fence="false" id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.1.cmml">|</mo><msub id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml"><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.2" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.2.cmml">a</mi><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.3" stretchy="false" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.1b"><apply id="S5.E1.m1.1.1.cmml" xref="S5.E1.m1.1.1"><eq id="S5.E1.m1.1.1.2.cmml" xref="S5.E1.m1.1.1.2"></eq><csymbol cd="latexml" id="S5.E1.m1.1.1.3.cmml" xref="S5.E1.m1.1.1.3">absent</csymbol><apply id="S5.E1.m1.1.1.1.cmml" xref="S5.E1.m1.1.1.1"><times id="S5.E1.m1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.2"></times><apply id="S5.E1.m1.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.3"><divide id="S5.E1.m1.1.1.1.3.1.cmml" xref="S5.E1.m1.1.1.1.3"></divide><cn id="S5.E1.m1.1.1.1.3.2.cmml" type="integer" xref="S5.E1.m1.1.1.1.3.2">1</cn><apply id="S5.E1.m1.1.1.1.3.3.cmml" xref="S5.E1.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.3.3.1.cmml" xref="S5.E1.m1.1.1.1.3.3">superscript</csymbol><ci id="S5.E1.m1.1.1.1.3.3.2.cmml" xref="S5.E1.m1.1.1.1.3.3.2">𝑁</ci><cn id="S5.E1.m1.1.1.1.3.3.3.cmml" type="integer" xref="S5.E1.m1.1.1.1.3.3.3">2</cn></apply></apply><apply id="S5.E1.m1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1"><apply id="S5.E1.m1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.1.1.2">superscript</csymbol><apply id="S5.E1.m1.1.1.1.1.2.2.cmml" xref="S5.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.2.2.1.cmml" xref="S5.E1.m1.1.1.1.1.2">subscript</csymbol><sum id="S5.E1.m1.1.1.1.1.2.2.2.cmml" xref="S5.E1.m1.1.1.1.1.2.2.2"></sum><apply id="S5.E1.m1.1.1.1.1.2.2.3.cmml" xref="S5.E1.m1.1.1.1.1.2.2.3"><eq id="S5.E1.m1.1.1.1.1.2.2.3.1.cmml" xref="S5.E1.m1.1.1.1.1.2.2.3.1"></eq><ci id="S5.E1.m1.1.1.1.1.2.2.3.2.cmml" xref="S5.E1.m1.1.1.1.1.2.2.3.2">𝑖</ci><cn id="S5.E1.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E1.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E1.m1.1.1.1.1.2.3.cmml" xref="S5.E1.m1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S5.E1.m1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1"><apply id="S5.E1.m1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.2">superscript</csymbol><apply id="S5.E1.m1.1.1.1.1.1.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.2.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.2">subscript</csymbol><sum id="S5.E1.m1.1.1.1.1.1.2.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.2.2.2"></sum><apply id="S5.E1.m1.1.1.1.1.1.2.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.2.2.3"><eq id="S5.E1.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S5.E1.m1.1.1.1.1.1.2.2.3.1"></eq><ci id="S5.E1.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S5.E1.m1.1.1.1.1.1.2.2.3.2">𝑗</ci><cn id="S5.E1.m1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E1.m1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E1.m1.1.1.1.1.1.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S5.E1.m1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1"><minus id="S5.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.3"></minus><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1"><times id="S5.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3"><log id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.1"></log><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.2">𝑞</ci><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑏</ci><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝑎</ci><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2"><times id="S5.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.2"></times><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3"><log id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.1"></log><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.2">𝑞</ci><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.3.2.3">𝜃</ci></apply></apply><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1"><csymbol cd="latexml" id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.1">conditional</csymbol><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2">subscript</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.2">𝑏</ci><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.2.3">𝑗</ci></apply><apply id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3">subscript</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.2">𝑎</ci><ci id="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.2.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.1c">\displaystyle=\frac{1}{N^{2}}\sum_{i=1}^{N}\sum_{j=1}^{N}\left[\log q_{\theta}%
(b_{i}|a_{i})-\log q_{\theta}(b_{j}|a_{i})\right]</annotation><annotation encoding="application/x-llamapun" id="S5.E1.m1.1d">= divide start_ARG 1 end_ARG start_ARG italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT [ roman_log italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - roman_log italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p3">
<p class="ltx_p" id="S5.SS1.SSS3.p3.3">We employ an MLP <math alttext="q_{\theta}(b|a)" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p3.1.m1.1"><semantics id="S5.SS1.SSS3.p3.1.m1.1a"><mrow id="S5.SS1.SSS3.p3.1.m1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.cmml"><msub id="S5.SS1.SSS3.p3.1.m1.1.1.3" xref="S5.SS1.SSS3.p3.1.m1.1.1.3.cmml"><mi id="S5.SS1.SSS3.p3.1.m1.1.1.3.2" xref="S5.SS1.SSS3.p3.1.m1.1.1.3.2.cmml">q</mi><mi id="S5.SS1.SSS3.p3.1.m1.1.1.3.3" xref="S5.SS1.SSS3.p3.1.m1.1.1.3.3.cmml">θ</mi></msub><mo id="S5.SS1.SSS3.p3.1.m1.1.1.2" xref="S5.SS1.SSS3.p3.1.m1.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p3.1.m1.1.1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.cmml"><mo id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.2" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.2.cmml">b</mi><mo fence="false" id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.3" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.3.cmml">a</mi></mrow><mo id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.1.m1.1b"><apply id="S5.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1"><times id="S5.SS1.SSS3.p3.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.2"></times><apply id="S5.SS1.SSS3.p3.1.m1.1.1.3.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p3.1.m1.1.1.3.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p3.1.m1.1.1.3.2.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.3.2">𝑞</ci><ci id="S5.SS1.SSS3.p3.1.m1.1.1.3.3.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.3.3">𝜃</ci></apply><apply id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.2">𝑏</ci><ci id="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.1.1.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.1.m1.1c">q_{\theta}(b|a)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p3.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b | italic_a )</annotation></semantics></math> to provide a variational approximation of <math alttext="q_{\theta}(b|a)" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p3.2.m2.1"><semantics id="S5.SS1.SSS3.p3.2.m2.1a"><mrow id="S5.SS1.SSS3.p3.2.m2.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.cmml"><msub id="S5.SS1.SSS3.p3.2.m2.1.1.3" xref="S5.SS1.SSS3.p3.2.m2.1.1.3.cmml"><mi id="S5.SS1.SSS3.p3.2.m2.1.1.3.2" xref="S5.SS1.SSS3.p3.2.m2.1.1.3.2.cmml">q</mi><mi id="S5.SS1.SSS3.p3.2.m2.1.1.3.3" xref="S5.SS1.SSS3.p3.2.m2.1.1.3.3.cmml">θ</mi></msub><mo id="S5.SS1.SSS3.p3.2.m2.1.1.2" xref="S5.SS1.SSS3.p3.2.m2.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p3.2.m2.1.1.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.cmml"><mo id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.2" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.2.cmml">b</mi><mo fence="false" id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.3" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.3.cmml">a</mi></mrow><mo id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.2.m2.1b"><apply id="S5.SS1.SSS3.p3.2.m2.1.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1"><times id="S5.SS1.SSS3.p3.2.m2.1.1.2.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.2"></times><apply id="S5.SS1.SSS3.p3.2.m2.1.1.3.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p3.2.m2.1.1.3.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p3.2.m2.1.1.3.2.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.3.2">𝑞</ci><ci id="S5.SS1.SSS3.p3.2.m2.1.1.3.3.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.3.3">𝜃</ci></apply><apply id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.2">𝑏</ci><ci id="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.1.1.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.2.m2.1c">q_{\theta}(b|a)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p3.2.m2.1d">italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b | italic_a )</annotation></semantics></math>, so the variational approximation <math alttext="q_{\theta}(b|a)" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p3.3.m3.1"><semantics id="S5.SS1.SSS3.p3.3.m3.1a"><mrow id="S5.SS1.SSS3.p3.3.m3.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.cmml"><msub id="S5.SS1.SSS3.p3.3.m3.1.1.3" xref="S5.SS1.SSS3.p3.3.m3.1.1.3.cmml"><mi id="S5.SS1.SSS3.p3.3.m3.1.1.3.2" xref="S5.SS1.SSS3.p3.3.m3.1.1.3.2.cmml">q</mi><mi id="S5.SS1.SSS3.p3.3.m3.1.1.3.3" xref="S5.SS1.SSS3.p3.3.m3.1.1.3.3.cmml">θ</mi></msub><mo id="S5.SS1.SSS3.p3.3.m3.1.1.2" xref="S5.SS1.SSS3.p3.3.m3.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p3.3.m3.1.1.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.cmml"><mo id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.2" stretchy="false" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.2" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.2.cmml">b</mi><mo fence="false" id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.3" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.3.cmml">a</mi></mrow><mo id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.3" stretchy="false" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.3.m3.1b"><apply id="S5.SS1.SSS3.p3.3.m3.1.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1"><times id="S5.SS1.SSS3.p3.3.m3.1.1.2.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.2"></times><apply id="S5.SS1.SSS3.p3.3.m3.1.1.3.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p3.3.m3.1.1.3.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p3.3.m3.1.1.3.2.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.3.2">𝑞</ci><ci id="S5.SS1.SSS3.p3.3.m3.1.1.3.3.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.3.3">𝜃</ci></apply><apply id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1"><csymbol cd="latexml" id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.2">𝑏</ci><ci id="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.1.1.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.3.m3.1c">q_{\theta}(b|a)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p3.3.m3.1d">italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b | italic_a )</annotation></semantics></math> can be optimized by maximizing the log-likelihood as defined in equation 2:</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p4">
<table class="ltx_equation ltx_eqn_table" id="S5.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="L_{\text{estimator}}(a,b)=\frac{1}{N}\sum_{i=1}^{N}\log q_{\theta}(b_{i}|a_{i})" class="ltx_Math" display="block" id="S5.E2.m1.3"><semantics id="S5.E2.m1.3a"><mrow id="S5.E2.m1.3.3" xref="S5.E2.m1.3.3.cmml"><mrow id="S5.E2.m1.3.3.3" xref="S5.E2.m1.3.3.3.cmml"><msub id="S5.E2.m1.3.3.3.2" xref="S5.E2.m1.3.3.3.2.cmml"><mi id="S5.E2.m1.3.3.3.2.2" xref="S5.E2.m1.3.3.3.2.2.cmml">L</mi><mtext id="S5.E2.m1.3.3.3.2.3" xref="S5.E2.m1.3.3.3.2.3a.cmml">estimator</mtext></msub><mo id="S5.E2.m1.3.3.3.1" xref="S5.E2.m1.3.3.3.1.cmml">⁢</mo><mrow id="S5.E2.m1.3.3.3.3.2" xref="S5.E2.m1.3.3.3.3.1.cmml"><mo id="S5.E2.m1.3.3.3.3.2.1" stretchy="false" xref="S5.E2.m1.3.3.3.3.1.cmml">(</mo><mi id="S5.E2.m1.1.1" xref="S5.E2.m1.1.1.cmml">a</mi><mo id="S5.E2.m1.3.3.3.3.2.2" xref="S5.E2.m1.3.3.3.3.1.cmml">,</mo><mi id="S5.E2.m1.2.2" xref="S5.E2.m1.2.2.cmml">b</mi><mo id="S5.E2.m1.3.3.3.3.2.3" stretchy="false" xref="S5.E2.m1.3.3.3.3.1.cmml">)</mo></mrow></mrow><mo id="S5.E2.m1.3.3.2" xref="S5.E2.m1.3.3.2.cmml">=</mo><mrow id="S5.E2.m1.3.3.1" xref="S5.E2.m1.3.3.1.cmml"><mfrac id="S5.E2.m1.3.3.1.3" xref="S5.E2.m1.3.3.1.3.cmml"><mn id="S5.E2.m1.3.3.1.3.2" xref="S5.E2.m1.3.3.1.3.2.cmml">1</mn><mi id="S5.E2.m1.3.3.1.3.3" xref="S5.E2.m1.3.3.1.3.3.cmml">N</mi></mfrac><mo id="S5.E2.m1.3.3.1.2" xref="S5.E2.m1.3.3.1.2.cmml">⁢</mo><mrow id="S5.E2.m1.3.3.1.1" xref="S5.E2.m1.3.3.1.1.cmml"><munderover id="S5.E2.m1.3.3.1.1.2" xref="S5.E2.m1.3.3.1.1.2.cmml"><mo id="S5.E2.m1.3.3.1.1.2.2.2" movablelimits="false" xref="S5.E2.m1.3.3.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E2.m1.3.3.1.1.2.2.3" xref="S5.E2.m1.3.3.1.1.2.2.3.cmml"><mi id="S5.E2.m1.3.3.1.1.2.2.3.2" xref="S5.E2.m1.3.3.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E2.m1.3.3.1.1.2.2.3.1" xref="S5.E2.m1.3.3.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E2.m1.3.3.1.1.2.2.3.3" xref="S5.E2.m1.3.3.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E2.m1.3.3.1.1.2.3" xref="S5.E2.m1.3.3.1.1.2.3.cmml">N</mi></munderover><mrow id="S5.E2.m1.3.3.1.1.1" xref="S5.E2.m1.3.3.1.1.1.cmml"><mrow id="S5.E2.m1.3.3.1.1.1.3" xref="S5.E2.m1.3.3.1.1.1.3.cmml"><mi id="S5.E2.m1.3.3.1.1.1.3.1" xref="S5.E2.m1.3.3.1.1.1.3.1.cmml">log</mi><mo id="S5.E2.m1.3.3.1.1.1.3a" lspace="0.167em" xref="S5.E2.m1.3.3.1.1.1.3.cmml">⁡</mo><msub id="S5.E2.m1.3.3.1.1.1.3.2" xref="S5.E2.m1.3.3.1.1.1.3.2.cmml"><mi id="S5.E2.m1.3.3.1.1.1.3.2.2" xref="S5.E2.m1.3.3.1.1.1.3.2.2.cmml">q</mi><mi id="S5.E2.m1.3.3.1.1.1.3.2.3" xref="S5.E2.m1.3.3.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="S5.E2.m1.3.3.1.1.1.2" xref="S5.E2.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S5.E2.m1.3.3.1.1.1.1.1" xref="S5.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S5.E2.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="S5.E2.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E2.m1.3.3.1.1.1.1.1.1" xref="S5.E2.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S5.E2.m1.3.3.1.1.1.1.1.1.2" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S5.E2.m1.3.3.1.1.1.1.1.1.2.2" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml">b</mi><mi id="S5.E2.m1.3.3.1.1.1.1.1.1.2.3" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S5.E2.m1.3.3.1.1.1.1.1.1.1" xref="S5.E2.m1.3.3.1.1.1.1.1.1.1.cmml">|</mo><msub id="S5.E2.m1.3.3.1.1.1.1.1.1.3" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S5.E2.m1.3.3.1.1.1.1.1.1.3.2" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml">a</mi><mi id="S5.E2.m1.3.3.1.1.1.1.1.1.3.3" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E2.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="S5.E2.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.3b"><apply id="S5.E2.m1.3.3.cmml" xref="S5.E2.m1.3.3"><eq id="S5.E2.m1.3.3.2.cmml" xref="S5.E2.m1.3.3.2"></eq><apply id="S5.E2.m1.3.3.3.cmml" xref="S5.E2.m1.3.3.3"><times id="S5.E2.m1.3.3.3.1.cmml" xref="S5.E2.m1.3.3.3.1"></times><apply id="S5.E2.m1.3.3.3.2.cmml" xref="S5.E2.m1.3.3.3.2"><csymbol cd="ambiguous" id="S5.E2.m1.3.3.3.2.1.cmml" xref="S5.E2.m1.3.3.3.2">subscript</csymbol><ci id="S5.E2.m1.3.3.3.2.2.cmml" xref="S5.E2.m1.3.3.3.2.2">𝐿</ci><ci id="S5.E2.m1.3.3.3.2.3a.cmml" xref="S5.E2.m1.3.3.3.2.3"><mtext id="S5.E2.m1.3.3.3.2.3.cmml" mathsize="70%" xref="S5.E2.m1.3.3.3.2.3">estimator</mtext></ci></apply><interval closure="open" id="S5.E2.m1.3.3.3.3.1.cmml" xref="S5.E2.m1.3.3.3.3.2"><ci id="S5.E2.m1.1.1.cmml" xref="S5.E2.m1.1.1">𝑎</ci><ci id="S5.E2.m1.2.2.cmml" xref="S5.E2.m1.2.2">𝑏</ci></interval></apply><apply id="S5.E2.m1.3.3.1.cmml" xref="S5.E2.m1.3.3.1"><times id="S5.E2.m1.3.3.1.2.cmml" xref="S5.E2.m1.3.3.1.2"></times><apply id="S5.E2.m1.3.3.1.3.cmml" xref="S5.E2.m1.3.3.1.3"><divide id="S5.E2.m1.3.3.1.3.1.cmml" xref="S5.E2.m1.3.3.1.3"></divide><cn id="S5.E2.m1.3.3.1.3.2.cmml" type="integer" xref="S5.E2.m1.3.3.1.3.2">1</cn><ci id="S5.E2.m1.3.3.1.3.3.cmml" xref="S5.E2.m1.3.3.1.3.3">𝑁</ci></apply><apply id="S5.E2.m1.3.3.1.1.cmml" xref="S5.E2.m1.3.3.1.1"><apply id="S5.E2.m1.3.3.1.1.2.cmml" xref="S5.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.3.3.1.1.2.1.cmml" xref="S5.E2.m1.3.3.1.1.2">superscript</csymbol><apply id="S5.E2.m1.3.3.1.1.2.2.cmml" xref="S5.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.3.3.1.1.2.2.1.cmml" xref="S5.E2.m1.3.3.1.1.2">subscript</csymbol><sum id="S5.E2.m1.3.3.1.1.2.2.2.cmml" xref="S5.E2.m1.3.3.1.1.2.2.2"></sum><apply id="S5.E2.m1.3.3.1.1.2.2.3.cmml" xref="S5.E2.m1.3.3.1.1.2.2.3"><eq id="S5.E2.m1.3.3.1.1.2.2.3.1.cmml" xref="S5.E2.m1.3.3.1.1.2.2.3.1"></eq><ci id="S5.E2.m1.3.3.1.1.2.2.3.2.cmml" xref="S5.E2.m1.3.3.1.1.2.2.3.2">𝑖</ci><cn id="S5.E2.m1.3.3.1.1.2.2.3.3.cmml" type="integer" xref="S5.E2.m1.3.3.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E2.m1.3.3.1.1.2.3.cmml" xref="S5.E2.m1.3.3.1.1.2.3">𝑁</ci></apply><apply id="S5.E2.m1.3.3.1.1.1.cmml" xref="S5.E2.m1.3.3.1.1.1"><times id="S5.E2.m1.3.3.1.1.1.2.cmml" xref="S5.E2.m1.3.3.1.1.1.2"></times><apply id="S5.E2.m1.3.3.1.1.1.3.cmml" xref="S5.E2.m1.3.3.1.1.1.3"><log id="S5.E2.m1.3.3.1.1.1.3.1.cmml" xref="S5.E2.m1.3.3.1.1.1.3.1"></log><apply id="S5.E2.m1.3.3.1.1.1.3.2.cmml" xref="S5.E2.m1.3.3.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E2.m1.3.3.1.1.1.3.2.1.cmml" xref="S5.E2.m1.3.3.1.1.1.3.2">subscript</csymbol><ci id="S5.E2.m1.3.3.1.1.1.3.2.2.cmml" xref="S5.E2.m1.3.3.1.1.1.3.2.2">𝑞</ci><ci id="S5.E2.m1.3.3.1.1.1.3.2.3.cmml" xref="S5.E2.m1.3.3.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="S5.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S5.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.1">conditional</csymbol><apply id="S5.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2.2">𝑏</ci><ci id="S5.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S5.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3.2">𝑎</ci><ci id="S5.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S5.E2.m1.3.3.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.3c">L_{\text{estimator}}(a,b)=\frac{1}{N}\sum_{i=1}^{N}\log q_{\theta}(b_{i}|a_{i})</annotation><annotation encoding="application/x-llamapun" id="S5.E2.m1.3d">italic_L start_POSTSUBSCRIPT estimator end_POSTSUBSCRIPT ( italic_a , italic_b ) = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_log italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p5">
<p class="ltx_p" id="S5.SS1.SSS3.p5.1">Thus the mutual information loss is can be seen in equation 3:</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p6">
<table class="ltx_equation ltx_eqn_table" id="S5.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\text{MILOSS}=L_{v}^{CLUB}(S_{a}+S_{b})+L_{\text{estimator}}(S_{a}+S_{b},S_{c})" class="ltx_Math" display="block" id="S5.E3.m1.3"><semantics id="S5.E3.m1.3a"><mrow id="S5.E3.m1.3.3" xref="S5.E3.m1.3.3.cmml"><mtext id="S5.E3.m1.3.3.5" xref="S5.E3.m1.3.3.5a.cmml">MILOSS</mtext><mo id="S5.E3.m1.3.3.4" xref="S5.E3.m1.3.3.4.cmml">=</mo><mrow id="S5.E3.m1.3.3.3" xref="S5.E3.m1.3.3.3.cmml"><mrow id="S5.E3.m1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.cmml"><msubsup id="S5.E3.m1.1.1.1.1.3" xref="S5.E3.m1.1.1.1.1.3.cmml"><mi id="S5.E3.m1.1.1.1.1.3.2.2" xref="S5.E3.m1.1.1.1.1.3.2.2.cmml">L</mi><mi id="S5.E3.m1.1.1.1.1.3.2.3" xref="S5.E3.m1.1.1.1.1.3.2.3.cmml">v</mi><mrow id="S5.E3.m1.1.1.1.1.3.3" xref="S5.E3.m1.1.1.1.1.3.3.cmml"><mi id="S5.E3.m1.1.1.1.1.3.3.2" xref="S5.E3.m1.1.1.1.1.3.3.2.cmml">C</mi><mo id="S5.E3.m1.1.1.1.1.3.3.1" xref="S5.E3.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.3.3.3" xref="S5.E3.m1.1.1.1.1.3.3.3.cmml">L</mi><mo id="S5.E3.m1.1.1.1.1.3.3.1a" xref="S5.E3.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.3.3.4" xref="S5.E3.m1.1.1.1.1.3.3.4.cmml">U</mi><mo id="S5.E3.m1.1.1.1.1.3.3.1b" xref="S5.E3.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S5.E3.m1.1.1.1.1.3.3.5" xref="S5.E3.m1.1.1.1.1.3.3.5.cmml">B</mi></mrow></msubsup><mo id="S5.E3.m1.1.1.1.1.2" xref="S5.E3.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E3.m1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml"><mo id="S5.E3.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E3.m1.1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml"><msub id="S5.E3.m1.1.1.1.1.1.1.1.2" xref="S5.E3.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E3.m1.1.1.1.1.1.1.1.2.2" xref="S5.E3.m1.1.1.1.1.1.1.1.2.2.cmml">S</mi><mi id="S5.E3.m1.1.1.1.1.1.1.1.2.3" xref="S5.E3.m1.1.1.1.1.1.1.1.2.3.cmml">a</mi></msub><mo id="S5.E3.m1.1.1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S5.E3.m1.1.1.1.1.1.1.1.3" xref="S5.E3.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S5.E3.m1.1.1.1.1.1.1.1.3.2" xref="S5.E3.m1.1.1.1.1.1.1.1.3.2.cmml">S</mi><mi id="S5.E3.m1.1.1.1.1.1.1.1.3.3" xref="S5.E3.m1.1.1.1.1.1.1.1.3.3.cmml">b</mi></msub></mrow><mo id="S5.E3.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E3.m1.3.3.3.4" xref="S5.E3.m1.3.3.3.4.cmml">+</mo><mrow id="S5.E3.m1.3.3.3.3" xref="S5.E3.m1.3.3.3.3.cmml"><msub id="S5.E3.m1.3.3.3.3.4" xref="S5.E3.m1.3.3.3.3.4.cmml"><mi id="S5.E3.m1.3.3.3.3.4.2" xref="S5.E3.m1.3.3.3.3.4.2.cmml">L</mi><mtext id="S5.E3.m1.3.3.3.3.4.3" xref="S5.E3.m1.3.3.3.3.4.3a.cmml">estimator</mtext></msub><mo id="S5.E3.m1.3.3.3.3.3" xref="S5.E3.m1.3.3.3.3.3.cmml">⁢</mo><mrow id="S5.E3.m1.3.3.3.3.2.2" xref="S5.E3.m1.3.3.3.3.2.3.cmml"><mo id="S5.E3.m1.3.3.3.3.2.2.3" stretchy="false" xref="S5.E3.m1.3.3.3.3.2.3.cmml">(</mo><mrow id="S5.E3.m1.2.2.2.2.1.1.1" xref="S5.E3.m1.2.2.2.2.1.1.1.cmml"><msub id="S5.E3.m1.2.2.2.2.1.1.1.2" xref="S5.E3.m1.2.2.2.2.1.1.1.2.cmml"><mi id="S5.E3.m1.2.2.2.2.1.1.1.2.2" xref="S5.E3.m1.2.2.2.2.1.1.1.2.2.cmml">S</mi><mi id="S5.E3.m1.2.2.2.2.1.1.1.2.3" xref="S5.E3.m1.2.2.2.2.1.1.1.2.3.cmml">a</mi></msub><mo id="S5.E3.m1.2.2.2.2.1.1.1.1" xref="S5.E3.m1.2.2.2.2.1.1.1.1.cmml">+</mo><msub id="S5.E3.m1.2.2.2.2.1.1.1.3" xref="S5.E3.m1.2.2.2.2.1.1.1.3.cmml"><mi id="S5.E3.m1.2.2.2.2.1.1.1.3.2" xref="S5.E3.m1.2.2.2.2.1.1.1.3.2.cmml">S</mi><mi id="S5.E3.m1.2.2.2.2.1.1.1.3.3" xref="S5.E3.m1.2.2.2.2.1.1.1.3.3.cmml">b</mi></msub></mrow><mo id="S5.E3.m1.3.3.3.3.2.2.4" xref="S5.E3.m1.3.3.3.3.2.3.cmml">,</mo><msub id="S5.E3.m1.3.3.3.3.2.2.2" xref="S5.E3.m1.3.3.3.3.2.2.2.cmml"><mi id="S5.E3.m1.3.3.3.3.2.2.2.2" xref="S5.E3.m1.3.3.3.3.2.2.2.2.cmml">S</mi><mi id="S5.E3.m1.3.3.3.3.2.2.2.3" xref="S5.E3.m1.3.3.3.3.2.2.2.3.cmml">c</mi></msub><mo id="S5.E3.m1.3.3.3.3.2.2.5" stretchy="false" xref="S5.E3.m1.3.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E3.m1.3b"><apply id="S5.E3.m1.3.3.cmml" xref="S5.E3.m1.3.3"><eq id="S5.E3.m1.3.3.4.cmml" xref="S5.E3.m1.3.3.4"></eq><ci id="S5.E3.m1.3.3.5a.cmml" xref="S5.E3.m1.3.3.5"><mtext id="S5.E3.m1.3.3.5.cmml" xref="S5.E3.m1.3.3.5">MILOSS</mtext></ci><apply id="S5.E3.m1.3.3.3.cmml" xref="S5.E3.m1.3.3.3"><plus id="S5.E3.m1.3.3.3.4.cmml" xref="S5.E3.m1.3.3.3.4"></plus><apply id="S5.E3.m1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1"><times id="S5.E3.m1.1.1.1.1.2.cmml" xref="S5.E3.m1.1.1.1.1.2"></times><apply id="S5.E3.m1.1.1.1.1.3.cmml" xref="S5.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.3.1.cmml" xref="S5.E3.m1.1.1.1.1.3">superscript</csymbol><apply id="S5.E3.m1.1.1.1.1.3.2.cmml" xref="S5.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.3.2.1.cmml" xref="S5.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.3.2.2.cmml" xref="S5.E3.m1.1.1.1.1.3.2.2">𝐿</ci><ci id="S5.E3.m1.1.1.1.1.3.2.3.cmml" xref="S5.E3.m1.1.1.1.1.3.2.3">𝑣</ci></apply><apply id="S5.E3.m1.1.1.1.1.3.3.cmml" xref="S5.E3.m1.1.1.1.1.3.3"><times id="S5.E3.m1.1.1.1.1.3.3.1.cmml" xref="S5.E3.m1.1.1.1.1.3.3.1"></times><ci id="S5.E3.m1.1.1.1.1.3.3.2.cmml" xref="S5.E3.m1.1.1.1.1.3.3.2">𝐶</ci><ci id="S5.E3.m1.1.1.1.1.3.3.3.cmml" xref="S5.E3.m1.1.1.1.1.3.3.3">𝐿</ci><ci id="S5.E3.m1.1.1.1.1.3.3.4.cmml" xref="S5.E3.m1.1.1.1.1.3.3.4">𝑈</ci><ci id="S5.E3.m1.1.1.1.1.3.3.5.cmml" xref="S5.E3.m1.1.1.1.1.3.3.5">𝐵</ci></apply></apply><apply id="S5.E3.m1.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><plus id="S5.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.1"></plus><apply id="S5.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.2.2">𝑆</ci><ci id="S5.E3.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.2.3">𝑎</ci></apply><apply id="S5.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.3.2">𝑆</ci><ci id="S5.E3.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.3.3">𝑏</ci></apply></apply></apply><apply id="S5.E3.m1.3.3.3.3.cmml" xref="S5.E3.m1.3.3.3.3"><times id="S5.E3.m1.3.3.3.3.3.cmml" xref="S5.E3.m1.3.3.3.3.3"></times><apply id="S5.E3.m1.3.3.3.3.4.cmml" xref="S5.E3.m1.3.3.3.3.4"><csymbol cd="ambiguous" id="S5.E3.m1.3.3.3.3.4.1.cmml" xref="S5.E3.m1.3.3.3.3.4">subscript</csymbol><ci id="S5.E3.m1.3.3.3.3.4.2.cmml" xref="S5.E3.m1.3.3.3.3.4.2">𝐿</ci><ci id="S5.E3.m1.3.3.3.3.4.3a.cmml" xref="S5.E3.m1.3.3.3.3.4.3"><mtext id="S5.E3.m1.3.3.3.3.4.3.cmml" mathsize="70%" xref="S5.E3.m1.3.3.3.3.4.3">estimator</mtext></ci></apply><interval closure="open" id="S5.E3.m1.3.3.3.3.2.3.cmml" xref="S5.E3.m1.3.3.3.3.2.2"><apply id="S5.E3.m1.2.2.2.2.1.1.1.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1"><plus id="S5.E3.m1.2.2.2.2.1.1.1.1.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.1"></plus><apply id="S5.E3.m1.2.2.2.2.1.1.1.2.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E3.m1.2.2.2.2.1.1.1.2.1.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.2">subscript</csymbol><ci id="S5.E3.m1.2.2.2.2.1.1.1.2.2.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.2.2">𝑆</ci><ci id="S5.E3.m1.2.2.2.2.1.1.1.2.3.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.2.3">𝑎</ci></apply><apply id="S5.E3.m1.2.2.2.2.1.1.1.3.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E3.m1.2.2.2.2.1.1.1.3.1.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.3">subscript</csymbol><ci id="S5.E3.m1.2.2.2.2.1.1.1.3.2.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.3.2">𝑆</ci><ci id="S5.E3.m1.2.2.2.2.1.1.1.3.3.cmml" xref="S5.E3.m1.2.2.2.2.1.1.1.3.3">𝑏</ci></apply></apply><apply id="S5.E3.m1.3.3.3.3.2.2.2.cmml" xref="S5.E3.m1.3.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.E3.m1.3.3.3.3.2.2.2.1.cmml" xref="S5.E3.m1.3.3.3.3.2.2.2">subscript</csymbol><ci id="S5.E3.m1.3.3.3.3.2.2.2.2.cmml" xref="S5.E3.m1.3.3.3.3.2.2.2.2">𝑆</ci><ci id="S5.E3.m1.3.3.3.3.2.2.2.3.cmml" xref="S5.E3.m1.3.3.3.3.2.2.2.3">𝑐</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E3.m1.3c">\text{MILOSS}=L_{v}^{CLUB}(S_{a}+S_{b})+L_{\text{estimator}}(S_{a}+S_{b},S_{c})</annotation><annotation encoding="application/x-llamapun" id="S5.E3.m1.3d">MILOSS = italic_L start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C italic_L italic_U italic_B end_POSTSUPERSCRIPT ( italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT + italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ) + italic_L start_POSTSUBSCRIPT estimator end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT + italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p7">
<p class="ltx_p" id="S5.SS1.SSS3.p7.5">Here, after optimizing the mutual information between the modality-specific information and the modality-common information, we utilize dense fusion<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib83" title="">83</a>]</cite> to allow for denser interaction between modalities. Instead of directly connecting a prediction classifier on top of the fused representation <math alttext="S_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p7.1.m1.1"><semantics id="S5.SS1.SSS3.p7.1.m1.1a"><msub id="S5.SS1.SSS3.p7.1.m1.1.1" xref="S5.SS1.SSS3.p7.1.m1.1.1.cmml"><mi id="S5.SS1.SSS3.p7.1.m1.1.1.2" xref="S5.SS1.SSS3.p7.1.m1.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p7.1.m1.1.1.3" xref="S5.SS1.SSS3.p7.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p7.1.m1.1b"><apply id="S5.SS1.SSS3.p7.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.1.m1.1.1.1.cmml" xref="S5.SS1.SSS3.p7.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p7.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p7.1.m1.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p7.1.m1.1.1.3.cmml" xref="S5.SS1.SSS3.p7.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p7.1.m1.1c">S_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p7.1.m1.1d">italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, we instead learn deeper representations of the image and non-image features and add skip connections to concatenate with the fused representation to form a final fused embedding, <math alttext="h_{a}=f_{a}(S_{a})" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p7.2.m2.1"><semantics id="S5.SS1.SSS3.p7.2.m2.1a"><mrow id="S5.SS1.SSS3.p7.2.m2.1.1" xref="S5.SS1.SSS3.p7.2.m2.1.1.cmml"><msub id="S5.SS1.SSS3.p7.2.m2.1.1.3" xref="S5.SS1.SSS3.p7.2.m2.1.1.3.cmml"><mi id="S5.SS1.SSS3.p7.2.m2.1.1.3.2" xref="S5.SS1.SSS3.p7.2.m2.1.1.3.2.cmml">h</mi><mi id="S5.SS1.SSS3.p7.2.m2.1.1.3.3" xref="S5.SS1.SSS3.p7.2.m2.1.1.3.3.cmml">a</mi></msub><mo id="S5.SS1.SSS3.p7.2.m2.1.1.2" xref="S5.SS1.SSS3.p7.2.m2.1.1.2.cmml">=</mo><mrow id="S5.SS1.SSS3.p7.2.m2.1.1.1" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.cmml"><msub id="S5.SS1.SSS3.p7.2.m2.1.1.1.3" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3.cmml"><mi id="S5.SS1.SSS3.p7.2.m2.1.1.1.3.2" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3.2.cmml">f</mi><mi id="S5.SS1.SSS3.p7.2.m2.1.1.1.3.3" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3.3.cmml">a</mi></msub><mo id="S5.SS1.SSS3.p7.2.m2.1.1.1.2" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.cmml"><mo id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.2" stretchy="false" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.2" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.3" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.3" stretchy="false" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p7.2.m2.1b"><apply id="S5.SS1.SSS3.p7.2.m2.1.1.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1"><eq id="S5.SS1.SSS3.p7.2.m2.1.1.2.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.2"></eq><apply id="S5.SS1.SSS3.p7.2.m2.1.1.3.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.2.m2.1.1.3.1.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p7.2.m2.1.1.3.2.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.3.2">ℎ</ci><ci id="S5.SS1.SSS3.p7.2.m2.1.1.3.3.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.3.3">𝑎</ci></apply><apply id="S5.SS1.SSS3.p7.2.m2.1.1.1.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1"><times id="S5.SS1.SSS3.p7.2.m2.1.1.1.2.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.2"></times><apply id="S5.SS1.SSS3.p7.2.m2.1.1.1.3.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.2.m2.1.1.1.3.1.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p7.2.m2.1.1.1.3.2.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3.2">𝑓</ci><ci id="S5.SS1.SSS3.p7.2.m2.1.1.1.3.3.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.3.3">𝑎</ci></apply><apply id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p7.2.m2.1.1.1.1.1.1.3">𝑎</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p7.2.m2.1c">h_{a}=f_{a}(S_{a})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p7.2.m2.1d">italic_h start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT )</annotation></semantics></math> And <math alttext="h_{b}=f_{b}(S_{b})" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p7.3.m3.1"><semantics id="S5.SS1.SSS3.p7.3.m3.1a"><mrow id="S5.SS1.SSS3.p7.3.m3.1.1" xref="S5.SS1.SSS3.p7.3.m3.1.1.cmml"><msub id="S5.SS1.SSS3.p7.3.m3.1.1.3" xref="S5.SS1.SSS3.p7.3.m3.1.1.3.cmml"><mi id="S5.SS1.SSS3.p7.3.m3.1.1.3.2" xref="S5.SS1.SSS3.p7.3.m3.1.1.3.2.cmml">h</mi><mi id="S5.SS1.SSS3.p7.3.m3.1.1.3.3" xref="S5.SS1.SSS3.p7.3.m3.1.1.3.3.cmml">b</mi></msub><mo id="S5.SS1.SSS3.p7.3.m3.1.1.2" xref="S5.SS1.SSS3.p7.3.m3.1.1.2.cmml">=</mo><mrow id="S5.SS1.SSS3.p7.3.m3.1.1.1" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.cmml"><msub id="S5.SS1.SSS3.p7.3.m3.1.1.1.3" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3.cmml"><mi id="S5.SS1.SSS3.p7.3.m3.1.1.1.3.2" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3.2.cmml">f</mi><mi id="S5.SS1.SSS3.p7.3.m3.1.1.1.3.3" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3.3.cmml">b</mi></msub><mo id="S5.SS1.SSS3.p7.3.m3.1.1.1.2" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.cmml"><mo id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.2" stretchy="false" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.cmml">(</mo><msub id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.2" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.2.cmml">S</mi><mi id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.3" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.3.cmml">b</mi></msub><mo id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.3" stretchy="false" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p7.3.m3.1b"><apply id="S5.SS1.SSS3.p7.3.m3.1.1.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1"><eq id="S5.SS1.SSS3.p7.3.m3.1.1.2.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.2"></eq><apply id="S5.SS1.SSS3.p7.3.m3.1.1.3.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.3.m3.1.1.3.1.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p7.3.m3.1.1.3.2.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.3.2">ℎ</ci><ci id="S5.SS1.SSS3.p7.3.m3.1.1.3.3.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.3.3">𝑏</ci></apply><apply id="S5.SS1.SSS3.p7.3.m3.1.1.1.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1"><times id="S5.SS1.SSS3.p7.3.m3.1.1.1.2.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.2"></times><apply id="S5.SS1.SSS3.p7.3.m3.1.1.1.3.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.3.m3.1.1.1.3.1.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3">subscript</csymbol><ci id="S5.SS1.SSS3.p7.3.m3.1.1.1.3.2.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3.2">𝑓</ci><ci id="S5.SS1.SSS3.p7.3.m3.1.1.1.3.3.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.3.3">𝑏</ci></apply><apply id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.2">𝑆</ci><ci id="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p7.3.m3.1.1.1.1.1.1.3">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p7.3.m3.1c">h_{b}=f_{b}(S_{b})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p7.3.m3.1d">italic_h start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT )</annotation></semantics></math>, where <math alttext="f_{a}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p7.4.m4.1"><semantics id="S5.SS1.SSS3.p7.4.m4.1a"><msub id="S5.SS1.SSS3.p7.4.m4.1.1" xref="S5.SS1.SSS3.p7.4.m4.1.1.cmml"><mi id="S5.SS1.SSS3.p7.4.m4.1.1.2" xref="S5.SS1.SSS3.p7.4.m4.1.1.2.cmml">f</mi><mi id="S5.SS1.SSS3.p7.4.m4.1.1.3" xref="S5.SS1.SSS3.p7.4.m4.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p7.4.m4.1b"><apply id="S5.SS1.SSS3.p7.4.m4.1.1.cmml" xref="S5.SS1.SSS3.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.4.m4.1.1.1.cmml" xref="S5.SS1.SSS3.p7.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p7.4.m4.1.1.2.cmml" xref="S5.SS1.SSS3.p7.4.m4.1.1.2">𝑓</ci><ci id="S5.SS1.SSS3.p7.4.m4.1.1.3.cmml" xref="S5.SS1.SSS3.p7.4.m4.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p7.4.m4.1c">f_{a}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p7.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f_{b}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p7.5.m5.1"><semantics id="S5.SS1.SSS3.p7.5.m5.1a"><msub id="S5.SS1.SSS3.p7.5.m5.1.1" xref="S5.SS1.SSS3.p7.5.m5.1.1.cmml"><mi id="S5.SS1.SSS3.p7.5.m5.1.1.2" xref="S5.SS1.SSS3.p7.5.m5.1.1.2.cmml">f</mi><mi id="S5.SS1.SSS3.p7.5.m5.1.1.3" xref="S5.SS1.SSS3.p7.5.m5.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p7.5.m5.1b"><apply id="S5.SS1.SSS3.p7.5.m5.1.1.cmml" xref="S5.SS1.SSS3.p7.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p7.5.m5.1.1.1.cmml" xref="S5.SS1.SSS3.p7.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p7.5.m5.1.1.2.cmml" xref="S5.SS1.SSS3.p7.5.m5.1.1.2">𝑓</ci><ci id="S5.SS1.SSS3.p7.5.m5.1.1.3.cmml" xref="S5.SS1.SSS3.p7.5.m5.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p7.5.m5.1c">f_{b}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p7.5.m5.1d">italic_f start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> are fully-connected layers. representation that not only aggregates the modality-specific features, but also incorporates the modality common representation from the previous stage of the network given by the equation 4:</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p8">
<table class="ltx_equation ltx_eqn_table" id="S5.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="h_{final}=concat(h_{a},S_{c},h_{b})" class="ltx_Math" display="block" id="S5.E4.m1.3"><semantics id="S5.E4.m1.3a"><mrow id="S5.E4.m1.3.3" xref="S5.E4.m1.3.3.cmml"><msub id="S5.E4.m1.3.3.5" xref="S5.E4.m1.3.3.5.cmml"><mi id="S5.E4.m1.3.3.5.2" xref="S5.E4.m1.3.3.5.2.cmml">h</mi><mrow id="S5.E4.m1.3.3.5.3" xref="S5.E4.m1.3.3.5.3.cmml"><mi id="S5.E4.m1.3.3.5.3.2" xref="S5.E4.m1.3.3.5.3.2.cmml">f</mi><mo id="S5.E4.m1.3.3.5.3.1" xref="S5.E4.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S5.E4.m1.3.3.5.3.3" xref="S5.E4.m1.3.3.5.3.3.cmml">i</mi><mo id="S5.E4.m1.3.3.5.3.1a" xref="S5.E4.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S5.E4.m1.3.3.5.3.4" xref="S5.E4.m1.3.3.5.3.4.cmml">n</mi><mo id="S5.E4.m1.3.3.5.3.1b" xref="S5.E4.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S5.E4.m1.3.3.5.3.5" xref="S5.E4.m1.3.3.5.3.5.cmml">a</mi><mo id="S5.E4.m1.3.3.5.3.1c" xref="S5.E4.m1.3.3.5.3.1.cmml">⁢</mo><mi id="S5.E4.m1.3.3.5.3.6" xref="S5.E4.m1.3.3.5.3.6.cmml">l</mi></mrow></msub><mo id="S5.E4.m1.3.3.4" xref="S5.E4.m1.3.3.4.cmml">=</mo><mrow id="S5.E4.m1.3.3.3" xref="S5.E4.m1.3.3.3.cmml"><mi id="S5.E4.m1.3.3.3.5" xref="S5.E4.m1.3.3.3.5.cmml">c</mi><mo id="S5.E4.m1.3.3.3.4" xref="S5.E4.m1.3.3.3.4.cmml">⁢</mo><mi id="S5.E4.m1.3.3.3.6" xref="S5.E4.m1.3.3.3.6.cmml">o</mi><mo id="S5.E4.m1.3.3.3.4a" xref="S5.E4.m1.3.3.3.4.cmml">⁢</mo><mi id="S5.E4.m1.3.3.3.7" xref="S5.E4.m1.3.3.3.7.cmml">n</mi><mo id="S5.E4.m1.3.3.3.4b" xref="S5.E4.m1.3.3.3.4.cmml">⁢</mo><mi id="S5.E4.m1.3.3.3.8" xref="S5.E4.m1.3.3.3.8.cmml">c</mi><mo id="S5.E4.m1.3.3.3.4c" xref="S5.E4.m1.3.3.3.4.cmml">⁢</mo><mi id="S5.E4.m1.3.3.3.9" xref="S5.E4.m1.3.3.3.9.cmml">a</mi><mo id="S5.E4.m1.3.3.3.4d" xref="S5.E4.m1.3.3.3.4.cmml">⁢</mo><mi id="S5.E4.m1.3.3.3.10" xref="S5.E4.m1.3.3.3.10.cmml">t</mi><mo id="S5.E4.m1.3.3.3.4e" xref="S5.E4.m1.3.3.3.4.cmml">⁢</mo><mrow id="S5.E4.m1.3.3.3.3.3" xref="S5.E4.m1.3.3.3.3.4.cmml"><mo id="S5.E4.m1.3.3.3.3.3.4" stretchy="false" xref="S5.E4.m1.3.3.3.3.4.cmml">(</mo><msub id="S5.E4.m1.1.1.1.1.1.1" xref="S5.E4.m1.1.1.1.1.1.1.cmml"><mi id="S5.E4.m1.1.1.1.1.1.1.2" xref="S5.E4.m1.1.1.1.1.1.1.2.cmml">h</mi><mi id="S5.E4.m1.1.1.1.1.1.1.3" xref="S5.E4.m1.1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S5.E4.m1.3.3.3.3.3.5" xref="S5.E4.m1.3.3.3.3.4.cmml">,</mo><msub id="S5.E4.m1.2.2.2.2.2.2" xref="S5.E4.m1.2.2.2.2.2.2.cmml"><mi id="S5.E4.m1.2.2.2.2.2.2.2" xref="S5.E4.m1.2.2.2.2.2.2.2.cmml">S</mi><mi id="S5.E4.m1.2.2.2.2.2.2.3" xref="S5.E4.m1.2.2.2.2.2.2.3.cmml">c</mi></msub><mo id="S5.E4.m1.3.3.3.3.3.6" xref="S5.E4.m1.3.3.3.3.4.cmml">,</mo><msub id="S5.E4.m1.3.3.3.3.3.3" xref="S5.E4.m1.3.3.3.3.3.3.cmml"><mi id="S5.E4.m1.3.3.3.3.3.3.2" xref="S5.E4.m1.3.3.3.3.3.3.2.cmml">h</mi><mi id="S5.E4.m1.3.3.3.3.3.3.3" xref="S5.E4.m1.3.3.3.3.3.3.3.cmml">b</mi></msub><mo id="S5.E4.m1.3.3.3.3.3.7" stretchy="false" xref="S5.E4.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.3b"><apply id="S5.E4.m1.3.3.cmml" xref="S5.E4.m1.3.3"><eq id="S5.E4.m1.3.3.4.cmml" xref="S5.E4.m1.3.3.4"></eq><apply id="S5.E4.m1.3.3.5.cmml" xref="S5.E4.m1.3.3.5"><csymbol cd="ambiguous" id="S5.E4.m1.3.3.5.1.cmml" xref="S5.E4.m1.3.3.5">subscript</csymbol><ci id="S5.E4.m1.3.3.5.2.cmml" xref="S5.E4.m1.3.3.5.2">ℎ</ci><apply id="S5.E4.m1.3.3.5.3.cmml" xref="S5.E4.m1.3.3.5.3"><times id="S5.E4.m1.3.3.5.3.1.cmml" xref="S5.E4.m1.3.3.5.3.1"></times><ci id="S5.E4.m1.3.3.5.3.2.cmml" xref="S5.E4.m1.3.3.5.3.2">𝑓</ci><ci id="S5.E4.m1.3.3.5.3.3.cmml" xref="S5.E4.m1.3.3.5.3.3">𝑖</ci><ci id="S5.E4.m1.3.3.5.3.4.cmml" xref="S5.E4.m1.3.3.5.3.4">𝑛</ci><ci id="S5.E4.m1.3.3.5.3.5.cmml" xref="S5.E4.m1.3.3.5.3.5">𝑎</ci><ci id="S5.E4.m1.3.3.5.3.6.cmml" xref="S5.E4.m1.3.3.5.3.6">𝑙</ci></apply></apply><apply id="S5.E4.m1.3.3.3.cmml" xref="S5.E4.m1.3.3.3"><times id="S5.E4.m1.3.3.3.4.cmml" xref="S5.E4.m1.3.3.3.4"></times><ci id="S5.E4.m1.3.3.3.5.cmml" xref="S5.E4.m1.3.3.3.5">𝑐</ci><ci id="S5.E4.m1.3.3.3.6.cmml" xref="S5.E4.m1.3.3.3.6">𝑜</ci><ci id="S5.E4.m1.3.3.3.7.cmml" xref="S5.E4.m1.3.3.3.7">𝑛</ci><ci id="S5.E4.m1.3.3.3.8.cmml" xref="S5.E4.m1.3.3.3.8">𝑐</ci><ci id="S5.E4.m1.3.3.3.9.cmml" xref="S5.E4.m1.3.3.3.9">𝑎</ci><ci id="S5.E4.m1.3.3.3.10.cmml" xref="S5.E4.m1.3.3.3.10">𝑡</ci><vector id="S5.E4.m1.3.3.3.3.4.cmml" xref="S5.E4.m1.3.3.3.3.3"><apply id="S5.E4.m1.1.1.1.1.1.1.cmml" xref="S5.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E4.m1.1.1.1.1.1.1.1.cmml" xref="S5.E4.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E4.m1.1.1.1.1.1.1.2.cmml" xref="S5.E4.m1.1.1.1.1.1.1.2">ℎ</ci><ci id="S5.E4.m1.1.1.1.1.1.1.3.cmml" xref="S5.E4.m1.1.1.1.1.1.1.3">𝑎</ci></apply><apply id="S5.E4.m1.2.2.2.2.2.2.cmml" xref="S5.E4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.2.2.2.2.1.cmml" xref="S5.E4.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S5.E4.m1.2.2.2.2.2.2.2.cmml" xref="S5.E4.m1.2.2.2.2.2.2.2">𝑆</ci><ci id="S5.E4.m1.2.2.2.2.2.2.3.cmml" xref="S5.E4.m1.2.2.2.2.2.2.3">𝑐</ci></apply><apply id="S5.E4.m1.3.3.3.3.3.3.cmml" xref="S5.E4.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S5.E4.m1.3.3.3.3.3.3.1.cmml" xref="S5.E4.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S5.E4.m1.3.3.3.3.3.3.2.cmml" xref="S5.E4.m1.3.3.3.3.3.3.2">ℎ</ci><ci id="S5.E4.m1.3.3.3.3.3.3.3.cmml" xref="S5.E4.m1.3.3.3.3.3.3.3">𝑏</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.3c">h_{final}=concat(h_{a},S_{c},h_{b})</annotation><annotation encoding="application/x-llamapun" id="S5.E4.m1.3d">italic_h start_POSTSUBSCRIPT italic_f italic_i italic_n italic_a italic_l end_POSTSUBSCRIPT = italic_c italic_o italic_n italic_c italic_a italic_t ( italic_h start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p9">
<p class="ltx_p" id="S5.SS1.SSS3.p9.1">Finally, a dense block g is used to generate <math alttext="y=g(h_{final})" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p9.1.m1.1"><semantics id="S5.SS1.SSS3.p9.1.m1.1a"><mrow id="S5.SS1.SSS3.p9.1.m1.1.1" xref="S5.SS1.SSS3.p9.1.m1.1.1.cmml"><mi id="S5.SS1.SSS3.p9.1.m1.1.1.3" xref="S5.SS1.SSS3.p9.1.m1.1.1.3.cmml">y</mi><mo id="S5.SS1.SSS3.p9.1.m1.1.1.2" xref="S5.SS1.SSS3.p9.1.m1.1.1.2.cmml">=</mo><mrow id="S5.SS1.SSS3.p9.1.m1.1.1.1" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.3" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.3.cmml">g</mi><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.2" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.cmml"><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.2" stretchy="false" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.cmml"><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.2" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.2.cmml">h</mi><mrow id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.2" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.2.cmml">f</mi><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.3" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.3.cmml">i</mi><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1a" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.4" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.4.cmml">n</mi><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1b" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.5" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.5.cmml">a</mi><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1c" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.6" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.6.cmml">l</mi></mrow></msub><mo id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.3" stretchy="false" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p9.1.m1.1b"><apply id="S5.SS1.SSS3.p9.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1"><eq id="S5.SS1.SSS3.p9.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.2"></eq><ci id="S5.SS1.SSS3.p9.1.m1.1.1.3.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.3">𝑦</ci><apply id="S5.SS1.SSS3.p9.1.m1.1.1.1.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1"><times id="S5.SS1.SSS3.p9.1.m1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.2"></times><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.3">𝑔</ci><apply id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.2">ℎ</ci><apply id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3"><times id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.1"></times><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.2">𝑓</ci><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.3">𝑖</ci><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.4.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.4">𝑛</ci><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.5.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.5">𝑎</ci><ci id="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.6.cmml" xref="S5.SS1.SSS3.p9.1.m1.1.1.1.1.1.1.3.6">𝑙</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p9.1.m1.1c">y=g(h_{final})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS3.p9.1.m1.1d">italic_y = italic_g ( italic_h start_POSTSUBSCRIPT italic_f italic_i italic_n italic_a italic_l end_POSTSUBSCRIPT )</annotation></semantics></math> , and the model is trained by optimizing the prediction loss (focal loss or mean square error loss). This allows for dense interaction of features from each modality, aggregating information across different stages of the network. Finally the final loss defined in equation 5, optimizes a combination of the prediction objective and a mutual information loss controlled by a hyperparameter lambda of value range [0,1].</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS3.p10">
<table class="ltx_equation ltx_eqn_table" id="S5.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\text{Loss}_{\text{final}}=L_{\text{objective}}(g(h_{\text{final}}))+\lambda%
\text{MI}(\text{concat}(S_{a},S_{b}),S_{c})" class="ltx_Math" display="block" id="S5.E5.m1.3"><semantics id="S5.E5.m1.3a"><mrow id="S5.E5.m1.3.3" xref="S5.E5.m1.3.3.cmml"><msub id="S5.E5.m1.3.3.5" xref="S5.E5.m1.3.3.5.cmml"><mtext id="S5.E5.m1.3.3.5.2" xref="S5.E5.m1.3.3.5.2a.cmml">Loss</mtext><mtext id="S5.E5.m1.3.3.5.3" xref="S5.E5.m1.3.3.5.3a.cmml">final</mtext></msub><mo id="S5.E5.m1.3.3.4" xref="S5.E5.m1.3.3.4.cmml">=</mo><mrow id="S5.E5.m1.3.3.3" xref="S5.E5.m1.3.3.3.cmml"><mrow id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml"><msub id="S5.E5.m1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.3.cmml"><mi id="S5.E5.m1.1.1.1.1.3.2" xref="S5.E5.m1.1.1.1.1.3.2.cmml">L</mi><mtext id="S5.E5.m1.1.1.1.1.3.3" xref="S5.E5.m1.1.1.1.1.3.3a.cmml">objective</mtext></msub><mo id="S5.E5.m1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E5.m1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml"><mo id="S5.E5.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.3.cmml">g</mi><mo id="S5.E5.m1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S5.E5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mtext id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3a.cmml">final</mtext></msub><mo id="S5.E5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E5.m1.3.3.3.4" xref="S5.E5.m1.3.3.3.4.cmml">+</mo><mrow id="S5.E5.m1.3.3.3.3" xref="S5.E5.m1.3.3.3.3.cmml"><mi id="S5.E5.m1.3.3.3.3.4" xref="S5.E5.m1.3.3.3.3.4.cmml">λ</mi><mo id="S5.E5.m1.3.3.3.3.3" xref="S5.E5.m1.3.3.3.3.3.cmml">⁢</mo><mtext id="S5.E5.m1.3.3.3.3.5" xref="S5.E5.m1.3.3.3.3.5a.cmml">MI</mtext><mo id="S5.E5.m1.3.3.3.3.3a" xref="S5.E5.m1.3.3.3.3.3.cmml">⁢</mo><mrow id="S5.E5.m1.3.3.3.3.2.2" xref="S5.E5.m1.3.3.3.3.2.3.cmml"><mo id="S5.E5.m1.3.3.3.3.2.2.3" stretchy="false" xref="S5.E5.m1.3.3.3.3.2.3.cmml">(</mo><mrow id="S5.E5.m1.2.2.2.2.1.1.1" xref="S5.E5.m1.2.2.2.2.1.1.1.cmml"><mtext id="S5.E5.m1.2.2.2.2.1.1.1.4" xref="S5.E5.m1.2.2.2.2.1.1.1.4a.cmml">concat</mtext><mo id="S5.E5.m1.2.2.2.2.1.1.1.3" xref="S5.E5.m1.2.2.2.2.1.1.1.3.cmml">⁢</mo><mrow id="S5.E5.m1.2.2.2.2.1.1.1.2.2" xref="S5.E5.m1.2.2.2.2.1.1.1.2.3.cmml"><mo id="S5.E5.m1.2.2.2.2.1.1.1.2.2.3" stretchy="false" xref="S5.E5.m1.2.2.2.2.1.1.1.2.3.cmml">(</mo><msub id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.cmml"><mi id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.2" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.2.cmml">S</mi><mi id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.3" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S5.E5.m1.2.2.2.2.1.1.1.2.2.4" xref="S5.E5.m1.2.2.2.2.1.1.1.2.3.cmml">,</mo><msub id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.cmml"><mi id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.2" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.2.cmml">S</mi><mi id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.3" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.3.cmml">b</mi></msub><mo id="S5.E5.m1.2.2.2.2.1.1.1.2.2.5" stretchy="false" xref="S5.E5.m1.2.2.2.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S5.E5.m1.3.3.3.3.2.2.4" xref="S5.E5.m1.3.3.3.3.2.3.cmml">,</mo><msub id="S5.E5.m1.3.3.3.3.2.2.2" xref="S5.E5.m1.3.3.3.3.2.2.2.cmml"><mi id="S5.E5.m1.3.3.3.3.2.2.2.2" xref="S5.E5.m1.3.3.3.3.2.2.2.2.cmml">S</mi><mi id="S5.E5.m1.3.3.3.3.2.2.2.3" xref="S5.E5.m1.3.3.3.3.2.2.2.3.cmml">c</mi></msub><mo id="S5.E5.m1.3.3.3.3.2.2.5" stretchy="false" xref="S5.E5.m1.3.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.3b"><apply id="S5.E5.m1.3.3.cmml" xref="S5.E5.m1.3.3"><eq id="S5.E5.m1.3.3.4.cmml" xref="S5.E5.m1.3.3.4"></eq><apply id="S5.E5.m1.3.3.5.cmml" xref="S5.E5.m1.3.3.5"><csymbol cd="ambiguous" id="S5.E5.m1.3.3.5.1.cmml" xref="S5.E5.m1.3.3.5">subscript</csymbol><ci id="S5.E5.m1.3.3.5.2a.cmml" xref="S5.E5.m1.3.3.5.2"><mtext id="S5.E5.m1.3.3.5.2.cmml" xref="S5.E5.m1.3.3.5.2">Loss</mtext></ci><ci id="S5.E5.m1.3.3.5.3a.cmml" xref="S5.E5.m1.3.3.5.3"><mtext id="S5.E5.m1.3.3.5.3.cmml" mathsize="70%" xref="S5.E5.m1.3.3.5.3">final</mtext></ci></apply><apply id="S5.E5.m1.3.3.3.cmml" xref="S5.E5.m1.3.3.3"><plus id="S5.E5.m1.3.3.3.4.cmml" xref="S5.E5.m1.3.3.3.4"></plus><apply id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1"><times id="S5.E5.m1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.2"></times><apply id="S5.E5.m1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.3.1.cmml" xref="S5.E5.m1.1.1.1.1.3">subscript</csymbol><ci id="S5.E5.m1.1.1.1.1.3.2.cmml" xref="S5.E5.m1.1.1.1.1.3.2">𝐿</ci><ci id="S5.E5.m1.1.1.1.1.3.3a.cmml" xref="S5.E5.m1.1.1.1.1.3.3"><mtext id="S5.E5.m1.1.1.1.1.3.3.cmml" mathsize="70%" xref="S5.E5.m1.1.1.1.1.3.3">objective</mtext></ci></apply><apply id="S5.E5.m1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1"><times id="S5.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2"></times><ci id="S5.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.3">𝑔</ci><apply id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2">ℎ</ci><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3">final</mtext></ci></apply></apply></apply><apply id="S5.E5.m1.3.3.3.3.cmml" xref="S5.E5.m1.3.3.3.3"><times id="S5.E5.m1.3.3.3.3.3.cmml" xref="S5.E5.m1.3.3.3.3.3"></times><ci id="S5.E5.m1.3.3.3.3.4.cmml" xref="S5.E5.m1.3.3.3.3.4">𝜆</ci><ci id="S5.E5.m1.3.3.3.3.5a.cmml" xref="S5.E5.m1.3.3.3.3.5"><mtext id="S5.E5.m1.3.3.3.3.5.cmml" xref="S5.E5.m1.3.3.3.3.5">MI</mtext></ci><interval closure="open" id="S5.E5.m1.3.3.3.3.2.3.cmml" xref="S5.E5.m1.3.3.3.3.2.2"><apply id="S5.E5.m1.2.2.2.2.1.1.1.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1"><times id="S5.E5.m1.2.2.2.2.1.1.1.3.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.3"></times><ci id="S5.E5.m1.2.2.2.2.1.1.1.4a.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.4"><mtext id="S5.E5.m1.2.2.2.2.1.1.1.4.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.4">concat</mtext></ci><interval closure="open" id="S5.E5.m1.2.2.2.2.1.1.1.2.3.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2"><apply id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.2">𝑆</ci><ci id="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.1.1.1.3">𝑎</ci></apply><apply id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.1.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2">subscript</csymbol><ci id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.2.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.2">𝑆</ci><ci id="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.3.cmml" xref="S5.E5.m1.2.2.2.2.1.1.1.2.2.2.3">𝑏</ci></apply></interval></apply><apply id="S5.E5.m1.3.3.3.3.2.2.2.cmml" xref="S5.E5.m1.3.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.3.3.3.3.2.2.2.1.cmml" xref="S5.E5.m1.3.3.3.3.2.2.2">subscript</csymbol><ci id="S5.E5.m1.3.3.3.3.2.2.2.2.cmml" xref="S5.E5.m1.3.3.3.3.2.2.2.2">𝑆</ci><ci id="S5.E5.m1.3.3.3.3.2.2.2.3.cmml" xref="S5.E5.m1.3.3.3.3.2.2.2.3">𝑐</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.3c">\text{Loss}_{\text{final}}=L_{\text{objective}}(g(h_{\text{final}}))+\lambda%
\text{MI}(\text{concat}(S_{a},S_{b}),S_{c})</annotation><annotation encoding="application/x-llamapun" id="S5.E5.m1.3d">Loss start_POSTSUBSCRIPT final end_POSTSUBSCRIPT = italic_L start_POSTSUBSCRIPT objective end_POSTSUBSCRIPT ( italic_g ( italic_h start_POSTSUBSCRIPT final end_POSTSUBSCRIPT ) ) + italic_λ MI ( concat ( italic_S start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ) , italic_S start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.4 </span>Overfitting Analysis</h4>
<div class="ltx_para" id="S5.SS1.SSS4.p1">
<p class="ltx_p" id="S5.SS1.SSS4.p1.5">Separate logistic regression and neural network models were developed for image embeddings and metadata, considering class weights to address overfitting due to data imbalance in logistic regression, and other techniques such as L2 normalization and Early Stopping in the neural network models. The datasets were randomly split into train and test sets, using 70% for training and the remaining 30% for testing. The models were evaluated using F1 scores due to the dataset’s imbalance (results in Table 2). An early fusion approach was then applied for the fusion model, combining the preprocessed modalities (image embeddings and metadata features) into a single feature set. This feature set was used to train a Logistic regression model using the same train-test split and calculating the same metrics.
Given the big risk of overfitting due to class imbalance, class weights were applied in the loss function in the logistic regression models. Class weights were calculated using the equation described in equation 6, where <math alttext="W(C)" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p1.1.m1.1"><semantics id="S5.SS1.SSS4.p1.1.m1.1a"><mrow id="S5.SS1.SSS4.p1.1.m1.1.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.cmml"><mi id="S5.SS1.SSS4.p1.1.m1.1.2.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.2.cmml">W</mi><mo id="S5.SS1.SSS4.p1.1.m1.1.2.1" xref="S5.SS1.SSS4.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS4.p1.1.m1.1.2.3.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.cmml"><mo id="S5.SS1.SSS4.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS4.p1.1.m1.1.2.cmml">(</mo><mi id="S5.SS1.SSS4.p1.1.m1.1.1" xref="S5.SS1.SSS4.p1.1.m1.1.1.cmml">C</mi><mo id="S5.SS1.SSS4.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS4.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.1.m1.1b"><apply id="S5.SS1.SSS4.p1.1.m1.1.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2"><times id="S5.SS1.SSS4.p1.1.m1.1.2.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.1"></times><ci id="S5.SS1.SSS4.p1.1.m1.1.2.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.2">𝑊</ci><ci id="S5.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.1.m1.1c">W(C)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p1.1.m1.1d">italic_W ( italic_C )</annotation></semantics></math> indicates the weights for the class <math alttext="C" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p1.2.m2.1"><semantics id="S5.SS1.SSS4.p1.2.m2.1a"><mi id="S5.SS1.SSS4.p1.2.m2.1.1" xref="S5.SS1.SSS4.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.2.m2.1b"><ci id="S5.SS1.SSS4.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS4.p1.2.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.2.m2.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p1.2.m2.1d">italic_C</annotation></semantics></math>, <math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p1.3.m3.1"><semantics id="S5.SS1.SSS4.p1.3.m3.1a"><mi id="S5.SS1.SSS4.p1.3.m3.1.1" xref="S5.SS1.SSS4.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.3.m3.1b"><ci id="S5.SS1.SSS4.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS4.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p1.3.m3.1d">italic_N</annotation></semantics></math> represents the total data points in the train set, K represents the number of classes, and <math alttext="N_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p1.4.m4.1"><semantics id="S5.SS1.SSS4.p1.4.m4.1a"><msub id="S5.SS1.SSS4.p1.4.m4.1.1" xref="S5.SS1.SSS4.p1.4.m4.1.1.cmml"><mi id="S5.SS1.SSS4.p1.4.m4.1.1.2" xref="S5.SS1.SSS4.p1.4.m4.1.1.2.cmml">N</mi><mi id="S5.SS1.SSS4.p1.4.m4.1.1.3" xref="S5.SS1.SSS4.p1.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.4.m4.1b"><apply id="S5.SS1.SSS4.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS4.p1.4.m4.1.1.1.cmml" xref="S5.SS1.SSS4.p1.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.SSS4.p1.4.m4.1.1.2.cmml" xref="S5.SS1.SSS4.p1.4.m4.1.1.2">𝑁</ci><ci id="S5.SS1.SSS4.p1.4.m4.1.1.3.cmml" xref="S5.SS1.SSS4.p1.4.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.4.m4.1c">N_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p1.4.m4.1d">italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> represents the number of data points of class <math alttext="C" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p1.5.m5.1"><semantics id="S5.SS1.SSS4.p1.5.m5.1a"><mi id="S5.SS1.SSS4.p1.5.m5.1.1" xref="S5.SS1.SSS4.p1.5.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.5.m5.1b"><ci id="S5.SS1.SSS4.p1.5.m5.1.1.cmml" xref="S5.SS1.SSS4.p1.5.m5.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.5.m5.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p1.5.m5.1d">italic_C</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p2">
<table class="ltx_equation ltx_eqn_table" id="S5.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\alpha(C)=\frac{N}{K\cdot N_{c}}" class="ltx_Math" display="block" id="S5.E6.m1.1"><semantics id="S5.E6.m1.1a"><mrow id="S5.E6.m1.1.2" xref="S5.E6.m1.1.2.cmml"><mrow id="S5.E6.m1.1.2.2" xref="S5.E6.m1.1.2.2.cmml"><mi id="S5.E6.m1.1.2.2.2" xref="S5.E6.m1.1.2.2.2.cmml">α</mi><mo id="S5.E6.m1.1.2.2.1" xref="S5.E6.m1.1.2.2.1.cmml">⁢</mo><mrow id="S5.E6.m1.1.2.2.3.2" xref="S5.E6.m1.1.2.2.cmml"><mo id="S5.E6.m1.1.2.2.3.2.1" stretchy="false" xref="S5.E6.m1.1.2.2.cmml">(</mo><mi id="S5.E6.m1.1.1" xref="S5.E6.m1.1.1.cmml">C</mi><mo id="S5.E6.m1.1.2.2.3.2.2" stretchy="false" xref="S5.E6.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S5.E6.m1.1.2.1" xref="S5.E6.m1.1.2.1.cmml">=</mo><mfrac id="S5.E6.m1.1.2.3" xref="S5.E6.m1.1.2.3.cmml"><mi id="S5.E6.m1.1.2.3.2" xref="S5.E6.m1.1.2.3.2.cmml">N</mi><mrow id="S5.E6.m1.1.2.3.3" xref="S5.E6.m1.1.2.3.3.cmml"><mi id="S5.E6.m1.1.2.3.3.2" xref="S5.E6.m1.1.2.3.3.2.cmml">K</mi><mo id="S5.E6.m1.1.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="S5.E6.m1.1.2.3.3.1.cmml">⋅</mo><msub id="S5.E6.m1.1.2.3.3.3" xref="S5.E6.m1.1.2.3.3.3.cmml"><mi id="S5.E6.m1.1.2.3.3.3.2" xref="S5.E6.m1.1.2.3.3.3.2.cmml">N</mi><mi id="S5.E6.m1.1.2.3.3.3.3" xref="S5.E6.m1.1.2.3.3.3.3.cmml">c</mi></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.E6.m1.1b"><apply id="S5.E6.m1.1.2.cmml" xref="S5.E6.m1.1.2"><eq id="S5.E6.m1.1.2.1.cmml" xref="S5.E6.m1.1.2.1"></eq><apply id="S5.E6.m1.1.2.2.cmml" xref="S5.E6.m1.1.2.2"><times id="S5.E6.m1.1.2.2.1.cmml" xref="S5.E6.m1.1.2.2.1"></times><ci id="S5.E6.m1.1.2.2.2.cmml" xref="S5.E6.m1.1.2.2.2">𝛼</ci><ci id="S5.E6.m1.1.1.cmml" xref="S5.E6.m1.1.1">𝐶</ci></apply><apply id="S5.E6.m1.1.2.3.cmml" xref="S5.E6.m1.1.2.3"><divide id="S5.E6.m1.1.2.3.1.cmml" xref="S5.E6.m1.1.2.3"></divide><ci id="S5.E6.m1.1.2.3.2.cmml" xref="S5.E6.m1.1.2.3.2">𝑁</ci><apply id="S5.E6.m1.1.2.3.3.cmml" xref="S5.E6.m1.1.2.3.3"><ci id="S5.E6.m1.1.2.3.3.1.cmml" xref="S5.E6.m1.1.2.3.3.1">⋅</ci><ci id="S5.E6.m1.1.2.3.3.2.cmml" xref="S5.E6.m1.1.2.3.3.2">𝐾</ci><apply id="S5.E6.m1.1.2.3.3.3.cmml" xref="S5.E6.m1.1.2.3.3.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.2.3.3.3.1.cmml" xref="S5.E6.m1.1.2.3.3.3">subscript</csymbol><ci id="S5.E6.m1.1.2.3.3.3.2.cmml" xref="S5.E6.m1.1.2.3.3.3.2">𝑁</ci><ci id="S5.E6.m1.1.2.3.3.3.3.cmml" xref="S5.E6.m1.1.2.3.3.3.3">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E6.m1.1c">\alpha(C)=\frac{N}{K\cdot N_{c}}</annotation><annotation encoding="application/x-llamapun" id="S5.E6.m1.1d">italic_α ( italic_C ) = divide start_ARG italic_N end_ARG start_ARG italic_K ⋅ italic_N start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p3">
<p class="ltx_p" id="S5.SS1.SSS4.p3.1">Then the class weights were applied into the class-weighted focal loss, given by equation 7:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="FL(p_{t,c})=-\sum_{c=1}^{C}\alpha_{c}(1-p_{t,c})^{y}\log(p_{t,c})" class="ltx_Math" display="block" id="S5.E7.m1.10"><semantics id="S5.E7.m1.10a"><mrow id="S5.E7.m1.10.10" xref="S5.E7.m1.10.10.cmml"><mrow id="S5.E7.m1.8.8.1" xref="S5.E7.m1.8.8.1.cmml"><mi id="S5.E7.m1.8.8.1.3" xref="S5.E7.m1.8.8.1.3.cmml">F</mi><mo id="S5.E7.m1.8.8.1.2" xref="S5.E7.m1.8.8.1.2.cmml">⁢</mo><mi id="S5.E7.m1.8.8.1.4" xref="S5.E7.m1.8.8.1.4.cmml">L</mi><mo id="S5.E7.m1.8.8.1.2a" xref="S5.E7.m1.8.8.1.2.cmml">⁢</mo><mrow id="S5.E7.m1.8.8.1.1.1" xref="S5.E7.m1.8.8.1.1.1.1.cmml"><mo id="S5.E7.m1.8.8.1.1.1.2" stretchy="false" xref="S5.E7.m1.8.8.1.1.1.1.cmml">(</mo><msub id="S5.E7.m1.8.8.1.1.1.1" xref="S5.E7.m1.8.8.1.1.1.1.cmml"><mi id="S5.E7.m1.8.8.1.1.1.1.2" xref="S5.E7.m1.8.8.1.1.1.1.2.cmml">p</mi><mrow id="S5.E7.m1.2.2.2.4" xref="S5.E7.m1.2.2.2.3.cmml"><mi id="S5.E7.m1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.cmml">t</mi><mo id="S5.E7.m1.2.2.2.4.1" xref="S5.E7.m1.2.2.2.3.cmml">,</mo><mi id="S5.E7.m1.2.2.2.2" xref="S5.E7.m1.2.2.2.2.cmml">c</mi></mrow></msub><mo id="S5.E7.m1.8.8.1.1.1.3" stretchy="false" xref="S5.E7.m1.8.8.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E7.m1.10.10.4" xref="S5.E7.m1.10.10.4.cmml">=</mo><mrow id="S5.E7.m1.10.10.3" xref="S5.E7.m1.10.10.3.cmml"><mo id="S5.E7.m1.10.10.3a" xref="S5.E7.m1.10.10.3.cmml">−</mo><mrow id="S5.E7.m1.10.10.3.2" xref="S5.E7.m1.10.10.3.2.cmml"><munderover id="S5.E7.m1.10.10.3.2.3" xref="S5.E7.m1.10.10.3.2.3.cmml"><mo id="S5.E7.m1.10.10.3.2.3.2.2" movablelimits="false" xref="S5.E7.m1.10.10.3.2.3.2.2.cmml">∑</mo><mrow id="S5.E7.m1.10.10.3.2.3.2.3" xref="S5.E7.m1.10.10.3.2.3.2.3.cmml"><mi id="S5.E7.m1.10.10.3.2.3.2.3.2" xref="S5.E7.m1.10.10.3.2.3.2.3.2.cmml">c</mi><mo id="S5.E7.m1.10.10.3.2.3.2.3.1" xref="S5.E7.m1.10.10.3.2.3.2.3.1.cmml">=</mo><mn id="S5.E7.m1.10.10.3.2.3.2.3.3" xref="S5.E7.m1.10.10.3.2.3.2.3.3.cmml">1</mn></mrow><mi id="S5.E7.m1.10.10.3.2.3.3" xref="S5.E7.m1.10.10.3.2.3.3.cmml">C</mi></munderover><mrow id="S5.E7.m1.10.10.3.2.2" xref="S5.E7.m1.10.10.3.2.2.cmml"><msub id="S5.E7.m1.10.10.3.2.2.4" xref="S5.E7.m1.10.10.3.2.2.4.cmml"><mi id="S5.E7.m1.10.10.3.2.2.4.2" xref="S5.E7.m1.10.10.3.2.2.4.2.cmml">α</mi><mi id="S5.E7.m1.10.10.3.2.2.4.3" xref="S5.E7.m1.10.10.3.2.2.4.3.cmml">c</mi></msub><mo id="S5.E7.m1.10.10.3.2.2.3" xref="S5.E7.m1.10.10.3.2.2.3.cmml">⁢</mo><msup id="S5.E7.m1.9.9.2.1.1.1" xref="S5.E7.m1.9.9.2.1.1.1.cmml"><mrow id="S5.E7.m1.9.9.2.1.1.1.1.1" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.cmml"><mo id="S5.E7.m1.9.9.2.1.1.1.1.1.2" stretchy="false" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E7.m1.9.9.2.1.1.1.1.1.1" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.cmml"><mn id="S5.E7.m1.9.9.2.1.1.1.1.1.1.2" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.2.cmml">1</mn><mo id="S5.E7.m1.9.9.2.1.1.1.1.1.1.1" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.1.cmml">−</mo><msub id="S5.E7.m1.9.9.2.1.1.1.1.1.1.3" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.cmml"><mi id="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.2" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.2.cmml">p</mi><mrow id="S5.E7.m1.4.4.2.4" xref="S5.E7.m1.4.4.2.3.cmml"><mi id="S5.E7.m1.3.3.1.1" xref="S5.E7.m1.3.3.1.1.cmml">t</mi><mo id="S5.E7.m1.4.4.2.4.1" xref="S5.E7.m1.4.4.2.3.cmml">,</mo><mi id="S5.E7.m1.4.4.2.2" xref="S5.E7.m1.4.4.2.2.cmml">c</mi></mrow></msub></mrow><mo id="S5.E7.m1.9.9.2.1.1.1.1.1.3" stretchy="false" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S5.E7.m1.9.9.2.1.1.1.3" xref="S5.E7.m1.9.9.2.1.1.1.3.cmml">y</mi></msup><mo id="S5.E7.m1.10.10.3.2.2.3a" lspace="0.167em" xref="S5.E7.m1.10.10.3.2.2.3.cmml">⁢</mo><mrow id="S5.E7.m1.10.10.3.2.2.2.1" xref="S5.E7.m1.10.10.3.2.2.2.2.cmml"><mi id="S5.E7.m1.7.7" xref="S5.E7.m1.7.7.cmml">log</mi><mo id="S5.E7.m1.10.10.3.2.2.2.1a" xref="S5.E7.m1.10.10.3.2.2.2.2.cmml">⁡</mo><mrow id="S5.E7.m1.10.10.3.2.2.2.1.1" xref="S5.E7.m1.10.10.3.2.2.2.2.cmml"><mo id="S5.E7.m1.10.10.3.2.2.2.1.1.2" stretchy="false" xref="S5.E7.m1.10.10.3.2.2.2.2.cmml">(</mo><msub id="S5.E7.m1.10.10.3.2.2.2.1.1.1" xref="S5.E7.m1.10.10.3.2.2.2.1.1.1.cmml"><mi id="S5.E7.m1.10.10.3.2.2.2.1.1.1.2" xref="S5.E7.m1.10.10.3.2.2.2.1.1.1.2.cmml">p</mi><mrow id="S5.E7.m1.6.6.2.4" xref="S5.E7.m1.6.6.2.3.cmml"><mi id="S5.E7.m1.5.5.1.1" xref="S5.E7.m1.5.5.1.1.cmml">t</mi><mo id="S5.E7.m1.6.6.2.4.1" xref="S5.E7.m1.6.6.2.3.cmml">,</mo><mi id="S5.E7.m1.6.6.2.2" xref="S5.E7.m1.6.6.2.2.cmml">c</mi></mrow></msub><mo id="S5.E7.m1.10.10.3.2.2.2.1.1.3" stretchy="false" xref="S5.E7.m1.10.10.3.2.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E7.m1.10b"><apply id="S5.E7.m1.10.10.cmml" xref="S5.E7.m1.10.10"><eq id="S5.E7.m1.10.10.4.cmml" xref="S5.E7.m1.10.10.4"></eq><apply id="S5.E7.m1.8.8.1.cmml" xref="S5.E7.m1.8.8.1"><times id="S5.E7.m1.8.8.1.2.cmml" xref="S5.E7.m1.8.8.1.2"></times><ci id="S5.E7.m1.8.8.1.3.cmml" xref="S5.E7.m1.8.8.1.3">𝐹</ci><ci id="S5.E7.m1.8.8.1.4.cmml" xref="S5.E7.m1.8.8.1.4">𝐿</ci><apply id="S5.E7.m1.8.8.1.1.1.1.cmml" xref="S5.E7.m1.8.8.1.1.1"><csymbol cd="ambiguous" id="S5.E7.m1.8.8.1.1.1.1.1.cmml" xref="S5.E7.m1.8.8.1.1.1">subscript</csymbol><ci id="S5.E7.m1.8.8.1.1.1.1.2.cmml" xref="S5.E7.m1.8.8.1.1.1.1.2">𝑝</ci><list id="S5.E7.m1.2.2.2.3.cmml" xref="S5.E7.m1.2.2.2.4"><ci id="S5.E7.m1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1">𝑡</ci><ci id="S5.E7.m1.2.2.2.2.cmml" xref="S5.E7.m1.2.2.2.2">𝑐</ci></list></apply></apply><apply id="S5.E7.m1.10.10.3.cmml" xref="S5.E7.m1.10.10.3"><minus id="S5.E7.m1.10.10.3.3.cmml" xref="S5.E7.m1.10.10.3"></minus><apply id="S5.E7.m1.10.10.3.2.cmml" xref="S5.E7.m1.10.10.3.2"><apply id="S5.E7.m1.10.10.3.2.3.cmml" xref="S5.E7.m1.10.10.3.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.10.10.3.2.3.1.cmml" xref="S5.E7.m1.10.10.3.2.3">superscript</csymbol><apply id="S5.E7.m1.10.10.3.2.3.2.cmml" xref="S5.E7.m1.10.10.3.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.10.10.3.2.3.2.1.cmml" xref="S5.E7.m1.10.10.3.2.3">subscript</csymbol><sum id="S5.E7.m1.10.10.3.2.3.2.2.cmml" xref="S5.E7.m1.10.10.3.2.3.2.2"></sum><apply id="S5.E7.m1.10.10.3.2.3.2.3.cmml" xref="S5.E7.m1.10.10.3.2.3.2.3"><eq id="S5.E7.m1.10.10.3.2.3.2.3.1.cmml" xref="S5.E7.m1.10.10.3.2.3.2.3.1"></eq><ci id="S5.E7.m1.10.10.3.2.3.2.3.2.cmml" xref="S5.E7.m1.10.10.3.2.3.2.3.2">𝑐</ci><cn id="S5.E7.m1.10.10.3.2.3.2.3.3.cmml" type="integer" xref="S5.E7.m1.10.10.3.2.3.2.3.3">1</cn></apply></apply><ci id="S5.E7.m1.10.10.3.2.3.3.cmml" xref="S5.E7.m1.10.10.3.2.3.3">𝐶</ci></apply><apply id="S5.E7.m1.10.10.3.2.2.cmml" xref="S5.E7.m1.10.10.3.2.2"><times id="S5.E7.m1.10.10.3.2.2.3.cmml" xref="S5.E7.m1.10.10.3.2.2.3"></times><apply id="S5.E7.m1.10.10.3.2.2.4.cmml" xref="S5.E7.m1.10.10.3.2.2.4"><csymbol cd="ambiguous" id="S5.E7.m1.10.10.3.2.2.4.1.cmml" xref="S5.E7.m1.10.10.3.2.2.4">subscript</csymbol><ci id="S5.E7.m1.10.10.3.2.2.4.2.cmml" xref="S5.E7.m1.10.10.3.2.2.4.2">𝛼</ci><ci id="S5.E7.m1.10.10.3.2.2.4.3.cmml" xref="S5.E7.m1.10.10.3.2.2.4.3">𝑐</ci></apply><apply id="S5.E7.m1.9.9.2.1.1.1.cmml" xref="S5.E7.m1.9.9.2.1.1.1"><csymbol cd="ambiguous" id="S5.E7.m1.9.9.2.1.1.1.2.cmml" xref="S5.E7.m1.9.9.2.1.1.1">superscript</csymbol><apply id="S5.E7.m1.9.9.2.1.1.1.1.1.1.cmml" xref="S5.E7.m1.9.9.2.1.1.1.1.1"><minus id="S5.E7.m1.9.9.2.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.1"></minus><cn id="S5.E7.m1.9.9.2.1.1.1.1.1.1.2.cmml" type="integer" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.2">1</cn><apply id="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.1.cmml" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.2.cmml" xref="S5.E7.m1.9.9.2.1.1.1.1.1.1.3.2">𝑝</ci><list id="S5.E7.m1.4.4.2.3.cmml" xref="S5.E7.m1.4.4.2.4"><ci id="S5.E7.m1.3.3.1.1.cmml" xref="S5.E7.m1.3.3.1.1">𝑡</ci><ci id="S5.E7.m1.4.4.2.2.cmml" xref="S5.E7.m1.4.4.2.2">𝑐</ci></list></apply></apply><ci id="S5.E7.m1.9.9.2.1.1.1.3.cmml" xref="S5.E7.m1.9.9.2.1.1.1.3">𝑦</ci></apply><apply id="S5.E7.m1.10.10.3.2.2.2.2.cmml" xref="S5.E7.m1.10.10.3.2.2.2.1"><log id="S5.E7.m1.7.7.cmml" xref="S5.E7.m1.7.7"></log><apply id="S5.E7.m1.10.10.3.2.2.2.1.1.1.cmml" xref="S5.E7.m1.10.10.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S5.E7.m1.10.10.3.2.2.2.1.1.1.1.cmml" xref="S5.E7.m1.10.10.3.2.2.2.1.1.1">subscript</csymbol><ci id="S5.E7.m1.10.10.3.2.2.2.1.1.1.2.cmml" xref="S5.E7.m1.10.10.3.2.2.2.1.1.1.2">𝑝</ci><list id="S5.E7.m1.6.6.2.3.cmml" xref="S5.E7.m1.6.6.2.4"><ci id="S5.E7.m1.5.5.1.1.cmml" xref="S5.E7.m1.5.5.1.1">𝑡</ci><ci id="S5.E7.m1.6.6.2.2.cmml" xref="S5.E7.m1.6.6.2.2">𝑐</ci></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E7.m1.10c">FL(p_{t,c})=-\sum_{c=1}^{C}\alpha_{c}(1-p_{t,c})^{y}\log(p_{t,c})</annotation><annotation encoding="application/x-llamapun" id="S5.E7.m1.10d">italic_F italic_L ( italic_p start_POSTSUBSCRIPT italic_t , italic_c end_POSTSUBSCRIPT ) = - ∑ start_POSTSUBSCRIPT italic_c = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT italic_α start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( 1 - italic_p start_POSTSUBSCRIPT italic_t , italic_c end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT roman_log ( italic_p start_POSTSUBSCRIPT italic_t , italic_c end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p4">
<p class="ltx_p" id="S5.SS1.SSS4.p4.5">Where <math alttext="FL" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p4.1.m1.1"><semantics id="S5.SS1.SSS4.p4.1.m1.1a"><mrow id="S5.SS1.SSS4.p4.1.m1.1.1" xref="S5.SS1.SSS4.p4.1.m1.1.1.cmml"><mi id="S5.SS1.SSS4.p4.1.m1.1.1.2" xref="S5.SS1.SSS4.p4.1.m1.1.1.2.cmml">F</mi><mo id="S5.SS1.SSS4.p4.1.m1.1.1.1" xref="S5.SS1.SSS4.p4.1.m1.1.1.1.cmml">⁢</mo><mi id="S5.SS1.SSS4.p4.1.m1.1.1.3" xref="S5.SS1.SSS4.p4.1.m1.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p4.1.m1.1b"><apply id="S5.SS1.SSS4.p4.1.m1.1.1.cmml" xref="S5.SS1.SSS4.p4.1.m1.1.1"><times id="S5.SS1.SSS4.p4.1.m1.1.1.1.cmml" xref="S5.SS1.SSS4.p4.1.m1.1.1.1"></times><ci id="S5.SS1.SSS4.p4.1.m1.1.1.2.cmml" xref="S5.SS1.SSS4.p4.1.m1.1.1.2">𝐹</ci><ci id="S5.SS1.SSS4.p4.1.m1.1.1.3.cmml" xref="S5.SS1.SSS4.p4.1.m1.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p4.1.m1.1c">FL</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p4.1.m1.1d">italic_F italic_L</annotation></semantics></math> is the focal loss for class <math alttext="c" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p4.2.m2.1"><semantics id="S5.SS1.SSS4.p4.2.m2.1a"><mi id="S5.SS1.SSS4.p4.2.m2.1.1" xref="S5.SS1.SSS4.p4.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p4.2.m2.1b"><ci id="S5.SS1.SSS4.p4.2.m2.1.1.cmml" xref="S5.SS1.SSS4.p4.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p4.2.m2.1c">c</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p4.2.m2.1d">italic_c</annotation></semantics></math> given a prediction, <math alttext="C" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p4.3.m3.1"><semantics id="S5.SS1.SSS4.p4.3.m3.1a"><mi id="S5.SS1.SSS4.p4.3.m3.1.1" xref="S5.SS1.SSS4.p4.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p4.3.m3.1b"><ci id="S5.SS1.SSS4.p4.3.m3.1.1.cmml" xref="S5.SS1.SSS4.p4.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p4.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p4.3.m3.1d">italic_C</annotation></semantics></math> is the total number of classes, <math alttext="\gamma" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p4.4.m4.1"><semantics id="S5.SS1.SSS4.p4.4.m4.1a"><mi id="S5.SS1.SSS4.p4.4.m4.1.1" xref="S5.SS1.SSS4.p4.4.m4.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p4.4.m4.1b"><ci id="S5.SS1.SSS4.p4.4.m4.1.1.cmml" xref="S5.SS1.SSS4.p4.4.m4.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p4.4.m4.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p4.4.m4.1d">italic_γ</annotation></semantics></math> is the focusing parameter, <math alttext="\alpha_{c}" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p4.5.m5.1"><semantics id="S5.SS1.SSS4.p4.5.m5.1a"><msub id="S5.SS1.SSS4.p4.5.m5.1.1" xref="S5.SS1.SSS4.p4.5.m5.1.1.cmml"><mi id="S5.SS1.SSS4.p4.5.m5.1.1.2" xref="S5.SS1.SSS4.p4.5.m5.1.1.2.cmml">α</mi><mi id="S5.SS1.SSS4.p4.5.m5.1.1.3" xref="S5.SS1.SSS4.p4.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p4.5.m5.1b"><apply id="S5.SS1.SSS4.p4.5.m5.1.1.cmml" xref="S5.SS1.SSS4.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS4.p4.5.m5.1.1.1.cmml" xref="S5.SS1.SSS4.p4.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.SSS4.p4.5.m5.1.1.2.cmml" xref="S5.SS1.SSS4.p4.5.m5.1.1.2">𝛼</ci><ci id="S5.SS1.SSS4.p4.5.m5.1.1.3.cmml" xref="S5.SS1.SSS4.p4.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p4.5.m5.1c">\alpha_{c}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p4.5.m5.1d">italic_α start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> is the class weight.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p5">
<p class="ltx_p" id="S5.SS1.SSS4.p5.8">For the neural network models to avoid overfitting, <math alttext="L2" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.1.m1.1"><semantics id="S5.SS1.SSS4.p5.1.m1.1a"><mrow id="S5.SS1.SSS4.p5.1.m1.1.1" xref="S5.SS1.SSS4.p5.1.m1.1.1.cmml"><mi id="S5.SS1.SSS4.p5.1.m1.1.1.2" xref="S5.SS1.SSS4.p5.1.m1.1.1.2.cmml">L</mi><mo id="S5.SS1.SSS4.p5.1.m1.1.1.1" xref="S5.SS1.SSS4.p5.1.m1.1.1.1.cmml">⁢</mo><mn id="S5.SS1.SSS4.p5.1.m1.1.1.3" xref="S5.SS1.SSS4.p5.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.1.m1.1b"><apply id="S5.SS1.SSS4.p5.1.m1.1.1.cmml" xref="S5.SS1.SSS4.p5.1.m1.1.1"><times id="S5.SS1.SSS4.p5.1.m1.1.1.1.cmml" xref="S5.SS1.SSS4.p5.1.m1.1.1.1"></times><ci id="S5.SS1.SSS4.p5.1.m1.1.1.2.cmml" xref="S5.SS1.SSS4.p5.1.m1.1.1.2">𝐿</ci><cn id="S5.SS1.SSS4.p5.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS4.p5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.1.m1.1c">L2</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.1.m1.1d">italic_L 2</annotation></semantics></math> regularization was applied. <math alttext="L2" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.2.m2.1"><semantics id="S5.SS1.SSS4.p5.2.m2.1a"><mrow id="S5.SS1.SSS4.p5.2.m2.1.1" xref="S5.SS1.SSS4.p5.2.m2.1.1.cmml"><mi id="S5.SS1.SSS4.p5.2.m2.1.1.2" xref="S5.SS1.SSS4.p5.2.m2.1.1.2.cmml">L</mi><mo id="S5.SS1.SSS4.p5.2.m2.1.1.1" xref="S5.SS1.SSS4.p5.2.m2.1.1.1.cmml">⁢</mo><mn id="S5.SS1.SSS4.p5.2.m2.1.1.3" xref="S5.SS1.SSS4.p5.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.2.m2.1b"><apply id="S5.SS1.SSS4.p5.2.m2.1.1.cmml" xref="S5.SS1.SSS4.p5.2.m2.1.1"><times id="S5.SS1.SSS4.p5.2.m2.1.1.1.cmml" xref="S5.SS1.SSS4.p5.2.m2.1.1.1"></times><ci id="S5.SS1.SSS4.p5.2.m2.1.1.2.cmml" xref="S5.SS1.SSS4.p5.2.m2.1.1.2">𝐿</ci><cn id="S5.SS1.SSS4.p5.2.m2.1.1.3.cmml" type="integer" xref="S5.SS1.SSS4.p5.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.2.m2.1c">L2</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.2.m2.1d">italic_L 2</annotation></semantics></math> regularization, also known as weight decay, prevents overfitting by penalizing large weights in a model’s parameters. This is achieved by adding a regularization term to the model’s loss function. The goal of <math alttext="L2" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.3.m3.1"><semantics id="S5.SS1.SSS4.p5.3.m3.1a"><mrow id="S5.SS1.SSS4.p5.3.m3.1.1" xref="S5.SS1.SSS4.p5.3.m3.1.1.cmml"><mi id="S5.SS1.SSS4.p5.3.m3.1.1.2" xref="S5.SS1.SSS4.p5.3.m3.1.1.2.cmml">L</mi><mo id="S5.SS1.SSS4.p5.3.m3.1.1.1" xref="S5.SS1.SSS4.p5.3.m3.1.1.1.cmml">⁢</mo><mn id="S5.SS1.SSS4.p5.3.m3.1.1.3" xref="S5.SS1.SSS4.p5.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.3.m3.1b"><apply id="S5.SS1.SSS4.p5.3.m3.1.1.cmml" xref="S5.SS1.SSS4.p5.3.m3.1.1"><times id="S5.SS1.SSS4.p5.3.m3.1.1.1.cmml" xref="S5.SS1.SSS4.p5.3.m3.1.1.1"></times><ci id="S5.SS1.SSS4.p5.3.m3.1.1.2.cmml" xref="S5.SS1.SSS4.p5.3.m3.1.1.2">𝐿</ci><cn id="S5.SS1.SSS4.p5.3.m3.1.1.3.cmml" type="integer" xref="S5.SS1.SSS4.p5.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.3.m3.1c">L2</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.3.m3.1d">italic_L 2</annotation></semantics></math> regularization is to encourage the model to learn simpler patterns that generalize better to unseen data. The mathematical formulation of <math alttext="L2" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.4.m4.1"><semantics id="S5.SS1.SSS4.p5.4.m4.1a"><mrow id="S5.SS1.SSS4.p5.4.m4.1.1" xref="S5.SS1.SSS4.p5.4.m4.1.1.cmml"><mi id="S5.SS1.SSS4.p5.4.m4.1.1.2" xref="S5.SS1.SSS4.p5.4.m4.1.1.2.cmml">L</mi><mo id="S5.SS1.SSS4.p5.4.m4.1.1.1" xref="S5.SS1.SSS4.p5.4.m4.1.1.1.cmml">⁢</mo><mn id="S5.SS1.SSS4.p5.4.m4.1.1.3" xref="S5.SS1.SSS4.p5.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.4.m4.1b"><apply id="S5.SS1.SSS4.p5.4.m4.1.1.cmml" xref="S5.SS1.SSS4.p5.4.m4.1.1"><times id="S5.SS1.SSS4.p5.4.m4.1.1.1.cmml" xref="S5.SS1.SSS4.p5.4.m4.1.1.1"></times><ci id="S5.SS1.SSS4.p5.4.m4.1.1.2.cmml" xref="S5.SS1.SSS4.p5.4.m4.1.1.2">𝐿</ci><cn id="S5.SS1.SSS4.p5.4.m4.1.1.3.cmml" type="integer" xref="S5.SS1.SSS4.p5.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.4.m4.1c">L2</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.4.m4.1d">italic_L 2</annotation></semantics></math> regularization can be described as in equation 8. Where <math alttext="L_{r}eg" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.5.m5.1"><semantics id="S5.SS1.SSS4.p5.5.m5.1a"><mrow id="S5.SS1.SSS4.p5.5.m5.1.1" xref="S5.SS1.SSS4.p5.5.m5.1.1.cmml"><msub id="S5.SS1.SSS4.p5.5.m5.1.1.2" xref="S5.SS1.SSS4.p5.5.m5.1.1.2.cmml"><mi id="S5.SS1.SSS4.p5.5.m5.1.1.2.2" xref="S5.SS1.SSS4.p5.5.m5.1.1.2.2.cmml">L</mi><mi id="S5.SS1.SSS4.p5.5.m5.1.1.2.3" xref="S5.SS1.SSS4.p5.5.m5.1.1.2.3.cmml">r</mi></msub><mo id="S5.SS1.SSS4.p5.5.m5.1.1.1" xref="S5.SS1.SSS4.p5.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS1.SSS4.p5.5.m5.1.1.3" xref="S5.SS1.SSS4.p5.5.m5.1.1.3.cmml">e</mi><mo id="S5.SS1.SSS4.p5.5.m5.1.1.1a" xref="S5.SS1.SSS4.p5.5.m5.1.1.1.cmml">⁢</mo><mi id="S5.SS1.SSS4.p5.5.m5.1.1.4" xref="S5.SS1.SSS4.p5.5.m5.1.1.4.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.5.m5.1b"><apply id="S5.SS1.SSS4.p5.5.m5.1.1.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1"><times id="S5.SS1.SSS4.p5.5.m5.1.1.1.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.1"></times><apply id="S5.SS1.SSS4.p5.5.m5.1.1.2.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS4.p5.5.m5.1.1.2.1.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.2">subscript</csymbol><ci id="S5.SS1.SSS4.p5.5.m5.1.1.2.2.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.2.2">𝐿</ci><ci id="S5.SS1.SSS4.p5.5.m5.1.1.2.3.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.2.3">𝑟</ci></apply><ci id="S5.SS1.SSS4.p5.5.m5.1.1.3.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.3">𝑒</ci><ci id="S5.SS1.SSS4.p5.5.m5.1.1.4.cmml" xref="S5.SS1.SSS4.p5.5.m5.1.1.4">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.5.m5.1c">L_{r}eg</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.5.m5.1d">italic_L start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT italic_e italic_g</annotation></semantics></math> indicates regularized loss, <math alttext="L" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.6.m6.1"><semantics id="S5.SS1.SSS4.p5.6.m6.1a"><mi id="S5.SS1.SSS4.p5.6.m6.1.1" xref="S5.SS1.SSS4.p5.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.6.m6.1b"><ci id="S5.SS1.SSS4.p5.6.m6.1.1.cmml" xref="S5.SS1.SSS4.p5.6.m6.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.6.m6.1c">L</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.6.m6.1d">italic_L</annotation></semantics></math> indicates the original loss function, <math alttext="\theta" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.7.m7.1"><semantics id="S5.SS1.SSS4.p5.7.m7.1a"><mi id="S5.SS1.SSS4.p5.7.m7.1.1" xref="S5.SS1.SSS4.p5.7.m7.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.7.m7.1b"><ci id="S5.SS1.SSS4.p5.7.m7.1.1.cmml" xref="S5.SS1.SSS4.p5.7.m7.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.7.m7.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.7.m7.1d">italic_θ</annotation></semantics></math> is the weight vector, and <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p5.8.m8.1"><semantics id="S5.SS1.SSS4.p5.8.m8.1a"><mi id="S5.SS1.SSS4.p5.8.m8.1.1" xref="S5.SS1.SSS4.p5.8.m8.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p5.8.m8.1b"><ci id="S5.SS1.SSS4.p5.8.m8.1.1.cmml" xref="S5.SS1.SSS4.p5.8.m8.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p5.8.m8.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS4.p5.8.m8.1d">italic_λ</annotation></semantics></math> is the regularization strength.</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS4.p6">
<table class="ltx_equation ltx_eqn_table" id="S5.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="L_{\text{reg}}(\theta)=L(\theta)+\frac{\lambda}{2}\|\theta\|_{2}^{2}" class="ltx_Math" display="block" id="S5.E8.m1.3"><semantics id="S5.E8.m1.3a"><mrow id="S5.E8.m1.3.4" xref="S5.E8.m1.3.4.cmml"><mrow id="S5.E8.m1.3.4.2" xref="S5.E8.m1.3.4.2.cmml"><msub id="S5.E8.m1.3.4.2.2" xref="S5.E8.m1.3.4.2.2.cmml"><mi id="S5.E8.m1.3.4.2.2.2" xref="S5.E8.m1.3.4.2.2.2.cmml">L</mi><mtext id="S5.E8.m1.3.4.2.2.3" xref="S5.E8.m1.3.4.2.2.3a.cmml">reg</mtext></msub><mo id="S5.E8.m1.3.4.2.1" xref="S5.E8.m1.3.4.2.1.cmml">⁢</mo><mrow id="S5.E8.m1.3.4.2.3.2" xref="S5.E8.m1.3.4.2.cmml"><mo id="S5.E8.m1.3.4.2.3.2.1" stretchy="false" xref="S5.E8.m1.3.4.2.cmml">(</mo><mi id="S5.E8.m1.1.1" xref="S5.E8.m1.1.1.cmml">θ</mi><mo id="S5.E8.m1.3.4.2.3.2.2" stretchy="false" xref="S5.E8.m1.3.4.2.cmml">)</mo></mrow></mrow><mo id="S5.E8.m1.3.4.1" xref="S5.E8.m1.3.4.1.cmml">=</mo><mrow id="S5.E8.m1.3.4.3" xref="S5.E8.m1.3.4.3.cmml"><mrow id="S5.E8.m1.3.4.3.2" xref="S5.E8.m1.3.4.3.2.cmml"><mi id="S5.E8.m1.3.4.3.2.2" xref="S5.E8.m1.3.4.3.2.2.cmml">L</mi><mo id="S5.E8.m1.3.4.3.2.1" xref="S5.E8.m1.3.4.3.2.1.cmml">⁢</mo><mrow id="S5.E8.m1.3.4.3.2.3.2" xref="S5.E8.m1.3.4.3.2.cmml"><mo id="S5.E8.m1.3.4.3.2.3.2.1" stretchy="false" xref="S5.E8.m1.3.4.3.2.cmml">(</mo><mi id="S5.E8.m1.2.2" xref="S5.E8.m1.2.2.cmml">θ</mi><mo id="S5.E8.m1.3.4.3.2.3.2.2" stretchy="false" xref="S5.E8.m1.3.4.3.2.cmml">)</mo></mrow></mrow><mo id="S5.E8.m1.3.4.3.1" xref="S5.E8.m1.3.4.3.1.cmml">+</mo><mrow id="S5.E8.m1.3.4.3.3" xref="S5.E8.m1.3.4.3.3.cmml"><mfrac id="S5.E8.m1.3.4.3.3.2" xref="S5.E8.m1.3.4.3.3.2.cmml"><mi id="S5.E8.m1.3.4.3.3.2.2" xref="S5.E8.m1.3.4.3.3.2.2.cmml">λ</mi><mn id="S5.E8.m1.3.4.3.3.2.3" xref="S5.E8.m1.3.4.3.3.2.3.cmml">2</mn></mfrac><mo id="S5.E8.m1.3.4.3.3.1" xref="S5.E8.m1.3.4.3.3.1.cmml">⁢</mo><msubsup id="S5.E8.m1.3.4.3.3.3" xref="S5.E8.m1.3.4.3.3.3.cmml"><mrow id="S5.E8.m1.3.4.3.3.3.2.2.2" xref="S5.E8.m1.3.4.3.3.3.2.2.1.cmml"><mo id="S5.E8.m1.3.4.3.3.3.2.2.2.1" stretchy="false" xref="S5.E8.m1.3.4.3.3.3.2.2.1.1.cmml">‖</mo><mi id="S5.E8.m1.3.3" xref="S5.E8.m1.3.3.cmml">θ</mi><mo id="S5.E8.m1.3.4.3.3.3.2.2.2.2" stretchy="false" xref="S5.E8.m1.3.4.3.3.3.2.2.1.1.cmml">‖</mo></mrow><mn id="S5.E8.m1.3.4.3.3.3.2.3" xref="S5.E8.m1.3.4.3.3.3.2.3.cmml">2</mn><mn id="S5.E8.m1.3.4.3.3.3.3" xref="S5.E8.m1.3.4.3.3.3.3.cmml">2</mn></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E8.m1.3b"><apply id="S5.E8.m1.3.4.cmml" xref="S5.E8.m1.3.4"><eq id="S5.E8.m1.3.4.1.cmml" xref="S5.E8.m1.3.4.1"></eq><apply id="S5.E8.m1.3.4.2.cmml" xref="S5.E8.m1.3.4.2"><times id="S5.E8.m1.3.4.2.1.cmml" xref="S5.E8.m1.3.4.2.1"></times><apply id="S5.E8.m1.3.4.2.2.cmml" xref="S5.E8.m1.3.4.2.2"><csymbol cd="ambiguous" id="S5.E8.m1.3.4.2.2.1.cmml" xref="S5.E8.m1.3.4.2.2">subscript</csymbol><ci id="S5.E8.m1.3.4.2.2.2.cmml" xref="S5.E8.m1.3.4.2.2.2">𝐿</ci><ci id="S5.E8.m1.3.4.2.2.3a.cmml" xref="S5.E8.m1.3.4.2.2.3"><mtext id="S5.E8.m1.3.4.2.2.3.cmml" mathsize="70%" xref="S5.E8.m1.3.4.2.2.3">reg</mtext></ci></apply><ci id="S5.E8.m1.1.1.cmml" xref="S5.E8.m1.1.1">𝜃</ci></apply><apply id="S5.E8.m1.3.4.3.cmml" xref="S5.E8.m1.3.4.3"><plus id="S5.E8.m1.3.4.3.1.cmml" xref="S5.E8.m1.3.4.3.1"></plus><apply id="S5.E8.m1.3.4.3.2.cmml" xref="S5.E8.m1.3.4.3.2"><times id="S5.E8.m1.3.4.3.2.1.cmml" xref="S5.E8.m1.3.4.3.2.1"></times><ci id="S5.E8.m1.3.4.3.2.2.cmml" xref="S5.E8.m1.3.4.3.2.2">𝐿</ci><ci id="S5.E8.m1.2.2.cmml" xref="S5.E8.m1.2.2">𝜃</ci></apply><apply id="S5.E8.m1.3.4.3.3.cmml" xref="S5.E8.m1.3.4.3.3"><times id="S5.E8.m1.3.4.3.3.1.cmml" xref="S5.E8.m1.3.4.3.3.1"></times><apply id="S5.E8.m1.3.4.3.3.2.cmml" xref="S5.E8.m1.3.4.3.3.2"><divide id="S5.E8.m1.3.4.3.3.2.1.cmml" xref="S5.E8.m1.3.4.3.3.2"></divide><ci id="S5.E8.m1.3.4.3.3.2.2.cmml" xref="S5.E8.m1.3.4.3.3.2.2">𝜆</ci><cn id="S5.E8.m1.3.4.3.3.2.3.cmml" type="integer" xref="S5.E8.m1.3.4.3.3.2.3">2</cn></apply><apply id="S5.E8.m1.3.4.3.3.3.cmml" xref="S5.E8.m1.3.4.3.3.3"><csymbol cd="ambiguous" id="S5.E8.m1.3.4.3.3.3.1.cmml" xref="S5.E8.m1.3.4.3.3.3">superscript</csymbol><apply id="S5.E8.m1.3.4.3.3.3.2.cmml" xref="S5.E8.m1.3.4.3.3.3"><csymbol cd="ambiguous" id="S5.E8.m1.3.4.3.3.3.2.1.cmml" xref="S5.E8.m1.3.4.3.3.3">subscript</csymbol><apply id="S5.E8.m1.3.4.3.3.3.2.2.1.cmml" xref="S5.E8.m1.3.4.3.3.3.2.2.2"><csymbol cd="latexml" id="S5.E8.m1.3.4.3.3.3.2.2.1.1.cmml" xref="S5.E8.m1.3.4.3.3.3.2.2.2.1">norm</csymbol><ci id="S5.E8.m1.3.3.cmml" xref="S5.E8.m1.3.3">𝜃</ci></apply><cn id="S5.E8.m1.3.4.3.3.3.2.3.cmml" type="integer" xref="S5.E8.m1.3.4.3.3.3.2.3">2</cn></apply><cn id="S5.E8.m1.3.4.3.3.3.3.cmml" type="integer" xref="S5.E8.m1.3.4.3.3.3.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E8.m1.3c">L_{\text{reg}}(\theta)=L(\theta)+\frac{\lambda}{2}\|\theta\|_{2}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.E8.m1.3d">italic_L start_POSTSUBSCRIPT reg end_POSTSUBSCRIPT ( italic_θ ) = italic_L ( italic_θ ) + divide start_ARG italic_λ end_ARG start_ARG 2 end_ARG ∥ italic_θ ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We compared the results with the current state of the art methods in BRSET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib84" title="">84</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib85" title="">85</a>]</cite>, and with the current state of the art foundation model RetFound <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib39" title="">39</a>]</cite> to predict diabetic retinopathy. The models demonstrated varying degrees of accuracy and F1 scores across different classification tasks (5-class, 3-class, and binary). The results can be seen in Table 2. Notably, the fusion model outperformed individual modality models, and current state of the art results underscoring the effectiveness of multimodal data fusion in medical diagnoses and the efficacy of our approach.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Model Results for Different Prediction Tasks for 5 class, 3 class, and 2 class classification</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.1.1.1.1">Modality</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.1.1.1.2">Model</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.1.1.1.3">Accuracy</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.4">F1 Macro Avg</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.5">F1 Weighted Avg</th>
<td class="ltx_td ltx_nopad_r ltx_border_tt" id="S5.T2.1.1.1.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="6" id="S5.T2.1.2.2.1">5 Class - Diabetic Retinopathy</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.3.3.1">Metadata</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.3.3.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.3.3.3">0.83</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.4">0.37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.3.3.5">0.88</td>
<td class="ltx_td ltx_border_t" id="S5.T2.1.3.3.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.4.4">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.4.4.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.4.4.2">Neural Network</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.4.4.3">0.95</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.4.4.4">0.35</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.4.4.5">0.94</td>
<td class="ltx_td" id="S5.T2.1.4.4.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.5.5.1">Image Embeddings</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.5.5.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.5.5.3">0.80</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.5.5.4">0.43</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.5.5.5">0.86</td>
<td class="ltx_td" id="S5.T2.1.5.5.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.6.6">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.6.6.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.6.6.2">Neural Network</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.6.6.3">0.96</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.6.6.4">0.52</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.6.6.5">0.95</td>
<td class="ltx_td" id="S5.T2.1.6.6.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.7.7.1">Raw Images</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.7.7.2">RetFound <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib39" title="">39</a>]</cite>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.7.7.3">0.96</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.7.7.4">0.48</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.7.7.5">0.95</td>
<td class="ltx_td" id="S5.T2.1.7.7.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.8.8.1">Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.8.8.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.8.8.3">0.82</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.8.8.4">0.43</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.8.8.5">0.87</td>
<td class="ltx_td" id="S5.T2.1.8.8.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.9.9">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.9.9.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.9.9.2">Dense Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.9.9.3">0.93</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.9.9.4">0.56</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.9.9.5">0.92</td>
<td class="ltx_td" id="S5.T2.1.9.9.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.10.10">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.10.10.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.10.10.2">Disentangled Dense Fusion (Ours)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.10.10.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.3.1">0.97</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.10.10.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.4.1">0.60</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.10.10.5"><span class="ltx_text ltx_font_bold" id="S5.T2.1.10.10.5.1">0.96</span></td>
<td class="ltx_td" id="S5.T2.1.10.10.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.11.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S5.T2.1.11.11.1">3 Class - Diabetic Retinopathy</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.12.12.1">Metadata</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.12.12.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.12.12.3">0.89</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.12.12.4">0.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.12.12.5">0.91</td>
<td class="ltx_td ltx_border_t" id="S5.T2.1.12.12.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.13.13">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.13.13.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.13.13.2">Neural Network</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.13.13.3">0.96</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.13.13.4">0.61</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.13.13.5">0.96</td>
<td class="ltx_td" id="S5.T2.1.13.13.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.14.14.1">Image Embeddings</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.14.14.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.14.14.3">0.89</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.14.14.4">0.65</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.14.14.5">0.91</td>
<td class="ltx_td" id="S5.T2.1.14.14.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.15.15">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.15.15.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.15.15.2">Neural Network</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.15.15.3">0.96</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.15.15.4">0.75</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.15.15.5">0.96</td>
<td class="ltx_td" id="S5.T2.1.15.15.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.16.16.1">Raw Images</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.16.16.2">RetFound <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib39" title="">39</a>]</cite>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.16.16.3">0.96</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.16.16.4">0.78</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.16.16.5">0.96</td>
<td class="ltx_td" id="S5.T2.1.16.16.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.17.17.1">Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.17.17.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.17.17.3">0.90</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.17.17.4">0.67</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.17.17.5">0.92</td>
<td class="ltx_td" id="S5.T2.1.17.17.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.18.18">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.18.18.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.18.18.2">Dense Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.18.18.3">0.93</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.18.18.4">0.73</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.18.18.5">0.93</td>
<td class="ltx_td" id="S5.T2.1.18.18.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.19.19">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.19.19.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.19.19.2">Disentangled Dense Fusion (Ours)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.19.19.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.19.19.3.1">0.96</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.19.19.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.19.19.4.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.19.19.5"><span class="ltx_text ltx_font_bold" id="S5.T2.1.19.19.5.1">0.96</span></td>
<td class="ltx_td" id="S5.T2.1.19.19.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.20.20">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S5.T2.1.20.20.1">2 Class - Diabetic Retinopathy</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.21.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.21.21.1">Metadata</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.21.21.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.21.21.3">0.94</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.21.21.4">0.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.21.21.5">0.95</td>
<td class="ltx_td ltx_border_t" id="S5.T2.1.21.21.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.22.22">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.22.22.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.22.22.2">Neural Network</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.22.22.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.22.22.3.1">0.98</span></th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.22.22.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.22.22.4.1">0.92</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.22.22.5"><span class="ltx_text ltx_font_bold" id="S5.T2.1.22.22.5.1">0.98</span></td>
<td class="ltx_td" id="S5.T2.1.22.22.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.23.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.23.23.1">Image Embeddings</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.23.23.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.23.23.3">0.93</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.23.23.4">0.78</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.23.23.5">0.94</td>
<td class="ltx_td" id="S5.T2.1.23.23.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.24.24">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.24.24.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.24.24.2">Neural Network</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.24.24.3">0.97</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.24.24.4">0.86</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.24.24.5">0.97</td>
<td class="ltx_td" id="S5.T2.1.24.24.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.25.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.25.25.1">Raw Images</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.25.25.2">ResNet 50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib85" title="">85</a>]</cite>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.25.25.3">0.97</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.25.25.4">0.82</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.25.25.5">N/A</td>
<td class="ltx_td" id="S5.T2.1.25.25.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.26.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.26.26.1">Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.26.26.2">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.26.26.3">0.97</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.26.26.4">0.87</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.26.26.5">0.97</td>
<td class="ltx_td" id="S5.T2.1.26.26.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.27.27">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.1.27.27.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.27.27.2">Dense Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.27.27.3">0.98</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.27.27.4">0.91</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.27.27.5">0.98</td>
<td class="ltx_td" id="S5.T2.1.27.27.6"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.28.28">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S5.T2.1.28.28.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.1.28.28.2">Disentangled Dense Fusion (Ours)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.1.28.28.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.28.28.3.1">0.98</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.28.28.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.28.28.4.1">0.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.28.28.5"><span class="ltx_text ltx_font_bold" id="S5.T2.1.28.28.5.1">0.98</span></td>
<td class="ltx_td ltx_border_bb" id="S5.T2.1.28.28.6"></td>
</tr>
</tbody>
</table>
</figure>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Potential Biases and Limitations</h4>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1">Despite the promising results, several biases and limitations were noted:</p>
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1">Geographical Bias: The dataset solely comprised Brazilian patients, potentially limiting the model’s applicability to other populations.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1">Gender Imbalance: The underrepresentation of male patients (38%) may result in gender-biased predictions.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i3.p1">
<p class="ltx_p" id="S5.I2.i3.p1.1">Age Data: A significant portion of the dataset had missing age data, which might impact the model’s effectiveness in age-related analysis.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Use case 2: Domestic Violence Prediction Using Open Data</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">This study leverages the unique capabilities of satellite imagery and internet data to enhance predictive modeling. Satellite images serve as a rich source of information, offering insights into the social determinants of health by revealing spatial and temporal changes in communities and environments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib87" title="">87</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib88" title="">88</a>]</cite>. These images can provide valuable indicators related to urban development <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib89" title="">89</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib90" title="">90</a>]</cite>, population density <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib91" title="">91</a>]</cite>, and environmental conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib92" title="">92</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib93" title="">93</a>]</cite>, all of which are crucial in understanding social dynamics that might influence domestic violence. On the other hand, internet data, encompassing Google Trends and online news, acts as a real-time reflection of societal interests and concerns. Internet data has been used to predict the behavior of diseases and social issues <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib94" title="">94</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib95" title="">95</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib96" title="">96</a>]</cite>, offering a dynamic and current perspective on public discourse and awareness. These alternative data sources are particularly beneficial in low-resource settings where traditional data collection methods might be challenging or insufficient.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Dataset Description and Data Collection</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p" id="S5.SS3.SSS1.p1.1">This use case employs a novel approach to predict domestic violence in the top 10 Colombian cities (Medellín, Cali, Soacha, Villavicencio, Pasto, Barranquilla, Bucaramanga, Ibagué, Popayán, Cúcuta) with the highest reports of such cases. The dataset spans from January 2016 to January 2023, with the following features:</p>
<ul class="ltx_itemize" id="S5.I3">
<li class="ltx_item" id="S5.I3.1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div class="ltx_para" id="S5.I3.1.p1">
<p class="ltx_p" id="S5.I3.1.p1.1">[label=]</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i1.p1">
<p class="ltx_p" id="S5.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i1.p1.1.1">Census Data (2018 Colombian Census):</span> Incorporates social determinants of health and demographic data, providing a comprehensive backdrop of the societal context. The census data included demographic information of the region analyzed. The demographic information included distributions of age, distributions of sex, and ethnicity of the population, while socioeconomic information included information such as access to water, incomes, and level of education.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i2.p1">
<p class="ltx_p" id="S5.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i2.p1.1.1">Satellite Images (July 2015 - December 2022):</span> These images, obtained from Sentinel-2 via Sentinel Hub, cover the targeted cities, offering a spatial perspective.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i3.p1">
<p class="ltx_p" id="S5.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.p1.1.1">Internet Data:</span></p>
<ul class="ltx_itemize" id="S5.I3.i3.I1">
<li class="ltx_item" id="S5.I3.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i3.I1.i1.p1">
<p class="ltx_p" id="S5.I3.i3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i1.p1.1.1">Google Trends:</span> Extracted using the topic ”Violence” and keywords related to gender violence in Spanish, offering insights into public interest and awareness.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i3.I1.i2.p1">
<p class="ltx_p" id="S5.I3.i3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i2.p1.1.1">Online Local Newspapers:</span> Aggregated violence-related news utilizing Media Cloud, capturing media attention and public discourse.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="S5.I3.i3.I1.i3.p1">
<p class="ltx_p" id="S5.I3.i3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.I1.i3.p1.1.1">GDELT Events:</span> Focused on relevant events in the selected municipalities, categorized by specific event IDs related to protests and demonstrations for rights and equality.</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Exploratory Data Analysis</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p" id="S5.SS3.SSS2.p1.1">An individual data analysis of each modality measuring frequency, format, and missing data, among other variables, was conducted. Exploratory analysis led to the selection of a cohort from Epiweek 51 of 2017 to Epiweek 52 of 2022, primarily due to the lack of comprehensive satellite imagery before 2018.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.3 </span>Preprocessing</h4>
<div class="ltx_para" id="S5.SS3.SSS3.p1">
<ul class="ltx_itemize" id="S5.I4">
<li class="ltx_item" id="S5.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i1.p1">
<p class="ltx_p" id="S5.I4.i1.p1.1">Labels: Represented as the count of domestic violence cases per Epiweek. Epiweeks with no purports were assumed to be 0.</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i2.p1">
<p class="ltx_p" id="S5.I4.i2.p1.1">Google Trends: Mapped to epiweeks for temporal alignment.</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i3.p1">
<p class="ltx_p" id="S5.I4.i3.p1.1">Media Cloud &amp; GDELT: Aggregated by epiweek and city. For GDELT, web scraping supplemented the data with extracted text from URLs. Text data was later discarded due to noise, focusing on quantitative features like publication counts and trend data.</p>
</div>
</li>
<li class="ltx_item" id="S5.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I4.i4.p1">
<p class="ltx_p" id="S5.I4.i4.p1.5">Satellite Images: The embeddings of the satellite images were extracted using Variational Autoencoder (VAE) with a ResNet 50 V2 backbone (Fig. 1). This model was trained on a wider set of 81 Colombian cities’ images from 2016 to 2018. The cohort of 81 Colombian cities was chosen to expand the dataset’s diversity of landscapes by incorporating 81 cities spatially distributed throughout the country. This spatial and temporal shift allows us to avoid data leakage, incorporating at the same time a greater diversity of spatial environments that allow the model to extract better quality embeddings. Then, the embeddings were extracted from the latent space for dimensionality reduction. The VAE was used to sample all the images into a lower dimensional space, sampling to a normal distribution. The Variational Autoencoder used for processing satellite images is fundamentally based on two mathematical components: reconstruction loss and Kullback-Leibler (KL) divergence. The reconstruction loss was, in this case, the mean squared error mse, as can be seen in equation 9. The KL Divergence measures how much the learned distribution <math alttext="q(z|x)" class="ltx_Math" display="inline" id="S5.I4.i4.p1.1.m1.1"><semantics id="S5.I4.i4.p1.1.m1.1a"><mrow id="S5.I4.i4.p1.1.m1.1.1" xref="S5.I4.i4.p1.1.m1.1.1.cmml"><mi id="S5.I4.i4.p1.1.m1.1.1.3" xref="S5.I4.i4.p1.1.m1.1.1.3.cmml">q</mi><mo id="S5.I4.i4.p1.1.m1.1.1.2" xref="S5.I4.i4.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S5.I4.i4.p1.1.m1.1.1.1.1" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.cmml"><mo id="S5.I4.i4.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.I4.i4.p1.1.m1.1.1.1.1.1" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.cmml"><mi id="S5.I4.i4.p1.1.m1.1.1.1.1.1.2" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.2.cmml">z</mi><mo fence="false" id="S5.I4.i4.p1.1.m1.1.1.1.1.1.1" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.I4.i4.p1.1.m1.1.1.1.1.1.3" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S5.I4.i4.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I4.i4.p1.1.m1.1b"><apply id="S5.I4.i4.p1.1.m1.1.1.cmml" xref="S5.I4.i4.p1.1.m1.1.1"><times id="S5.I4.i4.p1.1.m1.1.1.2.cmml" xref="S5.I4.i4.p1.1.m1.1.1.2"></times><ci id="S5.I4.i4.p1.1.m1.1.1.3.cmml" xref="S5.I4.i4.p1.1.m1.1.1.3">𝑞</ci><apply id="S5.I4.i4.p1.1.m1.1.1.1.1.1.cmml" xref="S5.I4.i4.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.I4.i4.p1.1.m1.1.1.1.1.1.1.cmml" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.I4.i4.p1.1.m1.1.1.1.1.1.2.cmml" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.2">𝑧</ci><ci id="S5.I4.i4.p1.1.m1.1.1.1.1.1.3.cmml" xref="S5.I4.i4.p1.1.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.i4.p1.1.m1.1c">q(z|x)</annotation><annotation encoding="application/x-llamapun" id="S5.I4.i4.p1.1.m1.1d">italic_q ( italic_z | italic_x )</annotation></semantics></math> (the encoder’s output) deviates from the prior distribution <math alttext="p(z)" class="ltx_Math" display="inline" id="S5.I4.i4.p1.2.m2.1"><semantics id="S5.I4.i4.p1.2.m2.1a"><mrow id="S5.I4.i4.p1.2.m2.1.2" xref="S5.I4.i4.p1.2.m2.1.2.cmml"><mi id="S5.I4.i4.p1.2.m2.1.2.2" xref="S5.I4.i4.p1.2.m2.1.2.2.cmml">p</mi><mo id="S5.I4.i4.p1.2.m2.1.2.1" xref="S5.I4.i4.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S5.I4.i4.p1.2.m2.1.2.3.2" xref="S5.I4.i4.p1.2.m2.1.2.cmml"><mo id="S5.I4.i4.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S5.I4.i4.p1.2.m2.1.2.cmml">(</mo><mi id="S5.I4.i4.p1.2.m2.1.1" xref="S5.I4.i4.p1.2.m2.1.1.cmml">z</mi><mo id="S5.I4.i4.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S5.I4.i4.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I4.i4.p1.2.m2.1b"><apply id="S5.I4.i4.p1.2.m2.1.2.cmml" xref="S5.I4.i4.p1.2.m2.1.2"><times id="S5.I4.i4.p1.2.m2.1.2.1.cmml" xref="S5.I4.i4.p1.2.m2.1.2.1"></times><ci id="S5.I4.i4.p1.2.m2.1.2.2.cmml" xref="S5.I4.i4.p1.2.m2.1.2.2">𝑝</ci><ci id="S5.I4.i4.p1.2.m2.1.1.cmml" xref="S5.I4.i4.p1.2.m2.1.1">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.i4.p1.2.m2.1c">p(z)</annotation><annotation encoding="application/x-llamapun" id="S5.I4.i4.p1.2.m2.1d">italic_p ( italic_z )</annotation></semantics></math>, which is often assumed to be a standard normal distribution. The KL divergence is given by equation 10. where <math alttext="\mu" class="ltx_Math" display="inline" id="S5.I4.i4.p1.3.m3.1"><semantics id="S5.I4.i4.p1.3.m3.1a"><mi id="S5.I4.i4.p1.3.m3.1.1" xref="S5.I4.i4.p1.3.m3.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S5.I4.i4.p1.3.m3.1b"><ci id="S5.I4.i4.p1.3.m3.1.1.cmml" xref="S5.I4.i4.p1.3.m3.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.i4.p1.3.m3.1c">\mu</annotation><annotation encoding="application/x-llamapun" id="S5.I4.i4.p1.3.m3.1d">italic_μ</annotation></semantics></math> and <math alttext="\sigma" class="ltx_Math" display="inline" id="S5.I4.i4.p1.4.m4.1"><semantics id="S5.I4.i4.p1.4.m4.1a"><mi id="S5.I4.i4.p1.4.m4.1.1" xref="S5.I4.i4.p1.4.m4.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S5.I4.i4.p1.4.m4.1b"><ci id="S5.I4.i4.p1.4.m4.1.1.cmml" xref="S5.I4.i4.p1.4.m4.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.i4.p1.4.m4.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S5.I4.i4.p1.4.m4.1d">italic_σ</annotation></semantics></math> are the mean and standard deviation of the learned distribution, and <math alttext="J" class="ltx_Math" display="inline" id="S5.I4.i4.p1.5.m5.1"><semantics id="S5.I4.i4.p1.5.m5.1a"><mi id="S5.I4.i4.p1.5.m5.1.1" xref="S5.I4.i4.p1.5.m5.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S5.I4.i4.p1.5.m5.1b"><ci id="S5.I4.i4.p1.5.m5.1.1.cmml" xref="S5.I4.i4.p1.5.m5.1.1">𝐽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.i4.p1.5.m5.1c">J</annotation><annotation encoding="application/x-llamapun" id="S5.I4.i4.p1.5.m5.1d">italic_J</annotation></semantics></math> is the dimensionality of the latent space. Finally, the total loss is just the sum equation 11.
In cases like satellite images, embeddings generated by foundation models such as DINO V2 may be less effective. In this case, we generated our embeddings using a VAE and compared them with those generated using DINO V2. The two methods were evaluated in predicting domestic violence. In all cases, the embeddings generated with our approach improved the results of DINO V2, as can be seen in Table 3.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S5.E9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\text{Reconstruction Loss}=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\hat{x}_{i})^{2}" class="ltx_Math" display="block" id="S5.E9.m1.1"><semantics id="S5.E9.m1.1a"><mrow id="S5.E9.m1.1.1" xref="S5.E9.m1.1.1.cmml"><mtext id="S5.E9.m1.1.1.3" xref="S5.E9.m1.1.1.3a.cmml">Reconstruction Loss</mtext><mo id="S5.E9.m1.1.1.2" xref="S5.E9.m1.1.1.2.cmml">=</mo><mrow id="S5.E9.m1.1.1.1" xref="S5.E9.m1.1.1.1.cmml"><mfrac id="S5.E9.m1.1.1.1.3" xref="S5.E9.m1.1.1.1.3.cmml"><mn id="S5.E9.m1.1.1.1.3.2" xref="S5.E9.m1.1.1.1.3.2.cmml">1</mn><mi id="S5.E9.m1.1.1.1.3.3" xref="S5.E9.m1.1.1.1.3.3.cmml">n</mi></mfrac><mo id="S5.E9.m1.1.1.1.2" xref="S5.E9.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E9.m1.1.1.1.1" xref="S5.E9.m1.1.1.1.1.cmml"><munderover id="S5.E9.m1.1.1.1.1.2" xref="S5.E9.m1.1.1.1.1.2.cmml"><mo id="S5.E9.m1.1.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S5.E9.m1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E9.m1.1.1.1.1.2.2.3" xref="S5.E9.m1.1.1.1.1.2.2.3.cmml"><mi id="S5.E9.m1.1.1.1.1.2.2.3.2" xref="S5.E9.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E9.m1.1.1.1.1.2.2.3.1" xref="S5.E9.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E9.m1.1.1.1.1.2.2.3.3" xref="S5.E9.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E9.m1.1.1.1.1.2.3" xref="S5.E9.m1.1.1.1.1.2.3.cmml">n</mi></munderover><msup id="S5.E9.m1.1.1.1.1.1" xref="S5.E9.m1.1.1.1.1.1.cmml"><mrow id="S5.E9.m1.1.1.1.1.1.1.1" xref="S5.E9.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S5.E9.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E9.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E9.m1.1.1.1.1.1.1.1.1" xref="S5.E9.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S5.E9.m1.1.1.1.1.1.1.1.1.2" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E9.m1.1.1.1.1.1.1.1.1.2.2" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S5.E9.m1.1.1.1.1.1.1.1.1.2.3" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S5.E9.m1.1.1.1.1.1.1.1.1.1" xref="S5.E9.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S5.E9.m1.1.1.1.1.1.1.1.1.3" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S5.E9.m1.1.1.1.1.1.1.1.1.3.2" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mo id="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.1" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S5.E9.m1.1.1.1.1.1.1.1.1.3.3" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E9.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E9.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S5.E9.m1.1.1.1.1.1.3" xref="S5.E9.m1.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E9.m1.1b"><apply id="S5.E9.m1.1.1.cmml" xref="S5.E9.m1.1.1"><eq id="S5.E9.m1.1.1.2.cmml" xref="S5.E9.m1.1.1.2"></eq><ci id="S5.E9.m1.1.1.3a.cmml" xref="S5.E9.m1.1.1.3"><mtext id="S5.E9.m1.1.1.3.cmml" xref="S5.E9.m1.1.1.3">Reconstruction Loss</mtext></ci><apply id="S5.E9.m1.1.1.1.cmml" xref="S5.E9.m1.1.1.1"><times id="S5.E9.m1.1.1.1.2.cmml" xref="S5.E9.m1.1.1.1.2"></times><apply id="S5.E9.m1.1.1.1.3.cmml" xref="S5.E9.m1.1.1.1.3"><divide id="S5.E9.m1.1.1.1.3.1.cmml" xref="S5.E9.m1.1.1.1.3"></divide><cn id="S5.E9.m1.1.1.1.3.2.cmml" type="integer" xref="S5.E9.m1.1.1.1.3.2">1</cn><ci id="S5.E9.m1.1.1.1.3.3.cmml" xref="S5.E9.m1.1.1.1.3.3">𝑛</ci></apply><apply id="S5.E9.m1.1.1.1.1.cmml" xref="S5.E9.m1.1.1.1.1"><apply id="S5.E9.m1.1.1.1.1.2.cmml" xref="S5.E9.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E9.m1.1.1.1.1.2.1.cmml" xref="S5.E9.m1.1.1.1.1.2">superscript</csymbol><apply id="S5.E9.m1.1.1.1.1.2.2.cmml" xref="S5.E9.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E9.m1.1.1.1.1.2.2.1.cmml" xref="S5.E9.m1.1.1.1.1.2">subscript</csymbol><sum id="S5.E9.m1.1.1.1.1.2.2.2.cmml" xref="S5.E9.m1.1.1.1.1.2.2.2"></sum><apply id="S5.E9.m1.1.1.1.1.2.2.3.cmml" xref="S5.E9.m1.1.1.1.1.2.2.3"><eq id="S5.E9.m1.1.1.1.1.2.2.3.1.cmml" xref="S5.E9.m1.1.1.1.1.2.2.3.1"></eq><ci id="S5.E9.m1.1.1.1.1.2.2.3.2.cmml" xref="S5.E9.m1.1.1.1.1.2.2.3.2">𝑖</ci><cn id="S5.E9.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E9.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E9.m1.1.1.1.1.2.3.cmml" xref="S5.E9.m1.1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E9.m1.1.1.1.1.1.cmml" xref="S5.E9.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E9.m1.1.1.1.1.1.2.cmml" xref="S5.E9.m1.1.1.1.1.1">superscript</csymbol><apply id="S5.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1"><minus id="S5.E9.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S5.E9.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E9.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E9.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S5.E9.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S5.E9.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E9.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.2"><ci id="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.2.2">𝑥</ci></apply><ci id="S5.E9.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E9.m1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><cn id="S5.E9.m1.1.1.1.1.1.3.cmml" type="integer" xref="S5.E9.m1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E9.m1.1c">\text{Reconstruction Loss}=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\hat{x}_{i})^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.E9.m1.1d">Reconstruction Loss = divide start_ARG 1 end_ARG start_ARG italic_n end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p3">
<table class="ltx_equation ltx_eqn_table" id="S5.E10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\text{KL Divergence}=-\frac{1}{2}\sum_{j=1}^{J}\left(1+\log(\sigma_{j}^{2})-%
\mu_{j}^{2}-\sigma_{j}^{2}\right)" class="ltx_Math" display="block" id="S5.E10.m1.2"><semantics id="S5.E10.m1.2a"><mrow id="S5.E10.m1.2.2" xref="S5.E10.m1.2.2.cmml"><mtext id="S5.E10.m1.2.2.3" xref="S5.E10.m1.2.2.3a.cmml">KL Divergence</mtext><mo id="S5.E10.m1.2.2.2" xref="S5.E10.m1.2.2.2.cmml">=</mo><mrow id="S5.E10.m1.2.2.1" xref="S5.E10.m1.2.2.1.cmml"><mo id="S5.E10.m1.2.2.1a" xref="S5.E10.m1.2.2.1.cmml">−</mo><mrow id="S5.E10.m1.2.2.1.1" xref="S5.E10.m1.2.2.1.1.cmml"><mfrac id="S5.E10.m1.2.2.1.1.3" xref="S5.E10.m1.2.2.1.1.3.cmml"><mn id="S5.E10.m1.2.2.1.1.3.2" xref="S5.E10.m1.2.2.1.1.3.2.cmml">1</mn><mn id="S5.E10.m1.2.2.1.1.3.3" xref="S5.E10.m1.2.2.1.1.3.3.cmml">2</mn></mfrac><mo id="S5.E10.m1.2.2.1.1.2" xref="S5.E10.m1.2.2.1.1.2.cmml">⁢</mo><mrow id="S5.E10.m1.2.2.1.1.1" xref="S5.E10.m1.2.2.1.1.1.cmml"><munderover id="S5.E10.m1.2.2.1.1.1.2" xref="S5.E10.m1.2.2.1.1.1.2.cmml"><mo id="S5.E10.m1.2.2.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S5.E10.m1.2.2.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E10.m1.2.2.1.1.1.2.2.3" xref="S5.E10.m1.2.2.1.1.1.2.2.3.cmml"><mi id="S5.E10.m1.2.2.1.1.1.2.2.3.2" xref="S5.E10.m1.2.2.1.1.1.2.2.3.2.cmml">j</mi><mo id="S5.E10.m1.2.2.1.1.1.2.2.3.1" xref="S5.E10.m1.2.2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E10.m1.2.2.1.1.1.2.2.3.3" xref="S5.E10.m1.2.2.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E10.m1.2.2.1.1.1.2.3" xref="S5.E10.m1.2.2.1.1.1.2.3.cmml">J</mi></munderover><mrow id="S5.E10.m1.2.2.1.1.1.1.1" xref="S5.E10.m1.2.2.1.1.1.1.1.1.cmml"><mo id="S5.E10.m1.2.2.1.1.1.1.1.2" xref="S5.E10.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E10.m1.2.2.1.1.1.1.1.1" xref="S5.E10.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S5.E10.m1.2.2.1.1.1.1.1.1.1" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.cmml"><mn id="S5.E10.m1.2.2.1.1.1.1.1.1.1.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.3.cmml">1</mn><mo id="S5.E10.m1.2.2.1.1.1.1.1.1.1.2" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.2.cmml">+</mo><mrow id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E10.m1.1.1" xref="S5.E10.m1.1.1.cmml">log</mi><mo id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1a" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">⁡</mo><mrow id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mo id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">(</mo><msubsup id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">σ</mi><mi id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">j</mi><mn id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">2</mn></msubsup><mo id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S5.E10.m1.2.2.1.1.1.1.1.1.2" xref="S5.E10.m1.2.2.1.1.1.1.1.1.2.cmml">−</mo><msubsup id="S5.E10.m1.2.2.1.1.1.1.1.1.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.2" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.2.cmml">μ</mi><mi id="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.3.cmml">j</mi><mn id="S5.E10.m1.2.2.1.1.1.1.1.1.3.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.3.cmml">2</mn></msubsup><mo id="S5.E10.m1.2.2.1.1.1.1.1.1.2a" xref="S5.E10.m1.2.2.1.1.1.1.1.1.2.cmml">−</mo><msubsup id="S5.E10.m1.2.2.1.1.1.1.1.1.4" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.cmml"><mi id="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.2" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.2.cmml">σ</mi><mi id="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.3.cmml">j</mi><mn id="S5.E10.m1.2.2.1.1.1.1.1.1.4.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.3.cmml">2</mn></msubsup></mrow><mo id="S5.E10.m1.2.2.1.1.1.1.1.3" xref="S5.E10.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E10.m1.2b"><apply id="S5.E10.m1.2.2.cmml" xref="S5.E10.m1.2.2"><eq id="S5.E10.m1.2.2.2.cmml" xref="S5.E10.m1.2.2.2"></eq><ci id="S5.E10.m1.2.2.3a.cmml" xref="S5.E10.m1.2.2.3"><mtext id="S5.E10.m1.2.2.3.cmml" xref="S5.E10.m1.2.2.3">KL Divergence</mtext></ci><apply id="S5.E10.m1.2.2.1.cmml" xref="S5.E10.m1.2.2.1"><minus id="S5.E10.m1.2.2.1.2.cmml" xref="S5.E10.m1.2.2.1"></minus><apply id="S5.E10.m1.2.2.1.1.cmml" xref="S5.E10.m1.2.2.1.1"><times id="S5.E10.m1.2.2.1.1.2.cmml" xref="S5.E10.m1.2.2.1.1.2"></times><apply id="S5.E10.m1.2.2.1.1.3.cmml" xref="S5.E10.m1.2.2.1.1.3"><divide id="S5.E10.m1.2.2.1.1.3.1.cmml" xref="S5.E10.m1.2.2.1.1.3"></divide><cn id="S5.E10.m1.2.2.1.1.3.2.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.3.2">1</cn><cn id="S5.E10.m1.2.2.1.1.3.3.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.3.3">2</cn></apply><apply id="S5.E10.m1.2.2.1.1.1.cmml" xref="S5.E10.m1.2.2.1.1.1"><apply id="S5.E10.m1.2.2.1.1.1.2.cmml" xref="S5.E10.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.2.1.cmml" xref="S5.E10.m1.2.2.1.1.1.2">superscript</csymbol><apply id="S5.E10.m1.2.2.1.1.1.2.2.cmml" xref="S5.E10.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.2.2.1.cmml" xref="S5.E10.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S5.E10.m1.2.2.1.1.1.2.2.2.cmml" xref="S5.E10.m1.2.2.1.1.1.2.2.2"></sum><apply id="S5.E10.m1.2.2.1.1.1.2.2.3.cmml" xref="S5.E10.m1.2.2.1.1.1.2.2.3"><eq id="S5.E10.m1.2.2.1.1.1.2.2.3.1.cmml" xref="S5.E10.m1.2.2.1.1.1.2.2.3.1"></eq><ci id="S5.E10.m1.2.2.1.1.1.2.2.3.2.cmml" xref="S5.E10.m1.2.2.1.1.1.2.2.3.2">𝑗</ci><cn id="S5.E10.m1.2.2.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E10.m1.2.2.1.1.1.2.3.cmml" xref="S5.E10.m1.2.2.1.1.1.2.3">𝐽</ci></apply><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1"><minus id="S5.E10.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.2"></minus><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1"><plus id="S5.E10.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.2"></plus><cn id="S5.E10.m1.2.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.3">1</cn><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1"><log id="S5.E10.m1.1.1.cmml" xref="S5.E10.m1.1.1"></log><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2">𝜎</ci><ci id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑗</ci></apply><cn id="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">2</cn></apply></apply></apply><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3">superscript</csymbol><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.2">𝜇</ci><ci id="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.3.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.2.3">𝑗</ci></apply><cn id="S5.E10.m1.2.2.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.1.1.1.1.3.3">2</cn></apply><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.1.1.1.4.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4">superscript</csymbol><apply id="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.1.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4">subscript</csymbol><ci id="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.2.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.2">𝜎</ci><ci id="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.3.cmml" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.2.3">𝑗</ci></apply><cn id="S5.E10.m1.2.2.1.1.1.1.1.1.4.3.cmml" type="integer" xref="S5.E10.m1.2.2.1.1.1.1.1.1.4.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E10.m1.2c">\text{KL Divergence}=-\frac{1}{2}\sum_{j=1}^{J}\left(1+\log(\sigma_{j}^{2})-%
\mu_{j}^{2}-\sigma_{j}^{2}\right)</annotation><annotation encoding="application/x-llamapun" id="S5.E10.m1.2d">KL Divergence = - divide start_ARG 1 end_ARG start_ARG 2 end_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_J end_POSTSUPERSCRIPT ( 1 + roman_log ( italic_σ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) - italic_μ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_σ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS3.SSS3.p4">
<table class="ltx_equation ltx_eqn_table" id="S5.E11">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math alttext="\text{Total Loss}=\text{Reconstruction Loss}+\text{KL Divergence}" class="ltx_Math" display="block" id="S5.E11.m1.1"><semantics id="S5.E11.m1.1a"><mrow id="S5.E11.m1.1.1" xref="S5.E11.m1.1.1.cmml"><mtext id="S5.E11.m1.1.1.2" xref="S5.E11.m1.1.1.2a.cmml">Total Loss</mtext><mo id="S5.E11.m1.1.1.1" xref="S5.E11.m1.1.1.1.cmml">=</mo><mrow id="S5.E11.m1.1.1.3" xref="S5.E11.m1.1.1.3.cmml"><mtext id="S5.E11.m1.1.1.3.2" xref="S5.E11.m1.1.1.3.2a.cmml">Reconstruction Loss</mtext><mo id="S5.E11.m1.1.1.3.1" xref="S5.E11.m1.1.1.3.1.cmml">+</mo><mtext id="S5.E11.m1.1.1.3.3" xref="S5.E11.m1.1.1.3.3a.cmml">KL Divergence</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E11.m1.1b"><apply id="S5.E11.m1.1.1.cmml" xref="S5.E11.m1.1.1"><eq id="S5.E11.m1.1.1.1.cmml" xref="S5.E11.m1.1.1.1"></eq><ci id="S5.E11.m1.1.1.2a.cmml" xref="S5.E11.m1.1.1.2"><mtext id="S5.E11.m1.1.1.2.cmml" xref="S5.E11.m1.1.1.2">Total Loss</mtext></ci><apply id="S5.E11.m1.1.1.3.cmml" xref="S5.E11.m1.1.1.3"><plus id="S5.E11.m1.1.1.3.1.cmml" xref="S5.E11.m1.1.1.3.1"></plus><ci id="S5.E11.m1.1.1.3.2a.cmml" xref="S5.E11.m1.1.1.3.2"><mtext id="S5.E11.m1.1.1.3.2.cmml" xref="S5.E11.m1.1.1.3.2">Reconstruction Loss</mtext></ci><ci id="S5.E11.m1.1.1.3.3a.cmml" xref="S5.E11.m1.1.1.3.3"><mtext id="S5.E11.m1.1.1.3.3.cmml" xref="S5.E11.m1.1.1.3.3">KL Divergence</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E11.m1.1c">\text{Total Loss}=\text{Reconstruction Loss}+\text{KL Divergence}</annotation><annotation encoding="application/x-llamapun" id="S5.E11.m1.1d">Total Loss = Reconstruction Loss + KL Divergence</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="500" id="S5.F5.g1" src="x5.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Satellite image embedding extraction approach using a variational autoencoder with a Resnet 50 V2 backbone as encoder.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.4 </span>Disentangled Dense Fusion for Time Series</h4>
<div class="ltx_para" id="S5.SS3.SSS4.p1">
<p class="ltx_p" id="S5.SS3.SSS4.p1.1">The predictive modeling was structured as a regression task using a sliding window of 3 epiweeks. The data was chronologically split (80% train, 20% test) and normalized. The model architecture can be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.F6" title="Figure 6 ‣ 5.3.4 Disentangled Dense Fusion for Time Series ‣ 5.3 Use case 2: Domestic Violence Prediction Using Open Data ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">6</span></a>. The model was designed to accept two modalities as input A and B. Each modality is passed through two temporal feature extraction blocks and two modality-specific feature extractor networks. The rest of the architecture is the same as our Disentangled Dense Fusion for classification tasks, except that the objective loss term in the final loss here is mean square error loss instead of the focal loss/cross entropy.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S5.F6.g1" src="x6.png" width="914"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Disentangled dense data fusion for temporal prediction tasks.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.SSS4.p2">
<p class="ltx_p" id="S5.SS3.SSS4.p2.1">To avoid overfitting during the training of the model, early stopping was applied using an independent evaluation set as we evaluate the output of the model at the end of each training epoch. Since overfitting is caused by a continuous decrease of the training loss and increase in training performance, while a continuous loss in the capacity of the model to generalize; if the performance of the model in the evaluation loss starts decreasing, overfitting is observed. If after a number of epochs, defined by 7 in our case, the performance in validation keeps decreasing, then the model stops the training and we take the weights with the best validation performance for further testing.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.5 </span>Results</h4>
<div class="ltx_para" id="S5.SS3.SSS5.p1">
<p class="ltx_p" id="S5.SS3.SSS5.p1.1">To evaluate the modalities’ performance in predicting domestic violence, we conducted experiments where we tested different combinations of data sources and evaluated using metrics such as MAE, MSE, SMAPE, and R2. All the experiments were run 3 times, and the average value and standard deviation were reported, as seen in Table 3. The performance of our embedding generation method was also assessed using the fusion model to combine metadata and image embeddings to predict domestic violence. The same metrics were measured and reported in Table 3. We can see that simply adding more information without regularization will not help the learning, as learning all modalities concatenated together with MLP performs worse than just Internet Data+Census data. Our disentangled dense fusion method indeed eliminates the redundant information across modalities and achieves around 4.2% <math alttext="R^{2}" class="ltx_Math" display="inline" id="S5.SS3.SSS5.p1.1.m1.1"><semantics id="S5.SS3.SSS5.p1.1.m1.1a"><msup id="S5.SS3.SSS5.p1.1.m1.1.1" xref="S5.SS3.SSS5.p1.1.m1.1.1.cmml"><mi id="S5.SS3.SSS5.p1.1.m1.1.1.2" xref="S5.SS3.SSS5.p1.1.m1.1.1.2.cmml">R</mi><mn id="S5.SS3.SSS5.p1.1.m1.1.1.3" xref="S5.SS3.SSS5.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS5.p1.1.m1.1b"><apply id="S5.SS3.SSS5.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.SSS5.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1">superscript</csymbol><ci id="S5.SS3.SSS5.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS5.p1.1.m1.1.1.2">𝑅</ci><cn id="S5.SS3.SSS5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.SSS5.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS5.p1.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.SSS5.p1.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> improvement over dense fusion.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of the 3 modalities (Census data, Internet data and Satellite Images) for domestic violence prediction using our fusion model.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T3.1.1.1.1">Modality</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.2">MAE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.3">RMSE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.4">sMAPE</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.5">R2</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.2.1.1">Satellite Images (DinoV2)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.2">27.135±0.535</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.3">38.287±1.519</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.1.4">53.385±5.934</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T3.1.2.1.5">0.358±0.050</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.3.2.1">Satellite Images (Resnet50 v2)</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.2">25.885±4.262</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.3">33.897±4.219</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.3.2.4">46.034±4.939</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.3.2.5">0.490±0.127</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.4.3.1">Census Data</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.2">28.039±1.082</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.3">41.862±5.270</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.4.3.4">46.236±2.870</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.4.3.5">0.221±0.194</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.5.4.1">Satellite Images + Census Data</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.2">25.885±4.262</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.3">33.897±4.219</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.5.4.4">46.034±4.939</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.5.4.5">0.490±0.127</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.6.5.1">Internet Data + Census Data</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.6.5.2">22.393±2.345</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.6.5.3">28.766±2.691</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.6.5.4">38.487±2.227</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.6.5.5">0.691±0.057</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.7.6.1">All modalities (MLP)</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.7.6.2">22.487±2.260</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.7.6.3">29.994±2.391</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.7.6.4">37.992±7.380</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.7.6.5">0.6652±0.054</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.8.7.1">All modalities (Dense Fusion)</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.8.7.2">21.548±0.724</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.8.7.3">25.390±0.185</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.8.7.4">25.732±0.580</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.1.8.7.5">0.812±0.012</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.1.9.8.1">All modalities (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.9.8.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.9.8.2.1">14.664±0.652</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.9.8.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.9.8.3.1">20.02±0.327</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.9.8.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.9.8.4.1">24.868±0.471</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T3.1.9.8.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.9.8.5.1">0.854±0.015</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS6">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.6 </span>Bias Consideration</h4>
<div class="ltx_para" id="S5.SS3.SSS6.p1">
<p class="ltx_p" id="S5.SS3.SSS6.p1.1">Notably, the model exhibits biases:</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS6.p2">
<ul class="ltx_itemize" id="S5.I5">
<li class="ltx_item" id="S5.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I5.i1.p1">
<p class="ltx_p" id="S5.I5.i1.p1.1">Geographical Limitation: Data from only 10 cities may not represent broader trends in Colombia.</p>
</div>
</li>
<li class="ltx_item" id="S5.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I5.i2.p1">
<p class="ltx_p" id="S5.I5.i2.p1.1">Sampling Bias: The dataset is limited to the top 10 Colombian cities with the most reports of domestic violence. This geographic focus may not capture the nuances and characteristics of domestic violence incidents in smaller cities or rural areas</p>
</div>
</li>
<li class="ltx_item" id="S5.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I5.i3.p1">
<p class="ltx_p" id="S5.I5.i3.p1.1">Potential Shortcut Learning: There’s a risk that the model learns shortcut features, like seasonal patterns, rather than actual indicators of domestic violence.</p>
</div>
</li>
<li class="ltx_item" id="S5.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I5.i4.p1">
<p class="ltx_p" id="S5.I5.i4.p1.1">Internet Data and Public Perception Bias: Using Google Trends and online news articles as part of the features may introduce biases related to public perception and media attention, which do not always accurately reflect the actual incidence of domestic violence.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Use case 3: Chest X-ray diagnosis and bias identification using MIMIC CXR</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">For our third use case, the Medical Information Mart for Intensive Care in its Chest X-ray version (MIMIC-CXR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib97" title="">97</a>]</cite> was used. MIMIC-CXR is a large dataset, publicly available, that contains a collection of chest radiographs paired with clinical notes, offering a perfect multimodal X-ray dataset used in many multimodal tasks. The dataset was collected from the Beth Israel Deaconess Medical Center in Boston, and is composed of 371,920 chest X-ray images from 227,943 imaging studies of 65,079 patients. The dataset includes many tasks including clinical tasks such as disease prediction, and fairness tasks such as race identification, or sex prediction. In this case, we will evaluate our method on the clinical task disease diagnosis, and the fairness task sex prediction.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.1 </span>Dataset Description and Data Collection</h4>
<div class="ltx_para" id="S5.SS4.SSS1.p1">
<p class="ltx_p" id="S5.SS4.SSS1.p1.1">Given that the focus of this analysis is sex prediction, and disease prediction. In this case, we will center our analysis on those two variables. As a first step we excluded all patients with undetermined race to avoid incomplete data and reports, our cohort contains a subset of 153,128 image and text pairs. The sex prediction contains the categories male and female, and presents a distribution of 82,026 (53.56 %) male patients, and 71,102 (46.43%) female patients. The disease prediction was grouped into 4 possible conditions labeled as: others with 90,843 (59.32%) data points, no finding with 47,184 (30.81 %) data points, pneumonia with 11,202 (7.31%) data points, and Lung Lesion with 3,899 (2.55%) data points.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.2 </span>Preprocessing</h4>
<div class="ltx_para" id="S5.SS4.SSS2.p1">
<p class="ltx_p" id="S5.SS4.SSS2.p1.1">To prepare the MIMIC-CXR dataset for analysis, we implemented several preprocessing steps:</p>
</div>
<div class="ltx_para" id="S5.SS4.SSS2.p2">
<ul class="ltx_itemize" id="S5.I6">
<li class="ltx_item" id="S5.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I6.i1.p1">
<p class="ltx_p" id="S5.I6.i1.p1.1">Exclusion of Incomplete Records: Patients with unspecified race were excluded to ensure an analysis of patients with full metadata and reports, reducing the number of data points from 371,920 to 153,128.</p>
</div>
</li>
<li class="ltx_item" id="S5.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I6.i2.p1">
<p class="ltx_p" id="S5.I6.i2.p1.1">Image Conversion: All X-ray images were converted to JPG format with a resolution of 224x224 pixels to reduce computational demands without significantly compromising image quality.</p>
</div>
</li>
<li class="ltx_item" id="S5.I6.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I6.i3.p1">
<p class="ltx_p" id="S5.I6.i3.p1.1">Train-test split: We splitted the dataset into training, testing, and validation splits using the official split defined in the original dataset.</p>
</div>
</li>
<li class="ltx_item" id="S5.I6.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I6.i4.p1">
<p class="ltx_p" id="S5.I6.i4.p1.1">Image Embedding Extraction: We utilized Dino V2 to convert images into vector embeddings, facilitating efficient computational processing and analysis.</p>
</div>
</li>
<li class="ltx_item" id="S5.I6.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I6.i5.p1">
<p class="ltx_p" id="S5.I6.i5.p1.1">Text Embedding Extraction: We used the language foundation model Llama 2 with its 7 billion parameter configuration to convert the text in the clinical notes into vector embeddings, enabling a nuanced understanding of clinical notes in a lower dimensional and computationally efficient representation.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.3 </span>Modeling</h4>
<div class="ltx_para" id="S5.SS4.SSS3.p1">
<p class="ltx_p" id="S5.SS4.SSS3.p1.1">We apply the exact same training set up, model architecture and loss optimization as in the diabetic retinopathy classification task, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#S5.F4" title="Figure 4 ‣ 5.1.3 Disentangled Dense Fusion ‣ 5.1 Use case 1: Diabetic Retinopathy ‣ 5 Use Cases ‣ DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era"><span class="ltx_text ltx_ref_tag">4</span></a>. The single modality models were a logistic regression model, and a simple neural network composed. Early stopping with patience = 7 was applied.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.4 </span>Results</h4>
<div class="ltx_para" id="S5.SS4.SSS4.p1">
<p class="ltx_p" id="S5.SS4.SSS4.p1.1">The performance metrics measured for this task were the accuracy and the Area Under the Curve (AUC) with macro average, since these are the most commonly used metrics for this specific dataset. The results of sex prediction were measured using the single modality models, and multimodal models, and compared with related works.
As can be seen in Table 4, for age prediction, our model archived an AUC of 0.99 for the Fusion model using a neural network archiving same results as the state of the art models in this same task and datasets using larger models like DenseNet-121 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib98" title="">98</a>]</cite>, ResNet18, ResNet50, VGG19, or InceptionV3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib99" title="">99</a>]</cite>.
For the disease classification, results can be seen in Table 5. The best performing model was the logistic regression using only text data reaching a macro AUC of 0.92 and the fusion model using the neural network with an accuracy of 0.80. These results are comparable with related work results for clinical diagnosis using MIMIC CXR, surpassing the macro AUC results reported in literature archiving 0.89 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib100" title="">100</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.12278v2#bib.bib101" title="">101</a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>MIMIC CXR Results for Sex Classification Task</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T4.1.1.1.1">Modality</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T4.1.1.1.2">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.1.1.1.3">Accuracy</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.1.1.1.4">AUC Macro Avg</th>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="4" id="S5.T4.1.2.2.1">Sex Classification</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.3.1.1">Images</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.3.1.2">Logistic Regression</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.1.3">0.92</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T4.1.3.1.4">0.97</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.1.4.2.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.4.2.2">Neural Network</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.2.3">0.92</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.4.2.4">0.98</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.5.3.1">Text</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.5.3.2">Logistic Regression</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.3.3">0.76</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.5.3.4">0.86</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.6.4">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.1.6.4.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.6.4.2">Neural Network</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.4.3">0.77</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.6.4.4">0.88</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.7.5.1">Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.7.5.2">Logistic Regression</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.5.3">0.92</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.7.5.4">0.97</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.8.6">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T4.1.8.6.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.8.6.2">Dense Fusion</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.6.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.6.3.1">0.94</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.8.6.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.6.4.1">0.99</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.9.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S5.T4.1.9.7.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T4.1.9.7.2">Disentangled Dense Fusion (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.9.7.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.7.3.1">0.94</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T4.1.9.7.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.7.4.1">0.99</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>MIMIC CXR Results for Disease Classification Task</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T5.1.1.1.1">Modality</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T5.1.1.1.2">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.3">Accuracy</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.4">AUC Macro Avg</th>
</tr>
<tr class="ltx_tr" id="S5.T5.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="4" id="S5.T5.1.2.2.1">Disease Classification</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.1.3.1.1">Images</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.1.3.1.2">Logistic Regression</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.3.1.3">0.44</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T5.1.3.1.4">0.71</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T5.1.4.2.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.4.2.2">Neural Network</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.4.2.3">0.50</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T5.1.4.2.4">0.63</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.5.3.1">Text</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.5.3.2">Logistic Regression</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.5.3.3">0.74</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T5.1.5.3.4">0.72</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.6.4">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T5.1.6.4.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.6.4.2">Neural Network</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.6.4.3">0.78</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T5.1.6.4.4">0.76</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.7.5.1">Fusion</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.7.5.2">Logistic Regression</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.7.5.3">0.48</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T5.1.7.5.4">0.74</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.8.6">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T5.1.8.6.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.8.6.2">Dense Fusion</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.8.6.3">0.76</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T5.1.8.6.4">0.78</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.9.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S5.T5.1.9.7.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T5.1.9.7.2">Disentangled Dense Fusion (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.9.7.3"><span class="ltx_text ltx_font_bold" id="S5.T5.1.9.7.3.1">0.80</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T5.1.9.7.4"><span class="ltx_text ltx_font_bold" id="S5.T5.1.9.7.4.1">0.84</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.5 </span>Bias Consideration</h4>
<div class="ltx_para" id="S5.SS4.SSS5.p1">
<ul class="ltx_itemize" id="S5.I7">
<li class="ltx_item" id="S5.I7.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I7.i1.p1">
<p class="ltx_p" id="S5.I7.i1.p1.1">Geographical Bias: The MIMIC-CXR dataset is derived from a single hospital in Boston, limiting the model’s applicability to populations in different geographic regions with varying disease prevalence and demographic characteristics.</p>
</div>
</li>
<li class="ltx_item" id="S5.I7.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I7.i2.p1">
<p class="ltx_p" id="S5.I7.i2.p1.1">Demographic Representation: The inclusion of sex labels allows for the assessment of model performance across different demographic groups. However, it also highlights the risk of perpetuating existing biases in medical diagnosis if not carefully addressed. Other analysis such as fairness analysis on variables like sex and individual group performance should be addressed.</p>
</div>
</li>
<li class="ltx_item" id="S5.I7.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I7.i3.p1">
<p class="ltx_p" id="S5.I7.i3.p1.1">Disease Label Bias: The classification of diseases in the dataset may reflect historical diagnostic biases, potentially influencing the AI models’ training and predictions.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S5.SS4.SSS5.p1.1">To mitigate these biases, strategies such as diversifying the training data, implementing fairness-aware machine learning techniques, and conducting extensive validation across different populations were recommended.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The framework proposed in this paper presents a novel approach for multimodal data fusion centered on the use of embeddings, foundation models, and data mining techniques. It addresses an efficient process for extracting knowledge from diverse data modalities while considering resource constraints. In this section, we discuss the advantages and implications of our approach, contrast it with existing models, and discuss potential limitations.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Advantages of the Proposed Framework</h3>
<div class="ltx_para" id="S6.SS1.p1">
<ul class="ltx_itemize" id="S6.I1">
<li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i1.p1">
<p class="ltx_p" id="S6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">Efficiency and Flexibility:</span> Our framework introduces a direct and efficient communication channel between the human-in-the-loop and all model levels, enhancing the ability to detect and correct errors at early stages. This feature is vital in resource-constrained settings and real-time decision-making scenarios, such as healthcare or IoT applications.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i2.p1">
<p class="ltx_p" id="S6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">Revisitation of Levels:</span> By allowing revisits to previous levels, the framework accommodates changes in data quality or requirements. This flexibility is a significant departure from the one-way approach of traditional DFGI and JDL models.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i3.p1">
<p class="ltx_p" id="S6.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i3.p1.1.1">Enhanced Data Understanding:</span> Incorporating data understanding from the CRISP-DM model into our framework enhances data quality at its earliest stages. Understanding the nature and quality of diverse data modalities becomes a cornerstone for effective data processing, fusion, and modeling reliability.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i4.p1">
<p class="ltx_p" id="S6.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i4.p1.1.1">Dimensionality Reduction with Embeddings:</span> Using foundation models and embeddings introduces an efficient solution for high-dimensional modalities like text and images. This method reduces computational costs for model training and data storage, making it a practical choice for resource-constrained environments.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i5.p1">
<p class="ltx_p" id="S6.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i5.p1.1.1">Causal Inference:</span> By introducing the possibility of causal inference at Level 3, our framework mitigates the impact of bias, especially when data collection is challenging. This addition provides more accurate and realistic predictions in uncertain environments, such as medical or environmental applications.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i6.p1">
<p class="ltx_p" id="S6.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i6.p1.1.1">Business Understanding:</span> Our framework emphasizes the importance of business understanding at the initial stages and throughout the entire process. This holistic approach ensures that the fusion of data aligns with the overarching objectives and constraints of the application.</p>
</div>
</li>
<li class="ltx_item" id="S6.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S6.I1.i7.p1">
<p class="ltx_p" id="S6.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="S6.I1.i7.p1.1.1">Bias mitigation:</span> Our framework incorporates a dedicated level (Level 7 - Bias Assessment) to systematically address and mitigate bias throughout the entire DF-DM model. By recognizing that bias can manifest at different stages, we provide some strategies for each aspect. This proactive approach involves techniques such as diverse data collection, bias detection, preprocessing, analysis of foundation models, causal inference, bias awareness training, and audits or peer review.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Comparison with Existing Models</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">While traditional data fusion models, such as the DFGI model, offer a structured approach, they often need more flexibility and efficiency to handle diverse data modalities, particularly in resource-limited settings. Our proposed framework bridges these gaps by drawing inspiration from the well-established DFGI model and integrating the flexibility and modern data understanding elements of the CRISP-DM model and the most up-to-date DL techniques. The introduction of foundation models and embeddings further enhances the efficiency and effectiveness of the proposed model.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Dense Mutual Information Model</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">Our approach systematically maximizes the shared information content between the embeddings of different modalities while allowing for dense modality interactions. This method ensures that the fusion process retains the most relevant and complementary features across data sources, facilitating a more coherent yet diverse representation of the data.
Our approach stands out for its ability to navigate the inherent information optimization challenges of multimodal fusion, such as information redundancy caused by high dimensionality and noisy inputs, and poor joint representation modeling due to heterogeneity of the data sources. Traditional methods often struggle to reconcile differences between modalities and learn useful joint representations, leading to suboptimal fusion outcomes as can be seen in use case 2, which shows that monotonically adding modalities does not guarantee performance boost. In contrast, our model leverages the mutual information metric to identify and disentangle the underlying correlations between modalities, showing improvement across 3 use cases. Furthermore, the model’s lightweight and efficient design ensures its applicability in resource-constrained settings, making it a versatile tool for a wide range of applications in healthcare, environmental monitoring, and beyond.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Use Cases</h3>
<section class="ltx_subsubsection" id="S6.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.1 </span>Use case 1: Diabetic Retinopathy</h4>
<div class="ltx_para" id="S6.SS4.SSS1.p1">
<p class="ltx_p" id="S6.SS4.SSS1.p1.1">In the case of Diabetic Retinopathy, our DF-DM model employed a logistic regression, and a neural network-based approach, demonstrating that a relatively simple machine learning algorithm can yield significant results even outperforming the state of the results in diabetic retinopathy using BRSET. This way, the DF-DM model proves to be particularly beneficial in environments where resources and specialized knowledge are scarce.
In this case, we can also see how the use of a fusion model represented an improvement in the performance of diabetic retinopathy classification. By combining different modalities, the fusion model enhanced the model’s performance.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.2 </span>Use case 2: Domestic Violence Prediction Using Open Data</h4>
<div class="ltx_para" id="S6.SS4.SSS2.p1">
<p class="ltx_p" id="S6.SS4.SSS2.p1.1">In the context of predicting domestic violence, the model showcased its ability to tackle complex social issues using publicly available data. This is particularly relevant in areas where data collection faces economic, geographical, or social barriers. The methodology can be generalized and adapted to various contexts, emphasizing its versatility and applicability.</p>
</div>
<div class="ltx_para" id="S6.SS4.SSS2.p2">
<p class="ltx_p" id="S6.SS4.SSS2.p2.1">Notably, the use of self-supervised learning in domain-specific scenarios, such as our Resnet 50 V2 VAE model, outperformed foundation computer vision models like Dino V2. This highlights the importance of domain specific knowledge for data analysis and model training.</p>
</div>
<div class="ltx_para" id="S6.SS4.SSS2.p3">
<p class="ltx_p" id="S6.SS4.SSS2.p3.1">The introduction of a temporal data fusion model was fundamental in handling heterogeneous data. However, the model using internet and census data improved the performance of the model employing all modalities. This could be attributed to the potential noise in satellite imagery, which, while informative, has less predictive capacity than internet data for predicting domestic violence. Incorporating attention mechanisms in the fusion process could mitigate this issue.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.3 </span>Use case 3: MIMIC CXR Clinical notes and x-ray images</h4>
<div class="ltx_para" id="S6.SS4.SSS3.p1">
<p class="ltx_p" id="S6.SS4.SSS3.p1.1">The MIMIC-CXR dataset presented an evaluation of the DF-DM model’s efficacy across both clinical and fairness tasks, specifically disease diagnosis and sex prediction. This dual-focused analysis underscores the versatility of our model, not only in tackling complex medical diagnostic challenges but also in addressing critical issues of bias within AI-driven healthcare solutions. The implementation of our model on this extensive dataset, encompassing a broad spectrum of chest radiographs paired with clinical notes, highlights the model’s capability to process and derive insights from multimodal data effectively. This ability is paramount in the context of healthcare, where the integration of various data types can significantly enhance diagnostic accuracy and patient outcomes.
By achieving superior, performance metrics against state-of-the-art models in these tasks, our model demonstrates its potential to serve as a valuable tool in clinical settings. The inclusion of sex prediction as a fairness task further enriches our analysis, providing a platform to detect and mitigate potential biases inherent in machine learning models. Such considerations are crucial in ensuring that AI-driven healthcare solutions promote equity and do not perpetuate existing disparities.
The successful application of the DF-DM model in this use case not only validates its conceptual framework but also accentuates its practical utility in real-world scenarios. By navigating the challenges presented by the high-dimensional and heterogeneous nature of the MIMIC-CXR dataset, our model underscores the importance of leveraging embeddings and foundation models to streamline data processing and enhance computational efficiency.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS4.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.4.4 </span>General Comments</h4>
<div class="ltx_para" id="S6.SS4.SSS4.p1">
<p class="ltx_p" id="S6.SS4.SSS4.p1.1">Both case studies underline the pivotal role of data analysis in detecting noise, removing outliers, and establishing a robust cohort. This process is essential in all data fusion projects to avoid costly errors later in the project.
The use of embeddings in our model provided a simple and cost-effective solution, facilitating the fusion process. Additionally, acknowledging data bias is crucial in every step of data fusion. Recognizing the limitations of data and modeling approaches is vital to prevent future harm and bias.
Utilizing diverse metrics offered a more comprehensive understanding of the results, reducing the risk of further bias.
Although the DF-DM process model applied in three use cases showed its effectiveness and potential applicability in other contexts, it is important to note the limitations of our approach. While successful in the specific cases of Diabetic Retinopathy, Domestic Violence Prediction, and Disease and Sex classification from radiological data, applying this model to different use cases might yield other challenges, diverse results, and unique specifications. Each application demands a tailored approach, considering the distinct nature of the data and the specific problem at hand.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Limitations and Future Directions</h3>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">It is essential to acknowledge that our framework, while addressing many challenges in multimodal data fusion, has limitations. The effectiveness of our approach depends on the availability of foundation models, which may not always be accessible in specific domains. Additionally, the human-in-the-loop approach introduced in Level 5 may require additional resources and time.
As a future direction, research can focus on optimizing the framework for scenarios where foundation models are not readily available, exploring the development of more efficient techniques for dimensionality reduction, and further refining the interaction between human experts and the model to minimize resource requirements.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we introduced the Data Fusion for Data Mining (DF-DM) model, a groundbreaking process model that not only leverages the power of embeddings and foundation models for efficient data fusion but also introduces a novel mutual information based dense fusion model. By optimizing for mutual information, our model ensures that the fused data representation captures the most relevant shared information between modalities while ensuring modality-specific expressiveness, significantly improving the cohesion and efficacy of the fusion process. Our approach enhances efficiency, flexibility, and data understanding while considering resource constraints. By bridging the gaps in existing models, we provide a pathway for improved data fusion in a wide range of applications. We also provided a validation of the model showcasing three healthcare scenarios proving the effectiveness of the approach in healthcare settings.
The proposed DF-DM and mutual embedding information alignment model offer a foundational approach to multimodal data fusion, addressing the challenges of efficiency, flexibility, and data understanding. However, it is essential to acknowledge and actively mitigate biases that may arise in the complex process of integrating diverse data modalities. Including Level 7 - Bias Assessment and the outlined strategies reflect our commitment to promoting fairness, equity, and reliability in the fusion of multimodal data.
As the volume and complexity of multimodal data continue to grow, this framework offers a promising solution that combines the best of traditional data fusion models with the most used techniques in data mining and deep learning with embeddings and foundation models. This research provides a way for more efficient and resource-aware data fusion processes, contributing to advancements in healthcare, environmental sciences, and beyond.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">LAC is funded by the National Institute of Health through R01 EB017205, DS-I Africa U54 TW012043-01 and Bridge2AI OT2OD032701, and the National Science Foundation through ITEST 2148451. DML was funded by a grant from the Colombian Agency of Science, Technology, and Innovation Colciencias under Call 896-2021, project “Knowledge management on the effects of violence on health in the Pacific region of Nariño. A social determinants of health approach”, project ID 110489684405, Contract. 647-2021.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.1.1">
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.1.1.1.1">\bibcommenthead</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Goodwin, P.:
Tape and cloud: Solving storage problems in the zettabyte era o f data


</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Pan, I.,
Mason, L.R.,
Matar, O.K.:
Data-centric engineering: integrating simulation, machine learning and statistics. challenges and opportunities
<span class="ltx_text ltx_font_bold" id="bib.bib2.1.1">249</span>,
117271
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.ces.2021.117271" title="">https://doi.org/10.1016/j.ces.2021.117271</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Furman, J.,
Seamans, R.:
AI and the economy
<span class="ltx_text ltx_font_bold" id="bib.bib3.1.1">19</span>,
161–191
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1086/699936" title="">https://doi.org/10.1086/699936</a> .
_eprint: https://doi.org/10.1086/699936


</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Shaik, T.,
Tao, X.,
Li, L.,
Xie, H.,
Velásquez, J.D.:
A survey of multimodal information fusion for smart healthcare: Mapping the journey from data to wisdom
<span class="ltx_text ltx_font_bold" id="bib.bib4.1.1">102</span>,
102040
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.inffus.2023.102040" title="">https://doi.org/10.1016/j.inffus.2023.102040</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. [2023]</span>
<span class="ltx_bibblock">
Ma, D.,
Dang, B.,
Li, S.,
Zang, H.,
Dong, X.:
Implementation of computer vision technology based on artificial intelligence for medical image analysis.
International Journal of Computer Science and Information Technology
<span class="ltx_text ltx_font_bold" id="bib.bib5.1.1">1</span>(1),
69–76
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Haribabu, M.,
Guruviah, V.,
Yogarajah, P.:
Recent advancements in multimodal medical image fusion techniquesfor better diagnosis: An overview
<span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">19</span>(7),
060622205668
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.2174/1573405618666220606161137" title="">https://doi.org/10.2174/1573405618666220606161137</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. [2024]</span>
<span class="ltx_bibblock">
Xiao, M.,
Li, Y.,
Yan, X.,
Gao, M.,
Wang, W.:
Convolutional neural network classification of cancer cytopathology images: taking breast cancer as an example.
arXiv preprint arXiv:2404.08279
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. [2024]</span>
<span class="ltx_bibblock">
Yan, X.,
Wang, W.,
Xiao, M.,
Li, Y.,
Gao, M.:
Survival prediction across diverse cancer types using neural networks.
arXiv preprint arXiv:2404.08713
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Mohsen, F.,
Ali, H.,
El Hajj, N.,
Shah, Z.:
Artificial intelligence-based methods for fusion of electronic health records and imaging data
<span class="ltx_text ltx_font_bold" id="bib.bib9.1.1">12</span>(1),
17981
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1038/s41598-022-22514-4" title="">https://doi.org/10.1038/s41598-022-22514-4</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Azam, M.A.,
Khan, K.B.,
Salahuddin, S.,
Rehman, E.,
Khan, S.A.,
Khan, M.A.,
Kadry, S.,
Gandomi, A.H.:
A review on multimodal medical image fusion: Compendious analysis of medical modalities, multimodal databases, fusion techniques and quality metrics
<span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">144</span>,
105253
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.compbiomed.2022.105253" title="">https://doi.org/10.1016/j.compbiomed.2022.105253</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2024]</span>
<span class="ltx_bibblock">
Zhang, J.,
Xiao, L.,
Zhang, Y.,
Lai, J.,
Yang, Y.:
Optimization and performance evaluation of deep learning algorithm in medical image processing.
Frontiers in Computing and Intelligent Systems
<span class="ltx_text ltx_font_bold" id="bib.bib11.1.1">7</span>(3),
67–71
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. [2024]</span>
<span class="ltx_bibblock">
Yuan, J.,
Wu, L.,
Gong, Y.,
Yu, Z.,
Liu, Z.,
He, S.:
Research on intelligent aided diagnosis system of medical image based on computer deep learning.
arXiv preprint arXiv:2404.18419
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Zhang, Y.-D.,
Dong, Z.,
Wang, S.-H.,
Yu, X.,
Yao, X.,
Zhou, Q.,
Hu, H.,
Li, M.,
Jiménez-Mesa, C.,
Ramirez, J.,
Martinez, F.J.,
Gorriz, J.M.:
Advances in multimodal data fusion in neuroimaging: Overview, challenges, and novel orientation
<span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">64</span>,
149–187
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.inffus.2020.07.006" title="">https://doi.org/10.1016/j.inffus.2020.07.006</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
John, A.,
Redmond, S.J.,
Cardiff, B.,
John, D.:
A multimodal data fusion technique for heartbeat detection in wearable IoT sensors
<span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">9</span>(3),
2071–2082
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/JIOT.2021.3093112" title="">https://doi.org/10.1109/JIOT.2021.3093112</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Muhammad, G.,
Alshehri, F.,
Karray, F.,
Saddik, A.E.,
Alsulaiman, M.,
Falk, T.H.:
A comprehensive survey on multimodal medical signals fusion for smart healthcare systems
<span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">76</span>,
355–375
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.inffus.2021.06.007" title="">https://doi.org/10.1016/j.inffus.2021.06.007</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Rizzoli, G.,
Barbato, F.,
Zanuttigh, P.:
Multimodal semantic segmentation in autonomous driving: A review of current approaches and future perspectives
<span class="ltx_text ltx_font_bold" id="bib.bib16.1.1">10</span>(4),
90
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3390/technologies10040090" title="">https://doi.org/10.3390/technologies10040090</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Butt, F.A.,
Chattha, J.N.,
Ahmad, J.,
Zia, M.U.,
Rizwan, M.,
Naqvi, I.H.:
On the integration of enabling wireless technologies and sensor fusion for next-generation connected and autonomous vehicles
<span class="ltx_text ltx_font_bold" id="bib.bib17.1.1">10</span>,
14643–14668
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2022.3145972" title="">https://doi.org/10.1109/ACCESS.2022.3145972</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Himeur, Y.,
Rimal, B.,
Tiwary, A.,
Amira, A.:
Using artificial intelligence and data fusion for environmental monitoring: A review and future perspectives
<span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">86-87</span>,
44–75
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.inffus.2022.06.003" title="">https://doi.org/10.1016/j.inffus.2022.06.003</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Lunga, D.,
Dias, P.:
Advancing data fusion in earth sciences.
In: IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium,
pp. 5077–5080.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/IGARSS46834.2022.9883176" title="">https://doi.org/10.1109/IGARSS46834.2022.9883176</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Nathan Gaw, S.Y.,
Gahrooei, M.R.:
Multimodal data fusion for systems improvement: A review
<span class="ltx_text ltx_font_bold" id="bib.bib20.1.1">54</span>(11),
1098–1116
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/24725854.2021.1987593" title="">https://doi.org/10.1080/24725854.2021.1987593</a> .
Publisher: Taylor &amp; Francis _eprint: https://doi.org/10.1080/24725854.2021.1987593


</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2024]</span>
<span class="ltx_bibblock">
Li, M.,
Zhu, Z.,
Xu, R.,
Feng, Y.,
Xiao, L.:
Research on image classification and semantic segmentation model based on convolutional neural network.
Journal of Computing and Electronic Information Management
<span class="ltx_text ltx_font_bold" id="bib.bib21.1.1">12</span>(3),
94–100
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Sun, F.,
Diao, Z.:
Research on data fusion method based on multisource data awareness of internet of things
<span class="ltx_text ltx_font_bold" id="bib.bib22.1.1">2022</span>,
5001953
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1155/2022/5001953" title="">https://doi.org/10.1155/2022/5001953</a> .
Publisher: Hindawi


</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2024]</span>
<span class="ltx_bibblock">
Zhao, W.,
Liu, X.,
Xu, R.,
Xiao, L.,
Li, M.:
E-commerce webpage recommendation scheme base on semantic mining and neural networks.
Journal of Theory and Practice of Engineering Science
<span class="ltx_text ltx_font_bold" id="bib.bib23.1.1">4</span>(03),
207–215
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Gan, W.,
Dao, M.S.,
Zettsu, K.,
Sun, Y.:
IoT-based multimodal analysis for smart education: Current status, challenges and opportunities.
In: Proceedings of the 3rd ACM Workshop on Intelligent Cross-Data Analysis and Retrieval.
ICDAR ’22,
pp. 32–40.
Association for Computing Machinery.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3512731.3534208" title="">https://doi.org/10.1145/3512731.3534208</a> .
event-place: Newark, NJ, USA


</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Vaswani, A.,
Shazeer, N.,
Parmar, N.,
Uszkoreit, J.,
Jones, L.,
Gomez, A.N.,
Kaiser, \.,
Polosukhin, I.:
Attention is all you need
<span class="ltx_text ltx_font_bold" id="bib.bib25.1.1">30</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Devlin, J.,
Chang, M.-W.,
Lee, K.,
Toutanova, K.:
Bert: Pre-training of deep bidirectional transformers for language understanding


</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Radford, A.,
Narasimhan, K.,
Salimans, T.,
Sutskever, I.:
Improving language understanding with unsupervised learning.
Publisher: Technical report, OpenAI


</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Dosovitskiy, A.,
Beyer, L.,
Kolesnikov, A.,
Weissenborn, D.,
Zhai, X.,
Unterthiner, T.,
Dehghani, M.,
Minderer, M.,
Heigold, G.,
Gelly, S., et al.:
An image is worth 16x16 words: Transformers for image recognition at scale


</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haupt and Marks [2023]</span>
<span class="ltx_bibblock">
Haupt, C.E.,
Marks, M.:
Ai-generated medical advice—gpt and beyond.
Jama
<span class="ltx_text ltx_font_bold" id="bib.bib29.1.1">329</span>(16),
1349–1350
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brin et al. [2023]</span>
<span class="ltx_bibblock">
Brin, D.,
Sorin, V.,
Vaid, A.,
Soroush, A.,
Glicksberg, B.S.,
Charney, A.W.,
Nadkarni, G.,
Klang, E.:
Comparing chatgpt and gpt-4 performance in usmle soft skill assessments.
Scientific Reports
<span class="ltx_text ltx_font_bold" id="bib.bib30.1.1">13</span>(1),
16492
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waisberg et al. [2023]</span>
<span class="ltx_bibblock">
Waisberg, E.,
Ong, J.,
Masalkhi, M.,
Kamran, S.A.,
Zaman, N.,
Sarker, P.,
Lee, A.G.,
Tavakkoli, A.:
Gpt-4: a new era of artificial intelligence in medicine.
Irish Journal of Medical Science (1971-)
<span class="ltx_text ltx_font_bold" id="bib.bib31.1.1">192</span>(6),
3197–3200
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Fan, A.,
Lavril, T.,
Grave, E.,
Joulin, A.,
Sukhbaatar, S.:
Addressing some limitations of transformers with feedback memory


</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Gao, S.,
Alawad, M.,
Young, M.T.,
Gounley, J.,
Schaefferkoetter, N.,
Yoon, H.J.,
Wu, X.-C.,
Durbin, E.B.,
Doherty, J.,
Stroup, A.,
Coyle, L.,
Tourassi, G.:
Limitations of transformers on clinical text classification
<span class="ltx_text ltx_font_bold" id="bib.bib33.1.1">25</span>(9),
3596–3607
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/JBHI.2021.3062322" title="">https://doi.org/10.1109/JBHI.2021.3062322</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2024]</span>
<span class="ltx_bibblock">
Xu, T.,
Li, I.,
Zhan, Q.,
Hu, Y.,
Yang, H.:
Research on intelligent system of multimodal deep learning in image recognition.
Journal of Computing and Electronic Information Management
<span class="ltx_text ltx_font_bold" id="bib.bib34.1.1">12</span>(3),
79–83
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Oquab, M.,
Darcet, T.,
Moutakanni, T.,
Vo, H.,
Szafraniec, M.,
Khalidov, V.,
Fernandez, P.,
Haziza, D.,
Massa, F.,
El-Nouby, A., et al.:
Dinov2: Learning robust visual features without supervision


</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Touvron, H.,
Martin, L.,
Stone, K.,
Albert, P.,
Almahairi, A.,
Babaei, Y.,
Bashlykov, N.,
Batra, S.,
Bhargava, P.,
Bhosale, S., et al.:
Llama 2: Open foundation and fine-tuned chat models


</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasmy et al. [2021]</span>
<span class="ltx_bibblock">
Rasmy, L.,
Xiang, Y.,
Xie, Z.,
Tao, C.,
Zhi, D.:
Med-bert: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction.
NPJ digital medicine
<span class="ltx_text ltx_font_bold" id="bib.bib37.1.1">4</span>(1),
86
(2021)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miglani et al. [2023]</span>
<span class="ltx_bibblock">
Miglani, P.,
Vatsal, P.,
Sharma, R.:
Leveraging small-bert and bio-bert for abbreviation identification in scientific text.
In: International Conference on Applications of Natural Language to Information Systems,
pp. 566–576
(2023).
Springer


</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. [2023]</span>
<span class="ltx_bibblock">
Zhou, Y.,
Chia, M.A.,
Wagner, S.K.,
Ayhan, M.S.,
Williamson, D.J.,
Struyven, R.R.,
Liu, T.,
Xu, M.,
Lozano, M.G.,
Woodward-Court, P., <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">et al.</span>:
A foundation model for generalizable disease detection from retinal images.
Nature
<span class="ltx_text ltx_font_bold" id="bib.bib39.2.2">622</span>(7981),
156–163
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Martínez-Plumed, F.,
Contreras-Ochando, L.,
Ferri, C.,
Hernández-Orallo, J.,
Kull, M.,
Lachiche, N.,
Ramírez-Quintana, M.J.,
Flach, P.:
CRISP-DM twenty years later: From data mining processes to data science trajectories
<span class="ltx_text ltx_font_bold" id="bib.bib40.1.1">33</span>(8),
3048–3061
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/%****%20sn-article.tex%20Line%201400%20****10.1109/TKDE.2019.2962680" title="">https://doi.org/%****␣sn-article.tex␣Line␣1400␣****10.1109/TKDE.2019.2962680</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Celi, L.A.,
Cellini, J.,
Charpignon, M.-L.,
Dee, E.C.,
Dernoncourt, F.,
Eber, R.,
Mitchell, W.G.,
Moukheiber, L.,
Schirmer, J.,
Situ, J.,
Paguio, J.,
Park, J.,
Wawira, J.G.,
Yao, S.,
Data, f.M.C.:
Sources of bias in artificial intelligence that perpetuate healthcare disparities—a global review
<span class="ltx_text ltx_font_bold" id="bib.bib41.1.1">1</span>(3),
1–19
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/%****%20sn-article.tex%20Line%201425%20****10.1371/journal.pdig.0000022" title="">https://doi.org/%****␣sn-article.tex␣Line␣1425␣****10.1371/journal.pdig.0000022</a> .
Publisher: Public Library of Science


</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Ntoutsi, E.,
Fafalios, P.,
Gadiraju, U.,
Iosifidis, V.,
Nejdl, W.,
Vidal, M.-E.,
Ruggieri, S.,
Turini, F.,
Papadopoulos, S.,
Krasanakis, E.,
Kompatsiaris, I.,
Kinder-Kurlanda, K.,
Wagner, C.,
Karimi, F.,
Fernandez, M.,
Alani, H.,
Berendt, B.,
Kruegel, T.,
Heinze, C.,
Broelemann, K.,
Kasneci, G.,
Tiropanis, T.,
Staab, S.:
Bias in data-driven artificial intelligence systems—an introductory survey
<span class="ltx_text ltx_font_bold" id="bib.bib42.1.1">10</span>(3),
1356
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1002/widm.1356" title="">https://doi.org/10.1002/widm.1356</a> .
_eprint: https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1356


</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Roselli, D.,
Matthews, J.,
Talagala, N.:
Managing bias in AI.
In: Companion Proceedings of The 2019 World Wide Web Conference.
WWW ’19,
pp. 539–544.
Association for Computing Machinery.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/%****%20sn-article.tex%20Line%201475%20****10.1145/3308560.3317590" title="">https://doi.org/%****␣sn-article.tex␣Line␣1475␣****10.1145/3308560.3317590</a> .
event-place: San Francisco, USA


</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2023]</span>
<span class="ltx_bibblock">
Dai, W.,
Tao, J.,
Yan, X.,
Feng, Z.,
Chen, J.:
Addressing unintended bias in toxicity detection: An lstm and attention-based approach.
In: 2023 5th International Conference on Artificial Intelligence and Computer Applications (ICAICA),
pp. 375–379
(2023).
IEEE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
John-Mathews, J.-M.,
Cardon, D.,
Balagué, C.:
From reality to world. a critical perspective on AI fairness
<span class="ltx_text ltx_font_bold" id="bib.bib45.1.1">178</span>(4),
945–959
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10551-022-05055-8" title="">https://doi.org/10.1007/s10551-022-05055-8</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gichoya et al. [2022]</span>
<span class="ltx_bibblock">
Gichoya, J.W.,
Meltzer, C.,
Newsome, J.,
Correa, R.,
Trivedi, H.,
Banerjee, I.,
Davis, M.,
Celi, L.A.:
Ethical considerations of artificial intelligence applications in healthcare.
In: Artificial Intelligence in Cardiothoracic Imaging,
pp. 561–565.
Springer, ???
(2022)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Restrepo et al. [2023]</span>
<span class="ltx_bibblock">
Restrepo, D.,
Quion, J.,
Vásquez-Venegas, C.,
Villanueva, C.,
Anthony Celi, L.,
Nakayama, L.F.:
A scoping review of the landscape of health-related open datasets in Latin America.
Public Library of Science San Francisco, CA USA
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steinberg and Bowman [2017]</span>
<span class="ltx_bibblock">
Steinberg, A.N.,
Bowman, C.L.:
Revisions to the jdl data fusion model.
In: Handbook of Multisensor Data Fusion,
pp. 65–88.
CRC press, ???
(2017)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Blasch, E.:
One decade of the data fusion information group (DFIG) model.
In: Broome, B.D., Hanratty, T.P., Hall, D.L., Llinas, J. (eds.)
Next-Generation Analyst III,
vol. 9499,
p. 94990.
SPIE.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1117/12.2176934" title="">https://doi.org/10.1117/12.2176934</a> .
Backup Publisher: International Society for Optics and Photonics


</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Blasch, E.,
Sullivan, N.,
Chen, G.,
Chen, Y.,
Shen, D.,
Yu, W.,
Chen, H.-M.:
Data fusion information group (DFIG) model meets AI+ ML.
In: Signal Processing, Sensor/Information Fusion, and Target Recognition XXXI,
vol. 12122,
pp. 162–171.
SPIE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
López, D.M.,
Rico-Olarte, C.,
Blobel, B.,
Hullin, C.:
Challenges and solutions for transforming health ecosystems in low- and middle-income countries through artificial intelligence
<span class="ltx_text ltx_font_bold" id="bib.bib51.1.1">9</span>
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3389/fmed.2022.958097" title="">https://doi.org/10.3389/fmed.2022.958097</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
White, F.E.:
Data fusion lexicon, joint directors of laboratories, technical panel for c3, data fusion sub-panel


</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steinberg et al. [1999]</span>
<span class="ltx_bibblock">
Steinberg, A.N.,
Bowman, C.,
White, F.:
Revisions to the jdl data fusion model.
In: Defense, Security, and Sensing
(1999).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:45034990" title="">https://api.semanticscholar.org/CorpusID:45034990</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kadar [2002]</span>
<span class="ltx_bibblock">
Kadar, I.:
Perceptual reasoning in adaptive fusion processing.
In: Signal Processing, Sensor Fusion, and Target Recognition XI,
vol. 4729,
pp. 342–351
(2002).
SPIE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Llinas, J.,
Bowman, C.,
Rogova, G.,
Steinberg, A.,
Waltz, E.,
White, F.:
Revisiting the JDL data fusion model II.
In: Proceedings of the Seventh International Conference on Information Fusion, FUSION 2004,
vol. 2,
pp. 1218–1230.
Type: Conference paper


</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salerno [2007]</span>
<span class="ltx_bibblock">
Salerno, J.J.:
Where’s level 2/3 fusion - a look back over the past 10 years.
In: 2007 10th International Conference on Information Fusion,
pp. 1–4
(2007).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICIF.2007.4408209" title="">https://doi.org/10.1109/ICIF.2007.4408209</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2006]</span>
<span class="ltx_bibblock">
Chen, G.,
Shen, D.,
Kwan, C.,
Cruz, J.B.,
Kruger, M.:
Game theoretic approach to threat prediction and situation awareness.
In: 2006 9th International Conference on Information Fusion,
pp. 1–8
(2006).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICIF.2006.301670" title="">https://doi.org/10.1109/ICIF.2006.301670</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Wang [2010]</span>
<span class="ltx_bibblock">
Xu, N.,
Wang, X.:
An information fusion method based on game theory.
In: 2010 2nd International Conference on Signal Processing Systems,
vol. 1,
pp. 1–95198
(2010).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICSPS.2010.5555605" title="">https://doi.org/10.1109/ICSPS.2010.5555605</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Becerra et al. [2018]</span>
<span class="ltx_bibblock">
Becerra, M.A.,
Alvarez-Uribe, K.C.,
Peluffo-Ordoñez, D.H.:
Low data fusion framework oriented to information quality for bci systems.
In: Rojas, I.,
Ortuño, F. (eds.)
Bioinformatics and Biomedical Engineering,
pp. 289–300.
Springer,
Cham
(2018).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-319-78759-6_27" title="">https://doi.org/10.1007/978-3-319-78759-6_27</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noughabi et al. [2013]</span>
<span class="ltx_bibblock">
Noughabi, H.A.,
Kahani, M.,
Behkamal, B.:
Semfus: Semantic fusion framework based on jdl.
In: Elleithy, K.,
Sobh, T. (eds.)
Innovations and Advances in Computer, Information, Systems Sciences, and Engineering,
pp. 583–594.
Springer,
New York, NY
(2013).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-1-4614-3535-8_49" title="">https://doi.org/10.1007/978-1-4614-3535-8_49</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holender et al. [2007]</span>
<span class="ltx_bibblock">
Holender, M.,
Nagi, R.,
Sudit, M.,
Terry Rickard, J.:
Information fusion using conceptual spaces: Mathematical programming models and methods.
In: 2007 10th International Conference on Information Fusion,
pp. 1–8
(2007).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICIF.2007.4408111" title="">https://doi.org/10.1109/ICIF.2007.4408111</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Osadciw et al. [2009]</span>
<span class="ltx_bibblock">
Osadciw, L.,
Srinivas, N.,
Veeramachaneni, K.:
Combining correlated data from multiple classifiers.
In: Swarm Intelligence for Multi-objective Problems in Data Mining,
pp. 259–281.
Springer, ???
(2009)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2024]</span>
<span class="ltx_bibblock">
Xu, R.,
Yang, Y.,
Qiu, H.,
Liu, X.,
Zhang, J.:
Research on multimodal generative adversarial networks in the framework of deep learning.
Journal of Computing and Electronic Information Management
<span class="ltx_text ltx_font_bold" id="bib.bib63.1.1">12</span>(3),
84–88
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Llinas et al. [2010]</span>
<span class="ltx_bibblock">
Llinas, J.,
Nagi, R.,
Hall, D.,
Lavery, J.:
A multi-disciplinary university research initiative in hard and soft information fusion: Overview, research strategies and initial results.
In: 2010 13th International Conference on Information Fusion,
pp. 1–7
(2010).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICIF.2010.5712083" title="">https://doi.org/10.1109/ICIF.2010.5712083</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rimland et al. [2013]</span>
<span class="ltx_bibblock">
Rimland, J.,
McNeese, M.,
Hall, D.:
Conserving analyst attention units: use of multi-agent software and CEP methods to assist information analysis.
In: Broome, B.D.,
Hall, D.L.,
Llinas, J. (eds.)
Next-Generation Analyst,
vol. 8758,
p. 87580.
SPIE, ???
(2013).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1117/12.2015759" title="">https://doi.org/10.1117/12.2015759</a> .
International Society for Optics and Photonics


</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Bowman, C.:
Engineering Resource Management Solutions by Leveraging Dual Data Fusion Solutions.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.2514/6.2010-3501" title="">https://doi.org/10.2514/6.2010-3501</a> .
Type: Conference paper


</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Steinberg and Bowman [2013]</span>
<span class="ltx_bibblock">
Steinberg, A.N.,
Bowman, C.L.:
Adaptive context exploitation.
In: Broome, B.D.,
Hall, D.L.,
Llinas, J. (eds.)
Next-Generation Analyst,
vol. 8758,
p. 875804.
SPIE, ???
(2013).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1117/12.2015623" title="">https://doi.org/10.1117/12.2015623</a> .
International Society for Optics and Photonics


</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Braines et al. [2019]</span>
<span class="ltx_bibblock">
Braines, D.,
Tomsett, R.,
Preece, A.:
Supporting user fusion of ai services through conversational explanations.
In: 2019 22th International Conference on Information Fusion (FUSION),
pp. 1–8
(2019).
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/%****%20sn-article.tex%20Line%201850%20****10.23919/FUSION43075.2019.9011434" title="">https://doi.org/%****␣sn-article.tex␣Line␣1850␣****10.23919/FUSION43075.2019.9011434</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Wirth, R.,
Hipp, J.:
CRISP-DM: Towards a standard process model for data mining.
In: Proceedings of the 4th International Conference on the Practical Applications of Knowledge Discovery and Data Mining,
vol. 1,
pp. 29–39.
Manchester


</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schröer et al. [2021]</span>
<span class="ltx_bibblock">
Schröer, C.,
Kruse, F.,
Gómez, J.M.:
A systematic literature review on applying crisp-dm process model.
Procedia Computer Science
<span class="ltx_text ltx_font_bold" id="bib.bib70.1.1">181</span>,
526–534
(2021)
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.procs.2021.01.199" title="">https://doi.org/10.1016/j.procs.2021.01.199</a> .
CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020


</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rosero Perez et al. [2023]</span>
<span class="ltx_bibblock">
Rosero Perez, P.A.,
Realpe Gonzalez, J.S.,
Salazar-Cabrera, R.,
Restrepo, D.,
López, D.M.,
Blobel, B.:
Multidimensional machine learning model to calculate a covid-19 vulnerability index.
Journal of Personalized Medicine
<span class="ltx_text ltx_font_bold" id="bib.bib71.1.1">13</span>(7),
1141
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caetano et al. [2015]</span>
<span class="ltx_bibblock">
Caetano, N.,
Cortez, P.,
Laureano, R.M.:
Using data mining for prediction of hospital length of stay: An application of the crisp-dm methodology.
In: Enterprise Information Systems: 16th International Conference, ICEIS 2014, Lisbon, Portugal, April 27-30, 2014, Revised Selected Papers 16,
pp. 149–166
(2015).
Springer


</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Gunes, H.,
Piccardi, M.:
Affect recognition from face and body: early fusion vs. late fusion.
In: 2005 IEEE International Conference on Systems, Man and Cybernetics,
vol. 4,
pp. 3437–34434.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICSMC.2005.1571679" title="">https://doi.org/10.1109/ICSMC.2005.1571679</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Suresh, H.,
Guttag, J.:
A framework for understanding sources of harm throughout the machine learning life cycle.
In: Proceedings of the 1st ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization.
EAAMO ’21.
Association for Computing Machinery.
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3465416.3483305" title="">https://doi.org/10.1145/3465416.3483305</a> .
event-place: –, NY, USA


</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Habib et al. [2021]</span>
<span class="ltx_bibblock">
Habib, A.R.,
Lin, A.L.,
Grant, R.W.:
The epic sepsis model falls short—the importance of external validation.
JAMA Internal Medicine
<span class="ltx_text ltx_font_bold" id="bib.bib75.1.1">181</span>(8),
1040–1041
(2021)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zech et al. [2018]</span>
<span class="ltx_bibblock">
Zech, J.R.,
Badgeley, M.A.,
Liu, M.,
Costa, A.B.,
Titano, J.J.,
Oermann, E.K.:
Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study.
PLoS medicine
<span class="ltx_text ltx_font_bold" id="bib.bib76.1.1">15</span>(11),
1002683
(2018)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2021]</span>
<span class="ltx_bibblock">
Lee, A.Y.,
Yanagihara, R.T.,
Lee, C.S.,
Blazes, M.,
Jung, H.C.,
Chee, Y.E.,
Gencarella, M.D.,
Gee, H.,
Maa, A.Y.,
Cockerham, G.C., <span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">et al.</span>:
Multicenter, head-to-head, real-world validation study of seven automated artificial intelligence diabetic retinopathy screening systems.
Diabetes care
<span class="ltx_text ltx_font_bold" id="bib.bib77.2.2">44</span>(5),
1168–1175
(2021)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berthet [2022]</span>
<span class="ltx_bibblock">
Berthet, V.:
The impact of cognitive biases on professionals’ decision-making: A review of four occupational areas.
Frontiers in psychology
<span class="ltx_text ltx_font_bold" id="bib.bib78.1.1">12</span>,
802439
(2022)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakayama et al. [2023]</span>
<span class="ltx_bibblock">
Nakayama, L.F.,
Goncalves, M.,
Zago Ribeiro, L.,
Santos, H.,
Ferraz, D.,
Malerbi, F.,
Celi, L.A.,
Regatieri, C.:
A Brazilian multilabel ophthalmological dataset (BRSET).
PhysioNet
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilkinson et al. [2003]</span>
<span class="ltx_bibblock">
Wilkinson, C.P.,
Ferris III, F.L.,
Klein, R.E.,
Lee, P.P.,
Agardh, C.D.,
Davis, M.,
Dills, D.,
Kampik, A.,
Pararajasegaram, R.,
Verdaguer, J.T., <span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">et al.</span>:
Proposed international clinical diabetic retinopathy and diabetic macular edema disease severity scales.
Ophthalmology
<span class="ltx_text ltx_font_bold" id="bib.bib80.2.2">110</span>(9),
1677–1682
(2003)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. [2023]</span>
<span class="ltx_bibblock">
Liang, P.P.,
Cheng, Y.,
Fan, X.,
Ling, C.K.,
Nie, S.,
Chen, R.,
Deng, Z.,
Mahmood, F.,
Salakhutdinov, R.,
Morency, L.-P.:
Quantifying &amp; modeling feature interactions: An information decomposition framework.
arXiv e-prints,
2302
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2024]</span>
<span class="ltx_bibblock">
Zhang, Y.,
Xu, Y.,
Chen, J.,
Xie, F.,
Chen, H.:
Prototypical information bottlenecking and disentangling for multimodal cancer survival prediction.
arXiv preprint arXiv:2401.01646
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holste et al. [2023]</span>
<span class="ltx_bibblock">
Holste, G.,
Wal, D.,
Pinckaers, H.,
Yamashita, R.,
Mitani, A.,
Esteva, A.:
Improved multimodal fusion for small datasets with auxiliary supervision.
In: 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI),
pp. 1–5
(2023).
IEEE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakayama et al. [2024]</span>
<span class="ltx_bibblock">
Nakayama, L.F.,
Restrepo, D.,
Matos, J.,
Ribeiro, L.Z.,
Malerbi, F.K.,
Celi, L.A.,
Regatieri, C.S.:
Brset: A brazilian multilabel ophthalmological dataset of retina fundus photos.
medRxiv,
2024–01
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gould et al. [2024]</span>
<span class="ltx_bibblock">
Gould, D.S.,
Yang, J.,
Clifton, D.A.:
Deep learning for multi-label disease classification of retinal images: Insights from brazilian data for ai development in lower-middle income countries.
medRxiv,
2024–02
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Weng [2012]</span>
<span class="ltx_bibblock">
Liu, H.,
Weng, Q.:
Enhancing temporal resolution of satellite imagery for public health studies: A case study of west nile virus outbreak in los angeles in 2007.
Remote Sensing of Environment
<span class="ltx_text ltx_font_bold" id="bib.bib86.1.1">117</span>,
57–71
(2012)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Persello and Kuffer [2020]</span>
<span class="ltx_bibblock">
Persello, C.,
Kuffer, M.:
Towards uncovering socio-economic inequalities using vhr satellite images and deep learning.
In: IGARSS 2020-2020 IEEE International Geoscience and Remote Sensing Symposium,
pp. 3747–3750
(2020).
IEEE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Restrepo et al. [2022]</span>
<span class="ltx_bibblock">
Restrepo, D.S.,
Pérez, L.E.,
López, D.M.,
Vargas-Cañas, R.,
Osorio-Valencia, J.S.:
Multi-dimensional dataset of open data and satellite images for characterization of food security and nutrition.
Frontiers in Nutrition
<span class="ltx_text ltx_font_bold" id="bib.bib88.1.1">8</span>,
796082
(2022)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burke et al. [2021]</span>
<span class="ltx_bibblock">
Burke, M.,
Driscoll, A.,
Lobell, D.B.,
Ermon, S.:
Using satellite imagery to understand and promote sustainable development.
Science
<span class="ltx_text ltx_font_bold" id="bib.bib89.1.1">371</span>(6535),
8628
(2021)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neupane et al. [2021]</span>
<span class="ltx_bibblock">
Neupane, B.,
Horanont, T.,
Aryal, J.:
Deep learning-based semantic segmentation of urban features in satellite images: A review and meta-analysis.
Remote Sensing
<span class="ltx_text ltx_font_bold" id="bib.bib90.1.1">13</span>(4),
808
(2021)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ortakavak et al. [2020]</span>
<span class="ltx_bibblock">
Ortakavak, Z.,
Çabuk, S.N.,
Cetin, M.,
Senyel Kurkcuoglu, M.A.,
Cabuk, A.:
Determination of the nighttime light imagery for urban city population using dmsp-ols methods in istanbul.
Environmental monitoring and assessment
<span class="ltx_text ltx_font_bold" id="bib.bib91.1.1">192</span>(12),
790
(2020)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed et al. [2024]</span>
<span class="ltx_bibblock">
Ahmed, A.A.M.,
Jui, S.J.J.,
Sharma, E.,
Ahmed, M.H.,
Raj, N.,
Bose, A.:
An advanced deep learning predictive model for air quality index forecasting with remote satellite-derived hydro-climatological variables.
Science of The Total Environment
<span class="ltx_text ltx_font_bold" id="bib.bib92.1.1">906</span>,
167234
(2024)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonte et al. [2021]</span>
<span class="ltx_bibblock">
Bonte, K.,
Moshtaghi, M.,
Van Tricht, K.,
Tits, L.:
Automated crop harvest detection algorithm based on synergistic use of optical and radar satellite imagery.
In: 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS,
pp. 5981–5984
(2021).
IEEE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barros et al. [2020]</span>
<span class="ltx_bibblock">
Barros, J.M.,
Duggan, J.,
Rebholz-Schuhmann, D.:
The application of internet-based sources for public health surveillance (infoveillance): systematic review.
Journal of medical internet research
<span class="ltx_text ltx_font_bold" id="bib.bib94.1.1">22</span>(3),
13680
(2020)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. [2020]</span>
<span class="ltx_bibblock">
Pan, Z.,
Nguyen, H.L.,
Abu-Gellban, H.,
Zhang, Y.:
Google trends analysis of covid-19 pandemic.
In: 2020 IEEE International Conference on Big Data (Big Data),
pp. 3438–3446
(2020).
IEEE


</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhawan et al. [2021]</span>
<span class="ltx_bibblock">
Dhawan, D.,
Bekalu, M.,
Pinnamaneni, R.,
McCloud, R.,
Viswanath, K.:
Covid-19 news and misinformation: do they matter for public health prevention?
Journal of health communication
<span class="ltx_text ltx_font_bold" id="bib.bib96.1.1">26</span>(11),
799–808
(2021)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. [2019]</span>
<span class="ltx_bibblock">
Johnson, A.E.,
Pollard, T.J.,
Berkowitz, S.J.,
Greenbaum, N.R.,
Lungren, M.P.,
Deng, C.-y.,
Mark, R.G.,
Horng, S.:
Mimic-cxr, a de-identified publicly available database of chest radiographs with free-text reports.
Scientific data
<span class="ltx_text ltx_font_bold" id="bib.bib97.1.1">6</span>(1),
317
(2019)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glocker et al. [2023]</span>
<span class="ltx_bibblock">
Glocker, B.,
Jones, C.,
Bernhardt, M.,
Winzeck, S.:
Algorithmic encoding of protected characteristics in chest x-ray disease detection models.
EBioMedicine
<span class="ltx_text ltx_font_bold" id="bib.bib98.1.1">89</span>
(2023)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2022]</span>
<span class="ltx_bibblock">
Li, D.,
Lin, C.T.,
Sulam, J.,
Yi, P.H.:
Deep learning prediction of sex on chest radiographs: a potential contributor to biased algorithms.
Emergency Radiology
<span class="ltx_text ltx_font_bold" id="bib.bib99.1.1">29</span>(2),
365–370
(2022)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. [2022]</span>
<span class="ltx_bibblock">
Huang, T.,
Yang, R.,
Shen, L.,
Feng, A.,
Li, L.,
He, N.,
Li, S.,
Huang, L.,
Lyu, J.:
Deep transfer learning to quantify pleural effusion severity in chest x-rays.
BMC Medical Imaging
<span class="ltx_text ltx_font_bold" id="bib.bib100.1.1">22</span>(1),
100
(2022)


</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong et al. [2023]</span>
<span class="ltx_bibblock">
Jeong, J.,
Jeoun, B.,
Park, Y.,
Han, B.:
An optimized ensemble framework for multi-label classification on long-tailed chest x-ray data.
In: Proceedings of the IEEE/CVF International Conference on Computer Vision,
pp. 2739–2746
(2023)


</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Jun  2 16:59:58 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
