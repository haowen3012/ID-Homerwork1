<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification</title>
<!--Generated on Tue May 14 19:44:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2209.15168v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S1" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S2" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Motivation &amp; Hypothesis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S2.SS0.SSS0.Px1" title="In 2. Motivation &amp; Hypothesis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Adapting to New Tasks.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S3" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Tasks, Datasets, and Raised Questions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S3.SS1" title="In 3. Tasks, Datasets, and Raised Questions ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Few-Shot Adaptation on NER</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S3.SS1.SSS0.Px1" title="In 3.1. Few-Shot Adaptation on NER ‣ 3. Tasks, Datasets, and Raised Questions ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">CoNLL-2003</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S3.SS1.SSS0.Px2" title="In 3.1. Few-Shot Adaptation on NER ‣ 3. Tasks, Datasets, and Raised Questions ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">WikiAnn</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S3.SS2" title="In 3. Tasks, Datasets, and Raised Questions ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Masked Language Modeling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4.SS0.SSS0.Px1" title="In 4. Models ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Layer Concatenation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4.SS0.SSS0.Px2" title="In 4. Models ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Depth-Wise Attention.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4.SS1" title="In 4. Models ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Baselines</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4.SS1.SSS0.Px1" title="In 4.1. Baselines ‣ 4. Models ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Base Model.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4.SS1.SSS0.Px2" title="In 4.1. Baselines ‣ 4. Models ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Extra Transformer Layers.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S5" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimentation Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S5.SS1" title="In 5. Experimentation Setup ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Base Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S5.SS2" title="In 5. Experimentation Setup ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S5.SS3" title="In 5. Experimentation Setup ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results and Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.SS1" title="In 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span><span class="ltx_text ltx_font_typewriter">CoNLL</span>: Few-Shot Adaptation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.SS2" title="In 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Step and Sample Efficiency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.SS3" title="In 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Feature Extractor Adaptability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.SS4" title="In 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Scaling by Depth</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.SS5" title="In 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span><span class="ltx_text ltx_font_typewriter">WikiAnn</span>: Adapting to High, Mid, and Low Resource Languages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.SS6" title="In 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.6 </span>Masked Language Modeling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S7" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S7.SS0.SSS0.Px1" title="In 7. Related Work ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Adaptors.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S7.SS0.SSS0.Px2" title="In 7. Related Work ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Layer Aggregation (static weights).</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S7.SS0.SSS0.Px3" title="In 7. Related Work ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Dynamic Layer Mixing.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS1" title="In 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Notes on Selected Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS1.SSS0.Px1" title="In 8.1. Notes on Selected Evaluations ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">NER: A Token-level Downstream Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS1.SSS0.Px2" title="In 8.1. Notes on Selected Evaluations ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">MLM: Pretraining objective</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS2" title="In 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Levels of Abstraction</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS2.SSS0.Px1" title="In 8.2. Levels of Abstraction ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Hiding Within Scale.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS2.SSS0.Px2" title="In 8.2. Levels of Abstraction ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Intuition as Shortcuts From Raw Input.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS2.SSS0.Px3" title="In 8.2. Levels of Abstraction ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Proposition.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS3" title="In 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3 </span>Modeling Capacity</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS3.SSS0.Px1" title="In 8.3. Modeling Capacity ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title">Modeling Dimensions.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S9" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Design Details</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S9.SS1" title="In 9. Design Details ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.1 </span>Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S9.SS2" title="In 9. Design Details ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.2 </span>Layer Index Embedding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S9.SS3" title="In 9. Design Details ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.3 </span>MLP Modules</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S10" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Conclusion &amp; Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S11" title="In Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11 </span>Bibliographical References</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">
Depth-Wise Attention (DWAtt): 
<br class="ltx_break"/>A Layer Fusion Method for Data-Efficient Classification
</h1>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Language Models pretrained on large textual data have been shown to encode different types of knowledge simultaneously.
Traditionally, only the features from the last layer are used when adapting to new tasks or data.
We put forward that, when using or finetuning deep pretrained models, intermediate layer features that may be relevant to the downstream task are buried too deep to be used efficiently in terms of needed samples or steps.
To test this, we propose a new layer fusion method: Depth-Wise Attention (DWAtt), to help re-surface signals from non-final layers. We compare DWAtt to a basic concatenation-based layer fusion method (Concat), and compare both to a deeper model baseline—all kept within a similar parameter budget.
Our findings show that DWAtt and Concat are more step- and sample-efficient than the baseline, especially in the few-shot setting. DWAtt outperforms Concat on larger data sizes.
On <span class="ltx_text ltx_font_typewriter" id="id1.1.1">CoNLL-03</span> NER, layer fusion shows <math alttext="3.68-9.73\%" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">3.68</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">−</mo><mrow id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml"><mn id="id1.1.m1.1.1.3.2" xref="id1.1.m1.1.1.3.2.cmml">9.73</mn><mo id="id1.1.m1.1.1.3.1" xref="id1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><minus id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1"></minus><cn id="id1.1.m1.1.1.2.cmml" type="float" xref="id1.1.m1.1.1.2">3.68</cn><apply id="id1.1.m1.1.1.3.cmml" xref="id1.1.m1.1.1.3"><csymbol cd="latexml" id="id1.1.m1.1.1.3.1.cmml" xref="id1.1.m1.1.1.3.1">percent</csymbol><cn id="id1.1.m1.1.1.3.2.cmml" type="float" xref="id1.1.m1.1.1.3.2">9.73</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">3.68-9.73\%</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">3.68 - 9.73 %</annotation></semantics></math> F1 gain at different few-shot sizes.
The layer fusion models presented significantly outperform the baseline in various training scenarios with different data sizes, architectures, and training constraints.</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\NAT@set@cites</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1"><span class="ltx_text" id="p2.1.1"></span></p>
</div>
<div class="ltx_logical-block" id="id11">
<div class="ltx_para" id="id11.p1">
<p class="ltx_p ltx_align_center" id="id11.p1.1"><span class="ltx_text ltx_font_bold" id="id11.p1.1.1" style="font-size:144%;">Depth-Wise Attention (DWAtt): 
<br class="ltx_break"/>A Layer Fusion Method for Data-Efficient Classification</span></p>
<br class="ltx_break ltx_centering"/>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top" id="id10.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="id4.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="id4.3.3.3"><span class="ltx_text ltx_font_bold" id="id4.3.3.3.3" style="font-size:120%;">Muhammad ElNokrashy<sup class="ltx_sup" id="id4.3.3.3.3.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id4.3.3.3.3.1.1">∗μ</span></sup>, Badr AlKhamissi<sup class="ltx_sup" id="id4.3.3.3.3.2"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id4.3.3.3.3.2.1">∗†β</span></sup>, Mona Diab<sup class="ltx_sup" id="id4.3.3.3.3.3"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id4.3.3.3.3.3.1">†ω</span></sup></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="id7.6.6">
<td class="ltx_td ltx_align_center" id="id7.6.6.3">
<sup class="ltx_sup" id="id7.6.6.3.1"><span class="ltx_text ltx_font_italic" id="id7.6.6.3.1.1">μ</span></sup>Microsoft Egypt,
<sup class="ltx_sup" id="id7.6.6.3.2"><span class="ltx_text ltx_font_italic" id="id7.6.6.3.2.1">β</span></sup>EPFL,
<sup class="ltx_sup" id="id7.6.6.3.3"><span class="ltx_text ltx_font_italic" id="id7.6.6.3.3.1">ω</span></sup>CMU</td>
</tr>
<tr class="ltx_tr" id="id10.9.9">
<td class="ltx_td ltx_align_center" id="id10.9.9.3">
<sup class="ltx_sup" id="id10.9.9.3.1"><span class="ltx_text ltx_font_italic" id="id10.9.9.3.1.1">μ</span></sup>muelnokr@microsoft.com,
<sup class="ltx_sup" id="id10.9.9.3.2"><span class="ltx_text ltx_font_italic" id="id10.9.9.3.2.1">β</span></sup>badr.alkhamissi@epfl.ch,
<sup class="ltx_sup" id="id10.9.9.3.3"><span class="ltx_text ltx_font_italic" id="id10.9.9.3.3.1">ω</span></sup>mdiab@andrew.cmu.edu</td>
</tr>
</tbody>
</table>
<p class="ltx_p ltx_align_center" id="id11.p1.2"><span class="ltx_text ltx_font_italic" id="id11.p1.2.1">Abstract content</span></p>
</div>
</div>
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup class="ltx_sup" id="footnote1.1">∗</sup> Equal contribution.</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1a"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup class="ltx_sup" id="footnote1a.1"><span class="ltx_text ltx_font_italic" id="footnote1a.1.1">β</span></sup> Started independently, finished at Meta AI residency.</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1b"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup class="ltx_sup" id="footnote1b.1">†</sup> Work done while at Meta AI.</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1c"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><sup class="ltx_sup" id="footnote1c.1">⋄</sup> Source code available at <a class="ltx_ref ltx_href" href="https://github.com/munael/dwatt-depth_wise_attention-lrec_coling_2024" title="">github.com/munael/dwatt-depth_wise_attention-lrec_coling_2024</a></span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">1.   Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The Transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib29" title="">2017</a>)</cite> and variants <cite class="ltx_cite ltx_citemacro_citep">(Fan et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib11" title="">2020</a>)</cite> have become a mainstream, reliable choice for a wide range of Natural Language Processing (<span class="ltx_text ltx_font_bold" id="S1.p1.1.1">NLP</span>) tasks, such as sentence classification, token labeling, retrieval, and question answering <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib32" title="">2018a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib31" title="">2019a</a>)</cite>.
This is in part due to architectural properties that enable enhanced parallelization and better modeling of long-range dependencies.
Several models have since surfaced, setting new records on different benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib9" title="">2019</a>; Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib17" title="">2020</a>; Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib5" title="">2020</a>)</cite>.
In the vanilla architecture, a stack of Transformer blocks are applied sequentially to refine the representation of an input sequence, which is then fed to a task-specific module, such as a classifier head.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recent works have shown that hidden representations from intermediate layers may benefit downstream tasks <cite class="ltx_cite ltx_citemacro_citep">(Wallat et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib30" title="">2021</a>)</cite>.
Other works have tested the fusion of hidden representations in tasks such as sequence-to-sequence machine translation <cite class="ltx_cite ltx_citemacro_citep">(Shen et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib27" title="">2018</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib19" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib20" title="">2021</a>)</cite>.
See also speech modeling works <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib18" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we propose a method to combine the hidden representations of encoder layers to more easily utilize the full model.
Moreover, we further investigate a simpler alternative as a compelling baseline.
This work expands on <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">Vertical Attention</span>, introduced in <cite class="ltx_cite ltx_citemacro_citet">AlKhamissi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib1" title="">2021</a>)</cite>, by providing a more detailed specification and an extensive evaluation and analysis.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S1.F1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.10.5.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.8.4" style="font-size:90%;">Basic architecture: The Mixer <math alttext="H" class="ltx_Math" display="inline" id="S1.F1.5.1.m1.1"><semantics id="S1.F1.5.1.m1.1b"><mi id="S1.F1.5.1.m1.1.1" xref="S1.F1.5.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S1.F1.5.1.m1.1c"><ci id="S1.F1.5.1.m1.1.1.cmml" xref="S1.F1.5.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.5.1.m1.1d">H</annotation><annotation encoding="application/x-llamapun" id="S1.F1.5.1.m1.1e">italic_H</annotation></semantics></math> can be a Sum of Affine Transformations, a Dot-Product Attention module, etc. Different variants may define <math alttext="K_{i}" class="ltx_Math" display="inline" id="S1.F1.6.2.m2.1"><semantics id="S1.F1.6.2.m2.1b"><msub id="S1.F1.6.2.m2.1.1" xref="S1.F1.6.2.m2.1.1.cmml"><mi id="S1.F1.6.2.m2.1.1.2" xref="S1.F1.6.2.m2.1.1.2.cmml">K</mi><mi id="S1.F1.6.2.m2.1.1.3" xref="S1.F1.6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F1.6.2.m2.1c"><apply id="S1.F1.6.2.m2.1.1.cmml" xref="S1.F1.6.2.m2.1.1"><csymbol cd="ambiguous" id="S1.F1.6.2.m2.1.1.1.cmml" xref="S1.F1.6.2.m2.1.1">subscript</csymbol><ci id="S1.F1.6.2.m2.1.1.2.cmml" xref="S1.F1.6.2.m2.1.1.2">𝐾</ci><ci id="S1.F1.6.2.m2.1.1.3.cmml" xref="S1.F1.6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.2.m2.1d">K_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.6.2.m2.1e">italic_K start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="V_{i}" class="ltx_Math" display="inline" id="S1.F1.7.3.m3.1"><semantics id="S1.F1.7.3.m3.1b"><msub id="S1.F1.7.3.m3.1.1" xref="S1.F1.7.3.m3.1.1.cmml"><mi id="S1.F1.7.3.m3.1.1.2" xref="S1.F1.7.3.m3.1.1.2.cmml">V</mi><mi id="S1.F1.7.3.m3.1.1.3" xref="S1.F1.7.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F1.7.3.m3.1c"><apply id="S1.F1.7.3.m3.1.1.cmml" xref="S1.F1.7.3.m3.1.1"><csymbol cd="ambiguous" id="S1.F1.7.3.m3.1.1.1.cmml" xref="S1.F1.7.3.m3.1.1">subscript</csymbol><ci id="S1.F1.7.3.m3.1.1.2.cmml" xref="S1.F1.7.3.m3.1.1.2">𝑉</ci><ci id="S1.F1.7.3.m3.1.1.3.cmml" xref="S1.F1.7.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.7.3.m3.1d">V_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.7.3.m3.1e">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="Q" class="ltx_Math" display="inline" id="S1.F1.8.4.m4.1"><semantics id="S1.F1.8.4.m4.1b"><mi id="S1.F1.8.4.m4.1.1" xref="S1.F1.8.4.m4.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S1.F1.8.4.m4.1c"><ci id="S1.F1.8.4.m4.1.1.cmml" xref="S1.F1.8.4.m4.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.8.4.m4.1d">Q</annotation><annotation encoding="application/x-llamapun" id="S1.F1.8.4.m4.1e">italic_Q</annotation></semantics></math> (key, value, and query transforms) and utilize them differently.
</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">2.   Motivation &amp; Hypothesis</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">A common goal when designing deeper networks is enhancing their ability to represent deeper chains of abstraction in different data domains and training objectives.
As the model is tuned for a specific task, seemingly <em class="ltx_emph ltx_font_italic" id="S2.p1.1.1">unneeded</em> information is ignored. More general patterns that could benefit different downstream tasks become less likely to pass through intermediate layers to the final representation.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Some base models (like Large Language Models) posses properties which may implicitly mitigate this effect—by leveraging their large parameter capacity and increased width.
The additional parameters enable memorizing more subtleties or idiosyncrasies of the training data, while the increased model width allows for a less compact final representation, which may let through patterns not <em class="ltx_emph ltx_font_italic" id="S2.p2.1.1">directly</em> used by the general language modeling objective of choice.
Some tasks may need such low-level knowledge across a large example space <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib20" title="">2021</a>)</cite>.
A similar problem is the strength and clarity of gradients into earlier intermediate layers. Methods to alleviate this include skip connections <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib13" title="">2016</a>)</cite>, and alternatives to full back-propagation <cite class="ltx_cite ltx_citemacro_citep">(Nøkland, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib25" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">We propose an add-on module that can augment any pretrained deep sequence model by combining the representations of its intermediate layers to adapt better to novel tasks.
To investigate our proposed modules, we experiment with the following tasks:
<span class="ltx_text ltx_font_italic" id="S2.p3.1.1">(a)</span> Named Entity Recognition (<span class="ltx_text ltx_font_bold" id="S2.p3.1.2">NER</span>) in the few-shot setting on the <span class="ltx_text ltx_font_typewriter" id="S2.p3.1.3">CoNLL-03</span> and <span class="ltx_text ltx_font_typewriter" id="S2.p3.1.4">WikiAnn</span> datasets, and
<span class="ltx_text ltx_font_italic" id="S2.p3.1.5">(b)</span> Masked Language Modeling (<span class="ltx_text ltx_font_bold" id="S2.p3.1.6">MLM</span>) on a small text dataset (<span class="ltx_text ltx_font_typewriter" id="S2.p3.1.7">WikiText-2</span>). Two settings are considered: Finetuning (<span class="ltx_text ltx_font_bold" id="S2.p3.1.8">FT</span>) and Feature Extraction (<span class="ltx_text ltx_font_bold" id="S2.p3.1.9">FE</span>).</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Adapting to New Tasks.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">For many pretraining projects, adaptability to novel language tasks is a crucial performance signal. it allows one to exploit general language understanding from self-supervised tasks like MLM on large datasets.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Useful signals include: <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p2.1.1">(a)</span> Performance versus a model trained on task-specific data only, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p2.1.2">(b)</span> time to convergence, and <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p2.1.3">(c)</span> size of the needed task data to achieve the desired performance.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p3.1">One could finetune the whole model (possibly infeasible), or use it as a feature extractor and train only a task-specific module. A commonly researched alternative is finding or introducing a subset of parameters specifically for finetuning <cite class="ltx_cite ltx_citemacro_citep">(Houlsby et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib15" title="">2019</a>; Ben-Zaken et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib4" title="">2022</a>)</cite>.
We test our proposed method and an alternative in different adaptation settings with multiple n-shot training sizes, max training steps, and tiers of availability of language data during pretraining.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S2.F2.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.17.5.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.8.4" style="font-size:90%;">F1-Score on the <span class="ltx_text ltx_font_typewriter" id="S2.F2.8.4.1">CoNLL-03</span> dev set after training for <math alttext="100" class="ltx_Math" display="inline" id="S2.F2.5.1.m1.1"><semantics id="S2.F2.5.1.m1.1b"><mn id="S2.F2.5.1.m1.1.1" xref="S2.F2.5.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S2.F2.5.1.m1.1c"><cn id="S2.F2.5.1.m1.1.1.cmml" type="integer" xref="S2.F2.5.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.5.1.m1.1d">100</annotation><annotation encoding="application/x-llamapun" id="S2.F2.5.1.m1.1e">100</annotation></semantics></math> epochs on few-shot training datasets with <span class="ltx_text ltx_font_italic" id="S2.F2.8.4.2">N-Shot</span> samples per class sampled uniformly from the full training set.
Both <span class="ltx_text ltx_font_typewriter" id="S2.F2.8.4.3">DWAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S2.F2.8.4.4">Concat</span> improve on the additional layers baseline <span class="ltx_text ltx_font_typewriter" id="S2.F2.8.4.5">R<sub class="ltx_sub" id="S2.F2.8.4.5.1">26</sub></span>. At <math alttext="128" class="ltx_Math" display="inline" id="S2.F2.6.2.m2.1"><semantics id="S2.F2.6.2.m2.1b"><mn id="S2.F2.6.2.m2.1.1" xref="S2.F2.6.2.m2.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S2.F2.6.2.m2.1c"><cn id="S2.F2.6.2.m2.1.1.cmml" type="integer" xref="S2.F2.6.2.m2.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.6.2.m2.1d">128</annotation><annotation encoding="application/x-llamapun" id="S2.F2.6.2.m2.1e">128</annotation></semantics></math> samples per class, <span class="ltx_text ltx_font_typewriter" id="S2.F2.8.4.6">DWAtt</span> improves on both <span class="ltx_text ltx_font_typewriter" id="S2.F2.8.4.7">Concat</span> and the enhanced baseline by <math alttext="1.6\%" class="ltx_Math" display="inline" id="S2.F2.7.3.m3.1"><semantics id="S2.F2.7.3.m3.1b"><mrow id="S2.F2.7.3.m3.1.1" xref="S2.F2.7.3.m3.1.1.cmml"><mn id="S2.F2.7.3.m3.1.1.2" xref="S2.F2.7.3.m3.1.1.2.cmml">1.6</mn><mo id="S2.F2.7.3.m3.1.1.1" xref="S2.F2.7.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.7.3.m3.1c"><apply id="S2.F2.7.3.m3.1.1.cmml" xref="S2.F2.7.3.m3.1.1"><csymbol cd="latexml" id="S2.F2.7.3.m3.1.1.1.cmml" xref="S2.F2.7.3.m3.1.1.1">percent</csymbol><cn id="S2.F2.7.3.m3.1.1.2.cmml" type="float" xref="S2.F2.7.3.m3.1.1.2">1.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.3.m3.1d">1.6\%</annotation><annotation encoding="application/x-llamapun" id="S2.F2.7.3.m3.1e">1.6 %</annotation></semantics></math> and <math alttext="5.28\%" class="ltx_Math" display="inline" id="S2.F2.8.4.m4.1"><semantics id="S2.F2.8.4.m4.1b"><mrow id="S2.F2.8.4.m4.1.1" xref="S2.F2.8.4.m4.1.1.cmml"><mn id="S2.F2.8.4.m4.1.1.2" xref="S2.F2.8.4.m4.1.1.2.cmml">5.28</mn><mo id="S2.F2.8.4.m4.1.1.1" xref="S2.F2.8.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.8.4.m4.1c"><apply id="S2.F2.8.4.m4.1.1.cmml" xref="S2.F2.8.4.m4.1.1"><csymbol cd="latexml" id="S2.F2.8.4.m4.1.1.1.cmml" xref="S2.F2.8.4.m4.1.1.1">percent</csymbol><cn id="S2.F2.8.4.m4.1.1.2.cmml" type="float" xref="S2.F2.8.4.m4.1.1.2">5.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.4.m4.1d">5.28\%</annotation><annotation encoding="application/x-llamapun" id="S2.F2.8.4.m4.1e">5.28 %</annotation></semantics></math> absolute, respectively.
</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">3.   Tasks, Datasets, and Raised Questions</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">On many common benchmarks, state-of-the-art performance is often near saturation. We consider some useful synthesizable variants of the benchmarks that test particular training settings or aspects of performance. Our experiments aim to test the following aspects: <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">adaptability</span> (finetuning (FT) versus feature extraction (FE)), <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">sample efficiency</span> (few-shot training), <span class="ltx_text ltx_font_italic" id="S3.p1.1.3">training step efficiency</span> (time to convergence), and <span class="ltx_text ltx_font_italic" id="S3.p1.1.4">effect of model depth</span>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">3.1.   Few-Shot Adaptation on NER</h3>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S3.T1.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.2.1">Labels</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.3.1">Resource</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.2.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.4.1">Train</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S3.T1.2.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.5.1">Dev</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.2.2.2.1"><span class="ltx_text ltx_font_typewriter" id="S3.T1.2.2.2.1.1">CoNLL-03</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T1.2.2.2.2">4</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.2.2.3">High</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.2.2.4">14k</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.2.2.2.5">3250</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T1.2.3.3.1" rowspan="3"><span class="ltx_text ltx_font_typewriter" id="S3.T1.2.3.3.1.1">WikiAnn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T1.2.3.3.2" rowspan="3"><span class="ltx_text" id="S3.T1.2.3.3.2.1">3</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.3.3">High</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.3.4">20k</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.2.3.3.5">10k</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.4.4">
<td class="ltx_td ltx_align_center" id="S3.T1.2.4.4.1">Mid</td>
<td class="ltx_td ltx_align_center" id="S3.T1.2.4.4.2">1k-5k</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.2.4.4.3">1k</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.5.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.5.5.1">Low</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.2.5.5.2">100</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T1.2.5.5.3">100</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.4.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.5.2" style="font-size:90%;">Train and Dev subset sizes in sentence count. For <span class="ltx_text ltx_font_typewriter" id="S3.T1.5.2.1">WikiAnn</span>, we list the average size of a language in the corresponding resource tier, determined by train size.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">NER, a moderately complex task, evaluates performance at a token-level, and reasonably can benefit from intermediate features. See section <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS1" title="8.1. Notes on Selected Evaluations ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">8.1</span></a>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_typewriter ltx_title_paragraph">CoNLL-2003</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">The <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px1.p1.1.1">CoNLL-03</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(Tjong Kim Sang and De Meulder, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib28" title="">2003</a>)</cite> provides a mainstream NER benchmark in the English language. For few-shot trials, we sample training points uniformly at random from the full training set.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_font_typewriter ltx_title_paragraph">WikiAnn</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">The <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px2.p1.1.1">WikiAnn</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(Rahimi et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib26" title="">2019</a>)</cite> is a multilingual NER benchmark which we use to test the effect of resource availability in the pretraining phase. For few-shot experiments, we sample a fixed training set of size <math alttext="N\!=\!100" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">N</mi><mo id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1" lspace="0.108em" rspace="0.108em" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1"><eq id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1"></eq><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2">𝑁</ci><cn id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">N\!=\!100</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.1.m1.1d">italic_N = 100</annotation></semantics></math> and train for each language separately. We also compare performance on the English subset between RoBERTa and the multilingual XLM-RoBERTa.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">3.2.   Masked Language Modeling</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">WikiText-2</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(Merity et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib23" title="">2017</a>)</cite> is a subset of the English Wikipedia developed for use in long-term dependency language modeling. It contains the first <math alttext="2" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn id="S3.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">2</annotation></semantics></math> million words of a dump of the English Wikipedia at the time of creation.
We report the perplexity on the dev and test sets. We hypothesize that retaining better pretraining performance points to increased reliability. See Section <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS1" title="8.1. Notes on Selected Evaluations ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">8.1</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">4.   Models</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.4">Let <math alttext="L" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">italic_L</annotation></semantics></math> denote a deep network’s layer stack.
Then <math alttext="{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{H}}" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" mathcolor="#FF0000" xref="S4.p1.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{H}}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">italic_H</annotation></semantics></math><span class="ltx_note ltx_role_footnote" id="footnote1d"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In this work, symbols in <span class="ltx_text" id="footnote1d.1" style="color:#FF0000;"> red</span> have learned parameters.</span></span></span> is a learned function that mixes the layers’ intermediate representations <math alttext="\{{\mathbf{z}}_{n}\mid n\in\lvert L\rvert\}" class="ltx_Math" display="inline" id="S4.p1.3.m3.3"><semantics id="S4.p1.3.m3.3a"><mrow id="S4.p1.3.m3.3.3.2" xref="S4.p1.3.m3.3.3.3.cmml"><mo id="S4.p1.3.m3.3.3.2.3" stretchy="false" xref="S4.p1.3.m3.3.3.3.1.cmml">{</mo><msub id="S4.p1.3.m3.2.2.1.1" xref="S4.p1.3.m3.2.2.1.1.cmml"><mi id="S4.p1.3.m3.2.2.1.1.2" xref="S4.p1.3.m3.2.2.1.1.2.cmml">𝐳</mi><mi id="S4.p1.3.m3.2.2.1.1.3" xref="S4.p1.3.m3.2.2.1.1.3.cmml">n</mi></msub><mo fence="true" id="S4.p1.3.m3.3.3.2.4" lspace="0em" rspace="0em" xref="S4.p1.3.m3.3.3.3.1.cmml">∣</mo><mrow id="S4.p1.3.m3.3.3.2.2" xref="S4.p1.3.m3.3.3.2.2.cmml"><mi id="S4.p1.3.m3.3.3.2.2.2" xref="S4.p1.3.m3.3.3.2.2.2.cmml">n</mi><mo id="S4.p1.3.m3.3.3.2.2.1" xref="S4.p1.3.m3.3.3.2.2.1.cmml">∈</mo><mrow id="S4.p1.3.m3.3.3.2.2.3.2" xref="S4.p1.3.m3.3.3.2.2.3.1.cmml"><mo id="S4.p1.3.m3.3.3.2.2.3.2.1" stretchy="false" xref="S4.p1.3.m3.3.3.2.2.3.1.1.cmml">|</mo><mi id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">L</mi><mo id="S4.p1.3.m3.3.3.2.2.3.2.2" stretchy="false" xref="S4.p1.3.m3.3.3.2.2.3.1.1.cmml">|</mo></mrow></mrow><mo id="S4.p1.3.m3.3.3.2.5" stretchy="false" xref="S4.p1.3.m3.3.3.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.3b"><apply id="S4.p1.3.m3.3.3.3.cmml" xref="S4.p1.3.m3.3.3.2"><csymbol cd="latexml" id="S4.p1.3.m3.3.3.3.1.cmml" xref="S4.p1.3.m3.3.3.2.3">conditional-set</csymbol><apply id="S4.p1.3.m3.2.2.1.1.cmml" xref="S4.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S4.p1.3.m3.2.2.1.1.1.cmml" xref="S4.p1.3.m3.2.2.1.1">subscript</csymbol><ci id="S4.p1.3.m3.2.2.1.1.2.cmml" xref="S4.p1.3.m3.2.2.1.1.2">𝐳</ci><ci id="S4.p1.3.m3.2.2.1.1.3.cmml" xref="S4.p1.3.m3.2.2.1.1.3">𝑛</ci></apply><apply id="S4.p1.3.m3.3.3.2.2.cmml" xref="S4.p1.3.m3.3.3.2.2"><in id="S4.p1.3.m3.3.3.2.2.1.cmml" xref="S4.p1.3.m3.3.3.2.2.1"></in><ci id="S4.p1.3.m3.3.3.2.2.2.cmml" xref="S4.p1.3.m3.3.3.2.2.2">𝑛</ci><apply id="S4.p1.3.m3.3.3.2.2.3.1.cmml" xref="S4.p1.3.m3.3.3.2.2.3.2"><abs id="S4.p1.3.m3.3.3.2.2.3.1.1.cmml" xref="S4.p1.3.m3.3.3.2.2.3.2.1"></abs><ci id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.3c">\{{\mathbf{z}}_{n}\mid n\in\lvert L\rvert\}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.3.m3.3d">{ bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∣ italic_n ∈ | italic_L | }</annotation></semantics></math>, and <math alttext="{{\mathbf{h}}}" class="ltx_Math" display="inline" id="S4.p1.4.m4.1"><semantics id="S4.p1.4.m4.1a"><mi id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><ci id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">{{\mathbf{h}}}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.4.m4.1d">bold_h</annotation></semantics></math> is the final representation.</p>
</div>
<div class="ltx_para" id="S4.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{{\mathbf{h}}}={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{H}}~{}(\cdots,\big{\{}(n,{\mathbf{z}}_{n})\mid n\in\lvert L\rvert\big{%
\}})" class="ltx_Math" display="block" id="S4.E1.m1.4"><semantics id="S4.E1.m1.4a"><mrow id="S4.E1.m1.4.4" xref="S4.E1.m1.4.4.cmml"><mi id="S4.E1.m1.4.4.3" xref="S4.E1.m1.4.4.3.cmml">𝐡</mi><mo id="S4.E1.m1.4.4.2" xref="S4.E1.m1.4.4.2.cmml">=</mo><mrow id="S4.E1.m1.4.4.1" xref="S4.E1.m1.4.4.1.cmml"><mi id="S4.E1.m1.4.4.1.3" mathcolor="#FF0000" xref="S4.E1.m1.4.4.1.3.cmml">H</mi><mo id="S4.E1.m1.4.4.1.2" lspace="0.330em" xref="S4.E1.m1.4.4.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.4.4.1.1.1" xref="S4.E1.m1.4.4.1.1.2.cmml"><mo id="S4.E1.m1.4.4.1.1.1.2" stretchy="false" xref="S4.E1.m1.4.4.1.1.2.cmml">(</mo><mi id="S4.E1.m1.3.3" mathvariant="normal" xref="S4.E1.m1.3.3.cmml">⋯</mi><mo id="S4.E1.m1.4.4.1.1.1.3" xref="S4.E1.m1.4.4.1.1.2.cmml">,</mo><mrow id="S4.E1.m1.4.4.1.1.1.1.2" xref="S4.E1.m1.4.4.1.1.1.1.3.cmml"><mo id="S4.E1.m1.4.4.1.1.1.1.2.3" maxsize="120%" minsize="120%" xref="S4.E1.m1.4.4.1.1.1.1.3.1.cmml">{</mo><mrow id="S4.E1.m1.4.4.1.1.1.1.1.1.1" xref="S4.E1.m1.4.4.1.1.1.1.1.1.2.cmml"><mo id="S4.E1.m1.4.4.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E1.m1.4.4.1.1.1.1.1.1.2.cmml">(</mo><mi id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">n</mi><mo id="S4.E1.m1.4.4.1.1.1.1.1.1.1.3" xref="S4.E1.m1.4.4.1.1.1.1.1.1.2.cmml">,</mo><msub id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E1.m1.4.4.1.1.1.1.1.1.1.4" stretchy="false" xref="S4.E1.m1.4.4.1.1.1.1.1.1.2.cmml">)</mo></mrow><mo fence="true" id="S4.E1.m1.4.4.1.1.1.1.2.4" lspace="0em" rspace="0em" xref="S4.E1.m1.4.4.1.1.1.1.3.1.cmml">∣</mo><mrow id="S4.E1.m1.4.4.1.1.1.1.2.2" xref="S4.E1.m1.4.4.1.1.1.1.2.2.cmml"><mi id="S4.E1.m1.4.4.1.1.1.1.2.2.2" xref="S4.E1.m1.4.4.1.1.1.1.2.2.2.cmml">n</mi><mo id="S4.E1.m1.4.4.1.1.1.1.2.2.1" xref="S4.E1.m1.4.4.1.1.1.1.2.2.1.cmml">∈</mo><mrow id="S4.E1.m1.4.4.1.1.1.1.2.2.3.2" xref="S4.E1.m1.4.4.1.1.1.1.2.2.3.1.cmml"><mo id="S4.E1.m1.4.4.1.1.1.1.2.2.3.2.1" stretchy="false" xref="S4.E1.m1.4.4.1.1.1.1.2.2.3.1.1.cmml">|</mo><mi id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml">L</mi><mo id="S4.E1.m1.4.4.1.1.1.1.2.2.3.2.2" stretchy="false" xref="S4.E1.m1.4.4.1.1.1.1.2.2.3.1.1.cmml">|</mo></mrow></mrow><mo id="S4.E1.m1.4.4.1.1.1.1.2.5" maxsize="120%" minsize="120%" xref="S4.E1.m1.4.4.1.1.1.1.3.1.cmml">}</mo></mrow><mo id="S4.E1.m1.4.4.1.1.1.4" stretchy="false" xref="S4.E1.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.4b"><apply id="S4.E1.m1.4.4.cmml" xref="S4.E1.m1.4.4"><eq id="S4.E1.m1.4.4.2.cmml" xref="S4.E1.m1.4.4.2"></eq><ci id="S4.E1.m1.4.4.3.cmml" xref="S4.E1.m1.4.4.3">𝐡</ci><apply id="S4.E1.m1.4.4.1.cmml" xref="S4.E1.m1.4.4.1"><times id="S4.E1.m1.4.4.1.2.cmml" xref="S4.E1.m1.4.4.1.2"></times><ci id="S4.E1.m1.4.4.1.3.cmml" xref="S4.E1.m1.4.4.1.3">𝐻</ci><interval closure="open" id="S4.E1.m1.4.4.1.1.2.cmml" xref="S4.E1.m1.4.4.1.1.1"><ci id="S4.E1.m1.3.3.cmml" xref="S4.E1.m1.3.3">⋯</ci><apply id="S4.E1.m1.4.4.1.1.1.1.3.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2"><csymbol cd="latexml" id="S4.E1.m1.4.4.1.1.1.1.3.1.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2.3">conditional-set</csymbol><interval closure="open" id="S4.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1"><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">𝑛</ci><apply id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.2">𝐳</ci><ci id="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.4.4.1.1.1.1.1.1.1.1.3">𝑛</ci></apply></interval><apply id="S4.E1.m1.4.4.1.1.1.1.2.2.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2.2"><in id="S4.E1.m1.4.4.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2.2.1"></in><ci id="S4.E1.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2.2.2">𝑛</ci><apply id="S4.E1.m1.4.4.1.1.1.1.2.2.3.1.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2.2.3.2"><abs id="S4.E1.m1.4.4.1.1.1.1.2.2.3.1.1.cmml" xref="S4.E1.m1.4.4.1.1.1.1.2.2.3.2.1"></abs><ci id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2">𝐿</ci></apply></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.4c">{{\mathbf{h}}}={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{H}}~{}(\cdots,\big{\{}(n,{\mathbf{z}}_{n})\mid n\in\lvert L\rvert\big{%
\}})</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.4d">bold_h = italic_H ( ⋯ , { ( italic_n , bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ∣ italic_n ∈ | italic_L | } )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p2.4">The <math alttext="H" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">H</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_H</annotation></semantics></math> module is a function of the layer indices <math alttext="n" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_n</annotation></semantics></math> and the corresponding representation vectors <math alttext="{\mathbf{z}}_{n}" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><msub id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">𝐳</mi><mi id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">𝐳</ci><ci id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">{\mathbf{z}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, but can take other signals, like <math alttext="{\mathbf{z}}_{L}\mapsto{\mathbf{q}}" class="ltx_Math" display="inline" id="S4.p2.4.m4.1"><semantics id="S4.p2.4.m4.1a"><mrow id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><msub id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml"><mi id="S4.p2.4.m4.1.1.2.2" xref="S4.p2.4.m4.1.1.2.2.cmml">𝐳</mi><mi id="S4.p2.4.m4.1.1.2.3" xref="S4.p2.4.m4.1.1.2.3.cmml">L</mi></msub><mo id="S4.p2.4.m4.1.1.1" stretchy="false" xref="S4.p2.4.m4.1.1.1.cmml">↦</mo><mi id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml">𝐪</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1">maps-to</csymbol><apply id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.p2.4.m4.1.1.2.1.cmml" xref="S4.p2.4.m4.1.1.2">subscript</csymbol><ci id="S4.p2.4.m4.1.1.2.2.cmml" xref="S4.p2.4.m4.1.1.2.2">𝐳</ci><ci id="S4.p2.4.m4.1.1.2.3.cmml" xref="S4.p2.4.m4.1.1.2.3">𝐿</ci></apply><ci id="S4.p2.4.m4.1.1.3.cmml" xref="S4.p2.4.m4.1.1.3">𝐪</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">{\mathbf{z}}_{L}\mapsto{\mathbf{q}}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.4.m4.1d">bold_z start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT ↦ bold_q</annotation></semantics></math> for query.
See diagram in Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">1</span></a>.
We consider the following layer fusion models.</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Layer Concatenation.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.2">A sum of linear transforms.
Note that this is equivalent to concatenating all <math alttext="\{{\mathbf{z}}_{n}\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml">𝐳</mi><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><set id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1"><apply id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.2">𝐳</ci><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.1.1.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">\{{\mathbf{z}}_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.1.m1.1d">{ bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> then transforming the concatenation into the model width <math alttext="{{d}_{\textbf{\small\,z}}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px1.p1.2.m2.1a"><msub id="S4.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.3" mathsize="128%" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.3a.cmml"> z</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.2">𝑑</ci><ci id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.3a.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" mathsize="90%" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.3"> z</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.2.m2.1c">{{d}_{\textbf{\small\,z}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px1.p1.2.m2.1d">italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{{\mathbf{h}}}={\textstyle\sum_{n}}\ {\color[rgb]{1,0,0}\definecolor[named]{%
pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{W}}_{n}}}({\mathbf{z}}_{n})" class="ltx_Math" display="block" id="S4.E2.m1.1"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mi id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml">𝐡</mi><mo id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">=</mo><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.cmml"><mstyle displaystyle="false" id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.2.cmml"><msub id="S4.E2.m1.1.1.1.2a" xref="S4.E2.m1.1.1.1.2.cmml"><mo id="S4.E2.m1.1.1.1.2.2" xref="S4.E2.m1.1.1.1.2.2.cmml">∑</mo><mi id="S4.E2.m1.1.1.1.2.3" xref="S4.E2.m1.1.1.1.2.3.cmml">n</mi></msub></mstyle><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><msub id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2" mathcolor="#FF0000" xref="S4.E2.m1.1.1.1.1.3.2.cmml">𝐖</mi><mi id="S4.E2.m1.1.1.1.1.3.3" mathcolor="#FF0000" xref="S4.E2.m1.1.1.1.1.3.3.cmml">n</mi></msub><mo id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml"><mo id="S4.E2.m1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E2.m1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="S4.E2.m1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E2.m1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><eq id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2"></eq><ci id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3">𝐡</ci><apply id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><apply id="S4.E2.m1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.2">subscript</csymbol><sum id="S4.E2.m1.1.1.1.2.2.cmml" xref="S4.E2.m1.1.1.1.2.2"></sum><ci id="S4.E2.m1.1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1"><times id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2"></times><apply id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2">𝐖</ci><ci id="S4.E2.m1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3">𝑛</ci></apply><apply id="S4.E2.m1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.2">𝐳</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">{{\mathbf{h}}}={\textstyle\sum_{n}}\ {\color[rgb]{1,0,0}\definecolor[named]{%
pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{W}}_{n}}}({\mathbf{z}}_{n})</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.1d">bold_h = ∑ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT bold_W start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Depth-Wise Attention.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.3"><span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px2.p1.3.1">DWAtt</span> uses dot-product attention with
keys <math alttext="{\mathbf{k}}_{n}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">𝐤</mi><mi id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2">𝐤</ci><ci id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">{\mathbf{k}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.1.m1.1d">bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, values <math alttext="{\mathbf{v}}_{n}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml">𝐯</mi><mi id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.2">𝐯</ci><ci id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">{\mathbf{v}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.2.m2.1d">bold_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, and query <math alttext="{\mathbf{q}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S4.SS0.SSS0.Px2.p1.3.m3.1a"><mi id="S4.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">𝐪</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.3.m3.1b"><ci id="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1">𝐪</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.3.m3.1c">{\mathbf{q}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.3.m3.1d">bold_q</annotation></semantics></math>.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S11.EGx1">
<tbody id="S4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle{\mathbf{k}}_{n}" class="ltx_Math" display="inline" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><msub id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mi id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">𝐤</mi><mi id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1">subscript</csymbol><ci id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2">𝐤</ci><ci id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\displaystyle{\mathbf{k}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{\operatorname{\vphantom{fg}\mathsf{PE}}}}(n)" class="ltx_Math" display="inline" id="S4.E3.m2.2"><semantics id="S4.E3.m2.2a"><mrow id="S4.E3.m2.2.3" xref="S4.E3.m2.2.3.cmml"><mi id="S4.E3.m2.2.3.2" xref="S4.E3.m2.2.3.2.cmml"></mi><mo id="S4.E3.m2.2.3.1" xref="S4.E3.m2.2.3.1.cmml">=</mo><mrow id="S4.E3.m2.2.3.3.2" xref="S4.E3.m2.2.3.3.1.cmml"><mi id="S4.E3.m2.1.1" mathcolor="#FF0000" xref="S4.E3.m2.1.1.cmml">𝖯𝖤</mi><mo id="S4.E3.m2.2.3.3.2a" xref="S4.E3.m2.2.3.3.1.cmml">⁡</mo><mrow id="S4.E3.m2.2.3.3.2.1" xref="S4.E3.m2.2.3.3.1.cmml"><mo id="S4.E3.m2.2.3.3.2.1.1" mathcolor="#000000" stretchy="false" xref="S4.E3.m2.2.3.3.1.cmml">(</mo><mi id="S4.E3.m2.2.2" mathcolor="#000000" xref="S4.E3.m2.2.2.cmml">n</mi><mo id="S4.E3.m2.2.3.3.2.1.2" mathcolor="#000000" stretchy="false" xref="S4.E3.m2.2.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m2.2b"><apply id="S4.E3.m2.2.3.cmml" xref="S4.E3.m2.2.3"><eq id="S4.E3.m2.2.3.1.cmml" xref="S4.E3.m2.2.3.1"></eq><csymbol cd="latexml" id="S4.E3.m2.2.3.2.cmml" xref="S4.E3.m2.2.3.2">absent</csymbol><apply id="S4.E3.m2.2.3.3.1.cmml" xref="S4.E3.m2.2.3.3.2"><ci id="S4.E3.m2.1.1.cmml" xref="S4.E3.m2.1.1">𝖯𝖤</ci><ci id="S4.E3.m2.2.2.cmml" xref="S4.E3.m2.2.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m2.2c">\displaystyle={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{\operatorname{\vphantom{fg}\mathsf{PE}}}}(n)</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m2.2d">= start_OPFUNCTION sansserif_PE end_OPFUNCTION ( italic_n )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S4.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle{\mathbf{v}}_{n}" class="ltx_Math" display="inline" id="S4.E4.m1.1"><semantics id="S4.E4.m1.1a"><msub id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml"><mi id="S4.E4.m1.1.1.2" xref="S4.E4.m1.1.1.2.cmml">𝐯</mi><mi id="S4.E4.m1.1.1.3" xref="S4.E4.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.2.cmml" xref="S4.E4.m1.1.1.2">𝐯</ci><ci id="S4.E4.m1.1.1.3.cmml" xref="S4.E4.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">\displaystyle{\mathbf{v}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.1d">bold_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{\operatorname{\vphantom{fg}\mathsf{LN}}_{n}}}\left({\color[rgb]{1,0,0}%
\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{f^{V}_{n}}}({\mathbf{z}}_{n})\right)" class="ltx_Math" display="inline" id="S4.E4.m2.2"><semantics id="S4.E4.m2.2a"><mrow id="S4.E4.m2.2.2" xref="S4.E4.m2.2.2.cmml"><mi id="S4.E4.m2.2.2.4" xref="S4.E4.m2.2.2.4.cmml"></mi><mo id="S4.E4.m2.2.2.3" xref="S4.E4.m2.2.2.3.cmml">=</mo><mrow id="S4.E4.m2.2.2.2.2" xref="S4.E4.m2.2.2.2.3.cmml"><msub id="S4.E4.m2.1.1.1.1.1" xref="S4.E4.m2.1.1.1.1.1.cmml"><mi id="S4.E4.m2.1.1.1.1.1.2" mathcolor="#FF0000" xref="S4.E4.m2.1.1.1.1.1.2.cmml">𝖫𝖭</mi><mi id="S4.E4.m2.1.1.1.1.1.3" mathcolor="#FF0000" xref="S4.E4.m2.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E4.m2.2.2.2.2a" xref="S4.E4.m2.2.2.2.3.cmml">⁡</mo><mrow id="S4.E4.m2.2.2.2.2.2" xref="S4.E4.m2.2.2.2.3.cmml"><mo id="S4.E4.m2.2.2.2.2.2.2" xref="S4.E4.m2.2.2.2.3.cmml">(</mo><mrow id="S4.E4.m2.2.2.2.2.2.1" xref="S4.E4.m2.2.2.2.2.2.1.cmml"><msubsup id="S4.E4.m2.2.2.2.2.2.1.3" xref="S4.E4.m2.2.2.2.2.2.1.3.cmml"><mi id="S4.E4.m2.2.2.2.2.2.1.3.2.2" mathcolor="#FF0000" xref="S4.E4.m2.2.2.2.2.2.1.3.2.2.cmml">f</mi><mi id="S4.E4.m2.2.2.2.2.2.1.3.3" mathcolor="#FF0000" xref="S4.E4.m2.2.2.2.2.2.1.3.3.cmml">n</mi><mi id="S4.E4.m2.2.2.2.2.2.1.3.2.3" mathcolor="#FF0000" xref="S4.E4.m2.2.2.2.2.2.1.3.2.3.cmml">V</mi></msubsup><mo id="S4.E4.m2.2.2.2.2.2.1.2" xref="S4.E4.m2.2.2.2.2.2.1.2.cmml">⁢</mo><mrow id="S4.E4.m2.2.2.2.2.2.1.1.1" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.cmml"><mo id="S4.E4.m2.2.2.2.2.2.1.1.1.2" stretchy="false" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.cmml">(</mo><msub id="S4.E4.m2.2.2.2.2.2.1.1.1.1" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.cmml"><mi id="S4.E4.m2.2.2.2.2.2.1.1.1.1.2" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.2.cmml">𝐳</mi><mi id="S4.E4.m2.2.2.2.2.2.1.1.1.1.3" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E4.m2.2.2.2.2.2.1.1.1.3" stretchy="false" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m2.2.2.2.2.2.3" xref="S4.E4.m2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m2.2b"><apply id="S4.E4.m2.2.2.cmml" xref="S4.E4.m2.2.2"><eq id="S4.E4.m2.2.2.3.cmml" xref="S4.E4.m2.2.2.3"></eq><csymbol cd="latexml" id="S4.E4.m2.2.2.4.cmml" xref="S4.E4.m2.2.2.4">absent</csymbol><apply id="S4.E4.m2.2.2.2.3.cmml" xref="S4.E4.m2.2.2.2.2"><apply id="S4.E4.m2.1.1.1.1.1.cmml" xref="S4.E4.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m2.1.1.1.1.1.1.cmml" xref="S4.E4.m2.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m2.1.1.1.1.1.2.cmml" xref="S4.E4.m2.1.1.1.1.1.2">𝖫𝖭</ci><ci id="S4.E4.m2.1.1.1.1.1.3.cmml" xref="S4.E4.m2.1.1.1.1.1.3">𝑛</ci></apply><apply id="S4.E4.m2.2.2.2.2.2.1.cmml" xref="S4.E4.m2.2.2.2.2.2.1"><times id="S4.E4.m2.2.2.2.2.2.1.2.cmml" xref="S4.E4.m2.2.2.2.2.2.1.2"></times><apply id="S4.E4.m2.2.2.2.2.2.1.3.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S4.E4.m2.2.2.2.2.2.1.3.1.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3">subscript</csymbol><apply id="S4.E4.m2.2.2.2.2.2.1.3.2.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S4.E4.m2.2.2.2.2.2.1.3.2.1.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3">superscript</csymbol><ci id="S4.E4.m2.2.2.2.2.2.1.3.2.2.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3.2.2">𝑓</ci><ci id="S4.E4.m2.2.2.2.2.2.1.3.2.3.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3.2.3">𝑉</ci></apply><ci id="S4.E4.m2.2.2.2.2.2.1.3.3.cmml" xref="S4.E4.m2.2.2.2.2.2.1.3.3">𝑛</ci></apply><apply id="S4.E4.m2.2.2.2.2.2.1.1.1.1.cmml" xref="S4.E4.m2.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m2.2.2.2.2.2.1.1.1.1.1.cmml" xref="S4.E4.m2.2.2.2.2.2.1.1.1">subscript</csymbol><ci id="S4.E4.m2.2.2.2.2.2.1.1.1.1.2.cmml" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.2">𝐳</ci><ci id="S4.E4.m2.2.2.2.2.2.1.1.1.1.3.cmml" xref="S4.E4.m2.2.2.2.2.2.1.1.1.1.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m2.2c">\displaystyle={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{\operatorname{\vphantom{fg}\mathsf{LN}}_{n}}}\left({\color[rgb]{1,0,0}%
\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{f^{V}_{n}}}({\mathbf{z}}_{n})\right)</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m2.2d">= start_OPFUNCTION sansserif_LN end_OPFUNCTION start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_f start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
<tbody id="S4.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle{\mathbf{q}}" class="ltx_Math" display="inline" id="S4.E5.m1.1"><semantics id="S4.E5.m1.1a"><mi id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml">𝐪</mi><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><ci id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1">𝐪</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">\displaystyle{\mathbf{q}}</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.1d">bold_q</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=1+\operatorname{\vphantom{fg}\mathsf{elu}}\left({\mathbf{z}}_{L}%
+{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{f^{Q}}}({%
\mathbf{z}}_{L})\right)" class="ltx_Math" display="inline" id="S4.E5.m2.2"><semantics id="S4.E5.m2.2a"><mrow id="S4.E5.m2.2.2" xref="S4.E5.m2.2.2.cmml"><mi id="S4.E5.m2.2.2.3" xref="S4.E5.m2.2.2.3.cmml"></mi><mo id="S4.E5.m2.2.2.2" xref="S4.E5.m2.2.2.2.cmml">=</mo><mrow id="S4.E5.m2.2.2.1" xref="S4.E5.m2.2.2.1.cmml"><mn id="S4.E5.m2.2.2.1.3" xref="S4.E5.m2.2.2.1.3.cmml">1</mn><mo id="S4.E5.m2.2.2.1.2" xref="S4.E5.m2.2.2.1.2.cmml">+</mo><mrow id="S4.E5.m2.2.2.1.1.1" xref="S4.E5.m2.2.2.1.1.2.cmml"><mi id="S4.E5.m2.1.1" xref="S4.E5.m2.1.1.cmml">𝖾𝗅𝗎</mi><mo id="S4.E5.m2.2.2.1.1.1a" xref="S4.E5.m2.2.2.1.1.2.cmml">⁡</mo><mrow id="S4.E5.m2.2.2.1.1.1.1" xref="S4.E5.m2.2.2.1.1.2.cmml"><mo id="S4.E5.m2.2.2.1.1.1.1.2" xref="S4.E5.m2.2.2.1.1.2.cmml">(</mo><mrow id="S4.E5.m2.2.2.1.1.1.1.1" xref="S4.E5.m2.2.2.1.1.1.1.1.cmml"><msub id="S4.E5.m2.2.2.1.1.1.1.1.3" xref="S4.E5.m2.2.2.1.1.1.1.1.3.cmml"><mi id="S4.E5.m2.2.2.1.1.1.1.1.3.2" xref="S4.E5.m2.2.2.1.1.1.1.1.3.2.cmml">𝐳</mi><mi id="S4.E5.m2.2.2.1.1.1.1.1.3.3" xref="S4.E5.m2.2.2.1.1.1.1.1.3.3.cmml">L</mi></msub><mo id="S4.E5.m2.2.2.1.1.1.1.1.2" xref="S4.E5.m2.2.2.1.1.1.1.1.2.cmml">+</mo><mrow id="S4.E5.m2.2.2.1.1.1.1.1.1" xref="S4.E5.m2.2.2.1.1.1.1.1.1.cmml"><msup id="S4.E5.m2.2.2.1.1.1.1.1.1.3" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3.cmml"><mi id="S4.E5.m2.2.2.1.1.1.1.1.1.3.2" mathcolor="#FF0000" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S4.E5.m2.2.2.1.1.1.1.1.1.3.3" mathcolor="#FF0000" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3.3.cmml">Q</mi></msup><mo id="S4.E5.m2.2.2.1.1.1.1.1.1.2" xref="S4.E5.m2.2.2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.2" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.3.cmml">L</mi></msub><mo id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E5.m2.2.2.1.1.1.1.3" xref="S4.E5.m2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m2.2b"><apply id="S4.E5.m2.2.2.cmml" xref="S4.E5.m2.2.2"><eq id="S4.E5.m2.2.2.2.cmml" xref="S4.E5.m2.2.2.2"></eq><csymbol cd="latexml" id="S4.E5.m2.2.2.3.cmml" xref="S4.E5.m2.2.2.3">absent</csymbol><apply id="S4.E5.m2.2.2.1.cmml" xref="S4.E5.m2.2.2.1"><plus id="S4.E5.m2.2.2.1.2.cmml" xref="S4.E5.m2.2.2.1.2"></plus><cn id="S4.E5.m2.2.2.1.3.cmml" type="integer" xref="S4.E5.m2.2.2.1.3">1</cn><apply id="S4.E5.m2.2.2.1.1.2.cmml" xref="S4.E5.m2.2.2.1.1.1"><ci id="S4.E5.m2.1.1.cmml" xref="S4.E5.m2.1.1">𝖾𝗅𝗎</ci><apply id="S4.E5.m2.2.2.1.1.1.1.1.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1"><plus id="S4.E5.m2.2.2.1.1.1.1.1.2.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.2"></plus><apply id="S4.E5.m2.2.2.1.1.1.1.1.3.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m2.2.2.1.1.1.1.1.3.1.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E5.m2.2.2.1.1.1.1.1.3.2.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.3.2">𝐳</ci><ci id="S4.E5.m2.2.2.1.1.1.1.1.3.3.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.3.3">𝐿</ci></apply><apply id="S4.E5.m2.2.2.1.1.1.1.1.1.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1"><times id="S4.E5.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.2"></times><apply id="S4.E5.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m2.2.2.1.1.1.1.1.1.3.1.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E5.m2.2.2.1.1.1.1.1.1.3.2.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3.2">𝑓</ci><ci id="S4.E5.m2.2.2.1.1.1.1.1.1.3.3.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.3.3">𝑄</ci></apply><apply id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.2">𝐳</ci><ci id="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m2.2.2.1.1.1.1.1.1.1.1.1.3">𝐿</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m2.2c">\displaystyle=1+\operatorname{\vphantom{fg}\mathsf{elu}}\left({\mathbf{z}}_{L}%
+{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{f^{Q}}}({%
\mathbf{z}}_{L})\right)</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m2.2d">= 1 + start_OPFUNCTION sansserif_elu end_OPFUNCTION ( bold_z start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT + italic_f start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ( bold_z start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.11">Where <math alttext="\operatorname{\vphantom{fg}\mathsf{PE}}(n)" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.4.m1.2"><semantics id="S4.SS0.SSS0.Px2.p1.4.m1.2a"><mrow id="S4.SS0.SSS0.Px2.p1.4.m1.2.3.2" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.3.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.4.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.4.m1.1.1.cmml">𝖯𝖤</mi><mo id="S4.SS0.SSS0.Px2.p1.4.m1.2.3.2a" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.3.1.cmml">⁡</mo><mrow id="S4.SS0.SSS0.Px2.p1.4.m1.2.3.2.1" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.3.1.cmml"><mo id="S4.SS0.SSS0.Px2.p1.4.m1.2.3.2.1.1" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.3.1.cmml">(</mo><mi id="S4.SS0.SSS0.Px2.p1.4.m1.2.2" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.2.cmml">n</mi><mo id="S4.SS0.SSS0.Px2.p1.4.m1.2.3.2.1.2" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.4.m1.2b"><apply id="S4.SS0.SSS0.Px2.p1.4.m1.2.3.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.3.2"><ci id="S4.SS0.SSS0.Px2.p1.4.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m1.1.1">𝖯𝖤</ci><ci id="S4.SS0.SSS0.Px2.p1.4.m1.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.4.m1.2.2">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.4.m1.2c">\operatorname{\vphantom{fg}\mathsf{PE}}(n)</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.4.m1.2d">start_OPFUNCTION sansserif_PE end_OPFUNCTION ( italic_n )</annotation></semantics></math> is a learned positional embedding vector for layers <math alttext="\{n\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.5.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.5.m2.1a"><mrow id="S4.SS0.SSS0.Px2.p1.5.m2.1.2.2" xref="S4.SS0.SSS0.Px2.p1.5.m2.1.2.1.cmml"><mo id="S4.SS0.SSS0.Px2.p1.5.m2.1.2.2.1" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.5.m2.1.2.1.cmml">{</mo><mi id="S4.SS0.SSS0.Px2.p1.5.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.5.m2.1.1.cmml">n</mi><mo id="S4.SS0.SSS0.Px2.p1.5.m2.1.2.2.2" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.5.m2.1.2.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.5.m2.1b"><set id="S4.SS0.SSS0.Px2.p1.5.m2.1.2.1.cmml" xref="S4.SS0.SSS0.Px2.p1.5.m2.1.2.2"><ci id="S4.SS0.SSS0.Px2.p1.5.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.5.m2.1.1">𝑛</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.5.m2.1c">\{n\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.5.m2.1d">{ italic_n }</annotation></semantics></math>.
<math alttext="\operatorname{\vphantom{fg}\mathsf{LN}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.6.m3.1"><semantics id="S4.SS0.SSS0.Px2.p1.6.m3.1a"><mi id="S4.SS0.SSS0.Px2.p1.6.m3.1.1" xref="S4.SS0.SSS0.Px2.p1.6.m3.1.1.cmml">𝖫𝖭</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.6.m3.1b"><ci id="S4.SS0.SSS0.Px2.p1.6.m3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.6.m3.1.1">𝖫𝖭</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.6.m3.1c">\operatorname{\vphantom{fg}\mathsf{LN}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.6.m3.1d">sansserif_LN</annotation></semantics></math> is LayerNorm <cite class="ltx_cite ltx_citemacro_citep">(Ba et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib2" title="">2016</a>)</cite>.
<math alttext="f^{Q}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.7.m4.1"><semantics id="S4.SS0.SSS0.Px2.p1.7.m4.1a"><msup id="S4.SS0.SSS0.Px2.p1.7.m4.1.1" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.7.m4.1.1.2" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px2.p1.7.m4.1.1.3" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1.3.cmml">Q</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.7.m4.1b"><apply id="S4.SS0.SSS0.Px2.p1.7.m4.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.7.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.7.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1.2">𝑓</ci><ci id="S4.SS0.SSS0.Px2.p1.7.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.7.m4.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.7.m4.1c">f^{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.7.m4.1d">italic_f start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="f^{V}_{n}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.8.m5.1"><semantics id="S4.SS0.SSS0.Px2.p1.8.m5.1a"><msubsup id="S4.SS0.SSS0.Px2.p1.8.m5.1.1" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.2" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.3" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.3.cmml">n</mi><mi id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.3" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.3.cmml">V</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.8.m5.1b"><apply id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.2">𝑓</ci><ci id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.2.3">𝑉</ci></apply><ci id="S4.SS0.SSS0.Px2.p1.8.m5.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.8.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.8.m5.1c">f^{V}_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.8.m5.1d">italic_f start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> are MLPs with a bottleneck at <math alttext="1/2" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.9.m6.1"><semantics id="S4.SS0.SSS0.Px2.p1.9.m6.1a"><mrow id="S4.SS0.SSS0.Px2.p1.9.m6.1.1" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.cmml"><mn id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.2" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.2.cmml">1</mn><mo id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.1" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.1.cmml">/</mo><mn id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.3" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.9.m6.1b"><apply id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1"><divide id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.1"></divide><cn id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.2.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.2">1</cn><cn id="S4.SS0.SSS0.Px2.p1.9.m6.1.1.3.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.9.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.9.m6.1c">1/2</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.9.m6.1d">1 / 2</annotation></semantics></math> the model width <math alttext="{{d}_{\textbf{\small\,z}}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.10.m7.1"><semantics id="S4.SS0.SSS0.Px2.p1.10.m7.1a"><msub id="S4.SS0.SSS0.Px2.p1.10.m7.1.1" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.2" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.3" mathsize="128%" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1.3a.cmml"> z</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.10.m7.1b"><apply id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1.2">𝑑</ci><ci id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.3a.cmml" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1.3"><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px2.p1.10.m7.1.1.3.cmml" mathsize="90%" xref="S4.SS0.SSS0.Px2.p1.10.m7.1.1.3"> z</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.10.m7.1c">{{d}_{\textbf{\small\,z}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.10.m7.1d">italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT</annotation></semantics></math>.
<math alttext="\operatorname{\vphantom{fg}\mathsf{elu}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.11.m8.1"><semantics id="S4.SS0.SSS0.Px2.p1.11.m8.1a"><mi id="S4.SS0.SSS0.Px2.p1.11.m8.1.1" xref="S4.SS0.SSS0.Px2.p1.11.m8.1.1.cmml">𝖾𝗅𝗎</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.11.m8.1b"><ci id="S4.SS0.SSS0.Px2.p1.11.m8.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.11.m8.1.1">𝖾𝗅𝗎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.11.m8.1c">\operatorname{\vphantom{fg}\mathsf{elu}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.11.m8.1d">sansserif_elu</annotation></semantics></math> is from <cite class="ltx_cite ltx_citemacro_citet">Clevert et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib6" title="">2015</a>)</cite>.</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="f({\mathbf{z}})={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{{\mathbf{W}}}}\cdot{\color[rgb]{1,0,0}\definecolor[named]{%
pgfstrokecolor}{rgb}{1,0,0}{\operatorname*{\vphantom{fg}\mathsf{LN}}}}(%
\operatorname{\vphantom{fg}\mathsf{gelu}}({\color[rgb]{1,0,0}\definecolor[%
named]{pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{U}}}}{\mathbf{z}}))" class="ltx_Math" display="block" id="S4.E6.m1.4"><semantics id="S4.E6.m1.4a"><mrow id="S4.E6.m1.4.4" xref="S4.E6.m1.4.4.cmml"><mrow id="S4.E6.m1.4.4.3" xref="S4.E6.m1.4.4.3.cmml"><mi id="S4.E6.m1.4.4.3.2" xref="S4.E6.m1.4.4.3.2.cmml">f</mi><mo id="S4.E6.m1.4.4.3.1" xref="S4.E6.m1.4.4.3.1.cmml">⁢</mo><mrow id="S4.E6.m1.4.4.3.3.2" xref="S4.E6.m1.4.4.3.cmml"><mo id="S4.E6.m1.4.4.3.3.2.1" stretchy="false" xref="S4.E6.m1.4.4.3.cmml">(</mo><mi id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml">𝐳</mi><mo id="S4.E6.m1.4.4.3.3.2.2" stretchy="false" xref="S4.E6.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S4.E6.m1.4.4.2" xref="S4.E6.m1.4.4.2.cmml">=</mo><mrow id="S4.E6.m1.4.4.1" xref="S4.E6.m1.4.4.1.cmml"><mi id="S4.E6.m1.4.4.1.3" mathcolor="#FF0000" xref="S4.E6.m1.4.4.1.3.cmml">𝐖</mi><mo id="S4.E6.m1.4.4.1.2" lspace="0.222em" xref="S4.E6.m1.4.4.1.2.cmml">⋅</mo><mrow id="S4.E6.m1.4.4.1.1.1" xref="S4.E6.m1.4.4.1.1.2.cmml"><mo id="S4.E6.m1.3.3" lspace="0.055em" mathcolor="#FF0000" rspace="0em" xref="S4.E6.m1.3.3.cmml">𝖫𝖭</mo><mrow id="S4.E6.m1.4.4.1.1.1.1" xref="S4.E6.m1.4.4.1.1.2.cmml"><mo id="S4.E6.m1.4.4.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S4.E6.m1.4.4.1.1.2.cmml">(</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.2.cmml"><mi id="S4.E6.m1.2.2" mathcolor="#000000" xref="S4.E6.m1.2.2.cmml">𝗀𝖾𝗅𝗎</mi><mo id="S4.E6.m1.4.4.1.1.1.1.1.1a" xref="S4.E6.m1.4.4.1.1.1.1.1.2.cmml">⁡</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.2.cmml"><mo id="S4.E6.m1.4.4.1.1.1.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S4.E6.m1.4.4.1.1.1.1.1.2.cmml">(</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2" mathcolor="#FF0000" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">𝐔</mi><mo id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3" mathcolor="#000000" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">𝐳</mi></mrow><mo id="S4.E6.m1.4.4.1.1.1.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S4.E6.m1.4.4.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E6.m1.4.4.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S4.E6.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.4b"><apply id="S4.E6.m1.4.4.cmml" xref="S4.E6.m1.4.4"><eq id="S4.E6.m1.4.4.2.cmml" xref="S4.E6.m1.4.4.2"></eq><apply id="S4.E6.m1.4.4.3.cmml" xref="S4.E6.m1.4.4.3"><times id="S4.E6.m1.4.4.3.1.cmml" xref="S4.E6.m1.4.4.3.1"></times><ci id="S4.E6.m1.4.4.3.2.cmml" xref="S4.E6.m1.4.4.3.2">𝑓</ci><ci id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1">𝐳</ci></apply><apply id="S4.E6.m1.4.4.1.cmml" xref="S4.E6.m1.4.4.1"><ci id="S4.E6.m1.4.4.1.2.cmml" xref="S4.E6.m1.4.4.1.2">⋅</ci><ci id="S4.E6.m1.4.4.1.3.cmml" xref="S4.E6.m1.4.4.1.3">𝐖</ci><apply id="S4.E6.m1.4.4.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1"><ci id="S4.E6.m1.3.3.cmml" xref="S4.E6.m1.3.3">𝖫𝖭</ci><apply id="S4.E6.m1.4.4.1.1.1.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1"><ci id="S4.E6.m1.2.2.cmml" xref="S4.E6.m1.2.2">𝗀𝖾𝗅𝗎</ci><apply id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1"><times id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1"></times><ci id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2">𝐔</ci><ci id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3">𝐳</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.4c">f({\mathbf{z}})={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{{\mathbf{W}}}}\cdot{\color[rgb]{1,0,0}\definecolor[named]{%
pgfstrokecolor}{rgb}{1,0,0}{\operatorname*{\vphantom{fg}\mathsf{LN}}}}(%
\operatorname{\vphantom{fg}\mathsf{gelu}}({\color[rgb]{1,0,0}\definecolor[%
named]{pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{U}}}}{\mathbf{z}}))</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.4d">italic_f ( bold_z ) = bold_W ⋅ start_OPERATOR sansserif_LN end_OPERATOR ( start_OPFUNCTION sansserif_gelu end_OPFUNCTION ( bold_U bold_z ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.18">It is then comparable to a single linear layer of size <math alttext="{{d}_{\textbf{\small\,z}}}\times{{d}_{\textbf{\small\,z}}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.12.m1.1"><semantics id="S4.SS0.SSS0.Px2.p1.12.m1.1a"><mrow id="S4.SS0.SSS0.Px2.p1.12.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.cmml"><msub id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.2" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.3" mathsize="128%" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.3a.cmml"> z</mtext></msub><mo id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.1.cmml">×</mo><msub id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.2" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.3" mathsize="128%" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.3a.cmml"> z</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.12.m1.1b"><apply id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1"><times id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.1"></times><apply id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.2">𝑑</ci><ci id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.3a.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.3"><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.3.cmml" mathsize="90%" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.2.3"> z</mtext></ci></apply><apply id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.2">𝑑</ci><ci id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.3a.cmml" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.3"><mtext class="ltx_mathvariant_bold" id="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.3.cmml" mathsize="90%" xref="S4.SS0.SSS0.Px2.p1.12.m1.1.1.3.3"> z</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.12.m1.1c">{{d}_{\textbf{\small\,z}}}\times{{d}_{\textbf{\small\,z}}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.12.m1.1d">italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT × italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT</annotation></semantics></math>. See Section <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S9" title="9. Design Details ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">9</span></a> for details.
Note: the scoring step in <math alttext="\operatorname{\vphantom{fg}\mathsf{Attend}}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.13.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.13.m2.1a"><mi id="S4.SS0.SSS0.Px2.p1.13.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.13.m2.1.1.cmml">𝖠𝗍𝗍𝖾𝗇𝖽</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.13.m2.1b"><ci id="S4.SS0.SSS0.Px2.p1.13.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.13.m2.1.1">𝖠𝗍𝗍𝖾𝗇𝖽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.13.m2.1c">\operatorname{\vphantom{fg}\mathsf{Attend}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.13.m2.1d">sansserif_Attend</annotation></semantics></math> reduces to a single, vector-by-static matrix multiplication as the keys <math alttext="\{{\mathbf{k}}_{n}\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.14.m3.1"><semantics id="S4.SS0.SSS0.Px2.p1.14.m3.1a"><mrow id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.2.cmml">𝐤</mi><mi id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.14.m3.1b"><set id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1"><apply id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.2">𝐤</ci><ci id="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.14.m3.1.1.1.1.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.14.m3.1c">\{{\mathbf{k}}_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.14.m3.1d">{ bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> need no input.
Assume a time step <math alttext="t" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.15.m4.1"><semantics id="S4.SS0.SSS0.Px2.p1.15.m4.1a"><mi id="S4.SS0.SSS0.Px2.p1.15.m4.1.1" xref="S4.SS0.SSS0.Px2.p1.15.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.15.m4.1b"><ci id="S4.SS0.SSS0.Px2.p1.15.m4.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.15.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.15.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.15.m4.1d">italic_t</annotation></semantics></math>, then let <math alttext="{\mathbf{K}}=\{{\mathbf{k}}_{n}\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.16.m5.1"><semantics id="S4.SS0.SSS0.Px2.p1.16.m5.1a"><mrow id="S4.SS0.SSS0.Px2.p1.16.m5.1.1" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.3" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.3.cmml">𝐊</mi><mo id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.2" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.2.cmml">=</mo><mrow id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.2.cmml">𝐤</mi><mi id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.16.m5.1b"><apply id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1"><eq id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.2"></eq><ci id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.3">𝐊</ci><set id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1"><apply id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.2">𝐤</ci><ci id="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.16.m5.1.1.1.1.1.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.16.m5.1c">{\mathbf{K}}=\{{\mathbf{k}}_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.16.m5.1d">bold_K = { bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="{\mathbf{V}}=\{{\mathbf{v}}_{n}\}" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.17.m6.1"><semantics id="S4.SS0.SSS0.Px2.p1.17.m6.1a"><mrow id="S4.SS0.SSS0.Px2.p1.17.m6.1.1" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.3" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.3.cmml">𝐕</mi><mo id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.2" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.2.cmml">=</mo><mrow id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.2.cmml"><mo id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.2" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.2.cmml">{</mo><msub id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.2.cmml">𝐯</mi><mi id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.3" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.17.m6.1b"><apply id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1"><eq id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.2"></eq><ci id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.3">𝐕</ci><set id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1"><apply id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.2">𝐯</ci><ci id="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.17.m6.1.1.1.1.1.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.17.m6.1c">{\mathbf{V}}=\{{\mathbf{v}}_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.17.m6.1d">bold_V = { bold_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> be the matrix forms of the keys and values for <math alttext="n\in\lvert L\rvert" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.18.m7.1"><semantics id="S4.SS0.SSS0.Px2.p1.18.m7.1a"><mrow id="S4.SS0.SSS0.Px2.p1.18.m7.1.2" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.cmml"><mi id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.2" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.2.cmml">n</mi><mo id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.1" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.1.cmml">∈</mo><mrow id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.2" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.1.cmml"><mo id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.2.1" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.1.1.cmml">|</mo><mi id="S4.SS0.SSS0.Px2.p1.18.m7.1.1" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.1.cmml">L</mi><mo id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.2.2" stretchy="false" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.18.m7.1b"><apply id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2"><in id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.1.cmml" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.1"></in><ci id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.2">𝑛</ci><apply id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.1.cmml" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.2"><abs id="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.2.3.2.1"></abs><ci id="S4.SS0.SSS0.Px2.p1.18.m7.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.18.m7.1.1">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.18.m7.1c">n\in\lvert L\rvert</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.18.m7.1d">italic_n ∈ | italic_L |</annotation></semantics></math>. Then:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S11.EGx2">
<tbody id="S4.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\operatorname*{\vphantom{fg}\mathsf{Score}}({\mathbf{q}},{\mathbf%
{K}})" class="ltx_Math" display="inline" id="S4.E7.m1.3"><semantics id="S4.E7.m1.3a"><mrow id="S4.E7.m1.3.4.2" xref="S4.E7.m1.3.4.1.cmml"><mo id="S4.E7.m1.1.1" rspace="0em" xref="S4.E7.m1.1.1.cmml">𝖲𝖼𝗈𝗋𝖾</mo><mrow id="S4.E7.m1.3.4.2.1" xref="S4.E7.m1.3.4.1.cmml"><mo id="S4.E7.m1.3.4.2.1.1" stretchy="false" xref="S4.E7.m1.3.4.1.cmml">(</mo><mi id="S4.E7.m1.2.2" xref="S4.E7.m1.2.2.cmml">𝐪</mi><mo id="S4.E7.m1.3.4.2.1.2" xref="S4.E7.m1.3.4.1.cmml">,</mo><mi id="S4.E7.m1.3.3" xref="S4.E7.m1.3.3.cmml">𝐊</mi><mo id="S4.E7.m1.3.4.2.1.3" stretchy="false" xref="S4.E7.m1.3.4.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.3b"><apply id="S4.E7.m1.3.4.1.cmml" xref="S4.E7.m1.3.4.2"><ci id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1">𝖲𝖼𝗈𝗋𝖾</ci><ci id="S4.E7.m1.2.2.cmml" xref="S4.E7.m1.2.2">𝐪</ci><ci id="S4.E7.m1.3.3.cmml" xref="S4.E7.m1.3.3">𝐊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.3c">\displaystyle\operatorname*{\vphantom{fg}\mathsf{Score}}({\mathbf{q}},{\mathbf%
{K}})</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m1.3d">start_OPERATOR sansserif_Score end_OPERATOR ( bold_q , bold_K )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\operatorname{\vphantom{fg}\mathsf{softmax}}_{n}\left({\mathbf{q%
}}\cdot{\mathbf{K}}^{\top}\right)," class="ltx_Math" display="inline" id="S4.E7.m2.1"><semantics id="S4.E7.m2.1a"><mrow id="S4.E7.m2.1.1.1" xref="S4.E7.m2.1.1.1.1.cmml"><mrow id="S4.E7.m2.1.1.1.1" xref="S4.E7.m2.1.1.1.1.cmml"><mi id="S4.E7.m2.1.1.1.1.4" xref="S4.E7.m2.1.1.1.1.4.cmml"></mi><mo id="S4.E7.m2.1.1.1.1.3" xref="S4.E7.m2.1.1.1.1.3.cmml">=</mo><mrow id="S4.E7.m2.1.1.1.1.2.2" xref="S4.E7.m2.1.1.1.1.2.3.cmml"><msub id="S4.E7.m2.1.1.1.1.1.1.1" xref="S4.E7.m2.1.1.1.1.1.1.1.cmml"><mi id="S4.E7.m2.1.1.1.1.1.1.1.2" xref="S4.E7.m2.1.1.1.1.1.1.1.2.cmml">𝗌𝗈𝖿𝗍𝗆𝖺𝗑</mi><mi id="S4.E7.m2.1.1.1.1.1.1.1.3" xref="S4.E7.m2.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E7.m2.1.1.1.1.2.2a" xref="S4.E7.m2.1.1.1.1.2.3.cmml">⁡</mo><mrow id="S4.E7.m2.1.1.1.1.2.2.2" xref="S4.E7.m2.1.1.1.1.2.3.cmml"><mo id="S4.E7.m2.1.1.1.1.2.2.2.2" xref="S4.E7.m2.1.1.1.1.2.3.cmml">(</mo><mrow id="S4.E7.m2.1.1.1.1.2.2.2.1" xref="S4.E7.m2.1.1.1.1.2.2.2.1.cmml"><mi id="S4.E7.m2.1.1.1.1.2.2.2.1.2" xref="S4.E7.m2.1.1.1.1.2.2.2.1.2.cmml">𝐪</mi><mo id="S4.E7.m2.1.1.1.1.2.2.2.1.1" lspace="0.222em" rspace="0.222em" xref="S4.E7.m2.1.1.1.1.2.2.2.1.1.cmml">⋅</mo><msup id="S4.E7.m2.1.1.1.1.2.2.2.1.3" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3.cmml"><mi id="S4.E7.m2.1.1.1.1.2.2.2.1.3.2" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3.2.cmml">𝐊</mi><mo id="S4.E7.m2.1.1.1.1.2.2.2.1.3.3" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3.3.cmml">⊤</mo></msup></mrow><mo id="S4.E7.m2.1.1.1.1.2.2.2.3" xref="S4.E7.m2.1.1.1.1.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E7.m2.1.1.1.2" xref="S4.E7.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m2.1b"><apply id="S4.E7.m2.1.1.1.1.cmml" xref="S4.E7.m2.1.1.1"><eq id="S4.E7.m2.1.1.1.1.3.cmml" xref="S4.E7.m2.1.1.1.1.3"></eq><csymbol cd="latexml" id="S4.E7.m2.1.1.1.1.4.cmml" xref="S4.E7.m2.1.1.1.1.4">absent</csymbol><apply id="S4.E7.m2.1.1.1.1.2.3.cmml" xref="S4.E7.m2.1.1.1.1.2.2"><apply id="S4.E7.m2.1.1.1.1.1.1.1.cmml" xref="S4.E7.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m2.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E7.m2.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m2.1.1.1.1.1.1.1.2">𝗌𝗈𝖿𝗍𝗆𝖺𝗑</ci><ci id="S4.E7.m2.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m2.1.1.1.1.1.1.1.3">𝑛</ci></apply><apply id="S4.E7.m2.1.1.1.1.2.2.2.1.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1"><ci id="S4.E7.m2.1.1.1.1.2.2.2.1.1.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1.1">⋅</ci><ci id="S4.E7.m2.1.1.1.1.2.2.2.1.2.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1.2">𝐪</ci><apply id="S4.E7.m2.1.1.1.1.2.2.2.1.3.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3"><csymbol cd="ambiguous" id="S4.E7.m2.1.1.1.1.2.2.2.1.3.1.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3">superscript</csymbol><ci id="S4.E7.m2.1.1.1.1.2.2.2.1.3.2.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3.2">𝐊</ci><csymbol cd="latexml" id="S4.E7.m2.1.1.1.1.2.2.2.1.3.3.cmml" xref="S4.E7.m2.1.1.1.1.2.2.2.1.3.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m2.1c">\displaystyle=\operatorname{\vphantom{fg}\mathsf{softmax}}_{n}\left({\mathbf{q%
}}\cdot{\mathbf{K}}^{\top}\right),</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m2.1d">= start_OPFUNCTION sansserif_softmax end_OPFUNCTION start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( bold_q ⋅ bold_K start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
<tbody id="S4.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\operatorname*{\vphantom{fg}\mathsf{Attend}}(\cdots)" class="ltx_Math" display="inline" id="S4.E8.m1.2"><semantics id="S4.E8.m1.2a"><mrow id="S4.E8.m1.2.3.2" xref="S4.E8.m1.2.3.1.cmml"><mo id="S4.E8.m1.1.1" rspace="0em" xref="S4.E8.m1.1.1.cmml">𝖠𝗍𝗍𝖾𝗇𝖽</mo><mrow id="S4.E8.m1.2.3.2.1" xref="S4.E8.m1.2.3.1.cmml"><mo id="S4.E8.m1.2.3.2.1.1" stretchy="false" xref="S4.E8.m1.2.3.1.cmml">(</mo><mi id="S4.E8.m1.2.2" mathvariant="normal" xref="S4.E8.m1.2.2.cmml">⋯</mi><mo id="S4.E8.m1.2.3.2.1.2" stretchy="false" xref="S4.E8.m1.2.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m1.2b"><apply id="S4.E8.m1.2.3.1.cmml" xref="S4.E8.m1.2.3.2"><ci id="S4.E8.m1.1.1.cmml" xref="S4.E8.m1.1.1">𝖠𝗍𝗍𝖾𝗇𝖽</ci><ci id="S4.E8.m1.2.2.cmml" xref="S4.E8.m1.2.2">⋯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.2c">\displaystyle\operatorname*{\vphantom{fg}\mathsf{Attend}}(\cdots)</annotation><annotation encoding="application/x-llamapun" id="S4.E8.m1.2d">start_OPERATOR sansserif_Attend end_OPERATOR ( ⋯ )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\operatorname{\vphantom{fg}\mathsf{Score}}({\mathbf{q}},{\mathbf%
{K}})\cdot{\mathbf{V}}," class="ltx_Math" display="inline" id="S4.E8.m2.4"><semantics id="S4.E8.m2.4a"><mrow id="S4.E8.m2.4.4.1" xref="S4.E8.m2.4.4.1.1.cmml"><mrow id="S4.E8.m2.4.4.1.1" xref="S4.E8.m2.4.4.1.1.cmml"><mi id="S4.E8.m2.4.4.1.1.2" xref="S4.E8.m2.4.4.1.1.2.cmml"></mi><mo id="S4.E8.m2.4.4.1.1.1" xref="S4.E8.m2.4.4.1.1.1.cmml">=</mo><mrow id="S4.E8.m2.4.4.1.1.3" xref="S4.E8.m2.4.4.1.1.3.cmml"><mrow id="S4.E8.m2.4.4.1.1.3.2.2" xref="S4.E8.m2.4.4.1.1.3.2.1.cmml"><mi id="S4.E8.m2.1.1" xref="S4.E8.m2.1.1.cmml">𝖲𝖼𝗈𝗋𝖾</mi><mo id="S4.E8.m2.4.4.1.1.3.2.2a" xref="S4.E8.m2.4.4.1.1.3.2.1.cmml">⁡</mo><mrow id="S4.E8.m2.4.4.1.1.3.2.2.1" xref="S4.E8.m2.4.4.1.1.3.2.1.cmml"><mo id="S4.E8.m2.4.4.1.1.3.2.2.1.1" stretchy="false" xref="S4.E8.m2.4.4.1.1.3.2.1.cmml">(</mo><mi id="S4.E8.m2.2.2" xref="S4.E8.m2.2.2.cmml">𝐪</mi><mo id="S4.E8.m2.4.4.1.1.3.2.2.1.2" xref="S4.E8.m2.4.4.1.1.3.2.1.cmml">,</mo><mi id="S4.E8.m2.3.3" xref="S4.E8.m2.3.3.cmml">𝐊</mi><mo id="S4.E8.m2.4.4.1.1.3.2.2.1.3" rspace="0.055em" stretchy="false" xref="S4.E8.m2.4.4.1.1.3.2.1.cmml">)</mo></mrow></mrow><mo id="S4.E8.m2.4.4.1.1.3.1" rspace="0.222em" xref="S4.E8.m2.4.4.1.1.3.1.cmml">⋅</mo><mi id="S4.E8.m2.4.4.1.1.3.3" xref="S4.E8.m2.4.4.1.1.3.3.cmml">𝐕</mi></mrow></mrow><mo id="S4.E8.m2.4.4.1.2" xref="S4.E8.m2.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m2.4b"><apply id="S4.E8.m2.4.4.1.1.cmml" xref="S4.E8.m2.4.4.1"><eq id="S4.E8.m2.4.4.1.1.1.cmml" xref="S4.E8.m2.4.4.1.1.1"></eq><csymbol cd="latexml" id="S4.E8.m2.4.4.1.1.2.cmml" xref="S4.E8.m2.4.4.1.1.2">absent</csymbol><apply id="S4.E8.m2.4.4.1.1.3.cmml" xref="S4.E8.m2.4.4.1.1.3"><ci id="S4.E8.m2.4.4.1.1.3.1.cmml" xref="S4.E8.m2.4.4.1.1.3.1">⋅</ci><apply id="S4.E8.m2.4.4.1.1.3.2.1.cmml" xref="S4.E8.m2.4.4.1.1.3.2.2"><ci id="S4.E8.m2.1.1.cmml" xref="S4.E8.m2.1.1">𝖲𝖼𝗈𝗋𝖾</ci><ci id="S4.E8.m2.2.2.cmml" xref="S4.E8.m2.2.2">𝐪</ci><ci id="S4.E8.m2.3.3.cmml" xref="S4.E8.m2.3.3">𝐊</ci></apply><ci id="S4.E8.m2.4.4.1.1.3.3.cmml" xref="S4.E8.m2.4.4.1.1.3.3">𝐕</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m2.4c">\displaystyle=\operatorname{\vphantom{fg}\mathsf{Score}}({\mathbf{q}},{\mathbf%
{K}})\cdot{\mathbf{V}},</annotation><annotation encoding="application/x-llamapun" id="S4.E8.m2.4d">= start_OPFUNCTION sansserif_Score end_OPFUNCTION ( bold_q , bold_K ) ⋅ bold_V ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
<tbody id="S4.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle{{\mathbf{h}}}" class="ltx_Math" display="inline" id="S4.E9.m1.1"><semantics id="S4.E9.m1.1a"><mi id="S4.E9.m1.1.1" xref="S4.E9.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S4.E9.m1.1b"><ci id="S4.E9.m1.1.1.cmml" xref="S4.E9.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.1c">\displaystyle{{\mathbf{h}}}</annotation><annotation encoding="application/x-llamapun" id="S4.E9.m1.1d">bold_h</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle={\mathbf{z}}_{L}+\operatorname{\vphantom{fg}\mathsf{Attend}}\big%
{(}{\mathbf{q}},\{{\mathbf{k}}_{n}\},\{{\mathbf{v}}_{n}\}\big{)}." class="ltx_Math" display="inline" id="S4.E9.m2.3"><semantics id="S4.E9.m2.3a"><mrow id="S4.E9.m2.3.3.1" xref="S4.E9.m2.3.3.1.1.cmml"><mrow id="S4.E9.m2.3.3.1.1" xref="S4.E9.m2.3.3.1.1.cmml"><mi id="S4.E9.m2.3.3.1.1.4" xref="S4.E9.m2.3.3.1.1.4.cmml"></mi><mo id="S4.E9.m2.3.3.1.1.3" xref="S4.E9.m2.3.3.1.1.3.cmml">=</mo><mrow id="S4.E9.m2.3.3.1.1.2" xref="S4.E9.m2.3.3.1.1.2.cmml"><msub id="S4.E9.m2.3.3.1.1.2.4" xref="S4.E9.m2.3.3.1.1.2.4.cmml"><mi id="S4.E9.m2.3.3.1.1.2.4.2" xref="S4.E9.m2.3.3.1.1.2.4.2.cmml">𝐳</mi><mi id="S4.E9.m2.3.3.1.1.2.4.3" xref="S4.E9.m2.3.3.1.1.2.4.3.cmml">L</mi></msub><mo id="S4.E9.m2.3.3.1.1.2.3" xref="S4.E9.m2.3.3.1.1.2.3.cmml">+</mo><mrow id="S4.E9.m2.3.3.1.1.2.2.2" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml"><mi id="S4.E9.m2.1.1" xref="S4.E9.m2.1.1.cmml">𝖠𝗍𝗍𝖾𝗇𝖽</mi><mo id="S4.E9.m2.3.3.1.1.2.2.2a" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml">⁡</mo><mrow id="S4.E9.m2.3.3.1.1.2.2.2.2" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml"><mo id="S4.E9.m2.3.3.1.1.2.2.2.2.3" maxsize="120%" minsize="120%" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml">(</mo><mi id="S4.E9.m2.2.2" xref="S4.E9.m2.2.2.cmml">𝐪</mi><mo id="S4.E9.m2.3.3.1.1.2.2.2.2.4" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml">,</mo><mrow id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.2.cmml"><mo id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.2.cmml">{</mo><msub id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.2" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.2.cmml">𝐤</mi><mi id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.3" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.2.cmml">}</mo></mrow><mo id="S4.E9.m2.3.3.1.1.2.2.2.2.5" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml">,</mo><mrow id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.2.cmml"><mo id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.2" stretchy="false" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.2.cmml">{</mo><msub id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.cmml"><mi id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.2" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.2.cmml">𝐯</mi><mi id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.3" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.3.cmml">n</mi></msub><mo id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.3" stretchy="false" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.2.cmml">}</mo></mrow><mo id="S4.E9.m2.3.3.1.1.2.2.2.2.6" maxsize="120%" minsize="120%" xref="S4.E9.m2.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E9.m2.3.3.1.2" lspace="0em" xref="S4.E9.m2.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m2.3b"><apply id="S4.E9.m2.3.3.1.1.cmml" xref="S4.E9.m2.3.3.1"><eq id="S4.E9.m2.3.3.1.1.3.cmml" xref="S4.E9.m2.3.3.1.1.3"></eq><csymbol cd="latexml" id="S4.E9.m2.3.3.1.1.4.cmml" xref="S4.E9.m2.3.3.1.1.4">absent</csymbol><apply id="S4.E9.m2.3.3.1.1.2.cmml" xref="S4.E9.m2.3.3.1.1.2"><plus id="S4.E9.m2.3.3.1.1.2.3.cmml" xref="S4.E9.m2.3.3.1.1.2.3"></plus><apply id="S4.E9.m2.3.3.1.1.2.4.cmml" xref="S4.E9.m2.3.3.1.1.2.4"><csymbol cd="ambiguous" id="S4.E9.m2.3.3.1.1.2.4.1.cmml" xref="S4.E9.m2.3.3.1.1.2.4">subscript</csymbol><ci id="S4.E9.m2.3.3.1.1.2.4.2.cmml" xref="S4.E9.m2.3.3.1.1.2.4.2">𝐳</ci><ci id="S4.E9.m2.3.3.1.1.2.4.3.cmml" xref="S4.E9.m2.3.3.1.1.2.4.3">𝐿</ci></apply><apply id="S4.E9.m2.3.3.1.1.2.2.3.cmml" xref="S4.E9.m2.3.3.1.1.2.2.2"><ci id="S4.E9.m2.1.1.cmml" xref="S4.E9.m2.1.1">𝖠𝗍𝗍𝖾𝗇𝖽</ci><ci id="S4.E9.m2.2.2.cmml" xref="S4.E9.m2.2.2">𝐪</ci><set id="S4.E9.m2.3.3.1.1.1.1.1.1.1.2.cmml" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1"><apply id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.2">𝐤</ci><ci id="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E9.m2.3.3.1.1.1.1.1.1.1.1.1.3">𝑛</ci></apply></set><set id="S4.E9.m2.3.3.1.1.2.2.2.2.2.2.cmml" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1"><apply id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.cmml" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.1.cmml" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1">subscript</csymbol><ci id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.2.cmml" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.2">𝐯</ci><ci id="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.3.cmml" xref="S4.E9.m2.3.3.1.1.2.2.2.2.2.1.1.3">𝑛</ci></apply></set></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m2.3c">\displaystyle={\mathbf{z}}_{L}+\operatorname{\vphantom{fg}\mathsf{Attend}}\big%
{(}{\mathbf{q}},\{{\mathbf{k}}_{n}\},\{{\mathbf{v}}_{n}\}\big{)}.</annotation><annotation encoding="application/x-llamapun" id="S4.E9.m2.3d">= bold_z start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT + start_OPFUNCTION sansserif_Attend end_OPFUNCTION ( bold_q , { bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , { bold_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.1.   Baselines</h3>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.1">Name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.3.1">New Layer</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1">+ <math alttext="O(\cdot)" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.m1.1.2" xref="S4.T2.1.1.1.1.m1.1.2.cmml"><mi id="S4.T2.1.1.1.1.m1.1.2.2" xref="S4.T2.1.1.1.1.m1.1.2.2.cmml">O</mi><mo id="S4.T2.1.1.1.1.m1.1.2.1" xref="S4.T2.1.1.1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S4.T2.1.1.1.1.m1.1.2.3.2" xref="S4.T2.1.1.1.1.m1.1.2.cmml"><mo id="S4.T2.1.1.1.1.m1.1.2.3.2.1" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.2.cmml">(</mo><mo id="S4.T2.1.1.1.1.m1.1.1" lspace="0em" rspace="0em" xref="S4.T2.1.1.1.1.m1.1.1.cmml">⋅</mo><mo id="S4.T2.1.1.1.1.m1.1.2.3.2.2" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.m1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.2"><times id="S4.T2.1.1.1.1.m1.1.2.1.cmml" xref="S4.T2.1.1.1.1.m1.1.2.1"></times><ci id="S4.T2.1.1.1.1.m1.1.2.2.cmml" xref="S4.T2.1.1.1.1.m1.1.2.2">𝑂</ci><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">O(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">italic_O ( ⋅ )</annotation></semantics></math></span></th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.1">+ #</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.8.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.8.9.1.1.1">Base</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.8.9.1.2">-</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.8.9.1.3">-</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T2.8.9.1.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.1">Base<sub class="ltx_sub" id="S4.T2.4.4.4.1.1">+n</sub></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.2.2.1">
<math alttext="n\times" class="ltx_math_unparsed" display="inline" id="S4.T2.2.2.1.m1.1"><semantics id="S4.T2.2.2.1.m1.1a"><mrow id="S4.T2.2.2.1.m1.1b"><mi id="S4.T2.2.2.1.m1.1.1">n</mi><mo id="S4.T2.2.2.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">n\times</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.1.m1.1d">italic_n ×</annotation></semantics></math> Base</th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.3.2"><math alttext="7n\ (d+d^{2})" class="ltx_Math" display="inline" id="S4.T2.3.3.2.m1.1"><semantics id="S4.T2.3.3.2.m1.1a"><mrow id="S4.T2.3.3.2.m1.1.1" xref="S4.T2.3.3.2.m1.1.1.cmml"><mn id="S4.T2.3.3.2.m1.1.1.3" xref="S4.T2.3.3.2.m1.1.1.3.cmml">7</mn><mo id="S4.T2.3.3.2.m1.1.1.2" xref="S4.T2.3.3.2.m1.1.1.2.cmml">⁢</mo><mi id="S4.T2.3.3.2.m1.1.1.4" xref="S4.T2.3.3.2.m1.1.1.4.cmml">n</mi><mo id="S4.T2.3.3.2.m1.1.1.2a" lspace="0.500em" xref="S4.T2.3.3.2.m1.1.1.2.cmml">⁢</mo><mrow id="S4.T2.3.3.2.m1.1.1.1.1" xref="S4.T2.3.3.2.m1.1.1.1.1.1.cmml"><mo id="S4.T2.3.3.2.m1.1.1.1.1.2" stretchy="false" xref="S4.T2.3.3.2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.T2.3.3.2.m1.1.1.1.1.1" xref="S4.T2.3.3.2.m1.1.1.1.1.1.cmml"><mi id="S4.T2.3.3.2.m1.1.1.1.1.1.2" xref="S4.T2.3.3.2.m1.1.1.1.1.1.2.cmml">d</mi><mo id="S4.T2.3.3.2.m1.1.1.1.1.1.1" xref="S4.T2.3.3.2.m1.1.1.1.1.1.1.cmml">+</mo><msup id="S4.T2.3.3.2.m1.1.1.1.1.1.3" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3.cmml"><mi id="S4.T2.3.3.2.m1.1.1.1.1.1.3.2" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3.2.cmml">d</mi><mn id="S4.T2.3.3.2.m1.1.1.1.1.1.3.3" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3.3.cmml">2</mn></msup></mrow><mo id="S4.T2.3.3.2.m1.1.1.1.1.3" stretchy="false" xref="S4.T2.3.3.2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.2.m1.1b"><apply id="S4.T2.3.3.2.m1.1.1.cmml" xref="S4.T2.3.3.2.m1.1.1"><times id="S4.T2.3.3.2.m1.1.1.2.cmml" xref="S4.T2.3.3.2.m1.1.1.2"></times><cn id="S4.T2.3.3.2.m1.1.1.3.cmml" type="integer" xref="S4.T2.3.3.2.m1.1.1.3">7</cn><ci id="S4.T2.3.3.2.m1.1.1.4.cmml" xref="S4.T2.3.3.2.m1.1.1.4">𝑛</ci><apply id="S4.T2.3.3.2.m1.1.1.1.1.1.cmml" xref="S4.T2.3.3.2.m1.1.1.1.1"><plus id="S4.T2.3.3.2.m1.1.1.1.1.1.1.cmml" xref="S4.T2.3.3.2.m1.1.1.1.1.1.1"></plus><ci id="S4.T2.3.3.2.m1.1.1.1.1.1.2.cmml" xref="S4.T2.3.3.2.m1.1.1.1.1.1.2">𝑑</ci><apply id="S4.T2.3.3.2.m1.1.1.1.1.1.3.cmml" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.T2.3.3.2.m1.1.1.1.1.1.3.1.cmml" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.T2.3.3.2.m1.1.1.1.1.1.3.2.cmml" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3.2">𝑑</ci><cn id="S4.T2.3.3.2.m1.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.T2.3.3.2.m1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.2.m1.1c">7n\ (d+d^{2})</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.2.m1.1d">7 italic_n ( italic_d + italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T2.4.4.3">
<math alttext="25.19" class="ltx_Math" display="inline" id="S4.T2.4.4.3.m1.1"><semantics id="S4.T2.4.4.3.m1.1a"><mn id="S4.T2.4.4.3.m1.1.1" xref="S4.T2.4.4.3.m1.1.1.cmml">25.19</mn><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.3.m1.1b"><cn id="S4.T2.4.4.3.m1.1.1.cmml" type="float" xref="S4.T2.4.4.3.m1.1.1">25.19</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.3.m1.1c">25.19</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.3.m1.1d">25.19</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.6.6.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.3.1">Concat</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.6.6.4">Affine</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.5.5.1"><math alttext="Ld^{2}" class="ltx_Math" display="inline" id="S4.T2.5.5.1.m1.1"><semantics id="S4.T2.5.5.1.m1.1a"><mrow id="S4.T2.5.5.1.m1.1.1" xref="S4.T2.5.5.1.m1.1.1.cmml"><mi id="S4.T2.5.5.1.m1.1.1.2" xref="S4.T2.5.5.1.m1.1.1.2.cmml">L</mi><mo id="S4.T2.5.5.1.m1.1.1.1" xref="S4.T2.5.5.1.m1.1.1.1.cmml">⁢</mo><msup id="S4.T2.5.5.1.m1.1.1.3" xref="S4.T2.5.5.1.m1.1.1.3.cmml"><mi id="S4.T2.5.5.1.m1.1.1.3.2" xref="S4.T2.5.5.1.m1.1.1.3.2.cmml">d</mi><mn id="S4.T2.5.5.1.m1.1.1.3.3" xref="S4.T2.5.5.1.m1.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.m1.1b"><apply id="S4.T2.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1"><times id="S4.T2.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1.1"></times><ci id="S4.T2.5.5.1.m1.1.1.2.cmml" xref="S4.T2.5.5.1.m1.1.1.2">𝐿</ci><apply id="S4.T2.5.5.1.m1.1.1.3.cmml" xref="S4.T2.5.5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T2.5.5.1.m1.1.1.3.1.cmml" xref="S4.T2.5.5.1.m1.1.1.3">superscript</csymbol><ci id="S4.T2.5.5.1.m1.1.1.3.2.cmml" xref="S4.T2.5.5.1.m1.1.1.3.2">𝑑</ci><cn id="S4.T2.5.5.1.m1.1.1.3.3.cmml" type="integer" xref="S4.T2.5.5.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.m1.1c">Ld^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.1.m1.1d">italic_L italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T2.6.6.2">
<math alttext="25.18" class="ltx_Math" display="inline" id="S4.T2.6.6.2.m1.1"><semantics id="S4.T2.6.6.2.m1.1a"><mn id="S4.T2.6.6.2.m1.1.1" xref="S4.T2.6.6.2.m1.1.1.cmml">25.18</mn><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.2.m1.1b"><cn id="S4.T2.6.6.2.m1.1.1.cmml" type="float" xref="S4.T2.6.6.2.m1.1.1">25.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.2.m1.1c">25.18</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.2.m1.1d">25.18</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T2.8.8.3"><span class="ltx_text ltx_font_bold" id="S4.T2.8.8.3.1">DWAtt</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T2.8.8.4">DWAtt</th>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T2.7.7.1"><math alttext="Ld^{2}+d^{2}+Ld" class="ltx_Math" display="inline" id="S4.T2.7.7.1.m1.1"><semantics id="S4.T2.7.7.1.m1.1a"><mrow id="S4.T2.7.7.1.m1.1.1" xref="S4.T2.7.7.1.m1.1.1.cmml"><mrow id="S4.T2.7.7.1.m1.1.1.2" xref="S4.T2.7.7.1.m1.1.1.2.cmml"><mi id="S4.T2.7.7.1.m1.1.1.2.2" xref="S4.T2.7.7.1.m1.1.1.2.2.cmml">L</mi><mo id="S4.T2.7.7.1.m1.1.1.2.1" xref="S4.T2.7.7.1.m1.1.1.2.1.cmml">⁢</mo><msup id="S4.T2.7.7.1.m1.1.1.2.3" xref="S4.T2.7.7.1.m1.1.1.2.3.cmml"><mi id="S4.T2.7.7.1.m1.1.1.2.3.2" xref="S4.T2.7.7.1.m1.1.1.2.3.2.cmml">d</mi><mn id="S4.T2.7.7.1.m1.1.1.2.3.3" xref="S4.T2.7.7.1.m1.1.1.2.3.3.cmml">2</mn></msup></mrow><mo id="S4.T2.7.7.1.m1.1.1.1" xref="S4.T2.7.7.1.m1.1.1.1.cmml">+</mo><msup id="S4.T2.7.7.1.m1.1.1.3" xref="S4.T2.7.7.1.m1.1.1.3.cmml"><mi id="S4.T2.7.7.1.m1.1.1.3.2" xref="S4.T2.7.7.1.m1.1.1.3.2.cmml">d</mi><mn id="S4.T2.7.7.1.m1.1.1.3.3" xref="S4.T2.7.7.1.m1.1.1.3.3.cmml">2</mn></msup><mo id="S4.T2.7.7.1.m1.1.1.1a" xref="S4.T2.7.7.1.m1.1.1.1.cmml">+</mo><mrow id="S4.T2.7.7.1.m1.1.1.4" xref="S4.T2.7.7.1.m1.1.1.4.cmml"><mi id="S4.T2.7.7.1.m1.1.1.4.2" xref="S4.T2.7.7.1.m1.1.1.4.2.cmml">L</mi><mo id="S4.T2.7.7.1.m1.1.1.4.1" xref="S4.T2.7.7.1.m1.1.1.4.1.cmml">⁢</mo><mi id="S4.T2.7.7.1.m1.1.1.4.3" xref="S4.T2.7.7.1.m1.1.1.4.3.cmml">d</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.1.m1.1b"><apply id="S4.T2.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.1.m1.1.1"><plus id="S4.T2.7.7.1.m1.1.1.1.cmml" xref="S4.T2.7.7.1.m1.1.1.1"></plus><apply id="S4.T2.7.7.1.m1.1.1.2.cmml" xref="S4.T2.7.7.1.m1.1.1.2"><times id="S4.T2.7.7.1.m1.1.1.2.1.cmml" xref="S4.T2.7.7.1.m1.1.1.2.1"></times><ci id="S4.T2.7.7.1.m1.1.1.2.2.cmml" xref="S4.T2.7.7.1.m1.1.1.2.2">𝐿</ci><apply id="S4.T2.7.7.1.m1.1.1.2.3.cmml" xref="S4.T2.7.7.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S4.T2.7.7.1.m1.1.1.2.3.1.cmml" xref="S4.T2.7.7.1.m1.1.1.2.3">superscript</csymbol><ci id="S4.T2.7.7.1.m1.1.1.2.3.2.cmml" xref="S4.T2.7.7.1.m1.1.1.2.3.2">𝑑</ci><cn id="S4.T2.7.7.1.m1.1.1.2.3.3.cmml" type="integer" xref="S4.T2.7.7.1.m1.1.1.2.3.3">2</cn></apply></apply><apply id="S4.T2.7.7.1.m1.1.1.3.cmml" xref="S4.T2.7.7.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T2.7.7.1.m1.1.1.3.1.cmml" xref="S4.T2.7.7.1.m1.1.1.3">superscript</csymbol><ci id="S4.T2.7.7.1.m1.1.1.3.2.cmml" xref="S4.T2.7.7.1.m1.1.1.3.2">𝑑</ci><cn id="S4.T2.7.7.1.m1.1.1.3.3.cmml" type="integer" xref="S4.T2.7.7.1.m1.1.1.3.3">2</cn></apply><apply id="S4.T2.7.7.1.m1.1.1.4.cmml" xref="S4.T2.7.7.1.m1.1.1.4"><times id="S4.T2.7.7.1.m1.1.1.4.1.cmml" xref="S4.T2.7.7.1.m1.1.1.4.1"></times><ci id="S4.T2.7.7.1.m1.1.1.4.2.cmml" xref="S4.T2.7.7.1.m1.1.1.4.2">𝐿</ci><ci id="S4.T2.7.7.1.m1.1.1.4.3.cmml" xref="S4.T2.7.7.1.m1.1.1.4.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.1.m1.1c">Ld^{2}+d^{2}+Ld</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.7.1.m1.1d">italic_L italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_L italic_d</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb ltx_border_t" id="S4.T2.8.8.2">
<math alttext="26.38" class="ltx_Math" display="inline" id="S4.T2.8.8.2.m1.1"><semantics id="S4.T2.8.8.2.m1.1a"><mn id="S4.T2.8.8.2.m1.1.1" xref="S4.T2.8.8.2.m1.1.1.cmml">26.38</mn><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.2.m1.1b"><cn id="S4.T2.8.8.2.m1.1.1.cmml" type="float" xref="S4.T2.8.8.2.m1.1.1">26.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.2.m1.1c">26.38</annotation><annotation encoding="application/x-llamapun" id="S4.T2.8.8.2.m1.1d">26.38</annotation></semantics></math>M</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.20.3.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.12.2" style="font-size:90%;">The <span class="ltx_text ltx_font_bold" id="S4.T2.12.2.1">size and count of parameters of new layers</span> in different configurations. Counts are of models building on RoBERTa<sub class="ltx_sub" id="S4.T2.12.2.2">24</sub>.
<span class="ltx_text ltx_font_typewriter" id="S4.T2.12.2.3">Base<sub class="ltx_sub" id="S4.T2.12.2.3.1">+n</sub></span> (deeper baseline) is chosen to be close in size to <span class="ltx_text ltx_font_typewriter" id="S4.T2.12.2.4">DWAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S4.T2.12.2.5">Concat</span>.
For example, for base models with 12 layers, only n=1 layers are added; n=2 for 24 layer models. <math alttext="L" class="ltx_Math" display="inline" id="S4.T2.11.1.m1.1"><semantics id="S4.T2.11.1.m1.1b"><mi id="S4.T2.11.1.m1.1.1" xref="S4.T2.11.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.T2.11.1.m1.1c"><ci id="S4.T2.11.1.m1.1.1.cmml" xref="S4.T2.11.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.1.m1.1d">L</annotation><annotation encoding="application/x-llamapun" id="S4.T2.11.1.m1.1e">italic_L</annotation></semantics></math> refers to the depth of the <em class="ltx_emph ltx_font_italic" id="S4.T2.12.2.6">base</em> model, while <math alttext="d" class="ltx_Math" display="inline" id="S4.T2.12.2.m2.1"><semantics id="S4.T2.12.2.m2.1b"><mi id="S4.T2.12.2.m2.1.1" xref="S4.T2.12.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.T2.12.2.m2.1c"><ci id="S4.T2.12.2.m2.1.1.cmml" xref="S4.T2.12.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.2.m2.1d">d</annotation><annotation encoding="application/x-llamapun" id="S4.T2.12.2.m2.1e">italic_d</annotation></semantics></math> refers to the model width.
</span></figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Base Model.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">The base model (RoBERTa or XLM-RoBERTa in <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px1.p1.1.1">base</span> or <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px1.p1.1.2">large</span> sizes) is used as-is. The task module is changed where needed. In <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px1.p1.1.3">FE</span> only the task module (or vocabulary module in MLM) is trained.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Extra Transformer Layers.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">On top of the base model, we add <math alttext="2" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px2.p1.1.m1.1a"><mn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.1.m1.1b"><cn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px2.p1.1.m1.1d">2</annotation></semantics></math> more Transformer layers before the classification head. In <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.1">FE</span> mode, we train only the added layers. We refer to this model as <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.2">R<sub class="ltx_sub" id="S4.SS1.SSS0.Px2.p1.1.2.1">26</sub></span> (RoBERTa) or <span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S4.SS1.SSS0.Px2.p1.1.3">XLM-R<sub class="ltx_sub" id="S4.SS1.SSS0.Px2.p1.1.3.1">26</sub></span> (XLM-RoBERTa).</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">5.   Experimentation Setup</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.1.   Base Models</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Monolingual experiments using <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.1">CoNLL-03</span>, the English subset of <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.2">WikiAnn</span>, and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.3">WikiText-2</span> all build on <span class="ltx_text" id="S5.SS1.p1.1.4">RoBERTa</span> (<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.5">R</span>) <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib21" title="">2019</a>)</cite> via the pretrained <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.6">roberta-large</span> model. Multilingual experiments using <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.7">WikiAnn</span> build on <span class="ltx_text" id="S5.SS1.p1.1.8">XLM-RoBERTa</span> (<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.9">XLM-R</span>) via the pretrained <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.10">xlm-roberta-large</span> model. Experiments using other variants are explicitly specified. Pretrained models are accessed via the HuggingFace package <cite class="ltx_cite ltx_citemacro_citep">(Wolf et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib36" title="">2019</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.2.   Training</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">In figures where the epoch count is reported: Each chart shows an experiment with the indicated <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><msub id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">N</mi><mi id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">𝑁</ci><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">{N_{\mathsf{\vphantom{fg}epochs}}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT</annotation></semantics></math> max epochs, which starts LR at max then decays it linearly to zero.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.4">Few-shot experiments sample <math alttext="NC" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mrow id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">N</mi><mo id="S5.SS2.p2.1.m1.1.1.1" xref="S5.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><times id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1"></times><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">𝑁</ci><ci id="S5.SS2.p2.1.m1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">NC</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_N italic_C</annotation></semantics></math> points uniformly at random from the full training set. Sampling is not stratified, so <math alttext="N=8" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">N</mi><mo id="S5.SS2.p2.2.m2.1.1.1" xref="S5.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><eq id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1.1"></eq><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">𝑁</ci><cn id="S5.SS2.p2.2.m2.1.1.3.cmml" type="integer" xref="S5.SS2.p2.2.m2.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">N=8</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">italic_N = 8</annotation></semantics></math> Shot for <math alttext="C=4" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mrow id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml"><mi id="S5.SS2.p2.3.m3.1.1.2" xref="S5.SS2.p2.3.m3.1.1.2.cmml">C</mi><mo id="S5.SS2.p2.3.m3.1.1.1" xref="S5.SS2.p2.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS2.p2.3.m3.1.1.3" xref="S5.SS2.p2.3.m3.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><apply id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1"><eq id="S5.SS2.p2.3.m3.1.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1.1"></eq><ci id="S5.SS2.p2.3.m3.1.1.2.cmml" xref="S5.SS2.p2.3.m3.1.1.2">𝐶</ci><cn id="S5.SS2.p2.3.m3.1.1.3.cmml" type="integer" xref="S5.SS2.p2.3.m3.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">C=4</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">italic_C = 4</annotation></semantics></math> classes means <math alttext="32" class="ltx_Math" display="inline" id="S5.SS2.p2.4.m4.1"><semantics id="S5.SS2.p2.4.m4.1a"><mn id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><cn id="S5.SS2.p2.4.m4.1.1.cmml" type="integer" xref="S5.SS2.p2.4.m4.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">32</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.4.m4.1d">32</annotation></semantics></math> points in total sampled without replacement.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">5.3.   Evaluation</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.2">NER experiments report Micro-Average F1 using seqeval <cite class="ltx_cite ltx_citemacro_citep">(Nakayama, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib24" title="">2018</a>)</cite>.
Where applicable, experiments are given 5 trials whose average and confidence interval are reported by <span class="ltx_text" id="S5.SS3.p1.2.1" style="background-color:#E6E6E6;"> <span class="ltx_text ltx_phantom" id="S5.SS3.p1.2.1.1"><span style="visibility:hidden">Ay</span></span><span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.2.1.2">seaborn</span> </span> <cite class="ltx_cite ltx_citemacro_citep">(Waskom, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib35" title="">2021</a>)</cite>. For easier reading, we report scores that lie in <math alttext="[0,1]" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.2"><semantics id="S5.SS3.p1.1.m1.2a"><mrow id="S5.SS3.p1.1.m1.2.3.2" xref="S5.SS3.p1.1.m1.2.3.1.cmml"><mo id="S5.SS3.p1.1.m1.2.3.2.1" stretchy="false" xref="S5.SS3.p1.1.m1.2.3.1.cmml">[</mo><mn id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">0</mn><mo id="S5.SS3.p1.1.m1.2.3.2.2" xref="S5.SS3.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.SS3.p1.1.m1.2.2" xref="S5.SS3.p1.1.m1.2.2.cmml">1</mn><mo id="S5.SS3.p1.1.m1.2.3.2.3" stretchy="false" xref="S5.SS3.p1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.2b"><interval closure="closed" id="S5.SS3.p1.1.m1.2.3.1.cmml" xref="S5.SS3.p1.1.m1.2.3.2"><cn id="S5.SS3.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1">0</cn><cn id="S5.SS3.p1.1.m1.2.2.cmml" type="integer" xref="S5.SS3.p1.1.m1.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.2c">[0,1]</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.2d">[ 0 , 1 ]</annotation></semantics></math> as percentages <math alttext="[0,100]\%" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.2"><semantics id="S5.SS3.p1.2.m2.2a"><mrow id="S5.SS3.p1.2.m2.2.3" xref="S5.SS3.p1.2.m2.2.3.cmml"><mrow id="S5.SS3.p1.2.m2.2.3.2.2" xref="S5.SS3.p1.2.m2.2.3.2.1.cmml"><mo id="S5.SS3.p1.2.m2.2.3.2.2.1" stretchy="false" xref="S5.SS3.p1.2.m2.2.3.2.1.cmml">[</mo><mn id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml">0</mn><mo id="S5.SS3.p1.2.m2.2.3.2.2.2" xref="S5.SS3.p1.2.m2.2.3.2.1.cmml">,</mo><mn id="S5.SS3.p1.2.m2.2.2" xref="S5.SS3.p1.2.m2.2.2.cmml">100</mn><mo id="S5.SS3.p1.2.m2.2.3.2.2.3" stretchy="false" xref="S5.SS3.p1.2.m2.2.3.2.1.cmml">]</mo></mrow><mo id="S5.SS3.p1.2.m2.2.3.1" xref="S5.SS3.p1.2.m2.2.3.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.2b"><apply id="S5.SS3.p1.2.m2.2.3.cmml" xref="S5.SS3.p1.2.m2.2.3"><csymbol cd="latexml" id="S5.SS3.p1.2.m2.2.3.1.cmml" xref="S5.SS3.p1.2.m2.2.3.1">percent</csymbol><interval closure="closed" id="S5.SS3.p1.2.m2.2.3.2.1.cmml" xref="S5.SS3.p1.2.m2.2.3.2.2"><cn id="S5.SS3.p1.2.m2.1.1.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1">0</cn><cn id="S5.SS3.p1.2.m2.2.2.cmml" type="integer" xref="S5.SS3.p1.2.m2.2.2">100</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.2c">[0,100]\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.2d">[ 0 , 100 ] %</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">6.   Results and Analysis</h2>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.1.   <span class="ltx_text ltx_align_left ltx_font_typewriter" id="S6.SS1.1.1">CoNLL</span>: Few-Shot Adaptation</h3>
<figure class="ltx_figure" id="S6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F3.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.19.8.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text ltx_font_bold" id="S6.F3.14.7" style="font-size:90%;">F1-Score on the <span class="ltx_text ltx_font_typewriter" id="S6.F3.14.7.8">CoNLL-03</span> devset.<span class="ltx_text ltx_font_medium" id="S6.F3.14.7.9"> All pretrained weights are frozen (</span>FE<span class="ltx_text ltx_font_medium" id="S6.F3.14.7.7">). In each chart from left to right, training is constrained to <math alttext="25" class="ltx_Math" display="inline" id="S6.F3.8.1.1.m1.1"><semantics id="S6.F3.8.1.1.m1.1b"><mn id="S6.F3.8.1.1.m1.1.1" xref="S6.F3.8.1.1.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S6.F3.8.1.1.m1.1c"><cn id="S6.F3.8.1.1.m1.1.1.cmml" type="integer" xref="S6.F3.8.1.1.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.8.1.1.m1.1d">25</annotation><annotation encoding="application/x-llamapun" id="S6.F3.8.1.1.m1.1e">25</annotation></semantics></math>, <math alttext="50" class="ltx_Math" display="inline" id="S6.F3.9.2.2.m2.1"><semantics id="S6.F3.9.2.2.m2.1b"><mn id="S6.F3.9.2.2.m2.1.1" xref="S6.F3.9.2.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S6.F3.9.2.2.m2.1c"><cn id="S6.F3.9.2.2.m2.1.1.cmml" type="integer" xref="S6.F3.9.2.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.9.2.2.m2.1d">50</annotation><annotation encoding="application/x-llamapun" id="S6.F3.9.2.2.m2.1e">50</annotation></semantics></math>, <math alttext="75" class="ltx_Math" display="inline" id="S6.F3.10.3.3.m3.1"><semantics id="S6.F3.10.3.3.m3.1b"><mn id="S6.F3.10.3.3.m3.1.1" xref="S6.F3.10.3.3.m3.1.1.cmml">75</mn><annotation-xml encoding="MathML-Content" id="S6.F3.10.3.3.m3.1c"><cn id="S6.F3.10.3.3.m3.1.1.cmml" type="integer" xref="S6.F3.10.3.3.m3.1.1">75</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.10.3.3.m3.1d">75</annotation><annotation encoding="application/x-llamapun" id="S6.F3.10.3.3.m3.1e">75</annotation></semantics></math>, and <math alttext="100" class="ltx_Math" display="inline" id="S6.F3.11.4.4.m4.1"><semantics id="S6.F3.11.4.4.m4.1b"><mn id="S6.F3.11.4.4.m4.1.1" xref="S6.F3.11.4.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.F3.11.4.4.m4.1c"><cn id="S6.F3.11.4.4.m4.1.1.cmml" type="integer" xref="S6.F3.11.4.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.11.4.4.m4.1d">100</annotation><annotation encoding="application/x-llamapun" id="S6.F3.11.4.4.m4.1e">100</annotation></semantics></math> max epochs. For each <span class="ltx_text ltx_font_italic" id="S6.F3.14.7.7.1">N-Shot</span> experiment, <math alttext="NC" class="ltx_Math" display="inline" id="S6.F3.12.5.5.m5.1"><semantics id="S6.F3.12.5.5.m5.1b"><mrow id="S6.F3.12.5.5.m5.1.1" xref="S6.F3.12.5.5.m5.1.1.cmml"><mi id="S6.F3.12.5.5.m5.1.1.2" xref="S6.F3.12.5.5.m5.1.1.2.cmml">N</mi><mo id="S6.F3.12.5.5.m5.1.1.1" xref="S6.F3.12.5.5.m5.1.1.1.cmml">⁢</mo><mi id="S6.F3.12.5.5.m5.1.1.3" xref="S6.F3.12.5.5.m5.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.F3.12.5.5.m5.1c"><apply id="S6.F3.12.5.5.m5.1.1.cmml" xref="S6.F3.12.5.5.m5.1.1"><times id="S6.F3.12.5.5.m5.1.1.1.cmml" xref="S6.F3.12.5.5.m5.1.1.1"></times><ci id="S6.F3.12.5.5.m5.1.1.2.cmml" xref="S6.F3.12.5.5.m5.1.1.2">𝑁</ci><ci id="S6.F3.12.5.5.m5.1.1.3.cmml" xref="S6.F3.12.5.5.m5.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.12.5.5.m5.1d">NC</annotation><annotation encoding="application/x-llamapun" id="S6.F3.12.5.5.m5.1e">italic_N italic_C</annotation></semantics></math> samples (<math alttext="C=4" class="ltx_Math" display="inline" id="S6.F3.13.6.6.m6.1"><semantics id="S6.F3.13.6.6.m6.1b"><mrow id="S6.F3.13.6.6.m6.1.1" xref="S6.F3.13.6.6.m6.1.1.cmml"><mi id="S6.F3.13.6.6.m6.1.1.2" xref="S6.F3.13.6.6.m6.1.1.2.cmml">C</mi><mo id="S6.F3.13.6.6.m6.1.1.1" xref="S6.F3.13.6.6.m6.1.1.1.cmml">=</mo><mn id="S6.F3.13.6.6.m6.1.1.3" xref="S6.F3.13.6.6.m6.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F3.13.6.6.m6.1c"><apply id="S6.F3.13.6.6.m6.1.1.cmml" xref="S6.F3.13.6.6.m6.1.1"><eq id="S6.F3.13.6.6.m6.1.1.1.cmml" xref="S6.F3.13.6.6.m6.1.1.1"></eq><ci id="S6.F3.13.6.6.m6.1.1.2.cmml" xref="S6.F3.13.6.6.m6.1.1.2">𝐶</ci><cn id="S6.F3.13.6.6.m6.1.1.3.cmml" type="integer" xref="S6.F3.13.6.6.m6.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.13.6.6.m6.1d">C=4</annotation><annotation encoding="application/x-llamapun" id="S6.F3.13.6.6.m6.1e">italic_C = 4</annotation></semantics></math> classes) are randomly selected and trained on for the entire experiment. The scores are averaged across <math alttext="5" class="ltx_Math" display="inline" id="S6.F3.14.7.7.m7.1"><semantics id="S6.F3.14.7.7.m7.1b"><mn id="S6.F3.14.7.7.m7.1.1" xref="S6.F3.14.7.7.m7.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.F3.14.7.7.m7.1c"><cn id="S6.F3.14.7.7.m7.1.1.cmml" type="integer" xref="S6.F3.14.7.7.m7.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F3.14.7.7.m7.1d">5</annotation><annotation encoding="application/x-llamapun" id="S6.F3.14.7.7.m7.1e">5</annotation></semantics></math> trials with random initialization of weights and data sampling. We report the best observed dev score from the full training of each experiment and trial.</span></span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Micro-F1 is reported at each <span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.1">N-Shot</span> in <math alttext="\{8,16,32,64,128\}" class="ltx_Math" display="inline" id="S6.SS1.p1.1.m1.5"><semantics id="S6.SS1.p1.1.m1.5a"><mrow id="S6.SS1.p1.1.m1.5.6.2" xref="S6.SS1.p1.1.m1.5.6.1.cmml"><mo id="S6.SS1.p1.1.m1.5.6.2.1" stretchy="false" xref="S6.SS1.p1.1.m1.5.6.1.cmml">{</mo><mn id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">8</mn><mo id="S6.SS1.p1.1.m1.5.6.2.2" xref="S6.SS1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S6.SS1.p1.1.m1.2.2" xref="S6.SS1.p1.1.m1.2.2.cmml">16</mn><mo id="S6.SS1.p1.1.m1.5.6.2.3" xref="S6.SS1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S6.SS1.p1.1.m1.3.3" xref="S6.SS1.p1.1.m1.3.3.cmml">32</mn><mo id="S6.SS1.p1.1.m1.5.6.2.4" xref="S6.SS1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S6.SS1.p1.1.m1.4.4" xref="S6.SS1.p1.1.m1.4.4.cmml">64</mn><mo id="S6.SS1.p1.1.m1.5.6.2.5" xref="S6.SS1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S6.SS1.p1.1.m1.5.5" xref="S6.SS1.p1.1.m1.5.5.cmml">128</mn><mo id="S6.SS1.p1.1.m1.5.6.2.6" stretchy="false" xref="S6.SS1.p1.1.m1.5.6.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.5b"><set id="S6.SS1.p1.1.m1.5.6.1.cmml" xref="S6.SS1.p1.1.m1.5.6.2"><cn id="S6.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS1.p1.1.m1.1.1">8</cn><cn id="S6.SS1.p1.1.m1.2.2.cmml" type="integer" xref="S6.SS1.p1.1.m1.2.2">16</cn><cn id="S6.SS1.p1.1.m1.3.3.cmml" type="integer" xref="S6.SS1.p1.1.m1.3.3">32</cn><cn id="S6.SS1.p1.1.m1.4.4.cmml" type="integer" xref="S6.SS1.p1.1.m1.4.4">64</cn><cn id="S6.SS1.p1.1.m1.5.5.cmml" type="integer" xref="S6.SS1.p1.1.m1.5.5">128</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.5c">\{8,16,32,64,128\}</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p1.1.m1.5d">{ 8 , 16 , 32 , 64 , 128 }</annotation></semantics></math>.
Each model in Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F3" title="Figure 3 ‣ 6.1. CoNLL: Few-Shot Adaptation ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">3</span></a> adds the specified module on top of a pretrained RoBERTa<sub class="ltx_sub" id="S6.SS1.p1.1.2">LARGE</sub>.
<span class="ltx_text ltx_font_typewriter" id="S6.SS1.p1.1.3">Concat</span> (orange) noticeably outperforms <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p1.1.4">R<sub class="ltx_sub" id="S6.SS1.p1.1.4.1">26</sub></span> at all few-shot settings, while <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p1.1.5">DWAtt</span> (blue) outperforms <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p1.1.6">Concat</span> at the higher data sizes.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.2.   Step and Sample Efficiency</h3>
<figure class="ltx_figure" id="S6.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S6.F4.sf1.g1" src="extracted/2209.15168v2/plots/training_fe_models_n8.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf1.4.2.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F4.sf1.2.1" style="font-size:90%;">Few-shot at <math alttext="N=8" class="ltx_Math" display="inline" id="S6.F4.sf1.2.1.m1.1"><semantics id="S6.F4.sf1.2.1.m1.1b"><mrow id="S6.F4.sf1.2.1.m1.1.1" xref="S6.F4.sf1.2.1.m1.1.1.cmml"><mi id="S6.F4.sf1.2.1.m1.1.1.2" xref="S6.F4.sf1.2.1.m1.1.1.2.cmml">N</mi><mo id="S6.F4.sf1.2.1.m1.1.1.1" xref="S6.F4.sf1.2.1.m1.1.1.1.cmml">=</mo><mn id="S6.F4.sf1.2.1.m1.1.1.3" xref="S6.F4.sf1.2.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F4.sf1.2.1.m1.1c"><apply id="S6.F4.sf1.2.1.m1.1.1.cmml" xref="S6.F4.sf1.2.1.m1.1.1"><eq id="S6.F4.sf1.2.1.m1.1.1.1.cmml" xref="S6.F4.sf1.2.1.m1.1.1.1"></eq><ci id="S6.F4.sf1.2.1.m1.1.1.2.cmml" xref="S6.F4.sf1.2.1.m1.1.1.2">𝑁</ci><cn id="S6.F4.sf1.2.1.m1.1.1.3.cmml" type="integer" xref="S6.F4.sf1.2.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.sf1.2.1.m1.1d">N=8</annotation><annotation encoding="application/x-llamapun" id="S6.F4.sf1.2.1.m1.1e">italic_N = 8</annotation></semantics></math>.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S6.F4.sf2.g1" src="extracted/2209.15168v2/plots/training_fe_models_n128.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf2.4.2.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F4.sf2.2.1" style="font-size:90%;">Few-shot at <math alttext="N=128" class="ltx_Math" display="inline" id="S6.F4.sf2.2.1.m1.1"><semantics id="S6.F4.sf2.2.1.m1.1b"><mrow id="S6.F4.sf2.2.1.m1.1.1" xref="S6.F4.sf2.2.1.m1.1.1.cmml"><mi id="S6.F4.sf2.2.1.m1.1.1.2" xref="S6.F4.sf2.2.1.m1.1.1.2.cmml">N</mi><mo id="S6.F4.sf2.2.1.m1.1.1.1" xref="S6.F4.sf2.2.1.m1.1.1.1.cmml">=</mo><mn id="S6.F4.sf2.2.1.m1.1.1.3" xref="S6.F4.sf2.2.1.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F4.sf2.2.1.m1.1c"><apply id="S6.F4.sf2.2.1.m1.1.1.cmml" xref="S6.F4.sf2.2.1.m1.1.1"><eq id="S6.F4.sf2.2.1.m1.1.1.1.cmml" xref="S6.F4.sf2.2.1.m1.1.1.1"></eq><ci id="S6.F4.sf2.2.1.m1.1.1.2.cmml" xref="S6.F4.sf2.2.1.m1.1.1.2">𝑁</ci><cn id="S6.F4.sf2.2.1.m1.1.1.3.cmml" type="integer" xref="S6.F4.sf2.2.1.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.sf2.2.1.m1.1d">N=128</annotation><annotation encoding="application/x-llamapun" id="S6.F4.sf2.2.1.m1.1e">italic_N = 128</annotation></semantics></math>.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.9.2.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" id="S6.F4.2.1" style="font-size:90%;">Training Behavior.<span class="ltx_text ltx_font_medium" id="S6.F4.2.1.2">
Validation F1-Score across steps in </span>FE<span class="ltx_text ltx_font_medium" id="S6.F4.2.1.1"> training on <span class="ltx_text ltx_font_typewriter" id="S6.F4.2.1.1.1">CoNLL-03</span>. <span class="ltx_text ltx_font_typewriter" id="S6.F4.2.1.1.2">Concat</span> generalizes more readily at smaller <math alttext="N" class="ltx_Math" display="inline" id="S6.F4.2.1.1.m1.1"><semantics id="S6.F4.2.1.1.m1.1b"><mi id="S6.F4.2.1.1.m1.1.1" xref="S6.F4.2.1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S6.F4.2.1.1.m1.1c"><ci id="S6.F4.2.1.1.m1.1.1.cmml" xref="S6.F4.2.1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.2.1.1.m1.1d">N</annotation><annotation encoding="application/x-llamapun" id="S6.F4.2.1.1.m1.1e">italic_N</annotation></semantics></math> compared to <span class="ltx_text ltx_font_typewriter" id="S6.F4.2.1.1.3">DWAtt</span>. At both sizes, layer fusion methods are able to extract more from pretrained models than traditional last-layer fitting.
</span></span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.8">In <span class="ltx_text ltx_font_bold" id="S6.SS2.p1.8.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F3" title="Figure 3 ‣ 6.1. CoNLL: Few-Shot Adaptation ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">3</span></a></span>, <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.2">Concat</span> outperforms noticeably at the lowest end (<math alttext="N{=}8" class="ltx_Math" display="inline" id="S6.SS2.p1.1.m1.1"><semantics id="S6.SS2.p1.1.m1.1a"><mrow id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml"><mi id="S6.SS2.p1.1.m1.1.1.2" xref="S6.SS2.p1.1.m1.1.1.2.cmml">N</mi><mo id="S6.SS2.p1.1.m1.1.1.1" xref="S6.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS2.p1.1.m1.1.1.3" xref="S6.SS2.p1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><apply id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1"><eq id="S6.SS2.p1.1.m1.1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1.1"></eq><ci id="S6.SS2.p1.1.m1.1.1.2.cmml" xref="S6.SS2.p1.1.m1.1.1.2">𝑁</ci><cn id="S6.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S6.SS2.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">N{=}8</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.1.m1.1d">italic_N = 8</annotation></semantics></math> at <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}{=}25" class="ltx_Math" display="inline" id="S6.SS2.p1.2.m2.1"><semantics id="S6.SS2.p1.2.m2.1a"><mrow id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml"><msub id="S6.SS2.p1.2.m2.1.1.2" xref="S6.SS2.p1.2.m2.1.1.2.cmml"><mi id="S6.SS2.p1.2.m2.1.1.2.2" xref="S6.SS2.p1.2.m2.1.1.2.2.cmml">N</mi><mi id="S6.SS2.p1.2.m2.1.1.2.3" xref="S6.SS2.p1.2.m2.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.SS2.p1.2.m2.1.1.1" xref="S6.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS2.p1.2.m2.1.1.3" xref="S6.SS2.p1.2.m2.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><apply id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1"><eq id="S6.SS2.p1.2.m2.1.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1.1"></eq><apply id="S6.SS2.p1.2.m2.1.1.2.cmml" xref="S6.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.p1.2.m2.1.1.2.1.cmml" xref="S6.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S6.SS2.p1.2.m2.1.1.2.2.cmml" xref="S6.SS2.p1.2.m2.1.1.2.2">𝑁</ci><ci id="S6.SS2.p1.2.m2.1.1.2.3.cmml" xref="S6.SS2.p1.2.m2.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S6.SS2.p1.2.m2.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">{N_{\mathsf{\vphantom{fg}epochs}}}{=}25</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.2.m2.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 25</annotation></semantics></math>), improving on <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.3">R<sub class="ltx_sub" id="S6.SS2.p1.8.3.1">26</sub></span> by <math alttext="\mathbf{58\%}" class="ltx_Math" display="inline" id="S6.SS2.p1.3.m3.1"><semantics id="S6.SS2.p1.3.m3.1a"><mrow id="S6.SS2.p1.3.m3.1.1" xref="S6.SS2.p1.3.m3.1.1.cmml"><mn id="S6.SS2.p1.3.m3.1.1.2" xref="S6.SS2.p1.3.m3.1.1.2.cmml">𝟓𝟖</mn><mo id="S6.SS2.p1.3.m3.1.1.1" xref="S6.SS2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.3.m3.1b"><apply id="S6.SS2.p1.3.m3.1.1.cmml" xref="S6.SS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S6.SS2.p1.3.m3.1.1.1.cmml" xref="S6.SS2.p1.3.m3.1.1.1">percent</csymbol><cn id="S6.SS2.p1.3.m3.1.1.2.cmml" type="integer" xref="S6.SS2.p1.3.m3.1.1.2">58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.3.m3.1c">\mathbf{58\%}</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.3.m3.1d">bold_58 %</annotation></semantics></math>—possibly owing to its simpler connectivity and gradient path.
While <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.4">DWAtt</span>’s improvement given increased data and training time may be explained by
its being more selective due to the attention module.
In the largest setup (<math alttext="N{=}128" class="ltx_Math" display="inline" id="S6.SS2.p1.4.m4.1"><semantics id="S6.SS2.p1.4.m4.1a"><mrow id="S6.SS2.p1.4.m4.1.1" xref="S6.SS2.p1.4.m4.1.1.cmml"><mi id="S6.SS2.p1.4.m4.1.1.2" xref="S6.SS2.p1.4.m4.1.1.2.cmml">N</mi><mo id="S6.SS2.p1.4.m4.1.1.1" xref="S6.SS2.p1.4.m4.1.1.1.cmml">=</mo><mn id="S6.SS2.p1.4.m4.1.1.3" xref="S6.SS2.p1.4.m4.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.4.m4.1b"><apply id="S6.SS2.p1.4.m4.1.1.cmml" xref="S6.SS2.p1.4.m4.1.1"><eq id="S6.SS2.p1.4.m4.1.1.1.cmml" xref="S6.SS2.p1.4.m4.1.1.1"></eq><ci id="S6.SS2.p1.4.m4.1.1.2.cmml" xref="S6.SS2.p1.4.m4.1.1.2">𝑁</ci><cn id="S6.SS2.p1.4.m4.1.1.3.cmml" type="integer" xref="S6.SS2.p1.4.m4.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.4.m4.1c">N{=}128</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.4.m4.1d">italic_N = 128</annotation></semantics></math>, <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}{=}100" class="ltx_Math" display="inline" id="S6.SS2.p1.5.m5.1"><semantics id="S6.SS2.p1.5.m5.1a"><mrow id="S6.SS2.p1.5.m5.1.1" xref="S6.SS2.p1.5.m5.1.1.cmml"><msub id="S6.SS2.p1.5.m5.1.1.2" xref="S6.SS2.p1.5.m5.1.1.2.cmml"><mi id="S6.SS2.p1.5.m5.1.1.2.2" xref="S6.SS2.p1.5.m5.1.1.2.2.cmml">N</mi><mi id="S6.SS2.p1.5.m5.1.1.2.3" xref="S6.SS2.p1.5.m5.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.SS2.p1.5.m5.1.1.1" xref="S6.SS2.p1.5.m5.1.1.1.cmml">=</mo><mn id="S6.SS2.p1.5.m5.1.1.3" xref="S6.SS2.p1.5.m5.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.5.m5.1b"><apply id="S6.SS2.p1.5.m5.1.1.cmml" xref="S6.SS2.p1.5.m5.1.1"><eq id="S6.SS2.p1.5.m5.1.1.1.cmml" xref="S6.SS2.p1.5.m5.1.1.1"></eq><apply id="S6.SS2.p1.5.m5.1.1.2.cmml" xref="S6.SS2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.p1.5.m5.1.1.2.1.cmml" xref="S6.SS2.p1.5.m5.1.1.2">subscript</csymbol><ci id="S6.SS2.p1.5.m5.1.1.2.2.cmml" xref="S6.SS2.p1.5.m5.1.1.2.2">𝑁</ci><ci id="S6.SS2.p1.5.m5.1.1.2.3.cmml" xref="S6.SS2.p1.5.m5.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.SS2.p1.5.m5.1.1.3.cmml" type="integer" xref="S6.SS2.p1.5.m5.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.5.m5.1c">{N_{\mathsf{\vphantom{fg}epochs}}}{=}100</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.5.m5.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 100</annotation></semantics></math>; Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S2.F2" title="Figure 2 ‣ Adapting to New Tasks. ‣ 2. Motivation &amp; Hypothesis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">2</span></a>),
<span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.5">Concat</span> improves on <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.6">R<sub class="ltx_sub" id="S6.SS2.p1.8.6.1">26</sub></span> by <math alttext="3.68\%" class="ltx_Math" display="inline" id="S6.SS2.p1.6.m6.1"><semantics id="S6.SS2.p1.6.m6.1a"><mrow id="S6.SS2.p1.6.m6.1.1" xref="S6.SS2.p1.6.m6.1.1.cmml"><mn id="S6.SS2.p1.6.m6.1.1.2" xref="S6.SS2.p1.6.m6.1.1.2.cmml">3.68</mn><mo id="S6.SS2.p1.6.m6.1.1.1" xref="S6.SS2.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.6.m6.1b"><apply id="S6.SS2.p1.6.m6.1.1.cmml" xref="S6.SS2.p1.6.m6.1.1"><csymbol cd="latexml" id="S6.SS2.p1.6.m6.1.1.1.cmml" xref="S6.SS2.p1.6.m6.1.1.1">percent</csymbol><cn id="S6.SS2.p1.6.m6.1.1.2.cmml" type="float" xref="S6.SS2.p1.6.m6.1.1.2">3.68</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.6.m6.1c">3.68\%</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.6.m6.1d">3.68 %</annotation></semantics></math>, while <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.7">DWAtt</span> improves on it by <math alttext="\mathbf{5.28\%}" class="ltx_Math" display="inline" id="S6.SS2.p1.7.m7.1"><semantics id="S6.SS2.p1.7.m7.1a"><mrow id="S6.SS2.p1.7.m7.1.1" xref="S6.SS2.p1.7.m7.1.1.cmml"><mn class="ltx_mathvariant_bold" id="S6.SS2.p1.7.m7.1.1.2" mathvariant="bold" xref="S6.SS2.p1.7.m7.1.1.2.cmml">5.28</mn><mo id="S6.SS2.p1.7.m7.1.1.1" xref="S6.SS2.p1.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.7.m7.1b"><apply id="S6.SS2.p1.7.m7.1.1.cmml" xref="S6.SS2.p1.7.m7.1.1"><csymbol cd="latexml" id="S6.SS2.p1.7.m7.1.1.1.cmml" xref="S6.SS2.p1.7.m7.1.1.1">percent</csymbol><cn id="S6.SS2.p1.7.m7.1.1.2.cmml" type="float" xref="S6.SS2.p1.7.m7.1.1.2">5.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.7.m7.1c">\mathbf{5.28\%}</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.7.m7.1d">bold_5.28 %</annotation></semantics></math>.
<span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.8.8">R<sub class="ltx_sub" id="S6.SS2.p1.8.8.1">26</sub></span> demonstrates the difficulties of extracting the patterns needed by a downstream task from a feature extractor that has already
fit its last layer representation (<math alttext="L{=}24" class="ltx_Math" display="inline" id="S6.SS2.p1.8.m8.1"><semantics id="S6.SS2.p1.8.m8.1a"><mrow id="S6.SS2.p1.8.m8.1.1" xref="S6.SS2.p1.8.m8.1.1.cmml"><mi id="S6.SS2.p1.8.m8.1.1.2" xref="S6.SS2.p1.8.m8.1.1.2.cmml">L</mi><mo id="S6.SS2.p1.8.m8.1.1.1" xref="S6.SS2.p1.8.m8.1.1.1.cmml">=</mo><mn id="S6.SS2.p1.8.m8.1.1.3" xref="S6.SS2.p1.8.m8.1.1.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.8.m8.1b"><apply id="S6.SS2.p1.8.m8.1.1.cmml" xref="S6.SS2.p1.8.m8.1.1"><eq id="S6.SS2.p1.8.m8.1.1.1.cmml" xref="S6.SS2.p1.8.m8.1.1.1"></eq><ci id="S6.SS2.p1.8.m8.1.1.2.cmml" xref="S6.SS2.p1.8.m8.1.1.2">𝐿</ci><cn id="S6.SS2.p1.8.m8.1.1.3.cmml" type="integer" xref="S6.SS2.p1.8.m8.1.1.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.8.m8.1c">L{=}24</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.8.m8.1d">italic_L = 24</annotation></semantics></math> for RoBERTa<sub class="ltx_sub" id="S6.SS2.p1.8.9">LARGE</sub>) for its pretraining task.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.4">In <span class="ltx_text ltx_font_bold" id="S6.SS2.p2.4.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F4" title="Figure 4 ‣ 6.2. Step and Sample Efficiency ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">4</span></a></span>, we focus on model validation behavior during training with <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}{=}50" class="ltx_Math" display="inline" id="S6.SS2.p2.1.m1.1"><semantics id="S6.SS2.p2.1.m1.1a"><mrow id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml"><msub id="S6.SS2.p2.1.m1.1.1.2" xref="S6.SS2.p2.1.m1.1.1.2.cmml"><mi id="S6.SS2.p2.1.m1.1.1.2.2" xref="S6.SS2.p2.1.m1.1.1.2.2.cmml">N</mi><mi id="S6.SS2.p2.1.m1.1.1.2.3" xref="S6.SS2.p2.1.m1.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.SS2.p2.1.m1.1.1.1" xref="S6.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS2.p2.1.m1.1.1.3" xref="S6.SS2.p2.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><apply id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1"><eq id="S6.SS2.p2.1.m1.1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1.1"></eq><apply id="S6.SS2.p2.1.m1.1.1.2.cmml" xref="S6.SS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.p2.1.m1.1.1.2.1.cmml" xref="S6.SS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="S6.SS2.p2.1.m1.1.1.2.2.cmml" xref="S6.SS2.p2.1.m1.1.1.2.2">𝑁</ci><ci id="S6.SS2.p2.1.m1.1.1.2.3.cmml" xref="S6.SS2.p2.1.m1.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="S6.SS2.p2.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">{N_{\mathsf{\vphantom{fg}epochs}}}{=}50</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p2.1.m1.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 50</annotation></semantics></math>. At <math alttext="N{=}8" class="ltx_Math" display="inline" id="S6.SS2.p2.2.m2.1"><semantics id="S6.SS2.p2.2.m2.1a"><mrow id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml"><mi id="S6.SS2.p2.2.m2.1.1.2" xref="S6.SS2.p2.2.m2.1.1.2.cmml">N</mi><mo id="S6.SS2.p2.2.m2.1.1.1" xref="S6.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS2.p2.2.m2.1.1.3" xref="S6.SS2.p2.2.m2.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><apply id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1"><eq id="S6.SS2.p2.2.m2.1.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1.1"></eq><ci id="S6.SS2.p2.2.m2.1.1.2.cmml" xref="S6.SS2.p2.2.m2.1.1.2">𝑁</ci><cn id="S6.SS2.p2.2.m2.1.1.3.cmml" type="integer" xref="S6.SS2.p2.2.m2.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">N{=}8</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p2.2.m2.1d">italic_N = 8</annotation></semantics></math>, only <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p2.4.2">Concat</span> manages to adapt well, and rapidly, converging in <math alttext="30\%" class="ltx_Math" display="inline" id="S6.SS2.p2.3.m3.1"><semantics id="S6.SS2.p2.3.m3.1a"><mrow id="S6.SS2.p2.3.m3.1.1" xref="S6.SS2.p2.3.m3.1.1.cmml"><mn id="S6.SS2.p2.3.m3.1.1.2" xref="S6.SS2.p2.3.m3.1.1.2.cmml">30</mn><mo id="S6.SS2.p2.3.m3.1.1.1" xref="S6.SS2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.3.m3.1b"><apply id="S6.SS2.p2.3.m3.1.1.cmml" xref="S6.SS2.p2.3.m3.1.1"><csymbol cd="latexml" id="S6.SS2.p2.3.m3.1.1.1.cmml" xref="S6.SS2.p2.3.m3.1.1.1">percent</csymbol><cn id="S6.SS2.p2.3.m3.1.1.2.cmml" type="integer" xref="S6.SS2.p2.3.m3.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.3.m3.1c">30\%</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p2.3.m3.1d">30 %</annotation></semantics></math> of training time. At <math alttext="N{=}128" class="ltx_Math" display="inline" id="S6.SS2.p2.4.m4.1"><semantics id="S6.SS2.p2.4.m4.1a"><mrow id="S6.SS2.p2.4.m4.1.1" xref="S6.SS2.p2.4.m4.1.1.cmml"><mi id="S6.SS2.p2.4.m4.1.1.2" xref="S6.SS2.p2.4.m4.1.1.2.cmml">N</mi><mo id="S6.SS2.p2.4.m4.1.1.1" xref="S6.SS2.p2.4.m4.1.1.1.cmml">=</mo><mn id="S6.SS2.p2.4.m4.1.1.3" xref="S6.SS2.p2.4.m4.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.4.m4.1b"><apply id="S6.SS2.p2.4.m4.1.1.cmml" xref="S6.SS2.p2.4.m4.1.1"><eq id="S6.SS2.p2.4.m4.1.1.1.cmml" xref="S6.SS2.p2.4.m4.1.1.1"></eq><ci id="S6.SS2.p2.4.m4.1.1.2.cmml" xref="S6.SS2.p2.4.m4.1.1.2">𝑁</ci><cn id="S6.SS2.p2.4.m4.1.1.3.cmml" type="integer" xref="S6.SS2.p2.4.m4.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.4.m4.1c">N{=}128</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p2.4.m4.1d">italic_N = 128</annotation></semantics></math>, <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p2.4.3">DWAtt</span> has enough data to reach similar performance at a similar pace, and quickly pulls ahead.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.4">We repeat in <span class="ltx_text ltx_font_bold" id="S6.SS2.p3.4.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F5" title="Figure 5 ‣ 6.2. Step and Sample Efficiency ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">5</span></a></span> the experiments from Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F3" title="Figure 3 ‣ 6.1. CoNLL: Few-Shot Adaptation ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">3</span></a> but on English only from <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.4.2">WikiAnn</span>, on <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.4.3">R<sub class="ltx_sub" id="S6.SS2.p3.4.3.1">26</sub></span>. Yet again <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.4.4">Concat</span> performs better with less data, while <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.4.5">DWAtt</span> is better at the higher end (<math alttext="N{=}128" class="ltx_Math" display="inline" id="S6.SS2.p3.1.m1.1"><semantics id="S6.SS2.p3.1.m1.1a"><mrow id="S6.SS2.p3.1.m1.1.1" xref="S6.SS2.p3.1.m1.1.1.cmml"><mi id="S6.SS2.p3.1.m1.1.1.2" xref="S6.SS2.p3.1.m1.1.1.2.cmml">N</mi><mo id="S6.SS2.p3.1.m1.1.1.1" xref="S6.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS2.p3.1.m1.1.1.3" xref="S6.SS2.p3.1.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.1.m1.1b"><apply id="S6.SS2.p3.1.m1.1.1.cmml" xref="S6.SS2.p3.1.m1.1.1"><eq id="S6.SS2.p3.1.m1.1.1.1.cmml" xref="S6.SS2.p3.1.m1.1.1.1"></eq><ci id="S6.SS2.p3.1.m1.1.1.2.cmml" xref="S6.SS2.p3.1.m1.1.1.2">𝑁</ci><cn id="S6.SS2.p3.1.m1.1.1.3.cmml" type="integer" xref="S6.SS2.p3.1.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.1.m1.1c">N{=}128</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p3.1.m1.1d">italic_N = 128</annotation></semantics></math>, <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}{=}100" class="ltx_Math" display="inline" id="S6.SS2.p3.2.m2.1"><semantics id="S6.SS2.p3.2.m2.1a"><mrow id="S6.SS2.p3.2.m2.1.1" xref="S6.SS2.p3.2.m2.1.1.cmml"><msub id="S6.SS2.p3.2.m2.1.1.2" xref="S6.SS2.p3.2.m2.1.1.2.cmml"><mi id="S6.SS2.p3.2.m2.1.1.2.2" xref="S6.SS2.p3.2.m2.1.1.2.2.cmml">N</mi><mi id="S6.SS2.p3.2.m2.1.1.2.3" xref="S6.SS2.p3.2.m2.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.SS2.p3.2.m2.1.1.1" xref="S6.SS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS2.p3.2.m2.1.1.3" xref="S6.SS2.p3.2.m2.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.2.m2.1b"><apply id="S6.SS2.p3.2.m2.1.1.cmml" xref="S6.SS2.p3.2.m2.1.1"><eq id="S6.SS2.p3.2.m2.1.1.1.cmml" xref="S6.SS2.p3.2.m2.1.1.1"></eq><apply id="S6.SS2.p3.2.m2.1.1.2.cmml" xref="S6.SS2.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S6.SS2.p3.2.m2.1.1.2.1.cmml" xref="S6.SS2.p3.2.m2.1.1.2">subscript</csymbol><ci id="S6.SS2.p3.2.m2.1.1.2.2.cmml" xref="S6.SS2.p3.2.m2.1.1.2.2">𝑁</ci><ci id="S6.SS2.p3.2.m2.1.1.2.3.cmml" xref="S6.SS2.p3.2.m2.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.SS2.p3.2.m2.1.1.3.cmml" type="integer" xref="S6.SS2.p3.2.m2.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.2.m2.1c">{N_{\mathsf{\vphantom{fg}epochs}}}{=}100</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p3.2.m2.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 100</annotation></semantics></math>) by <math alttext="+2.08\%" class="ltx_Math" display="inline" id="S6.SS2.p3.3.m3.1"><semantics id="S6.SS2.p3.3.m3.1a"><mrow id="S6.SS2.p3.3.m3.1.1" xref="S6.SS2.p3.3.m3.1.1.cmml"><mo id="S6.SS2.p3.3.m3.1.1a" xref="S6.SS2.p3.3.m3.1.1.cmml">+</mo><mrow id="S6.SS2.p3.3.m3.1.1.2" xref="S6.SS2.p3.3.m3.1.1.2.cmml"><mn id="S6.SS2.p3.3.m3.1.1.2.2" xref="S6.SS2.p3.3.m3.1.1.2.2.cmml">2.08</mn><mo id="S6.SS2.p3.3.m3.1.1.2.1" xref="S6.SS2.p3.3.m3.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.3.m3.1b"><apply id="S6.SS2.p3.3.m3.1.1.cmml" xref="S6.SS2.p3.3.m3.1.1"><plus id="S6.SS2.p3.3.m3.1.1.1.cmml" xref="S6.SS2.p3.3.m3.1.1"></plus><apply id="S6.SS2.p3.3.m3.1.1.2.cmml" xref="S6.SS2.p3.3.m3.1.1.2"><csymbol cd="latexml" id="S6.SS2.p3.3.m3.1.1.2.1.cmml" xref="S6.SS2.p3.3.m3.1.1.2.1">percent</csymbol><cn id="S6.SS2.p3.3.m3.1.1.2.2.cmml" type="float" xref="S6.SS2.p3.3.m3.1.1.2.2">2.08</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.3.m3.1c">+2.08\%</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p3.3.m3.1d">+ 2.08 %</annotation></semantics></math> and <math alttext="+0.92\%" class="ltx_Math" display="inline" id="S6.SS2.p3.4.m4.1"><semantics id="S6.SS2.p3.4.m4.1a"><mrow id="S6.SS2.p3.4.m4.1.1" xref="S6.SS2.p3.4.m4.1.1.cmml"><mo id="S6.SS2.p3.4.m4.1.1a" xref="S6.SS2.p3.4.m4.1.1.cmml">+</mo><mrow id="S6.SS2.p3.4.m4.1.1.2" xref="S6.SS2.p3.4.m4.1.1.2.cmml"><mn id="S6.SS2.p3.4.m4.1.1.2.2" xref="S6.SS2.p3.4.m4.1.1.2.2.cmml">0.92</mn><mo id="S6.SS2.p3.4.m4.1.1.2.1" xref="S6.SS2.p3.4.m4.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.4.m4.1b"><apply id="S6.SS2.p3.4.m4.1.1.cmml" xref="S6.SS2.p3.4.m4.1.1"><plus id="S6.SS2.p3.4.m4.1.1.1.cmml" xref="S6.SS2.p3.4.m4.1.1"></plus><apply id="S6.SS2.p3.4.m4.1.1.2.cmml" xref="S6.SS2.p3.4.m4.1.1.2"><csymbol cd="latexml" id="S6.SS2.p3.4.m4.1.1.2.1.cmml" xref="S6.SS2.p3.4.m4.1.1.2.1">percent</csymbol><cn id="S6.SS2.p3.4.m4.1.1.2.2.cmml" type="float" xref="S6.SS2.p3.4.m4.1.1.2.2">0.92</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.4.m4.1c">+0.92\%</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p3.4.m4.1d">+ 0.92 %</annotation></semantics></math> over <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.4.6">Concat</span> and <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.4.7">R<sub class="ltx_sub" id="S6.SS2.p3.4.7.1">26</sub></span>, respectively.</p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F5.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.8.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S6.F5.9.2" style="font-size:90%;">F1-Score on the <span class="ltx_text ltx_font_typewriter" id="S6.F5.9.2.1">WikiAnn</span> <em class="ltx_emph ltx_font_italic" id="S6.F5.9.2.2">English</em> devset on the <em class="ltx_emph ltx_font_italic" id="S6.F5.9.2.3">RoBERTa<sub class="ltx_sub" id="S6.F5.9.2.3.1">LARGE</sub></em> base model. The methods start behaving similarly at higher training epochs. <span class="ltx_text ltx_font_typewriter" id="S6.F5.9.2.4">DWAtt</span> leads <span class="ltx_text ltx_font_typewriter" id="S6.F5.9.2.5">Concat</span> leads <span class="ltx_text ltx_font_typewriter" id="S6.F5.9.2.6">R<sub class="ltx_sub" id="S6.F5.9.2.6.1">26</sub></span> at medium shot scenarios.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.3.   Feature Extractor Adaptability</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.3"><span class="ltx_text ltx_font_bold" id="S6.SS3.p1.3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F6" title="Figure 6 ‣ 6.3. Feature Extractor Adaptability ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">6</span></a></span> shows the effect of finetuning (<span class="ltx_text ltx_font_bold" id="S6.SS3.p1.3.2">FT</span>) all model parameters for each of the same configurations used in other <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.3.3">CoNLL-03</span> experiments.
At <math alttext="N=8" class="ltx_Math" display="inline" id="S6.SS3.p1.1.m1.1"><semantics id="S6.SS3.p1.1.m1.1a"><mrow id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml"><mi id="S6.SS3.p1.1.m1.1.1.2" xref="S6.SS3.p1.1.m1.1.1.2.cmml">N</mi><mo id="S6.SS3.p1.1.m1.1.1.1" xref="S6.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.1.m1.1.1.3" xref="S6.SS3.p1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><apply id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1"><eq id="S6.SS3.p1.1.m1.1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1.1"></eq><ci id="S6.SS3.p1.1.m1.1.1.2.cmml" xref="S6.SS3.p1.1.m1.1.1.2">𝑁</ci><cn id="S6.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S6.SS3.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">N=8</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.1.m1.1d">italic_N = 8</annotation></semantics></math>, <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.3.4">Concat</span> in feature extraction (<span class="ltx_text ltx_font_bold" id="S6.SS3.p1.3.5">FE</span>) training already gets most of the improvement observable from full <span class="ltx_text" id="S6.SS3.p1.3.6">FT</span> across the board.
At <math alttext="N=128" class="ltx_Math" display="inline" id="S6.SS3.p1.2.m2.1"><semantics id="S6.SS3.p1.2.m2.1a"><mrow id="S6.SS3.p1.2.m2.1.1" xref="S6.SS3.p1.2.m2.1.1.cmml"><mi id="S6.SS3.p1.2.m2.1.1.2" xref="S6.SS3.p1.2.m2.1.1.2.cmml">N</mi><mo id="S6.SS3.p1.2.m2.1.1.1" xref="S6.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS3.p1.2.m2.1.1.3" xref="S6.SS3.p1.2.m2.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.2.m2.1b"><apply id="S6.SS3.p1.2.m2.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1"><eq id="S6.SS3.p1.2.m2.1.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1.1"></eq><ci id="S6.SS3.p1.2.m2.1.1.2.cmml" xref="S6.SS3.p1.2.m2.1.1.2">𝑁</ci><cn id="S6.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S6.SS3.p1.2.m2.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.2.m2.1c">N=128</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.2.m2.1d">italic_N = 128</annotation></semantics></math> the effect is stronger. While layer fusion methods help close the gap—with <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.3.7">DWAtt</span> giving nearly half the improvement of <span class="ltx_text" id="S6.SS3.p1.3.8">FT</span> using only <span class="ltx_text" id="S6.SS3.p1.3.9">FE</span>, at <math alttext="+5.28\%" class="ltx_Math" display="inline" id="S6.SS3.p1.3.m3.1"><semantics id="S6.SS3.p1.3.m3.1a"><mrow id="S6.SS3.p1.3.m3.1.1" xref="S6.SS3.p1.3.m3.1.1.cmml"><mo id="S6.SS3.p1.3.m3.1.1a" xref="S6.SS3.p1.3.m3.1.1.cmml">+</mo><mrow id="S6.SS3.p1.3.m3.1.1.2" xref="S6.SS3.p1.3.m3.1.1.2.cmml"><mn id="S6.SS3.p1.3.m3.1.1.2.2" xref="S6.SS3.p1.3.m3.1.1.2.2.cmml">5.28</mn><mo id="S6.SS3.p1.3.m3.1.1.2.1" xref="S6.SS3.p1.3.m3.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.3.m3.1b"><apply id="S6.SS3.p1.3.m3.1.1.cmml" xref="S6.SS3.p1.3.m3.1.1"><plus id="S6.SS3.p1.3.m3.1.1.1.cmml" xref="S6.SS3.p1.3.m3.1.1"></plus><apply id="S6.SS3.p1.3.m3.1.1.2.cmml" xref="S6.SS3.p1.3.m3.1.1.2"><csymbol cd="latexml" id="S6.SS3.p1.3.m3.1.1.2.1.cmml" xref="S6.SS3.p1.3.m3.1.1.2.1">percent</csymbol><cn id="S6.SS3.p1.3.m3.1.1.2.2.cmml" type="float" xref="S6.SS3.p1.3.m3.1.1.2.2">5.28</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.3.m3.1c">+5.28\%</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p1.3.m3.1d">+ 5.28 %</annotation></semantics></math>—<span class="ltx_text" id="S6.SS3.p1.3.10">FT</span> still manages overshadow all <span class="ltx_text" id="S6.SS3.p1.3.11">FE</span> configurations even with only <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.3.12">R<sub class="ltx_sub" id="S6.SS3.p1.3.12.1">26</sub></span>.</p>
</div>
<figure class="ltx_figure" id="S6.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F6.sf1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.sf1.4.1.1" style="font-size:90%;">(a)</span> </span><math alttext="N=8" class="ltx_Math" display="inline" id="S6.F6.sf1.2.m1.1"><semantics id="S6.F6.sf1.2.m1.1b"><mrow id="S6.F6.sf1.2.m1.1.1" xref="S6.F6.sf1.2.m1.1.1.cmml"><mi id="S6.F6.sf1.2.m1.1.1.2" mathsize="90%" xref="S6.F6.sf1.2.m1.1.1.2.cmml">N</mi><mo id="S6.F6.sf1.2.m1.1.1.1" mathsize="90%" xref="S6.F6.sf1.2.m1.1.1.1.cmml">=</mo><mn id="S6.F6.sf1.2.m1.1.1.3" mathsize="90%" xref="S6.F6.sf1.2.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F6.sf1.2.m1.1c"><apply id="S6.F6.sf1.2.m1.1.1.cmml" xref="S6.F6.sf1.2.m1.1.1"><eq id="S6.F6.sf1.2.m1.1.1.1.cmml" xref="S6.F6.sf1.2.m1.1.1.1"></eq><ci id="S6.F6.sf1.2.m1.1.1.2.cmml" xref="S6.F6.sf1.2.m1.1.1.2">𝑁</ci><cn id="S6.F6.sf1.2.m1.1.1.3.cmml" type="integer" xref="S6.F6.sf1.2.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F6.sf1.2.m1.1d">N=8</annotation><annotation encoding="application/x-llamapun" id="S6.F6.sf1.2.m1.1e">italic_N = 8</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F6.sf2.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.sf2.4.1.1" style="font-size:90%;">(b)</span> </span><math alttext="N=128" class="ltx_Math" display="inline" id="S6.F6.sf2.2.m1.1"><semantics id="S6.F6.sf2.2.m1.1b"><mrow id="S6.F6.sf2.2.m1.1.1" xref="S6.F6.sf2.2.m1.1.1.cmml"><mi id="S6.F6.sf2.2.m1.1.1.2" mathsize="90%" xref="S6.F6.sf2.2.m1.1.1.2.cmml">N</mi><mo id="S6.F6.sf2.2.m1.1.1.1" mathsize="90%" xref="S6.F6.sf2.2.m1.1.1.1.cmml">=</mo><mn id="S6.F6.sf2.2.m1.1.1.3" mathsize="90%" xref="S6.F6.sf2.2.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F6.sf2.2.m1.1c"><apply id="S6.F6.sf2.2.m1.1.1.cmml" xref="S6.F6.sf2.2.m1.1.1"><eq id="S6.F6.sf2.2.m1.1.1.1.cmml" xref="S6.F6.sf2.2.m1.1.1.1"></eq><ci id="S6.F6.sf2.2.m1.1.1.2.cmml" xref="S6.F6.sf2.2.m1.1.1.2">𝑁</ci><cn id="S6.F6.sf2.2.m1.1.1.3.cmml" type="integer" xref="S6.F6.sf2.2.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F6.sf2.2.m1.1d">N=128</annotation><annotation encoding="application/x-llamapun" id="S6.F6.sf2.2.m1.1e">italic_N = 128</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.9.2.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text ltx_font_bold" id="S6.F6.2.1" style="font-size:90%;">Feature Extraction (<em class="ltx_emph ltx_font_italic" id="S6.F6.2.1.2">FE</em>) versus Finetuning (<em class="ltx_emph ltx_font_italic" id="S6.F6.2.1.3">FT</em>).<span class="ltx_text ltx_font_medium" id="S6.F6.2.1.1">
Best validation F1-Score on <span class="ltx_text ltx_font_typewriter" id="S6.F6.2.1.1.1">CoNLL-03</span> within <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}=50" class="ltx_Math" display="inline" id="S6.F6.2.1.1.m1.1"><semantics id="S6.F6.2.1.1.m1.1b"><mrow id="S6.F6.2.1.1.m1.1.1" xref="S6.F6.2.1.1.m1.1.1.cmml"><msub id="S6.F6.2.1.1.m1.1.1.2" xref="S6.F6.2.1.1.m1.1.1.2.cmml"><mi id="S6.F6.2.1.1.m1.1.1.2.2" xref="S6.F6.2.1.1.m1.1.1.2.2.cmml">N</mi><mi id="S6.F6.2.1.1.m1.1.1.2.3" xref="S6.F6.2.1.1.m1.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.F6.2.1.1.m1.1.1.1" xref="S6.F6.2.1.1.m1.1.1.1.cmml">=</mo><mn id="S6.F6.2.1.1.m1.1.1.3" xref="S6.F6.2.1.1.m1.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F6.2.1.1.m1.1c"><apply id="S6.F6.2.1.1.m1.1.1.cmml" xref="S6.F6.2.1.1.m1.1.1"><eq id="S6.F6.2.1.1.m1.1.1.1.cmml" xref="S6.F6.2.1.1.m1.1.1.1"></eq><apply id="S6.F6.2.1.1.m1.1.1.2.cmml" xref="S6.F6.2.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S6.F6.2.1.1.m1.1.1.2.1.cmml" xref="S6.F6.2.1.1.m1.1.1.2">subscript</csymbol><ci id="S6.F6.2.1.1.m1.1.1.2.2.cmml" xref="S6.F6.2.1.1.m1.1.1.2.2">𝑁</ci><ci id="S6.F6.2.1.1.m1.1.1.2.3.cmml" xref="S6.F6.2.1.1.m1.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.F6.2.1.1.m1.1.1.3.cmml" type="integer" xref="S6.F6.2.1.1.m1.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F6.2.1.1.m1.1d">{N_{\mathsf{\vphantom{fg}epochs}}}=50</annotation><annotation encoding="application/x-llamapun" id="S6.F6.2.1.1.m1.1e">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 50</annotation></semantics></math> training epochs. Finetuning consistently outperforms alternatives, but <span class="ltx_text ltx_font_typewriter" id="S6.F6.2.1.1.2">Concat</span> and <span class="ltx_text ltx_font_typewriter" id="S6.F6.2.1.1.3">DWAtt</span> approach its performance even in </span>FE<span class="ltx_text ltx_font_medium" id="S6.F6.2.1.4"> training at lower data sizes.
</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.4.   Scaling by Depth</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.2">In <span class="ltx_text ltx_font_bold" id="S6.SS4.p1.2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F7" title="Figure 7 ‣ 6.4. Scaling by Depth ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">7</span></a></span>, we compare the same add-on configurations on the <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.2.2">base</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.2.3">large</span> variants of RoBERTa. At <math alttext="N=8" class="ltx_Math" display="inline" id="S6.SS4.p1.1.m1.1"><semantics id="S6.SS4.p1.1.m1.1a"><mrow id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml"><mi id="S6.SS4.p1.1.m1.1.1.2" xref="S6.SS4.p1.1.m1.1.1.2.cmml">N</mi><mo id="S6.SS4.p1.1.m1.1.1.1" xref="S6.SS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS4.p1.1.m1.1.1.3" xref="S6.SS4.p1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><apply id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1"><eq id="S6.SS4.p1.1.m1.1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1.1"></eq><ci id="S6.SS4.p1.1.m1.1.1.2.cmml" xref="S6.SS4.p1.1.m1.1.1.2">𝑁</ci><cn id="S6.SS4.p1.1.m1.1.1.3.cmml" type="integer" xref="S6.SS4.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">N=8</annotation><annotation encoding="application/x-llamapun" id="S6.SS4.p1.1.m1.1d">italic_N = 8</annotation></semantics></math>, <span class="ltx_text ltx_font_typewriter" id="S6.SS4.p1.2.4">Concat</span> is an outlier in its performance gain over the alternatives. In all <math alttext="N\in\{8,128\}" class="ltx_Math" display="inline" id="S6.SS4.p1.2.m2.2"><semantics id="S6.SS4.p1.2.m2.2a"><mrow id="S6.SS4.p1.2.m2.2.3" xref="S6.SS4.p1.2.m2.2.3.cmml"><mi id="S6.SS4.p1.2.m2.2.3.2" xref="S6.SS4.p1.2.m2.2.3.2.cmml">N</mi><mo id="S6.SS4.p1.2.m2.2.3.1" xref="S6.SS4.p1.2.m2.2.3.1.cmml">∈</mo><mrow id="S6.SS4.p1.2.m2.2.3.3.2" xref="S6.SS4.p1.2.m2.2.3.3.1.cmml"><mo id="S6.SS4.p1.2.m2.2.3.3.2.1" stretchy="false" xref="S6.SS4.p1.2.m2.2.3.3.1.cmml">{</mo><mn id="S6.SS4.p1.2.m2.1.1" xref="S6.SS4.p1.2.m2.1.1.cmml">8</mn><mo id="S6.SS4.p1.2.m2.2.3.3.2.2" xref="S6.SS4.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S6.SS4.p1.2.m2.2.2" xref="S6.SS4.p1.2.m2.2.2.cmml">128</mn><mo id="S6.SS4.p1.2.m2.2.3.3.2.3" stretchy="false" xref="S6.SS4.p1.2.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.2.m2.2b"><apply id="S6.SS4.p1.2.m2.2.3.cmml" xref="S6.SS4.p1.2.m2.2.3"><in id="S6.SS4.p1.2.m2.2.3.1.cmml" xref="S6.SS4.p1.2.m2.2.3.1"></in><ci id="S6.SS4.p1.2.m2.2.3.2.cmml" xref="S6.SS4.p1.2.m2.2.3.2">𝑁</ci><set id="S6.SS4.p1.2.m2.2.3.3.1.cmml" xref="S6.SS4.p1.2.m2.2.3.3.2"><cn id="S6.SS4.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS4.p1.2.m2.1.1">8</cn><cn id="S6.SS4.p1.2.m2.2.2.cmml" type="integer" xref="S6.SS4.p1.2.m2.2.2">128</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.2.m2.2c">N\in\{8,128\}</annotation><annotation encoding="application/x-llamapun" id="S6.SS4.p1.2.m2.2d">italic_N ∈ { 8 , 128 }</annotation></semantics></math>, both <span class="ltx_text ltx_font_typewriter" id="S6.SS4.p1.2.5">Concat</span> and <span class="ltx_text ltx_font_typewriter" id="S6.SS4.p1.2.6">DWAtt</span> match or beat the performance gain observed from <span class="ltx_text ltx_font_typewriter" id="S6.SS4.p1.2.7">RoBERTa<span class="ltx_text" id="S6.SS4.p1.2.7.1">+</span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote2.1.1.1">2</span></span><span class="ltx_text" id="footnote2.9">RoBERTa<span class="ltx_text" id="footnote2.9.1">+</span></span><span class="ltx_text ltx_font_serif" id="footnote2.10"> </span><span class="ltx_text ltx_font_serif ltx_font_smallcaps" id="footnote2.11">base</span><span class="ltx_text ltx_font_serif" id="footnote2.12"> is </span><math alttext="L{=}12+1" class="ltx_Math" display="inline" id="footnotex2.m1a.1"><semantics id="footnotex2.m1a.1b"><mrow id="footnotex2.m1a.1.1" xref="footnotex2.m1a.1.1.cmml"><mi id="footnotex2.m1a.1.1.2" xref="footnotex2.m1a.1.1.2.cmml">L</mi><mo id="footnotex2.m1a.1.1.1" xref="footnotex2.m1a.1.1.1.cmml">=</mo><mrow id="footnotex2.m1a.1.1.3" xref="footnotex2.m1a.1.1.3.cmml"><mn id="footnotex2.m1a.1.1.3.2" xref="footnotex2.m1a.1.1.3.2.cmml">12</mn><mo id="footnotex2.m1a.1.1.3.1" xref="footnotex2.m1a.1.1.3.1.cmml">+</mo><mn id="footnotex2.m1a.1.1.3.3" xref="footnotex2.m1a.1.1.3.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnotex2.m1a.1c"><apply id="footnotex2.m1a.1.1.cmml" xref="footnotex2.m1a.1.1"><eq id="footnotex2.m1a.1.1.1.cmml" xref="footnotex2.m1a.1.1.1"></eq><ci id="footnotex2.m1a.1.1.2.cmml" xref="footnotex2.m1a.1.1.2">𝐿</ci><apply id="footnotex2.m1a.1.1.3.cmml" xref="footnotex2.m1a.1.1.3"><plus id="footnotex2.m1a.1.1.3.1.cmml" xref="footnotex2.m1a.1.1.3.1"></plus><cn id="footnotex2.m1a.1.1.3.2.cmml" type="integer" xref="footnotex2.m1a.1.1.3.2">12</cn><cn id="footnotex2.m1a.1.1.3.3.cmml" type="integer" xref="footnotex2.m1a.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnotex2.m1a.1d">L{=}12+1</annotation><annotation encoding="application/x-llamapun" id="footnotex2.m1a.1e">italic_L = 12 + 1</annotation></semantics></math><span class="ltx_text ltx_font_serif" id="footnote2.13"> layers, while </span><span class="ltx_text ltx_font_serif ltx_font_smallcaps" id="footnote2.14">large</span><span class="ltx_text ltx_font_serif" id="footnote2.15"> is </span><math alttext="L{=}24" class="ltx_Math" display="inline" id="footnotex2.m2a.1"><semantics id="footnotex2.m2a.1b"><mrow id="footnotex2.m2a.1.1" xref="footnotex2.m2a.1.1.cmml"><mi id="footnotex2.m2a.1.1.2" xref="footnotex2.m2a.1.1.2.cmml">L</mi><mo id="footnotex2.m2a.1.1.1" xref="footnotex2.m2a.1.1.1.cmml">=</mo><mn id="footnotex2.m2a.1.1.3" xref="footnotex2.m2a.1.1.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="footnotex2.m2a.1c"><apply id="footnotex2.m2a.1.1.cmml" xref="footnotex2.m2a.1.1"><eq id="footnotex2.m2a.1.1.1.cmml" xref="footnotex2.m2a.1.1.1"></eq><ci id="footnotex2.m2a.1.1.2.cmml" xref="footnotex2.m2a.1.1.2">𝐿</ci><cn id="footnotex2.m2a.1.1.3.cmml" type="integer" xref="footnotex2.m2a.1.1.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnotex2.m2a.1d">L{=}24</annotation><annotation encoding="application/x-llamapun" id="footnotex2.m2a.1e">italic_L = 24</annotation></semantics></math><span class="ltx_text ltx_font_serif" id="footnote2.16">+2.</span></span></span></span></span> when changing from <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.2.8">base</span> to <span class="ltx_text ltx_font_smallcaps" id="S6.SS4.p1.2.9">large</span>.
</p>
</div>
<figure class="ltx_figure" id="S6.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F7.sf1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf1.4.1.1" style="font-size:90%;">(a)</span> </span><math alttext="N=8" class="ltx_Math" display="inline" id="S6.F7.sf1.2.m1.1"><semantics id="S6.F7.sf1.2.m1.1b"><mrow id="S6.F7.sf1.2.m1.1.1" xref="S6.F7.sf1.2.m1.1.1.cmml"><mi id="S6.F7.sf1.2.m1.1.1.2" mathsize="90%" xref="S6.F7.sf1.2.m1.1.1.2.cmml">N</mi><mo id="S6.F7.sf1.2.m1.1.1.1" mathsize="90%" xref="S6.F7.sf1.2.m1.1.1.1.cmml">=</mo><mn id="S6.F7.sf1.2.m1.1.1.3" mathsize="90%" xref="S6.F7.sf1.2.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.sf1.2.m1.1c"><apply id="S6.F7.sf1.2.m1.1.1.cmml" xref="S6.F7.sf1.2.m1.1.1"><eq id="S6.F7.sf1.2.m1.1.1.1.cmml" xref="S6.F7.sf1.2.m1.1.1.1"></eq><ci id="S6.F7.sf1.2.m1.1.1.2.cmml" xref="S6.F7.sf1.2.m1.1.1.2">𝑁</ci><cn id="S6.F7.sf1.2.m1.1.1.3.cmml" type="integer" xref="S6.F7.sf1.2.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.sf1.2.m1.1d">N=8</annotation><annotation encoding="application/x-llamapun" id="S6.F7.sf1.2.m1.1e">italic_N = 8</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F7.sf2.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf2.4.1.1" style="font-size:90%;">(b)</span> </span><math alttext="N=128" class="ltx_Math" display="inline" id="S6.F7.sf2.2.m1.1"><semantics id="S6.F7.sf2.2.m1.1b"><mrow id="S6.F7.sf2.2.m1.1.1" xref="S6.F7.sf2.2.m1.1.1.cmml"><mi id="S6.F7.sf2.2.m1.1.1.2" mathsize="90%" xref="S6.F7.sf2.2.m1.1.1.2.cmml">N</mi><mo id="S6.F7.sf2.2.m1.1.1.1" mathsize="90%" xref="S6.F7.sf2.2.m1.1.1.1.cmml">=</mo><mn id="S6.F7.sf2.2.m1.1.1.3" mathsize="90%" xref="S6.F7.sf2.2.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.sf2.2.m1.1c"><apply id="S6.F7.sf2.2.m1.1.1.cmml" xref="S6.F7.sf2.2.m1.1.1"><eq id="S6.F7.sf2.2.m1.1.1.1.cmml" xref="S6.F7.sf2.2.m1.1.1.1"></eq><ci id="S6.F7.sf2.2.m1.1.1.2.cmml" xref="S6.F7.sf2.2.m1.1.1.2">𝑁</ci><cn id="S6.F7.sf2.2.m1.1.1.3.cmml" type="integer" xref="S6.F7.sf2.2.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.sf2.2.m1.1d">N=128</annotation><annotation encoding="application/x-llamapun" id="S6.F7.sf2.2.m1.1e">italic_N = 128</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.24.3.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S6.F7.4.2" style="font-size:90%;">base<span class="ltx_text ltx_font_upright" id="S6.F7.4.2.3"> versus </span>large<span class="ltx_text ltx_font_upright" id="S6.F7.4.2.2"> Pretrained Models.<span class="ltx_text ltx_font_medium" id="S6.F7.4.2.2.2">
Validation F1-Score on <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.1">CoNLL-03</span> on the <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.2">DWAtt</span>, <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.3">Concat</span>, and enhanced (+layers) configurations of RoBERTa <span class="ltx_text ltx_font_smallcaps" id="S6.F7.4.2.2.2.4">base</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.F7.4.2.2.2.5">large</span>.
<span class="ltx_text ltx_font_italic" id="S6.F7.4.2.2.2.6">(a)</span> At <math alttext="N\!=\!8" class="ltx_Math" display="inline" id="S6.F7.3.1.1.1.m1.1"><semantics id="S6.F7.3.1.1.1.m1.1b"><mrow id="S6.F7.3.1.1.1.m1.1.1" xref="S6.F7.3.1.1.1.m1.1.1.cmml"><mi id="S6.F7.3.1.1.1.m1.1.1.2" xref="S6.F7.3.1.1.1.m1.1.1.2.cmml">N</mi><mo id="S6.F7.3.1.1.1.m1.1.1.1" lspace="0.108em" rspace="0.108em" xref="S6.F7.3.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S6.F7.3.1.1.1.m1.1.1.3" xref="S6.F7.3.1.1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.3.1.1.1.m1.1c"><apply id="S6.F7.3.1.1.1.m1.1.1.cmml" xref="S6.F7.3.1.1.1.m1.1.1"><eq id="S6.F7.3.1.1.1.m1.1.1.1.cmml" xref="S6.F7.3.1.1.1.m1.1.1.1"></eq><ci id="S6.F7.3.1.1.1.m1.1.1.2.cmml" xref="S6.F7.3.1.1.1.m1.1.1.2">𝑁</ci><cn id="S6.F7.3.1.1.1.m1.1.1.3.cmml" type="integer" xref="S6.F7.3.1.1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.3.1.1.1.m1.1d">N\!=\!8</annotation><annotation encoding="application/x-llamapun" id="S6.F7.3.1.1.1.m1.1e">italic_N = 8</annotation></semantics></math>, <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.7">Concat<sub class="ltx_sub" id="S6.F7.4.2.2.2.7.1">BASE</sub></span> shows a clear lead even on <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.8">RoBERTa<span class="ltx_text" id="S6.F7.4.2.2.2.8.1">+</span><sub class="ltx_sub" id="S6.F7.4.2.2.2.8.2">BASE</sub></span>.
<span class="ltx_text ltx_font_italic" id="S6.F7.4.2.2.2.9">(b)</span> At <math alttext="N\!=\!128" class="ltx_Math" display="inline" id="S6.F7.4.2.2.2.m2.1"><semantics id="S6.F7.4.2.2.2.m2.1b"><mrow id="S6.F7.4.2.2.2.m2.1.1" xref="S6.F7.4.2.2.2.m2.1.1.cmml"><mi id="S6.F7.4.2.2.2.m2.1.1.2" xref="S6.F7.4.2.2.2.m2.1.1.2.cmml">N</mi><mo id="S6.F7.4.2.2.2.m2.1.1.1" lspace="0.108em" rspace="0.108em" xref="S6.F7.4.2.2.2.m2.1.1.1.cmml">=</mo><mn id="S6.F7.4.2.2.2.m2.1.1.3" xref="S6.F7.4.2.2.2.m2.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.4.2.2.2.m2.1c"><apply id="S6.F7.4.2.2.2.m2.1.1.cmml" xref="S6.F7.4.2.2.2.m2.1.1"><eq id="S6.F7.4.2.2.2.m2.1.1.1.cmml" xref="S6.F7.4.2.2.2.m2.1.1.1"></eq><ci id="S6.F7.4.2.2.2.m2.1.1.2.cmml" xref="S6.F7.4.2.2.2.m2.1.1.2">𝑁</ci><cn id="S6.F7.4.2.2.2.m2.1.1.3.cmml" type="integer" xref="S6.F7.4.2.2.2.m2.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.4.2.2.2.m2.1d">N\!=\!128</annotation><annotation encoding="application/x-llamapun" id="S6.F7.4.2.2.2.m2.1e">italic_N = 128</annotation></semantics></math>, <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.10">Concat<sub class="ltx_sub" id="S6.F7.4.2.2.2.10.1">BASE</sub></span> outperforms <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.11">RoBERTa<span class="ltx_text" id="S6.F7.4.2.2.2.11.1">+</span><sub class="ltx_sub" id="S6.F7.4.2.2.2.11.2">LARGE</sub></span>, while <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.12">DWAtt<sub class="ltx_sub" id="S6.F7.4.2.2.2.12.1">LARGE</sub></span> outperforms <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.13">Concat<sub class="ltx_sub" id="S6.F7.4.2.2.2.13.1">LARGE</sub></span>.
<span class="ltx_text ltx_font_italic" id="S6.F7.4.2.2.2.14">(c)</span> This also supports the claim for higher data and training efficiency from <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.15">Concat</span> and <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2.2.2.16">DWAtt</span> in </span>FE<span class="ltx_text ltx_font_medium" id="S6.F7.4.2.2.3"> training compared to traditional last-layer fitting.
</span></span></span></figcaption>
</figure>
<figure class="ltx_figure" id="S6.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F8.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F8.8.3.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S6.F8.4.2" style="font-size:90%;">F1-Score on the <span class="ltx_text ltx_font_typewriter" id="S6.F8.4.2.1">WikiAnn</span> devset. Each language is trained for <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}=25" class="ltx_Math" display="inline" id="S6.F8.3.1.m1.1"><semantics id="S6.F8.3.1.m1.1b"><mrow id="S6.F8.3.1.m1.1.1" xref="S6.F8.3.1.m1.1.1.cmml"><msub id="S6.F8.3.1.m1.1.1.2" xref="S6.F8.3.1.m1.1.1.2.cmml"><mi id="S6.F8.3.1.m1.1.1.2.2" xref="S6.F8.3.1.m1.1.1.2.2.cmml">N</mi><mi id="S6.F8.3.1.m1.1.1.2.3" xref="S6.F8.3.1.m1.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.F8.3.1.m1.1.1.1" xref="S6.F8.3.1.m1.1.1.1.cmml">=</mo><mn id="S6.F8.3.1.m1.1.1.3" xref="S6.F8.3.1.m1.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.F8.3.1.m1.1c"><apply id="S6.F8.3.1.m1.1.1.cmml" xref="S6.F8.3.1.m1.1.1"><eq id="S6.F8.3.1.m1.1.1.1.cmml" xref="S6.F8.3.1.m1.1.1.1"></eq><apply id="S6.F8.3.1.m1.1.1.2.cmml" xref="S6.F8.3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S6.F8.3.1.m1.1.1.2.1.cmml" xref="S6.F8.3.1.m1.1.1.2">subscript</csymbol><ci id="S6.F8.3.1.m1.1.1.2.2.cmml" xref="S6.F8.3.1.m1.1.1.2.2">𝑁</ci><ci id="S6.F8.3.1.m1.1.1.2.3.cmml" xref="S6.F8.3.1.m1.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.F8.3.1.m1.1.1.3.cmml" type="integer" xref="S6.F8.3.1.m1.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.3.1.m1.1d">{N_{\mathsf{\vphantom{fg}epochs}}}=25</annotation><annotation encoding="application/x-llamapun" id="S6.F8.3.1.m1.1e">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 25</annotation></semantics></math> and tested separately. Each model is initialized from XLM-R<sub class="ltx_sub" id="S6.F8.4.2.2">LARGE</sub> weights, augmented with the specified module (DWAtt, Concat, or additional layers), then trained on exactly <math alttext="100" class="ltx_Math" display="inline" id="S6.F8.4.2.m2.1"><semantics id="S6.F8.4.2.m2.1b"><mn id="S6.F8.4.2.m2.1.1" xref="S6.F8.4.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.F8.4.2.m2.1c"><cn id="S6.F8.4.2.m2.1.1.cmml" type="integer" xref="S6.F8.4.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.4.2.m2.1d">100</annotation><annotation encoding="application/x-llamapun" id="S6.F8.4.2.m2.1e">100</annotation></semantics></math> uniformly-sampled training points for each language. The languages are sorted by token count of pretraining data from <cite class="ltx_cite ltx_citemacro_citet">Conneau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib7" title="">2019</a>)</cite>.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.5.   <span class="ltx_text ltx_align_left ltx_font_typewriter" id="S6.SS5.1.1">WikiAnn</span>: Adapting to High, Mid, and Low Resource Languages</h3>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.6"><span class="ltx_text ltx_font_bold" id="S6.SS5.p1.6.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F9" title="Figure 9 ‣ 6.5. WikiAnn: Adapting to High, Mid, and Low Resource Languages ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">9</span></a></span> shows average performance grouped by the token count of pretraining data according to <cite class="ltx_cite ltx_citemacro_citet">Conneau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib7" title="">2019</a>)</cite>. Low-resource languages had <math alttext="10" class="ltx_Math" display="inline" id="S6.SS5.p1.1.m1.1"><semantics id="S6.SS5.p1.1.m1.1a"><mn id="S6.SS5.p1.1.m1.1.1" xref="S6.SS5.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.1.m1.1b"><cn id="S6.SS5.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS5.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.1.m1.1d">10</annotation></semantics></math>–<math alttext="100" class="ltx_Math" display="inline" id="S6.SS5.p1.2.m2.1"><semantics id="S6.SS5.p1.2.m2.1a"><mn id="S6.SS5.p1.2.m2.1.1" xref="S6.SS5.p1.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.2.m2.1b"><cn id="S6.SS5.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS5.p1.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.2.m2.1c">100</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.2.m2.1d">100</annotation></semantics></math>M tokens, Mid-resource languages had <math alttext="200" class="ltx_Math" display="inline" id="S6.SS5.p1.3.m3.1"><semantics id="S6.SS5.p1.3.m3.1a"><mn id="S6.SS5.p1.3.m3.1.1" xref="S6.SS5.p1.3.m3.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.3.m3.1b"><cn id="S6.SS5.p1.3.m3.1.1.cmml" type="integer" xref="S6.SS5.p1.3.m3.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.3.m3.1c">200</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.3.m3.1d">200</annotation></semantics></math>–<math alttext="300" class="ltx_Math" display="inline" id="S6.SS5.p1.4.m4.1"><semantics id="S6.SS5.p1.4.m4.1a"><mn id="S6.SS5.p1.4.m4.1.1" xref="S6.SS5.p1.4.m4.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.4.m4.1b"><cn id="S6.SS5.p1.4.m4.1.1.cmml" type="integer" xref="S6.SS5.p1.4.m4.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.4.m4.1c">300</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.4.m4.1d">300</annotation></semantics></math>M tokens , while High-resource languages had <math alttext="2" class="ltx_Math" display="inline" id="S6.SS5.p1.5.m5.1"><semantics id="S6.SS5.p1.5.m5.1a"><mn id="S6.SS5.p1.5.m5.1.1" xref="S6.SS5.p1.5.m5.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.5.m5.1b"><cn id="S6.SS5.p1.5.m5.1.1.cmml" type="integer" xref="S6.SS5.p1.5.m5.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.5.m5.1c">2</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.5.m5.1d">2</annotation></semantics></math>–<math alttext="20" class="ltx_Math" display="inline" id="S6.SS5.p1.6.m6.1"><semantics id="S6.SS5.p1.6.m6.1a"><mn id="S6.SS5.p1.6.m6.1.1" xref="S6.SS5.p1.6.m6.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p1.6.m6.1b"><cn id="S6.SS5.p1.6.m6.1.1.cmml" type="integer" xref="S6.SS5.p1.6.m6.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p1.6.m6.1c">20</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p1.6.m6.1d">20</annotation></semantics></math>G tokens.
While there is a slight lead for layer fusion methods in the Low-resource column, the difference does not translate to a similar lead in Mid-resource scores over High-resource.</p>
</div>
<div class="ltx_para" id="S6.SS5.p2">
<p class="ltx_p" id="S6.SS5.p2.4">Compare the scores in both <span class="ltx_text ltx_font_bold" id="S6.SS5.p2.4.1">Figures</span> <a class="ltx_ref ltx_font_bold" href="https://arxiv.org/html/2209.15168v2#S6.F5" title="Figure 5 ‣ 6.2. Step and Sample Efficiency ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">5</span></a> &amp; <a class="ltx_ref ltx_font_bold" href="https://arxiv.org/html/2209.15168v2#S6.F8" title="Figure 8 ‣ 6.4. Scaling by Depth ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">8</span></a>. Starting from <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}{=}25" class="ltx_Math" display="inline" id="S6.SS5.p2.1.m1.1"><semantics id="S6.SS5.p2.1.m1.1a"><mrow id="S6.SS5.p2.1.m1.1.1" xref="S6.SS5.p2.1.m1.1.1.cmml"><msub id="S6.SS5.p2.1.m1.1.1.2" xref="S6.SS5.p2.1.m1.1.1.2.cmml"><mi id="S6.SS5.p2.1.m1.1.1.2.2" xref="S6.SS5.p2.1.m1.1.1.2.2.cmml">N</mi><mi id="S6.SS5.p2.1.m1.1.1.2.3" xref="S6.SS5.p2.1.m1.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.SS5.p2.1.m1.1.1.1" xref="S6.SS5.p2.1.m1.1.1.1.cmml">=</mo><mn id="S6.SS5.p2.1.m1.1.1.3" xref="S6.SS5.p2.1.m1.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS5.p2.1.m1.1b"><apply id="S6.SS5.p2.1.m1.1.1.cmml" xref="S6.SS5.p2.1.m1.1.1"><eq id="S6.SS5.p2.1.m1.1.1.1.cmml" xref="S6.SS5.p2.1.m1.1.1.1"></eq><apply id="S6.SS5.p2.1.m1.1.1.2.cmml" xref="S6.SS5.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S6.SS5.p2.1.m1.1.1.2.1.cmml" xref="S6.SS5.p2.1.m1.1.1.2">subscript</csymbol><ci id="S6.SS5.p2.1.m1.1.1.2.2.cmml" xref="S6.SS5.p2.1.m1.1.1.2.2">𝑁</ci><ci id="S6.SS5.p2.1.m1.1.1.2.3.cmml" xref="S6.SS5.p2.1.m1.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.SS5.p2.1.m1.1.1.3.cmml" type="integer" xref="S6.SS5.p2.1.m1.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p2.1.m1.1c">{N_{\mathsf{\vphantom{fg}epochs}}}{=}25</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p2.1.m1.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 25</annotation></semantics></math> and only <math alttext="N{=}32" class="ltx_Math" display="inline" id="S6.SS5.p2.2.m2.1"><semantics id="S6.SS5.p2.2.m2.1a"><mrow id="S6.SS5.p2.2.m2.1.1" xref="S6.SS5.p2.2.m2.1.1.cmml"><mi id="S6.SS5.p2.2.m2.1.1.2" xref="S6.SS5.p2.2.m2.1.1.2.cmml">N</mi><mo id="S6.SS5.p2.2.m2.1.1.1" xref="S6.SS5.p2.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS5.p2.2.m2.1.1.3" xref="S6.SS5.p2.2.m2.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS5.p2.2.m2.1b"><apply id="S6.SS5.p2.2.m2.1.1.cmml" xref="S6.SS5.p2.2.m2.1.1"><eq id="S6.SS5.p2.2.m2.1.1.1.cmml" xref="S6.SS5.p2.2.m2.1.1.1"></eq><ci id="S6.SS5.p2.2.m2.1.1.2.cmml" xref="S6.SS5.p2.2.m2.1.1.2">𝑁</ci><cn id="S6.SS5.p2.2.m2.1.1.3.cmml" type="integer" xref="S6.SS5.p2.2.m2.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p2.2.m2.1c">N{=}32</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p2.2.m2.1d">italic_N = 32</annotation></semantics></math> samples, performance using RoBERTa<sub class="ltx_sub" id="S6.SS5.p2.4.2">LARGE</sub> as the base model beats the corresponding run on XLM-R<sub class="ltx_sub" id="S6.SS5.p2.4.3">LARGE</sub> at <math alttext="{N_{\mathsf{\vphantom{fg}epochs}}}{=}25" class="ltx_Math" display="inline" id="S6.SS5.p2.3.m3.1"><semantics id="S6.SS5.p2.3.m3.1a"><mrow id="S6.SS5.p2.3.m3.1.1" xref="S6.SS5.p2.3.m3.1.1.cmml"><msub id="S6.SS5.p2.3.m3.1.1.2" xref="S6.SS5.p2.3.m3.1.1.2.cmml"><mi id="S6.SS5.p2.3.m3.1.1.2.2" xref="S6.SS5.p2.3.m3.1.1.2.2.cmml">N</mi><mi id="S6.SS5.p2.3.m3.1.1.2.3" xref="S6.SS5.p2.3.m3.1.1.2.3.cmml">𝖾𝗉𝗈𝖼𝗁𝗌</mi></msub><mo id="S6.SS5.p2.3.m3.1.1.1" xref="S6.SS5.p2.3.m3.1.1.1.cmml">=</mo><mn id="S6.SS5.p2.3.m3.1.1.3" xref="S6.SS5.p2.3.m3.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS5.p2.3.m3.1b"><apply id="S6.SS5.p2.3.m3.1.1.cmml" xref="S6.SS5.p2.3.m3.1.1"><eq id="S6.SS5.p2.3.m3.1.1.1.cmml" xref="S6.SS5.p2.3.m3.1.1.1"></eq><apply id="S6.SS5.p2.3.m3.1.1.2.cmml" xref="S6.SS5.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S6.SS5.p2.3.m3.1.1.2.1.cmml" xref="S6.SS5.p2.3.m3.1.1.2">subscript</csymbol><ci id="S6.SS5.p2.3.m3.1.1.2.2.cmml" xref="S6.SS5.p2.3.m3.1.1.2.2">𝑁</ci><ci id="S6.SS5.p2.3.m3.1.1.2.3.cmml" xref="S6.SS5.p2.3.m3.1.1.2.3">𝖾𝗉𝗈𝖼𝗁𝗌</ci></apply><cn id="S6.SS5.p2.3.m3.1.1.3.cmml" type="integer" xref="S6.SS5.p2.3.m3.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p2.3.m3.1c">{N_{\mathsf{\vphantom{fg}epochs}}}{=}25</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p2.3.m3.1d">italic_N start_POSTSUBSCRIPT sansserif_epochs end_POSTSUBSCRIPT = 25</annotation></semantics></math> with <math alttext="100" class="ltx_Math" display="inline" id="S6.SS5.p2.4.m4.1"><semantics id="S6.SS5.p2.4.m4.1a"><mn id="S6.SS5.p2.4.m4.1.1" xref="S6.SS5.p2.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S6.SS5.p2.4.m4.1b"><cn id="S6.SS5.p2.4.m4.1.1.cmml" type="integer" xref="S6.SS5.p2.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS5.p2.4.m4.1c">100</annotation><annotation encoding="application/x-llamapun" id="S6.SS5.p2.4.m4.1d">100</annotation></semantics></math> samples.</p>
</div>
<figure class="ltx_figure" id="S6.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S6.F9.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F9.3.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="S6.F9.4.2" style="font-size:90%;">F1-Score on the <span class="ltx_text ltx_font_typewriter" id="S6.F9.4.2.1">WikiAnn</span> devset. Languages are grouped into three tiers of resource size. See Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F8" title="Figure 8 ‣ 6.4. Scaling by Depth ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">8</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S3.T1" title="Table 1 ‣ 3.1. Few-Shot Adaptation on NER ‣ 3. Tasks, Datasets, and Raised Questions ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">1</span></a> for details.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS6">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.6.   Masked Language Modeling</h3>
<figure class="ltx_table" id="S6.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.2.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T3.2.1.1.2.1">Test Perplexity</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.2.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.2.2.1.1">RoBERTa+</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S6.T3.2.2.1.2">2.98</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.3.2">
<td class="ltx_td ltx_align_center" id="S6.T3.2.3.2.1">Concat</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T3.2.3.2.2">3.44</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.4.3">
<td class="ltx_td ltx_align_center" id="S6.T3.2.4.3.1">DWAtt</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T3.2.4.3.2">2.91</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.5.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.2.5.4.1">Base</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S6.T3.2.5.4.2">2.90</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T3.4.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S6.T3.5.2" style="font-size:90%;">MLM perplexity on <span class="ltx_text ltx_font_typewriter" id="S6.T3.5.2.1">WikiText-2</span> test set.</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS6.p1">
<p class="ltx_p" id="S6.SS6.p1.1">We report the test perplexity of the checkpoint with the best validation loss from FT training. <span class="ltx_text ltx_font_typewriter" id="S6.SS6.p1.1.1">DWAtt</span> performs closer to the baseline <span class="ltx_text ltx_font_typewriter" id="S6.SS6.p1.1.2">Base</span> than <span class="ltx_text ltx_font_typewriter" id="S6.SS6.p1.1.3">Concat</span> and <span class="ltx_text ltx_font_typewriter" id="S6.SS6.p1.1.4">R<sub class="ltx_sub" id="S6.SS6.p1.1.4.1">26</sub></span>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">7.   Related Work</h2>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Adaptors.</h4>
<div class="ltx_para" id="S7.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px1.p1.1">Adaptors are layers introduced into a pretrained model layer stack and finetuned on a specific downstream task, to avoid changing the (larger) model’s weights. <cite class="ltx_cite ltx_citemacro_citep">(Houlsby et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib15" title="">2019</a>)</cite>, among others.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Layer Aggregation (static weights).</h4>
<div class="ltx_para" id="S7.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Bapna et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib3" title="">2018</a>)</cite> defines, for each decoder layer, a trainable softmax-normalized vector of weights to get the weighted sum of the encoder intermediates.
<cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib20" title="">2021</a>)</cite> provides one static, learned vector for each intermediate layer’s representation which acts as element-wise scaling.
Both works are similar to <span class="ltx_text ltx_font_typewriter" id="S7.SS0.SSS0.Px2.p1.1.1">Concat</span> in applying a static, learned mixing transform to all layers.
For each layer: The first provides a scalar weight,
the second provides a vector for element-wise multiplication,
while <span class="ltx_text ltx_font_typewriter" id="S7.SS0.SSS0.Px2.p1.1.2">Concat</span> applies a linear transform.</p>
</div>
<div class="ltx_para" id="S7.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p2.1">In <cite class="ltx_cite ltx_citemacro_citet">Shen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib27" title="">2018</a>)</cite>, the <span class="ltx_text ltx_font_bold" id="S7.SS0.SSS0.Px2.p2.1.1">DenseNMT</span> is an encoder-decoder NMT architecture densely connected in the style of <span class="ltx_text ltx_font_bold" id="S7.SS0.SSS0.Px2.p2.1.2">DenseNet</span> <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib16" title="">2016</a>)</cite>. Each encoder layer takes a concatenation of all previous layer representations. Similarly for decoder layers. See also <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib33" title="">2019b</a>)</cite>. These methods compare structurally to <span class="ltx_text ltx_font_typewriter" id="S7.SS0.SSS0.Px2.p2.1.3">Concat</span>, which is applied only once on the full layer stack.</p>
</div>
<div class="ltx_para" id="S7.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p3.2"><cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib34" title="">2018b</a>)</cite> generates the weight for an encoder layer via an MLP on the layer’s representation, irrespective of the rest of the model: <math alttext="{w}_{i}=f^{a}({\mathbf{z}}_{i})" class="ltx_Math" display="inline" id="S7.SS0.SSS0.Px2.p3.1.m1.1"><semantics id="S7.SS0.SSS0.Px2.p3.1.m1.1a"><mrow id="S7.SS0.SSS0.Px2.p3.1.m1.1.1" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.cmml"><msub id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.cmml"><mi id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.2" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.2.cmml">w</mi><mi id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.3" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.3.cmml">i</mi></msub><mo id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.2" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.2.cmml">=</mo><mrow id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.cmml"><msup id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.cmml"><mi id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.2" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.2.cmml">f</mi><mi id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.3" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.3.cmml">a</mi></msup><mo id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.2" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml"><mo id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.2" stretchy="false" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.2" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.3" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.3" stretchy="false" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px2.p3.1.m1.1b"><apply id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1"><eq id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.2"></eq><apply id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.1.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3">subscript</csymbol><ci id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.2.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.2">𝑤</ci><ci id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.3.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.3.3">𝑖</ci></apply><apply id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1"><times id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.2.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.2"></times><apply id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.1.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3">superscript</csymbol><ci id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.2.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.2">𝑓</ci><ci id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.3.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.3.3">𝑎</ci></apply><apply id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.2">𝐳</ci><ci id="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S7.SS0.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px2.p3.1.m1.1c">{w}_{i}=f^{a}({\mathbf{z}}_{i})</annotation><annotation encoding="application/x-llamapun" id="S7.SS0.SSS0.Px2.p3.1.m1.1d">italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_f start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT ( bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> then <math alttext="{{\mathbf{h}}}=\sum_{i}({w}_{i}{\mathbf{z}}_{i})" class="ltx_Math" display="inline" id="S7.SS0.SSS0.Px2.p3.2.m2.1"><semantics id="S7.SS0.SSS0.Px2.p3.2.m2.1a"><mrow id="S7.SS0.SSS0.Px2.p3.2.m2.1.1" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.cmml"><mi id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.3" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.3.cmml">𝐡</mi><mo id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.2" rspace="0.111em" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.2.cmml">=</mo><mrow id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.cmml"><msub id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.cmml"><mo id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.2" rspace="0em" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.2.cmml">∑</mo><mi id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.3" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.3.cmml">i</mi></msub><mrow id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.cmml"><mo id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.2" stretchy="false" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.cmml"><msub id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.2" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.3" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.1" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.1.cmml">⁢</mo><msub id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.2" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.2.cmml">𝐳</mi><mi id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.3" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.3" stretchy="false" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS0.SSS0.Px2.p3.2.m2.1b"><apply id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1"><eq id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.2.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.2"></eq><ci id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.3.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.3">𝐡</ci><apply id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1"><apply id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2"><csymbol cd="ambiguous" id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2">subscript</csymbol><sum id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.2.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.2"></sum><ci id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.3.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.2.3">𝑖</ci></apply><apply id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1"><times id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.1"></times><apply id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.2">𝑤</ci><ci id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.2">𝐳</ci><ci id="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S7.SS0.SSS0.Px2.p3.2.m2.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS0.SSS0.Px2.p3.2.m2.1c">{{\mathbf{h}}}=\sum_{i}({w}_{i}{\mathbf{z}}_{i})</annotation><annotation encoding="application/x-llamapun" id="S7.SS0.SSS0.Px2.p3.2.m2.1d">bold_h = ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Dynamic Layer Mixing.</h4>
<div class="ltx_para" id="S7.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S7.SS0.SSS0.Px3.p1.1">The following methods use signals from the input to change the transformation itself dynamically.
See also <span class="ltx_text ltx_font_typewriter" id="S7.SS0.SSS0.Px3.p1.1.1">DWAtt</span> which uses a Dot-Product Attention module for comparison.
<cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib18" title="">2018</a>)</cite> applies an LSTM depth-wise on the intermediate vectors of the stack of LSTM cells applied on input sequences, as expected.
We attempted adding an LSTM cell applied depth-wise to the Transformer encoder stack but observed lacking performance. Note that the referenced work utilizes a non-basic cell with peep-hole expressions, and some architecture connectivity that complicates experiments in the Feature Extraction context.
<cite class="ltx_cite ltx_citemacro_citet">Dou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib10" title="">2019</a>)</cite> utilizes a dynamically-weighted routing mechanism to mix transformations of each intermediate representation, then concatenate all such.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">8.   Discussion</h2>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">8.1.   Notes on Selected Evaluations</h3>
<section class="ltx_paragraph" id="S8.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">NER: A Token-level Downstream Task</h4>
<div class="ltx_para" id="S8.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S8.SS1.SSS0.Px1.p1.1">The NER task is selected to provide a more complex performance signal than sentence classification (which was the case in <cite class="ltx_cite ltx_citemacro_citep">AlKhamissi et al., <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib1" title="">2021</a></cite>).
See Section <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S8.SS3" title="8.3. Modeling Capacity ‣ 8. Discussion ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">8.3</span></a> where we hypothesize on the cases that would benefit from DWAtt. Briefly, tasks which look at individual tokens deeply and do not need increased spatial abstraction (for example because of increased context length) may be more likely to benefit from methods like DWAtt, especially if full fine-tuning is not available.
Further, prior work such as <cite class="ltx_cite ltx_citemacro_citet">Wallat et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib30" title="">2021</a>)</cite> suggests that there can be useful information in intermediate layers, and specifically probes for it by a token-level task.</p>
</div>
</section>
<section class="ltx_paragraph" id="S8.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">MLM: Pretraining objective</h4>
<div class="ltx_para" id="S8.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S8.SS1.SSS0.Px2.p1.1">Users build on pretrained large models in order to exploit a more general linguistic and logical capability than could be expected from training on a downstream task dataset much smaller than the smallest of unsupervised LM data collections.
We believe that fine-tuning must maintain this more general objective of the base model in order to make the claim that task performance generalizes outside the specific sub-domain of the test set. If fine-tuning results in great downstream results but equally great pretraining objective regression (e.g. MLM), we believe that method should be regarded as less reliable and desirable than one which maintains the pretraining objective scores.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">8.2.   Levels of Abstraction</h3>
<div class="ltx_para" id="S8.SS2.p1">
<p class="ltx_p" id="S8.SS2.p1.2">For non-recurrent deep neural networks, there exists a functional limit to the depth of abstraction obtainable, which is proportional to the depth of the network.
Abstraction here refers to the depth of composed rules that a model may learn to apply on low-level stimulus, such as pixels or tokens. For feed-forward models like an MLP or transformers, this corresponds to the depth in terms of stacked nonlinear layers.
As an example, to handle program-like systematic inputs, depth-recurrent and memory-augmented architecture were utilized in works such as <cite class="ltx_cite ltx_citemacro_citet">Dehghani et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib8" title="">2019</a>); Graves et al. (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib12" title="">2014</a>)</cite>.
For traditional Transformer models, like RoBERTa<sub class="ltx_sub" id="S8.SS2.p1.2.1">LARGE</sub>, we can say that the limit is proportional to the number of layers in the network (e.g. <math alttext="O(|L|)" class="ltx_Math" display="inline" id="S8.SS2.p1.1.m1.2"><semantics id="S8.SS2.p1.1.m1.2a"><mrow id="S8.SS2.p1.1.m1.2.2" xref="S8.SS2.p1.1.m1.2.2.cmml"><mi id="S8.SS2.p1.1.m1.2.2.3" xref="S8.SS2.p1.1.m1.2.2.3.cmml">O</mi><mo id="S8.SS2.p1.1.m1.2.2.2" xref="S8.SS2.p1.1.m1.2.2.2.cmml">⁢</mo><mrow id="S8.SS2.p1.1.m1.2.2.1.1" xref="S8.SS2.p1.1.m1.2.2.cmml"><mo id="S8.SS2.p1.1.m1.2.2.1.1.2" stretchy="false" xref="S8.SS2.p1.1.m1.2.2.cmml">(</mo><mrow id="S8.SS2.p1.1.m1.2.2.1.1.1.2" xref="S8.SS2.p1.1.m1.2.2.1.1.1.1.cmml"><mo id="S8.SS2.p1.1.m1.2.2.1.1.1.2.1" stretchy="false" xref="S8.SS2.p1.1.m1.2.2.1.1.1.1.1.cmml">|</mo><mi id="S8.SS2.p1.1.m1.1.1" xref="S8.SS2.p1.1.m1.1.1.cmml">L</mi><mo id="S8.SS2.p1.1.m1.2.2.1.1.1.2.2" stretchy="false" xref="S8.SS2.p1.1.m1.2.2.1.1.1.1.1.cmml">|</mo></mrow><mo id="S8.SS2.p1.1.m1.2.2.1.1.3" stretchy="false" xref="S8.SS2.p1.1.m1.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S8.SS2.p1.1.m1.2b"><apply id="S8.SS2.p1.1.m1.2.2.cmml" xref="S8.SS2.p1.1.m1.2.2"><times id="S8.SS2.p1.1.m1.2.2.2.cmml" xref="S8.SS2.p1.1.m1.2.2.2"></times><ci id="S8.SS2.p1.1.m1.2.2.3.cmml" xref="S8.SS2.p1.1.m1.2.2.3">𝑂</ci><apply id="S8.SS2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S8.SS2.p1.1.m1.2.2.1.1.1.2"><abs id="S8.SS2.p1.1.m1.2.2.1.1.1.1.1.cmml" xref="S8.SS2.p1.1.m1.2.2.1.1.1.2.1"></abs><ci id="S8.SS2.p1.1.m1.1.1.cmml" xref="S8.SS2.p1.1.m1.1.1">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.p1.1.m1.2c">O(|L|)</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.p1.1.m1.2d">italic_O ( | italic_L | )</annotation></semantics></math>; <math alttext="|L|=24" class="ltx_Math" display="inline" id="S8.SS2.p1.2.m2.1"><semantics id="S8.SS2.p1.2.m2.1a"><mrow id="S8.SS2.p1.2.m2.1.2" xref="S8.SS2.p1.2.m2.1.2.cmml"><mrow id="S8.SS2.p1.2.m2.1.2.2.2" xref="S8.SS2.p1.2.m2.1.2.2.1.cmml"><mo id="S8.SS2.p1.2.m2.1.2.2.2.1" stretchy="false" xref="S8.SS2.p1.2.m2.1.2.2.1.1.cmml">|</mo><mi id="S8.SS2.p1.2.m2.1.1" xref="S8.SS2.p1.2.m2.1.1.cmml">L</mi><mo id="S8.SS2.p1.2.m2.1.2.2.2.2" stretchy="false" xref="S8.SS2.p1.2.m2.1.2.2.1.1.cmml">|</mo></mrow><mo id="S8.SS2.p1.2.m2.1.2.1" xref="S8.SS2.p1.2.m2.1.2.1.cmml">=</mo><mn id="S8.SS2.p1.2.m2.1.2.3" xref="S8.SS2.p1.2.m2.1.2.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.SS2.p1.2.m2.1b"><apply id="S8.SS2.p1.2.m2.1.2.cmml" xref="S8.SS2.p1.2.m2.1.2"><eq id="S8.SS2.p1.2.m2.1.2.1.cmml" xref="S8.SS2.p1.2.m2.1.2.1"></eq><apply id="S8.SS2.p1.2.m2.1.2.2.1.cmml" xref="S8.SS2.p1.2.m2.1.2.2.2"><abs id="S8.SS2.p1.2.m2.1.2.2.1.1.cmml" xref="S8.SS2.p1.2.m2.1.2.2.2.1"></abs><ci id="S8.SS2.p1.2.m2.1.1.cmml" xref="S8.SS2.p1.2.m2.1.1">𝐿</ci></apply><cn id="S8.SS2.p1.2.m2.1.2.3.cmml" type="integer" xref="S8.SS2.p1.2.m2.1.2.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.p1.2.m2.1c">|L|=24</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.p1.2.m2.1d">| italic_L | = 24</annotation></semantics></math>).</p>
</div>
<section class="ltx_paragraph" id="S8.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Hiding Within Scale.</h4>
<div class="ltx_para" id="S8.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S8.SS2.SSS0.Px1.p1.1">In practice, this is seldom an obvious problem because large networks would have enough width-wise parameter capacity to directly encode “intuition”, i.e. shortcuts to knowledge and abstraction.
They may do so by tying the low-level representation of some inputs to intermediate signals for the high-level concepts they tend to manifest.
As an artificial example: A small, shallow model for classifying sentiment may tie a token such as <span class="ltx_text" id="S8.SS2.SSS0.Px1.p1.1.1" style="background-color:#E6E6E6;"> <span class="ltx_text ltx_phantom" id="S8.SS2.SSS0.Px1.p1.1.1.1"><span style="visibility:hidden">Ay</span></span><span class="ltx_text ltx_font_typewriter" id="S8.SS2.SSS0.Px1.p1.1.1.2">scary</span> </span> to become a strong signal for negative sentiment, say in a movie review setting. Sensible in the domain of kids movies; but may in fact signify a positive sentiment instead when observed in reviews for horror movies. The key point is that it is an early shortcut, not whether it is accurate.</p>
</div>
</section>
<section class="ltx_paragraph" id="S8.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Intuition as Shortcuts From Raw Input.</h4>
<div class="ltx_para" id="S8.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S8.SS2.SSS0.Px2.p1.1">Thus, earlier layers can encode information at a higher level than <math alttext="|L|" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S8.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S8.SS2.SSS0.Px2.p1.1.m1.1.2.2" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.2.1.cmml"><mo id="S8.SS2.SSS0.Px2.p1.1.m1.1.2.2.1" stretchy="false" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.2.1.1.cmml">|</mo><mi id="S8.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">L</mi><mo id="S8.SS2.SSS0.Px2.p1.1.m1.1.2.2.2" stretchy="false" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S8.SS2.SSS0.Px2.p1.1.m1.1.2.1.cmml" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.2.2"><abs id="S8.SS2.SSS0.Px2.p1.1.m1.1.2.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.2.2.1"></abs><ci id="S8.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S8.SS2.SSS0.Px2.p1.1.m1.1.1">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px2.p1.1.m1.1c">|L|</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px2.p1.1.m1.1d">| italic_L |</annotation></semantics></math>-steps of abstraction would suggest. This would be needed, and expected, for models of a reasonable depth and width to be able to satisfy the feature extraction needs of the <em class="ltx_emph ltx_font_italic" id="S8.SS2.SSS0.Px2.p1.1.1">pretraining</em> task at the last layer. Should a <em class="ltx_emph ltx_font_italic" id="S8.SS2.SSS0.Px2.p1.1.2">downstream</em> task require a different signal from what the <em class="ltx_emph ltx_font_italic" id="S8.SS2.SSS0.Px2.p1.1.3">pretraining</em> task exposed, it may have to <em class="ltx_emph ltx_font_italic" id="S8.SS2.SSS0.Px2.p1.1.4">shift</em> a large subset of the weights to relearn or resurface that information from the shallower levels.</p>
</div>
</section>
<section class="ltx_paragraph" id="S8.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Proposition.</h4>
<div class="ltx_para" id="S8.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S8.SS2.SSS0.Px3.p1.2">The methods we’ve discussed may enable downstream tasks to query the model for hidden but useful information. For the downstream task to make use of such features, it would likely need to transform them further.
By applying the <math alttext="2" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S8.SS2.SSS0.Px3.p1.1.m1.1a"><mn id="S8.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S8.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px3.p1.1.m1.1b"><cn id="S8.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" type="integer" xref="S8.SS2.SSS0.Px3.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px3.p1.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px3.p1.1.m1.1d">2</annotation></semantics></math>-layer MLPs <math alttext="f^{V}_{n}" class="ltx_Math" display="inline" id="S8.SS2.SSS0.Px3.p1.2.m2.1"><semantics id="S8.SS2.SSS0.Px3.p1.2.m2.1a"><msubsup id="S8.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.2" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.2.cmml">f</mi><mi id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml">n</mi><mi id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.3" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.3.cmml">V</mi></msubsup><annotation-xml encoding="MathML-Content" id="S8.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><apply id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.1.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1">superscript</csymbol><ci id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.2.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.2">𝑓</ci><ci id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.3.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.2.3">𝑉</ci></apply><ci id="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S8.SS2.SSS0.Px3.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS2.SSS0.Px3.p1.2.m2.1c">f^{V}_{n}</annotation><annotation encoding="application/x-llamapun" id="S8.SS2.SSS0.Px3.p1.2.m2.1d">italic_f start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> on these intermediate features (in <span class="ltx_text ltx_font_typewriter" id="S8.SS2.SSS0.Px3.p1.2.1">DWAtt</span>), and a linear transform in <span class="ltx_text ltx_font_typewriter" id="S8.SS2.SSS0.Px3.p1.2.2">Concat</span>, the task can extract a more useful representation from each level/layer.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S8.SS3">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">8.3.   Modeling Capacity</h3>
<div class="ltx_para" id="S8.SS3.p1">
<p class="ltx_p" id="S8.SS3.p1.2">The two models presented and highlighted—<span class="ltx_text ltx_font_typewriter" id="S8.SS3.p1.2.1">DWAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S8.SS3.p1.2.2">Concat</span>—are aggregate views of the features of all intermediate Transformer layers <math alttext="\{{\mathbf{z}}_{n}\mid n\in|L|\}" class="ltx_Math" display="inline" id="S8.SS3.p1.1.m1.3"><semantics id="S8.SS3.p1.1.m1.3a"><mrow id="S8.SS3.p1.1.m1.3.3.2" xref="S8.SS3.p1.1.m1.3.3.3.cmml"><mo id="S8.SS3.p1.1.m1.3.3.2.3" stretchy="false" xref="S8.SS3.p1.1.m1.3.3.3.1.cmml">{</mo><msub id="S8.SS3.p1.1.m1.2.2.1.1" xref="S8.SS3.p1.1.m1.2.2.1.1.cmml"><mi id="S8.SS3.p1.1.m1.2.2.1.1.2" xref="S8.SS3.p1.1.m1.2.2.1.1.2.cmml">𝐳</mi><mi id="S8.SS3.p1.1.m1.2.2.1.1.3" xref="S8.SS3.p1.1.m1.2.2.1.1.3.cmml">n</mi></msub><mo fence="true" id="S8.SS3.p1.1.m1.3.3.2.4" lspace="0em" rspace="0em" xref="S8.SS3.p1.1.m1.3.3.3.1.cmml">∣</mo><mrow id="S8.SS3.p1.1.m1.3.3.2.2" xref="S8.SS3.p1.1.m1.3.3.2.2.cmml"><mi id="S8.SS3.p1.1.m1.3.3.2.2.2" xref="S8.SS3.p1.1.m1.3.3.2.2.2.cmml">n</mi><mo id="S8.SS3.p1.1.m1.3.3.2.2.1" xref="S8.SS3.p1.1.m1.3.3.2.2.1.cmml">∈</mo><mrow id="S8.SS3.p1.1.m1.3.3.2.2.3.2" xref="S8.SS3.p1.1.m1.3.3.2.2.3.1.cmml"><mo id="S8.SS3.p1.1.m1.3.3.2.2.3.2.1" stretchy="false" xref="S8.SS3.p1.1.m1.3.3.2.2.3.1.1.cmml">|</mo><mi id="S8.SS3.p1.1.m1.1.1" xref="S8.SS3.p1.1.m1.1.1.cmml">L</mi><mo id="S8.SS3.p1.1.m1.3.3.2.2.3.2.2" stretchy="false" xref="S8.SS3.p1.1.m1.3.3.2.2.3.1.1.cmml">|</mo></mrow></mrow><mo id="S8.SS3.p1.1.m1.3.3.2.5" stretchy="false" xref="S8.SS3.p1.1.m1.3.3.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.SS3.p1.1.m1.3b"><apply id="S8.SS3.p1.1.m1.3.3.3.cmml" xref="S8.SS3.p1.1.m1.3.3.2"><csymbol cd="latexml" id="S8.SS3.p1.1.m1.3.3.3.1.cmml" xref="S8.SS3.p1.1.m1.3.3.2.3">conditional-set</csymbol><apply id="S8.SS3.p1.1.m1.2.2.1.1.cmml" xref="S8.SS3.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S8.SS3.p1.1.m1.2.2.1.1.1.cmml" xref="S8.SS3.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S8.SS3.p1.1.m1.2.2.1.1.2.cmml" xref="S8.SS3.p1.1.m1.2.2.1.1.2">𝐳</ci><ci id="S8.SS3.p1.1.m1.2.2.1.1.3.cmml" xref="S8.SS3.p1.1.m1.2.2.1.1.3">𝑛</ci></apply><apply id="S8.SS3.p1.1.m1.3.3.2.2.cmml" xref="S8.SS3.p1.1.m1.3.3.2.2"><in id="S8.SS3.p1.1.m1.3.3.2.2.1.cmml" xref="S8.SS3.p1.1.m1.3.3.2.2.1"></in><ci id="S8.SS3.p1.1.m1.3.3.2.2.2.cmml" xref="S8.SS3.p1.1.m1.3.3.2.2.2">𝑛</ci><apply id="S8.SS3.p1.1.m1.3.3.2.2.3.1.cmml" xref="S8.SS3.p1.1.m1.3.3.2.2.3.2"><abs id="S8.SS3.p1.1.m1.3.3.2.2.3.1.1.cmml" xref="S8.SS3.p1.1.m1.3.3.2.2.3.2.1"></abs><ci id="S8.SS3.p1.1.m1.1.1.cmml" xref="S8.SS3.p1.1.m1.1.1">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.p1.1.m1.3c">\{{\mathbf{z}}_{n}\mid n\in|L|\}</annotation><annotation encoding="application/x-llamapun" id="S8.SS3.p1.1.m1.3d">{ bold_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∣ italic_n ∈ | italic_L | }</annotation></semantics></math> (see Section <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S4" title="4. Models ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">4</span></a>).
<span class="ltx_text ltx_font_typewriter" id="S8.SS3.p1.2.3">DWAtt</span>’s added module requires access to the last layer’s <math alttext="{\mathbf{z}}_{L}" class="ltx_Math" display="inline" id="S8.SS3.p1.2.m2.1"><semantics id="S8.SS3.p1.2.m2.1a"><msub id="S8.SS3.p1.2.m2.1.1" xref="S8.SS3.p1.2.m2.1.1.cmml"><mi id="S8.SS3.p1.2.m2.1.1.2" xref="S8.SS3.p1.2.m2.1.1.2.cmml">𝐳</mi><mi id="S8.SS3.p1.2.m2.1.1.3" xref="S8.SS3.p1.2.m2.1.1.3.cmml">L</mi></msub><annotation-xml encoding="MathML-Content" id="S8.SS3.p1.2.m2.1b"><apply id="S8.SS3.p1.2.m2.1.1.cmml" xref="S8.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S8.SS3.p1.2.m2.1.1.1.cmml" xref="S8.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S8.SS3.p1.2.m2.1.1.2.cmml" xref="S8.SS3.p1.2.m2.1.1.2">𝐳</ci><ci id="S8.SS3.p1.2.m2.1.1.3.cmml" xref="S8.SS3.p1.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.p1.2.m2.1c">{\mathbf{z}}_{L}</annotation><annotation encoding="application/x-llamapun" id="S8.SS3.p1.2.m2.1d">bold_z start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT</annotation></semantics></math> to form the query, while <span class="ltx_text ltx_font_typewriter" id="S8.SS3.p1.2.4">Concat</span> does not.
Neither method makes any use of external signals such as, for example, a task embedding vector.</p>
</div>
<div class="ltx_para" id="S8.SS3.p2">
<p class="ltx_p" id="S8.SS3.p2.1">These three points together present an underlying property of the modeling capacity of <span class="ltx_text ltx_font_typewriter" id="S8.SS3.p2.1.1">DWAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S8.SS3.p2.1.2">Concat</span> when <em class="ltx_emph ltx_font_italic" id="S8.SS3.p2.1.3">fully-tuned</em>:
<em class="ltx_emph ltx_font_italic" id="S8.SS3.p2.1.4">The depth-wise layer mixing arrives at a model which is at most as expressive as the underlying sequence-modeler</em>.
See Figure <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#S6.F6" title="Figure 6 ‣ 6.3. Feature Extractor Adaptability ‣ 6. Results and Analysis ‣ Depth-Wise Attention (DWAtt): A Layer Fusion Method for Data-Efficient Classification"><span class="ltx_text ltx_ref_tag">6</span></a> where layer fusion under FE nears but does not exceed FT, while all methods are similar under FT.</p>
</div>
<section class="ltx_paragraph" id="S8.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Modeling Dimensions.</h4>
<div class="ltx_para" id="S8.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S8.SS3.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_typewriter" id="S8.SS3.SSS0.Px1.p1.1.1">DWAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S8.SS3.SSS0.Px1.p1.1.2">Concat</span> operate <em class="ltx_emph ltx_font_italic" id="S8.SS3.SSS0.Px1.p1.1.3">depth-wise</em> over a sequence-modeling model. By that very nature, it may not be the best option when the task at hand requires increased or improved <em class="ltx_emph ltx_font_italic" id="S8.SS3.SSS0.Px1.p1.1.4">spatial</em> abstraction—the ability to learn connections on a spatial axis (e.g. between tokens in sequences in a text Transformer).
Then, adding extra Transformer layers or full finetuning may be better options.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">9.   Design Details</h2>
<figure class="ltx_table" id="S9.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S9.T4.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S9.T4.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S9.T4.3.4.1.1"><span class="ltx_text ltx_font_bold" id="S9.T4.3.4.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S9.T4.3.4.1.2"><span class="ltx_text ltx_font_bold" id="S9.T4.3.4.1.2.1">Param</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S9.T4.3.4.1.3"><span class="ltx_text ltx_font_bold" id="S9.T4.3.4.1.3.1">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S9.T4.3.5.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T4.3.5.1.1"><span class="ltx_text ltx_font_bold" id="S9.T4.3.5.1.1.1">All<sub class="ltx_sub" id="S9.T4.3.5.1.1.1.1">Large</sub></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S9.T4.3.5.1.2">Transformer Layers</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S9.T4.3.5.1.3">24</td>
</tr>
<tr class="ltx_tr" id="S9.T4.3.6.2">
<td class="ltx_td ltx_align_center" id="S9.T4.3.6.2.1"><span class="ltx_text ltx_font_bold" id="S9.T4.3.6.2.1.1">All</span></td>
<td class="ltx_td ltx_align_left" id="S9.T4.3.6.2.2">Learning Rate</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S9.T4.3.6.2.3">1e-5</td>
</tr>
<tr class="ltx_tr" id="S9.T4.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T4.1.1.2"><span class="ltx_text ltx_font_bold" id="S9.T4.1.1.2.1">DWAtt</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S9.T4.1.1.1">
<math alttext="\gamma^{Q}" class="ltx_Math" display="inline" id="S9.T4.1.1.1.m1.1"><semantics id="S9.T4.1.1.1.m1.1a"><msup id="S9.T4.1.1.1.m1.1.1" xref="S9.T4.1.1.1.m1.1.1.cmml"><mi id="S9.T4.1.1.1.m1.1.1.2" xref="S9.T4.1.1.1.m1.1.1.2.cmml">γ</mi><mi id="S9.T4.1.1.1.m1.1.1.3" xref="S9.T4.1.1.1.m1.1.1.3.cmml">Q</mi></msup><annotation-xml encoding="MathML-Content" id="S9.T4.1.1.1.m1.1b"><apply id="S9.T4.1.1.1.m1.1.1.cmml" xref="S9.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S9.T4.1.1.1.m1.1.1.1.cmml" xref="S9.T4.1.1.1.m1.1.1">superscript</csymbol><ci id="S9.T4.1.1.1.m1.1.1.2.cmml" xref="S9.T4.1.1.1.m1.1.1.2">𝛾</ci><ci id="S9.T4.1.1.1.m1.1.1.3.cmml" xref="S9.T4.1.1.1.m1.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T4.1.1.1.m1.1c">\gamma^{Q}</annotation><annotation encoding="application/x-llamapun" id="S9.T4.1.1.1.m1.1d">italic_γ start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT</annotation></semantics></math>, query bottleneck</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S9.T4.1.1.3">0.5</td>
</tr>
<tr class="ltx_tr" id="S9.T4.2.2">
<td class="ltx_td ltx_align_center" id="S9.T4.2.2.2"><span class="ltx_text ltx_font_bold" id="S9.T4.2.2.2.1">DWAtt</span></td>
<td class="ltx_td ltx_align_left" id="S9.T4.2.2.1">
<math alttext="\gamma^{V}" class="ltx_Math" display="inline" id="S9.T4.2.2.1.m1.1"><semantics id="S9.T4.2.2.1.m1.1a"><msup id="S9.T4.2.2.1.m1.1.1" xref="S9.T4.2.2.1.m1.1.1.cmml"><mi id="S9.T4.2.2.1.m1.1.1.2" xref="S9.T4.2.2.1.m1.1.1.2.cmml">γ</mi><mi id="S9.T4.2.2.1.m1.1.1.3" xref="S9.T4.2.2.1.m1.1.1.3.cmml">V</mi></msup><annotation-xml encoding="MathML-Content" id="S9.T4.2.2.1.m1.1b"><apply id="S9.T4.2.2.1.m1.1.1.cmml" xref="S9.T4.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S9.T4.2.2.1.m1.1.1.1.cmml" xref="S9.T4.2.2.1.m1.1.1">superscript</csymbol><ci id="S9.T4.2.2.1.m1.1.1.2.cmml" xref="S9.T4.2.2.1.m1.1.1.2">𝛾</ci><ci id="S9.T4.2.2.1.m1.1.1.3.cmml" xref="S9.T4.2.2.1.m1.1.1.3">𝑉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T4.2.2.1.m1.1c">\gamma^{V}</annotation><annotation encoding="application/x-llamapun" id="S9.T4.2.2.1.m1.1d">italic_γ start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT</annotation></semantics></math>, values bottleneck</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S9.T4.2.2.3">0.5</td>
</tr>
<tr class="ltx_tr" id="S9.T4.3.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S9.T4.3.3.2"><span class="ltx_text ltx_font_bold" id="S9.T4.3.3.2.1">DWAtt</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S9.T4.3.3.1">
<math alttext="{{{d}_{\textbf{\small\,pos}}}}" class="ltx_Math" display="inline" id="S9.T4.3.3.1.m1.1"><semantics id="S9.T4.3.3.1.m1.1a"><msub id="S9.T4.3.3.1.m1.1.1" xref="S9.T4.3.3.1.m1.1.1.cmml"><mi id="S9.T4.3.3.1.m1.1.1.2" xref="S9.T4.3.3.1.m1.1.1.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S9.T4.3.3.1.m1.1.1.3" mathsize="128%" xref="S9.T4.3.3.1.m1.1.1.3a.cmml"> pos</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.T4.3.3.1.m1.1b"><apply id="S9.T4.3.3.1.m1.1.1.cmml" xref="S9.T4.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S9.T4.3.3.1.m1.1.1.1.cmml" xref="S9.T4.3.3.1.m1.1.1">subscript</csymbol><ci id="S9.T4.3.3.1.m1.1.1.2.cmml" xref="S9.T4.3.3.1.m1.1.1.2">𝑑</ci><ci id="S9.T4.3.3.1.m1.1.1.3a.cmml" xref="S9.T4.3.3.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" id="S9.T4.3.3.1.m1.1.1.3.cmml" mathsize="90%" xref="S9.T4.3.3.1.m1.1.1.3"> pos</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T4.3.3.1.m1.1c">{{{d}_{\textbf{\small\,pos}}}}</annotation><annotation encoding="application/x-llamapun" id="S9.T4.3.3.1.m1.1d">italic_d start_POSTSUBSCRIPT pos end_POSTSUBSCRIPT</annotation></semantics></math>, keys latent</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S9.T4.3.3.3">24</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S9.T4.5.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S9.T4.6.2" style="font-size:90%;">Architecture Parameters</span></figcaption>
</figure>
<section class="ltx_subsection" id="S9.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">9.1.   Training</h3>
<div class="ltx_para" id="S9.SS1.p1">
<p class="ltx_p" id="S9.SS1.p1.4">inline,color=red]Update for NER.
All trainings use the AdamW <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib22" title="">2017</a>)</cite> optimizer with a linear decay learning rate (LR) schedule. Training on <span class="ltx_text ltx_font_typewriter" id="S9.SS1.p1.4.1">WikiText-2</span> uses a batch size of <math alttext="8" class="ltx_Math" display="inline" id="S9.SS1.p1.1.m1.1"><semantics id="S9.SS1.p1.1.m1.1a"><mn id="S9.SS1.p1.1.m1.1.1" xref="S9.SS1.p1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S9.SS1.p1.1.m1.1b"><cn id="S9.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S9.SS1.p1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S9.SS1.p1.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="S9.SS1.p1.1.m1.1d">8</annotation></semantics></math> samples, and a max LR of <math alttext="5\text{\times}{10}^{-5}" class="ltx_markedasmath" display="inline" id="S9.SS1.p1.2.m2.1.1.m1.3"><semantics id="S9.SS1.p1.2.m2.1.1.m1.3a"><mrow id="S9.SS1.p1.2.m2.1.1.m1.3.3.3" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml"><mn id="S9.SS1.p1.2.m2.1.1.m1.1.1.1.1.1.1.1" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml">5</mn><mtext id="S9.SS1.p1.2.m2.1.1.m1.2.2.2.2.2.2.2" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml">×</mtext><msup id="S9.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml"><mn id="S9.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.2" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml">10</mn><mrow id="S9.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.2" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml"><mo id="S9.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.2a" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml">−</mo><mn id="S9.SS1.p1.2.m2.1.1.m1.3.3.3.3.3.3.3.3.2.2" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S9.SS1.p1.2.m2.1.1.m1.3b"><csymbol cd="latexml" id="S9.SS1.p1.2.m2.1.1.m1.3.3.3.cmml" xref="S9.SS1.p1.2.m2.1.1.m1.3.3.3">5E-5</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S9.SS1.p1.2.m2.1.1.m1.3c">5\text{\times}{10}^{-5}</annotation><annotation encoding="application/x-llamapun" id="S9.SS1.p1.2.m2.1.1.m1.3d">start_ARG 5 end_ARG start_ARG times end_ARG start_ARG power start_ARG 10 end_ARG start_ARG - 5 end_ARG end_ARG</annotation></semantics></math>. Training on <span class="ltx_text ltx_font_typewriter" id="S9.SS1.p1.4.2">CoNLL-03</span> and <span class="ltx_text ltx_font_typewriter" id="S9.SS1.p1.4.3">WikiAnn</span> uses a batch size of <math alttext="16" class="ltx_Math" display="inline" id="S9.SS1.p1.3.m3.1"><semantics id="S9.SS1.p1.3.m3.1a"><mn id="S9.SS1.p1.3.m3.1.1" xref="S9.SS1.p1.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S9.SS1.p1.3.m3.1b"><cn id="S9.SS1.p1.3.m3.1.1.cmml" type="integer" xref="S9.SS1.p1.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S9.SS1.p1.3.m3.1c">16</annotation><annotation encoding="application/x-llamapun" id="S9.SS1.p1.3.m3.1d">16</annotation></semantics></math> and a max LR of <math alttext="5\text{\times}{10}^{-5}" class="ltx_markedasmath" display="inline" id="S9.SS1.p1.4.m4.1.1.m1.3"><semantics id="S9.SS1.p1.4.m4.1.1.m1.3a"><mrow id="S9.SS1.p1.4.m4.1.1.m1.3.3.3" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml"><mn id="S9.SS1.p1.4.m4.1.1.m1.1.1.1.1.1.1.1" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml">5</mn><mtext id="S9.SS1.p1.4.m4.1.1.m1.2.2.2.2.2.2.2" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml">×</mtext><msup id="S9.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml"><mn id="S9.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.2" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml">10</mn><mrow id="S9.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.2" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml"><mo id="S9.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.2a" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml">−</mo><mn id="S9.SS1.p1.4.m4.1.1.m1.3.3.3.3.3.3.3.3.2.2" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S9.SS1.p1.4.m4.1.1.m1.3b"><csymbol cd="latexml" id="S9.SS1.p1.4.m4.1.1.m1.3.3.3.cmml" xref="S9.SS1.p1.4.m4.1.1.m1.3.3.3">5E-5</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S9.SS1.p1.4.m4.1.1.m1.3c">5\text{\times}{10}^{-5}</annotation><annotation encoding="application/x-llamapun" id="S9.SS1.p1.4.m4.1.1.m1.3d">start_ARG 5 end_ARG start_ARG times end_ARG start_ARG power start_ARG 10 end_ARG start_ARG - 5 end_ARG end_ARG</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S9.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">9.2.   Layer Index Embedding</h3>
<div class="ltx_para" id="S9.SS2.p1">
<p class="ltx_p" id="S9.SS2.p1.3"><math alttext="{\mathbf{k}}^{\mathsf{\vphantom{fg}pos}}_{n}\!\in\mathbb{R}^{{{d}_{\textbf{%
\small\,pos}}}}\!\!\sim\mathcal{U}(0,1)" class="ltx_Math" display="inline" id="S9.SS2.p1.1.m1.2"><semantics id="S9.SS2.p1.1.m1.2a"><mrow id="S9.SS2.p1.1.m1.2.3" xref="S9.SS2.p1.1.m1.2.3.cmml"><msubsup id="S9.SS2.p1.1.m1.2.3.2" xref="S9.SS2.p1.1.m1.2.3.2.cmml"><mi id="S9.SS2.p1.1.m1.2.3.2.2.2" xref="S9.SS2.p1.1.m1.2.3.2.2.2.cmml">𝐤</mi><mi id="S9.SS2.p1.1.m1.2.3.2.3" xref="S9.SS2.p1.1.m1.2.3.2.3.cmml">n</mi><mi id="S9.SS2.p1.1.m1.2.3.2.2.3" xref="S9.SS2.p1.1.m1.2.3.2.2.3.cmml">𝗉𝗈𝗌</mi></msubsup><mo id="S9.SS2.p1.1.m1.2.3.3" lspace="0.108em" xref="S9.SS2.p1.1.m1.2.3.3.cmml">∈</mo><msup id="S9.SS2.p1.1.m1.2.3.4" xref="S9.SS2.p1.1.m1.2.3.4.cmml"><mi id="S9.SS2.p1.1.m1.2.3.4.2" xref="S9.SS2.p1.1.m1.2.3.4.2.cmml">ℝ</mi><msub id="S9.SS2.p1.1.m1.2.3.4.3" xref="S9.SS2.p1.1.m1.2.3.4.3.cmml"><mi id="S9.SS2.p1.1.m1.2.3.4.3.2" xref="S9.SS2.p1.1.m1.2.3.4.3.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S9.SS2.p1.1.m1.2.3.4.3.3" mathsize="180%" xref="S9.SS2.p1.1.m1.2.3.4.3.3a.cmml"> pos</mtext></msub></msup><mo id="S9.SS2.p1.1.m1.2.3.5" xref="S9.SS2.p1.1.m1.2.3.5.cmml">∼</mo><mrow id="S9.SS2.p1.1.m1.2.3.6" xref="S9.SS2.p1.1.m1.2.3.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.SS2.p1.1.m1.2.3.6.2" xref="S9.SS2.p1.1.m1.2.3.6.2.cmml">𝒰</mi><mo id="S9.SS2.p1.1.m1.2.3.6.1" xref="S9.SS2.p1.1.m1.2.3.6.1.cmml">⁢</mo><mrow id="S9.SS2.p1.1.m1.2.3.6.3.2" xref="S9.SS2.p1.1.m1.2.3.6.3.1.cmml"><mo id="S9.SS2.p1.1.m1.2.3.6.3.2.1" stretchy="false" xref="S9.SS2.p1.1.m1.2.3.6.3.1.cmml">(</mo><mn id="S9.SS2.p1.1.m1.1.1" xref="S9.SS2.p1.1.m1.1.1.cmml">0</mn><mo id="S9.SS2.p1.1.m1.2.3.6.3.2.2" xref="S9.SS2.p1.1.m1.2.3.6.3.1.cmml">,</mo><mn id="S9.SS2.p1.1.m1.2.2" xref="S9.SS2.p1.1.m1.2.2.cmml">1</mn><mo id="S9.SS2.p1.1.m1.2.3.6.3.2.3" stretchy="false" xref="S9.SS2.p1.1.m1.2.3.6.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.SS2.p1.1.m1.2b"><apply id="S9.SS2.p1.1.m1.2.3.cmml" xref="S9.SS2.p1.1.m1.2.3"><and id="S9.SS2.p1.1.m1.2.3a.cmml" xref="S9.SS2.p1.1.m1.2.3"></and><apply id="S9.SS2.p1.1.m1.2.3b.cmml" xref="S9.SS2.p1.1.m1.2.3"><in id="S9.SS2.p1.1.m1.2.3.3.cmml" xref="S9.SS2.p1.1.m1.2.3.3"></in><apply id="S9.SS2.p1.1.m1.2.3.2.cmml" xref="S9.SS2.p1.1.m1.2.3.2"><csymbol cd="ambiguous" id="S9.SS2.p1.1.m1.2.3.2.1.cmml" xref="S9.SS2.p1.1.m1.2.3.2">subscript</csymbol><apply id="S9.SS2.p1.1.m1.2.3.2.2.cmml" xref="S9.SS2.p1.1.m1.2.3.2"><csymbol cd="ambiguous" id="S9.SS2.p1.1.m1.2.3.2.2.1.cmml" xref="S9.SS2.p1.1.m1.2.3.2">superscript</csymbol><ci id="S9.SS2.p1.1.m1.2.3.2.2.2.cmml" xref="S9.SS2.p1.1.m1.2.3.2.2.2">𝐤</ci><ci id="S9.SS2.p1.1.m1.2.3.2.2.3.cmml" xref="S9.SS2.p1.1.m1.2.3.2.2.3">𝗉𝗈𝗌</ci></apply><ci id="S9.SS2.p1.1.m1.2.3.2.3.cmml" xref="S9.SS2.p1.1.m1.2.3.2.3">𝑛</ci></apply><apply id="S9.SS2.p1.1.m1.2.3.4.cmml" xref="S9.SS2.p1.1.m1.2.3.4"><csymbol cd="ambiguous" id="S9.SS2.p1.1.m1.2.3.4.1.cmml" xref="S9.SS2.p1.1.m1.2.3.4">superscript</csymbol><ci id="S9.SS2.p1.1.m1.2.3.4.2.cmml" xref="S9.SS2.p1.1.m1.2.3.4.2">ℝ</ci><apply id="S9.SS2.p1.1.m1.2.3.4.3.cmml" xref="S9.SS2.p1.1.m1.2.3.4.3"><csymbol cd="ambiguous" id="S9.SS2.p1.1.m1.2.3.4.3.1.cmml" xref="S9.SS2.p1.1.m1.2.3.4.3">subscript</csymbol><ci id="S9.SS2.p1.1.m1.2.3.4.3.2.cmml" xref="S9.SS2.p1.1.m1.2.3.4.3.2">𝑑</ci><ci id="S9.SS2.p1.1.m1.2.3.4.3.3a.cmml" xref="S9.SS2.p1.1.m1.2.3.4.3.3"><mtext class="ltx_mathvariant_bold" id="S9.SS2.p1.1.m1.2.3.4.3.3.cmml" mathsize="90%" xref="S9.SS2.p1.1.m1.2.3.4.3.3"> pos</mtext></ci></apply></apply></apply><apply id="S9.SS2.p1.1.m1.2.3c.cmml" xref="S9.SS2.p1.1.m1.2.3"><csymbol cd="latexml" id="S9.SS2.p1.1.m1.2.3.5.cmml" xref="S9.SS2.p1.1.m1.2.3.5">similar-to</csymbol><share href="https://arxiv.org/html/2209.15168v2#S9.SS2.p1.1.m1.2.3.4.cmml" id="S9.SS2.p1.1.m1.2.3d.cmml" xref="S9.SS2.p1.1.m1.2.3"></share><apply id="S9.SS2.p1.1.m1.2.3.6.cmml" xref="S9.SS2.p1.1.m1.2.3.6"><times id="S9.SS2.p1.1.m1.2.3.6.1.cmml" xref="S9.SS2.p1.1.m1.2.3.6.1"></times><ci id="S9.SS2.p1.1.m1.2.3.6.2.cmml" xref="S9.SS2.p1.1.m1.2.3.6.2">𝒰</ci><interval closure="open" id="S9.SS2.p1.1.m1.2.3.6.3.1.cmml" xref="S9.SS2.p1.1.m1.2.3.6.3.2"><cn id="S9.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S9.SS2.p1.1.m1.1.1">0</cn><cn id="S9.SS2.p1.1.m1.2.2.cmml" type="integer" xref="S9.SS2.p1.1.m1.2.2">1</cn></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.SS2.p1.1.m1.2c">{\mathbf{k}}^{\mathsf{\vphantom{fg}pos}}_{n}\!\in\mathbb{R}^{{{d}_{\textbf{%
\small\,pos}}}}\!\!\sim\mathcal{U}(0,1)</annotation><annotation encoding="application/x-llamapun" id="S9.SS2.p1.1.m1.2d">bold_k start_POSTSUPERSCRIPT sansserif_pos end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT pos end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ∼ caligraphic_U ( 0 , 1 )</annotation></semantics></math> are static positional embedding vectors of the layer index <math alttext="n" class="ltx_Math" display="inline" id="S9.SS2.p1.2.m2.1"><semantics id="S9.SS2.p1.2.m2.1a"><mi id="S9.SS2.p1.2.m2.1.1" xref="S9.SS2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S9.SS2.p1.2.m2.1b"><ci id="S9.SS2.p1.2.m2.1.1.cmml" xref="S9.SS2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.SS2.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S9.SS2.p1.2.m2.1d">italic_n</annotation></semantics></math>. <math alttext="{\mathbf{W}}^{K}" class="ltx_Math" display="inline" id="S9.SS2.p1.3.m3.1"><semantics id="S9.SS2.p1.3.m3.1a"><msup id="S9.SS2.p1.3.m3.1.1" xref="S9.SS2.p1.3.m3.1.1.cmml"><mi id="S9.SS2.p1.3.m3.1.1.2" xref="S9.SS2.p1.3.m3.1.1.2.cmml">𝐖</mi><mi id="S9.SS2.p1.3.m3.1.1.3" xref="S9.SS2.p1.3.m3.1.1.3.cmml">K</mi></msup><annotation-xml encoding="MathML-Content" id="S9.SS2.p1.3.m3.1b"><apply id="S9.SS2.p1.3.m3.1.1.cmml" xref="S9.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S9.SS2.p1.3.m3.1.1.1.cmml" xref="S9.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S9.SS2.p1.3.m3.1.1.2.cmml" xref="S9.SS2.p1.3.m3.1.1.2">𝐖</ci><ci id="S9.SS2.p1.3.m3.1.1.3.cmml" xref="S9.SS2.p1.3.m3.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.SS2.p1.3.m3.1c">{\mathbf{W}}^{K}</annotation><annotation encoding="application/x-llamapun" id="S9.SS2.p1.3.m3.1d">bold_W start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math> is a learned affine transform.</p>
<table class="ltx_equation ltx_eqn_table" id="S9.E10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\mathbf{k}}_{n}=\operatorname{\vphantom{fg}\mathsf{PE}}(n)={\color[rgb]{1,0,0%
}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{W}}^{K}}}{\mathbf{k}%
}^{\mathsf{\vphantom{fg}pos}}_{n}" class="ltx_Math" display="block" id="S9.E10.m1.2"><semantics id="S9.E10.m1.2a"><mrow id="S9.E10.m1.2.3" xref="S9.E10.m1.2.3.cmml"><msub id="S9.E10.m1.2.3.2" xref="S9.E10.m1.2.3.2.cmml"><mi id="S9.E10.m1.2.3.2.2" xref="S9.E10.m1.2.3.2.2.cmml">𝐤</mi><mi id="S9.E10.m1.2.3.2.3" xref="S9.E10.m1.2.3.2.3.cmml">n</mi></msub><mo id="S9.E10.m1.2.3.3" xref="S9.E10.m1.2.3.3.cmml">=</mo><mrow id="S9.E10.m1.2.3.4.2" xref="S9.E10.m1.2.3.4.1.cmml"><mi id="S9.E10.m1.1.1" xref="S9.E10.m1.1.1.cmml">𝖯𝖤</mi><mo id="S9.E10.m1.2.3.4.2a" xref="S9.E10.m1.2.3.4.1.cmml">⁡</mo><mrow id="S9.E10.m1.2.3.4.2.1" xref="S9.E10.m1.2.3.4.1.cmml"><mo id="S9.E10.m1.2.3.4.2.1.1" stretchy="false" xref="S9.E10.m1.2.3.4.1.cmml">(</mo><mi id="S9.E10.m1.2.2" xref="S9.E10.m1.2.2.cmml">n</mi><mo id="S9.E10.m1.2.3.4.2.1.2" stretchy="false" xref="S9.E10.m1.2.3.4.1.cmml">)</mo></mrow></mrow><mo id="S9.E10.m1.2.3.5" xref="S9.E10.m1.2.3.5.cmml">=</mo><mrow id="S9.E10.m1.2.3.6" xref="S9.E10.m1.2.3.6.cmml"><msup id="S9.E10.m1.2.3.6.2" xref="S9.E10.m1.2.3.6.2.cmml"><mi id="S9.E10.m1.2.3.6.2.2" mathcolor="#FF0000" xref="S9.E10.m1.2.3.6.2.2.cmml">𝐖</mi><mi id="S9.E10.m1.2.3.6.2.3" mathcolor="#FF0000" xref="S9.E10.m1.2.3.6.2.3.cmml">K</mi></msup><mo id="S9.E10.m1.2.3.6.1" xref="S9.E10.m1.2.3.6.1.cmml">⁢</mo><msubsup id="S9.E10.m1.2.3.6.3" xref="S9.E10.m1.2.3.6.3.cmml"><mi id="S9.E10.m1.2.3.6.3.2.2" xref="S9.E10.m1.2.3.6.3.2.2.cmml">𝐤</mi><mi id="S9.E10.m1.2.3.6.3.3" xref="S9.E10.m1.2.3.6.3.3.cmml">n</mi><mi id="S9.E10.m1.2.3.6.3.2.3" xref="S9.E10.m1.2.3.6.3.2.3.cmml">𝗉𝗈𝗌</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.E10.m1.2b"><apply id="S9.E10.m1.2.3.cmml" xref="S9.E10.m1.2.3"><and id="S9.E10.m1.2.3a.cmml" xref="S9.E10.m1.2.3"></and><apply id="S9.E10.m1.2.3b.cmml" xref="S9.E10.m1.2.3"><eq id="S9.E10.m1.2.3.3.cmml" xref="S9.E10.m1.2.3.3"></eq><apply id="S9.E10.m1.2.3.2.cmml" xref="S9.E10.m1.2.3.2"><csymbol cd="ambiguous" id="S9.E10.m1.2.3.2.1.cmml" xref="S9.E10.m1.2.3.2">subscript</csymbol><ci id="S9.E10.m1.2.3.2.2.cmml" xref="S9.E10.m1.2.3.2.2">𝐤</ci><ci id="S9.E10.m1.2.3.2.3.cmml" xref="S9.E10.m1.2.3.2.3">𝑛</ci></apply><apply id="S9.E10.m1.2.3.4.1.cmml" xref="S9.E10.m1.2.3.4.2"><ci id="S9.E10.m1.1.1.cmml" xref="S9.E10.m1.1.1">𝖯𝖤</ci><ci id="S9.E10.m1.2.2.cmml" xref="S9.E10.m1.2.2">𝑛</ci></apply></apply><apply id="S9.E10.m1.2.3c.cmml" xref="S9.E10.m1.2.3"><eq id="S9.E10.m1.2.3.5.cmml" xref="S9.E10.m1.2.3.5"></eq><share href="https://arxiv.org/html/2209.15168v2#S9.E10.m1.2.3.4.cmml" id="S9.E10.m1.2.3d.cmml" xref="S9.E10.m1.2.3"></share><apply id="S9.E10.m1.2.3.6.cmml" xref="S9.E10.m1.2.3.6"><times id="S9.E10.m1.2.3.6.1.cmml" xref="S9.E10.m1.2.3.6.1"></times><apply id="S9.E10.m1.2.3.6.2.cmml" xref="S9.E10.m1.2.3.6.2"><csymbol cd="ambiguous" id="S9.E10.m1.2.3.6.2.1.cmml" xref="S9.E10.m1.2.3.6.2">superscript</csymbol><ci id="S9.E10.m1.2.3.6.2.2.cmml" xref="S9.E10.m1.2.3.6.2.2">𝐖</ci><ci id="S9.E10.m1.2.3.6.2.3.cmml" xref="S9.E10.m1.2.3.6.2.3">𝐾</ci></apply><apply id="S9.E10.m1.2.3.6.3.cmml" xref="S9.E10.m1.2.3.6.3"><csymbol cd="ambiguous" id="S9.E10.m1.2.3.6.3.1.cmml" xref="S9.E10.m1.2.3.6.3">subscript</csymbol><apply id="S9.E10.m1.2.3.6.3.2.cmml" xref="S9.E10.m1.2.3.6.3"><csymbol cd="ambiguous" id="S9.E10.m1.2.3.6.3.2.1.cmml" xref="S9.E10.m1.2.3.6.3">superscript</csymbol><ci id="S9.E10.m1.2.3.6.3.2.2.cmml" xref="S9.E10.m1.2.3.6.3.2.2">𝐤</ci><ci id="S9.E10.m1.2.3.6.3.2.3.cmml" xref="S9.E10.m1.2.3.6.3.2.3">𝗉𝗈𝗌</ci></apply><ci id="S9.E10.m1.2.3.6.3.3.cmml" xref="S9.E10.m1.2.3.6.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E10.m1.2c">{\mathbf{k}}_{n}=\operatorname{\vphantom{fg}\mathsf{PE}}(n)={\color[rgb]{1,0,0%
}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{W}}^{K}}}{\mathbf{k}%
}^{\mathsf{\vphantom{fg}pos}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S9.E10.m1.2d">bold_k start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = start_OPFUNCTION sansserif_PE end_OPFUNCTION ( italic_n ) = bold_W start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT bold_k start_POSTSUPERSCRIPT sansserif_pos end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S9.SS3">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">9.3.   MLP Modules</h3>
<div class="ltx_para" id="S9.SS3.p1">
<p class="ltx_p" id="S9.SS3.p1.2">For each role <math alttext="\in\{Q,V\}" class="ltx_Math" display="inline" id="S9.SS3.p1.1.m1.2"><semantics id="S9.SS3.p1.1.m1.2a"><mrow id="S9.SS3.p1.1.m1.2.3" xref="S9.SS3.p1.1.m1.2.3.cmml"><mi id="S9.SS3.p1.1.m1.2.3.2" xref="S9.SS3.p1.1.m1.2.3.2.cmml"></mi><mo id="S9.SS3.p1.1.m1.2.3.1" xref="S9.SS3.p1.1.m1.2.3.1.cmml">∈</mo><mrow id="S9.SS3.p1.1.m1.2.3.3.2" xref="S9.SS3.p1.1.m1.2.3.3.1.cmml"><mo id="S9.SS3.p1.1.m1.2.3.3.2.1" stretchy="false" xref="S9.SS3.p1.1.m1.2.3.3.1.cmml">{</mo><mi id="S9.SS3.p1.1.m1.1.1" xref="S9.SS3.p1.1.m1.1.1.cmml">Q</mi><mo id="S9.SS3.p1.1.m1.2.3.3.2.2" xref="S9.SS3.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S9.SS3.p1.1.m1.2.2" xref="S9.SS3.p1.1.m1.2.2.cmml">V</mi><mo id="S9.SS3.p1.1.m1.2.3.3.2.3" stretchy="false" xref="S9.SS3.p1.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.SS3.p1.1.m1.2b"><apply id="S9.SS3.p1.1.m1.2.3.cmml" xref="S9.SS3.p1.1.m1.2.3"><in id="S9.SS3.p1.1.m1.2.3.1.cmml" xref="S9.SS3.p1.1.m1.2.3.1"></in><csymbol cd="latexml" id="S9.SS3.p1.1.m1.2.3.2.cmml" xref="S9.SS3.p1.1.m1.2.3.2">absent</csymbol><set id="S9.SS3.p1.1.m1.2.3.3.1.cmml" xref="S9.SS3.p1.1.m1.2.3.3.2"><ci id="S9.SS3.p1.1.m1.1.1.cmml" xref="S9.SS3.p1.1.m1.1.1">𝑄</ci><ci id="S9.SS3.p1.1.m1.2.2.cmml" xref="S9.SS3.p1.1.m1.2.2">𝑉</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.SS3.p1.1.m1.2c">\in\{Q,V\}</annotation><annotation encoding="application/x-llamapun" id="S9.SS3.p1.1.m1.2d">∈ { italic_Q , italic_V }</annotation></semantics></math> that uses an MLP, one is defined for a layer <math alttext="n" class="ltx_Math" display="inline" id="S9.SS3.p1.2.m2.1"><semantics id="S9.SS3.p1.2.m2.1a"><mi id="S9.SS3.p1.2.m2.1.1" xref="S9.SS3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S9.SS3.p1.2.m2.1b"><ci id="S9.SS3.p1.2.m2.1.1.cmml" xref="S9.SS3.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.SS3.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S9.SS3.p1.2.m2.1d">italic_n</annotation></semantics></math> as:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S11.EGx3">
<tbody id="S9.E11"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle f_{n}({\mathbf{x}})" class="ltx_Math" display="inline" id="S9.E11.m1.1"><semantics id="S9.E11.m1.1a"><mrow id="S9.E11.m1.1.2" xref="S9.E11.m1.1.2.cmml"><msub id="S9.E11.m1.1.2.2" xref="S9.E11.m1.1.2.2.cmml"><mi id="S9.E11.m1.1.2.2.2" xref="S9.E11.m1.1.2.2.2.cmml">f</mi><mi id="S9.E11.m1.1.2.2.3" xref="S9.E11.m1.1.2.2.3.cmml">n</mi></msub><mo id="S9.E11.m1.1.2.1" xref="S9.E11.m1.1.2.1.cmml">⁢</mo><mrow id="S9.E11.m1.1.2.3.2" xref="S9.E11.m1.1.2.cmml"><mo id="S9.E11.m1.1.2.3.2.1" stretchy="false" xref="S9.E11.m1.1.2.cmml">(</mo><mi id="S9.E11.m1.1.1" xref="S9.E11.m1.1.1.cmml">𝐱</mi><mo id="S9.E11.m1.1.2.3.2.2" stretchy="false" xref="S9.E11.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.E11.m1.1b"><apply id="S9.E11.m1.1.2.cmml" xref="S9.E11.m1.1.2"><times id="S9.E11.m1.1.2.1.cmml" xref="S9.E11.m1.1.2.1"></times><apply id="S9.E11.m1.1.2.2.cmml" xref="S9.E11.m1.1.2.2"><csymbol cd="ambiguous" id="S9.E11.m1.1.2.2.1.cmml" xref="S9.E11.m1.1.2.2">subscript</csymbol><ci id="S9.E11.m1.1.2.2.2.cmml" xref="S9.E11.m1.1.2.2.2">𝑓</ci><ci id="S9.E11.m1.1.2.2.3.cmml" xref="S9.E11.m1.1.2.2.3">𝑛</ci></apply><ci id="S9.E11.m1.1.1.cmml" xref="S9.E11.m1.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E11.m1.1c">\displaystyle f_{n}({\mathbf{x}})</annotation><annotation encoding="application/x-llamapun" id="S9.E11.m1.1d">italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( bold_x )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{{\mathbf{W}}_{n}}}\cdot\operatorname*{\vphantom{fg}\mathsf{LN}}\left(%
\operatorname{\vphantom{fg}\mathsf{gelu}}\left({\color[rgb]{1,0,0}\definecolor%
[named]{pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{U}}_{n}}}~{}{\mathbf{x}}\right)\right)" class="ltx_Math" display="inline" id="S9.E11.m2.3"><semantics id="S9.E11.m2.3a"><mrow id="S9.E11.m2.3.3" xref="S9.E11.m2.3.3.cmml"><mi id="S9.E11.m2.3.3.3" xref="S9.E11.m2.3.3.3.cmml"></mi><mo id="S9.E11.m2.3.3.2" xref="S9.E11.m2.3.3.2.cmml">=</mo><mrow id="S9.E11.m2.3.3.1" xref="S9.E11.m2.3.3.1.cmml"><msub id="S9.E11.m2.3.3.1.3" xref="S9.E11.m2.3.3.1.3.cmml"><mi id="S9.E11.m2.3.3.1.3.2" mathcolor="#FF0000" xref="S9.E11.m2.3.3.1.3.2.cmml">𝐖</mi><mi id="S9.E11.m2.3.3.1.3.3" mathcolor="#FF0000" xref="S9.E11.m2.3.3.1.3.3.cmml">n</mi></msub><mo id="S9.E11.m2.3.3.1.2" lspace="0.222em" xref="S9.E11.m2.3.3.1.2.cmml">⋅</mo><mrow id="S9.E11.m2.3.3.1.1.1" xref="S9.E11.m2.3.3.1.1.2.cmml"><mo id="S9.E11.m2.2.2" lspace="0.055em" rspace="0em" xref="S9.E11.m2.2.2.cmml">𝖫𝖭</mo><mrow id="S9.E11.m2.3.3.1.1.1.1" xref="S9.E11.m2.3.3.1.1.2.cmml"><mo id="S9.E11.m2.3.3.1.1.1.1.2" xref="S9.E11.m2.3.3.1.1.2.cmml">(</mo><mrow id="S9.E11.m2.3.3.1.1.1.1.1.1" xref="S9.E11.m2.3.3.1.1.1.1.1.2.cmml"><mi id="S9.E11.m2.1.1" xref="S9.E11.m2.1.1.cmml">𝗀𝖾𝗅𝗎</mi><mo id="S9.E11.m2.3.3.1.1.1.1.1.1a" xref="S9.E11.m2.3.3.1.1.1.1.1.2.cmml">⁡</mo><mrow id="S9.E11.m2.3.3.1.1.1.1.1.1.1" xref="S9.E11.m2.3.3.1.1.1.1.1.2.cmml"><mo id="S9.E11.m2.3.3.1.1.1.1.1.1.1.2" xref="S9.E11.m2.3.3.1.1.1.1.1.2.cmml">(</mo><mrow id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.2" mathcolor="#FF0000" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.2.cmml">𝐔</mi><mi id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.3" mathcolor="#FF0000" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.1" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.3" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.3.cmml">𝐱</mi></mrow><mo id="S9.E11.m2.3.3.1.1.1.1.1.1.1.3" xref="S9.E11.m2.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S9.E11.m2.3.3.1.1.1.1.3" xref="S9.E11.m2.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.E11.m2.3b"><apply id="S9.E11.m2.3.3.cmml" xref="S9.E11.m2.3.3"><eq id="S9.E11.m2.3.3.2.cmml" xref="S9.E11.m2.3.3.2"></eq><csymbol cd="latexml" id="S9.E11.m2.3.3.3.cmml" xref="S9.E11.m2.3.3.3">absent</csymbol><apply id="S9.E11.m2.3.3.1.cmml" xref="S9.E11.m2.3.3.1"><ci id="S9.E11.m2.3.3.1.2.cmml" xref="S9.E11.m2.3.3.1.2">⋅</ci><apply id="S9.E11.m2.3.3.1.3.cmml" xref="S9.E11.m2.3.3.1.3"><csymbol cd="ambiguous" id="S9.E11.m2.3.3.1.3.1.cmml" xref="S9.E11.m2.3.3.1.3">subscript</csymbol><ci id="S9.E11.m2.3.3.1.3.2.cmml" xref="S9.E11.m2.3.3.1.3.2">𝐖</ci><ci id="S9.E11.m2.3.3.1.3.3.cmml" xref="S9.E11.m2.3.3.1.3.3">𝑛</ci></apply><apply id="S9.E11.m2.3.3.1.1.2.cmml" xref="S9.E11.m2.3.3.1.1.1"><ci id="S9.E11.m2.2.2.cmml" xref="S9.E11.m2.2.2">𝖫𝖭</ci><apply id="S9.E11.m2.3.3.1.1.1.1.1.2.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1"><ci id="S9.E11.m2.1.1.cmml" xref="S9.E11.m2.1.1">𝗀𝖾𝗅𝗎</ci><apply id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1"><times id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.1"></times><apply id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.2">𝐔</ci><ci id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.2.3">𝑛</ci></apply><ci id="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S9.E11.m2.3.3.1.1.1.1.1.1.1.1.3">𝐱</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E11.m2.3c">\displaystyle={\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
1,0,0}{{\mathbf{W}}_{n}}}\cdot\operatorname*{\vphantom{fg}\mathsf{LN}}\left(%
\operatorname{\vphantom{fg}\mathsf{gelu}}\left({\color[rgb]{1,0,0}\definecolor%
[named]{pgfstrokecolor}{rgb}{1,0,0}{{\mathbf{U}}_{n}}}~{}{\mathbf{x}}\right)\right)</annotation><annotation encoding="application/x-llamapun" id="S9.E11.m2.3d">= bold_W start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ⋅ start_OPERATOR sansserif_LN end_OPERATOR ( start_OPFUNCTION sansserif_gelu end_OPFUNCTION ( bold_U start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT bold_x ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S9.SS3.p1.6">Where <math alttext="{\mathbf{U}}_{n},{\mathbf{W}}_{n}" class="ltx_Math" display="inline" id="S9.SS3.p1.3.m1.2"><semantics id="S9.SS3.p1.3.m1.2a"><mrow id="S9.SS3.p1.3.m1.2.2.2" xref="S9.SS3.p1.3.m1.2.2.3.cmml"><msub id="S9.SS3.p1.3.m1.1.1.1.1" xref="S9.SS3.p1.3.m1.1.1.1.1.cmml"><mi id="S9.SS3.p1.3.m1.1.1.1.1.2" xref="S9.SS3.p1.3.m1.1.1.1.1.2.cmml">𝐔</mi><mi id="S9.SS3.p1.3.m1.1.1.1.1.3" xref="S9.SS3.p1.3.m1.1.1.1.1.3.cmml">n</mi></msub><mo id="S9.SS3.p1.3.m1.2.2.2.3" xref="S9.SS3.p1.3.m1.2.2.3.cmml">,</mo><msub id="S9.SS3.p1.3.m1.2.2.2.2" xref="S9.SS3.p1.3.m1.2.2.2.2.cmml"><mi id="S9.SS3.p1.3.m1.2.2.2.2.2" xref="S9.SS3.p1.3.m1.2.2.2.2.2.cmml">𝐖</mi><mi id="S9.SS3.p1.3.m1.2.2.2.2.3" xref="S9.SS3.p1.3.m1.2.2.2.2.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S9.SS3.p1.3.m1.2b"><list id="S9.SS3.p1.3.m1.2.2.3.cmml" xref="S9.SS3.p1.3.m1.2.2.2"><apply id="S9.SS3.p1.3.m1.1.1.1.1.cmml" xref="S9.SS3.p1.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S9.SS3.p1.3.m1.1.1.1.1.1.cmml" xref="S9.SS3.p1.3.m1.1.1.1.1">subscript</csymbol><ci id="S9.SS3.p1.3.m1.1.1.1.1.2.cmml" xref="S9.SS3.p1.3.m1.1.1.1.1.2">𝐔</ci><ci id="S9.SS3.p1.3.m1.1.1.1.1.3.cmml" xref="S9.SS3.p1.3.m1.1.1.1.1.3">𝑛</ci></apply><apply id="S9.SS3.p1.3.m1.2.2.2.2.cmml" xref="S9.SS3.p1.3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S9.SS3.p1.3.m1.2.2.2.2.1.cmml" xref="S9.SS3.p1.3.m1.2.2.2.2">subscript</csymbol><ci id="S9.SS3.p1.3.m1.2.2.2.2.2.cmml" xref="S9.SS3.p1.3.m1.2.2.2.2.2">𝐖</ci><ci id="S9.SS3.p1.3.m1.2.2.2.2.3.cmml" xref="S9.SS3.p1.3.m1.2.2.2.2.3">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S9.SS3.p1.3.m1.2c">{\mathbf{U}}_{n},{\mathbf{W}}_{n}</annotation><annotation encoding="application/x-llamapun" id="S9.SS3.p1.3.m1.2d">bold_U start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , bold_W start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> are the down and up projections of the bottleneck (<math alttext="{{d}_{\textbf{\small\,z}}}\mapsto\gamma{{d}_{\textbf{\small\,z}}}\mapsto{{d}_{%
\textbf{\small\,z}}}" class="ltx_Math" display="inline" id="S9.SS3.p1.4.m2.1"><semantics id="S9.SS3.p1.4.m2.1a"><mrow id="S9.SS3.p1.4.m2.1.1" xref="S9.SS3.p1.4.m2.1.1.cmml"><msub id="S9.SS3.p1.4.m2.1.1.2" xref="S9.SS3.p1.4.m2.1.1.2.cmml"><mi id="S9.SS3.p1.4.m2.1.1.2.2" xref="S9.SS3.p1.4.m2.1.1.2.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S9.SS3.p1.4.m2.1.1.2.3" mathsize="128%" xref="S9.SS3.p1.4.m2.1.1.2.3a.cmml"> z</mtext></msub><mo id="S9.SS3.p1.4.m2.1.1.3" stretchy="false" xref="S9.SS3.p1.4.m2.1.1.3.cmml">↦</mo><mrow id="S9.SS3.p1.4.m2.1.1.4" xref="S9.SS3.p1.4.m2.1.1.4.cmml"><mi id="S9.SS3.p1.4.m2.1.1.4.2" xref="S9.SS3.p1.4.m2.1.1.4.2.cmml">γ</mi><mo id="S9.SS3.p1.4.m2.1.1.4.1" xref="S9.SS3.p1.4.m2.1.1.4.1.cmml">⁢</mo><msub id="S9.SS3.p1.4.m2.1.1.4.3" xref="S9.SS3.p1.4.m2.1.1.4.3.cmml"><mi id="S9.SS3.p1.4.m2.1.1.4.3.2" xref="S9.SS3.p1.4.m2.1.1.4.3.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S9.SS3.p1.4.m2.1.1.4.3.3" mathsize="128%" xref="S9.SS3.p1.4.m2.1.1.4.3.3a.cmml"> z</mtext></msub></mrow><mo id="S9.SS3.p1.4.m2.1.1.5" stretchy="false" xref="S9.SS3.p1.4.m2.1.1.5.cmml">↦</mo><msub id="S9.SS3.p1.4.m2.1.1.6" xref="S9.SS3.p1.4.m2.1.1.6.cmml"><mi id="S9.SS3.p1.4.m2.1.1.6.2" xref="S9.SS3.p1.4.m2.1.1.6.2.cmml">d</mi><mtext class="ltx_mathvariant_bold" id="S9.SS3.p1.4.m2.1.1.6.3" mathsize="128%" xref="S9.SS3.p1.4.m2.1.1.6.3a.cmml"> z</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S9.SS3.p1.4.m2.1b"><apply id="S9.SS3.p1.4.m2.1.1.cmml" xref="S9.SS3.p1.4.m2.1.1"><and id="S9.SS3.p1.4.m2.1.1a.cmml" xref="S9.SS3.p1.4.m2.1.1"></and><apply id="S9.SS3.p1.4.m2.1.1b.cmml" xref="S9.SS3.p1.4.m2.1.1"><csymbol cd="latexml" id="S9.SS3.p1.4.m2.1.1.3.cmml" xref="S9.SS3.p1.4.m2.1.1.3">maps-to</csymbol><apply id="S9.SS3.p1.4.m2.1.1.2.cmml" xref="S9.SS3.p1.4.m2.1.1.2"><csymbol cd="ambiguous" id="S9.SS3.p1.4.m2.1.1.2.1.cmml" xref="S9.SS3.p1.4.m2.1.1.2">subscript</csymbol><ci id="S9.SS3.p1.4.m2.1.1.2.2.cmml" xref="S9.SS3.p1.4.m2.1.1.2.2">𝑑</ci><ci id="S9.SS3.p1.4.m2.1.1.2.3a.cmml" xref="S9.SS3.p1.4.m2.1.1.2.3"><mtext class="ltx_mathvariant_bold" id="S9.SS3.p1.4.m2.1.1.2.3.cmml" mathsize="90%" xref="S9.SS3.p1.4.m2.1.1.2.3"> z</mtext></ci></apply><apply id="S9.SS3.p1.4.m2.1.1.4.cmml" xref="S9.SS3.p1.4.m2.1.1.4"><times id="S9.SS3.p1.4.m2.1.1.4.1.cmml" xref="S9.SS3.p1.4.m2.1.1.4.1"></times><ci id="S9.SS3.p1.4.m2.1.1.4.2.cmml" xref="S9.SS3.p1.4.m2.1.1.4.2">𝛾</ci><apply id="S9.SS3.p1.4.m2.1.1.4.3.cmml" xref="S9.SS3.p1.4.m2.1.1.4.3"><csymbol cd="ambiguous" id="S9.SS3.p1.4.m2.1.1.4.3.1.cmml" xref="S9.SS3.p1.4.m2.1.1.4.3">subscript</csymbol><ci id="S9.SS3.p1.4.m2.1.1.4.3.2.cmml" xref="S9.SS3.p1.4.m2.1.1.4.3.2">𝑑</ci><ci id="S9.SS3.p1.4.m2.1.1.4.3.3a.cmml" xref="S9.SS3.p1.4.m2.1.1.4.3.3"><mtext class="ltx_mathvariant_bold" id="S9.SS3.p1.4.m2.1.1.4.3.3.cmml" mathsize="90%" xref="S9.SS3.p1.4.m2.1.1.4.3.3"> z</mtext></ci></apply></apply></apply><apply id="S9.SS3.p1.4.m2.1.1c.cmml" xref="S9.SS3.p1.4.m2.1.1"><csymbol cd="latexml" id="S9.SS3.p1.4.m2.1.1.5.cmml" xref="S9.SS3.p1.4.m2.1.1.5">maps-to</csymbol><share href="https://arxiv.org/html/2209.15168v2#S9.SS3.p1.4.m2.1.1.4.cmml" id="S9.SS3.p1.4.m2.1.1d.cmml" xref="S9.SS3.p1.4.m2.1.1"></share><apply id="S9.SS3.p1.4.m2.1.1.6.cmml" xref="S9.SS3.p1.4.m2.1.1.6"><csymbol cd="ambiguous" id="S9.SS3.p1.4.m2.1.1.6.1.cmml" xref="S9.SS3.p1.4.m2.1.1.6">subscript</csymbol><ci id="S9.SS3.p1.4.m2.1.1.6.2.cmml" xref="S9.SS3.p1.4.m2.1.1.6.2">𝑑</ci><ci id="S9.SS3.p1.4.m2.1.1.6.3a.cmml" xref="S9.SS3.p1.4.m2.1.1.6.3"><mtext class="ltx_mathvariant_bold" id="S9.SS3.p1.4.m2.1.1.6.3.cmml" mathsize="90%" xref="S9.SS3.p1.4.m2.1.1.6.3"> z</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.SS3.p1.4.m2.1c">{{d}_{\textbf{\small\,z}}}\mapsto\gamma{{d}_{\textbf{\small\,z}}}\mapsto{{d}_{%
\textbf{\small\,z}}}</annotation><annotation encoding="application/x-llamapun" id="S9.SS3.p1.4.m2.1d">italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT ↦ italic_γ italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT ↦ italic_d start_POSTSUBSCRIPT z end_POSTSUBSCRIPT</annotation></semantics></math>), respectively. This means, for example, that for value transforms one set of weights is assigned to each layer <math alttext="n" class="ltx_Math" display="inline" id="S9.SS3.p1.5.m3.1"><semantics id="S9.SS3.p1.5.m3.1a"><mi id="S9.SS3.p1.5.m3.1.1" xref="S9.SS3.p1.5.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S9.SS3.p1.5.m3.1b"><ci id="S9.SS3.p1.5.m3.1.1.cmml" xref="S9.SS3.p1.5.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.SS3.p1.5.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S9.SS3.p1.5.m3.1d">italic_n</annotation></semantics></math> with nothing shared. <math alttext="\operatorname{\vphantom{fg}\mathsf{gelu}}" class="ltx_Math" display="inline" id="S9.SS3.p1.6.m4.1"><semantics id="S9.SS3.p1.6.m4.1a"><mi id="S9.SS3.p1.6.m4.1.1" xref="S9.SS3.p1.6.m4.1.1.cmml">𝗀𝖾𝗅𝗎</mi><annotation-xml encoding="MathML-Content" id="S9.SS3.p1.6.m4.1b"><ci id="S9.SS3.p1.6.m4.1.1.cmml" xref="S9.SS3.p1.6.m4.1.1">𝗀𝖾𝗅𝗎</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.SS3.p1.6.m4.1c">\operatorname{\vphantom{fg}\mathsf{gelu}}</annotation><annotation encoding="application/x-llamapun" id="S9.SS3.p1.6.m4.1d">sansserif_gelu</annotation></semantics></math> is the activation function from <cite class="ltx_cite ltx_citemacro_citet">Hendrycks and Gimpel (<a class="ltx_ref" href="https://arxiv.org/html/2209.15168v2#bib.bib14" title="">2016</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">10.   Conclusion &amp; Future Work</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.3">inline,color=yellow]@bkhmsi - Review.
We present <span class="ltx_text ltx_font_typewriter" id="S10.p1.3.1">DWAtt</span>—a new method of reusing the latent representations of a deep neural network.
We analyze <span class="ltx_text ltx_font_typewriter" id="S10.p1.3.2">DWAtt</span> and a similar, simpler method—<span class="ltx_text ltx_font_typewriter" id="S10.p1.3.3">Concat</span>—from multiple aspects of performance and scaling on NER and MLM tasks.
Results suggest similar layer fusion methods can be a strong tool for downstream adaptation. Performance gains from <math alttext="1\%" class="ltx_Math" display="inline" id="S10.p1.1.m1.1"><semantics id="S10.p1.1.m1.1a"><mrow id="S10.p1.1.m1.1.1" xref="S10.p1.1.m1.1.1.cmml"><mn id="S10.p1.1.m1.1.1.2" xref="S10.p1.1.m1.1.1.2.cmml">1</mn><mo id="S10.p1.1.m1.1.1.1" xref="S10.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.1.m1.1b"><apply id="S10.p1.1.m1.1.1.cmml" xref="S10.p1.1.m1.1.1"><csymbol cd="latexml" id="S10.p1.1.m1.1.1.1.cmml" xref="S10.p1.1.m1.1.1.1">percent</csymbol><cn id="S10.p1.1.m1.1.1.2.cmml" type="integer" xref="S10.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="S10.p1.1.m1.1d">1 %</annotation></semantics></math> to <math alttext="6\%" class="ltx_Math" display="inline" id="S10.p1.2.m2.1"><semantics id="S10.p1.2.m2.1a"><mrow id="S10.p1.2.m2.1.1" xref="S10.p1.2.m2.1.1.cmml"><mn id="S10.p1.2.m2.1.1.2" xref="S10.p1.2.m2.1.1.2.cmml">6</mn><mo id="S10.p1.2.m2.1.1.1" xref="S10.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.2.m2.1b"><apply id="S10.p1.2.m2.1.1.cmml" xref="S10.p1.2.m2.1.1"><csymbol cd="latexml" id="S10.p1.2.m2.1.1.1.cmml" xref="S10.p1.2.m2.1.1.1">percent</csymbol><cn id="S10.p1.2.m2.1.1.2.cmml" type="integer" xref="S10.p1.2.m2.1.1.2">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.2.m2.1c">6\%</annotation><annotation encoding="application/x-llamapun" id="S10.p1.2.m2.1d">6 %</annotation></semantics></math> and as high as <math alttext="30\%" class="ltx_Math" display="inline" id="S10.p1.3.m3.1"><semantics id="S10.p1.3.m3.1a"><mrow id="S10.p1.3.m3.1.1" xref="S10.p1.3.m3.1.1.cmml"><mn id="S10.p1.3.m3.1.1.2" xref="S10.p1.3.m3.1.1.2.cmml">30</mn><mo id="S10.p1.3.m3.1.1.1" xref="S10.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.3.m3.1b"><apply id="S10.p1.3.m3.1.1.cmml" xref="S10.p1.3.m3.1.1"><csymbol cd="latexml" id="S10.p1.3.m3.1.1.1.cmml" xref="S10.p1.3.m3.1.1.1">percent</csymbol><cn id="S10.p1.3.m3.1.1.2.cmml" type="integer" xref="S10.p1.3.m3.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.3.m3.1c">30\%</annotation><annotation encoding="application/x-llamapun" id="S10.p1.3.m3.1d">30 %</annotation></semantics></math> can be seen in various experiments for different few-shot sizes and training times, under Finetuning or Feature Extraction, and on base models of different depths. <span class="ltx_text ltx_font_typewriter" id="S10.p1.3.4">DWAtt</span> and <span class="ltx_text ltx_font_typewriter" id="S10.p1.3.5">Concat</span> have shown improved performance even in Feature Extraction training against full Finetuning.
We believe this effect may extend to other tasks besides sequence labeling and to other sequence modeling architectures besides the Transformer—and propose such analysis for future work.
We believe <em class="ltx_emph ltx_font_italic" id="S10.p1.3.6">add-on</em>-style additions to pretrained models, such as adapters and depth-wise mixing, to be a fertile ground for research into low-cost adaptation of large models that has not been saturated yet.</p>
</div>
</section>
<section class="ltx_section" id="S11">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">11.   Bibliographical References</h2>
<div class="ltx_para" id="S11.p1">
<span class="ltx_ERROR undefined" id="S11.p1.1">\c@NAT@ctr</span>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography"></h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AlKhamissi et al. (2021)</span>
<span class="ltx_bibblock">
Badr AlKhamissi, Mohamed Gabr, Muhammad ElNokrashy, and Khaled Essam. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.wanlp-1.29" title="">Adapting marbert for improved arabic dialect identification: Submission to the nadi 2021 shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the Sixth Arabic Natural Language Processing Workshop</em>, page 260–264. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ba et al. (2016)</span>
<span class="ltx_bibblock">
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.1607.06450" title="">Layer normalization</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bapna et al. (2018)</span>
<span class="ltx_bibblock">
Ankur Bapna, Mia Xu Chen, Orhan Firat, Yuan Cao, and Yonghui Wu. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1808.07561" title="">Training deeper neural machine translation models with transparent attention</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">CoRR</em>, abs/1808.07561.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben-Zaken et al. (2022)</span>
<span class="ltx_bibblock">
Elad Ben-Zaken, Shauli Ravfogel, and Yoav Goldberg. 2022.

</span>
<span class="ltx_bibblock">Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">ACL</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Advances in Neural Information Processing Systems</em>, volume 33, pages 1877–1901. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clevert et al. (2015)</span>
<span class="ltx_bibblock">
Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.1511.07289" title="">Fast and accurate deep network learning by exponential linear units (elus)</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2019)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1911.02116" title="">Unsupervised cross-lingual representation learning at scale</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CoRR</em>, abs/1911.02116.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dehghani et al. (2019)</span>
<span class="ltx_bibblock">
Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser. 2019.

</span>
<span class="ltx_bibblock">Universal transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">ArXiv</em>, abs/1807.03819.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" title="">BERT: Pre-training of deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dou et al. (2019)</span>
<span class="ltx_bibblock">
Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Longyue Wang, Shuming Shi, and Tong Zhang. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1902.05770" title="">Dynamic layer aggregation for neural machine translation with routing-by-agreement</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">CoRR</em>, abs/1902.05770.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. (2020)</span>
<span class="ltx_bibblock">
Angela Fan, Thibaut Lavril, Edouard Grave, Armand Joulin, and Sainbayar Sukhbaatar. 2020.

</span>
<span class="ltx_bibblock">Accessing higher-level representations in sequential transformers with feedback memory.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">ArXiv</em>, abs/2002.09402.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. (2014)</span>
<span class="ltx_bibblock">
Alex Graves, Greg Wayne, and Ivo Danihelka. 2014.

</span>
<span class="ltx_bibblock">Neural turing machines.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">ArXiv</em>, abs/1410.5401.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. 2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 770–778.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks and Gimpel (2016)</span>
<span class="ltx_bibblock">
Dan Hendrycks and Kevin Gimpel. 2016.

</span>
<span class="ltx_bibblock">Bridging nonlinearities and stochastic regularizers with gaussian error linear units.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ArXiv</em>, abs/1606.08415.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Houlsby et al. (2019)</span>
<span class="ltx_bibblock">
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019.

</span>
<span class="ltx_bibblock">Parameter-efficient transfer learning for nlp.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">ICML</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2016)</span>
<span class="ltx_bibblock">
Gao Huang, Zhuang Liu, and Kilian Q. Weinberger. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1608.06993" title="">Densely connected convolutional networks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">CoRR</em>, abs/1608.06993.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7871–7880, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2018)</span>
<span class="ltx_bibblock">
Jinyu Li, Changliang Liu, and Yifan Gong. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1808.09522" title="">Layer trajectory lstm</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv</em>, abs/1808.09522.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Fenglin Liu, Xuancheng Ren, Guangxiang Zhao, and Xu Sun. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2005.08081" title="">Layer-wise cross-view decoding for sequence-to-sequence learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">CoRR</em>, abs/2005.08081.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Xuebo Liu, Longyue Wang, Derek F. Wong, Liang Ding, Lidia S. Chao, and Zhaopeng Tu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=n1HD8M6WGn" title="">Understanding and improving encoder layer fusion in sequence-to-sequence learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, M. Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Roberta: A robustly optimized bert pretraining approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">ArXiv</em>, abs/1907.11692.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.1711.05101" title="">Decoupled weight decay regularization</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merity et al. (2017)</span>
<span class="ltx_bibblock">
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2017.

</span>
<span class="ltx_bibblock">Pointer sentinel mixture models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ArXiv</em>, abs/1609.07843.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakayama (2018)</span>
<span class="ltx_bibblock">
Hiroki Nakayama. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/chakki-works/seqeval" title="">seqeval: A python framework for sequence labeling evaluation</a>.

</span>
<span class="ltx_bibblock">Software available from https://github.com/chakki-works/seqeval.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nøkland (2016)</span>
<span class="ltx_bibblock">
Arild Nøkland. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.1609.01596" title="">Direct feedback alignment provides learning in deep neural networks</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rahimi et al. (2019)</span>
<span class="ltx_bibblock">
Afshin Rahimi, Yuan Li, and Trevor Cohn. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.aclweb.org/anthology/P19-1015" title="">Massively multilingual transfer for NER</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 151–164, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. (2018)</span>
<span class="ltx_bibblock">
Yanyao Shen, Xu Tan, Di He, Tao Qin, and Tie-Yan Liu. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1806.00722" title="">Dense information flow for neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">CoRR</em>, abs/1806.00722.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tjong Kim Sang and De Meulder (2003)</span>
<span class="ltx_bibblock">
Erik F. Tjong Kim Sang and Fien De Meulder. 2003.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.aclweb.org/anthology/W03-0419" title="">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</em>, pages 142–147.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, undefinedukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 31st International Conference on Neural Information Processing Systems</em>, NIPS’17, page 6000–6010, Red Hook, NY, USA. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wallat et al. (2021)</span>
<span class="ltx_bibblock">
Jonas Wallat, Jaspreet Singh, and Avishek Anand. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2106.02902" title="">BERTnesia: Investigating the capture and forgetting of knowledge in BERT</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv:2106.02902 [cs]</em>.

</span>
<span class="ltx_bibblock">ArXiv: 2106.02902.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2019a)</span>
<span class="ltx_bibblock">
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1905.00537" title="">Superglue: A stickier benchmark for general-purpose language understanding systems</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">CoRR</em>, abs/1905.00537.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2018a)</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2018a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1804.07461" title="">GLUE: A multi-task benchmark and analysis platform for natural language understanding</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">CoRR</em>, abs/1804.07461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2019b)</span>
<span class="ltx_bibblock">
Qiang Wang, Bei Li, Tong Xiao, Jingbo Zhu, Changliang Li, Derek F. Wong, and Lidia S. Chao. 2019b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1906.01787" title="">Learning deep transformer models for machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">CoRR</em>, abs/1906.01787.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2018b)</span>
<span class="ltx_bibblock">
Qiang Wang, Fuxue Li, Tong Xiao, Yanyang Li, Yinqiao Li, and Jingbo Zhu. 2018b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.aclweb.org/anthology/C18-1255.pdf" title="">Multi-layer representation fusion for neural machine translation</a>.

</span>
<span class="ltx_bibblock">pages 3015–3026.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waskom (2021)</span>
<span class="ltx_bibblock">
Michael L. Waskom. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.21105/joss.03021" title="">seaborn: statistical data visualization</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Journal of Open Source Software</em>, 6(60):3021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al. (2019)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R’emi Louf, Morgan Funtowicz, and Jamie Brew. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1910.03771" title="">Huggingface’s transformers: State-of-the-art natural language processing</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">ArXiv</em>, abs/1910.03771.

</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="Layer Fusion, Transformers, Named Entity Recognition, Few-shot Learning" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="cs.CL" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="
Depth-Wise Attention (DWAtt): \\
A Layer Fusion Method for Data-Efficient Classification
" property="dcterms:title"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue May 14 19:44:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
