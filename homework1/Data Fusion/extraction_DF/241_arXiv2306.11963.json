{
    "S2.T1.5.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.1.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.1.1\">Modality</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.2.1\">Datatype</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.3.1\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.4.1\">No. of Instances</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.5.1\">No. of Attributes</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.6.1\">Task</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S2.T1.5.1.1.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S2.T1.5.1.1.1.7.1\">Popularity*</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.1\" rowspan=\"14\">\n<span class=\"ltx_text\" id=\"S2.T1.5.1.2.2.1.1\">Single Modality</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.2\" rowspan=\"2\">\n<span class=\"ltx_text\" id=\"S2.T1.5.1.2.2.2.1\">EHR</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.2.2.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.3.1.1.1\">eICU Collaborative</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.3.1.2.1\">Research Database&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib32\" title=\"\">32</a>]</cite>\n</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.4\">200,000 admissions</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.5\">Varies</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.6\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.2.2.6.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.6.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.6.1.1.1\">Various tasks, mainly</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.6.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.6.1.2.1\">diagnosis and prognosis</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.2.2.7\">Medium</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.3.3\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.3.3.1\">MIMIC-III&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib33\" title=\"\">33</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.3.3.2\">40,000 patients</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.3.3.3\">Varies</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.3.3.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.3.3.4.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.3.3.4.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.3.3.4.1.1.1\">Various tasks, mainly</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.3.3.4.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.3.3.4.1.2.1\">diagnosis and prognosis</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.3.3.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.4.4\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.4.4.1\" rowspan=\"12\">\n<span class=\"ltx_text\" id=\"S2.T1.5.1.4.4.1.1\">Imaging</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.4.4.2\">MRNet&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib34\" title=\"\">34</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.4.4.3\">1,370 exams</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.4.4.4\">MRI data</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.4.4.5\">Disease detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.4.4.6\">Low</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.5.5\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.5.5.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.5.5.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.5.5.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.5.5.1.1.1.1\">RSNA Pneumonia</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.5.5.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.5.5.1.1.2.1\">Detection Challenge&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib35\" title=\"\">35</a>]</cite>\n</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.5.5.2\">30,000 images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.5.5.3\">Pneumonia labels</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.5.5.4\">Disease detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.5.5.5\">Low</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.6.6\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.6.6.1\">MURA&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib36\" title=\"\">36</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.6.6.2\">40,895 images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.6.6.3\">Abnormal/normal</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.6.6.4\">Disease detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.6.6.5\">Medium</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.7.7\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.7.7.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.7.7.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.7.7.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.7.7.1.1.1.1\">Pediatric Bone Age</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.7.7.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.7.7.1.1.2.1\">Challenge Dataset&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib37\" title=\"\">37</a>]</cite>\n</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.7.7.2\">Thousands of images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.7.7.3\">Bone age</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.7.7.4\">Bone age estimation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.7.7.5\">Medium</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.8.8.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.8.8.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.1.1.1.1\">Indiana University Chest</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.1.1.2.1\">X-ray Collection&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib38\" title=\"\">38</a>]</cite>\n</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.8.8.2\">8,000 images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.8.8.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.8.8.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.3.1.1.1\">Chest radiograph</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.3.1.2.1\">DICOM images</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.8.8.4\">Various tasks</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.8.8.5\">Medium</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.9.9\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.9.9.1\">FastMRI&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib39\" title=\"\">39</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.9.9.2\">Thousands of scans</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.9.9.3\">MRI data</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.9.9.4\">Image reconstruction</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.9.9.5\">Medium</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.10.10\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.10.10.1\">CheXpert&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib40\" title=\"\">40</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.10.10.2\">224,316 images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.10.10.3\">14 labels per image</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.10.10.4\">Disease detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.10.10.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.11.11\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.11.11.1\">OASIS Brains Project&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib41\" title=\"\">41</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.11.11.2\">Varies with dataset</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.11.11.3\">MRI and clinical data</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.11.11.4\">Brain studies</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.11.11.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.12.12\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.12.12.1\">LIDC-IDRI&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib42\" title=\"\">42</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.12.12.2\">Over 1,000 patients</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.12.12.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.12.12.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.12.12.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.12.12.3.1.1.1\">CT scans with marked-up</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.12.12.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.12.12.3.1.2.1\">annotated lesions</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.12.12.4\">Nodule detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.12.12.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.13.13\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.13.13.1\">TCIA&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib43\" title=\"\">43</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.13.13.2\">Millions of images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.13.13.3\">Various data types</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.13.13.4\">Cancer research</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.13.13.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.14.14\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.14.14.1\">ChestX-ray8&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib44\" title=\"\">44</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.14.14.2\">108,948 images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.14.14.3\">8 labels per image</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.14.14.4\">Disease detection</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.14.14.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.15.15\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.15.15.1\">BraTS&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib45\" title=\"\">45</a>, <a class=\"ltx_ref\" href=\"#bib.bib46\" title=\"\">46</a>, <a class=\"ltx_ref\" href=\"#bib.bib47\" title=\"\">47</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.15.15.2\">Varies annually</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.15.15.3\">MRI data</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.15.15.4\">Tumor segmentation</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.15.15.5\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.16.16\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.16.16.1\" rowspan=\"6\">\n<span class=\"ltx_text\" id=\"S2.T1.5.1.16.16.1.1\">Multimodality</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.16.16.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.16.16.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.16.16.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.16.16.2.1.1.1\">Genomics,</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.16.16.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.16.16.2.1.2.1\">Imaging</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.16.16.3\">TCGA&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib48\" title=\"\">48</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.16.16.4\">Thousands of patients</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.16.16.5\">Genomic and clinical data</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.16.16.6\">Cancer research</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.16.16.7\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.17.17\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.17.17.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.17.17.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.17.17.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.17.17.1.1.1.1\">Genomics,</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.17.17.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.17.17.1.1.2.1\">Imaging, EHR</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.17.17.2\">UK Biobank&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib49\" title=\"\">49</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.17.17.3\">500,000 individuals</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.17.17.4\">Various data types</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.17.17.5\">Various tasks</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.17.17.6\">Medium</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.18.18\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.18.18.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.18.18.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.18.18.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.18.18.1.1.1.1\">Imaging,</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.18.18.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.18.18.1.1.2.1\">Genomics, EHR</td>\n</tr>\n</table>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.18.18.2\">ADNI&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib50\" title=\"\">50</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.18.18.3\">Thousands of patients</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.18.18.4\">MRI and clinical data</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.18.18.5\">Alzheimer&#8217;s research</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.18.18.6\">High</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.19.19\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.19.19.1\" rowspan=\"2\">\n<span class=\"ltx_text\" id=\"S2.T1.5.1.19.19.1.1\">Imaging, Text</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.19.19.2\">ImageCLEFmed&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib51\" title=\"\">51</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.19.19.3\">Varies annually</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.19.19.4\">Various data types</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.19.19.5\">Various tasks</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.19.19.6\">Low</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.20.20\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.20.20.1\">Openi&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib52\" title=\"\">52</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.20.20.2\">4.5 million images</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.20.20.3\">Various data types</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.20.20.4\">Various tasks</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S2.T1.5.1.20.20.5\">Low</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.21.21\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.21.21.1\">Various modalities</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.21.21.2\">PhysioNet&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib53\" title=\"\">53</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.21.21.3\">Various datasets</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.21.21.4\">Various data types</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.21.21.5\">Various tasks</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" id=\"S2.T1.5.1.21.21.6\">High</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [
            "[32]\n\nT. J. Pollard, A. E. Johnson, J. D. Raffa, L. A. Celi, R. G. Mark, and\nO. Badawi, “The eicu collaborative research database, a freely available\nmulti-center database for critical care research,” Scientific data,\nvol. 5, no. 1, pp. 1–13, 2018.",
            "[33]\n\nA. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng, M. Ghassemi,\nB. Moody, P. Szolovits, L. Anthony Celi, and R. G. Mark, “Mimic-iii, a\nfreely accessible critical care database,” Scientific data, vol. 3,\nno. 1, pp. 1–9, 2016.",
            "[34]\n\nD. Azcona, K. McGuinness, and A. F. Smeaton, “A comparative study of existing\nand new deep learning methods for detecting knee injuries using the mrnet\ndataset,” arXiv preprint arXiv:2010.01947, 2020.",
            "[35]\n\nG. Shih, C. C. Wu, S. S. Halabi, M. D. Kohli, L. M. Prevedello, T. S. Cook,\nA. Sharma, J. K. Amorosa, V. Arteaga, M. Galperin-Aizenberg, et al.,\n“Augmenting the national institutes of health chest radiograph dataset with\nexpert annotations of possible pneumonia,” Radiology: Artificial\nIntelligence, vol. 1, no. 1, p. e180041, 2019.",
            "[36]\n\nP. Rajpurkar, J. Irvin, A. Bagul, D. Ding, T. Duan, H. Mehta, B. Yang, K. Zhu,\nD. Laird, R. L. Ball, et al., “Mura: Large dataset for abnormality\ndetection in musculoskeletal radiographs,” arXiv preprint\narXiv:1712.06957, 2017.",
            "[37]\n\nS. S. Halabi, L. M. Prevedello, J. Kalpathy-Cramer, A. B. Mamonov, A. Bilbily,\nM. Cicero, I. Pan, L. A. Pereira, R. T. Sousa, N. Abdala, et al., “The\nrsna pediatric bone age machine learning challenge,” Radiology,\nvol. 290, no. 2, pp. 498–503, 2019.",
            "[38]\n\nD. Demner-Fushman, M. D. Kohli, M. B. Rosenman, S. E. Shooshan, L. Rodriguez,\nS. Antani, G. R. Thoma, and C. J. McDonald, “Preparing a collection of\nradiology examinations for distribution and retrieval,” Journal of the\nAmerican Medical Informatics Association, vol. 23, no. 2, pp. 304–310,\n2016.",
            "[39]\n\nJ. Zbontar, F. Knoll, A. Sriram, T. Murrell, Z. Huang, M. J. Muckley,\nA. Defazio, R. Stern, P. Johnson, M. Bruno, et al., “fastmri: An open\ndataset and benchmarks for accelerated mri,” arXiv preprint\narXiv:1811.08839, 2018.",
            "[40]\n\nJ. Irvin, P. Rajpurkar, M. Ko, Y. Yu, S. Ciurea-Ilcus, C. Chute, H. Marklund,\nB. Haghgoo, R. Ball, K. Shpanskaya, et al., “Chexpert: A large chest\nradiograph dataset with uncertainty labels and expert comparison,” in Proceedings of the AAAI Conf. on artificial intelligence, vol. 33,\npp. 590–597, 2019.",
            "[41]\n\nD. S. Marcus, T. H. Wang, J. Parker, J. G. Csernansky, J. C. Morris, and R. L.\nBuckner, “Open access series of imaging studies (oasis): cross-sectional mri\ndata in young, middle aged, nondemented, and demented older adults,” Journal of cognitive neuroscience, vol. 19, no. 9, pp. 1498–1507, 2007.",
            "[42]\n\nS. G. Armato III, G. McLennan, L. Bidaut, M. F. McNitt-Gray, C. R. Meyer, A. P.\nReeves, B. Zhao, D. R. Aberle, C. I. Henschke, E. A. Hoffman, et al.,\n“The lung image database consortium (lidc) and image database resource\ninitiative (idri): a completed reference database of lung nodules on ct\nscans,” Medical physics, vol. 38, no. 2, pp. 915–931, 2011.",
            "[43]\n\nK. Clark, B. Vendt, K. Smith, J. Freymann, J. Kirby, P. Koppel, S. Moore,\nS. Phillips, D. Maffitt, M. Pringle, et al., “The cancer imaging\narchive (tcia): maintaining and operating a public information repository,”\nJournal of digital imaging, vol. 26, pp. 1045–1057, 2013.",
            "[44]\n\nX. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers, “Chestx-ray8:\nHospital-scale chest x-ray database and benchmarks on weakly-supervised\nclassification and localization of common thorax diseases,” in Proceedings of the IEEE Conf. on computer vision and pattern recognition,\npp. 2097–2106, 2017.",
            "[45]\n\nB. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby,\nY. Burren, N. Porz, J. Slotboom, R. Wiest, et al., “The multimodal\nbrain tumor image segmentation benchmark (brats),” IEEE transactions on\nmedical imaging, vol. 34, no. 10, pp. 1993–2024, 2014.",
            "[46]\n\nS. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. S. Kirby, J. B.\nFreymann, K. Farahani, and C. Davatzikos, “Advancing the cancer genome atlas\nglioma mri collections with expert segmentation labels and radiomic\nfeatures,” Scientific data, vol. 4, no. 1, pp. 1–13, 2017.",
            "[47]\n\nS. Bakas, M. Reyes, A. Jakab, S. Bauer, M. Rempfler, A. Crimi, R. T. Shinohara,\nC. Berger, S. M. Ha, M. Rozycki, et al., “Identifying the best machine\nlearning algorithms for brain tumor segmentation, progression assessment, and\noverall survival prediction in the brats challenge,” arXiv preprint\narXiv:1811.02629, 2018.",
            "[48]\n\nK. Tomczak, P. Czerwińska, and M. Wiznerowicz, “Review the cancer genome\natlas (tcga): an immeasurable source of knowledge,” Contemporary\nOncology/Współczesna Onkologia, vol. 2015, no. 1, pp. 68–77, 2015.",
            "[49]\n\nN. E. Allen, C. Sudlow, T. Peakman, R. Collins, and U. biobank, “Uk biobank\ndata: come and get it,” 2014.",
            "[50]\n\nC. R. Jack Jr, M. A. Bernstein, N. C. Fox, P. Thompson, G. Alexander,\nD. Harvey, B. Borowski, P. J. Britson, J. L. Whitwell, C. Ward, et al.,\n“The alzheimer’s disease neuroimaging initiative (adni): Mri methods,” Journal of Magnetic Resonance Imaging: An Official Journal of the Int’l\nSociety for Magnetic Resonance in Medicine, vol. 27, no. 4, pp. 685–691,\n2008.",
            "[51]\n\nA. García Seco de Herrera, R. Schaer, S. Bromuri, and H. Müller, “Overview\nof the ImageCLEF 2016 medical task,” in Working Notes of CLEF 2016\n(Cross Language Evaluation Forum), September 2016.",
            "[52]\n\nD. Demner-Fushman, S. Antani, M. Simpson, and G. R. Thoma, “Design and\ndevelopment of a multimodal biomedical information retrieval system,” Journal of Computing Science and Engineering, vol. 6, no. 2, pp. 168–177,\n2012.",
            "[53]\n\nA. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. C. Ivanov,\nR. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley,\n“PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research\nresource for complex physiologic signals,” Circulation, vol. 101,\nno. 23, pp. e215–e220, 2000 (June 13).\n\n\nCirculation Electronic Pages:\nhttp://circ.ahajournals.org/content/101/23/e215.full PMID:1085218; doi:\n10.1161/01.CIR.101.23.e215."
        ],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.2.2.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.2.2.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.3.1.1.1\">eICU Collaborative</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.3.1.2.1\">Research Database&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib32\" title=\"\">32</a>]</cite>\n</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [
            "[32]\n\nT. J. Pollard, A. E. Johnson, J. D. Raffa, L. A. Celi, R. G. Mark, and\nO. Badawi, “The eicu collaborative research database, a freely available\nmulti-center database for critical care research,” Scientific data,\nvol. 5, no. 1, pp. 1–13, 2018."
        ],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.2.2.6.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.2.2.6.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.6.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.6.1.1.1\">Various tasks, mainly</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.2.2.6.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.2.2.6.1.2.1\">diagnosis and prognosis</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.3.3.4.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.3.3.4.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.3.3.4.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.3.3.4.1.1.1\">Various tasks, mainly</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.3.3.4.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.3.3.4.1.2.1\">diagnosis and prognosis</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.5.5.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.5.5.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.5.5.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.5.5.1.1.1.1\">RSNA Pneumonia</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.5.5.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.5.5.1.1.2.1\">Detection Challenge&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib35\" title=\"\">35</a>]</cite>\n</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [
            "[35]\n\nG. Shih, C. C. Wu, S. S. Halabi, M. D. Kohli, L. M. Prevedello, T. S. Cook,\nA. Sharma, J. K. Amorosa, V. Arteaga, M. Galperin-Aizenberg, et al.,\n“Augmenting the national institutes of health chest radiograph dataset with\nexpert annotations of possible pneumonia,” Radiology: Artificial\nIntelligence, vol. 1, no. 1, p. e180041, 2019."
        ],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.7.7.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.7.7.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.7.7.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.7.7.1.1.1.1\">Pediatric Bone Age</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.7.7.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.7.7.1.1.2.1\">Challenge Dataset&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib37\" title=\"\">37</a>]</cite>\n</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [
            "[37]\n\nS. S. Halabi, L. M. Prevedello, J. Kalpathy-Cramer, A. B. Mamonov, A. Bilbily,\nM. Cicero, I. Pan, L. A. Pereira, R. T. Sousa, N. Abdala, et al., “The\nrsna pediatric bone age machine learning challenge,” Radiology,\nvol. 290, no. 2, pp. 498–503, 2019."
        ],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.8.8.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.8.8.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.1.1.1.1\">Indiana University Chest</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.1.1.2.1\">X-ray Collection&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"#bib.bib38\" title=\"\">38</a>]</cite>\n</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [
            "[38]\n\nD. Demner-Fushman, M. D. Kohli, M. B. Rosenman, S. E. Shooshan, L. Rodriguez,\nS. Antani, G. R. Thoma, and C. J. McDonald, “Preparing a collection of\nradiology examinations for distribution and retrieval,” Journal of the\nAmerican Medical Informatics Association, vol. 23, no. 2, pp. 304–310,\n2016."
        ],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.8.8.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.8.8.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.3.1.1.1\">Chest radiograph</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.8.8.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.8.8.3.1.2.1\">DICOM images</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.12.12.3.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.12.12.3.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.12.12.3.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.12.12.3.1.1.1\">CT scans with marked-up</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.12.12.3.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.12.12.3.1.2.1\">annotated lesions</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.16.16.2.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.16.16.2.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.16.16.2.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.16.16.2.1.1.1\">Genomics,</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.16.16.2.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.16.16.2.1.2.1\">Imaging</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.17.17.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.17.17.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.17.17.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.17.17.1.1.1.1\">Genomics,</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.17.17.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.17.17.1.1.2.1\">Imaging, EHR</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    },
    "S2.T1.5.1.18.18.1.1": {
        "table": "<table class=\"ltx_tabular ltx_align_middle\" id=\"S2.T1.5.1.18.18.1.1\">\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.18.18.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.18.18.1.1.1.1\">Imaging,</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S2.T1.5.1.18.18.1.1.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S2.T1.5.1.18.18.1.1.2.1\">Genomics, EHR</td>\n</tr>\n</table>\n",
        "caption": "TABLE I: Multimodal Datasets for smart healthcare",
        "footnotes": [],
        "references": [
            "An overview of multimodal datasets used in smart healthcare is presented in Table I. It includes information on the modality, dataset name, number of instances, number of attributes, task, popularity, and reference count. The datasets cover various modalities such as EHRs, Genomics, Imaging, and Text. Examples of datasets include the eICU Collaborative Research Database, TCGA, UK Biobank, MRNet, RSNA Pneumonia Detection Challenge, MURA, and ChestX-ray8. These datasets are used for diagnosis, prognosis, cancer research, disease detection, and image segmentation [58]. The popularity of the datasets depends on the reference counts, and the table provides reference counts for further exploration."
        ]
    }
}