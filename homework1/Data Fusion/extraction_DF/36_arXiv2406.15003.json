{
    "S3.E1": {
        "table": "<table class=\"ltx_equation ltx_eqn_table\" id=\"S3.E1\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"G_{i}=\\{G_{i}^{\\tau}\\}_{\\tau\\text{=}1}^{T_{i}}\" class=\"ltx_Math\" display=\"block\" id=\"S3.E1.m1.1\"><semantics id=\"S3.E1.m1.1a\"><mrow id=\"S3.E1.m1.1.1\" xref=\"S3.E1.m1.1.1.cmml\"><msub id=\"S3.E1.m1.1.1.3\" xref=\"S3.E1.m1.1.1.3.cmml\"><mi id=\"S3.E1.m1.1.1.3.2\" xref=\"S3.E1.m1.1.1.3.2.cmml\">G</mi><mi id=\"S3.E1.m1.1.1.3.3\" xref=\"S3.E1.m1.1.1.3.3.cmml\">i</mi></msub><mo id=\"S3.E1.m1.1.1.2\" xref=\"S3.E1.m1.1.1.2.cmml\">=</mo><msubsup id=\"S3.E1.m1.1.1.1\" xref=\"S3.E1.m1.1.1.1.cmml\"><mrow id=\"S3.E1.m1.1.1.1.1.1.1\" xref=\"S3.E1.m1.1.1.1.1.1.2.cmml\"><mo id=\"S3.E1.m1.1.1.1.1.1.1.2\" stretchy=\"false\" xref=\"S3.E1.m1.1.1.1.1.1.2.cmml\">{</mo><msubsup id=\"S3.E1.m1.1.1.1.1.1.1.1\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.cmml\"><mi id=\"S3.E1.m1.1.1.1.1.1.1.1.2.2\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.2.2.cmml\">G</mi><mi id=\"S3.E1.m1.1.1.1.1.1.1.1.2.3\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.2.3.cmml\">i</mi><mi id=\"S3.E1.m1.1.1.1.1.1.1.1.3\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.3.cmml\">&#964;</mi></msubsup><mo id=\"S3.E1.m1.1.1.1.1.1.1.3\" stretchy=\"false\" xref=\"S3.E1.m1.1.1.1.1.1.2.cmml\">}</mo></mrow><mrow id=\"S3.E1.m1.1.1.1.1.3\" xref=\"S3.E1.m1.1.1.1.1.3.cmml\"><mi id=\"S3.E1.m1.1.1.1.1.3.2\" xref=\"S3.E1.m1.1.1.1.1.3.2.cmml\">&#964;</mi><mo id=\"S3.E1.m1.1.1.1.1.3.1\" xref=\"S3.E1.m1.1.1.1.1.3.1.cmml\">&#8290;</mo><mtext id=\"S3.E1.m1.1.1.1.1.3.3\" xref=\"S3.E1.m1.1.1.1.1.3.3a.cmml\">=</mtext><mo id=\"S3.E1.m1.1.1.1.1.3.1a\" xref=\"S3.E1.m1.1.1.1.1.3.1.cmml\">&#8290;</mo><mn id=\"S3.E1.m1.1.1.1.1.3.4\" xref=\"S3.E1.m1.1.1.1.1.3.4.cmml\">1</mn></mrow><msub id=\"S3.E1.m1.1.1.1.3\" xref=\"S3.E1.m1.1.1.1.3.cmml\"><mi id=\"S3.E1.m1.1.1.1.3.2\" xref=\"S3.E1.m1.1.1.1.3.2.cmml\">T</mi><mi id=\"S3.E1.m1.1.1.1.3.3\" xref=\"S3.E1.m1.1.1.1.3.3.cmml\">i</mi></msub></msubsup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.E1.m1.1b\"><apply id=\"S3.E1.m1.1.1.cmml\" xref=\"S3.E1.m1.1.1\"><eq id=\"S3.E1.m1.1.1.2.cmml\" xref=\"S3.E1.m1.1.1.2\"></eq><apply id=\"S3.E1.m1.1.1.3.cmml\" xref=\"S3.E1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.3.1.cmml\" xref=\"S3.E1.m1.1.1.3\">subscript</csymbol><ci id=\"S3.E1.m1.1.1.3.2.cmml\" xref=\"S3.E1.m1.1.1.3.2\">&#119866;</ci><ci id=\"S3.E1.m1.1.1.3.3.cmml\" xref=\"S3.E1.m1.1.1.3.3\">&#119894;</ci></apply><apply id=\"S3.E1.m1.1.1.1.cmml\" xref=\"S3.E1.m1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.1.2.cmml\" xref=\"S3.E1.m1.1.1.1\">superscript</csymbol><apply id=\"S3.E1.m1.1.1.1.1.cmml\" xref=\"S3.E1.m1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.1.1.2.cmml\" xref=\"S3.E1.m1.1.1.1\">subscript</csymbol><set id=\"S3.E1.m1.1.1.1.1.1.2.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1\"><apply id=\"S3.E1.m1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1\">superscript</csymbol><apply id=\"S3.E1.m1.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.1.1.1.1.1.2.1.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S3.E1.m1.1.1.1.1.1.1.1.2.2.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.2.2\">&#119866;</ci><ci id=\"S3.E1.m1.1.1.1.1.1.1.1.2.3.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.2.3\">&#119894;</ci></apply><ci id=\"S3.E1.m1.1.1.1.1.1.1.1.3.cmml\" xref=\"S3.E1.m1.1.1.1.1.1.1.1.3\">&#120591;</ci></apply></set><apply id=\"S3.E1.m1.1.1.1.1.3.cmml\" xref=\"S3.E1.m1.1.1.1.1.3\"><times id=\"S3.E1.m1.1.1.1.1.3.1.cmml\" xref=\"S3.E1.m1.1.1.1.1.3.1\"></times><ci id=\"S3.E1.m1.1.1.1.1.3.2.cmml\" xref=\"S3.E1.m1.1.1.1.1.3.2\">&#120591;</ci><ci id=\"S3.E1.m1.1.1.1.1.3.3a.cmml\" xref=\"S3.E1.m1.1.1.1.1.3.3\"><mtext id=\"S3.E1.m1.1.1.1.1.3.3.cmml\" mathsize=\"70%\" xref=\"S3.E1.m1.1.1.1.1.3.3\">=</mtext></ci><cn id=\"S3.E1.m1.1.1.1.1.3.4.cmml\" type=\"integer\" xref=\"S3.E1.m1.1.1.1.1.3.4\">1</cn></apply></apply><apply id=\"S3.E1.m1.1.1.1.3.cmml\" xref=\"S3.E1.m1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.1.3.1.cmml\" xref=\"S3.E1.m1.1.1.1.3\">subscript</csymbol><ci id=\"S3.E1.m1.1.1.1.3.2.cmml\" xref=\"S3.E1.m1.1.1.1.3.2\">&#119879;</ci><ci id=\"S3.E1.m1.1.1.1.3.3.cmml\" xref=\"S3.E1.m1.1.1.1.3.3\">&#119894;</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.E1.m1.1c\">G_{i}=\\{G_{i}^{\\tau}\\}_{\\tau\\text{=}1}^{T_{i}}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.E1.m1.1d\">italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_&#964; end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_&#964; = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(1)</span></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": [
            "If gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT denotes a dynamic gesture and S=Chh‚Å¢=‚Å¢1NùëÜsuperscriptsubscriptsubscriptùê∂‚Ñé‚Ñé=1ùëÅS={C_{h}}_{h\\text{=}1}^{N}italic_S = italic_C start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT start_POSTSUBSCRIPT italic_h = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT represents the set of gesture sequences across NùëÅNitalic_N classes, the temporal variation of gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is defined in Equation 1 as follows:"
        ]
    },
    "S3.E2": {
        "table": "<table class=\"ltx_equation ltx_eqn_table\" id=\"S3.E2\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"g_{i}=g_{i}-mean(g_{i})-(L/2)\" class=\"ltx_Math\" display=\"block\" id=\"S3.E2.m1.2\"><semantics id=\"S3.E2.m1.2a\"><mrow id=\"S3.E2.m1.2.2\" xref=\"S3.E2.m1.2.2.cmml\"><msub id=\"S3.E2.m1.2.2.4\" xref=\"S3.E2.m1.2.2.4.cmml\"><mi id=\"S3.E2.m1.2.2.4.2\" xref=\"S3.E2.m1.2.2.4.2.cmml\">g</mi><mi id=\"S3.E2.m1.2.2.4.3\" xref=\"S3.E2.m1.2.2.4.3.cmml\">i</mi></msub><mo id=\"S3.E2.m1.2.2.3\" xref=\"S3.E2.m1.2.2.3.cmml\">=</mo><mrow id=\"S3.E2.m1.2.2.2\" xref=\"S3.E2.m1.2.2.2.cmml\"><msub id=\"S3.E2.m1.2.2.2.4\" xref=\"S3.E2.m1.2.2.2.4.cmml\"><mi id=\"S3.E2.m1.2.2.2.4.2\" xref=\"S3.E2.m1.2.2.2.4.2.cmml\">g</mi><mi id=\"S3.E2.m1.2.2.2.4.3\" xref=\"S3.E2.m1.2.2.2.4.3.cmml\">i</mi></msub><mo id=\"S3.E2.m1.2.2.2.3\" xref=\"S3.E2.m1.2.2.2.3.cmml\">&#8722;</mo><mrow id=\"S3.E2.m1.1.1.1.1\" xref=\"S3.E2.m1.1.1.1.1.cmml\"><mi id=\"S3.E2.m1.1.1.1.1.3\" xref=\"S3.E2.m1.1.1.1.1.3.cmml\">m</mi><mo id=\"S3.E2.m1.1.1.1.1.2\" xref=\"S3.E2.m1.1.1.1.1.2.cmml\">&#8290;</mo><mi id=\"S3.E2.m1.1.1.1.1.4\" xref=\"S3.E2.m1.1.1.1.1.4.cmml\">e</mi><mo id=\"S3.E2.m1.1.1.1.1.2a\" xref=\"S3.E2.m1.1.1.1.1.2.cmml\">&#8290;</mo><mi id=\"S3.E2.m1.1.1.1.1.5\" xref=\"S3.E2.m1.1.1.1.1.5.cmml\">a</mi><mo id=\"S3.E2.m1.1.1.1.1.2b\" xref=\"S3.E2.m1.1.1.1.1.2.cmml\">&#8290;</mo><mi id=\"S3.E2.m1.1.1.1.1.6\" xref=\"S3.E2.m1.1.1.1.1.6.cmml\">n</mi><mo id=\"S3.E2.m1.1.1.1.1.2c\" xref=\"S3.E2.m1.1.1.1.1.2.cmml\">&#8290;</mo><mrow id=\"S3.E2.m1.1.1.1.1.1.1\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.cmml\"><mo id=\"S3.E2.m1.1.1.1.1.1.1.2\" stretchy=\"false\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S3.E2.m1.1.1.1.1.1.1.1\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.cmml\"><mi id=\"S3.E2.m1.1.1.1.1.1.1.1.2\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.2.cmml\">g</mi><mi id=\"S3.E2.m1.1.1.1.1.1.1.1.3\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S3.E2.m1.1.1.1.1.1.1.3\" stretchy=\"false\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S3.E2.m1.2.2.2.3a\" xref=\"S3.E2.m1.2.2.2.3.cmml\">&#8722;</mo><mrow id=\"S3.E2.m1.2.2.2.2.1\" xref=\"S3.E2.m1.2.2.2.2.1.1.cmml\"><mo id=\"S3.E2.m1.2.2.2.2.1.2\" stretchy=\"false\" xref=\"S3.E2.m1.2.2.2.2.1.1.cmml\">(</mo><mrow id=\"S3.E2.m1.2.2.2.2.1.1\" xref=\"S3.E2.m1.2.2.2.2.1.1.cmml\"><mi id=\"S3.E2.m1.2.2.2.2.1.1.2\" xref=\"S3.E2.m1.2.2.2.2.1.1.2.cmml\">L</mi><mo id=\"S3.E2.m1.2.2.2.2.1.1.1\" xref=\"S3.E2.m1.2.2.2.2.1.1.1.cmml\">/</mo><mn id=\"S3.E2.m1.2.2.2.2.1.1.3\" xref=\"S3.E2.m1.2.2.2.2.1.1.3.cmml\">2</mn></mrow><mo id=\"S3.E2.m1.2.2.2.2.1.3\" stretchy=\"false\" xref=\"S3.E2.m1.2.2.2.2.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.E2.m1.2b\"><apply id=\"S3.E2.m1.2.2.cmml\" xref=\"S3.E2.m1.2.2\"><eq id=\"S3.E2.m1.2.2.3.cmml\" xref=\"S3.E2.m1.2.2.3\"></eq><apply id=\"S3.E2.m1.2.2.4.cmml\" xref=\"S3.E2.m1.2.2.4\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.2.2.4.1.cmml\" xref=\"S3.E2.m1.2.2.4\">subscript</csymbol><ci id=\"S3.E2.m1.2.2.4.2.cmml\" xref=\"S3.E2.m1.2.2.4.2\">&#119892;</ci><ci id=\"S3.E2.m1.2.2.4.3.cmml\" xref=\"S3.E2.m1.2.2.4.3\">&#119894;</ci></apply><apply id=\"S3.E2.m1.2.2.2.cmml\" xref=\"S3.E2.m1.2.2.2\"><minus id=\"S3.E2.m1.2.2.2.3.cmml\" xref=\"S3.E2.m1.2.2.2.3\"></minus><apply id=\"S3.E2.m1.2.2.2.4.cmml\" xref=\"S3.E2.m1.2.2.2.4\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.2.2.2.4.1.cmml\" xref=\"S3.E2.m1.2.2.2.4\">subscript</csymbol><ci id=\"S3.E2.m1.2.2.2.4.2.cmml\" xref=\"S3.E2.m1.2.2.2.4.2\">&#119892;</ci><ci id=\"S3.E2.m1.2.2.2.4.3.cmml\" xref=\"S3.E2.m1.2.2.2.4.3\">&#119894;</ci></apply><apply id=\"S3.E2.m1.1.1.1.1.cmml\" xref=\"S3.E2.m1.1.1.1.1\"><times id=\"S3.E2.m1.1.1.1.1.2.cmml\" xref=\"S3.E2.m1.1.1.1.1.2\"></times><ci id=\"S3.E2.m1.1.1.1.1.3.cmml\" xref=\"S3.E2.m1.1.1.1.1.3\">&#119898;</ci><ci id=\"S3.E2.m1.1.1.1.1.4.cmml\" xref=\"S3.E2.m1.1.1.1.1.4\">&#119890;</ci><ci id=\"S3.E2.m1.1.1.1.1.5.cmml\" xref=\"S3.E2.m1.1.1.1.1.5\">&#119886;</ci><ci id=\"S3.E2.m1.1.1.1.1.6.cmml\" xref=\"S3.E2.m1.1.1.1.1.6\">&#119899;</ci><apply id=\"S3.E2.m1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E2.m1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E2.m1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S3.E2.m1.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.2\">&#119892;</ci><ci id=\"S3.E2.m1.1.1.1.1.1.1.1.3.cmml\" xref=\"S3.E2.m1.1.1.1.1.1.1.1.3\">&#119894;</ci></apply></apply><apply id=\"S3.E2.m1.2.2.2.2.1.1.cmml\" xref=\"S3.E2.m1.2.2.2.2.1\"><divide id=\"S3.E2.m1.2.2.2.2.1.1.1.cmml\" xref=\"S3.E2.m1.2.2.2.2.1.1.1\"></divide><ci id=\"S3.E2.m1.2.2.2.2.1.1.2.cmml\" xref=\"S3.E2.m1.2.2.2.2.1.1.2\">&#119871;</ci><cn id=\"S3.E2.m1.2.2.2.2.1.1.3.cmml\" type=\"integer\" xref=\"S3.E2.m1.2.2.2.2.1.1.3\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.E2.m1.2c\">g_{i}=g_{i}-mean(g_{i})-(L/2)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.E2.m1.2d\">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_m italic_e italic_a italic_n ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - ( italic_L / 2 )</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(2)</span></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": [
            "Equation 2 adjusts each gesture gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (a sequence of 3D skeleton coordinates) by subtracting its mean and half the target length LùêøLitalic_L of the static image. This adjustment shifts the gesture to the centre of the image and ensures that the virtual camera is consistently fixed at the image centre PùëÉPitalic_P for all gi‚ààSsubscriptùëîùëñùëÜg_{i}\\in Sitalic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà italic_S, as outlined in Equation 3.\nEquation 4 dynamically estimates the zoom level ZisubscriptùëçùëñZ_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of the virtual camera for each gesture gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT based on the minimum and maximum bounds of the gesture‚Äôs 3D visualization. An optional padding value Œ≥ùõæ\\gammaitalic_Œ≥ can be added to all gestures gi‚ààSsubscriptùëîùëñùëÜg_{i}\\in Sitalic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà italic_S or set to zero."
        ]
    },
    "S3.E3": {
        "table": "<table class=\"ltx_equation ltx_eqn_table\" id=\"S3.E3\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"P=(L/2)\" class=\"ltx_Math\" display=\"block\" id=\"S3.E3.m1.1\"><semantics id=\"S3.E3.m1.1a\"><mrow id=\"S3.E3.m1.1.1\" xref=\"S3.E3.m1.1.1.cmml\"><mi id=\"S3.E3.m1.1.1.3\" xref=\"S3.E3.m1.1.1.3.cmml\">P</mi><mo id=\"S3.E3.m1.1.1.2\" xref=\"S3.E3.m1.1.1.2.cmml\">=</mo><mrow id=\"S3.E3.m1.1.1.1.1\" xref=\"S3.E3.m1.1.1.1.1.1.cmml\"><mo id=\"S3.E3.m1.1.1.1.1.2\" stretchy=\"false\" xref=\"S3.E3.m1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S3.E3.m1.1.1.1.1.1\" xref=\"S3.E3.m1.1.1.1.1.1.cmml\"><mi id=\"S3.E3.m1.1.1.1.1.1.2\" xref=\"S3.E3.m1.1.1.1.1.1.2.cmml\">L</mi><mo id=\"S3.E3.m1.1.1.1.1.1.1\" xref=\"S3.E3.m1.1.1.1.1.1.1.cmml\">/</mo><mn id=\"S3.E3.m1.1.1.1.1.1.3\" xref=\"S3.E3.m1.1.1.1.1.1.3.cmml\">2</mn></mrow><mo id=\"S3.E3.m1.1.1.1.1.3\" stretchy=\"false\" xref=\"S3.E3.m1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.E3.m1.1b\"><apply id=\"S3.E3.m1.1.1.cmml\" xref=\"S3.E3.m1.1.1\"><eq id=\"S3.E3.m1.1.1.2.cmml\" xref=\"S3.E3.m1.1.1.2\"></eq><ci id=\"S3.E3.m1.1.1.3.cmml\" xref=\"S3.E3.m1.1.1.3\">&#119875;</ci><apply id=\"S3.E3.m1.1.1.1.1.1.cmml\" xref=\"S3.E3.m1.1.1.1.1\"><divide id=\"S3.E3.m1.1.1.1.1.1.1.cmml\" xref=\"S3.E3.m1.1.1.1.1.1.1\"></divide><ci id=\"S3.E3.m1.1.1.1.1.1.2.cmml\" xref=\"S3.E3.m1.1.1.1.1.1.2\">&#119871;</ci><cn id=\"S3.E3.m1.1.1.1.1.1.3.cmml\" type=\"integer\" xref=\"S3.E3.m1.1.1.1.1.1.3\">2</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.E3.m1.1c\">P=(L/2)</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.E3.m1.1d\">italic_P = ( italic_L / 2 )</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(3)</span></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": [
            "Equation 2 adjusts each gesture gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (a sequence of 3D skeleton coordinates) by subtracting its mean and half the target length LùêøLitalic_L of the static image. This adjustment shifts the gesture to the centre of the image and ensures that the virtual camera is consistently fixed at the image centre PùëÉPitalic_P for all gi‚ààSsubscriptùëîùëñùëÜg_{i}\\in Sitalic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà italic_S, as outlined in Equation 3.\nEquation 4 dynamically estimates the zoom level ZisubscriptùëçùëñZ_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of the virtual camera for each gesture gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT based on the minimum and maximum bounds of the gesture‚Äôs 3D visualization. An optional padding value Œ≥ùõæ\\gammaitalic_Œ≥ can be added to all gestures gi‚ààSsubscriptùëîùëñùëÜg_{i}\\in Sitalic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà italic_S or set to zero."
        ]
    },
    "S3.E4": {
        "table": "<table class=\"ltx_equation ltx_eqn_table\" id=\"S3.E4\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"Z_{i}=max(g_{i})-min(g_{i})+\\gamma\" class=\"ltx_Math\" display=\"block\" id=\"S3.E4.m1.2\"><semantics id=\"S3.E4.m1.2a\"><mrow id=\"S3.E4.m1.2.2\" xref=\"S3.E4.m1.2.2.cmml\"><msub id=\"S3.E4.m1.2.2.4\" xref=\"S3.E4.m1.2.2.4.cmml\"><mi id=\"S3.E4.m1.2.2.4.2\" xref=\"S3.E4.m1.2.2.4.2.cmml\">Z</mi><mi id=\"S3.E4.m1.2.2.4.3\" xref=\"S3.E4.m1.2.2.4.3.cmml\">i</mi></msub><mo id=\"S3.E4.m1.2.2.3\" xref=\"S3.E4.m1.2.2.3.cmml\">=</mo><mrow id=\"S3.E4.m1.2.2.2\" xref=\"S3.E4.m1.2.2.2.cmml\"><mrow id=\"S3.E4.m1.2.2.2.2\" xref=\"S3.E4.m1.2.2.2.2.cmml\"><mrow id=\"S3.E4.m1.1.1.1.1.1\" xref=\"S3.E4.m1.1.1.1.1.1.cmml\"><mi id=\"S3.E4.m1.1.1.1.1.1.3\" xref=\"S3.E4.m1.1.1.1.1.1.3.cmml\">m</mi><mo id=\"S3.E4.m1.1.1.1.1.1.2\" xref=\"S3.E4.m1.1.1.1.1.1.2.cmml\">&#8290;</mo><mi id=\"S3.E4.m1.1.1.1.1.1.4\" xref=\"S3.E4.m1.1.1.1.1.1.4.cmml\">a</mi><mo id=\"S3.E4.m1.1.1.1.1.1.2a\" xref=\"S3.E4.m1.1.1.1.1.1.2.cmml\">&#8290;</mo><mi id=\"S3.E4.m1.1.1.1.1.1.5\" xref=\"S3.E4.m1.1.1.1.1.1.5.cmml\">x</mi><mo id=\"S3.E4.m1.1.1.1.1.1.2b\" xref=\"S3.E4.m1.1.1.1.1.1.2.cmml\">&#8290;</mo><mrow id=\"S3.E4.m1.1.1.1.1.1.1.1\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S3.E4.m1.1.1.1.1.1.1.1.2\" stretchy=\"false\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S3.E4.m1.1.1.1.1.1.1.1.1\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S3.E4.m1.1.1.1.1.1.1.1.1.2\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml\">g</mi><mi id=\"S3.E4.m1.1.1.1.1.1.1.1.1.3\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S3.E4.m1.1.1.1.1.1.1.1.3\" stretchy=\"false\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S3.E4.m1.2.2.2.2.3\" xref=\"S3.E4.m1.2.2.2.2.3.cmml\">&#8722;</mo><mrow id=\"S3.E4.m1.2.2.2.2.2\" xref=\"S3.E4.m1.2.2.2.2.2.cmml\"><mi id=\"S3.E4.m1.2.2.2.2.2.3\" xref=\"S3.E4.m1.2.2.2.2.2.3.cmml\">m</mi><mo id=\"S3.E4.m1.2.2.2.2.2.2\" xref=\"S3.E4.m1.2.2.2.2.2.2.cmml\">&#8290;</mo><mi id=\"S3.E4.m1.2.2.2.2.2.4\" xref=\"S3.E4.m1.2.2.2.2.2.4.cmml\">i</mi><mo id=\"S3.E4.m1.2.2.2.2.2.2a\" xref=\"S3.E4.m1.2.2.2.2.2.2.cmml\">&#8290;</mo><mi id=\"S3.E4.m1.2.2.2.2.2.5\" xref=\"S3.E4.m1.2.2.2.2.2.5.cmml\">n</mi><mo id=\"S3.E4.m1.2.2.2.2.2.2b\" xref=\"S3.E4.m1.2.2.2.2.2.2.cmml\">&#8290;</mo><mrow id=\"S3.E4.m1.2.2.2.2.2.1.1\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.cmml\"><mo id=\"S3.E4.m1.2.2.2.2.2.1.1.2\" stretchy=\"false\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.cmml\">(</mo><msub id=\"S3.E4.m1.2.2.2.2.2.1.1.1\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.cmml\"><mi id=\"S3.E4.m1.2.2.2.2.2.1.1.1.2\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.2.cmml\">g</mi><mi id=\"S3.E4.m1.2.2.2.2.2.1.1.1.3\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.3.cmml\">i</mi></msub><mo id=\"S3.E4.m1.2.2.2.2.2.1.1.3\" stretchy=\"false\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S3.E4.m1.2.2.2.3\" xref=\"S3.E4.m1.2.2.2.3.cmml\">+</mo><mi id=\"S3.E4.m1.2.2.2.4\" xref=\"S3.E4.m1.2.2.2.4.cmml\">&#947;</mi></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.E4.m1.2b\"><apply id=\"S3.E4.m1.2.2.cmml\" xref=\"S3.E4.m1.2.2\"><eq id=\"S3.E4.m1.2.2.3.cmml\" xref=\"S3.E4.m1.2.2.3\"></eq><apply id=\"S3.E4.m1.2.2.4.cmml\" xref=\"S3.E4.m1.2.2.4\"><csymbol cd=\"ambiguous\" id=\"S3.E4.m1.2.2.4.1.cmml\" xref=\"S3.E4.m1.2.2.4\">subscript</csymbol><ci id=\"S3.E4.m1.2.2.4.2.cmml\" xref=\"S3.E4.m1.2.2.4.2\">&#119885;</ci><ci id=\"S3.E4.m1.2.2.4.3.cmml\" xref=\"S3.E4.m1.2.2.4.3\">&#119894;</ci></apply><apply id=\"S3.E4.m1.2.2.2.cmml\" xref=\"S3.E4.m1.2.2.2\"><plus id=\"S3.E4.m1.2.2.2.3.cmml\" xref=\"S3.E4.m1.2.2.2.3\"></plus><apply id=\"S3.E4.m1.2.2.2.2.cmml\" xref=\"S3.E4.m1.2.2.2.2\"><minus id=\"S3.E4.m1.2.2.2.2.3.cmml\" xref=\"S3.E4.m1.2.2.2.2.3\"></minus><apply id=\"S3.E4.m1.1.1.1.1.1.cmml\" xref=\"S3.E4.m1.1.1.1.1.1\"><times id=\"S3.E4.m1.1.1.1.1.1.2.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.2\"></times><ci id=\"S3.E4.m1.1.1.1.1.1.3.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.3\">&#119898;</ci><ci id=\"S3.E4.m1.1.1.1.1.1.4.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.4\">&#119886;</ci><ci id=\"S3.E4.m1.1.1.1.1.1.5.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.5\">&#119909;</ci><apply id=\"S3.E4.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.2\">&#119892;</ci><ci id=\"S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S3.E4.m1.1.1.1.1.1.1.1.1.3\">&#119894;</ci></apply></apply><apply id=\"S3.E4.m1.2.2.2.2.2.cmml\" xref=\"S3.E4.m1.2.2.2.2.2\"><times id=\"S3.E4.m1.2.2.2.2.2.2.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.2\"></times><ci id=\"S3.E4.m1.2.2.2.2.2.3.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.3\">&#119898;</ci><ci id=\"S3.E4.m1.2.2.2.2.2.4.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.4\">&#119894;</ci><ci id=\"S3.E4.m1.2.2.2.2.2.5.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.5\">&#119899;</ci><apply id=\"S3.E4.m1.2.2.2.2.2.1.1.1.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E4.m1.2.2.2.2.2.1.1.1.1.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.1.1\">subscript</csymbol><ci id=\"S3.E4.m1.2.2.2.2.2.1.1.1.2.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.2\">&#119892;</ci><ci id=\"S3.E4.m1.2.2.2.2.2.1.1.1.3.cmml\" xref=\"S3.E4.m1.2.2.2.2.2.1.1.1.3\">&#119894;</ci></apply></apply></apply><ci id=\"S3.E4.m1.2.2.2.4.cmml\" xref=\"S3.E4.m1.2.2.2.4\">&#120574;</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.E4.m1.2c\">Z_{i}=max(g_{i})-min(g_{i})+\\gamma</annotation><annotation encoding=\"application/x-llamapun\" id=\"S3.E4.m1.2d\">italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_m italic_a italic_x ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_m italic_i italic_n ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) + italic_&#947;</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(4)</span></td>\n</tr></tbody>\n</table>\n\n",
        "caption": "",
        "footnotes": [],
        "references": [
            "Equation 2 adjusts each gesture gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (a sequence of 3D skeleton coordinates) by subtracting its mean and half the target length LùêøLitalic_L of the static image. This adjustment shifts the gesture to the centre of the image and ensures that the virtual camera is consistently fixed at the image centre PùëÉPitalic_P for all gi‚ààSsubscriptùëîùëñùëÜg_{i}\\in Sitalic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà italic_S, as outlined in Equation 3.\nEquation 4 dynamically estimates the zoom level ZisubscriptùëçùëñZ_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of the virtual camera for each gesture gisubscriptùëîùëñg_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT based on the minimum and maximum bounds of the gesture‚Äôs 3D visualization. An optional padding value Œ≥ùõæ\\gammaitalic_Œ≥ can be added to all gestures gi‚ààSsubscriptùëîùëñùëÜg_{i}\\in Sitalic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà italic_S or set to zero."
        ]
    },
    "S4.T1.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.1.1.1.1\">View Orientation</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.2\">DHG1428</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.3\">SHREC2017</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.4\">FPHA</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.1.1.1.5\">LMDHG</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.1.2.1.1\">top-down</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.2\">(0.0, 0.0)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.3\">(0.0, 0.0)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.4\">(90.0, 0.0)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.2.1.5\">(0.0, 0.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.3.2.1\">front-to</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.2\">(90.0, 180.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.3\">(90.0, 180.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.4\">(0.0, 180.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.3.2.5\">(-90.0, -180.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.4.3.1\">front-away</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.2\">(-90.0, 0.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.3\">(-90.0, 0.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.4\">(0.0, 0.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.4.3.5\">(90.0, 0.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.5.4.1\">side-right</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.4.2\">(0.0, -90.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.4.3\">(0.0, -90.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.4.4\">(0.0, 90.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.5.4.5\">(0.0, 90.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.1.6.5.1\">side-left</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.5.2\">(0.0, 90.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.5.3\">(0.0, 90.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.5.4\">(0.0, -90.0)</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.6.5.5\">(0.0, -90.0)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.1.7.6.1\">custom</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.7.6.2\">(30.0, -132.5)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.7.6.3\">(30.0, -132.5)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.7.6.4\">(25.0, 115.0)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.1.7.6.5\">(-15.0, -135.0)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE I: Virtual Camera (elevation, azimuth) Angles (in degrees) For Each View Orientation.",
        "footnotes": [],
        "references": [
            "Our proposed HGR framework, in its generalized form, incorporates data-level fusion to create static 2D spatiotemporal images combined with the specialized end-to-end Ensemble Tuner (e2eET) CNN architecture for classifying said images. Table I shows that the elevation and azimuth angles of the virtual camera required for the view orientations during data-level fusion are dataset-specific. The same padding value Œ≥=0.125ùõæ0.125\\gamma=0.125italic_Œ≥ = 0.125 was used for all datasets during sequence fitting. Note that the aforementioned settings do not apply to the CNR dataset as it only provides encoded images."
        ]
    },
    "S4.T2.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" colspan=\"2\" id=\"S4.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.1.1\">CNN Architecture</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" id=\"S4.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.1.2.1\">Classification Accuracies (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.2.2.1\">Family</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.2.2.2\">Variants</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.2.3\">TS1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.2.4\">TS2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.2.2.5\">Average</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.3.3.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T2.1.3.3.1.1\">ResNet</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.3.3.2\">ResNet18</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.3.3\">80.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.3.4\">77.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.3.3.5\" rowspan=\"5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.3.3.5.1\">81.49</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.4.4.1\">ResNet34</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.4.2\">81.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.4.4.3\">79.52</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.5.5.1\">ResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.5.5.2.1\">84.17</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.5.5.3\">80.12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.6.6.1\">ResNet101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.6.2\">82.26</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.6.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.6.6.3.1\">82.86</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.7.7.1\">ResNet152</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.7.2\">83.10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.7.7.3\">82.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.8.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.8.8.1\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T2.1.8.8.1.1\">Inception</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.8.8.2\">Inception-v3</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.8.8.3\">81.55</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.8.8.4\">77.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.8.8.5\" rowspan=\"4\"><span class=\"ltx_text\" id=\"S4.T2.1.8.8.5.1\">81.24</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.9.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.9.9.1\">Inception-v4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.9.9.2\">83.10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.9.9.3\">79.64</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.10.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.10.10.1\">Inception-ResNet-v1</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.10.10.2\">81.79</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.10.10.3\">82.62</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.11.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.11.11.1\">Inception-ResNet-v2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.11.11.2\">81.67</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.11.11.3\">81.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.12.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.12.12.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T2.1.12.12.1.1\">EfficientNet</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.12.12.2\">EfficientNet-B0</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.12.12.3\">81.43</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.12.12.4\">79.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.12.12.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T2.1.12.12.5.1\">80.80</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.13.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.13.13.1\">EfficientNet-B3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.13.13.2\">81.07</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.13.13.3\">81.07</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.14.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.14.14.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T2.1.14.14.1.1\">ResNeXt</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.14.14.2\">ResNeXt26</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.14.14.3\">80.48</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.14.14.4\">77.26</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.14.14.5\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T2.1.14.14.5.1\">80.42</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.15.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.15.15.1\">ResNeXt50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.15.15.2\">82.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.15.15.3\">79.52</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.16.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.16.16.1\">ResNeXt101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.16.16.2\">82.26</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.16.16.3\">80.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.17.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.17.17.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T2.1.17.17.1.1\">SE-ResNeXt</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.17.17.2\">SE-ResNeXt50</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.17.17.3\">81.43</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.17.17.4\">75.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.17.17.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T2.1.17.17.5.1\">80.33</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.18.18\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.18.18.1\">SE-ResNeXt101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.18.18.2\">84.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.18.18.3\">79.88</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.19.19\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.19.19.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T2.1.19.19.1.1\">SE-ResNet</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.19.19.2\">SE-ResNet18</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.19.19.3\">78.81</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.19.19.4\">77.74</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.19.19.5\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S4.T2.1.19.19.5.1\">80.32</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.20.20\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.20.20.1\">SE-ResNet26</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.20.20.2\">80.48</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.20.20.3\">77.26</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.21.21\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.21.21.1\">SE-ResNet50</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.21.21.2\">81.79</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.21.21.3\">80.24</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.22.22\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.22.22.1\">SE-ResNet101</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.22.22.2\">83.10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.22.22.3\">81.31</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.23.23\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.23.23.1\">SE-ResNet152</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.23.23.2\">80.60</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.23.23.3\">81.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.24.24\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" id=\"S4.T2.1.24.24.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T2.1.24.24.1.1\">xResNet</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.1.24.24.2\">xResNet50</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.24.24.3\">74.40</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.24.24.4\">73.33</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T2.1.24.24.5\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T2.1.24.24.5.1\">73.79</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.25.25\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.1.25.25.1\">xResNet50-Deep</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.25.25.2\">72.26</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.25.25.3\">73.57</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.26.26\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.1.26.26.1\">xResNet50-Deeper</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.26.26.2\">74.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.1.26.26.3\">75.12</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE II: Comparative Analysis of Various Pre-trained CNN Architectures.",
        "footnotes": [],
        "references": [
            "For transfer learning, a base architecture is selected, and the fully connected (FC) layers of a pretrained model are customized for the new task. We evaluated ImageNet-pretrained models from various families of CNN architectures known for their SOTA performance on various benchmarks. Our selection criteria for the base architecture focused on minimizing computational footprint while maximizing classification accuracy. See Table II for details.",
            "For the choice of base architecture, the performance of 26 CNN architectures from the ResNet, Inception, EfficientNet, ResNeXt, SE-ResNeXt, SE-ResNet, and xResNet families was evaluated as shown in Table II.\nImageNet-pretrained models for said architectures were modified as described in Section III-B and evaluated in single-stream mode on spatiotemporal images generated from the DHG1428 dataset with the ‚Äòfront-to‚Äô view orientation.\nFrom the empirical results for two distinct training setups (TS1 and TS2), the ResNet variants ResNet-50 and ResNet-18 were chosen for the multi-stream and ensemble tuner sub-networks, respectively."
        ]
    },
    "S5.T3.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T3.1.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T3.1.1.1.2\">Classification Accuracy (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T3.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T3.1.2.1.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T3.1.2.1.1.1\">e2eET (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T3.1.2.1.2\">97.05</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T3.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T3.1.3.2.1\">Lupinetti et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib17\" title=\"\">17</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T3.1.3.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T3.1.3.2.2.1\">98.78</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE III: Comparison of Validation Accuracy with SOTA on the CNR Dataset",
        "footnotes": [
            "[17]\n\nK. Lupinetti, A. Ranieri, F. Giannini, and M. Monti, ‚Äú3D Dynamic Hand Gestures Recognition Using the Leap Motion Sensor and Convolutional Neural Networks,‚Äù in Augmented Reality, Virtual Reality, and Computer Graphics, L. T. De Paolis and P. Bourdot, Eds.   Cham: Springer International Publishing, 2020, pp. 420‚Äì439."
        ],
        "references": [
            "For the CNR dataset (Table III), our framework had a slightly lower performance than the SOTA [17] by -1.73%. This performance drop was due to the absence of the raw skeleton data for the CNR dataset, which prevented our framework from leveraging the enhancements in temporal information condensation and our specialized multi-stream network."
        ]
    },
    "S5.T4.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T4.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T4.1.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T4.1.1.1.2\">Classification Accuracy (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T4.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T4.1.2.1.1\">Boulahia et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib29\" title=\"\">29</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T4.1.2.1.2\">84.78</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.1.3.2.1\">Lupinetti et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib17\" title=\"\">17</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.3.2.2\">92.11</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T4.1.4.3.1\">Mohammed et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib19\" title=\"\">19</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T4.1.4.3.2\">93.81</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T4.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T4.1.5.4.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T4.1.5.4.1.1\">e2eET (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T4.1.5.4.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T4.1.5.4.2.1\">98.97</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE IV: Comparison of Validation Accuracy with SOTA on the LMDHG Dataset",
        "footnotes": [
            "[29]\n\nS. Y. Boulahia, E. Anquetil, F. Multon, and R. Kulpa, ‚ÄúDynamic hand gesture recognition based on 3D pattern assembled trajectories,‚Äù in 2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA), Nov. 2017, pp. 1‚Äì6.",
            "[17]\n\nK. Lupinetti, A. Ranieri, F. Giannini, and M. Monti, ‚Äú3D Dynamic Hand Gestures Recognition Using the Leap Motion Sensor and Convolutional Neural Networks,‚Äù in Augmented Reality, Virtual Reality, and Computer Graphics, L. T. De Paolis and P. Bourdot, Eds.   Cham: Springer International Publishing, 2020, pp. 420‚Äì439.",
            "[19]\n\nA. Mohammed, Y. Gao, Z. Ji, J. Lv, S. Islam, and Y. Sang, ‚ÄúAutomatic 3D Skeleton-based Dynamic Hand Gesture Recognition Using Multi-Layer Convolutional LSTM,‚Äù in Proceedings of the 7th International Conference on Robotics and Artificial Intelligence, ser. ICRAI ‚Äô21.   New York, NY, USA: Association for Computing Machinery, Apr. 2022, pp. 8‚Äì14. [Online]. Available: https://dl.acm.org/doi/10.1145/3505688.3505690"
        ],
        "references": [
            "For the LMDHG dataset (Table IV), our framework surpassed the SOTA results presented in [19] by +5.16%, attributed to the utilization of our improved data-level fusion approach for generating spatiotemporal images. These evaluation results highlight the effectiveness of our data-level fusion enhancements and the subsequent shift from dynamic hand gesture recognition to static image classification. In addition, our transformation process effectively preserved crucial semantic information by utilizing an optimal sequence of VOs‚Äî[custom, front-away, top-down]."
        ]
    },
    "S5.T5.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T5.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T5.1.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S5.T5.1.1.1.2\">Classification Accuracy (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T5.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T5.1.2.1.1\">Sahbi <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib15\" title=\"\">15</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T5.1.2.1.2\">86.78</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.3.2.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib3\" title=\"\">3</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.3.2.2\">87.32</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.4.3.1\">Liu et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib16\" title=\"\">16</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.4.3.2\">89.04</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.5.4.1\">Peng et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib30\" title=\"\">30</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.5.4.2\">89.04</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.6.5.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib2\" title=\"\">2</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.6.5.2\">90.26</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.7.6.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib7\" title=\"\">7</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.7.6.2\">91.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.8.7.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T5.1.8.7.1.1\">e2eET (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.8.7.2\">91.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.9.8.1\">Narayan et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib20\" title=\"\">20</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.9.8.2\">92.48</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T5.1.10.9.1\">Rehan et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib5\" title=\"\">5</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T5.1.10.9.2\">93.91</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T5.1.11.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T5.1.11.10.1\">Sabater et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib31\" title=\"\">31</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T5.1.11.10.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T5.1.11.10.2.1\">95.93</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE V: Comparison of Validation Accuracy with SOTA on the FPHA Dataset",
        "footnotes": [
            "[15]\n\nH. Sahbi, ‚ÄúSkeleton-based Hand-Gesture Recognition with Lightweight Graph Convolutional Networks,‚Äù arXiv:2104.04255 [cs], Apr. 2021. [Online]. Available: http://arxiv.org/abs/2104.04255",
            "[3]\n\nS. Li, Z. Liu, G. Duan, and J. Tan, ‚ÄúMVHANet: Multi-view hierarchical aggregation network for skeleton-based hand gesture recognition,‚Äù Signal, Image and Video Processing, vol. 17, no. 5, pp. 2521‚Äì2529, Jul. 2023. [Online]. Available: https://doi.org/10.1007/s11760-022-02469-9",
            "[16]\n\nJ. Liu, Y. Wang, S. Xiang, and C. Pan, ‚ÄúHAN: An Efficient Hierarchical Self-Attention Network for Skeleton-Based Gesture Recognition,‚Äù arXiv:2106.13391 [cs], Jun. 2021. [Online]. Available: http://arxiv.org/abs/2106.13391",
            "[30]\n\nS.-H. Peng and P.-H. Tsai, ‚ÄúAn Efficient Graph Convolution Network for Skeleton-Based Dynamic Hand Gesture Recognition,‚Äù IEEE Transactions on Cognitive and Developmental Systems, vol. 15, no. 4, pp. 2179‚Äì2189, Dec. 2023. [Online]. Available: https://ieeexplore.ieee.org/document/10039714",
            "[2]\n\nC. Li, S. Li, Y. Gao, X. Zhang, and W. Li, ‚ÄúA Two-stream Neural Network for Pose-based Hand Gesture Recognition,‚Äù arXiv:2101.08926 [cs], Jan. 2021. [Online]. Available: http://arxiv.org/abs/2101.08926",
            "[7]\n\nY. Li, G. Wei, C. Desrosiers, and Y. Zhou, ‚ÄúDecoupled and boosted learning for skeleton-based dynamic hand gesture recognition,‚Äù Pattern Recognition, vol. 153, p. 110536, Sep. 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0031320324002875",
            "[20]\n\nS. Narayan, A. P. Mazumdar, and S. K. Vipparthi, ‚ÄúSBI-DHGR: Skeleton-based intelligent dynamic hand gestures recognition,‚Äù Expert Systems with Applications, vol. 232, p. 120735, Dec. 2023. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S095741742301237X",
            "[5]\n\nM. Rehan, H. Wannous, J. Alkheir, and K. Aboukassem, ‚ÄúLearning Co-occurrence Features Across Spatial and Temporal Domains for Hand Gesture Recognition,‚Äù in Proceedings of the 19th International Conference on Content-based Multimedia Indexing, ser. CBMI ‚Äô22.   New York, NY, USA: Association for Computing Machinery, Oct. 2022, pp. 36‚Äì42. [Online]. Available: https://dl.acm.org/doi/10.1145/3549555.3549591",
            "[31]\n\nA. Sabater, I. Alonso, L. Montesano, and A. C. Murillo, ‚ÄúDomain and View-point Agnostic Hand Action Recognition,‚Äù arXiv:2103.02303 [cs], Oct. 2021. [Online]. Available: http://arxiv.org/abs/2103.02303"
        ],
        "references": [
            "The FPHA dataset is particularly challenging for HGR evaluation due to the low ratio of gesture sequences (1175) to gesture classes (45). This difficulty is compounded by the 1:1 evaluation protocol, which results in closely balanced training and validation proportions. As shown in (Table V), our framework fell short of the SOTA [31] by -4.10%, even with the optimal sequence of VOs‚Äî[front-away, custom, top-down]."
        ]
    },
    "S5.T6.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T6.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T6.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T6.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T6.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S5.T6.1.1.1.2\">Classification Accuracy (%)</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S5.T6.1.2.2.1\">14G</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S5.T6.1.2.2.2\">28G</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S5.T6.1.2.2.3\">Average</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T6.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T6.1.3.1.1\">Aiman et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib14\" title=\"\">14</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.1.3.1.2\">94.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.1.3.1.3\">89.04</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T6.1.3.1.4\">91.72</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.4.2.1\">Mahmud et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib10\" title=\"\">10</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.4.2.2\">93.81</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.4.2.3\">90.24</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.4.2.4\">92.03</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.5.3.1\">Sabater et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib31\" title=\"\">31</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.5.3.2\">93.57</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.5.3.3\">91.43</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.5.3.4\">92.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.6.4.1\">Balaji et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib8\" title=\"\">8</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.6.4.2\">94.17</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.6.4.3\">93.21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.6.4.4\">93.69</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.7.5.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib3\" title=\"\">3</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.7.5.2\">94.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.7.5.3\">92.56</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.7.5.4\">93.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.8.6.1\">Liu et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib16\" title=\"\">16</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.8.6.2\">95.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.8.6.3\">92.86</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.8.6.4\">93.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.9.7.1\">Rehan et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib5\" title=\"\">5</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.9.7.2\">95.60</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.9.7.3\">92.74</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.9.7.4\">94.17</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.10.8.1\">Peng et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib30\" title=\"\">30</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.10.8.2\">95.36</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.10.8.3\">93.10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.10.8.4\">94.23</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.11.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.11.9.1\">Mohammed et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib19\" title=\"\">19</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.11.9.2\">95.60</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.11.9.3\">93.10</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.11.9.4\">94.35</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.12.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.12.10.1\">Narayan et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib20\" title=\"\">20</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.12.10.2\">97.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.12.10.3\">92.36</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.12.10.4\">94.68</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.13.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.13.11.1\">Deng et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib1\" title=\"\">1</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.13.11.2\">96.40</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.13.11.3\">93.30</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.13.11.4\">94.85</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.14.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.14.12.1\">Miah et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib4\" title=\"\">4</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.14.12.2\">97.01</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.14.12.3\">92.78</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.14.12.4\">94.90</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.15.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.15.13.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib7\" title=\"\">7</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.15.13.2\">96.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.15.13.3\">94.17</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.15.13.4\">95.53</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.16.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T6.1.16.14.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T6.1.16.14.1.1\">e2eET (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.16.14.2\">97.86</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.16.14.3\">95.36</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T6.1.16.14.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.1.16.14.4.1\">96.61</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T6.1.17.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T6.1.17.15.1\">Zhao et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib23\" title=\"\">23</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.1.17.15.2\">97.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.1.17.15.3\">95.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T6.1.17.15.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T6.1.17.15.4.1\">96.72</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE VI: Comparison of Validation Accuracy with SOTA on the SHREC2017 Dataset",
        "footnotes": [
            "[14]\n\nU. Aiman and T. Ahmad, ‚ÄúAngle based hand gesture recognition using graph convolutional network,‚Äù Computer Animation and Virtual Worlds, vol. 35, no. 1, p. e2207, 2024. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.2207",
            "[10]\n\nH. Mahmud, M. M. Morshed, and M. K. Hasan, ‚ÄúQuantized depth image and skeleton-based multimodal dynamic hand gesture recognition,‚Äù The Visual Computer, vol. 40, no. 1, pp. 11‚Äì25, Jan. 2024. [Online]. Available: https://doi.org/10.1007/s00371-022-02762-1",
            "[31]\n\nA. Sabater, I. Alonso, L. Montesano, and A. C. Murillo, ‚ÄúDomain and View-point Agnostic Hand Action Recognition,‚Äù arXiv:2103.02303 [cs], Oct. 2021. [Online]. Available: http://arxiv.org/abs/2103.02303",
            "[8]\n\nP. Balaji and M. Ranjan Prusty, ‚ÄúMultimodal fusion hierarchical self-attention network for dynamic hand gesture recognition,‚Äù Journal of Visual Communication and Image Representation, vol. 98, p. 104019, Feb. 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S1047320323002699",
            "[3]\n\nS. Li, Z. Liu, G. Duan, and J. Tan, ‚ÄúMVHANet: Multi-view hierarchical aggregation network for skeleton-based hand gesture recognition,‚Äù Signal, Image and Video Processing, vol. 17, no. 5, pp. 2521‚Äì2529, Jul. 2023. [Online]. Available: https://doi.org/10.1007/s11760-022-02469-9",
            "[16]\n\nJ. Liu, Y. Wang, S. Xiang, and C. Pan, ‚ÄúHAN: An Efficient Hierarchical Self-Attention Network for Skeleton-Based Gesture Recognition,‚Äù arXiv:2106.13391 [cs], Jun. 2021. [Online]. Available: http://arxiv.org/abs/2106.13391",
            "[5]\n\nM. Rehan, H. Wannous, J. Alkheir, and K. Aboukassem, ‚ÄúLearning Co-occurrence Features Across Spatial and Temporal Domains for Hand Gesture Recognition,‚Äù in Proceedings of the 19th International Conference on Content-based Multimedia Indexing, ser. CBMI ‚Äô22.   New York, NY, USA: Association for Computing Machinery, Oct. 2022, pp. 36‚Äì42. [Online]. Available: https://dl.acm.org/doi/10.1145/3549555.3549591",
            "[30]\n\nS.-H. Peng and P.-H. Tsai, ‚ÄúAn Efficient Graph Convolution Network for Skeleton-Based Dynamic Hand Gesture Recognition,‚Äù IEEE Transactions on Cognitive and Developmental Systems, vol. 15, no. 4, pp. 2179‚Äì2189, Dec. 2023. [Online]. Available: https://ieeexplore.ieee.org/document/10039714",
            "[19]\n\nA. Mohammed, Y. Gao, Z. Ji, J. Lv, S. Islam, and Y. Sang, ‚ÄúAutomatic 3D Skeleton-based Dynamic Hand Gesture Recognition Using Multi-Layer Convolutional LSTM,‚Äù in Proceedings of the 7th International Conference on Robotics and Artificial Intelligence, ser. ICRAI ‚Äô21.   New York, NY, USA: Association for Computing Machinery, Apr. 2022, pp. 8‚Äì14. [Online]. Available: https://dl.acm.org/doi/10.1145/3505688.3505690",
            "[20]\n\nS. Narayan, A. P. Mazumdar, and S. K. Vipparthi, ‚ÄúSBI-DHGR: Skeleton-based intelligent dynamic hand gestures recognition,‚Äù Expert Systems with Applications, vol. 232, p. 120735, Dec. 2023. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S095741742301237X",
            "[1]\n\nZ. Deng, Q. Gao, Z. Ju, and X. Yu, ‚ÄúSkeleton-Based Multifeatures and Multistream Network for Real-Time Action Recognition,‚Äù IEEE Sensors Journal, vol. 23, no. 7, pp. 7397‚Äì7409, Apr. 2023.",
            "[4]\n\nA. S. M. Miah, M. A. M. Hasan, and J. Shin, ‚ÄúDynamic Hand Gesture Recognition Using Multi-Branch Attention Based Graph and General Deep Learning Model,‚Äù IEEE Access, vol. 11, pp. 4703‚Äì4716, 2023.",
            "[7]\n\nY. Li, G. Wei, C. Desrosiers, and Y. Zhou, ‚ÄúDecoupled and boosted learning for skeleton-based dynamic hand gesture recognition,‚Äù Pattern Recognition, vol. 153, p. 110536, Sep. 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0031320324002875",
            "[23]\n\nD. Zhao, H. Li, and S. Yan, ‚ÄúSpatial‚ÄìTemporal Synchronous Transformer for Skeleton-Based Hand Gesture Recognition,‚Äù IEEE Transactions on Circuits and Systems for Video Technology, vol. 34, no. 3, pp. 1403‚Äì1412, Mar. 2024. [Online]. Available: https://ieeexplore.ieee.org/document/10182358"
        ],
        "references": [
            "For the SHREC2017 dataset, the optimal sequence of VOs‚Äî[front-away, custom, front-to]‚Äîresulted in 14G and 28G validation accuracies of 97.86% and 95.36%, respectively. The results presented in Table VI show our framework tied with the SOTA [23] with differences of +0.24% and -0.47% respectively.",
            "For the DHG1428 dataset, the optimal sequence of view orientations‚Äî[custom, top-down, front-away]‚Äîproduced 14G and 28G validation accuracies of 95.83% and 92.38%, respectively. As shown in Table VII, our framework exhibited a marginally lower performance than the SOTA [12] by -2.27% and -1.82%, respectively.\nWhile the SHREC2017 and DHG1428 datasets share similarities, DHG1428 offers an equal distribution of subjects across all classes. Thus, classification accuracies for DHG1428 14G and 28G are consistently lower in the literature compared to SHREC2017, as shown in Table VI and Table VII. Our framework follows this trend, with DHG1428 14G and 28G results being -2.03% and -2.98% lower than their SHREC2017 equivalents."
        ]
    },
    "S5.T7.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T7.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T7.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S5.T7.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T7.1.1.1.1.1\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\" id=\"S5.T7.1.1.1.2\">Classification Accuracy (%)</th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S5.T7.1.2.2.1\">14G</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S5.T7.1.2.2.2\">28G</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S5.T7.1.2.2.3\">Average</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T7.1.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T7.1.3.1.1\">Aiman et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib14\" title=\"\">14</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.3.1.2\">90.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.3.1.3\">88.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T7.1.3.1.4\">89.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.4.2.1\">Mahmud et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib10\" title=\"\">10</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.4.2.2\">90.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.4.2.3\">89.21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.4.2.4\">90.01</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.5.3.1\">Miah et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib4\" title=\"\">4</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.5.3.2\">92.00</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.5.3.3\">88.78</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.5.3.4\">90.39</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.6.4.1\">Mohammed et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib19\" title=\"\">19</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.6.4.2\">91.64</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.6.4.3\">89.46</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.6.4.4\">90.55</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.7.5.1\">Liu et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib16\" title=\"\">16</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.7.5.2\">92.71</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.7.5.3\">89.15</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.7.5.4\">90.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.8.6.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib3\" title=\"\">3</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.8.6.2\">92.36</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.8.6.3\">89.56</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.8.6.4\">90.96</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.9.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.9.7.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib7\" title=\"\">7</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.9.7.2\">94.21</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.9.7.3\">92.11</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.9.7.4\">93.16</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.10.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.10.8.1\">Narayan et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib20\" title=\"\">20</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.10.8.2\">94.64</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.10.8.3\">91.79</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.10.8.4\">93.22</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.11.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.11.9.1\">Zhao et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib23\" title=\"\">23</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.11.9.2\">94.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.11.9.3\">93.18</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.11.9.4\">94.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.12.10\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.12.10.1\">Balaji et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib8\" title=\"\">8</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.12.10.2\">94.11</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.12.10.3\">93.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.12.10.4\">94.00</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.13.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.13.11.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T7.1.13.11.1.1\">e2eET (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.13.11.2\">95.83</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.13.11.3\">92.38</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.13.11.4\">94.11</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.14.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T7.1.14.12.1\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib2\" title=\"\">2</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.14.12.2\">96.31</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.14.12.3\">94.05</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T7.1.14.12.4\">95.18</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T7.1.15.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T7.1.15.13.1\">Tripathi et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib12\" title=\"\">12</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.15.13.2\">98.10</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.15.13.3\">94.20</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T7.1.15.13.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T7.1.15.13.4.1\">96.15</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE VII: Comparison of Validation Accuracy with SOTA on the DHG1428 Dataset",
        "footnotes": [
            "[14]\n\nU. Aiman and T. Ahmad, ‚ÄúAngle based hand gesture recognition using graph convolutional network,‚Äù Computer Animation and Virtual Worlds, vol. 35, no. 1, p. e2207, 2024. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.2207",
            "[10]\n\nH. Mahmud, M. M. Morshed, and M. K. Hasan, ‚ÄúQuantized depth image and skeleton-based multimodal dynamic hand gesture recognition,‚Äù The Visual Computer, vol. 40, no. 1, pp. 11‚Äì25, Jan. 2024. [Online]. Available: https://doi.org/10.1007/s00371-022-02762-1",
            "[4]\n\nA. S. M. Miah, M. A. M. Hasan, and J. Shin, ‚ÄúDynamic Hand Gesture Recognition Using Multi-Branch Attention Based Graph and General Deep Learning Model,‚Äù IEEE Access, vol. 11, pp. 4703‚Äì4716, 2023.",
            "[19]\n\nA. Mohammed, Y. Gao, Z. Ji, J. Lv, S. Islam, and Y. Sang, ‚ÄúAutomatic 3D Skeleton-based Dynamic Hand Gesture Recognition Using Multi-Layer Convolutional LSTM,‚Äù in Proceedings of the 7th International Conference on Robotics and Artificial Intelligence, ser. ICRAI ‚Äô21.   New York, NY, USA: Association for Computing Machinery, Apr. 2022, pp. 8‚Äì14. [Online]. Available: https://dl.acm.org/doi/10.1145/3505688.3505690",
            "[16]\n\nJ. Liu, Y. Wang, S. Xiang, and C. Pan, ‚ÄúHAN: An Efficient Hierarchical Self-Attention Network for Skeleton-Based Gesture Recognition,‚Äù arXiv:2106.13391 [cs], Jun. 2021. [Online]. Available: http://arxiv.org/abs/2106.13391",
            "[3]\n\nS. Li, Z. Liu, G. Duan, and J. Tan, ‚ÄúMVHANet: Multi-view hierarchical aggregation network for skeleton-based hand gesture recognition,‚Äù Signal, Image and Video Processing, vol. 17, no. 5, pp. 2521‚Äì2529, Jul. 2023. [Online]. Available: https://doi.org/10.1007/s11760-022-02469-9",
            "[7]\n\nY. Li, G. Wei, C. Desrosiers, and Y. Zhou, ‚ÄúDecoupled and boosted learning for skeleton-based dynamic hand gesture recognition,‚Äù Pattern Recognition, vol. 153, p. 110536, Sep. 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0031320324002875",
            "[20]\n\nS. Narayan, A. P. Mazumdar, and S. K. Vipparthi, ‚ÄúSBI-DHGR: Skeleton-based intelligent dynamic hand gestures recognition,‚Äù Expert Systems with Applications, vol. 232, p. 120735, Dec. 2023. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S095741742301237X",
            "[23]\n\nD. Zhao, H. Li, and S. Yan, ‚ÄúSpatial‚ÄìTemporal Synchronous Transformer for Skeleton-Based Hand Gesture Recognition,‚Äù IEEE Transactions on Circuits and Systems for Video Technology, vol. 34, no. 3, pp. 1403‚Äì1412, Mar. 2024. [Online]. Available: https://ieeexplore.ieee.org/document/10182358",
            "[8]\n\nP. Balaji and M. Ranjan Prusty, ‚ÄúMultimodal fusion hierarchical self-attention network for dynamic hand gesture recognition,‚Äù Journal of Visual Communication and Image Representation, vol. 98, p. 104019, Feb. 2024. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S1047320323002699",
            "[2]\n\nC. Li, S. Li, Y. Gao, X. Zhang, and W. Li, ‚ÄúA Two-stream Neural Network for Pose-based Hand Gesture Recognition,‚Äù arXiv:2101.08926 [cs], Jan. 2021. [Online]. Available: http://arxiv.org/abs/2101.08926",
            "[12]\n\nR. Tripathi and B. Verma, ‚ÄúMotion feature estimation using bi-directional GRU for skeleton-based dynamic hand gesture recognition,‚Äù Signal, Image and Video Processing, vol. 18, no. 1, pp. 299‚Äì308, Aug. 2024. [Online]. Available: https://doi.org/10.1007/s11760-024-03153-w"
        ],
        "references": [
            "For the DHG1428 dataset, the optimal sequence of view orientations‚Äî[custom, top-down, front-away]‚Äîproduced 14G and 28G validation accuracies of 95.83% and 92.38%, respectively. As shown in Table VII, our framework exhibited a marginally lower performance than the SOTA [12] by -2.27% and -1.82%, respectively.\nWhile the SHREC2017 and DHG1428 datasets share similarities, DHG1428 offers an equal distribution of subjects across all classes. Thus, classification accuracies for DHG1428 14G and 28G are consistently lower in the literature compared to SHREC2017, as shown in Table VI and Table VII. Our framework follows this trend, with DHG1428 14G and 28G results being -2.03% and -2.98% lower than their SHREC2017 equivalents."
        ]
    },
    "S5.T8.1": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T8.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T8.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" id=\"S5.T8.1.1.1.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S5.T8.1.1.1.1.1\">Method</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" id=\"S5.T8.1.1.1.2\">Average Cross-Validation</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.2.2\">\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.2.2.1\">Classification Accuracy (%)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.3.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S5.T8.1.3.3.1\">Liu et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib39\" title=\"\">39</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S5.T8.1.3.3.2\">93.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.4.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T8.1.4.4.1\">Kacem et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib40\" title=\"\">40</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.4.4.2\">93.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.5.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T8.1.5.5.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S5.T8.1.5.5.1.1\">e2eET (Ours)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.5.5.2\">93.96</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.6.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S5.T8.1.6.6.1\">Maghoumi et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib41\" title=\"\">41</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S5.T8.1.6.6.2\">95.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T8.1.7.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S5.T8.1.7.7.1\">Zhang et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.15003v2#bib.bib38\" title=\"\">38</a>]</cite>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S5.T8.1.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T8.1.7.7.2.1\">98.30</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "TABLE VIII: Comparison of Validation Accuracy with SOTA on the SBUKID Dataset",
        "footnotes": [
            "[39]\n\nX. Liu, H. Shi, X. Hong, H. Chen, D. Tao, and G. Zhao, ‚Äú3D Skeletal Gesture Recognition via Hidden States Exploration,‚Äù IEEE Transactions on Image Processing, vol. 29, pp. 4583‚Äì4597, 2020.",
            "[40]\n\nA. Kacem, M. Daoudi, B. B. Amor, S. Berretti, and J. C. Alvarez-Paiva, ‚ÄúA Novel Geometric Framework on Gram Matrix Trajectories for Human Behavior Understanding,‚Äù IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 1, pp. 1‚Äì14, Jan. 2020.",
            "[41]\n\nM. Maghoumi and J. J. LaViola Jr, ‚ÄúDeepGRU: Deep Gesture Recognition Utility,‚Äù arXiv:1810.12514 [cs], Oct. 2019. [Online]. Available: http://arxiv.org/abs/1810.12514",
            "[38]\n\nP. Zhang, C. Lan, J. Xing, W. Zeng, J. Xue, and N. Zheng, ‚ÄúView Adaptive Neural Networks for High Performance Skeleton-Based Human Action Recognition,‚Äù IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 41, no. 8, pp. 1963‚Äì1978, Aug. 2019."
        ],
        "references": [
            "We generated spatiotemporal datasets from the SBUKID dataset using all six VOs and used them to train single-stream versions of the multi-stream sub-network from our specialized e2eET CNN architecture. The evaluation results presented in Table VIII show that our framework compares favourably with frameworks designed specifically for action recognition. The best classification accuracy was obtained from the [front-away] VO, which was only -4.34% lower than the SOTA [38]."
        ]
    }
}