{
    "S4.T1.7": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.7\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.7.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T1.7.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.1.1.1.1\">Architecture</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.7.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.1.1.2.1\">Accuracy</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.7.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.1.1.3.1\">Precision</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.7.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.1.1.4.1\">Recall</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T1.7.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.1.1.5.1\">F1</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.7.2.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T1.7.2.2.1\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.7.2.2.1.1\">Video reference</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.7.2.2.2\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.7.2.2.2.1\">0.98</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.7.2.2.3\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.7.2.2.3.1\">0.99</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.7.2.2.4\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.7.2.2.4.1\">0.98</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.7.2.2.5\"><span class=\"ltx_text ltx_font_italic\" id=\"S4.T1.7.2.2.5.1\">0.98</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.7.3.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T1.7.3.1.1\">No-Fused-1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.7.3.1.2\">0.50</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.7.3.1.3\">0.49</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.7.3.1.4\">0.51</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.7.3.1.5\">0.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.7.4.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.7.4.2.1\">No-Fused-2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.4.2.2\">0.62</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.4.2.3\">0.62</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.4.2.4\">0.63</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.4.2.5\">0.62</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.7.5.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.7.5.3.1\">No-Fused-3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.5.3.2\">0.53</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.5.3.3\">0.53</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.5.3.4\">0.51</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.5.3.5\">0.52</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.7.6.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.7.6.4.1\">No-Fused-4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.6.4.2\">0.76</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.6.4.3\">0.76</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.6.4.4\">0.77</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.6.4.5\">0.77</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.7.7.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T1.7.7.5.1\">Early-Fusing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.7.5.2\">0.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.7.5.3\">0.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.7.5.4\">0.85</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.7.7.5.5\">0.84</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.7.8.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T1.7.8.6.1\">Delayed-Fusing</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.7.8.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.8.6.2.1\">0.95</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.7.8.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.8.6.3.1\">0.95</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.7.8.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.8.6.4.1\">0.95</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.7.8.6.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.7.8.6.5.1\">0.95</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table I: Accuracy and average precision, recall and F1 score of DeepProbHAR with different data fusion strategies. The accuracy of the extracted declarative knowledge tested over the video feed is provided as Video reference and is the upper limit of DeepProbHAR‚Äôs performance.",
        "footnotes": [],
        "references": [
            "Table I summarises the main results of the DeepProbHAR architectures for all the fusion strategies considered in [2] (\\cfSection III-C).\nSimilarly to [2]‚Äôs results, the Delayed-Fusing fusion strategy yields the best results.\nThe model‚Äôs accuracy that combines the data of different antennas, each processed by a separate VAE, closely approaches the accuracy of the reference classifier trained on video data.\nHowever, as highlighted by the confusion matrixes of DeepProbHAR for the various data fusion techniques (Figure 9), classification errors are not limited to the classes walk and run."
        ]
    },
    "S4.T2.4": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.4\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.4.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" id=\"S4.T2.4.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.1.1.1\">Architecture</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.4.1.1.2\"><span class=\"ltx_text ltx_font_sansserif\" id=\"S4.T2.4.1.1.2.1\">DeepProbHAR</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.4.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.1.3.1\">Small MLP</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T2.4.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.1.1.4.1\">Large MLP</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.4.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T2.4.2.1.1\">No-Fused-1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.2.1.2\">0.50</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.2.1.3\">0.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.4.2.1.4\">0.62</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.4.3.2.1\">No-Fused-2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.3.2.2\">0.62</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.3.2.3\">0.74</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.3.2.4\">0.76</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.4.4.3.1\">No-Fused-3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.4.3.2\">0.53</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.4.3.3\">0.58</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.4.3.4\">0.59</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.4.5.4.1\">No-Fused-4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.5.4.2\">0.76</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.5.4.3\">0.78</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.5.4.4\">0.80</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T2.4.6.5.1\">Early-Fusing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.6.5.2\">0.84</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.6.5.3\">0.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.4.6.5.4\">0.89</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.4.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T2.4.7.6.1\">Delayed-Fusing</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.7.6.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.7.6.2.1\">0.95</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.7.6.3.1\">0.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.4.7.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.4.7.6.4.1\">0.98</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table II: Comparison with state-of-the-art non-neuro-symbolic approaches using a single MLP trained on the corresponding dataset of each different architecture.",
        "footnotes": [],
        "references": [
            "In Table II, we compare the results with two state-of-the-art non-neuro-symbolic architectures derived from the work in [2].\nThese architectures use the same VAE and one single MLP substituting the entire neuro-symbolic architecture.\nIn the neuro-symbolic architecture, each of the six MLPs learning a separate feature has 130 parameters (226 for the Delayed-Fusing approach).\nIf we try to approximate the neuro-symbolic architecture using a single small MLP (2 hidden layers, 8 neurons each), the resulting model has 175 parameters (271 for the Delayed-Fusing approach).\nArguably, since the neuro-symbolic architecture features six MLPs, it would be interesting to consider a large MLP (2 hidden layers, 22 neurons each) whose number of parameters closely matches the one of all the neuro-symbolic MLPs.\nThe results in Table II reveal that the neuro-symbolic architectures perform worse than the single MLPs when considering just one antenna, but their accuracy becomes similar when fusing the data from multiple antennas.\nWe also highlight that the models in [2] were evaluated on different activities, so the corresponding MLPs have been trained from scratch in this work."
        ]
    },
    "S4.T3.5": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.5\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.5.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" colspan=\"8\" id=\"S4.T3.5.1.1.1\">\n<span class=\"ltx_text ltx_font_sansserif\" id=\"S4.T3.5.1.1.1.1\">DeepProbHAR</span><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.1.1.1.2\">&#8217;s MLPs</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.5.2.1\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S4.T3.5.2.1.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.2.1\">MLP 1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.3.1\">MLP 2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.4.1\">MLP 3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.5.1\">MLP 4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.6.1\">MLP 5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.7.1\">MLP 6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.2.1.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.2.1.8.1\">Overall</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.3.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.1.1\">Architecture</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.2.1\">(right lower leg)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.3.1\">(right lower leg #2)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.4.1\">(right arm)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.5.1\">(left upper leg)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.6.1\">(left arm)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.7.1\">(left forearm)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.3.2.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.3.2.8.1\">Accuracy</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.4.3.1\">No-Fused-1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.2\">0.80</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.3\">0.79</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.4\">0.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.5\">0.84</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.6\">0.67</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.7\">0.84</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.4.3.8\">0.50</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.5.4\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.5.4.1\">No-Fused-2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.2\">0.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.3\">0.74</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.4\">0.97</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.5\">0.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.6\">0.89</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.7\">0.93</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.5.4.8\">0.62</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.6.5\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.6.5.1\">No-Fused-3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.2\">0.86</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.3\">0.66</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.4\">0.72</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.5\">0.70</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.6\">0.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.7\">0.97</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.6.5.8\">0.53</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.7.6\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.7.6.1\">No-Fused-4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.2\">0.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.7.6.3.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.4\">0.92</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.5\">0.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.6\">0.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.7.6.7.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.7.6.8\">0.76</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.8.7\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.8.7.1\">Early-Fusing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.2\">0.94</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.8.7.3.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.4\">0.85</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.5\">0.99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.6\">0.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.7\">0.99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.8.7.8\">0.84</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.9.8\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.9.8.1\">Delayed-Fusing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.2.1\">0.99</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.3.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.4.1\">0.96</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.5.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.6.1\">0.96</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.7.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.9.8.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.9.8.8.1\">0.95</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.10.9\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt ltx_border_tt\" colspan=\"8\" id=\"S4.T3.5.10.9.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.10.9.1.1\">MLPs trained independently on finely labelled dataset of simple movements</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.11.10\">\n<th class=\"ltx_td ltx_th ltx_th_row\" id=\"S4.T3.5.11.10.1\"></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.2.1\">MLP 1</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.3.1\">MLP 2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.4.1\">MLP 3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.5.1\">MLP 4</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.6.1\">MLP 5</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.7.1\">MLP 6</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.11.10.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.11.10.8.1\">Overall</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.12.11\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.12.11.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.1.1\">Architecture</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.2.1\">(right lower leg)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.3.1\">(right lower leg #2)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.4.1\">(right arm)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.5.1\">(left upper leg)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.6.1\">(left arm)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.7.1\">(left forearm)</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.12.11.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.12.11.8.1\">Accuracy</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.13.12\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" id=\"S4.T3.5.13.12.1\">No-Fused-1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.2\">0.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.3\">0.81</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.4\">0.68</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.5\">0.84</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.6\">0.85</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.7\">0.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T3.5.13.12.8\">0.59</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.14.13\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.14.13.1\">No-Fused-2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.2\">0.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.3\">0.82</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.4\">0.97</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.5\">0.99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.6\">0.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.7\">0.93</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.14.13.8\">0.70</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.15.14\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.15.14.1\">No-Fused-3</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.2\">0.89</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.3\">0.68</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.4\">0.74</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.5\">0.70</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.6\">0.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.7\">0.99</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.15.14.8\">0.58</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.16.15\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.16.15.1\">No-Fused-4</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.2\">0.90</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.3\">0.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.4\">0.92</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.5\">0.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.6\">0.88</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.16.15.7.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.16.15.8\">0.79</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.17.16\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" id=\"S4.T3.5.17.16.1\">Early-Fusing</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.2\">0.96</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.3\">0.98</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.4\">0.87</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.17.16.5.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.6\">0.89</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.17.16.7.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.5.17.16.8\">0.86</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.18.17\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.5.18.17.1\">Delayed-Fusing</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.2.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.3.1\">0.99</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.4.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.5.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.6.1\">0.98</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.7.1\">1.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.18.17.8\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.18.17.8.1\">0.98</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table III: Classification accuracy of the various DeepProbHAR‚Äôs MLPs compared to specialised MLPs trained on a finely labelled dataset of simple movements.",
        "footnotes": [],
        "references": [
            "Table III (top) shows the results of the six MLPs that have been trained in DeepProbHAR, one for each feature as illustrated in Figure 6. For the sake of comparison, we also trained independently six MLP over a finely labelled dataset of simple movements ‚Äì it is worth mentioning that labelling such a dataset could be extremely costly in less controlled settings ‚Äì so that each MLP was optimised to classify only one of the relevant features, see Table III (bottom).",
            "Secondly, the overall accuracy (last column) is lower than each of the accuracies for all the MLPs.\nThis is due to the independence assumptions underlying the training of all such neural networks and their subsequent usage for classification, whether via DeepProbHAR (which relies on the same strong independence assumptions of ProbLog [20, 18]444For a more comprehensive discussion on the role of probabilistic dependencies among variables in probabilistic circuits ‚Äì including those derived from ProbLog ‚Äì we refer the interested reader to [21].) or by a deterministic classifier that follows the decision tree in Fig. 6.\nIndeed, given a neural network f‚Å¢(‚ãÖ)ùëì‚ãÖf(\\cdot)italic_f ( ‚ãÖ ), its accuracy can be seen as the probability of f‚Å¢(‚ãÖ)ùëì‚ãÖf(\\cdot)italic_f ( ‚ãÖ ) to return the correct answer for a given input.\nIn Fig. 6, for instance, we see that classifying running and walking relies on three of the classifiers whose accuracies are available in Table III: MLP 1 that tells if the right lower leg moves; MLP 2 that tells if the right lower leg moves a lot; and MLP 3 that tells if the right upper arm moves.\nUnder independence assumptions, the probability of correct classification of running and walking is the product of the probability that each of the three classifiers returns a correct answer.\nThe average of the probabilities of correct classification for each of the activities as the product of the probabilities of correct classifications for the MLPs used for such a classification according to Figure 6 amounts to the same overall accuracy as computed in the last column of Table III."
        ]
    }
}