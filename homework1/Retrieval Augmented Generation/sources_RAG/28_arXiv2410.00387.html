<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation</title>
<!--Generated on Tue Oct  1 04:02:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.00387v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S1" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S2" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S2.SS1" title="In 2 Background and Related Work ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>The glossing task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S2.SS2" title="In 2 Background and Related Work ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Related Work</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3.SS1" title="In 3 Methodology ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Using Naive RAG to correct the output of a smaller model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3.SS2" title="In 3 Methodology ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Generating Labeling Justifications and Confidence Scores</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3.SS3" title="In 3 Methodology ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Modular RAG: Training the retriever with the sequence to sequence model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3.SS4" title="In 3 Methodology ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Baseline Glossing Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S4" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Uspanteko and Arapaho: Data and Grammars</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S4.SS0.SSS0.Px1" title="In 4 Uspanteko and Arapaho: Data and Grammars ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title">Data.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S5" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments and results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S6" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Qualitative analysis: usability</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S6.SS0.SSS0.Px1" title="In 6 Qualitative analysis: usability ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title">Glossing error types.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S6.SS0.SSS0.Px2" title="In 6 Qualitative analysis: usability ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title">Quality of explanations.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S7" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S8" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S9" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Ethical Considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A1" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Sample explanations</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A1.SS1" title="In Appendix A Sample explanations ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Uspanteko Example</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A1.SS2" title="In Appendix A Sample explanations ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Arapaho Example</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2" title="In Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Details of qualitative analyses</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.SS1" title="In Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Glossing error types</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.SS2" title="In Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Quality of explanations</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Boosting the Capabilities of Compact Models
in Low-Data Contexts

<br class="ltx_break"/>with Large Language Models and Retrieval-Augmented Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bhargav Shandilya and
Alexis Palmer 
<br class="ltx_break"/>University of Colorado Boulder
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{bhargav.shandilya,alexis.palmer}@colorado.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">The data and compute requirements of current language modeling technology pose challenges for the processing and analysis of low-resource languages. Declarative linguistic knowledge has the potential to partially bridge this data scarcity gap by providing models with useful inductive bias in the form of language-specific rules.
In this paper, we propose a retrieval augmented generation (RAG) framework backed by a large language model (LLM) to correct the output of a smaller model for the linguistic task of morphological glossing.
We leverage linguistic information to make up for the lack of data and trainable parameters, while allowing for inputs from written descriptive grammars interpreted and distilled through an LLM.</p>
<p class="ltx_p" id="id3.id2">The results demonstrate that significant leaps in performance and efficiency are possible with the right combination of: a) linguistic inputs in the form of grammars, b) the interpretive power of LLMs, and c) the trainability of smaller token classification networks. We show that a compact, RAG-supported model is highly effective in data-scarce settings, achieving a new state-of-the-art for this task and our target languages.
Our work also offers documentary linguists a more reliable and more usable tool for morphological glossing by providing well-reasoned explanations and confidence scores for each output. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code and data samples are available and will be released upon publication.</span></span></span></p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_ERROR undefined" id="p1.2.2">\ul</span>
</p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<div class="ltx_block ltx_align_bottom" id="p2.1">
<p class="ltx_p" id="p2.1.1"><span class="ltx_text ltx_font_bold" id="p2.1.1.1">Boosting the Capabilities of Compact Models
in Low-Data Contexts

<br class="ltx_break"/>with Large Language Models and Retrieval-Augmented Generation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p2.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p2.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p2.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p2.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p2.1.2.1.1.1.1.1.1">Bhargav Shandilya and
Alexis Palmer</span></span></span>
<span class="ltx_tr" id="p2.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.2.2.1">University of Colorado Boulder</span></span>
<span class="ltx_tr" id="p2.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p2.1.2.1.1.3.3.1"><span class="ltx_text ltx_font_typewriter" id="p2.1.2.1.1.3.3.1.1">{bhargav.shandilya,alexis.palmer}@colorado.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="515" id="S1.F1.g1" src="extracted/5891121/imgs/RAG-p1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>One Uspanteko sentence, with its original gloss, a predicted gloss, and an explanation from our IGT-RAG model. For each morpheme in the sentence, the model describes which section of the provided Uspanteko grammar it used to make its labeling decision.</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Over the last decade, language models have evolved rapidly, culminating in impressively domain-agnostic decoder-only models like GPT <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib4" title="">2020</a>)</cite> and Llama 2 <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib18" title="">2023</a>)</cite>. Although these models can be versatile in terms of being applicable to a wide variety of tasks and providing straightforward interfaces for quick inference, the fact remains that they are extremely parameter-heavy, making them difficult and expensive to train <cite class="ltx_cite ltx_citemacro_cite">Bender and Koller (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib3" title="">2020</a>)</cite>. LLMs, however, give us a unique descriptive power that can boost explainability when used in certain contexts. In this paper, we examine how LLMs can be used to make RAG-informed corrections for the task of morpheme glossing (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S2.SS1" title="2.1 The glossing task ‣ 2 Background and Related Work ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2.1</span></a>), a crucial and time-intensive part of the workflow of documenting endangered languages. Retrieval augmented generation (RAG) incorporates an initial retrieval step, where LLMs query an external data source to gather relevant information before generating answers or text. This retrieval phase not only informs the subsequent generation process but also ensures that the responses are based on solid evidence, thereby improving the accuracy and relevance of the output. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example of one sentence from the Mayan language Uspanteko, its true and predicted morpheme glosses, and the explanations produced by our RAG pipeline.
We test and compare the efficacy of two popular LLMs - Claude 3.5 Sonnet <cite class="ltx_cite ltx_citemacro_cite">Anthropic (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib2" title="">2024</a>)</cite> and GPT-4 <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib1" title="">2023</a>)</cite>. In our experiments, Claude-3.5-Sonnet gives the most promising outputs, with both word and morpheme-level accuracies improving significantly over baselines for Uspanteko and Arapaho.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">LLMs also come with a known limitation: they are inherently data-hungry, relying on vast amounts of training data to achieve their impressive performance <cite class="ltx_cite ltx_citemacro_cite">Holmström et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib12" title="">2023</a>)</cite>. This characteristic makes them less effective when dealing with small datasets, particularly prevalent in low-resource language contexts such as supporting documentation of endangered languages.
In these scenarios, leaner, tailor-made models
seem to be preferred, offering better computational efficiency and flexibility.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper, we specifically focus on the low-resource Uspanteko and Arapaho languages (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S4" title="4 Uspanteko and Arapaho: Data and Grammars ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a>) as we have author-approved access to grammar resources and data for these languages. Our approach leverages the knowledge encapsulated in large models combined with these digitized grammars. In <cite class="ltx_cite ltx_citemacro_citet">Reid et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib17" title="">2024</a>)</cite>, Google’s Gemini team demonstrated that they could fit an entire grammar for a low-resource language (Kalamang) in a single prompt owing to the massive context window size of Gemini 1.5.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">While this zero-shot setting may work well for individual inputs, it is important to remember that the model must process the full grammar each time it receives a new prompt.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">It is more computationally efficient and cost-effective to retrieve only the parts of the grammar most relevant to the given query.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The RAG pipeline has been well-established for question-answering tasks, and this paper explores the capacity of LLMs to retrieve, interpret, and use only the relevant, retrieved parts of the grammar in a zero-shot setting to correct the output of a smaller model.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">The process is not just about size reduction; it’s a strategic transfer of linguistic capabilities, ensuring that the compact model inherits the teacher’s strengths while remaining resource-efficient. In our baseline experimental setting, we simply call the LLM
at inference time to correct the output of the smaller token classification network. Experimenting further, we fine-tune the retrieval and re-ranking components in conjunction with the token classification model to boost performance.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Furthermore, large language models can be prompted to explain their chain-of-thought <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib20" title="">2023</a>)</cite>,
an approach with immense benefits for model explainability.
Apart from correcting the output, we also generate a JSON object that contains descriptions of which
chunks were retrieved, how these chunks informed the final output, and the level of confidence the pipeline has in its final predictions.
As seen in figure <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>, the LLM-generated explanations of the results and how RAG was used to achieve them are (largely) coherent and contextually relevant.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">Our specific contributions include (1) development of a RAG pipeline to correct the predictions of a smaller model, (2) improving the usability of NLP models for language documentation by eliciting confidence scores and explanations for each prediction, (3) demonstration of significant performance improvements in low-resource language processing and a new SOTA for this task, and (4) a scalable approach that balances computational efficiency with linguistic accuracy and explainability.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>The glossing task</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The specific task we address in this paper is morphological glossing, a component of the automatic production of interlinear glossed text (IGT).
IGT is a richly-annotated data format widely used in linguistics, especially as one product of work documenting and describing endangered languages.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The data format, an example of which appears below,
consists of multiple interrelated tiers containing different types of linguistic information.
This Uspanteko example is representative of a common IGT configuration, with one tier for the original utterance, one for a morphological segmentation, one for a detailed labeling of the component morphemes, and one line with a translation into a language of wider communication.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<span class="ltx_ERROR undefined" id="S2.SS1.p3.2">\ex</span><span class="ltx_ERROR undefined" id="S2.SS1.p3.3">\begingl</span><span class="ltx_ERROR undefined" id="S2.SS1.p3.4">\gla</span>
<p class="ltx_p" id="S2.SS1.p3.1">xqil//
<span class="ltx_ERROR undefined" id="S2.SS1.p3.1.1">\glb</span>x-<math alttext="\emptyset" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" mathvariant="normal" xref="S2.SS1.p3.1.m1.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><emptyset id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\emptyset</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">∅</annotation></semantics></math>-q-il//
<span class="ltx_ERROR undefined" id="S2.SS1.p3.1.2">\glc</span>COM-A3S-E1P-ver//
<span class="ltx_ERROR undefined" id="S2.SS1.p3.1.3">\glft</span>‘lo vimos’ (‘we saw it’)//
<span class="ltx_ERROR undefined" id="S2.SS1.p3.1.4">\endgl</span><span class="ltx_ERROR undefined" id="S2.SS1.p3.1.5">\xe</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">We focus specifically on the glossline, in which we see a mix of stem translations (e.g. <span class="ltx_text ltx_font_italic" id="S2.SS1.p4.1.1">ver</span> (in English, <span class="ltx_text ltx_font_italic" id="S2.SS1.p4.1.2">to see</span>) for the Uspanteko stem <span class="ltx_text ltx_font_italic" id="S2.SS1.p4.1.3">il</span>) and labels indicating morphosyntactic functions (e.g. <span class="ltx_text ltx_font_smallcaps" id="S2.SS1.p4.1.4">COM</span> indicates marking of completive aspect on the verb stem). Glossing is a sequence-to-sequence problem that can be approached in 2 ways. The first approach is to train a model to segment the data and then view it as a token classification task. The second is to view it as a translation problem with uneven input and output lengths, thus requiring an encoder-decoder model that can perform sequence-to-sequence conversion. In this paper, we use the former approach. The IGT task was the focus of a SIGMORPHON 2023 shared task. The task, resources, and previous models are described in detail in <cite class="ltx_cite ltx_citemacro_citet">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib9" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1">We directly use the segmented data in track 2 of the Sigmorphon 2023 glossing shared task to train our compact model. The corrective LLM only sees the segmented output of the compact model and the unsegmented text in the training data.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://sigmorphon.github.io/sharedtasks/2023/</span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Related Work</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Analyses like those by <cite class="ltx_cite ltx_citemacro_citet">Conneau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib5" title="">2020</a>)</cite> reveal the inadequacies of large language models in capturing the nuances of less-common languages. These studies underline the necessity for specialized models that cater to the unique characteristics of low-resource languages. Furthermore, position papers like <cite class="ltx_cite ltx_citemacro_citet">Bender and Koller (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib3" title="">2020</a>)</cite> critically analyze the bias and limitations in LLMs, advocating for more inclusive and adaptable language technologies. Another interesting approach to incorporating linguistic information is described in <cite class="ltx_cite ltx_citemacro_citet">Tziafas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib19" title="">2023</a>)</cite>. They directly apply syntactic supervision at the pre-training stage to enhance the model with syntactic awareness. While this approach shows promising results, pre-training again requires large amounts of labeled data which is not available in a low resource setting.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Introduced by <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib13" title="">2021</a>)</cite>, Retrieval-Augmented Generation (RAG) represents a significant advancement in the field of large language models (LLMs) for enhancing generative tasks. By dynamically retrieving information from knowledge bases during inference, RAG effectively addresses issues such as the generation of factually incorrect content, often referred to as “hallucinations.” The integration of RAG into LLMs has been rapidly adopted, making it a crucial technology for enhancing chatbot capabilities and making LLMs more practical for real-world applications.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Naive RAG is the most basic form of retrieval augmented generation. The retrieve-read framework, which was described by <cite class="ltx_cite ltx_citemacro_citet">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib15" title="">2023</a>)</cite>, explains the process of indexing and vectorizing reference documents, retrieving relevant chunks based on vector similarity, and generating outputs based on compound prompts that combine the chunks and the query. The idea of RAG has since been expanded and adapted to several domains.
<cite class="ltx_cite ltx_citemacro_citet">Yan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib22" title="">2024</a>)</cite> suggest a corrective RAG (CRAG) approach that incorporates a lightweight retrieval evaluator to test the quality and relevance of the retrieved content. The information is then filtered or accepted in the process of producing the final output. In our paper, we also add a corrective step in a different context. Instead of evaluating the retriever, we make the LLM itself generate confidence scores for each of its predicted outputs.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Other recent work on the IGT task takes various approaches. <cite class="ltx_cite ltx_citemacro_citet">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib10" title="">2024b</a>)</cite> build a very large, multilingual corpus of IGT and use it to finetune a ByT5 model <cite class="ltx_cite ltx_citemacro_cite">Xue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib21" title="">2022</a>)</cite>, achieving good results especially on languages not seen in training.
<cite class="ltx_cite ltx_citemacro_citet">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib11" title="">2024</a>)</cite> train models to extract IGT directly from audio data, and
<cite class="ltx_cite ltx_citemacro_citet">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib8" title="">2024a</a>)</cite> explore the use of in-context examples to teach LLMs to gloss low-resource language data. Using the same dataset we use, they find that LLM performance improves dramatically with targeted selection of examples. Even with no traditional training or fine-tuning, models like Gemini 1.5 Pro, Cohere’s Command R+ and GPT-4o outperform transformer baselines.
We do not explore few-shot prompting techniques, but it is possible that the performance of our corrective LLM can be further enhanced in this way.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our approach combines the strengths of compact token classification models with the knowledge embedded in large language models (LLMs) and structured grammatical descriptions. The process involves several key steps:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Initial glossing:</span> A compact token classification model (either RoBERTa or Bi-LSTM) generates an initial morphological gloss for the input sentence.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Retrieval:</span> Relevant chunks of grammatical information are retrieved based on the input sentence and initial gloss.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Augmented generation:</span> An LLM uses the retrieved grammar chunks to correct and refine the initial gloss.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Explanation generation:</span> The LLM provides detailed explanations and confidence scores for each morpheme in the corrected gloss.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">Modular optimization:</span> In an advanced version of our approach, we fine-tune the retrieval and token classification components together to optimize the entire pipeline.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.p1.2">We explore two main variants of this approach: a naive RAG method and a modular RAG method.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Using Naive RAG to correct the output of a smaller model</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The Naive Retrieval-Augmented Generation (RAG) approach enhances the performance of two compact token classification models trained for glossing of Uspanteko and Arapaho. The process begins by indexing and vectorizing reference grammar documents using a dense vector representation like BERT embeddings <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib7" title="">2018</a>)</cite>. Here, we use OpenAI embeddings <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib1" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.5">Let <math alttext="D={d_{1},d_{2},\ldots d_{n}}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.3"><semantics id="S3.SS1.p2.1.m1.3a"><mrow id="S3.SS1.p2.1.m1.3.3" xref="S3.SS1.p2.1.m1.3.3.cmml"><mi id="S3.SS1.p2.1.m1.3.3.5" xref="S3.SS1.p2.1.m1.3.3.5.cmml">D</mi><mo id="S3.SS1.p2.1.m1.3.3.4" xref="S3.SS1.p2.1.m1.3.3.4.cmml">=</mo><mrow id="S3.SS1.p2.1.m1.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.4.cmml"><msub id="S3.SS1.p2.1.m1.1.1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.1.1.1.2.cmml">d</mi><mn id="S3.SS1.p2.1.m1.1.1.1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.1.m1.3.3.3.3.4" xref="S3.SS1.p2.1.m1.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.1.m1.2.2.2.2.2" xref="S3.SS1.p2.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.p2.1.m1.2.2.2.2.2.2" xref="S3.SS1.p2.1.m1.2.2.2.2.2.2.cmml">d</mi><mn id="S3.SS1.p2.1.m1.2.2.2.2.2.3" xref="S3.SS1.p2.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p2.1.m1.3.3.3.3.5" xref="S3.SS1.p2.1.m1.3.3.3.4.cmml">,</mo><mrow id="S3.SS1.p2.1.m1.3.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.3.3.cmml"><mi id="S3.SS1.p2.1.m1.3.3.3.3.3.2" mathvariant="normal" xref="S3.SS1.p2.1.m1.3.3.3.3.3.2.cmml">…</mi><mo id="S3.SS1.p2.1.m1.3.3.3.3.3.1" xref="S3.SS1.p2.1.m1.3.3.3.3.3.1.cmml">⁢</mo><msub id="S3.SS1.p2.1.m1.3.3.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3.cmml"><mi id="S3.SS1.p2.1.m1.3.3.3.3.3.3.2" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3.2.cmml">d</mi><mi id="S3.SS1.p2.1.m1.3.3.3.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3.3.cmml">n</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.3b"><apply id="S3.SS1.p2.1.m1.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3"><eq id="S3.SS1.p2.1.m1.3.3.4.cmml" xref="S3.SS1.p2.1.m1.3.3.4"></eq><ci id="S3.SS1.p2.1.m1.3.3.5.cmml" xref="S3.SS1.p2.1.m1.3.3.5">𝐷</ci><list id="S3.SS1.p2.1.m1.3.3.3.4.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3"><apply id="S3.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.1.2">𝑑</ci><cn id="S3.SS1.p2.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2.2.2">𝑑</ci><cn id="S3.SS1.p2.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.2.2.2.2.2.3">2</cn></apply><apply id="S3.SS1.p2.1.m1.3.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3"><times id="S3.SS1.p2.1.m1.3.3.3.3.3.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3.1"></times><ci id="S3.SS1.p2.1.m1.3.3.3.3.3.2.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3.2">…</ci><apply id="S3.SS1.p2.1.m1.3.3.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.3.3.3.3.3.3.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.1.m1.3.3.3.3.3.3.2.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3.2">𝑑</ci><ci id="S3.SS1.p2.1.m1.3.3.3.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3.3.3">𝑛</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.3c">D={d_{1},d_{2},\ldots d_{n}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.3d">italic_D = italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> be the set of <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_n</annotation></semantics></math> grammar document chunks, where each <math alttext="d_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">d</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑑</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is represented as a dense vector <math alttext="v_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">v</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝑣</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">v_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in a high-dimensional space <math alttext="R^{d}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><msup id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">R</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝑅</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">R^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>. We experimented with different chunk sizes and chunking strategies and found that a default chunk size of 400 characters with a 50-character overlap on either side provided the best results across 5 trials. We also tried chunking according to headings in the grammar, but this resulted in chunks of uneven sizes that did not optimally aid the retrieval process and contextual inference.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.3">Given an input query <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_q</annotation></semantics></math>, in this case the sentence to be glossed along with the attempted prediction of the compact model, the retriever module computes the cosine similarity between the query embedding <math alttext="v_{q}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">v</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝑣</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">v_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_v start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and each document chunk embedding <math alttext="v_{i}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">v</mi><mi id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">𝑣</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">v_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{sim}(q,d_{i})=\frac{v_{q}\cdot v_{i}}{\|v_{q}\|\|v_{i}\|}" class="ltx_Math" display="block" id="S3.Ex1.m1.4"><semantics id="S3.Ex1.m1.4a"><mrow id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.4.4.cmml"><mrow id="S3.Ex1.m1.4.4.1" xref="S3.Ex1.m1.4.4.1.cmml"><mtext id="S3.Ex1.m1.4.4.1.3" xref="S3.Ex1.m1.4.4.1.3a.cmml">sim</mtext><mo id="S3.Ex1.m1.4.4.1.2" xref="S3.Ex1.m1.4.4.1.2.cmml">⁢</mo><mrow id="S3.Ex1.m1.4.4.1.1.1" xref="S3.Ex1.m1.4.4.1.1.2.cmml"><mo id="S3.Ex1.m1.4.4.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.2.cmml">(</mo><mi id="S3.Ex1.m1.3.3" xref="S3.Ex1.m1.3.3.cmml">q</mi><mo id="S3.Ex1.m1.4.4.1.1.1.3" xref="S3.Ex1.m1.4.4.1.1.2.cmml">,</mo><msub id="S3.Ex1.m1.4.4.1.1.1.1" xref="S3.Ex1.m1.4.4.1.1.1.1.cmml"><mi id="S3.Ex1.m1.4.4.1.1.1.1.2" xref="S3.Ex1.m1.4.4.1.1.1.1.2.cmml">d</mi><mi id="S3.Ex1.m1.4.4.1.1.1.1.3" xref="S3.Ex1.m1.4.4.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.Ex1.m1.4.4.1.1.1.4" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.4.4.2" xref="S3.Ex1.m1.4.4.2.cmml">=</mo><mfrac id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml"><mrow id="S3.Ex1.m1.2.2.4" xref="S3.Ex1.m1.2.2.4.cmml"><msub id="S3.Ex1.m1.2.2.4.2" xref="S3.Ex1.m1.2.2.4.2.cmml"><mi id="S3.Ex1.m1.2.2.4.2.2" xref="S3.Ex1.m1.2.2.4.2.2.cmml">v</mi><mi id="S3.Ex1.m1.2.2.4.2.3" xref="S3.Ex1.m1.2.2.4.2.3.cmml">q</mi></msub><mo id="S3.Ex1.m1.2.2.4.1" lspace="0.222em" rspace="0.222em" xref="S3.Ex1.m1.2.2.4.1.cmml">⋅</mo><msub id="S3.Ex1.m1.2.2.4.3" xref="S3.Ex1.m1.2.2.4.3.cmml"><mi id="S3.Ex1.m1.2.2.4.3.2" xref="S3.Ex1.m1.2.2.4.3.2.cmml">v</mi><mi id="S3.Ex1.m1.2.2.4.3.3" xref="S3.Ex1.m1.2.2.4.3.3.cmml">i</mi></msub></mrow><mrow id="S3.Ex1.m1.2.2.2" xref="S3.Ex1.m1.2.2.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.2.cmml"><mo id="S3.Ex1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.2.1.cmml">‖</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.cmml">q</mi></msub><mo id="S3.Ex1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.2.1.cmml">‖</mo></mrow><mo id="S3.Ex1.m1.2.2.2.3" xref="S3.Ex1.m1.2.2.2.3.cmml">⁢</mo><mrow id="S3.Ex1.m1.2.2.2.2.1" xref="S3.Ex1.m1.2.2.2.2.2.cmml"><mo id="S3.Ex1.m1.2.2.2.2.1.2" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.2.1.cmml">‖</mo><msub id="S3.Ex1.m1.2.2.2.2.1.1" xref="S3.Ex1.m1.2.2.2.2.1.1.cmml"><mi id="S3.Ex1.m1.2.2.2.2.1.1.2" xref="S3.Ex1.m1.2.2.2.2.1.1.2.cmml">v</mi><mi id="S3.Ex1.m1.2.2.2.2.1.1.3" xref="S3.Ex1.m1.2.2.2.2.1.1.3.cmml">i</mi></msub><mo id="S3.Ex1.m1.2.2.2.2.1.3" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.2.1.cmml">‖</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.4b"><apply id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4"><eq id="S3.Ex1.m1.4.4.2.cmml" xref="S3.Ex1.m1.4.4.2"></eq><apply id="S3.Ex1.m1.4.4.1.cmml" xref="S3.Ex1.m1.4.4.1"><times id="S3.Ex1.m1.4.4.1.2.cmml" xref="S3.Ex1.m1.4.4.1.2"></times><ci id="S3.Ex1.m1.4.4.1.3a.cmml" xref="S3.Ex1.m1.4.4.1.3"><mtext id="S3.Ex1.m1.4.4.1.3.cmml" xref="S3.Ex1.m1.4.4.1.3">sim</mtext></ci><interval closure="open" id="S3.Ex1.m1.4.4.1.1.2.cmml" xref="S3.Ex1.m1.4.4.1.1.1"><ci id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3">𝑞</ci><apply id="S3.Ex1.m1.4.4.1.1.1.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.4.4.1.1.1.1.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.4.4.1.1.1.1.2.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2">𝑑</ci><ci id="S3.Ex1.m1.4.4.1.1.1.1.3.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.3">𝑖</ci></apply></interval></apply><apply id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2"><divide id="S3.Ex1.m1.2.2.3.cmml" xref="S3.Ex1.m1.2.2"></divide><apply id="S3.Ex1.m1.2.2.4.cmml" xref="S3.Ex1.m1.2.2.4"><ci id="S3.Ex1.m1.2.2.4.1.cmml" xref="S3.Ex1.m1.2.2.4.1">⋅</ci><apply id="S3.Ex1.m1.2.2.4.2.cmml" xref="S3.Ex1.m1.2.2.4.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.4.2.1.cmml" xref="S3.Ex1.m1.2.2.4.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.4.2.2.cmml" xref="S3.Ex1.m1.2.2.4.2.2">𝑣</ci><ci id="S3.Ex1.m1.2.2.4.2.3.cmml" xref="S3.Ex1.m1.2.2.4.2.3">𝑞</ci></apply><apply id="S3.Ex1.m1.2.2.4.3.cmml" xref="S3.Ex1.m1.2.2.4.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.4.3.1.cmml" xref="S3.Ex1.m1.2.2.4.3">subscript</csymbol><ci id="S3.Ex1.m1.2.2.4.3.2.cmml" xref="S3.Ex1.m1.2.2.4.3.2">𝑣</ci><ci id="S3.Ex1.m1.2.2.4.3.3.cmml" xref="S3.Ex1.m1.2.2.4.3.3">𝑖</ci></apply></apply><apply id="S3.Ex1.m1.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2"><times id="S3.Ex1.m1.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.3"></times><apply id="S3.Ex1.m1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2">𝑣</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3">𝑞</ci></apply></apply><apply id="S3.Ex1.m1.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1"><csymbol cd="latexml" id="S3.Ex1.m1.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.2">norm</csymbol><apply id="S3.Ex1.m1.2.2.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.2">𝑣</ci><ci id="S3.Ex1.m1.2.2.2.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.4c">\text{sim}(q,d_{i})=\frac{v_{q}\cdot v_{i}}{\|v_{q}\|\|v_{i}\|}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.4d">sim ( italic_q , italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = divide start_ARG italic_v start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ⋅ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_v start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ∥ ∥ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p3.6">The top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m1.1"><semantics id="S3.SS1.p3.4.m1.1a"><mi id="S3.SS1.p3.4.m1.1.1" xref="S3.SS1.p3.4.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m1.1b"><ci id="S3.SS1.p3.4.m1.1.1.cmml" xref="S3.SS1.p3.4.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m1.1d">italic_k</annotation></semantics></math> most similar document chunks <math alttext="\mathcal{D}_{q}=\{d_{q1},d_{q2},\ldots,d_{qk}\}" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m2.4"><semantics id="S3.SS1.p3.5.m2.4a"><mrow id="S3.SS1.p3.5.m2.4.4" xref="S3.SS1.p3.5.m2.4.4.cmml"><msub id="S3.SS1.p3.5.m2.4.4.5" xref="S3.SS1.p3.5.m2.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.5.m2.4.4.5.2" xref="S3.SS1.p3.5.m2.4.4.5.2.cmml">𝒟</mi><mi id="S3.SS1.p3.5.m2.4.4.5.3" xref="S3.SS1.p3.5.m2.4.4.5.3.cmml">q</mi></msub><mo id="S3.SS1.p3.5.m2.4.4.4" xref="S3.SS1.p3.5.m2.4.4.4.cmml">=</mo><mrow id="S3.SS1.p3.5.m2.4.4.3.3" xref="S3.SS1.p3.5.m2.4.4.3.4.cmml"><mo id="S3.SS1.p3.5.m2.4.4.3.3.4" stretchy="false" xref="S3.SS1.p3.5.m2.4.4.3.4.cmml">{</mo><msub id="S3.SS1.p3.5.m2.2.2.1.1.1" xref="S3.SS1.p3.5.m2.2.2.1.1.1.cmml"><mi id="S3.SS1.p3.5.m2.2.2.1.1.1.2" xref="S3.SS1.p3.5.m2.2.2.1.1.1.2.cmml">d</mi><mrow id="S3.SS1.p3.5.m2.2.2.1.1.1.3" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.cmml"><mi id="S3.SS1.p3.5.m2.2.2.1.1.1.3.2" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.2.cmml">q</mi><mo id="S3.SS1.p3.5.m2.2.2.1.1.1.3.1" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.1.cmml">⁢</mo><mn id="S3.SS1.p3.5.m2.2.2.1.1.1.3.3" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS1.p3.5.m2.4.4.3.3.5" xref="S3.SS1.p3.5.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p3.5.m2.3.3.2.2.2" xref="S3.SS1.p3.5.m2.3.3.2.2.2.cmml"><mi id="S3.SS1.p3.5.m2.3.3.2.2.2.2" xref="S3.SS1.p3.5.m2.3.3.2.2.2.2.cmml">d</mi><mrow id="S3.SS1.p3.5.m2.3.3.2.2.2.3" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.cmml"><mi id="S3.SS1.p3.5.m2.3.3.2.2.2.3.2" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.2.cmml">q</mi><mo id="S3.SS1.p3.5.m2.3.3.2.2.2.3.1" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.1.cmml">⁢</mo><mn id="S3.SS1.p3.5.m2.3.3.2.2.2.3.3" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.3.cmml">2</mn></mrow></msub><mo id="S3.SS1.p3.5.m2.4.4.3.3.6" xref="S3.SS1.p3.5.m2.4.4.3.4.cmml">,</mo><mi id="S3.SS1.p3.5.m2.1.1" mathvariant="normal" xref="S3.SS1.p3.5.m2.1.1.cmml">…</mi><mo id="S3.SS1.p3.5.m2.4.4.3.3.7" xref="S3.SS1.p3.5.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p3.5.m2.4.4.3.3.3" xref="S3.SS1.p3.5.m2.4.4.3.3.3.cmml"><mi id="S3.SS1.p3.5.m2.4.4.3.3.3.2" xref="S3.SS1.p3.5.m2.4.4.3.3.3.2.cmml">d</mi><mrow id="S3.SS1.p3.5.m2.4.4.3.3.3.3" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.cmml"><mi id="S3.SS1.p3.5.m2.4.4.3.3.3.3.2" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.2.cmml">q</mi><mo id="S3.SS1.p3.5.m2.4.4.3.3.3.3.1" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.5.m2.4.4.3.3.3.3.3" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.3.cmml">k</mi></mrow></msub><mo id="S3.SS1.p3.5.m2.4.4.3.3.8" stretchy="false" xref="S3.SS1.p3.5.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m2.4b"><apply id="S3.SS1.p3.5.m2.4.4.cmml" xref="S3.SS1.p3.5.m2.4.4"><eq id="S3.SS1.p3.5.m2.4.4.4.cmml" xref="S3.SS1.p3.5.m2.4.4.4"></eq><apply id="S3.SS1.p3.5.m2.4.4.5.cmml" xref="S3.SS1.p3.5.m2.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m2.4.4.5.1.cmml" xref="S3.SS1.p3.5.m2.4.4.5">subscript</csymbol><ci id="S3.SS1.p3.5.m2.4.4.5.2.cmml" xref="S3.SS1.p3.5.m2.4.4.5.2">𝒟</ci><ci id="S3.SS1.p3.5.m2.4.4.5.3.cmml" xref="S3.SS1.p3.5.m2.4.4.5.3">𝑞</ci></apply><set id="S3.SS1.p3.5.m2.4.4.3.4.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3"><apply id="S3.SS1.p3.5.m2.2.2.1.1.1.cmml" xref="S3.SS1.p3.5.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.p3.5.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.p3.5.m2.2.2.1.1.1.2">𝑑</ci><apply id="S3.SS1.p3.5.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3"><times id="S3.SS1.p3.5.m2.2.2.1.1.1.3.1.cmml" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.1"></times><ci id="S3.SS1.p3.5.m2.2.2.1.1.1.3.2.cmml" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.2">𝑞</ci><cn id="S3.SS1.p3.5.m2.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p3.5.m2.2.2.1.1.1.3.3">1</cn></apply></apply><apply id="S3.SS1.p3.5.m2.3.3.2.2.2.cmml" xref="S3.SS1.p3.5.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p3.5.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p3.5.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p3.5.m2.3.3.2.2.2.2">𝑑</ci><apply id="S3.SS1.p3.5.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3"><times id="S3.SS1.p3.5.m2.3.3.2.2.2.3.1.cmml" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.1"></times><ci id="S3.SS1.p3.5.m2.3.3.2.2.2.3.2.cmml" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.2">𝑞</ci><cn id="S3.SS1.p3.5.m2.3.3.2.2.2.3.3.cmml" type="integer" xref="S3.SS1.p3.5.m2.3.3.2.2.2.3.3">2</cn></apply></apply><ci id="S3.SS1.p3.5.m2.1.1.cmml" xref="S3.SS1.p3.5.m2.1.1">…</ci><apply id="S3.SS1.p3.5.m2.4.4.3.3.3.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m2.4.4.3.3.3.1.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p3.5.m2.4.4.3.3.3.2.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3.2">𝑑</ci><apply id="S3.SS1.p3.5.m2.4.4.3.3.3.3.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3"><times id="S3.SS1.p3.5.m2.4.4.3.3.3.3.1.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.1"></times><ci id="S3.SS1.p3.5.m2.4.4.3.3.3.3.2.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.2">𝑞</ci><ci id="S3.SS1.p3.5.m2.4.4.3.3.3.3.3.cmml" xref="S3.SS1.p3.5.m2.4.4.3.3.3.3.3">𝑘</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m2.4c">\mathcal{D}_{q}=\{d_{q1},d_{q2},\ldots,d_{qk}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m2.4d">caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = { italic_d start_POSTSUBSCRIPT italic_q 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_q 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_q italic_k end_POSTSUBSCRIPT }</annotation></semantics></math> are retrieved based on their cosine similarity scores. These chunks are concatenated with the original input query to form a compound prompt <math alttext="P" class="ltx_Math" display="inline" id="S3.SS1.p3.6.m3.1"><semantics id="S3.SS1.p3.6.m3.1a"><mi id="S3.SS1.p3.6.m3.1.1" xref="S3.SS1.p3.6.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m3.1b"><ci id="S3.SS1.p3.6.m3.1.1.cmml" xref="S3.SS1.p3.6.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m3.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.6.m3.1d">italic_P</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P=[q;d_{q1};d_{q2};\ldots;d_{qk}]" class="ltx_Math" display="block" id="S3.Ex2.m1.5"><semantics id="S3.Ex2.m1.5a"><mrow id="S3.Ex2.m1.5.5" xref="S3.Ex2.m1.5.5.cmml"><mi id="S3.Ex2.m1.5.5.5" xref="S3.Ex2.m1.5.5.5.cmml">P</mi><mo id="S3.Ex2.m1.5.5.4" xref="S3.Ex2.m1.5.5.4.cmml">=</mo><mrow id="S3.Ex2.m1.5.5.3.3" xref="S3.Ex2.m1.5.5.3.4.cmml"><mo id="S3.Ex2.m1.5.5.3.3.4" stretchy="false" xref="S3.Ex2.m1.5.5.3.4.cmml">[</mo><mi id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml">q</mi><mo id="S3.Ex2.m1.5.5.3.3.5" xref="S3.Ex2.m1.5.5.3.4.cmml">;</mo><msub id="S3.Ex2.m1.3.3.1.1.1" xref="S3.Ex2.m1.3.3.1.1.1.cmml"><mi id="S3.Ex2.m1.3.3.1.1.1.2" xref="S3.Ex2.m1.3.3.1.1.1.2.cmml">d</mi><mrow id="S3.Ex2.m1.3.3.1.1.1.3" xref="S3.Ex2.m1.3.3.1.1.1.3.cmml"><mi id="S3.Ex2.m1.3.3.1.1.1.3.2" xref="S3.Ex2.m1.3.3.1.1.1.3.2.cmml">q</mi><mo id="S3.Ex2.m1.3.3.1.1.1.3.1" xref="S3.Ex2.m1.3.3.1.1.1.3.1.cmml">⁢</mo><mn id="S3.Ex2.m1.3.3.1.1.1.3.3" xref="S3.Ex2.m1.3.3.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.Ex2.m1.5.5.3.3.6" xref="S3.Ex2.m1.5.5.3.4.cmml">;</mo><msub id="S3.Ex2.m1.4.4.2.2.2" xref="S3.Ex2.m1.4.4.2.2.2.cmml"><mi id="S3.Ex2.m1.4.4.2.2.2.2" xref="S3.Ex2.m1.4.4.2.2.2.2.cmml">d</mi><mrow id="S3.Ex2.m1.4.4.2.2.2.3" xref="S3.Ex2.m1.4.4.2.2.2.3.cmml"><mi id="S3.Ex2.m1.4.4.2.2.2.3.2" xref="S3.Ex2.m1.4.4.2.2.2.3.2.cmml">q</mi><mo id="S3.Ex2.m1.4.4.2.2.2.3.1" xref="S3.Ex2.m1.4.4.2.2.2.3.1.cmml">⁢</mo><mn id="S3.Ex2.m1.4.4.2.2.2.3.3" xref="S3.Ex2.m1.4.4.2.2.2.3.3.cmml">2</mn></mrow></msub><mo id="S3.Ex2.m1.5.5.3.3.7" xref="S3.Ex2.m1.5.5.3.4.cmml">;</mo><mi id="S3.Ex2.m1.2.2" mathvariant="normal" xref="S3.Ex2.m1.2.2.cmml">…</mi><mo id="S3.Ex2.m1.5.5.3.3.8" xref="S3.Ex2.m1.5.5.3.4.cmml">;</mo><msub id="S3.Ex2.m1.5.5.3.3.3" xref="S3.Ex2.m1.5.5.3.3.3.cmml"><mi id="S3.Ex2.m1.5.5.3.3.3.2" xref="S3.Ex2.m1.5.5.3.3.3.2.cmml">d</mi><mrow id="S3.Ex2.m1.5.5.3.3.3.3" xref="S3.Ex2.m1.5.5.3.3.3.3.cmml"><mi id="S3.Ex2.m1.5.5.3.3.3.3.2" xref="S3.Ex2.m1.5.5.3.3.3.3.2.cmml">q</mi><mo id="S3.Ex2.m1.5.5.3.3.3.3.1" xref="S3.Ex2.m1.5.5.3.3.3.3.1.cmml">⁢</mo><mi id="S3.Ex2.m1.5.5.3.3.3.3.3" xref="S3.Ex2.m1.5.5.3.3.3.3.3.cmml">k</mi></mrow></msub><mo id="S3.Ex2.m1.5.5.3.3.9" stretchy="false" xref="S3.Ex2.m1.5.5.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.5b"><apply id="S3.Ex2.m1.5.5.cmml" xref="S3.Ex2.m1.5.5"><eq id="S3.Ex2.m1.5.5.4.cmml" xref="S3.Ex2.m1.5.5.4"></eq><ci id="S3.Ex2.m1.5.5.5.cmml" xref="S3.Ex2.m1.5.5.5">𝑃</ci><list id="S3.Ex2.m1.5.5.3.4.cmml" xref="S3.Ex2.m1.5.5.3.3"><ci id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1">𝑞</ci><apply id="S3.Ex2.m1.3.3.1.1.1.cmml" xref="S3.Ex2.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.3.3.1.1.1.1.cmml" xref="S3.Ex2.m1.3.3.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.3.3.1.1.1.2.cmml" xref="S3.Ex2.m1.3.3.1.1.1.2">𝑑</ci><apply id="S3.Ex2.m1.3.3.1.1.1.3.cmml" xref="S3.Ex2.m1.3.3.1.1.1.3"><times id="S3.Ex2.m1.3.3.1.1.1.3.1.cmml" xref="S3.Ex2.m1.3.3.1.1.1.3.1"></times><ci id="S3.Ex2.m1.3.3.1.1.1.3.2.cmml" xref="S3.Ex2.m1.3.3.1.1.1.3.2">𝑞</ci><cn id="S3.Ex2.m1.3.3.1.1.1.3.3.cmml" type="integer" xref="S3.Ex2.m1.3.3.1.1.1.3.3">1</cn></apply></apply><apply id="S3.Ex2.m1.4.4.2.2.2.cmml" xref="S3.Ex2.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.4.4.2.2.2.1.cmml" xref="S3.Ex2.m1.4.4.2.2.2">subscript</csymbol><ci id="S3.Ex2.m1.4.4.2.2.2.2.cmml" xref="S3.Ex2.m1.4.4.2.2.2.2">𝑑</ci><apply id="S3.Ex2.m1.4.4.2.2.2.3.cmml" xref="S3.Ex2.m1.4.4.2.2.2.3"><times id="S3.Ex2.m1.4.4.2.2.2.3.1.cmml" xref="S3.Ex2.m1.4.4.2.2.2.3.1"></times><ci id="S3.Ex2.m1.4.4.2.2.2.3.2.cmml" xref="S3.Ex2.m1.4.4.2.2.2.3.2">𝑞</ci><cn id="S3.Ex2.m1.4.4.2.2.2.3.3.cmml" type="integer" xref="S3.Ex2.m1.4.4.2.2.2.3.3">2</cn></apply></apply><ci id="S3.Ex2.m1.2.2.cmml" xref="S3.Ex2.m1.2.2">…</ci><apply id="S3.Ex2.m1.5.5.3.3.3.cmml" xref="S3.Ex2.m1.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.5.5.3.3.3.1.cmml" xref="S3.Ex2.m1.5.5.3.3.3">subscript</csymbol><ci id="S3.Ex2.m1.5.5.3.3.3.2.cmml" xref="S3.Ex2.m1.5.5.3.3.3.2">𝑑</ci><apply id="S3.Ex2.m1.5.5.3.3.3.3.cmml" xref="S3.Ex2.m1.5.5.3.3.3.3"><times id="S3.Ex2.m1.5.5.3.3.3.3.1.cmml" xref="S3.Ex2.m1.5.5.3.3.3.3.1"></times><ci id="S3.Ex2.m1.5.5.3.3.3.3.2.cmml" xref="S3.Ex2.m1.5.5.3.3.3.3.2">𝑞</ci><ci id="S3.Ex2.m1.5.5.3.3.3.3.3.cmml" xref="S3.Ex2.m1.5.5.3.3.3.3.3">𝑘</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.5c">P=[q;d_{q1};d_{q2};\ldots;d_{qk}]</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.5d">italic_P = [ italic_q ; italic_d start_POSTSUBSCRIPT italic_q 1 end_POSTSUBSCRIPT ; italic_d start_POSTSUBSCRIPT italic_q 2 end_POSTSUBSCRIPT ; … ; italic_d start_POSTSUBSCRIPT italic_q italic_k end_POSTSUBSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p3.9">The prompt <math alttext="P" class="ltx_Math" display="inline" id="S3.SS1.p3.7.m1.1"><semantics id="S3.SS1.p3.7.m1.1a"><mi id="S3.SS1.p3.7.m1.1.1" xref="S3.SS1.p3.7.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m1.1b"><ci id="S3.SS1.p3.7.m1.1.1.cmml" xref="S3.SS1.p3.7.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.7.m1.1d">italic_P</annotation></semantics></math> is then fed into an LLM, which interprets the linguistic rules and morphological patterns described in the retrieved grammar excerpts <math alttext="\mathcal{D}_{q}" class="ltx_Math" display="inline" id="S3.SS1.p3.8.m2.1"><semantics id="S3.SS1.p3.8.m2.1a"><msub id="S3.SS1.p3.8.m2.1.1" xref="S3.SS1.p3.8.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.8.m2.1.1.2" xref="S3.SS1.p3.8.m2.1.1.2.cmml">𝒟</mi><mi id="S3.SS1.p3.8.m2.1.1.3" xref="S3.SS1.p3.8.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m2.1b"><apply id="S3.SS1.p3.8.m2.1.1.cmml" xref="S3.SS1.p3.8.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m2.1.1.1.cmml" xref="S3.SS1.p3.8.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.8.m2.1.1.2.cmml" xref="S3.SS1.p3.8.m2.1.1.2">𝒟</ci><ci id="S3.SS1.p3.8.m2.1.1.3.cmml" xref="S3.SS1.p3.8.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m2.1c">\mathcal{D}_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.8.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>. It uses this information to identify and correct potential errors in the glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS1.p3.9.m3.1"><semantics id="S3.SS1.p3.9.m3.1a"><msub id="S3.SS1.p3.9.m3.1.1" xref="S3.SS1.p3.9.m3.1.1.cmml"><mi id="S3.SS1.p3.9.m3.1.1.2" xref="S3.SS1.p3.9.m3.1.1.2.cmml">g</mi><mi id="S3.SS1.p3.9.m3.1.1.3" xref="S3.SS1.p3.9.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m3.1b"><apply id="S3.SS1.p3.9.m3.1.1.cmml" xref="S3.SS1.p3.9.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m3.1.1.1.cmml" xref="S3.SS1.p3.9.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.9.m3.1.1.2.cmml" xref="S3.SS1.p3.9.m3.1.1.2">𝑔</ci><ci id="S3.SS1.p3.9.m3.1.1.3.cmml" xref="S3.SS1.p3.9.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m3.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.9.m3.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> generated by the smaller token classification model:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="g_{c}=\text{LLM}(P,g_{s})" class="ltx_Math" display="block" id="S3.Ex3.m1.2"><semantics id="S3.Ex3.m1.2a"><mrow id="S3.Ex3.m1.2.2" xref="S3.Ex3.m1.2.2.cmml"><msub id="S3.Ex3.m1.2.2.3" xref="S3.Ex3.m1.2.2.3.cmml"><mi id="S3.Ex3.m1.2.2.3.2" xref="S3.Ex3.m1.2.2.3.2.cmml">g</mi><mi id="S3.Ex3.m1.2.2.3.3" xref="S3.Ex3.m1.2.2.3.3.cmml">c</mi></msub><mo id="S3.Ex3.m1.2.2.2" xref="S3.Ex3.m1.2.2.2.cmml">=</mo><mrow id="S3.Ex3.m1.2.2.1" xref="S3.Ex3.m1.2.2.1.cmml"><mtext id="S3.Ex3.m1.2.2.1.3" xref="S3.Ex3.m1.2.2.1.3a.cmml">LLM</mtext><mo id="S3.Ex3.m1.2.2.1.2" xref="S3.Ex3.m1.2.2.1.2.cmml">⁢</mo><mrow id="S3.Ex3.m1.2.2.1.1.1" xref="S3.Ex3.m1.2.2.1.1.2.cmml"><mo id="S3.Ex3.m1.2.2.1.1.1.2" stretchy="false" xref="S3.Ex3.m1.2.2.1.1.2.cmml">(</mo><mi id="S3.Ex3.m1.1.1" xref="S3.Ex3.m1.1.1.cmml">P</mi><mo id="S3.Ex3.m1.2.2.1.1.1.3" xref="S3.Ex3.m1.2.2.1.1.2.cmml">,</mo><msub id="S3.Ex3.m1.2.2.1.1.1.1" xref="S3.Ex3.m1.2.2.1.1.1.1.cmml"><mi id="S3.Ex3.m1.2.2.1.1.1.1.2" xref="S3.Ex3.m1.2.2.1.1.1.1.2.cmml">g</mi><mi id="S3.Ex3.m1.2.2.1.1.1.1.3" xref="S3.Ex3.m1.2.2.1.1.1.1.3.cmml">s</mi></msub><mo id="S3.Ex3.m1.2.2.1.1.1.4" stretchy="false" xref="S3.Ex3.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.2b"><apply id="S3.Ex3.m1.2.2.cmml" xref="S3.Ex3.m1.2.2"><eq id="S3.Ex3.m1.2.2.2.cmml" xref="S3.Ex3.m1.2.2.2"></eq><apply id="S3.Ex3.m1.2.2.3.cmml" xref="S3.Ex3.m1.2.2.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.2.2.3.1.cmml" xref="S3.Ex3.m1.2.2.3">subscript</csymbol><ci id="S3.Ex3.m1.2.2.3.2.cmml" xref="S3.Ex3.m1.2.2.3.2">𝑔</ci><ci id="S3.Ex3.m1.2.2.3.3.cmml" xref="S3.Ex3.m1.2.2.3.3">𝑐</ci></apply><apply id="S3.Ex3.m1.2.2.1.cmml" xref="S3.Ex3.m1.2.2.1"><times id="S3.Ex3.m1.2.2.1.2.cmml" xref="S3.Ex3.m1.2.2.1.2"></times><ci id="S3.Ex3.m1.2.2.1.3a.cmml" xref="S3.Ex3.m1.2.2.1.3"><mtext id="S3.Ex3.m1.2.2.1.3.cmml" xref="S3.Ex3.m1.2.2.1.3">LLM</mtext></ci><interval closure="open" id="S3.Ex3.m1.2.2.1.1.2.cmml" xref="S3.Ex3.m1.2.2.1.1.1"><ci id="S3.Ex3.m1.1.1.cmml" xref="S3.Ex3.m1.1.1">𝑃</ci><apply id="S3.Ex3.m1.2.2.1.1.1.1.cmml" xref="S3.Ex3.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex3.m1.2.2.1.1.1.1.1.cmml" xref="S3.Ex3.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.Ex3.m1.2.2.1.1.1.1.2.cmml" xref="S3.Ex3.m1.2.2.1.1.1.1.2">𝑔</ci><ci id="S3.Ex3.m1.2.2.1.1.1.1.3.cmml" xref="S3.Ex3.m1.2.2.1.1.1.1.3">𝑠</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.2c">g_{c}=\text{LLM}(P,g_{s})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex3.m1.2d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = LLM ( italic_P , italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p3.13">where <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.SS1.p3.10.m1.1"><semantics id="S3.SS1.p3.10.m1.1a"><msub id="S3.SS1.p3.10.m1.1.1" xref="S3.SS1.p3.10.m1.1.1.cmml"><mi id="S3.SS1.p3.10.m1.1.1.2" xref="S3.SS1.p3.10.m1.1.1.2.cmml">g</mi><mi id="S3.SS1.p3.10.m1.1.1.3" xref="S3.SS1.p3.10.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.10.m1.1b"><apply id="S3.SS1.p3.10.m1.1.1.cmml" xref="S3.SS1.p3.10.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.10.m1.1.1.1.cmml" xref="S3.SS1.p3.10.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.10.m1.1.1.2.cmml" xref="S3.SS1.p3.10.m1.1.1.2">𝑔</ci><ci id="S3.SS1.p3.10.m1.1.1.3.cmml" xref="S3.SS1.p3.10.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.10.m1.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.10.m1.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> represents the corrected glossing sequence. To illustrate the correction process, let <math alttext="f_{s}" class="ltx_Math" display="inline" id="S3.SS1.p3.11.m2.1"><semantics id="S3.SS1.p3.11.m2.1a"><msub id="S3.SS1.p3.11.m2.1.1" xref="S3.SS1.p3.11.m2.1.1.cmml"><mi id="S3.SS1.p3.11.m2.1.1.2" xref="S3.SS1.p3.11.m2.1.1.2.cmml">f</mi><mi id="S3.SS1.p3.11.m2.1.1.3" xref="S3.SS1.p3.11.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.11.m2.1b"><apply id="S3.SS1.p3.11.m2.1.1.cmml" xref="S3.SS1.p3.11.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.11.m2.1.1.1.cmml" xref="S3.SS1.p3.11.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.11.m2.1.1.2.cmml" xref="S3.SS1.p3.11.m2.1.1.2">𝑓</ci><ci id="S3.SS1.p3.11.m2.1.1.3.cmml" xref="S3.SS1.p3.11.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.11.m2.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.11.m2.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> be the function learned by the smaller token classification model that maps the input sentence <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.p3.12.m3.1"><semantics id="S3.SS1.p3.12.m3.1a"><mi id="S3.SS1.p3.12.m3.1.1" xref="S3.SS1.p3.12.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.12.m3.1b"><ci id="S3.SS1.p3.12.m3.1.1.cmml" xref="S3.SS1.p3.12.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.12.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.12.m3.1d">italic_x</annotation></semantics></math> to the glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS1.p3.13.m4.1"><semantics id="S3.SS1.p3.13.m4.1a"><msub id="S3.SS1.p3.13.m4.1.1" xref="S3.SS1.p3.13.m4.1.1.cmml"><mi id="S3.SS1.p3.13.m4.1.1.2" xref="S3.SS1.p3.13.m4.1.1.2.cmml">g</mi><mi id="S3.SS1.p3.13.m4.1.1.3" xref="S3.SS1.p3.13.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.13.m4.1b"><apply id="S3.SS1.p3.13.m4.1.1.cmml" xref="S3.SS1.p3.13.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.13.m4.1.1.1.cmml" xref="S3.SS1.p3.13.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.13.m4.1.1.2.cmml" xref="S3.SS1.p3.13.m4.1.1.2">𝑔</ci><ci id="S3.SS1.p3.13.m4.1.1.3.cmml" xref="S3.SS1.p3.13.m4.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.13.m4.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.13.m4.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.5">The Naive RAG approach learns a corrector function <math alttext="f_{\text{RAG}}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">f</mi><mtext id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3a.cmml">RAG</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">𝑓</ci><ci id="S3.SS1.p4.1.m1.1.1.3a.cmml" xref="S3.SS1.p4.1.m1.1.1.3"><mtext id="S3.SS1.p4.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p4.1.m1.1.1.3">RAG</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">f_{\text{RAG}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_f start_POSTSUBSCRIPT RAG end_POSTSUBSCRIPT</annotation></semantics></math> that takes the original input <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_x</annotation></semantics></math>, the glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><msub id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2">𝑔</ci><ci id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and the retrieved grammar chunks <math alttext="\mathcal{D}_{q}" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.1"><semantics id="S3.SS1.p4.4.m4.1a"><msub id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml">𝒟</mi><mi id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">𝒟</ci><ci id="S3.SS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\mathcal{D}_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.1d">caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> to produce the corrected output <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m5.1"><semantics id="S3.SS1.p4.5.m5.1a"><msub id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><mi id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml">g</mi><mi id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2">𝑔</ci><ci id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m5.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="g_{c}=f_{\text{RAG}}(x,g_{s},\mathcal{D}_{q})" class="ltx_Math" display="block" id="S3.Ex4.m1.3"><semantics id="S3.Ex4.m1.3a"><mrow id="S3.Ex4.m1.3.3" xref="S3.Ex4.m1.3.3.cmml"><msub id="S3.Ex4.m1.3.3.4" xref="S3.Ex4.m1.3.3.4.cmml"><mi id="S3.Ex4.m1.3.3.4.2" xref="S3.Ex4.m1.3.3.4.2.cmml">g</mi><mi id="S3.Ex4.m1.3.3.4.3" xref="S3.Ex4.m1.3.3.4.3.cmml">c</mi></msub><mo id="S3.Ex4.m1.3.3.3" xref="S3.Ex4.m1.3.3.3.cmml">=</mo><mrow id="S3.Ex4.m1.3.3.2" xref="S3.Ex4.m1.3.3.2.cmml"><msub id="S3.Ex4.m1.3.3.2.4" xref="S3.Ex4.m1.3.3.2.4.cmml"><mi id="S3.Ex4.m1.3.3.2.4.2" xref="S3.Ex4.m1.3.3.2.4.2.cmml">f</mi><mtext id="S3.Ex4.m1.3.3.2.4.3" xref="S3.Ex4.m1.3.3.2.4.3a.cmml">RAG</mtext></msub><mo id="S3.Ex4.m1.3.3.2.3" xref="S3.Ex4.m1.3.3.2.3.cmml">⁢</mo><mrow id="S3.Ex4.m1.3.3.2.2.2" xref="S3.Ex4.m1.3.3.2.2.3.cmml"><mo id="S3.Ex4.m1.3.3.2.2.2.3" stretchy="false" xref="S3.Ex4.m1.3.3.2.2.3.cmml">(</mo><mi id="S3.Ex4.m1.1.1" xref="S3.Ex4.m1.1.1.cmml">x</mi><mo id="S3.Ex4.m1.3.3.2.2.2.4" xref="S3.Ex4.m1.3.3.2.2.3.cmml">,</mo><msub id="S3.Ex4.m1.2.2.1.1.1.1" xref="S3.Ex4.m1.2.2.1.1.1.1.cmml"><mi id="S3.Ex4.m1.2.2.1.1.1.1.2" xref="S3.Ex4.m1.2.2.1.1.1.1.2.cmml">g</mi><mi id="S3.Ex4.m1.2.2.1.1.1.1.3" xref="S3.Ex4.m1.2.2.1.1.1.1.3.cmml">s</mi></msub><mo id="S3.Ex4.m1.3.3.2.2.2.5" xref="S3.Ex4.m1.3.3.2.2.3.cmml">,</mo><msub id="S3.Ex4.m1.3.3.2.2.2.2" xref="S3.Ex4.m1.3.3.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex4.m1.3.3.2.2.2.2.2" xref="S3.Ex4.m1.3.3.2.2.2.2.2.cmml">𝒟</mi><mi id="S3.Ex4.m1.3.3.2.2.2.2.3" xref="S3.Ex4.m1.3.3.2.2.2.2.3.cmml">q</mi></msub><mo id="S3.Ex4.m1.3.3.2.2.2.6" stretchy="false" xref="S3.Ex4.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex4.m1.3b"><apply id="S3.Ex4.m1.3.3.cmml" xref="S3.Ex4.m1.3.3"><eq id="S3.Ex4.m1.3.3.3.cmml" xref="S3.Ex4.m1.3.3.3"></eq><apply id="S3.Ex4.m1.3.3.4.cmml" xref="S3.Ex4.m1.3.3.4"><csymbol cd="ambiguous" id="S3.Ex4.m1.3.3.4.1.cmml" xref="S3.Ex4.m1.3.3.4">subscript</csymbol><ci id="S3.Ex4.m1.3.3.4.2.cmml" xref="S3.Ex4.m1.3.3.4.2">𝑔</ci><ci id="S3.Ex4.m1.3.3.4.3.cmml" xref="S3.Ex4.m1.3.3.4.3">𝑐</ci></apply><apply id="S3.Ex4.m1.3.3.2.cmml" xref="S3.Ex4.m1.3.3.2"><times id="S3.Ex4.m1.3.3.2.3.cmml" xref="S3.Ex4.m1.3.3.2.3"></times><apply id="S3.Ex4.m1.3.3.2.4.cmml" xref="S3.Ex4.m1.3.3.2.4"><csymbol cd="ambiguous" id="S3.Ex4.m1.3.3.2.4.1.cmml" xref="S3.Ex4.m1.3.3.2.4">subscript</csymbol><ci id="S3.Ex4.m1.3.3.2.4.2.cmml" xref="S3.Ex4.m1.3.3.2.4.2">𝑓</ci><ci id="S3.Ex4.m1.3.3.2.4.3a.cmml" xref="S3.Ex4.m1.3.3.2.4.3"><mtext id="S3.Ex4.m1.3.3.2.4.3.cmml" mathsize="70%" xref="S3.Ex4.m1.3.3.2.4.3">RAG</mtext></ci></apply><vector id="S3.Ex4.m1.3.3.2.2.3.cmml" xref="S3.Ex4.m1.3.3.2.2.2"><ci id="S3.Ex4.m1.1.1.cmml" xref="S3.Ex4.m1.1.1">𝑥</ci><apply id="S3.Ex4.m1.2.2.1.1.1.1.cmml" xref="S3.Ex4.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex4.m1.2.2.1.1.1.1.1.cmml" xref="S3.Ex4.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.Ex4.m1.2.2.1.1.1.1.2.cmml" xref="S3.Ex4.m1.2.2.1.1.1.1.2">𝑔</ci><ci id="S3.Ex4.m1.2.2.1.1.1.1.3.cmml" xref="S3.Ex4.m1.2.2.1.1.1.1.3">𝑠</ci></apply><apply id="S3.Ex4.m1.3.3.2.2.2.2.cmml" xref="S3.Ex4.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.3.3.2.2.2.2.1.cmml" xref="S3.Ex4.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.Ex4.m1.3.3.2.2.2.2.2.cmml" xref="S3.Ex4.m1.3.3.2.2.2.2.2">𝒟</ci><ci id="S3.Ex4.m1.3.3.2.2.2.2.3.cmml" xref="S3.Ex4.m1.3.3.2.2.2.2.3">𝑞</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex4.m1.3c">g_{c}=f_{\text{RAG}}(x,g_{s},\mathcal{D}_{q})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex4.m1.3d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT RAG end_POSTSUBSCRIPT ( italic_x , italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.7">By leveraging the linguistic information retrieved from the grammar documents, the RAG model <math alttext="f_{\text{RAG}}" class="ltx_Math" display="inline" id="S3.SS1.p4.6.m1.1"><semantics id="S3.SS1.p4.6.m1.1a"><msub id="S3.SS1.p4.6.m1.1.1" xref="S3.SS1.p4.6.m1.1.1.cmml"><mi id="S3.SS1.p4.6.m1.1.1.2" xref="S3.SS1.p4.6.m1.1.1.2.cmml">f</mi><mtext id="S3.SS1.p4.6.m1.1.1.3" xref="S3.SS1.p4.6.m1.1.1.3a.cmml">RAG</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m1.1b"><apply id="S3.SS1.p4.6.m1.1.1.cmml" xref="S3.SS1.p4.6.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m1.1.1.1.cmml" xref="S3.SS1.p4.6.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.6.m1.1.1.2.cmml" xref="S3.SS1.p4.6.m1.1.1.2">𝑓</ci><ci id="S3.SS1.p4.6.m1.1.1.3a.cmml" xref="S3.SS1.p4.6.m1.1.1.3"><mtext id="S3.SS1.p4.6.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p4.6.m1.1.1.3">RAG</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m1.1c">f_{\text{RAG}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.6.m1.1d">italic_f start_POSTSUBSCRIPT RAG end_POSTSUBSCRIPT</annotation></semantics></math> is able to refine the predictions of the base model <math alttext="f_{s}" class="ltx_Math" display="inline" id="S3.SS1.p4.7.m2.1"><semantics id="S3.SS1.p4.7.m2.1a"><msub id="S3.SS1.p4.7.m2.1.1" xref="S3.SS1.p4.7.m2.1.1.cmml"><mi id="S3.SS1.p4.7.m2.1.1.2" xref="S3.SS1.p4.7.m2.1.1.2.cmml">f</mi><mi id="S3.SS1.p4.7.m2.1.1.3" xref="S3.SS1.p4.7.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m2.1b"><apply id="S3.SS1.p4.7.m2.1.1.cmml" xref="S3.SS1.p4.7.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m2.1.1.1.cmml" xref="S3.SS1.p4.7.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.7.m2.1.1.2.cmml" xref="S3.SS1.p4.7.m2.1.1.2">𝑓</ci><ci id="S3.SS1.p4.7.m2.1.1.3.cmml" xref="S3.SS1.p4.7.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m2.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.7.m2.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> and generate more accurate glossing sequences. The Naive RAG approach thus enables the smaller model to benefit from the vast knowledge captured by the LLM without the need for extensive fine-tuning or additional training data. This is particularly advantageous in low-resource scenarios where labeled data is scarce, as the LLM can provide valuable linguistic insights to guide the glossing process. [Refer to the appendix to see some of these generated explanations.]</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Generating Labeling Justifications and Confidence Scores</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.5">In addition to correcting glossing labels, our RAG pipeline also generates explanations justifying the corrections made. We achieve this by prompting the LLM to provide a chain-of-thought reasoning trace that justifies the decision-making process behind the corrections. The LLM is prompted with an instruction <math alttext="I" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_I</annotation></semantics></math> that requests a justification <math alttext="J" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝐽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">J</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_J</annotation></semantics></math>, an explanation of how RAG was used <math alttext="R" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_R</annotation></semantics></math>, and a confidence score <math alttext="C" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_C</annotation></semantics></math> for corrected glossing output <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">g</mi><mi id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">𝑔</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="[J,R,C]=\text{LLM}(I,P,g_{s},g_{c})" class="ltx_Math" display="block" id="S3.Ex5.m1.7"><semantics id="S3.Ex5.m1.7a"><mrow id="S3.Ex5.m1.7.7" xref="S3.Ex5.m1.7.7.cmml"><mrow id="S3.Ex5.m1.7.7.4.2" xref="S3.Ex5.m1.7.7.4.1.cmml"><mo id="S3.Ex5.m1.7.7.4.2.1" stretchy="false" xref="S3.Ex5.m1.7.7.4.1.cmml">[</mo><mi id="S3.Ex5.m1.1.1" xref="S3.Ex5.m1.1.1.cmml">J</mi><mo id="S3.Ex5.m1.7.7.4.2.2" xref="S3.Ex5.m1.7.7.4.1.cmml">,</mo><mi id="S3.Ex5.m1.2.2" xref="S3.Ex5.m1.2.2.cmml">R</mi><mo id="S3.Ex5.m1.7.7.4.2.3" xref="S3.Ex5.m1.7.7.4.1.cmml">,</mo><mi id="S3.Ex5.m1.3.3" xref="S3.Ex5.m1.3.3.cmml">C</mi><mo id="S3.Ex5.m1.7.7.4.2.4" stretchy="false" xref="S3.Ex5.m1.7.7.4.1.cmml">]</mo></mrow><mo id="S3.Ex5.m1.7.7.3" xref="S3.Ex5.m1.7.7.3.cmml">=</mo><mrow id="S3.Ex5.m1.7.7.2" xref="S3.Ex5.m1.7.7.2.cmml"><mtext id="S3.Ex5.m1.7.7.2.4" xref="S3.Ex5.m1.7.7.2.4a.cmml">LLM</mtext><mo id="S3.Ex5.m1.7.7.2.3" xref="S3.Ex5.m1.7.7.2.3.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.2.2.2" xref="S3.Ex5.m1.7.7.2.2.3.cmml"><mo id="S3.Ex5.m1.7.7.2.2.2.3" stretchy="false" xref="S3.Ex5.m1.7.7.2.2.3.cmml">(</mo><mi id="S3.Ex5.m1.4.4" xref="S3.Ex5.m1.4.4.cmml">I</mi><mo id="S3.Ex5.m1.7.7.2.2.2.4" xref="S3.Ex5.m1.7.7.2.2.3.cmml">,</mo><mi id="S3.Ex5.m1.5.5" xref="S3.Ex5.m1.5.5.cmml">P</mi><mo id="S3.Ex5.m1.7.7.2.2.2.5" xref="S3.Ex5.m1.7.7.2.2.3.cmml">,</mo><msub id="S3.Ex5.m1.6.6.1.1.1.1" xref="S3.Ex5.m1.6.6.1.1.1.1.cmml"><mi id="S3.Ex5.m1.6.6.1.1.1.1.2" xref="S3.Ex5.m1.6.6.1.1.1.1.2.cmml">g</mi><mi id="S3.Ex5.m1.6.6.1.1.1.1.3" xref="S3.Ex5.m1.6.6.1.1.1.1.3.cmml">s</mi></msub><mo id="S3.Ex5.m1.7.7.2.2.2.6" xref="S3.Ex5.m1.7.7.2.2.3.cmml">,</mo><msub id="S3.Ex5.m1.7.7.2.2.2.2" xref="S3.Ex5.m1.7.7.2.2.2.2.cmml"><mi id="S3.Ex5.m1.7.7.2.2.2.2.2" xref="S3.Ex5.m1.7.7.2.2.2.2.2.cmml">g</mi><mi id="S3.Ex5.m1.7.7.2.2.2.2.3" xref="S3.Ex5.m1.7.7.2.2.2.2.3.cmml">c</mi></msub><mo id="S3.Ex5.m1.7.7.2.2.2.7" stretchy="false" xref="S3.Ex5.m1.7.7.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex5.m1.7b"><apply id="S3.Ex5.m1.7.7.cmml" xref="S3.Ex5.m1.7.7"><eq id="S3.Ex5.m1.7.7.3.cmml" xref="S3.Ex5.m1.7.7.3"></eq><list id="S3.Ex5.m1.7.7.4.1.cmml" xref="S3.Ex5.m1.7.7.4.2"><ci id="S3.Ex5.m1.1.1.cmml" xref="S3.Ex5.m1.1.1">𝐽</ci><ci id="S3.Ex5.m1.2.2.cmml" xref="S3.Ex5.m1.2.2">𝑅</ci><ci id="S3.Ex5.m1.3.3.cmml" xref="S3.Ex5.m1.3.3">𝐶</ci></list><apply id="S3.Ex5.m1.7.7.2.cmml" xref="S3.Ex5.m1.7.7.2"><times id="S3.Ex5.m1.7.7.2.3.cmml" xref="S3.Ex5.m1.7.7.2.3"></times><ci id="S3.Ex5.m1.7.7.2.4a.cmml" xref="S3.Ex5.m1.7.7.2.4"><mtext id="S3.Ex5.m1.7.7.2.4.cmml" xref="S3.Ex5.m1.7.7.2.4">LLM</mtext></ci><vector id="S3.Ex5.m1.7.7.2.2.3.cmml" xref="S3.Ex5.m1.7.7.2.2.2"><ci id="S3.Ex5.m1.4.4.cmml" xref="S3.Ex5.m1.4.4">𝐼</ci><ci id="S3.Ex5.m1.5.5.cmml" xref="S3.Ex5.m1.5.5">𝑃</ci><apply id="S3.Ex5.m1.6.6.1.1.1.1.cmml" xref="S3.Ex5.m1.6.6.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex5.m1.6.6.1.1.1.1.1.cmml" xref="S3.Ex5.m1.6.6.1.1.1.1">subscript</csymbol><ci id="S3.Ex5.m1.6.6.1.1.1.1.2.cmml" xref="S3.Ex5.m1.6.6.1.1.1.1.2">𝑔</ci><ci id="S3.Ex5.m1.6.6.1.1.1.1.3.cmml" xref="S3.Ex5.m1.6.6.1.1.1.1.3">𝑠</ci></apply><apply id="S3.Ex5.m1.7.7.2.2.2.2.cmml" xref="S3.Ex5.m1.7.7.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.7.7.2.2.2.2.1.cmml" xref="S3.Ex5.m1.7.7.2.2.2.2">subscript</csymbol><ci id="S3.Ex5.m1.7.7.2.2.2.2.2.cmml" xref="S3.Ex5.m1.7.7.2.2.2.2.2">𝑔</ci><ci id="S3.Ex5.m1.7.7.2.2.2.2.3.cmml" xref="S3.Ex5.m1.7.7.2.2.2.2.3">𝑐</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex5.m1.7c">[J,R,C]=\text{LLM}(I,P,g_{s},g_{c})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex5.m1.7d">[ italic_J , italic_R , italic_C ] = LLM ( italic_I , italic_P , italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.7">The justification <math alttext="J" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m1.1"><semantics id="S3.SS2.p1.6.m1.1a"><mi id="S3.SS2.p1.6.m1.1.1" xref="S3.SS2.p1.6.m1.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m1.1b"><ci id="S3.SS2.p1.6.m1.1.1.cmml" xref="S3.SS2.p1.6.m1.1.1">𝐽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m1.1c">J</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m1.1d">italic_J</annotation></semantics></math> is a natural language explanation that describes the grammar rules and morphological patterns retrieved from the grammar excerpts <math alttext="\mathcal{D}_{q}" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m2.1"><semantics id="S3.SS2.p1.7.m2.1a"><msub id="S3.SS2.p1.7.m2.1.1" xref="S3.SS2.p1.7.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.7.m2.1.1.2" xref="S3.SS2.p1.7.m2.1.1.2.cmml">𝒟</mi><mi id="S3.SS2.p1.7.m2.1.1.3" xref="S3.SS2.p1.7.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m2.1b"><apply id="S3.SS2.p1.7.m2.1.1.cmml" xref="S3.SS2.p1.7.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m2.1.1.1.cmml" xref="S3.SS2.p1.7.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.7.m2.1.1.2.cmml" xref="S3.SS2.p1.7.m2.1.1.2">𝒟</ci><ci id="S3.SS2.p1.7.m2.1.1.3.cmml" xref="S3.SS2.p1.7.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m2.1c">\mathcal{D}_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and how they informed the corrections made to the glossing sequence. This explanation can be modeled as a set of reasoning steps:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="J=[r_{1},r_{2},\ldots,r_{m}]" class="ltx_Math" display="block" id="S3.Ex6.m1.4"><semantics id="S3.Ex6.m1.4a"><mrow id="S3.Ex6.m1.4.4" xref="S3.Ex6.m1.4.4.cmml"><mi id="S3.Ex6.m1.4.4.5" xref="S3.Ex6.m1.4.4.5.cmml">J</mi><mo id="S3.Ex6.m1.4.4.4" xref="S3.Ex6.m1.4.4.4.cmml">=</mo><mrow id="S3.Ex6.m1.4.4.3.3" xref="S3.Ex6.m1.4.4.3.4.cmml"><mo id="S3.Ex6.m1.4.4.3.3.4" stretchy="false" xref="S3.Ex6.m1.4.4.3.4.cmml">[</mo><msub id="S3.Ex6.m1.2.2.1.1.1" xref="S3.Ex6.m1.2.2.1.1.1.cmml"><mi id="S3.Ex6.m1.2.2.1.1.1.2" xref="S3.Ex6.m1.2.2.1.1.1.2.cmml">r</mi><mn id="S3.Ex6.m1.2.2.1.1.1.3" xref="S3.Ex6.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.Ex6.m1.4.4.3.3.5" xref="S3.Ex6.m1.4.4.3.4.cmml">,</mo><msub id="S3.Ex6.m1.3.3.2.2.2" xref="S3.Ex6.m1.3.3.2.2.2.cmml"><mi id="S3.Ex6.m1.3.3.2.2.2.2" xref="S3.Ex6.m1.3.3.2.2.2.2.cmml">r</mi><mn id="S3.Ex6.m1.3.3.2.2.2.3" xref="S3.Ex6.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.Ex6.m1.4.4.3.3.6" xref="S3.Ex6.m1.4.4.3.4.cmml">,</mo><mi id="S3.Ex6.m1.1.1" mathvariant="normal" xref="S3.Ex6.m1.1.1.cmml">…</mi><mo id="S3.Ex6.m1.4.4.3.3.7" xref="S3.Ex6.m1.4.4.3.4.cmml">,</mo><msub id="S3.Ex6.m1.4.4.3.3.3" xref="S3.Ex6.m1.4.4.3.3.3.cmml"><mi id="S3.Ex6.m1.4.4.3.3.3.2" xref="S3.Ex6.m1.4.4.3.3.3.2.cmml">r</mi><mi id="S3.Ex6.m1.4.4.3.3.3.3" xref="S3.Ex6.m1.4.4.3.3.3.3.cmml">m</mi></msub><mo id="S3.Ex6.m1.4.4.3.3.8" stretchy="false" xref="S3.Ex6.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex6.m1.4b"><apply id="S3.Ex6.m1.4.4.cmml" xref="S3.Ex6.m1.4.4"><eq id="S3.Ex6.m1.4.4.4.cmml" xref="S3.Ex6.m1.4.4.4"></eq><ci id="S3.Ex6.m1.4.4.5.cmml" xref="S3.Ex6.m1.4.4.5">𝐽</ci><list id="S3.Ex6.m1.4.4.3.4.cmml" xref="S3.Ex6.m1.4.4.3.3"><apply id="S3.Ex6.m1.2.2.1.1.1.cmml" xref="S3.Ex6.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Ex6.m1.2.2.1.1.1.1.cmml" xref="S3.Ex6.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.Ex6.m1.2.2.1.1.1.2.cmml" xref="S3.Ex6.m1.2.2.1.1.1.2">𝑟</ci><cn id="S3.Ex6.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.Ex6.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.Ex6.m1.3.3.2.2.2.cmml" xref="S3.Ex6.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.Ex6.m1.3.3.2.2.2.1.cmml" xref="S3.Ex6.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.Ex6.m1.3.3.2.2.2.2.cmml" xref="S3.Ex6.m1.3.3.2.2.2.2">𝑟</ci><cn id="S3.Ex6.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.Ex6.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.Ex6.m1.1.1.cmml" xref="S3.Ex6.m1.1.1">…</ci><apply id="S3.Ex6.m1.4.4.3.3.3.cmml" xref="S3.Ex6.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.Ex6.m1.4.4.3.3.3.1.cmml" xref="S3.Ex6.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.Ex6.m1.4.4.3.3.3.2.cmml" xref="S3.Ex6.m1.4.4.3.3.3.2">𝑟</ci><ci id="S3.Ex6.m1.4.4.3.3.3.3.cmml" xref="S3.Ex6.m1.4.4.3.3.3.3">𝑚</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex6.m1.4c">J=[r_{1},r_{2},\ldots,r_{m}]</annotation><annotation encoding="application/x-llamapun" id="S3.Ex6.m1.4d">italic_J = [ italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_r start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.10">where each <math alttext="r_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.8.m1.1"><semantics id="S3.SS2.p1.8.m1.1a"><msub id="S3.SS2.p1.8.m1.1.1" xref="S3.SS2.p1.8.m1.1.1.cmml"><mi id="S3.SS2.p1.8.m1.1.1.2" xref="S3.SS2.p1.8.m1.1.1.2.cmml">r</mi><mi id="S3.SS2.p1.8.m1.1.1.3" xref="S3.SS2.p1.8.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m1.1b"><apply id="S3.SS2.p1.8.m1.1.1.cmml" xref="S3.SS2.p1.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.8.m1.1.1.1.cmml" xref="S3.SS2.p1.8.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.8.m1.1.1.2.cmml" xref="S3.SS2.p1.8.m1.1.1.2">𝑟</ci><ci id="S3.SS2.p1.8.m1.1.1.3.cmml" xref="S3.SS2.p1.8.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m1.1c">r_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.8.m1.1d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents a single reason that links the retrieved linguistic information to the specific corrections made in <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.SS2.p1.9.m2.1"><semantics id="S3.SS2.p1.9.m2.1a"><msub id="S3.SS2.p1.9.m2.1.1" xref="S3.SS2.p1.9.m2.1.1.cmml"><mi id="S3.SS2.p1.9.m2.1.1.2" xref="S3.SS2.p1.9.m2.1.1.2.cmml">g</mi><mi id="S3.SS2.p1.9.m2.1.1.3" xref="S3.SS2.p1.9.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m2.1b"><apply id="S3.SS2.p1.9.m2.1.1.cmml" xref="S3.SS2.p1.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m2.1.1.1.cmml" xref="S3.SS2.p1.9.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.9.m2.1.1.2.cmml" xref="S3.SS2.p1.9.m2.1.1.2">𝑔</ci><ci id="S3.SS2.p1.9.m2.1.1.3.cmml" xref="S3.SS2.p1.9.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m2.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.9.m2.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. This set of <math alttext="r_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.10.m3.1"><semantics id="S3.SS2.p1.10.m3.1a"><msub id="S3.SS2.p1.10.m3.1.1" xref="S3.SS2.p1.10.m3.1.1.cmml"><mi id="S3.SS2.p1.10.m3.1.1.2" xref="S3.SS2.p1.10.m3.1.1.2.cmml">r</mi><mi id="S3.SS2.p1.10.m3.1.1.3" xref="S3.SS2.p1.10.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m3.1b"><apply id="S3.SS2.p1.10.m3.1.1.cmml" xref="S3.SS2.p1.10.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m3.1.1.1.cmml" xref="S3.SS2.p1.10.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.10.m3.1.1.2.cmml" xref="S3.SS2.p1.10.m3.1.1.2">𝑟</ci><ci id="S3.SS2.p1.10.m3.1.1.3.cmml" xref="S3.SS2.p1.10.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m3.1c">r_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.10.m3.1d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is not necessarily sequential.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.2">To quantify the model’s confidence in the corrected output, a confidence score <math alttext="C" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_C</annotation></semantics></math> is generated. This score reflects the LLM’s certainty in the accuracy of the final glossing sequence based on the retrieved grammar rules and the original output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">g</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑔</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>. When asked how it assigned confidence scores, this was Claude’s response:</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.1">"Confidence scores were assigned based on how closely each word or morpheme matched information provided in the grammar document. Higher scores (closer to 1.0) indicate a strong direct match, while lower scores (closer to 0.5) indicate a more tentative match based on context or inference."</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Through these confidence scores and justifications, the RAG pipeline boosts the interpretability of the model’s predictions. The explanations offer insights into the linguistic reasoning behind the corrections, allowing users to understand why certain changes were made. This can be crucially important for documentary linguists who may be reluctant to use NLP tools due to concerns about reliability and a lack of interpretibility.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Modular RAG: Training the retriever with the sequence to sequence model</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Due to the size of our grammars, it makes sense to further train our retriever and rank the retrieved content based on its relevance to the query. This is an extension of the previously described Naive RAG approach.
The modular RAG approach allows for a more sample-efficient utilization of the available grammar resources. By learning to retrieve and prioritize the most relevant excerpts, the model can focus on the linguistic information that is most beneficial for each specific input, rather than processing the entire grammar at once.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">Initial Retrieval:</span> The process begins by retrieving <math alttext="k" class="ltx_Math" display="inline" id="S3.I2.i1.p1.1.m1.1"><semantics id="S3.I2.i1.p1.1.m1.1a"><mi id="S3.I2.i1.p1.1.m1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><ci id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i1.p1.1.m1.1d">italic_k</annotation></semantics></math> context chunks from the grammar based on relevance to the input query.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.3"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.3.1">Retrieval Module Training:</span> The retrieval module, which is a different instance of the RoBERTa model, is fine-tuned based on the performance of the LLM outputs. The input to the retrieval module consists of all the initially retrieved chunks of context, and the output is a relevance vector <math alttext="r=[r_{1},r_{2},...,r_{k}]" class="ltx_Math" display="inline" id="S3.I2.i2.p1.1.m1.4"><semantics id="S3.I2.i2.p1.1.m1.4a"><mrow id="S3.I2.i2.p1.1.m1.4.4" xref="S3.I2.i2.p1.1.m1.4.4.cmml"><mi id="S3.I2.i2.p1.1.m1.4.4.5" xref="S3.I2.i2.p1.1.m1.4.4.5.cmml">r</mi><mo id="S3.I2.i2.p1.1.m1.4.4.4" xref="S3.I2.i2.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.I2.i2.p1.1.m1.4.4.3.3" xref="S3.I2.i2.p1.1.m1.4.4.3.4.cmml"><mo id="S3.I2.i2.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S3.I2.i2.p1.1.m1.4.4.3.4.cmml">[</mo><msub id="S3.I2.i2.p1.1.m1.2.2.1.1.1" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.I2.i2.p1.1.m1.2.2.1.1.1.2" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1.2.cmml">r</mi><mn id="S3.I2.i2.p1.1.m1.2.2.1.1.1.3" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.I2.i2.p1.1.m1.4.4.3.3.5" xref="S3.I2.i2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.I2.i2.p1.1.m1.3.3.2.2.2" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.I2.i2.p1.1.m1.3.3.2.2.2.2" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2.2.cmml">r</mi><mn id="S3.I2.i2.p1.1.m1.3.3.2.2.2.3" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.I2.i2.p1.1.m1.4.4.3.3.6" xref="S3.I2.i2.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.I2.i2.p1.1.m1.1.1" mathvariant="normal" xref="S3.I2.i2.p1.1.m1.1.1.cmml">…</mi><mo id="S3.I2.i2.p1.1.m1.4.4.3.3.7" xref="S3.I2.i2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.I2.i2.p1.1.m1.4.4.3.3.3" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3.cmml"><mi id="S3.I2.i2.p1.1.m1.4.4.3.3.3.2" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3.2.cmml">r</mi><mi id="S3.I2.i2.p1.1.m1.4.4.3.3.3.3" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3.3.cmml">k</mi></msub><mo id="S3.I2.i2.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S3.I2.i2.p1.1.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.4b"><apply id="S3.I2.i2.p1.1.m1.4.4.cmml" xref="S3.I2.i2.p1.1.m1.4.4"><eq id="S3.I2.i2.p1.1.m1.4.4.4.cmml" xref="S3.I2.i2.p1.1.m1.4.4.4"></eq><ci id="S3.I2.i2.p1.1.m1.4.4.5.cmml" xref="S3.I2.i2.p1.1.m1.4.4.5">𝑟</ci><list id="S3.I2.i2.p1.1.m1.4.4.3.4.cmml" xref="S3.I2.i2.p1.1.m1.4.4.3.3"><apply id="S3.I2.i2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1.2">𝑟</ci><cn id="S3.I2.i2.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.I2.i2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.I2.i2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.I2.i2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.I2.i2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2.2">𝑟</ci><cn id="S3.I2.i2.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.I2.i2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">…</ci><apply id="S3.I2.i2.p1.1.m1.4.4.3.3.3.cmml" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.I2.i2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.I2.i2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3.2">𝑟</ci><ci id="S3.I2.i2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.I2.i2.p1.1.m1.4.4.3.3.3.3">𝑘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.4c">r=[r_{1},r_{2},...,r_{k}]</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.1.m1.4d">italic_r = [ italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_r start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ]</annotation></semantics></math>, where <math alttext="r_{i}\in[0,1]" class="ltx_Math" display="inline" id="S3.I2.i2.p1.2.m2.2"><semantics id="S3.I2.i2.p1.2.m2.2a"><mrow id="S3.I2.i2.p1.2.m2.2.3" xref="S3.I2.i2.p1.2.m2.2.3.cmml"><msub id="S3.I2.i2.p1.2.m2.2.3.2" xref="S3.I2.i2.p1.2.m2.2.3.2.cmml"><mi id="S3.I2.i2.p1.2.m2.2.3.2.2" xref="S3.I2.i2.p1.2.m2.2.3.2.2.cmml">r</mi><mi id="S3.I2.i2.p1.2.m2.2.3.2.3" xref="S3.I2.i2.p1.2.m2.2.3.2.3.cmml">i</mi></msub><mo id="S3.I2.i2.p1.2.m2.2.3.1" xref="S3.I2.i2.p1.2.m2.2.3.1.cmml">∈</mo><mrow id="S3.I2.i2.p1.2.m2.2.3.3.2" xref="S3.I2.i2.p1.2.m2.2.3.3.1.cmml"><mo id="S3.I2.i2.p1.2.m2.2.3.3.2.1" stretchy="false" xref="S3.I2.i2.p1.2.m2.2.3.3.1.cmml">[</mo><mn id="S3.I2.i2.p1.2.m2.1.1" xref="S3.I2.i2.p1.2.m2.1.1.cmml">0</mn><mo id="S3.I2.i2.p1.2.m2.2.3.3.2.2" xref="S3.I2.i2.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.I2.i2.p1.2.m2.2.2" xref="S3.I2.i2.p1.2.m2.2.2.cmml">1</mn><mo id="S3.I2.i2.p1.2.m2.2.3.3.2.3" stretchy="false" xref="S3.I2.i2.p1.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.2.m2.2b"><apply id="S3.I2.i2.p1.2.m2.2.3.cmml" xref="S3.I2.i2.p1.2.m2.2.3"><in id="S3.I2.i2.p1.2.m2.2.3.1.cmml" xref="S3.I2.i2.p1.2.m2.2.3.1"></in><apply id="S3.I2.i2.p1.2.m2.2.3.2.cmml" xref="S3.I2.i2.p1.2.m2.2.3.2"><csymbol cd="ambiguous" id="S3.I2.i2.p1.2.m2.2.3.2.1.cmml" xref="S3.I2.i2.p1.2.m2.2.3.2">subscript</csymbol><ci id="S3.I2.i2.p1.2.m2.2.3.2.2.cmml" xref="S3.I2.i2.p1.2.m2.2.3.2.2">𝑟</ci><ci id="S3.I2.i2.p1.2.m2.2.3.2.3.cmml" xref="S3.I2.i2.p1.2.m2.2.3.2.3">𝑖</ci></apply><interval closure="closed" id="S3.I2.i2.p1.2.m2.2.3.3.1.cmml" xref="S3.I2.i2.p1.2.m2.2.3.3.2"><cn id="S3.I2.i2.p1.2.m2.1.1.cmml" type="integer" xref="S3.I2.i2.p1.2.m2.1.1">0</cn><cn id="S3.I2.i2.p1.2.m2.2.2.cmml" type="integer" xref="S3.I2.i2.p1.2.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.2.m2.2c">r_{i}\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.2.m2.2d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ [ 0 , 1 ]</annotation></semantics></math> indicates the relevance score for the <math alttext="i^{th}" class="ltx_Math" display="inline" id="S3.I2.i2.p1.3.m3.1"><semantics id="S3.I2.i2.p1.3.m3.1a"><msup id="S3.I2.i2.p1.3.m3.1.1" xref="S3.I2.i2.p1.3.m3.1.1.cmml"><mi id="S3.I2.i2.p1.3.m3.1.1.2" xref="S3.I2.i2.p1.3.m3.1.1.2.cmml">i</mi><mrow id="S3.I2.i2.p1.3.m3.1.1.3" xref="S3.I2.i2.p1.3.m3.1.1.3.cmml"><mi id="S3.I2.i2.p1.3.m3.1.1.3.2" xref="S3.I2.i2.p1.3.m3.1.1.3.2.cmml">t</mi><mo id="S3.I2.i2.p1.3.m3.1.1.3.1" xref="S3.I2.i2.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.I2.i2.p1.3.m3.1.1.3.3" xref="S3.I2.i2.p1.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.3.m3.1b"><apply id="S3.I2.i2.p1.3.m3.1.1.cmml" xref="S3.I2.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.3.m3.1.1.1.cmml" xref="S3.I2.i2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.I2.i2.p1.3.m3.1.1.2.cmml" xref="S3.I2.i2.p1.3.m3.1.1.2">𝑖</ci><apply id="S3.I2.i2.p1.3.m3.1.1.3.cmml" xref="S3.I2.i2.p1.3.m3.1.1.3"><times id="S3.I2.i2.p1.3.m3.1.1.3.1.cmml" xref="S3.I2.i2.p1.3.m3.1.1.3.1"></times><ci id="S3.I2.i2.p1.3.m3.1.1.3.2.cmml" xref="S3.I2.i2.p1.3.m3.1.1.3.2">𝑡</ci><ci id="S3.I2.i2.p1.3.m3.1.1.3.3.cmml" xref="S3.I2.i2.p1.3.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.3.m3.1c">i^{th}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.3.m3.1d">italic_i start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> chunk of context.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.2"><span class="ltx_text ltx_font_bold" id="S3.I2.i3.p1.2.1">Final Context Selection:</span> Out of the <math alttext="k" class="ltx_Math" display="inline" id="S3.I2.i3.p1.1.m1.1"><semantics id="S3.I2.i3.p1.1.m1.1a"><mi id="S3.I2.i3.p1.1.m1.1.1" xref="S3.I2.i3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><ci id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i3.p1.1.m1.1d">italic_k</annotation></semantics></math> retrieved pieces of context, only the top-<math alttext="n" class="ltx_Math" display="inline" id="S3.I2.i3.p1.2.m2.1"><semantics id="S3.I2.i3.p1.2.m2.1a"><mi id="S3.I2.i3.p1.2.m2.1.1" xref="S3.I2.i3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.2.m2.1b"><ci id="S3.I2.i3.p1.2.m2.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i3.p1.2.m2.1d">italic_n</annotation></semantics></math> most relevant pieces are selected for use in the final LLM prompt.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.8">Let <math alttext="f_{s}" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">f</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝑓</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> be the token classification model that maps input sentence <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">italic_x</annotation></semantics></math> to the initial glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝑔</ci><ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>. The retriever module <math alttext="f_{r}" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">f</mi><mi id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">𝑓</ci><ci id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">f_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> is trained to select the top-<math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m5.1"><semantics id="S3.SS3.p3.5.m5.1a"><mi id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><ci id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m5.1d">italic_n</annotation></semantics></math> relevant grammar chunks <math alttext="D_{q}" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m6.1"><semantics id="S3.SS3.p3.6.m6.1a"><msub id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml"><mi id="S3.SS3.p3.6.m6.1.1.2" xref="S3.SS3.p3.6.m6.1.1.2.cmml">D</mi><mi id="S3.SS3.p3.6.m6.1.1.3" xref="S3.SS3.p3.6.m6.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><apply id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p3.6.m6.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2">𝐷</ci><ci id="S3.SS3.p3.6.m6.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">D_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.6.m6.1d">italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> based on the input sentence <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m7.1"><semantics id="S3.SS3.p3.7.m7.1a"><mi id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b"><ci id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.7.m7.1d">italic_x</annotation></semantics></math> and the initial glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS3.p3.8.m8.1"><semantics id="S3.SS3.p3.8.m8.1a"><msub id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml"><mi id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">g</mi><mi id="S3.SS3.p3.8.m8.1.1.3" xref="S3.SS3.p3.8.m8.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b"><apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2">𝑔</ci><ci id="S3.SS3.p3.8.m8.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.8.m8.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="D_{q}=f_{r}(x,g_{s},k,n)" class="ltx_Math" display="block" id="S3.Ex7.m1.4"><semantics id="S3.Ex7.m1.4a"><mrow id="S3.Ex7.m1.4.4" xref="S3.Ex7.m1.4.4.cmml"><msub id="S3.Ex7.m1.4.4.3" xref="S3.Ex7.m1.4.4.3.cmml"><mi id="S3.Ex7.m1.4.4.3.2" xref="S3.Ex7.m1.4.4.3.2.cmml">D</mi><mi id="S3.Ex7.m1.4.4.3.3" xref="S3.Ex7.m1.4.4.3.3.cmml">q</mi></msub><mo id="S3.Ex7.m1.4.4.2" xref="S3.Ex7.m1.4.4.2.cmml">=</mo><mrow id="S3.Ex7.m1.4.4.1" xref="S3.Ex7.m1.4.4.1.cmml"><msub id="S3.Ex7.m1.4.4.1.3" xref="S3.Ex7.m1.4.4.1.3.cmml"><mi id="S3.Ex7.m1.4.4.1.3.2" xref="S3.Ex7.m1.4.4.1.3.2.cmml">f</mi><mi id="S3.Ex7.m1.4.4.1.3.3" xref="S3.Ex7.m1.4.4.1.3.3.cmml">r</mi></msub><mo id="S3.Ex7.m1.4.4.1.2" xref="S3.Ex7.m1.4.4.1.2.cmml">⁢</mo><mrow id="S3.Ex7.m1.4.4.1.1.1" xref="S3.Ex7.m1.4.4.1.1.2.cmml"><mo id="S3.Ex7.m1.4.4.1.1.1.2" stretchy="false" xref="S3.Ex7.m1.4.4.1.1.2.cmml">(</mo><mi id="S3.Ex7.m1.1.1" xref="S3.Ex7.m1.1.1.cmml">x</mi><mo id="S3.Ex7.m1.4.4.1.1.1.3" xref="S3.Ex7.m1.4.4.1.1.2.cmml">,</mo><msub id="S3.Ex7.m1.4.4.1.1.1.1" xref="S3.Ex7.m1.4.4.1.1.1.1.cmml"><mi id="S3.Ex7.m1.4.4.1.1.1.1.2" xref="S3.Ex7.m1.4.4.1.1.1.1.2.cmml">g</mi><mi id="S3.Ex7.m1.4.4.1.1.1.1.3" xref="S3.Ex7.m1.4.4.1.1.1.1.3.cmml">s</mi></msub><mo id="S3.Ex7.m1.4.4.1.1.1.4" xref="S3.Ex7.m1.4.4.1.1.2.cmml">,</mo><mi id="S3.Ex7.m1.2.2" xref="S3.Ex7.m1.2.2.cmml">k</mi><mo id="S3.Ex7.m1.4.4.1.1.1.5" xref="S3.Ex7.m1.4.4.1.1.2.cmml">,</mo><mi id="S3.Ex7.m1.3.3" xref="S3.Ex7.m1.3.3.cmml">n</mi><mo id="S3.Ex7.m1.4.4.1.1.1.6" stretchy="false" xref="S3.Ex7.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex7.m1.4b"><apply id="S3.Ex7.m1.4.4.cmml" xref="S3.Ex7.m1.4.4"><eq id="S3.Ex7.m1.4.4.2.cmml" xref="S3.Ex7.m1.4.4.2"></eq><apply id="S3.Ex7.m1.4.4.3.cmml" xref="S3.Ex7.m1.4.4.3"><csymbol cd="ambiguous" id="S3.Ex7.m1.4.4.3.1.cmml" xref="S3.Ex7.m1.4.4.3">subscript</csymbol><ci id="S3.Ex7.m1.4.4.3.2.cmml" xref="S3.Ex7.m1.4.4.3.2">𝐷</ci><ci id="S3.Ex7.m1.4.4.3.3.cmml" xref="S3.Ex7.m1.4.4.3.3">𝑞</ci></apply><apply id="S3.Ex7.m1.4.4.1.cmml" xref="S3.Ex7.m1.4.4.1"><times id="S3.Ex7.m1.4.4.1.2.cmml" xref="S3.Ex7.m1.4.4.1.2"></times><apply id="S3.Ex7.m1.4.4.1.3.cmml" xref="S3.Ex7.m1.4.4.1.3"><csymbol cd="ambiguous" id="S3.Ex7.m1.4.4.1.3.1.cmml" xref="S3.Ex7.m1.4.4.1.3">subscript</csymbol><ci id="S3.Ex7.m1.4.4.1.3.2.cmml" xref="S3.Ex7.m1.4.4.1.3.2">𝑓</ci><ci id="S3.Ex7.m1.4.4.1.3.3.cmml" xref="S3.Ex7.m1.4.4.1.3.3">𝑟</ci></apply><vector id="S3.Ex7.m1.4.4.1.1.2.cmml" xref="S3.Ex7.m1.4.4.1.1.1"><ci id="S3.Ex7.m1.1.1.cmml" xref="S3.Ex7.m1.1.1">𝑥</ci><apply id="S3.Ex7.m1.4.4.1.1.1.1.cmml" xref="S3.Ex7.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex7.m1.4.4.1.1.1.1.1.cmml" xref="S3.Ex7.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S3.Ex7.m1.4.4.1.1.1.1.2.cmml" xref="S3.Ex7.m1.4.4.1.1.1.1.2">𝑔</ci><ci id="S3.Ex7.m1.4.4.1.1.1.1.3.cmml" xref="S3.Ex7.m1.4.4.1.1.1.1.3">𝑠</ci></apply><ci id="S3.Ex7.m1.2.2.cmml" xref="S3.Ex7.m1.2.2">𝑘</ci><ci id="S3.Ex7.m1.3.3.cmml" xref="S3.Ex7.m1.3.3">𝑛</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex7.m1.4c">D_{q}=f_{r}(x,g_{s},k,n)</annotation><annotation encoding="application/x-llamapun" id="S3.Ex7.m1.4d">italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_x , italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_k , italic_n )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.3">where <math alttext="k" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1"><semantics id="S3.SS3.p5.1.m1.1a"><mi id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><ci id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.1.m1.1d">italic_k</annotation></semantics></math> is the initial number of retrieved chunks and <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.1"><semantics id="S3.SS3.p5.2.m2.1a"><mi id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><ci id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.2.m2.1d">italic_n</annotation></semantics></math> is the final number of selected chunks <math alttext="(n\leq k)" class="ltx_Math" display="inline" id="S3.SS3.p5.3.m3.1"><semantics id="S3.SS3.p5.3.m3.1a"><mrow id="S3.SS3.p5.3.m3.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.1.cmml"><mo id="S3.SS3.p5.3.m3.1.1.1.2" stretchy="false" xref="S3.SS3.p5.3.m3.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p5.3.m3.1.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.1.cmml"><mi id="S3.SS3.p5.3.m3.1.1.1.1.2" xref="S3.SS3.p5.3.m3.1.1.1.1.2.cmml">n</mi><mo id="S3.SS3.p5.3.m3.1.1.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.1.1.cmml">≤</mo><mi id="S3.SS3.p5.3.m3.1.1.1.1.3" xref="S3.SS3.p5.3.m3.1.1.1.1.3.cmml">k</mi></mrow><mo id="S3.SS3.p5.3.m3.1.1.1.3" stretchy="false" xref="S3.SS3.p5.3.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><apply id="S3.SS3.p5.3.m3.1.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1"><leq id="S3.SS3.p5.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.1"></leq><ci id="S3.SS3.p5.3.m3.1.1.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.2">𝑛</ci><ci id="S3.SS3.p5.3.m3.1.1.1.1.3.cmml" xref="S3.SS3.p5.3.m3.1.1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">(n\leq k)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.3.m3.1d">( italic_n ≤ italic_k )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.4">The selected grammar chunks <math alttext="D_{q}" class="ltx_Math" display="inline" id="S3.SS3.p6.1.m1.1"><semantics id="S3.SS3.p6.1.m1.1a"><msub id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mi id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2">𝐷</ci><ci id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">D_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.1.m1.1d">italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> are concatenated with the input sentence <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p6.2.m2.1"><semantics id="S3.SS3.p6.2.m2.1a"><mi id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><ci id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.2.m2.1d">italic_x</annotation></semantics></math> and the initial glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS3.p6.3.m3.1"><semantics id="S3.SS3.p6.3.m3.1a"><msub id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml"><mi id="S3.SS3.p6.3.m3.1.1.2" xref="S3.SS3.p6.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS3.p6.3.m3.1.1.3" xref="S3.SS3.p6.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><apply id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.3.m3.1.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p6.3.m3.1.1.2.cmml" xref="S3.SS3.p6.3.m3.1.1.2">𝑔</ci><ci id="S3.SS3.p6.3.m3.1.1.3.cmml" xref="S3.SS3.p6.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> to form a prompt <math alttext="P" class="ltx_Math" display="inline" id="S3.SS3.p6.4.m4.1"><semantics id="S3.SS3.p6.4.m4.1a"><mi id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.1b"><ci id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.4.m4.1d">italic_P</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS3.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P=[x;g_{s};D_{q}]" class="ltx_Math" display="block" id="S3.Ex8.m1.3"><semantics id="S3.Ex8.m1.3a"><mrow id="S3.Ex8.m1.3.3" xref="S3.Ex8.m1.3.3.cmml"><mi id="S3.Ex8.m1.3.3.4" xref="S3.Ex8.m1.3.3.4.cmml">P</mi><mo id="S3.Ex8.m1.3.3.3" xref="S3.Ex8.m1.3.3.3.cmml">=</mo><mrow id="S3.Ex8.m1.3.3.2.2" xref="S3.Ex8.m1.3.3.2.3.cmml"><mo id="S3.Ex8.m1.3.3.2.2.3" stretchy="false" xref="S3.Ex8.m1.3.3.2.3.cmml">[</mo><mi id="S3.Ex8.m1.1.1" xref="S3.Ex8.m1.1.1.cmml">x</mi><mo id="S3.Ex8.m1.3.3.2.2.4" xref="S3.Ex8.m1.3.3.2.3.cmml">;</mo><msub id="S3.Ex8.m1.2.2.1.1.1" xref="S3.Ex8.m1.2.2.1.1.1.cmml"><mi id="S3.Ex8.m1.2.2.1.1.1.2" xref="S3.Ex8.m1.2.2.1.1.1.2.cmml">g</mi><mi id="S3.Ex8.m1.2.2.1.1.1.3" xref="S3.Ex8.m1.2.2.1.1.1.3.cmml">s</mi></msub><mo id="S3.Ex8.m1.3.3.2.2.5" xref="S3.Ex8.m1.3.3.2.3.cmml">;</mo><msub id="S3.Ex8.m1.3.3.2.2.2" xref="S3.Ex8.m1.3.3.2.2.2.cmml"><mi id="S3.Ex8.m1.3.3.2.2.2.2" xref="S3.Ex8.m1.3.3.2.2.2.2.cmml">D</mi><mi id="S3.Ex8.m1.3.3.2.2.2.3" xref="S3.Ex8.m1.3.3.2.2.2.3.cmml">q</mi></msub><mo id="S3.Ex8.m1.3.3.2.2.6" stretchy="false" xref="S3.Ex8.m1.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex8.m1.3b"><apply id="S3.Ex8.m1.3.3.cmml" xref="S3.Ex8.m1.3.3"><eq id="S3.Ex8.m1.3.3.3.cmml" xref="S3.Ex8.m1.3.3.3"></eq><ci id="S3.Ex8.m1.3.3.4.cmml" xref="S3.Ex8.m1.3.3.4">𝑃</ci><list id="S3.Ex8.m1.3.3.2.3.cmml" xref="S3.Ex8.m1.3.3.2.2"><ci id="S3.Ex8.m1.1.1.cmml" xref="S3.Ex8.m1.1.1">𝑥</ci><apply id="S3.Ex8.m1.2.2.1.1.1.cmml" xref="S3.Ex8.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Ex8.m1.2.2.1.1.1.1.cmml" xref="S3.Ex8.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.Ex8.m1.2.2.1.1.1.2.cmml" xref="S3.Ex8.m1.2.2.1.1.1.2">𝑔</ci><ci id="S3.Ex8.m1.2.2.1.1.1.3.cmml" xref="S3.Ex8.m1.2.2.1.1.1.3">𝑠</ci></apply><apply id="S3.Ex8.m1.3.3.2.2.2.cmml" xref="S3.Ex8.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.Ex8.m1.3.3.2.2.2.1.cmml" xref="S3.Ex8.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.Ex8.m1.3.3.2.2.2.2.cmml" xref="S3.Ex8.m1.3.3.2.2.2.2">𝐷</ci><ci id="S3.Ex8.m1.3.3.2.2.2.3.cmml" xref="S3.Ex8.m1.3.3.2.2.2.3">𝑞</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex8.m1.3c">P=[x;g_{s};D_{q}]</annotation><annotation encoding="application/x-llamapun" id="S3.Ex8.m1.3d">italic_P = [ italic_x ; italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ; italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p8">
<p class="ltx_p" id="S3.SS3.p8.2">The prompt <math alttext="P" class="ltx_Math" display="inline" id="S3.SS3.p8.1.m1.1"><semantics id="S3.SS3.p8.1.m1.1a"><mi id="S3.SS3.p8.1.m1.1.1" xref="S3.SS3.p8.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.1.m1.1b"><ci id="S3.SS3.p8.1.m1.1.1.cmml" xref="S3.SS3.p8.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p8.1.m1.1d">italic_P</annotation></semantics></math> is then fed into the LLM to generate the corrected glossing sequence <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.SS3.p8.2.m2.1"><semantics id="S3.SS3.p8.2.m2.1a"><msub id="S3.SS3.p8.2.m2.1.1" xref="S3.SS3.p8.2.m2.1.1.cmml"><mi id="S3.SS3.p8.2.m2.1.1.2" xref="S3.SS3.p8.2.m2.1.1.2.cmml">g</mi><mi id="S3.SS3.p8.2.m2.1.1.3" xref="S3.SS3.p8.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.2.m2.1b"><apply id="S3.SS3.p8.2.m2.1.1.cmml" xref="S3.SS3.p8.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p8.2.m2.1.1.1.cmml" xref="S3.SS3.p8.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p8.2.m2.1.1.2.cmml" xref="S3.SS3.p8.2.m2.1.1.2">𝑔</ci><ci id="S3.SS3.p8.2.m2.1.1.3.cmml" xref="S3.SS3.p8.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.2.m2.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p8.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS3.p9">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="g_{c}=\text{LLM}(P)" class="ltx_Math" display="block" id="S3.Ex9.m1.1"><semantics id="S3.Ex9.m1.1a"><mrow id="S3.Ex9.m1.1.2" xref="S3.Ex9.m1.1.2.cmml"><msub id="S3.Ex9.m1.1.2.2" xref="S3.Ex9.m1.1.2.2.cmml"><mi id="S3.Ex9.m1.1.2.2.2" xref="S3.Ex9.m1.1.2.2.2.cmml">g</mi><mi id="S3.Ex9.m1.1.2.2.3" xref="S3.Ex9.m1.1.2.2.3.cmml">c</mi></msub><mo id="S3.Ex9.m1.1.2.1" xref="S3.Ex9.m1.1.2.1.cmml">=</mo><mrow id="S3.Ex9.m1.1.2.3" xref="S3.Ex9.m1.1.2.3.cmml"><mtext id="S3.Ex9.m1.1.2.3.2" xref="S3.Ex9.m1.1.2.3.2a.cmml">LLM</mtext><mo id="S3.Ex9.m1.1.2.3.1" xref="S3.Ex9.m1.1.2.3.1.cmml">⁢</mo><mrow id="S3.Ex9.m1.1.2.3.3.2" xref="S3.Ex9.m1.1.2.3.cmml"><mo id="S3.Ex9.m1.1.2.3.3.2.1" stretchy="false" xref="S3.Ex9.m1.1.2.3.cmml">(</mo><mi id="S3.Ex9.m1.1.1" xref="S3.Ex9.m1.1.1.cmml">P</mi><mo id="S3.Ex9.m1.1.2.3.3.2.2" stretchy="false" xref="S3.Ex9.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex9.m1.1b"><apply id="S3.Ex9.m1.1.2.cmml" xref="S3.Ex9.m1.1.2"><eq id="S3.Ex9.m1.1.2.1.cmml" xref="S3.Ex9.m1.1.2.1"></eq><apply id="S3.Ex9.m1.1.2.2.cmml" xref="S3.Ex9.m1.1.2.2"><csymbol cd="ambiguous" id="S3.Ex9.m1.1.2.2.1.cmml" xref="S3.Ex9.m1.1.2.2">subscript</csymbol><ci id="S3.Ex9.m1.1.2.2.2.cmml" xref="S3.Ex9.m1.1.2.2.2">𝑔</ci><ci id="S3.Ex9.m1.1.2.2.3.cmml" xref="S3.Ex9.m1.1.2.2.3">𝑐</ci></apply><apply id="S3.Ex9.m1.1.2.3.cmml" xref="S3.Ex9.m1.1.2.3"><times id="S3.Ex9.m1.1.2.3.1.cmml" xref="S3.Ex9.m1.1.2.3.1"></times><ci id="S3.Ex9.m1.1.2.3.2a.cmml" xref="S3.Ex9.m1.1.2.3.2"><mtext id="S3.Ex9.m1.1.2.3.2.cmml" xref="S3.Ex9.m1.1.2.3.2">LLM</mtext></ci><ci id="S3.Ex9.m1.1.1.cmml" xref="S3.Ex9.m1.1.1">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex9.m1.1c">g_{c}=\text{LLM}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.Ex9.m1.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = LLM ( italic_P )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p10">
<p class="ltx_p" id="S3.SS3.p10.2">During training, the retriever <math alttext="f_{r}" class="ltx_Math" display="inline" id="S3.SS3.p10.1.m1.1"><semantics id="S3.SS3.p10.1.m1.1a"><msub id="S3.SS3.p10.1.m1.1.1" xref="S3.SS3.p10.1.m1.1.1.cmml"><mi id="S3.SS3.p10.1.m1.1.1.2" xref="S3.SS3.p10.1.m1.1.1.2.cmml">f</mi><mi id="S3.SS3.p10.1.m1.1.1.3" xref="S3.SS3.p10.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p10.1.m1.1b"><apply id="S3.SS3.p10.1.m1.1.1.cmml" xref="S3.SS3.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p10.1.m1.1.1.1.cmml" xref="S3.SS3.p10.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p10.1.m1.1.1.2.cmml" xref="S3.SS3.p10.1.m1.1.1.2">𝑓</ci><ci id="S3.SS3.p10.1.m1.1.1.3.cmml" xref="S3.SS3.p10.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p10.1.m1.1c">f_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p10.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and token classification model <math alttext="f_{s}" class="ltx_Math" display="inline" id="S3.SS3.p10.2.m2.1"><semantics id="S3.SS3.p10.2.m2.1a"><msub id="S3.SS3.p10.2.m2.1.1" xref="S3.SS3.p10.2.m2.1.1.cmml"><mi id="S3.SS3.p10.2.m2.1.1.2" xref="S3.SS3.p10.2.m2.1.1.2.cmml">f</mi><mi id="S3.SS3.p10.2.m2.1.1.3" xref="S3.SS3.p10.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p10.2.m2.1b"><apply id="S3.SS3.p10.2.m2.1.1.cmml" xref="S3.SS3.p10.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p10.2.m2.1.1.1.cmml" xref="S3.SS3.p10.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p10.2.m2.1.1.2.cmml" xref="S3.SS3.p10.2.m2.1.1.2">𝑓</ci><ci id="S3.SS3.p10.2.m2.1.1.3.cmml" xref="S3.SS3.p10.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p10.2.m2.1c">f_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p10.2.m2.1d">italic_f start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> are jointly optimized using a combined loss function:</p>
</div>
<div class="ltx_para" id="S3.SS3.p11">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L=L_{s}(g_{c},g_{t})+\alpha\cdot L_{r}(D_{q},D_{t})" class="ltx_Math" display="block" id="S3.Ex10.m1.4"><semantics id="S3.Ex10.m1.4a"><mrow id="S3.Ex10.m1.4.4" xref="S3.Ex10.m1.4.4.cmml"><mi id="S3.Ex10.m1.4.4.6" xref="S3.Ex10.m1.4.4.6.cmml">L</mi><mo id="S3.Ex10.m1.4.4.5" xref="S3.Ex10.m1.4.4.5.cmml">=</mo><mrow id="S3.Ex10.m1.4.4.4" xref="S3.Ex10.m1.4.4.4.cmml"><mrow id="S3.Ex10.m1.2.2.2.2" xref="S3.Ex10.m1.2.2.2.2.cmml"><msub id="S3.Ex10.m1.2.2.2.2.4" xref="S3.Ex10.m1.2.2.2.2.4.cmml"><mi id="S3.Ex10.m1.2.2.2.2.4.2" xref="S3.Ex10.m1.2.2.2.2.4.2.cmml">L</mi><mi id="S3.Ex10.m1.2.2.2.2.4.3" xref="S3.Ex10.m1.2.2.2.2.4.3.cmml">s</mi></msub><mo id="S3.Ex10.m1.2.2.2.2.3" xref="S3.Ex10.m1.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.Ex10.m1.2.2.2.2.2.2" xref="S3.Ex10.m1.2.2.2.2.2.3.cmml"><mo id="S3.Ex10.m1.2.2.2.2.2.2.3" stretchy="false" xref="S3.Ex10.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.Ex10.m1.1.1.1.1.1.1.1" xref="S3.Ex10.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex10.m1.1.1.1.1.1.1.1.2" xref="S3.Ex10.m1.1.1.1.1.1.1.1.2.cmml">g</mi><mi id="S3.Ex10.m1.1.1.1.1.1.1.1.3" xref="S3.Ex10.m1.1.1.1.1.1.1.1.3.cmml">c</mi></msub><mo id="S3.Ex10.m1.2.2.2.2.2.2.4" xref="S3.Ex10.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S3.Ex10.m1.2.2.2.2.2.2.2" xref="S3.Ex10.m1.2.2.2.2.2.2.2.cmml"><mi id="S3.Ex10.m1.2.2.2.2.2.2.2.2" xref="S3.Ex10.m1.2.2.2.2.2.2.2.2.cmml">g</mi><mi id="S3.Ex10.m1.2.2.2.2.2.2.2.3" xref="S3.Ex10.m1.2.2.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.Ex10.m1.2.2.2.2.2.2.5" stretchy="false" xref="S3.Ex10.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.Ex10.m1.4.4.4.5" xref="S3.Ex10.m1.4.4.4.5.cmml">+</mo><mrow id="S3.Ex10.m1.4.4.4.4" xref="S3.Ex10.m1.4.4.4.4.cmml"><mrow id="S3.Ex10.m1.4.4.4.4.4" xref="S3.Ex10.m1.4.4.4.4.4.cmml"><mi id="S3.Ex10.m1.4.4.4.4.4.2" xref="S3.Ex10.m1.4.4.4.4.4.2.cmml">α</mi><mo id="S3.Ex10.m1.4.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="S3.Ex10.m1.4.4.4.4.4.1.cmml">⋅</mo><msub id="S3.Ex10.m1.4.4.4.4.4.3" xref="S3.Ex10.m1.4.4.4.4.4.3.cmml"><mi id="S3.Ex10.m1.4.4.4.4.4.3.2" xref="S3.Ex10.m1.4.4.4.4.4.3.2.cmml">L</mi><mi id="S3.Ex10.m1.4.4.4.4.4.3.3" xref="S3.Ex10.m1.4.4.4.4.4.3.3.cmml">r</mi></msub></mrow><mo id="S3.Ex10.m1.4.4.4.4.3" xref="S3.Ex10.m1.4.4.4.4.3.cmml">⁢</mo><mrow id="S3.Ex10.m1.4.4.4.4.2.2" xref="S3.Ex10.m1.4.4.4.4.2.3.cmml"><mo id="S3.Ex10.m1.4.4.4.4.2.2.3" stretchy="false" xref="S3.Ex10.m1.4.4.4.4.2.3.cmml">(</mo><msub id="S3.Ex10.m1.3.3.3.3.1.1.1" xref="S3.Ex10.m1.3.3.3.3.1.1.1.cmml"><mi id="S3.Ex10.m1.3.3.3.3.1.1.1.2" xref="S3.Ex10.m1.3.3.3.3.1.1.1.2.cmml">D</mi><mi id="S3.Ex10.m1.3.3.3.3.1.1.1.3" xref="S3.Ex10.m1.3.3.3.3.1.1.1.3.cmml">q</mi></msub><mo id="S3.Ex10.m1.4.4.4.4.2.2.4" xref="S3.Ex10.m1.4.4.4.4.2.3.cmml">,</mo><msub id="S3.Ex10.m1.4.4.4.4.2.2.2" xref="S3.Ex10.m1.4.4.4.4.2.2.2.cmml"><mi id="S3.Ex10.m1.4.4.4.4.2.2.2.2" xref="S3.Ex10.m1.4.4.4.4.2.2.2.2.cmml">D</mi><mi id="S3.Ex10.m1.4.4.4.4.2.2.2.3" xref="S3.Ex10.m1.4.4.4.4.2.2.2.3.cmml">t</mi></msub><mo id="S3.Ex10.m1.4.4.4.4.2.2.5" stretchy="false" xref="S3.Ex10.m1.4.4.4.4.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex10.m1.4b"><apply id="S3.Ex10.m1.4.4.cmml" xref="S3.Ex10.m1.4.4"><eq id="S3.Ex10.m1.4.4.5.cmml" xref="S3.Ex10.m1.4.4.5"></eq><ci id="S3.Ex10.m1.4.4.6.cmml" xref="S3.Ex10.m1.4.4.6">𝐿</ci><apply id="S3.Ex10.m1.4.4.4.cmml" xref="S3.Ex10.m1.4.4.4"><plus id="S3.Ex10.m1.4.4.4.5.cmml" xref="S3.Ex10.m1.4.4.4.5"></plus><apply id="S3.Ex10.m1.2.2.2.2.cmml" xref="S3.Ex10.m1.2.2.2.2"><times id="S3.Ex10.m1.2.2.2.2.3.cmml" xref="S3.Ex10.m1.2.2.2.2.3"></times><apply id="S3.Ex10.m1.2.2.2.2.4.cmml" xref="S3.Ex10.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.Ex10.m1.2.2.2.2.4.1.cmml" xref="S3.Ex10.m1.2.2.2.2.4">subscript</csymbol><ci id="S3.Ex10.m1.2.2.2.2.4.2.cmml" xref="S3.Ex10.m1.2.2.2.2.4.2">𝐿</ci><ci id="S3.Ex10.m1.2.2.2.2.4.3.cmml" xref="S3.Ex10.m1.2.2.2.2.4.3">𝑠</ci></apply><interval closure="open" id="S3.Ex10.m1.2.2.2.2.2.3.cmml" xref="S3.Ex10.m1.2.2.2.2.2.2"><apply id="S3.Ex10.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex10.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex10.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex10.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex10.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex10.m1.1.1.1.1.1.1.1.2">𝑔</ci><ci id="S3.Ex10.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex10.m1.1.1.1.1.1.1.1.3">𝑐</ci></apply><apply id="S3.Ex10.m1.2.2.2.2.2.2.2.cmml" xref="S3.Ex10.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex10.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.Ex10.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex10.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.Ex10.m1.2.2.2.2.2.2.2.2">𝑔</ci><ci id="S3.Ex10.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.Ex10.m1.2.2.2.2.2.2.2.3">𝑡</ci></apply></interval></apply><apply id="S3.Ex10.m1.4.4.4.4.cmml" xref="S3.Ex10.m1.4.4.4.4"><times id="S3.Ex10.m1.4.4.4.4.3.cmml" xref="S3.Ex10.m1.4.4.4.4.3"></times><apply id="S3.Ex10.m1.4.4.4.4.4.cmml" xref="S3.Ex10.m1.4.4.4.4.4"><ci id="S3.Ex10.m1.4.4.4.4.4.1.cmml" xref="S3.Ex10.m1.4.4.4.4.4.1">⋅</ci><ci id="S3.Ex10.m1.4.4.4.4.4.2.cmml" xref="S3.Ex10.m1.4.4.4.4.4.2">𝛼</ci><apply id="S3.Ex10.m1.4.4.4.4.4.3.cmml" xref="S3.Ex10.m1.4.4.4.4.4.3"><csymbol cd="ambiguous" id="S3.Ex10.m1.4.4.4.4.4.3.1.cmml" xref="S3.Ex10.m1.4.4.4.4.4.3">subscript</csymbol><ci id="S3.Ex10.m1.4.4.4.4.4.3.2.cmml" xref="S3.Ex10.m1.4.4.4.4.4.3.2">𝐿</ci><ci id="S3.Ex10.m1.4.4.4.4.4.3.3.cmml" xref="S3.Ex10.m1.4.4.4.4.4.3.3">𝑟</ci></apply></apply><interval closure="open" id="S3.Ex10.m1.4.4.4.4.2.3.cmml" xref="S3.Ex10.m1.4.4.4.4.2.2"><apply id="S3.Ex10.m1.3.3.3.3.1.1.1.cmml" xref="S3.Ex10.m1.3.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.Ex10.m1.3.3.3.3.1.1.1.1.cmml" xref="S3.Ex10.m1.3.3.3.3.1.1.1">subscript</csymbol><ci id="S3.Ex10.m1.3.3.3.3.1.1.1.2.cmml" xref="S3.Ex10.m1.3.3.3.3.1.1.1.2">𝐷</ci><ci id="S3.Ex10.m1.3.3.3.3.1.1.1.3.cmml" xref="S3.Ex10.m1.3.3.3.3.1.1.1.3">𝑞</ci></apply><apply id="S3.Ex10.m1.4.4.4.4.2.2.2.cmml" xref="S3.Ex10.m1.4.4.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.Ex10.m1.4.4.4.4.2.2.2.1.cmml" xref="S3.Ex10.m1.4.4.4.4.2.2.2">subscript</csymbol><ci id="S3.Ex10.m1.4.4.4.4.2.2.2.2.cmml" xref="S3.Ex10.m1.4.4.4.4.2.2.2.2">𝐷</ci><ci id="S3.Ex10.m1.4.4.4.4.2.2.2.3.cmml" xref="S3.Ex10.m1.4.4.4.4.2.2.2.3">𝑡</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex10.m1.4c">L=L_{s}(g_{c},g_{t})+\alpha\cdot L_{r}(D_{q},D_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.Ex10.m1.4d">italic_L = italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) + italic_α ⋅ italic_L start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p12">
<p class="ltx_p" id="S3.SS3.p12.1">where:</p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.3"><math alttext="L_{s}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.1.m1.1"><semantics id="S3.I3.i1.p1.1.m1.1a"><msub id="S3.I3.i1.p1.1.m1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.cmml"><mi id="S3.I3.i1.p1.1.m1.1.1.2" xref="S3.I3.i1.p1.1.m1.1.1.2.cmml">L</mi><mi id="S3.I3.i1.p1.1.m1.1.1.3" xref="S3.I3.i1.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.1.m1.1b"><apply id="S3.I3.i1.p1.1.m1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I3.i1.p1.1.m1.1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I3.i1.p1.1.m1.1.1.2.cmml" xref="S3.I3.i1.p1.1.m1.1.1.2">𝐿</ci><ci id="S3.I3.i1.p1.1.m1.1.1.3.cmml" xref="S3.I3.i1.p1.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.1.m1.1c">L_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.1.m1.1d">italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> is the sequence loss between the corrected glossing sequence <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.2.m2.1"><semantics id="S3.I3.i1.p1.2.m2.1a"><msub id="S3.I3.i1.p1.2.m2.1.1" xref="S3.I3.i1.p1.2.m2.1.1.cmml"><mi id="S3.I3.i1.p1.2.m2.1.1.2" xref="S3.I3.i1.p1.2.m2.1.1.2.cmml">g</mi><mi id="S3.I3.i1.p1.2.m2.1.1.3" xref="S3.I3.i1.p1.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.2.m2.1b"><apply id="S3.I3.i1.p1.2.m2.1.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I3.i1.p1.2.m2.1.1.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I3.i1.p1.2.m2.1.1.2.cmml" xref="S3.I3.i1.p1.2.m2.1.1.2">𝑔</ci><ci id="S3.I3.i1.p1.2.m2.1.1.3.cmml" xref="S3.I3.i1.p1.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.2.m2.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> and the ground truth glossing labels <math alttext="g_{t}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.3.m3.1"><semantics id="S3.I3.i1.p1.3.m3.1a"><msub id="S3.I3.i1.p1.3.m3.1.1" xref="S3.I3.i1.p1.3.m3.1.1.cmml"><mi id="S3.I3.i1.p1.3.m3.1.1.2" xref="S3.I3.i1.p1.3.m3.1.1.2.cmml">g</mi><mi id="S3.I3.i1.p1.3.m3.1.1.3" xref="S3.I3.i1.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.3.m3.1b"><apply id="S3.I3.i1.p1.3.m3.1.1.cmml" xref="S3.I3.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I3.i1.p1.3.m3.1.1.1.cmml" xref="S3.I3.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I3.i1.p1.3.m3.1.1.2.cmml" xref="S3.I3.i1.p1.3.m3.1.1.2">𝑔</ci><ci id="S3.I3.i1.p1.3.m3.1.1.3.cmml" xref="S3.I3.i1.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.3.m3.1c">g_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i1.p1.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.3"><math alttext="L_{r}" class="ltx_Math" display="inline" id="S3.I3.i2.p1.1.m1.1"><semantics id="S3.I3.i2.p1.1.m1.1a"><msub id="S3.I3.i2.p1.1.m1.1.1" xref="S3.I3.i2.p1.1.m1.1.1.cmml"><mi id="S3.I3.i2.p1.1.m1.1.1.2" xref="S3.I3.i2.p1.1.m1.1.1.2.cmml">L</mi><mi id="S3.I3.i2.p1.1.m1.1.1.3" xref="S3.I3.i2.p1.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I3.i2.p1.1.m1.1b"><apply id="S3.I3.i2.p1.1.m1.1.1.cmml" xref="S3.I3.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I3.i2.p1.1.m1.1.1.1.cmml" xref="S3.I3.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I3.i2.p1.1.m1.1.1.2.cmml" xref="S3.I3.i2.p1.1.m1.1.1.2">𝐿</ci><ci id="S3.I3.i2.p1.1.m1.1.1.3.cmml" xref="S3.I3.i2.p1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i2.p1.1.m1.1c">L_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i2.p1.1.m1.1d">italic_L start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> is the retrieval loss that encourages the retriever to select relevant grammar chunks. It is implemented as a ranking loss between the retrieved chunks <math alttext="D_{q}" class="ltx_Math" display="inline" id="S3.I3.i2.p1.2.m2.1"><semantics id="S3.I3.i2.p1.2.m2.1a"><msub id="S3.I3.i2.p1.2.m2.1.1" xref="S3.I3.i2.p1.2.m2.1.1.cmml"><mi id="S3.I3.i2.p1.2.m2.1.1.2" xref="S3.I3.i2.p1.2.m2.1.1.2.cmml">D</mi><mi id="S3.I3.i2.p1.2.m2.1.1.3" xref="S3.I3.i2.p1.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I3.i2.p1.2.m2.1b"><apply id="S3.I3.i2.p1.2.m2.1.1.cmml" xref="S3.I3.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I3.i2.p1.2.m2.1.1.1.cmml" xref="S3.I3.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I3.i2.p1.2.m2.1.1.2.cmml" xref="S3.I3.i2.p1.2.m2.1.1.2">𝐷</ci><ci id="S3.I3.i2.p1.2.m2.1.1.3.cmml" xref="S3.I3.i2.p1.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i2.p1.2.m2.1c">D_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i2.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and the chunks that led to the best LLM performance <math alttext="D_{t}" class="ltx_Math" display="inline" id="S3.I3.i2.p1.3.m3.1"><semantics id="S3.I3.i2.p1.3.m3.1a"><msub id="S3.I3.i2.p1.3.m3.1.1" xref="S3.I3.i2.p1.3.m3.1.1.cmml"><mi id="S3.I3.i2.p1.3.m3.1.1.2" xref="S3.I3.i2.p1.3.m3.1.1.2.cmml">D</mi><mi id="S3.I3.i2.p1.3.m3.1.1.3" xref="S3.I3.i2.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I3.i2.p1.3.m3.1b"><apply id="S3.I3.i2.p1.3.m3.1.1.cmml" xref="S3.I3.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I3.i2.p1.3.m3.1.1.1.cmml" xref="S3.I3.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I3.i2.p1.3.m3.1.1.2.cmml" xref="S3.I3.i2.p1.3.m3.1.1.2">𝐷</ci><ci id="S3.I3.i2.p1.3.m3.1.1.3.cmml" xref="S3.I3.i2.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i2.p1.3.m3.1c">D_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i2.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p" id="S3.I3.i3.p1.1"><math alttext="\alpha" class="ltx_Math" display="inline" id="S3.I3.i3.p1.1.m1.1"><semantics id="S3.I3.i3.p1.1.m1.1a"><mi id="S3.I3.i3.p1.1.m1.1.1" xref="S3.I3.i3.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i3.p1.1.m1.1b"><ci id="S3.I3.i3.p1.1.m1.1.1.cmml" xref="S3.I3.i3.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i3.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.I3.i3.p1.1.m1.1d">italic_α</annotation></semantics></math> is a hyperparameter that controls the weight of the retrieval loss.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS3.p13">
<p class="ltx_p" id="S3.SS3.p13.1">By jointly optimizing the retriever and token classification components, the modular RAG approach enables the model to learn to identify the most relevant grammar information and effectively incorporate it into the glossing process. The retriever learns to select excerpts that are most pertinent to the input sentence and initial gloss output.</p>
</div>
<div class="ltx_para" id="S3.SS3.p14">
<p class="ltx_p" id="S3.SS3.p14.6">During inference, the trained retriever <math alttext="f_{r}" class="ltx_Math" display="inline" id="S3.SS3.p14.1.m1.1"><semantics id="S3.SS3.p14.1.m1.1a"><msub id="S3.SS3.p14.1.m1.1.1" xref="S3.SS3.p14.1.m1.1.1.cmml"><mi id="S3.SS3.p14.1.m1.1.1.2" xref="S3.SS3.p14.1.m1.1.1.2.cmml">f</mi><mi id="S3.SS3.p14.1.m1.1.1.3" xref="S3.SS3.p14.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p14.1.m1.1b"><apply id="S3.SS3.p14.1.m1.1.1.cmml" xref="S3.SS3.p14.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p14.1.m1.1.1.1.cmml" xref="S3.SS3.p14.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p14.1.m1.1.1.2.cmml" xref="S3.SS3.p14.1.m1.1.1.2">𝑓</ci><ci id="S3.SS3.p14.1.m1.1.1.3.cmml" xref="S3.SS3.p14.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p14.1.m1.1c">f_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p14.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> is used to select the top-<math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p14.2.m2.1"><semantics id="S3.SS3.p14.2.m2.1a"><mi id="S3.SS3.p14.2.m2.1.1" xref="S3.SS3.p14.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p14.2.m2.1b"><ci id="S3.SS3.p14.2.m2.1.1.cmml" xref="S3.SS3.p14.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p14.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p14.2.m2.1d">italic_n</annotation></semantics></math> relevant grammar chunks <math alttext="D_{q}" class="ltx_Math" display="inline" id="S3.SS3.p14.3.m3.1"><semantics id="S3.SS3.p14.3.m3.1a"><msub id="S3.SS3.p14.3.m3.1.1" xref="S3.SS3.p14.3.m3.1.1.cmml"><mi id="S3.SS3.p14.3.m3.1.1.2" xref="S3.SS3.p14.3.m3.1.1.2.cmml">D</mi><mi id="S3.SS3.p14.3.m3.1.1.3" xref="S3.SS3.p14.3.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p14.3.m3.1b"><apply id="S3.SS3.p14.3.m3.1.1.cmml" xref="S3.SS3.p14.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p14.3.m3.1.1.1.cmml" xref="S3.SS3.p14.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p14.3.m3.1.1.2.cmml" xref="S3.SS3.p14.3.m3.1.1.2">𝐷</ci><ci id="S3.SS3.p14.3.m3.1.1.3.cmml" xref="S3.SS3.p14.3.m3.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p14.3.m3.1c">D_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p14.3.m3.1d">italic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> for each input sentence <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p14.4.m4.1"><semantics id="S3.SS3.p14.4.m4.1a"><mi id="S3.SS3.p14.4.m4.1.1" xref="S3.SS3.p14.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p14.4.m4.1b"><ci id="S3.SS3.p14.4.m4.1.1.cmml" xref="S3.SS3.p14.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p14.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p14.4.m4.1d">italic_x</annotation></semantics></math> and initial glossing output <math alttext="g_{s}" class="ltx_Math" display="inline" id="S3.SS3.p14.5.m5.1"><semantics id="S3.SS3.p14.5.m5.1a"><msub id="S3.SS3.p14.5.m5.1.1" xref="S3.SS3.p14.5.m5.1.1.cmml"><mi id="S3.SS3.p14.5.m5.1.1.2" xref="S3.SS3.p14.5.m5.1.1.2.cmml">g</mi><mi id="S3.SS3.p14.5.m5.1.1.3" xref="S3.SS3.p14.5.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p14.5.m5.1b"><apply id="S3.SS3.p14.5.m5.1.1.cmml" xref="S3.SS3.p14.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p14.5.m5.1.1.1.cmml" xref="S3.SS3.p14.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p14.5.m5.1.1.2.cmml" xref="S3.SS3.p14.5.m5.1.1.2">𝑔</ci><ci id="S3.SS3.p14.5.m5.1.1.3.cmml" xref="S3.SS3.p14.5.m5.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p14.5.m5.1c">g_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p14.5.m5.1d">italic_g start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>. These selected chunks are provided to the LLM to generate the corrected glossing sequence <math alttext="g_{c}" class="ltx_Math" display="inline" id="S3.SS3.p14.6.m6.1"><semantics id="S3.SS3.p14.6.m6.1a"><msub id="S3.SS3.p14.6.m6.1.1" xref="S3.SS3.p14.6.m6.1.1.cmml"><mi id="S3.SS3.p14.6.m6.1.1.2" xref="S3.SS3.p14.6.m6.1.1.2.cmml">g</mi><mi id="S3.SS3.p14.6.m6.1.1.3" xref="S3.SS3.p14.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p14.6.m6.1b"><apply id="S3.SS3.p14.6.m6.1.1.cmml" xref="S3.SS3.p14.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p14.6.m6.1.1.1.cmml" xref="S3.SS3.p14.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p14.6.m6.1.1.2.cmml" xref="S3.SS3.p14.6.m6.1.1.2">𝑔</ci><ci id="S3.SS3.p14.6.m6.1.1.3.cmml" xref="S3.SS3.p14.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p14.6.m6.1c">g_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p14.6.m6.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Baseline Glossing Models</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Our expectation is that the best results for this task will be achieved by combining a model that exploits all available training data (the compact transformer or LSTM model) with the analytical power of modern LLMs.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">More specifically, we use two baseline glossing models, both of which have been shown to achieve strong performance in the standard setting for the glossing task <cite class="ltx_cite ltx_citemacro_cite">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib9" title="">2023</a>)</cite>. Following this setting, we model the production of IGT as a token classification task rather than as a sequence-to-sequence task.
Specifically, we experiment with two baseline models: one using RoBERTa <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib14" title="">2019</a>)</cite>, the second using a Bi-LSTM architecture.
By exploiting the contextual information captured by these architectures, we aim to obtain accurate predictions of the morphological labels for each token in the input sentences. These predicted labels are then used as the initial glossing output in the RAG framework.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">For the RoBERTa baseline, we use the same setting as the baseline for the IGT shared task, as described in <cite class="ltx_cite ltx_citemacro_citet">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib9" title="">2023</a>)</cite>.
The input sentences are tokenized and encoded using the RoBERTa tokenizer and encoder. The encoded representations are then passed through a linear classification layer to predict the morphological labels for each token.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">For the Bi-LSTM model, input sentences are first tokenized and converted into word embeddings. These embeddings are then fed into the Bi-LSTM layer to obtain the contextualized token representations. A linear classification layer is applied on top of the Bi-LSTM outputs to predict the morphological labels for each token.
Both models are trained using cross-entropy loss and optimized using the Adam optimizer. We use an adaptive learning rate and early stopping to ensure a better fit to the data.</p>
</div>
<div class="ltx_para" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">We additionally compare with two different LLMs used in a single-model, zero-shot RAG architecture. In this setting, the LLMs are solely responsible for the glossing output, rather than correcting the output of a predecessor model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Uspanteko and Arapaho: Data and Grammars</h2>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S4.T1.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">Uspanteko</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S4.T1.1.1.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">Arapaho</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S4.T1.1.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.2.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Word-level</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">Morpheme-level</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.2.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">Word-level</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.2.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">Morpheme-level</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.3">
<td class="ltx_td ltx_border_l ltx_border_r" id="S4.T1.1.3.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.1.3.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">Accuracy</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T1.1.3.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">Accuracy</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.1.3.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">Accuracy</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.1.3.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">Accuracy</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.4.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">GPT-4 Baseline (Zero-shot RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.4.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.21</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.4.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">51.88</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.4.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">48.47</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.4.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">53.48</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.5.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Claude Baseline (Zero-shot RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.5.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">38.40</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.5.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.5.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">49.91</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.5.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">58.60</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.6.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Previous SOTA (Shared task)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.6.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.46</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.6.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">84.51</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.6.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">85.87</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.6.6.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">91.37</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S4.T1.1.7.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">RoBERTa Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.7.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">76.55</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S4.T1.1.7.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.48</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.7.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">85.44</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.7.7.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">91.11</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.8">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.8.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">RoBERTa + Claude (Train + RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.8.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.8.8.2.1">79.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.8.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.8.8.3.1">84.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.8.8.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T1.1.8.8.4.1">86.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.8.8.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T1.1.8.8.5.1">93.74</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.9">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.9.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">RoBERTa + GPT-4 (Train + RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.9.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.41</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.9.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.49</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.9.9.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">85.51</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.9.9.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">91.43</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10.10">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.10.10.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">RoBERTa + Claude (Modular RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.10.10.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T1.1.10.10.2.1">81.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.10.10.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T1.1.10.10.3.1">85.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.10.10.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.10.10.4.1">83.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.10.10.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.10.10.5.1">90.26</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11.11">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.11.11.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">RoBERTa + GPT-4 (Modular RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.11.11.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.44</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.11.11.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.98</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.11.11.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.41</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.11.11.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">88.68</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12.12">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S4.T1.1.12.12.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bi-LSTM Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.12.12.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">71.28</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S4.T1.1.12.12.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">73.90</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.12.12.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">76.41</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.12.12.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">80.44</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.13.13">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.13.13.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bi-LSTM + Claude (Train + RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.13.13.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.47</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.13.13.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">80.21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.13.13.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.13.13.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">85.44</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.14.14">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.14.14.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bi-LSTM + GPT-4 (Train + RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.14.14.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">73.17</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.14.14.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.23</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.14.14.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">74.16</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.14.14.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.31</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.15.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.15.15.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bi-LSTM + Claude (Modular RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.15.15.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.26</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T1.1.15.15.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.22</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.15.15.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.24</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.15.15.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">85.89</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.16.16">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.16.16.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bi-LSTM + GPT-4 (Modular RAG)</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.16.16.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">74.12</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t" id="S4.T1.1.16.16.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.99</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.16.16.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">76.77</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.16.16.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.18</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of all model performances for Uspanteko and Arapaho. Averaged over 5 runs. Highest scores for each model type (naive, modular) are in boldface; overall high scores underlined. Naive RAG retrieves up to 6 relevant chunks of context while Modular RAG restricts this to the top 3 chunks.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Uspanteko is an endangered Mayan language spoken primarily in Guatemala.
It is an ergative-absolutive language with moderately complex concatenative morphology.
Much morphological inflection occurs on the verb stem, which takes both prefixes and suffixes and inflects for person, number, participant role, tense/aspect/mood, and voice, with a final status suffix. Arapaho is an endangered Algonquian language spoken by several communities in the Western United States. The language has free word order, polysynthetic and agglutinating morphology, and especially complex verbal morphology <cite class="ltx_cite ltx_citemacro_cite">Cowell and Moss Sr (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib6" title="">2011</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Data.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">We use the Uspanteko and Arapaho IGT datasets provided as part of the 2023 SIGMORPHON shared task <cite class="ltx_cite ltx_citemacro_cite">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib9" title="">2023</a>)</cite>, licensed under CC BY-NC 4.0, and we use the data in accordance with the uses intended as part of the shared task. The Uspanteko dataset has about 11,000 usable sentences and about 80 unique morphological function labels.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p2.1">The average sentence is 4.37 words, with many multi-morphemic words.
The Arapaho dataset is much larger, consisting of 39,500 sentences (5.4 words on average per sentence) in the training set and 5000 in the dev set.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p3.1">For Uspanteko, we use a very short (10 page) grammatical description, in Spanish, from the beginning of an Uspanteko-Spanish dictionary <cite class="ltx_cite ltx_citemacro_cite">Méndez (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib16" title="">2007</a>)</cite>. For Arapaho, we use a 500-page reference grammar authored by Andrew Cowell and Alonzo Moss, Sr. <cite class="ltx_cite ltx_citemacro_cite">Cowell and Moss Sr (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib6" title="">2011</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S4.T1" title="Table 1 ‣ 4 Uspanteko and Arapaho: Data and Grammars ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a> shows results for all experimental settings, as well as the previous state-of-the-art for each language, as reported in <cite class="ltx_cite ltx_citemacro_citet">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib9" title="">2023</a>)</cite>.
The two LLM-only baselines perform well below the glossing baselines (RoBERTa and Bi-LSTM, see <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3.SS4" title="3.4 Baseline Glossing Models ‣ 3 Methodology ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3.4</span></a>) and all other models.
For each of the two glossing baselines, we compare our naive and modular RAG models (see <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S3" title="3 Methodology ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a>), separately in combination with Claude and GPT-4.
We aim to evaluate which LLM is most effective at correcting the glossing output of the smaller token classification network, given retrieved grammar excerpts. Before evaluation, we perform post-processing to correct some common punctuation errors in the LLM output.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.3">We evaluate on both word-level and morpheme-level accuracy metrics as described in <cite class="ltx_cite ltx_citemacro_cite">Ginn et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib9" title="">2023</a>)</cite>. These metrics are computed by comparing the corrected glossing sequences <math alttext="g_{c}^{LLM}" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><msubsup id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi id="S5.p2.1.m1.1.1.2.2" xref="S5.p2.1.m1.1.1.2.2.cmml">g</mi><mi id="S5.p2.1.m1.1.1.2.3" xref="S5.p2.1.m1.1.1.2.3.cmml">c</mi><mrow id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml"><mi id="S5.p2.1.m1.1.1.3.2" xref="S5.p2.1.m1.1.1.3.2.cmml">L</mi><mo id="S5.p2.1.m1.1.1.3.1" xref="S5.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.p2.1.m1.1.1.3.3" xref="S5.p2.1.m1.1.1.3.3.cmml">L</mi><mo id="S5.p2.1.m1.1.1.3.1a" xref="S5.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.p2.1.m1.1.1.3.4" xref="S5.p2.1.m1.1.1.3.4.cmml">M</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1">superscript</csymbol><apply id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.2.1.cmml" xref="S5.p2.1.m1.1.1">subscript</csymbol><ci id="S5.p2.1.m1.1.1.2.2.cmml" xref="S5.p2.1.m1.1.1.2.2">𝑔</ci><ci id="S5.p2.1.m1.1.1.2.3.cmml" xref="S5.p2.1.m1.1.1.2.3">𝑐</ci></apply><apply id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3"><times id="S5.p2.1.m1.1.1.3.1.cmml" xref="S5.p2.1.m1.1.1.3.1"></times><ci id="S5.p2.1.m1.1.1.3.2.cmml" xref="S5.p2.1.m1.1.1.3.2">𝐿</ci><ci id="S5.p2.1.m1.1.1.3.3.cmml" xref="S5.p2.1.m1.1.1.3.3">𝐿</ci><ci id="S5.p2.1.m1.1.1.3.4.cmml" xref="S5.p2.1.m1.1.1.3.4">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">g_{c}^{LLM}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">italic_g start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L italic_L italic_M end_POSTSUPERSCRIPT</annotation></semantics></math> with the ground truth glossing labels <math alttext="g_{t}" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><msub id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml"><mi id="S5.p2.2.m2.1.1.2" xref="S5.p2.2.m2.1.1.2.cmml">g</mi><mi id="S5.p2.2.m2.1.1.3" xref="S5.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><apply id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p2.2.m2.1.1.1.cmml" xref="S5.p2.2.m2.1.1">subscript</csymbol><ci id="S5.p2.2.m2.1.1.2.cmml" xref="S5.p2.2.m2.1.1.2">𝑔</ci><ci id="S5.p2.2.m2.1.1.3.cmml" xref="S5.p2.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">g_{t}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> for each input sentence <math alttext="x" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><mi id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><ci id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">italic_x</annotation></semantics></math> in the test set. We manage to beat the previous SOTA with modular RAG for Uspanteko and naive RAG for Arapaho.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">We see that a RAG approach combining the RoBERTa baseline with Claude consistently performs best. The Bi-LSTM model performs reasonably well in most cases, although it consistently trails RoBERTa. Selective retrieval seems to help more with Uspanteko than Arapaho. In fact, we see a performance drop when we train the retriever with Arapaho. Modular RAG retrieves a smaller, more focused set of grammar chunks than naive RAG. It is possible that this reduced set fails to capture all the information needed to inform the Arapaho gloss correction process, resulting in a small accuracy drop.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Qualitative analysis: usability</h2>
<figure class="ltx_table" id="S6.T2">
<table class="ltx_tabular ltx_align_middle" id="S6.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.1.1">Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.2.1">Explanation</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.3.1">Example</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T2.1.1.1.4.1">Frequency</span></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.2.2.1">content</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.2.2.2">true mismatches between expected output and model output</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.2.2.3">FUT for PAST</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.2.2.4">30</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.3.3.1">form</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.3.3.2">variation in form only; likely resolvable by users</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.3.3.3">EXIST for EXS</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.3.3.4">18</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.4.4.1">specificity</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.4.4.2">generated output is more or less specific than expected output</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.4.4.3">NOM for SAB (abstract noun)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.4.4.4">2</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.5.5.1">category</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.5.5.2">generated tag where lexical output is expected, or vice versa</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.5.5.3">PROHIB for ‘eat something’</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.5.5.4">39</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.6.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.6.6.1">presence</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.6.6.2">generated output contains spurious labels,</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T2.1.6.6.3">PAST-NEG for PAST</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T2.1.6.6.4">10</td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.7.7">
<td class="ltx_td ltx_border_l ltx_border_r" id="S6.T2.1.7.7.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T2.1.7.7.2">or has fewer labels than expected</td>
<td class="ltx_td ltx_border_r" id="S6.T2.1.7.7.3"></td>
<td class="ltx_td ltx_border_r" id="S6.T2.1.7.7.4"></td>
</tr>
<tr class="ltx_tr" id="S6.T2.1.8.8">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S6.T2.1.8.8.1">unk</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S6.T2.1.8.8.2">model generates ?, or replaces ? with a guess</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S6.T2.1.8.8.3">SREL for ?</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T2.1.8.8.4">4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Error types and frequencies across 50 randomly-selected instances.</figcaption>
</figure>
<figure class="ltx_table" id="S6.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S6.T3.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.2.1">pre-LLM errors</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.3.1">corr/inc/part</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.4.1">new errors</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T3.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.5.1">% corr. expl.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T3.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.6.1">exp. quality (1-5)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T3.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S6.T3.1.1.1.7.1">ret. quality (1-5)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S6.T3.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.1.2.1.1.1">Arapaho</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T3.1.2.1.2">21</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T3.1.2.1.3">7 / 10 / 4</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T3.1.2.1.4">7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T3.1.2.1.5">82.55%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T3.1.2.1.6">3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T3.1.2.1.7">1.98</td>
</tr>
<tr class="ltx_tr" id="S6.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S6.T3.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S6.T3.1.3.2.1.1">Uspanteko</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T3.1.3.2.2">23</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T3.1.3.2.3">16 / 7 / 0</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T3.1.3.2.4">9</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T3.1.3.2.5">81.38%</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T3.1.3.2.6">3.19</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S6.T3.1.3.2.7">2.42</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Manual analysis of model output, 14 Arapaho/16 Uspanteko examples. We count model corrections that are <span class="ltx_text ltx_font_bold" id="S6.T3.9.1">correct</span>, <span class="ltx_text ltx_font_bold" id="S6.T3.10.2">incorrect</span>, and <span class="ltx_text ltx_font_bold" id="S6.T3.11.3">partially correct</span>, as well as <span class="ltx_text ltx_font_bold" id="S6.T3.12.4">new errors</span> introduced by the corrective LLM. We also rate the average <span class="ltx_text ltx_font_bold" id="S6.T3.13.5">explanation correctness</span> and quality of both <span class="ltx_text ltx_font_bold" id="S6.T3.14.6">explanations</span> and <span class="ltx_text ltx_font_bold" id="S6.T3.15.7">retrieved chunks</span>. Details in Appendix C.</figcaption>
</figure>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This system is designed to support linguists and others performing the work of interlinear glossing. The explanations generated by the model improve interpretability, as they provide an opportunity for human users to get some insight into the model’s decision-making process.
The best evaluation of the usability of our system would come from proper user studies, which we have begun and will report on in later work. For the present paper, we perform two manual analyses, both performed using outputs from our Modular RAG pipeline with RoBERTa + Claude.</p>
</div>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Glossing error types.</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">Initial inspection of system outputs showed that, in some cases, the LLM proposes a corrected gloss that is close to the expected output without being identical, resulting in a ding to automatically-evaluated performance. For example, the model sometimes outputs <span class="ltx_text ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.1.1">3S</span> when the expected tag is <span class="ltx_text ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.1.2">3.S</span>. We randomly select 50 instances across the two datasets and evaluate them for error types. Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S6.T2" title="Table 2 ‣ 6 Qualitative analysis: usability ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a> explains our error types and their frequency across this sample; we identify 103 errors across the 50 instances. Arapaho sentences have an average of 2.2 errors per sentence, with 1.9 for Uspanteko.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p2.1">Category-type errors, where the model generates a tag instead of a lexical item, or vice versa, are most common, followed by content-type errors, which we consider “true” glossing errors. The error types form and specificity are those which we expect to be easily interpreted and corrected by human users; these account for roughly 19% of the errors. See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.SS1" title="B.1 Glossing error types ‣ Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">B.1</span></a> for error subtypes.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Quality of explanations.</h4>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">Our second manual analysis concerns the quality and relevance of the explanations provided by the LLM.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p2.1">Examples in App. <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A1" title="Appendix A Sample explanations ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">A</span></a> show the two-part structure of the explanations: 1) explanation of the presumed meaning of the morphemes, 2) explanation of which parts of the grammar were retrieved and used to make glossing decisions.</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p3.1">We randomly select 30 instances. For each, we collect the original text, expected gloss, output of the initial glossing model, LLM-corrected output, and the complete set of explanations and retrieved grammar chunks from the RAG pipeline. A professional linguist then analyzes the number of pre-LLM errors, how many are addressed correctly/incorrectly/partially correctly, the percentage of correct morpheme explanations, the subjective quality of the RAG explanations, and the subjective quality of the retrieved grammar chunks, the latter two on a Likert scale (1-5). (Details in App. <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.SS2" title="B.2 Quality of explanations ‣ Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">B.2</span></a>.)</p>
</div>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p4.1">The results appear in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S6.T3" title="Table 3 ‣ 6 Qualitative analysis: usability ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a>. On average, the Uspanteko corrections are more accurate, with a similar number of new errors being introduced for both languages. Model explanations for individual morphemes are largely correct, and the chunks retrieved for Uspanteko are slightly higher quality. We note that there is a clear difference in the nature of the two grammars. The Arapaho grammar is a full and complex reference grammar, and the Uspanteko grammar is a sketch, using simpler explanations in a more compact presentation. This initial analysis suggests the need for a deeper exploration into linguistic reference materials of different types and their use in RAG.
Arapaho morphology is also significantly more complex than Uspanteko morphology, increasing the complexity of the task.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This study demonstrates the effectiveness of a Retrieval-Augmented Generation (RAG) framework in enhancing the performance of compact models for morphological glossing in low-resource language contexts. By leveraging the interpretive power of Large Language Models (LLMs) and the structured knowledge contained in grammatical descriptions, we achieve a new state-of-the-art for both languages investigated. A second advantage is the interpretability provided by LLM-generated explanations, which is crucial for building trust in the system’s outputs and facilitating the use of NLP tools in language documentation efforts.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">The RAG approach (combining a RoBERTa baseline with Claude) consistently outperforms other configurations, achieving the highest word- and morpheme-level accuracies for both languages. This framework effectively bridges the gap between the limited training data available for low-resource languages and the rich linguistic knowledge encoded in grammatical descriptions. The ability of LLMs to provide detailed explanations and confidence scores for each morpheme adds a layer of interpretability to the glossing process, potentially increasing the utility of these tools for documentary linguists.
Even with minimal grammatical resources, as for Uspanteko, the RAG approach shows notable improvements over baseline models.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">These findings suggest that the integration of linguistic knowledge through RAG can be a powerful approach for improving NLP tasks in low-resource settings. By combining the strengths of compact, trainable models with the vast knowledge encoded in LLMs and structured grammatical descriptions, we can create more accurate and interpretable tools for language documentation and analysis.</p>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">For future work, we would like to investigate additional languages, explore more sophisticated retrieval mechanisms, incorporate additional linguistic resources (as in <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#bib.bib23" title="">2024</a>)</cite>), and optimize our LLM selection and fine-tuning approaches. Near term, we plan to implement the same framework using an open-source LLM.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">While the proposed RAG framework for morphological glossing demonstrates promising results, there are several limitations to consider:</p>
</div>
<div class="ltx_para" id="S8.p2">
<ol class="ltx_enumerate" id="S8.I1">
<li class="ltx_item" id="S8.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S8.I1.i1.p1">
<p class="ltx_p" id="S8.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i1.p1.1.1">Dependency on grammar quality:</span> The effectiveness of the RAG pipeline heavily relies on the quality and comprehensiveness of the available grammar documents. If the grammar descriptions are incomplete, inconsistent, or contain errors, the retrieved excerpts may not provide accurate or sufficient information to guide the glossing corrections. This can lead to sub-optimal performance of the RAG model.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S8.I1.i2.p1">
<p class="ltx_p" id="S8.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i2.p1.1.1">Limited expressiveness of grammars: </span>The linguistic rules and patterns described in grammar documents may not capture all the nuances and exceptions present in the target language. Some morphological phenomena may be too complex or irregular to be fully expressed in a concise set of rules. This limitation can hinder the RAG model’s ability to generate accurate glossing labels for such cases. This is especially true in the case of our relatively small Uspanteko grammar.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S8.I1.i3.p1">
<p class="ltx_p" id="S8.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i3.p1.1.1">Scalability to larger datasets:</span> The current experiments focus on low-resource languages with relatively small datasets. While the RAG approach is designed to be data-efficient, its performance and computational requirements when applied to larger datasets or more diverse language families remain to be investigated. The retrieval and processing of grammar excerpts may become more challenging as the size and complexity of the data increases.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S8.I1.i4.p1">
<p class="ltx_p" id="S8.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i4.p1.1.1">Generalization to unseen languages:</span> The RAG pipeline has been evaluated on specific low-resource languages, such as Uspanteko and Arapaho. However, its generalization capability to other unseen languages with different morphological typologies is not extensively tested. The effectiveness of the approach may vary depending on the similarity of the target language to the languages used in training and the availability of suitable grammar resources.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S8.I1.i5.p1">
<p class="ltx_p" id="S8.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i5.p1.1.1">Reliance on proprietary models:</span> We currently use two proprietary LLMs for these experiments. Once we have the appropriate compute infrastructure established, we plan to implement the same architecture using an open-source model.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="S8.I1.i6.p1">
<p class="ltx_p" id="S8.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I1.i6.p1.1.1">Single evaluator for manual qualitative analysis:</span> So far we have performed only a small-scale, somewhat subjective analysis of the quality of the generated explanations and the relevance of retrieved grammar chunks for the sentences being glossed. We are currently building a web interface to allow linguists and other users to interact and evaluate model outputs. Once finished, we will expand this analysis to a more robust user study with multiple users and multiple languages.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Ethical Considerations</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">Although generative AI is clearly helpful in making the process of language documentation more explainable and efficient, it can also be deceptively convincing in its justifications. Through the initial prompt, the LLM is primed to report any uncertainties and assign confidence scores, but as seen in the qualitative analysis, this is in no way a foolproof approach. The RAG-driven system is not ready to be used by language learners or for large-scale language documentation tasks without further testing.</p>
</div>
<div class="ltx_para" id="S9.p2">
<p class="ltx_p" id="S9.p2.1">We also recognize that we use sensitive language data and resources to obtain our results. All our data is part of the publicly available Sigmorphon 2023 shared task data as mentioned in section <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S4" title="4 Uspanteko and Arapaho: Data and Grammars ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a>, and we have permission from the producers of the two grammars to use them for research purposes. We will continue to seek express permission from communities and authors before using low-resource data and grammars for future experiments.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2024)</span>
<span class="ltx_bibblock">
Anthropic. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.anthropic.com/news/claude-3-5-sonnet" title="">Introducing claude 3.5 sonnet</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Koller (2020)</span>
<span class="ltx_bibblock">
Emily M. Bender and Alexander Koller. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.463" title="">Climbing towards NLU: On meaning, form, and understanding in the age of data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 5185–5198, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2005.14165" title="">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">CoRR</em>, abs/2005.14165.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2020)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.747" title="">Unsupervised cross-lingual representation learning at scale</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 8440–8451, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cowell and Moss Sr (2011)</span>
<span class="ltx_bibblock">
Andrew Cowell and Alonzo Moss Sr. 2011.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">The Arapaho language</em>.

</span>
<span class="ltx_bibblock">University Press of Colorado.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1810.04805" title="">BERT: pre-training of deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CoRR</em>, abs/1810.04805.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ginn et al. (2024a)</span>
<span class="ltx_bibblock">
Michael Ginn, Mans Hulden, and Alexis Palmer. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2406.18895" title="">Can we teach language models to gloss endangered languages?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Preprint</em>, arXiv:2406.18895.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ginn et al. (2023)</span>
<span class="ltx_bibblock">
Michael Ginn, Sarah Moeller, Alexis Palmer, Anna Stacey, Garrett Nicolai, Mans Hulden, and Miikka Silfverberg. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.sigmorphon-1.20" title="">Findings of the SIGMORPHON 2023 shared task on interlinear glossing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 20th SIGMORPHON workshop on Computational Research in Phonetics, Phonology, and Morphology</em>, pages 186–201, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ginn et al. (2024b)</span>
<span class="ltx_bibblock">
Michael Ginn, Lindia Tjuatja, Taiqi He, Enora Rice, Graham Neubig, Alexis Palmer, and Lori Levin. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.06399" title="">GlossLM: Multilingual pretraining for low-resource interlinear glossing</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Preprint</em>, arXiv:2403.06399.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2024)</span>
<span class="ltx_bibblock">
Taiqi He, Kwanghee Choi, Lindia Tjuatja, Nathaniel Robinson, Jiatong Shi, Shinji Watanabe, Graham Neubig, David Mortensen, and Lori Levin. 2024.

</span>
<span class="ltx_bibblock">Wav2Gloss: Generating interlinear glossed text from speech.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Bangkok, Thailand. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holmström et al. (2023)</span>
<span class="ltx_bibblock">
Oskar Holmström, Jenny Kunz, and Marco Kuhlmann. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.resourceful-1.13" title="">Bridging the resource gap: Exploring the efficacy of English and multilingual LLMs for Swedish</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Second Workshop on Resources and Representations for Under-Resourced Languages and Domains (RESOURCEFUL-2023)</em>, pages 92–110, Tórshavn, the Faroe Islands. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2021)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2005.11401" title="">Retrieval-augmented generation for knowledge-intensive nlp tasks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Preprint</em>, arXiv:2005.11401.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1907.11692" title="">Roberta: A robustly optimized bert pretraining approach</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Preprint</em>, arXiv:1907.11692.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.14283" title="">Query rewriting for retrieval-augmented large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint</em>, arXiv:2305.14283.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Méndez (2007)</span>
<span class="ltx_bibblock">
Miguel Angel Vicente Méndez. 2007.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Cholaj Tzijb’al li Uspanteko: Diccionario Bilingüe Uspanteko-Español</em>.

</span>
<span class="ltx_bibblock">OKMA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reid et al. (2024)</span>
<span class="ltx_bibblock">
Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et al. 2024.

</span>
<span class="ltx_bibblock">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2403.05530</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Preprint</em>, arXiv:2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tziafas et al. (2023)</span>
<span class="ltx_bibblock">
Georgios Tziafas, Konstantinos Kogkalidis, Gijs Wijnholds, and Michael Moortgat. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.clasp-1.18" title="">Improving BERT pretraining with syntactic supervision</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2023 CLASP Conference on Learning with Small Data (LSD)</em>, pages 176–184, Gothenburg, Sweden. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2201.11903" title="">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Preprint</em>, arXiv:2201.11903.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al. (2022)</span>
<span class="ltx_bibblock">
Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2105.13626" title="">Byt5: Towards a token-free future with pre-trained byte-to-byte models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arXiv:2105.13626.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. (2024)</span>
<span class="ltx_bibblock">
Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, and Zhen-Hua Ling. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.15884" title="">Corrective retrieval augmented generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Preprint</em>, arXiv:2401.15884.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Kexun Zhang, Yee Man Choi, Zhenqiao Song, Taiqi He, William Yang Wang, and Lei Li. 2024.

</span>
<span class="ltx_bibblock">Hire a linguist!: Learning endangered languages with in-context linguistic descriptions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2402.18025</em>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Sample explanations</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Uspanteko Example</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Given the Uspanteko sentence "t wi’ tene’ qleen tob’ool laq b’ee", Claude produced the following corrected gloss: "EXST talvez NEG-existir ayudar-NMLZ PREP camino".
In addition to the corrected gloss, Claude generated a detailed explanation for each morpheme, along with confidence scores:</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I1.i1.p1.1.1">’wi" is an existential predicate (EXIST) indicating the presence or existence of something. (confidence: 0.9)</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I1.i2.p1.1.1">’tene" is a particle meaning ’maybe’ or ’perhaps’. (confidence: 0.7)</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I1.i3.p1.1.1">’qleen’ is a negative existential predicate (NEG-exist), indicating the non-existence of something. (confidence: 0.9)</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I1.i4.p1.1.1">’tob’ool’ can be broken down as: ’tob" (verb root meaning ’to help’), ’-ool’ (suffix nominalizing the verb, NMLZ), yielding a noun meaning ’help’ or ’assistance’. (confidence: 0.8)</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I1.i5.p1.1.1">’laq’ is a preposition meaning ’at’ or ’in’. (confidence: 0.8)</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p" id="A1.I1.i6.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I1.i6.p1.1.1">’b’ee’ is a noun meaning ’path’, ’road’, or ’way’. (confidence: 0.9)</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.1">Claude also provided information on how the RAG approach was used to arrive at the corrections:</p>
</div>
<div class="ltx_para" id="A1.SS1.p4">
<ul class="ltx_itemize" id="A1.I2">
<li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i1.p1">
<p class="ltx_p" id="A1.I2.i1.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I2.i1.p1.1.1">The existential predicate ’wi" and the negative existential predicate ’qleen’, both of which appeared in the example sentences.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i2.p1">
<p class="ltx_p" id="A1.I2.i2.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I2.i2.p1.1.1">The information about the suffix ’-ool’ nominalizing verbs (NMLZ), which was mentioned in the ’Estructura de las entradas’ (Structure of the entries) section.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i3.p1">
<p class="ltx_p" id="A1.I2.i3.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I2.i3.p1.1.1">The noun ’b’ee’ meaning ’path’, which appeared in one of the example sentences.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i4.p1">
<p class="ltx_p" id="A1.I2.i4.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I2.i4.p1.1.1">The meanings of ’tene" and ’laq’ were inferred from context, as they are not explicitly defined in the grammar document.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Arapaho Example</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">Given the Arapaho sentence "Hookoh neniih’ei3i’okuno’ hoo3oo’o’ hiniito’eino notoone hiihoowuno’useenino ", Claude produced the following corrected gloss: "because IC.scattered-sit-1PL what 3S-relative-OBV.PL 1S-people NEG-arrive-3PL".
In addition to the corrected gloss, Claude generated a detailed explanation for each morpheme, along with confidence scores:</p>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<ul class="ltx_itemize" id="A1.I3">
<li class="ltx_item" id="A1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i1.p1">
<p class="ltx_p" id="A1.I3.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i1.p1.1.1">hookoh<span class="ltx_text ltx_font_medium" id="A1.I3.i1.p1.1.1.1">: glossed as because, seems to be a conjunction (confidence: 0.9)</span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i2.p1">
<p class="ltx_p" id="A1.I3.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i2.p1.1.1">neniih’ei3i’okuno’<span class="ltx_text ltx_font_medium" id="A1.I3.i2.p1.1.1.1">: a complex verb form (confidence: 0.8)</span></span></p>
<ul class="ltx_itemize" id="A1.I3.i2.I1">
<li class="ltx_item" id="A1.I3.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i2.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i2.I1.i1.p1">
<p class="ltx_p" id="A1.I3.i2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i2.I1.i1.p1.1.1">neniih’ei-<span class="ltx_text ltx_font_medium" id="A1.I3.i2.I1.i1.p1.1.1.1">: possibly an initial change (IC) form of scattered</span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i2.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i2.I1.i2.p1">
<p class="ltx_p" id="A1.I3.i2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i2.I1.i2.p1.1.1">-3i’oku-</span><span class="ltx_text ltx_font_italic" id="A1.I3.i2.I1.i2.p1.1.2">: likely means sit</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i2.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i2.I1.i3.p1">
<p class="ltx_p" id="A1.I3.i2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i2.I1.i3.p1.1.1">-no’</span><span class="ltx_text ltx_font_italic" id="A1.I3.i2.I1.i3.p1.1.2">: 1PL (first person plural) marker</span><span class="ltx_text" id="A1.I3.i2.I1.i3.p1.1.3"></span></p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A1.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i3.p1">
<p class="ltx_p" id="A1.I3.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i3.p1.1.1">hoo3oo’o<span class="ltx_text ltx_font_medium" id="A1.I3.i3.p1.1.1.1">: glossed as what, likely an interrogative pronoun (confidence: 0.9)</span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i4.p1">
<p class="ltx_p" id="A1.I3.i4.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i4.p1.1.1">hiniito’eino<span class="ltx_text ltx_font_medium" id="A1.I3.i4.p1.1.1.1">: appears to be a noun phrase (confidence: 0.7)</span></span></p>
<ul class="ltx_itemize" id="A1.I3.i4.I1">
<li class="ltx_item" id="A1.I3.i4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i4.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i4.I1.i1.p1">
<p class="ltx_p" id="A1.I3.i4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i4.I1.i1.p1.1.1">hini-<span class="ltx_text ltx_font_medium" id="A1.I3.i4.I1.i1.p1.1.1.1">: possibly 3S (third person singular) prefix</span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i4.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i4.I1.i2.p1">
<p class="ltx_p" id="A1.I3.i4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i4.I1.i2.p1.1.1">-ito’ei-</span><span class="ltx_text ltx_font_italic" id="A1.I3.i4.I1.i2.p1.1.2">: root meaning relative</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i4.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i4.I1.i3.p1">
<p class="ltx_p" id="A1.I3.i4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i4.I1.i3.p1.1.1">-no</span><span class="ltx_text ltx_font_italic" id="A1.I3.i4.I1.i3.p1.1.2">: OBV.PL (obviative plural) marker</span><span class="ltx_text" id="A1.I3.i4.I1.i3.p1.1.3"></span></p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A1.I3.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i5.p1">
<p class="ltx_p" id="A1.I3.i5.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i5.p1.1.1">notoone<span class="ltx_text ltx_font_medium" id="A1.I3.i5.p1.1.1.1">: glossed as 1S-people, likely a possessed noun (confidence: 0.8)</span></span></p>
<ul class="ltx_itemize" id="A1.I3.i5.I1">
<li class="ltx_item" id="A1.I3.i5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i5.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i5.I1.i1.p1">
<p class="ltx_p" id="A1.I3.i5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i5.I1.i1.p1.1.1">no-<span class="ltx_text ltx_font_medium" id="A1.I3.i5.I1.i1.p1.1.1.1">: 1S (first person singular) possessive prefix</span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i5.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i5.I1.i2.p1">
<p class="ltx_p" id="A1.I3.i5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i5.I1.i2.p1.1.1">-toone</span><span class="ltx_text ltx_font_italic" id="A1.I3.i5.I1.i2.p1.1.2">: root meaning people</span><span class="ltx_text" id="A1.I3.i5.I1.i2.p1.1.3"></span></p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A1.I3.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i6.p1">
<p class="ltx_p" id="A1.I3.i6.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i6.p1.1.1">hiihoowuno’useenino<span class="ltx_text ltx_font_medium" id="A1.I3.i6.p1.1.1.1">: a complex verb form (confidence: 0.8)</span></span></p>
<ul class="ltx_itemize" id="A1.I3.i6.I1">
<li class="ltx_item" id="A1.I3.i6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i6.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i6.I1.i1.p1">
<p class="ltx_p" id="A1.I3.i6.I1.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i6.I1.i1.p1.1.1">hiihoowu-<span class="ltx_text ltx_font_medium" id="A1.I3.i6.I1.i1.p1.1.1.1">: NEG (negation) prefix</span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i6.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i6.I1.i2.p1">
<p class="ltx_p" id="A1.I3.i6.I1.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i6.I1.i2.p1.1.1">-no’usee-</span><span class="ltx_text ltx_font_italic" id="A1.I3.i6.I1.i2.p1.1.2">: verb root meaning arrive</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I3.i6.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="A1.I3.i6.I1.i3.p1">
<p class="ltx_p" id="A1.I3.i6.I1.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="A1.I3.i6.I1.i3.p1.1.1">-nino</span><span class="ltx_text ltx_font_italic" id="A1.I3.i6.I1.i3.p1.1.2">: 3PL (third person plural) marker</span><span class="ltx_text" id="A1.I3.i6.I1.i3.p1.1.3"></span></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.1">Claude also provided information on how the RAG approach was used to arrive at the corrections:</p>
</div>
<div class="ltx_para" id="A1.SS2.p4">
<ul class="ltx_itemize" id="A1.I4">
<li class="ltx_item" id="A1.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I4.i1.p1">
<p class="ltx_p" id="A1.I4.i1.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I4.i1.p1.1.1">The basic morphosyntax structure provided insight into the order of elements in the verb complex.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I4.i2.p1">
<p class="ltx_p" id="A1.I4.i2.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I4.i2.p1.1.1">The document mentions person markers and their positions, which helped in identifying <span class="ltx_text ltx_font_bold" id="A1.I4.i2.p1.1.1.1">-no’</span> as 1PL and <span class="ltx_text ltx_font_bold" id="A1.I4.i2.p1.1.1.2">-nino</span> as 3PL.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I4.i3.p1">
<p class="ltx_p" id="A1.I4.i3.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I4.i3.p1.1.1">The negation prefix <span class="ltx_text ltx_font_bold" id="A1.I4.i3.p1.1.1.1">ihoowu-</span> is mentioned, which appears here as <span class="ltx_text ltx_font_bold" id="A1.I4.i3.p1.1.1.2">hiihoowu-</span>.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I4.i4.p1">
<p class="ltx_p" id="A1.I4.i4.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I4.i4.p1.1.1">The document discusses obviative plural markers, supporting the interpretation of <span class="ltx_text ltx_font_bold" id="A1.I4.i4.p1.1.1.1">-no</span> in hiniito’eino.</span></p>
</div>
</li>
<li class="ltx_item" id="A1.I4.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I4.i5.p1">
<p class="ltx_p" id="A1.I4.i5.p1.1"><span class="ltx_text ltx_font_italic" id="A1.I4.i5.p1.1.1">The contraction rules mentioned weren’t directly applicable here but provided context for understanding morpheme boundaries.</span></p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Details of qualitative analyses</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Glossing error types</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">In section <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#S6.SS0.SSS0.Px1" title="Glossing error types. ‣ 6 Qualitative analysis: usability ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a> we present an analysis of the types of glossing errors made by our best model, across 50 randomly-selected sentences.
The figures presented there are for high-level error categories.
During the analysis, we consider a number of subtypes for each high-level error type.</p>
</div>
<div class="ltx_para" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.T6" title="Table 6 ‣ B.1 Glossing error types ‣ Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a> (next page) shows the complete set of error types and subtypes, with frequencies, examples, and descriptions.</p>
</div>
<figure class="ltx_table" id="A2.T4">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T4.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.1.2.1">usefulness/correctness</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.2.1.1">1</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T4.1.2.1.2">all explanations incorrect and/or unuseful</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.3.2.1">2</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T4.1.3.2.2">most explanations incorrect and/or unuseful</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.4.3.1">3</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T4.1.4.3.2">about half of explanations correct and/or useful</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.5.4.1">4</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T4.1.5.4.2">most explanations correct and/or useful</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.6.5.1">5</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T4.1.6.5.2">all explanations correct and/or useful</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Likert scale used to score morpheme explanations provided by the corrective LLM.</figcaption>
</figure>
<figure class="ltx_table" id="A2.T5">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T5.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T5.1.1.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.2.1">quality/relevance</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T5.1.2.1.1">1</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.2.1.2">all explanations unhelpful or misleading</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T5.1.3.2.1">2</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.3.2.2">most explanations unhelpful or irrelevant</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T5.1.4.3.1">3</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.4.3.2">about half of explanations relevant and helpful</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T5.1.5.4.1">4</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.5.4.2">most explanations relevant and helpful</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A2.T5.1.6.5.1">5</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T5.1.6.5.2">all explanations relevant and helpful</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Likert scale used to score RAG explanations provided by the corrective LLM.</figcaption>
</figure>
<figure class="ltx_table" id="A2.T6">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.1.1">type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.2.1">subtype</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.3.1">example</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.4.1">notes</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.5.1">frequency</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T6.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="A2.T6.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.2.1.1.1">content</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.2.1.2">wholeDiff</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.2.1.3">FUT for NEG</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.2.1.4">single tag wrong, output is</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A2.T6.1.2.1.5">13</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.3.2">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.3.2.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.3.2.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.3.2.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.3.2.4">entirely different linguistic dimension</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.3.2.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.4.3">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.4.3.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.4.3.2">wholeSame</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.4.3.3">FUT for PAST</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.4.3.4">single tag wrong, output is</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.4.3.5">8</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.5.4">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.5.4.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.5.4.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.5.4.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.5.4.4">same linguistic dimension</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.5.4.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.6.5">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.6.5.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.6.5.2">partial</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.6.5.3">E3S for E3P</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.6.5.4">one part of compound tag is incorrect</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.6.5.5">8</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.7.6">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.7.6.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.7.6.2">multiple</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.7.6.3">0S for 3PL</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.7.6.4">all parts of compound tag are incorrect</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.7.6.5">1</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="A2.T6.1.8.7.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.8.7.1.1">form</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.8.7.2">variant</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.8.7.3">EXIST for EXS</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.8.7.4">output has generated a plausible variant</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A2.T6.1.8.7.5">5</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.9.8">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.9.8.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.9.8.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.9.8.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.9.8.4">not in the tagset (could be in the grammar)</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.9.8.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.10.9">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.10.9.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.10.9.2">similar</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.10.9.3">IMP for IMPER</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.10.9.4">output is incorrect tag, similar to correct</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.10.9.5">2</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.11.10">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.11.10.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.11.10.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.11.10.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.11.10.4">tag, both are in the tagset</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.11.10.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.12.11">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.12.11.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.12.11.2">punct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.12.11.3">3.S for 3S, 3-S for 3S</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.12.11.4">only difference is punctuation (could be</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.12.11.5">9</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.13.12">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.13.12.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.13.12.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.13.12.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.13.12.4">missing, could be spurious, could be replacement)</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.13.12.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.14.13">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.14.13.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.14.13.2">case</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.14.13.3">PAUSE for pause</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.14.13.4">difference is case (which is</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.14.13.5">2</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.15.14">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.15.14.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.15.14.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.15.14.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.15.14.4">potentially meaningful in this setting)</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.15.14.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.16.15">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="A2.T6.1.16.15.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.16.15.1.1">presence</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.16.15.2">extra</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.16.15.3">PAST-NEG for PAST</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.16.15.4">output contains spuriously generated material</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A2.T6.1.16.15.5">8</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.17.16">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.17.16.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.17.16.2">missing</td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A2.T6.1.17.16.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.17.16.4">output is missing a tag</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.17.16.5">2</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.18.17">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="A2.T6.1.18.17.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.18.17.1.1">specificity</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.18.17.2">hyper</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.18.17.3">NOM for SAB</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.18.17.4">generated output is less specific than expected</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A2.T6.1.18.17.5">1</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.19.18">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.19.18.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.19.18.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.19.18.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.19.18.4">tag (e.g. nominal for abstract noun)</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.19.18.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.20.19">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.20.19.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.20.19.2">hypo</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.20.19.3">DET for PART</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.20.19.4">generated output is more specific than expected</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.20.19.5">1</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.21.20">
<td class="ltx_td ltx_border_l ltx_border_r" id="A2.T6.1.21.20.1"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.21.20.2"></td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.21.20.3"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.21.20.4">tag (e.g. DET could be one of many types of particles)</td>
<td class="ltx_td ltx_border_r" id="A2.T6.1.21.20.5"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.22.21">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="A2.T6.1.22.21.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.22.21.1.1">category</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.22.21.2">2lex</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.22.21.3">so.that for DETACH</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.22.21.4">generated output has lexical translation instead of tag</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A2.T6.1.22.21.5">17</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.23.22">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.23.22.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.23.22.2">2tag</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.23.22.3">PROHIB for eat.s.t.</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.23.22.4">generated output has tag instead of lexical translation</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.23.22.5">22</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.24.23">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="A2.T6.1.24.23.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.24.23.1.1">unk</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.24.23.2">unk</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.24.23.3">? for SC</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A2.T6.1.24.23.4">model generates ?</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A2.T6.1.24.23.5">2</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.25.24">
<td class="ltx_td ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A2.T6.1.25.24.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T6.1.25.24.2">guess</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T6.1.25.24.3">SC for ?</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T6.1.25.24.4">model guesses where original gloss has question marks</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T6.1.25.24.5">2</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Glossing error analysis types and subtypes, together with frequencies across 50 sentences.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Quality of explanations</h3>
<div class="ltx_para" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">Our process for analyzing the quality of explanations provided consisted of five steps.</p>
</div>
<div class="ltx_para" id="A2.SS2.p2">
<ol class="ltx_enumerate" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1">Compare glossing output of the baseline token classification model to the expected (gold standard) glossing output, counting the number of errors at the morpheme level.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1">Compare the LLM-corrected to the baseline output. For each error in the baseline output, determine whether the LLM made a correct correction, an incorrect correction, or a partially correct correction. In addition, look for new errors introduced by the corrective LLM.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1">For the set of morpheme explanations, mark each as correct, partially correct, or incorrect. Determine the percentage of correct explanations by comparing to the expected gloss, with partially correct explanations receiving 0.5 points.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A2.I1.i4.p1">
<p class="ltx_p" id="A2.I1.i4.p1.1">Rate the set of explanations about how RAG was used according to their usefulness and/or correctness, using the scale in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.T4" title="Table 4 ‣ B.1 Glossing error types ‣ Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A2.I1.i5.p1">
<p class="ltx_p" id="A2.I1.i5.p1.1">For each retrieved grammar chunk, rate its quality/relevance for the example being glossed, using the scale in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.00387v1#A2.T5" title="Table 5 ‣ B.1 Glossing error types ‣ Appendix B Details of qualitative analyses ‣ Boosting the Capabilities of Compact Models in Low-Data Contexts with Large Language Models and Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a>. Compute the average score across all retrieved grammar chunks.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  1 04:02:34 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
