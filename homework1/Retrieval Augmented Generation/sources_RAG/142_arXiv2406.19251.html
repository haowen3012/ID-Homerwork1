<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation</title>
<!--Generated on Thu Jun 27 04:19:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.19251v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S1" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S2" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S2.SS1" title="In 2 Related Work â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>AutoML and LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S2.SS2" title="In 2 Related Work â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Hyper-parameter Optimization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S2.SS3" title="In 2 Related Work â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Hyper-parameter Tuning in RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.SS1" title="In 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Problem Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.SS2" title="In 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Two-level Hierarchical MAB</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.SS1" title="In 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experiment Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.SS2" title="In 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experiment Result</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.SS3" title="In 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.SS4" title="In 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Case Study: Upgrade Base LLM from GPT-3.5-Turbo to GPT-4</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S5" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S6" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Summary</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A1" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Grid Search Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A2" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experiment Result with GPT-3.5</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A3" title="In AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Prompts</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jia Fu<sup class="ltx_sup" id="id3.1.id1">1, 2</sup>, Xiaoting Qin<sup class="ltx_sup" id="id4.2.id2">3</sup>, Fangkai Yang<sup class="ltx_sup" id="id5.3.id3">3</sup>, Lu Wang<sup class="ltx_sup" id="id6.4.id4">3</sup>, Jue Zhang<sup class="ltx_sup" id="id7.5.id5">3</sup>, Qingwei Lin<sup class="ltx_sup" id="id8.6.id6">3</sup>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id9.7.id7">Yubo Chen<sup class="ltx_sup" id="id9.7.id7.1">1, 2</sup>, Dongmei Zhang<sup class="ltx_sup" id="id9.7.id7.2">3</sup>, Saravan Rajmohan<sup class="ltx_sup" id="id9.7.id7.3">3</sup>, Qi Zhang<sup class="ltx_sup" id="id9.7.id7.4">3</sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id9.7.id7.5"><span class="ltx_text ltx_font_medium" id="id9.7.id7.5.1">1</span></sup></span> Institute of Automation, Chinese Academy of Sciences, Beijing, China
<br class="ltx_break"/><sup class="ltx_sup" id="id10.8.id8">2</sup> School of Artificial Intelligence, University of Chinese Academy of Sciences
<br class="ltx_break"/><sup class="ltx_sup" id="id11.9.id9">3</sup> Microsoft
<br class="ltx_break"/>fujia2021@ia.ac.cn, yubo.chen@nlpr.ia.ac.cn 
<br class="ltx_break"/>{xiaotingqin, fangkaiyang, wlu, juezhang, qlin}@microsoft.com
</span><span class="ltx_author_notes">Work is done during an internship at Microsoft.Corresponding author.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.2">Recent advancements in Large Language Models have transformed ML/AI development, necessitating a reevaluation of AutoML principles for the Retrieval-Augmented Generation (RAG) systems. To address the challenges of hyper-parameter optimization and online adaptation in RAG, we propose the AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical MAB (Hier-MAB) method for efficient exploration of large search spaces. We conduct extensive experiments on tuning hyper-parameters, such as top-k retrieved documents, prompt compression ratio, and embedding methods, using the ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly optimization all three hyper-parameters demonstrate that MAB-based online learning methods can achieve Recall@5 <math alttext="\approx 0.8" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml"></mi><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">â‰ˆ</mo><mn id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml">0.8</mn></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><approx id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1"></approx><csymbol cd="latexml" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">absent</csymbol><cn id="id1.1.m1.1.1.3.cmml" type="float" xref="id1.1.m1.1.1.3">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\approx 0.8</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">â‰ˆ 0.8</annotation></semantics></math> for scenarios with prominent gradients in search space, using only <math alttext="\sim 20\%" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml"></mi><mo id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">âˆ¼</mo><mrow id="id2.2.m2.1.1.3" xref="id2.2.m2.1.1.3.cmml"><mn id="id2.2.m2.1.1.3.2" xref="id2.2.m2.1.1.3.2.cmml">20</mn><mo id="id2.2.m2.1.1.3.1" xref="id2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><csymbol cd="latexml" id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="id2.2.m2.1.1.2.cmml" xref="id2.2.m2.1.1.2">absent</csymbol><apply id="id2.2.m2.1.1.3.cmml" xref="id2.2.m2.1.1.3"><csymbol cd="latexml" id="id2.2.m2.1.1.3.1.cmml" xref="id2.2.m2.1.1.3.1">percent</csymbol><cn id="id2.2.m2.1.1.3.2.cmml" type="integer" xref="id2.2.m2.1.1.3.2">20</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\sim 20\%</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">âˆ¼ 20 %</annotation></semantics></math> of the LLM API calls required by the Grid Search approach. Additionally, the proposed Hier-MAB approach outperforms other baselines in more challenging optimization scenarios. The code will be made available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aka.ms/autorag" title="">https://aka.ms/autorag</a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Jia Fu<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">1, 2</sup><span class="ltx_note ltx_role_thanks" id="p1.1.2.1.1.1.1.1.1.2"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>Work is done during an internship at Microsoft.</span></span></span>, Xiaoting Qin<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3">3</sup>, Fangkai Yang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.4">3</sup>, Lu Wang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.5">3</sup>, Jue Zhang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.6">3</sup><span class="ltx_note ltx_role_thanks" id="p1.1.2.1.1.1.1.1.1.7"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>Corresponding author.</span></span></span>, Qingwei Lin<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.8">3</sup>,</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.2.2.1.1">Yubo Chen<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.1">1, 2</sup>, Dongmei Zhang<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.2">3</sup>, Saravan Rajmohan<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.3">3</sup>, Qi Zhang<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.4">3</sup></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1">1</sup> Institute of Automation, Chinese Academy of Sciences, Beijing, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1"><sup class="ltx_sup" id="p1.1.2.1.1.4.4.1.1">2</sup> School of Artificial Intelligence, University of Chinese Academy of Sciences</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.5.5">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.5.5.1"><sup class="ltx_sup" id="p1.1.2.1.1.5.5.1.1">3</sup> Microsoft</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.6.6">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.6.6.1">fujia2021@ia.ac.cn, yubo.chen@nlpr.ia.ac.cn</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.7.7">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.7.7.1">{xiaotingqin, fangkaiyang, wlu, juezhang, qlin}@microsoft.com</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent advancements in Large Language Models (LLMs)Â <cite class="ltx_cite ltx_citemacro_cite">Brown etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib8" title="">2020</a>); Ouyang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib31" title="">2022</a>); OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib30" title="">2023</a>)</cite> represent a significant shift in the development of ML/AI solutions. Traditionally, scenario-specific models were trained for most ML/AI applications. However, in the LLM era, foundational models serve as the base, with supplementary modules added for practical applications. This transformation significantly affects the automation of ML/AI solution development, previously known as AutoMLÂ <cite class="ltx_cite ltx_citemacro_cite">Hutter etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib13" title="">2019</a>); Bergstra etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib4" title="">2011a</a>)</cite>, necessitating a reevaluation of AutoML concepts in the context of LLMs.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Retrieval-Augmented Generation (RAG) has emerged as a prominent framework for building ML/AI solutions with LLMsÂ <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib22" title="">2020</a>)</cite>. While the standard RAG framework includes an information retrieval component to ground LLMâ€™s output in relevant data, numerous variants now integrate additional modules such as query rewriting <cite class="ltx_cite ltx_citemacro_cite">Ma etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib26" title="">2023</a>)</cite>, prompt compression <cite class="ltx_cite ltx_citemacro_cite">Jiang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib16" title="">2023a</a>); Pan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib32" title="">2024</a>)</cite>, and query routing <cite class="ltx_cite ltx_citemacro_cite">Ding etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib10" title="">2024</a>)</cite> to enhance performance.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The increased complexity of RAG systems presents two main challenges. First, the multitude of modules and hyper-parameters within the modules complicates the identification of optimal settings. Second, as we often receive online feedback from users (e.g., via thumb up/down feature), effectively utilizing those feedback to continuously tune the system is also crucial.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To address these challenges, we propose the development of an autonomous and self-optimizing system for RAG, termed <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">AutoRAG</span>, in line with the principles of AutoML. As the first step, this study focuses on hyper-parameter tuning in RAG (<span class="ltx_text ltx_font_bold" id="S1.p4.1.2">AutoRAG-HP</span>). While there exist prior works discussing hyper-parameter tuning in RAG, they tend to either focus on tunable hyper-parameters in LLM API callsÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib39" title="">2023a</a>)</cite> or assess the performance and impacts of RAG hyper-parameters through manual tuningÂ <cite class="ltx_cite ltx_citemacro_cite">Lyu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib25" title="">2024</a>)</cite>. In this work we focus on the optimization methods that can be applied in the online fashion. Specifically, we frame hyper-parameter selection as an online multi-armed bandit (MAB) problemÂ <cite class="ltx_cite ltx_citemacro_cite">Lai and Robbins (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib20" title="">1985</a>); Vermorel and Mohri (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib38" title="">2005</a>); Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib23" title="">2010</a>)</cite> and explore several variants in MAB. Moreover, to efficiently explore large search space when tuning multiple hyper-parameters simultaneously, we introduce a novel two-level Hierarchical MAB (Hier-MAB) method, wherein a high-level MAB guides the optimization of modules, while several low-level MABs search for optimal settings within each module. Our evaluation demonstrates that the MAB-based online learning methods are effective for scenarios with prominent gradients in search space, and the proposed Hier-MAB approach outperforms other baselines in more challenging optimization scenarios.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our contributions can be summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We introduce the AutoRAG-HP framework to address the pressing needs for optimal hyper-parameter tuning in RAG. To our best knowledge, we are the first to discuss the automatic online hyper-parameter tuning in RAG.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We formulate the online hyper-parameter search in RAG as a multi-armed bandit problem and propose a novel two-level hierarchical multi-armed bandit method to efficiently explore large search space.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">The efficacy of our approach is validated across several scenarios using public datasets.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>AutoML and LLMs</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In the process of developing ML/AI solutions, AutoML <cite class="ltx_cite ltx_citemacro_cite">Hutter etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib13" title="">2019</a>); Bergstra etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib4" title="">2011a</a>)</cite> has streamlined automation across three key areas: feature engineering, model construction, and hyper-parameter optimization. Over the past decade, AutoML has achieved remarkable success with heavily-utilized open-source frameworks like AutoSklearn <cite class="ltx_cite ltx_citemacro_cite">Feurer etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib11" title="">2015</a>)</cite>, TPOT <cite class="ltx_cite ltx_citemacro_cite">Olson etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib28" title="">2016</a>)</cite>, Auto-Keras <cite class="ltx_cite ltx_citemacro_cite">Jin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib18" title="">2023</a>)</cite>, Auto-PyTorch <cite class="ltx_cite ltx_citemacro_cite">Zimmer etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib43" title="">2021</a>)</cite>, and FLAML <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib41" title="">2019</a>)</cite>. However, with the emergence of LLMs, a notable shift has occurred where LLMs are frequently chosen as base models, bypassing the traditional model design and training stages.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The research community has started to investigate the opportunities and challenges of applying AutoML to optimize pre-training, fine-tuning, and inference processes in the lifecycle of LLMs. A recent paper <cite class="ltx_cite ltx_citemacro_cite">Tornede etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib36" title="">2024</a>)</cite> presents a timely survey discussing the potential symbiotic relationship between AutoML and LLMs, while also providing a future-oriented vision. Particularly, in leveraging AutoML for LLMs, existing efforts have primarily focused on hyper-parameter optimization during the pre-training and fine-tuning stages <cite class="ltx_cite ltx_citemacro_cite">Liu and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib24" title="">2021</a>); Treviso etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib37" title="">2022</a>); Tornede etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib36" title="">2024</a>)</cite>. LLaMA-NAS <cite class="ltx_cite ltx_citemacro_cite">Sarah etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib34" title="">2024</a>)</cite> also explored efficient neural architecture search for LLMs. For the inference stage, EcoOptiGen <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib39" title="">2023a</a>)</cite> represents a pioneering step towards applying AutoML to optimize LLM inference for text generation. This work targets tuning of hyper-parameters in OpenAI completion headers like temperature and max tokens.
Another work <cite class="ltx_cite ltx_citemacro_cite">Pryzant etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib33" title="">2023</a>)</cite> explored gradient decent and MAB in automatic optimization of prompts.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Hyper-parameter Optimization</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Common hyper-parameter optimization techniques include methods such as Grid Search <cite class="ltx_cite ltx_citemacro_cite">Lecun etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib21" title="">1998</a>)</cite>, Random Search <cite class="ltx_cite ltx_citemacro_cite">Bergstra and Bengio (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib6" title="">2012a</a>)</cite>, Bayesian Optimization <cite class="ltx_cite ltx_citemacro_cite">Bergstra etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib5" title="">2011b</a>)</cite> and manual tuning to identify optimal hyper-parameters. Grid search involves exhaustive searching within a predefined hyper-parameters grid, testing every possible combination to find the best fit. While straightforward, this approach can incur substantial computational costs, especially with expansive hyper-parameters spaces. Random search selects hyper-parameters through randomized sampling, yet its results may lack stability.
Manual tuning, on the other hand, adjusts hyper-parameters based on domain knowledge or experience. While flexible, this method is time-consuming and challenging to standardize. These hyper-parameter optimization approaches often overlook the evaluation costs, particularly in evaluating solutions based on LLMs. BlendSearch <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib40" title="">2021</a>)</cite> introduces an economic budget to enhance cost efficiency. However, these methods are not inherently learning-based and may not be well-suited for scenarios requiring adaptive optimization over time.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Hyper-parameter Tuning in RAG</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Significant attention has been directed towards refining models within individual modules such as indexing, retrieval, and generation independently <cite class="ltx_cite ltx_citemacro_cite">Izacard etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib15" title="">2022</a>); Jiang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib17" title="">2023b</a>); Ma etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib26" title="">2023</a>); Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib42" title="">2023b</a>)</cite>. However, in terms of hyper-parameters, these studies typically only report those leading to the best results, often chosen through manual tuning by experts during experimentation. Consequently, there has been scant exploration aimed at tuning hyper-parameters within each module, let alone collectively tuning various hyper-parameters across RAG modules.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">CRUD-RAG <cite class="ltx_cite ltx_citemacro_cite">Lyu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib25" title="">2024</a>)</cite> has delved into the manual tuning of RAG hyper-parameters and assessed the performance and impacts of different components of the RAG system, such as the retriever and context length. While such studies offer valuable insights for optimizing RAG technology, their applicability across diverse scenarios or real-world applications is limited. Additionally, a project <cite class="ltx_cite ltx_citemacro_cite">Marker-Inc-Korea (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib27" title="">2024</a>)</cite> mentions optimization via a greedy approach, initially generating all possible combinations of modules and hyper-parameters in each node.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Formulation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We formulate the hyper-parameter tuning problem in RAG as a multi-armed bandit (MAB) problemÂ <cite class="ltx_cite ltx_citemacro_cite">Lai and Robbins (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib20" title="">1985</a>)</cite>, drawing an analogy to the scenario of a player selecting from a slot machine with multiple arms in a casino. The playerâ€™s objective is to choose the arm that offers the highest expected gain. Each time the player pulls an arm and receives a gain or not, they update their estimation of the armâ€™s potential gain. The MAB problem involves making sequential decisions, requiring the agent to balance the exploration of different arms to learn their reward probabilities and the exploitation of arms that are expected to yield higher rewards based on past observations. Given that MAB is an online learning method, it is well-suited for the online setting of AutoRAG-HP.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="373" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A RAG system with tunable hyper-parameters.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.3">As an illustration, we present an example RAG system in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.F1" title="Figure 1 â€£ 3.1 Problem Formulation â€£ 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>, which comprises a retrieval module, a prompt compression module, and a prompt construction module (not shown) that assembles the final prompt sent to LLMs for answer generation. In the retrieval module, we introduce two tunable hyper-parameters: the top-k (<math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">caligraphic_K</annotation></semantics></math>) document chunks retrieved from an external knowledge base and the embedding model (<math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">caligraphic_E</annotation></semantics></math>) used for ranking these retrieved chunks. With the top-k chunks retrieved, the prompt compression module then compresses tokens in each chunk to eliminate irrelevant information and save token cost Â <cite class="ltx_cite ltx_citemacro_cite">Jiang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib16" title="">2023a</a>); Pan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib32" title="">2024</a>)</cite>. Since excessive compression may also remove relevant information, leading to decreased performance, it is crucial to find an optimal compression ratio (<math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">caligraphic_C</annotation></semantics></math>). Below, we introduce the terms in MAB in the context of AutoRAG-HP.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Arm</span> In this context, an arm refers to a specific combination of hyper-parameters that we aim to optimize. For instance, if we are optimizing the top-k parameter, an arm can represent a candidate value for top-k (e.g., <math alttext="\mathcal{K}=3" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">ğ’¦</mi><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><eq id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></eq><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ğ’¦</ci><cn id="S3.SS1.p3.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p3.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{K}=3</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">caligraphic_K = 3</annotation></semantics></math>). When optimizing multiple hyper-parameters simultaneously, an arm corresponds to a combination of these hyper-parameters, as defined in the standard formulation of the MAB problem. Note that since arms are discrete, the search space must first be discretized.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.2.1">Trial</span> A trial is a single iteration in which the algorithm selects an arm, observes the associated reward, and updates its estimation. In the RAG system, a trial can involve evaluating a group of queries with batch size <math alttext="B" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_B</annotation></semantics></math> for the current selection of hyper-parameter combinations (i.e., arms). Optimal settings may be determined after a predetermined number of iterations, <math alttext="T" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_T</annotation></semantics></math>, or upon meeting a specific stopping criterion.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.5"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.5.1">Reward</span> The reward function represents the userâ€™s objective and guides arm selection during the optimization process. For AutoRAG-HP, common goals include the maximization of response accuracy while paying less attention to the cost of LLM API calls (quantified by input token count), or balancing these objectives. For simplicity, we formulate the reward function as a linear combination of response accuracy and input token length:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Reward}=w\cdot acc-(1-w)\cdot\frac{t}{t_{max}}," class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mtext id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3a.cmml">Reward</mtext><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.3.2.2.cmml">w</mi><mo id="S3.E1.m1.1.1.1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.1.1.1.3.2.1.cmml">â‹…</mo><mi id="S3.E1.m1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.3.2.3.cmml">a</mi></mrow><mo id="S3.E1.m1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.3.3.cmml">c</mi><mo id="S3.E1.m1.1.1.1.1.1.3.1a" xref="S3.E1.m1.1.1.1.1.1.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.1.1.1.3.4" xref="S3.E1.m1.1.1.1.1.1.3.4.cmml">c</mi></mrow><mo id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml">w</mi></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.2" rspace="0.222em" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">â‹…</mo><mfrac id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">t</mi><msub id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.2.cmml">m</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.3.cmml">a</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.4" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.4.cmml">x</mi></mrow></msub></mfrac></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><ci id="S3.E1.m1.1.1.1.1.3a.cmml" xref="S3.E1.m1.1.1.1.1.3"><mtext id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3">Reward</mtext></ci><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></minus><apply id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.1"></times><apply id="S3.E1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2.1">â‹…</ci><ci id="S3.E1.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2.2">ğ‘¤</ci><ci id="S3.E1.m1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2.3">ğ‘</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.3.4">ğ‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">â‹…</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘¤</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><divide id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"></divide><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">ğ‘¡</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2">ğ‘¡</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3"><times id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.2">ğ‘š</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.3">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.4">ğ‘¥</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\text{Reward}=w\cdot acc-(1-w)\cdot\frac{t}{t_{max}},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">Reward = italic_w â‹… italic_a italic_c italic_c - ( 1 - italic_w ) â‹… divide start_ARG italic_t end_ARG start_ARG italic_t start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p5.4">where <math alttext="w" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><mi id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">italic_w</annotation></semantics></math> is the balance weight, <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p5.2.m2.1"><semantics id="S3.SS1.p5.2.m2.1a"><mi id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><ci id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.2.m2.1d">italic_t</annotation></semantics></math> denotes the input token length and normalized by the maximal input token length <math alttext="t_{max}" class="ltx_Math" display="inline" id="S3.SS1.p5.3.m3.1"><semantics id="S3.SS1.p5.3.m3.1a"><msub id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mi id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">t</mi><mrow id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml"><mi id="S3.SS1.p5.3.m3.1.1.3.2" xref="S3.SS1.p5.3.m3.1.1.3.2.cmml">m</mi><mo id="S3.SS1.p5.3.m3.1.1.3.1" xref="S3.SS1.p5.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS1.p5.3.m3.1.1.3.3" xref="S3.SS1.p5.3.m3.1.1.3.3.cmml">a</mi><mo id="S3.SS1.p5.3.m3.1.1.3.1a" xref="S3.SS1.p5.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS1.p5.3.m3.1.1.3.4" xref="S3.SS1.p5.3.m3.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2">ğ‘¡</ci><apply id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3"><times id="S3.SS1.p5.3.m3.1.1.3.1.cmml" xref="S3.SS1.p5.3.m3.1.1.3.1"></times><ci id="S3.SS1.p5.3.m3.1.1.3.2.cmml" xref="S3.SS1.p5.3.m3.1.1.3.2">ğ‘š</ci><ci id="S3.SS1.p5.3.m3.1.1.3.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3.3">ğ‘</ci><ci id="S3.SS1.p5.3.m3.1.1.3.4.cmml" xref="S3.SS1.p5.3.m3.1.1.3.4">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">t_{max}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.3.m3.1d">italic_t start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="acc" class="ltx_Math" display="inline" id="S3.SS1.p5.4.m4.1"><semantics id="S3.SS1.p5.4.m4.1a"><mrow id="S3.SS1.p5.4.m4.1.1" xref="S3.SS1.p5.4.m4.1.1.cmml"><mi id="S3.SS1.p5.4.m4.1.1.2" xref="S3.SS1.p5.4.m4.1.1.2.cmml">a</mi><mo id="S3.SS1.p5.4.m4.1.1.1" xref="S3.SS1.p5.4.m4.1.1.1.cmml">â¢</mo><mi id="S3.SS1.p5.4.m4.1.1.3" xref="S3.SS1.p5.4.m4.1.1.3.cmml">c</mi><mo id="S3.SS1.p5.4.m4.1.1.1a" xref="S3.SS1.p5.4.m4.1.1.1.cmml">â¢</mo><mi id="S3.SS1.p5.4.m4.1.1.4" xref="S3.SS1.p5.4.m4.1.1.4.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m4.1b"><apply id="S3.SS1.p5.4.m4.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1"><times id="S3.SS1.p5.4.m4.1.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1.1"></times><ci id="S3.SS1.p5.4.m4.1.1.2.cmml" xref="S3.SS1.p5.4.m4.1.1.2">ğ‘</ci><ci id="S3.SS1.p5.4.m4.1.1.3.cmml" xref="S3.SS1.p5.4.m4.1.1.3">ğ‘</ci><ci id="S3.SS1.p5.4.m4.1.1.4.cmml" xref="S3.SS1.p5.4.m4.1.1.4">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m4.1c">acc</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.4.m4.1d">italic_a italic_c italic_c</annotation></semantics></math> represents the LLMâ€™s response accuracy.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p6.1.1">Optimization Algorithm</span> Several optimization algorithms in MAB can guide arm selection based on the given reward function. One common choice is the Upper Confidence Bound (UCB) algorithmÂ <cite class="ltx_cite ltx_citemacro_cite">Auer etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib3" title="">2002</a>)</cite>, which effectively balances exploration and exploitation by selecting arms based on their upper confidence bounds. These bounds are derived from confidence intervals representing the estimated ranges of arm values. The UCB selection of arms is shown below:</p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\vspace*{-0.5em}A_{t}=\arg\max_{a\in\mathcal{A}}\left(Q_{t}(a)+\alpha\sqrt{%
\frac{\ln(t)}{N_{a}(t)}}\right)," class="ltx_Math" display="block" id="S3.E2.m1.5"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5.1" xref="S3.E2.m1.5.5.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.cmml"><msub id="S3.E2.m1.5.5.1.1.4" xref="S3.E2.m1.5.5.1.1.4.cmml"><mi id="S3.E2.m1.5.5.1.1.4.2" xref="S3.E2.m1.5.5.1.1.4.2.cmml">A</mi><mi id="S3.E2.m1.5.5.1.1.4.3" xref="S3.E2.m1.5.5.1.1.4.3.cmml">t</mi></msub><mo id="S3.E2.m1.5.5.1.1.3" xref="S3.E2.m1.5.5.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.5.5.1.1.2" xref="S3.E2.m1.5.5.1.1.2.cmml"><mi id="S3.E2.m1.5.5.1.1.2.3" xref="S3.E2.m1.5.5.1.1.2.3.cmml">arg</mi><mo id="S3.E2.m1.5.5.1.1.2a" lspace="0.167em" xref="S3.E2.m1.5.5.1.1.2.cmml">â¡</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.2" xref="S3.E2.m1.5.5.1.1.2.2.3.cmml"><munder id="S3.E2.m1.5.5.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.2.cmml">max</mi><mrow id="S3.E2.m1.5.5.1.1.1.1.1.1.3" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.2.cmml">a</mi><mo id="S3.E2.m1.5.5.1.1.1.1.1.1.3.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.5.5.1.1.1.1.1.1.3.3" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.3.cmml">ğ’œ</mi></mrow></munder><mo id="S3.E2.m1.5.5.1.1.2.2.2a" xref="S3.E2.m1.5.5.1.1.2.2.3.cmml">â¡</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.2.2" xref="S3.E2.m1.5.5.1.1.2.2.3.cmml"><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.2" xref="S3.E2.m1.5.5.1.1.2.2.3.cmml">(</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.2.2.1" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.cmml"><msub id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.cmml"><mi id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.2" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.2.cmml">Q</mi><mi id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.3" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.3.cmml">t</mi></msub><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.1" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.1.cmml">â¢</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.3.2" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.cmml"><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.3.2.1" stretchy="false" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.cmml">(</mo><mi id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">a</mi><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.3.2.2" stretchy="false" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.1.1" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.1.cmml">+</mo><mrow id="S3.E2.m1.5.5.1.1.2.2.2.2.1.3" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.cmml"><mi id="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.2" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.2.cmml">Î±</mi><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.1" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.1.cmml">â¢</mo><msqrt id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml"><mfrac id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml"><mrow id="S3.E2.m1.2.2.2.2.2.4" xref="S3.E2.m1.2.2.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml">ln</mi><mo id="S3.E2.m1.2.2.2.2.2.4a" xref="S3.E2.m1.2.2.2.2.2.3.cmml">â¡</mo><mrow id="S3.E2.m1.2.2.2.2.2.4.1" xref="S3.E2.m1.2.2.2.2.2.3.cmml"><mo id="S3.E2.m1.2.2.2.2.2.4.1.1" stretchy="false" xref="S3.E2.m1.2.2.2.2.2.3.cmml">(</mo><mi id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml">t</mi><mo id="S3.E2.m1.2.2.2.2.2.4.1.2" stretchy="false" xref="S3.E2.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.3.3.3.3.3" xref="S3.E2.m1.3.3.3.3.3.cmml"><msub id="S3.E2.m1.3.3.3.3.3.3" xref="S3.E2.m1.3.3.3.3.3.3.cmml"><mi id="S3.E2.m1.3.3.3.3.3.3.2" xref="S3.E2.m1.3.3.3.3.3.3.2.cmml">N</mi><mi id="S3.E2.m1.3.3.3.3.3.3.3" xref="S3.E2.m1.3.3.3.3.3.3.3.cmml">a</mi></msub><mo id="S3.E2.m1.3.3.3.3.3.2" xref="S3.E2.m1.3.3.3.3.3.2.cmml">â¢</mo><mrow id="S3.E2.m1.3.3.3.3.3.4.2" xref="S3.E2.m1.3.3.3.3.3.cmml"><mo id="S3.E2.m1.3.3.3.3.3.4.2.1" stretchy="false" xref="S3.E2.m1.3.3.3.3.3.cmml">(</mo><mi id="S3.E2.m1.3.3.3.3.3.1" xref="S3.E2.m1.3.3.3.3.3.1.cmml">t</mi><mo id="S3.E2.m1.3.3.3.3.3.4.2.2" stretchy="false" xref="S3.E2.m1.3.3.3.3.3.cmml">)</mo></mrow></mrow></mfrac></msqrt></mrow></mrow><mo id="S3.E2.m1.5.5.1.1.2.2.2.2.3" xref="S3.E2.m1.5.5.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.5.5.1.2" xref="S3.E2.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.1.1.cmml" xref="S3.E2.m1.5.5.1"><eq id="S3.E2.m1.5.5.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.3"></eq><apply id="S3.E2.m1.5.5.1.1.4.cmml" xref="S3.E2.m1.5.5.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.1.1.4.1.cmml" xref="S3.E2.m1.5.5.1.1.4">subscript</csymbol><ci id="S3.E2.m1.5.5.1.1.4.2.cmml" xref="S3.E2.m1.5.5.1.1.4.2">ğ´</ci><ci id="S3.E2.m1.5.5.1.1.4.3.cmml" xref="S3.E2.m1.5.5.1.1.4.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.5.5.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2"><arg id="S3.E2.m1.5.5.1.1.2.3.cmml" xref="S3.E2.m1.5.5.1.1.2.3"></arg><apply id="S3.E2.m1.5.5.1.1.2.2.3.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2"><apply id="S3.E2.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1">subscript</csymbol><max id="S3.E2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.2"></max><apply id="S3.E2.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3"><in id="S3.E2.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.1"></in><ci id="S3.E2.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E2.m1.5.5.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1.3.3">ğ’œ</ci></apply></apply><apply id="S3.E2.m1.5.5.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1"><plus id="S3.E2.m1.5.5.1.1.2.2.2.2.1.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.1"></plus><apply id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2"><times id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.1"></times><apply id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2">subscript</csymbol><ci id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.2">ğ‘„</ci><ci id="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.3.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">ğ‘</ci></apply><apply id="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.3"><times id="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.1.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.1"></times><ci id="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.2.cmml" xref="S3.E2.m1.5.5.1.1.2.2.2.2.1.3.2">ğ›¼</ci><apply id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"><root id="S3.E2.m1.3.3a.cmml" xref="S3.E2.m1.3.3"></root><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3"><divide id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3"></divide><apply id="S3.E2.m1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.4"><ln id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"></ln><ci id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2">ğ‘¡</ci></apply><apply id="S3.E2.m1.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3.3"><times id="S3.E2.m1.3.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.3.3.3.2"></times><apply id="S3.E2.m1.3.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.3.3.3.1.cmml" xref="S3.E2.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S3.E2.m1.3.3.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.3.3.3.3.2">ğ‘</ci><ci id="S3.E2.m1.3.3.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3.3.3.3">ğ‘</ci></apply><ci id="S3.E2.m1.3.3.3.3.3.1.cmml" xref="S3.E2.m1.3.3.3.3.3.1">ğ‘¡</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">\vspace*{-0.5em}A_{t}=\arg\max_{a\in\mathcal{A}}\left(Q_{t}(a)+\alpha\sqrt{%
\frac{\ln(t)}{N_{a}(t)}}\right),</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.5d">italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_a âˆˆ caligraphic_A end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_a ) + italic_Î± square-root start_ARG divide start_ARG roman_ln ( italic_t ) end_ARG start_ARG italic_N start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_t ) end_ARG end_ARG ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p7.9">where <math alttext="A_{t}" class="ltx_Math" display="inline" id="S3.SS1.p7.1.m1.1"><semantics id="S3.SS1.p7.1.m1.1a"><msub id="S3.SS1.p7.1.m1.1.1" xref="S3.SS1.p7.1.m1.1.1.cmml"><mi id="S3.SS1.p7.1.m1.1.1.2" xref="S3.SS1.p7.1.m1.1.1.2.cmml">A</mi><mi id="S3.SS1.p7.1.m1.1.1.3" xref="S3.SS1.p7.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.1b"><apply id="S3.SS1.p7.1.m1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p7.1.m1.1.1.2.cmml" xref="S3.SS1.p7.1.m1.1.1.2">ğ´</ci><ci id="S3.SS1.p7.1.m1.1.1.3.cmml" xref="S3.SS1.p7.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.1c">A_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.1.m1.1d">italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the selected arm, <em class="ltx_emph ltx_font_italic" id="S3.SS1.p7.9.1">i.e.</em>, the selected hyper-parameter or its combination, at timestep <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p7.2.m2.1"><semantics id="S3.SS1.p7.2.m2.1a"><mi id="S3.SS1.p7.2.m2.1.1" xref="S3.SS1.p7.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.2.m2.1b"><ci id="S3.SS1.p7.2.m2.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.2.m2.1d">italic_t</annotation></semantics></math>, and <math alttext="Q_{t}(a)" class="ltx_Math" display="inline" id="S3.SS1.p7.3.m3.1"><semantics id="S3.SS1.p7.3.m3.1a"><mrow id="S3.SS1.p7.3.m3.1.2" xref="S3.SS1.p7.3.m3.1.2.cmml"><msub id="S3.SS1.p7.3.m3.1.2.2" xref="S3.SS1.p7.3.m3.1.2.2.cmml"><mi id="S3.SS1.p7.3.m3.1.2.2.2" xref="S3.SS1.p7.3.m3.1.2.2.2.cmml">Q</mi><mi id="S3.SS1.p7.3.m3.1.2.2.3" xref="S3.SS1.p7.3.m3.1.2.2.3.cmml">t</mi></msub><mo id="S3.SS1.p7.3.m3.1.2.1" xref="S3.SS1.p7.3.m3.1.2.1.cmml">â¢</mo><mrow id="S3.SS1.p7.3.m3.1.2.3.2" xref="S3.SS1.p7.3.m3.1.2.cmml"><mo id="S3.SS1.p7.3.m3.1.2.3.2.1" stretchy="false" xref="S3.SS1.p7.3.m3.1.2.cmml">(</mo><mi id="S3.SS1.p7.3.m3.1.1" xref="S3.SS1.p7.3.m3.1.1.cmml">a</mi><mo id="S3.SS1.p7.3.m3.1.2.3.2.2" stretchy="false" xref="S3.SS1.p7.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.3.m3.1b"><apply id="S3.SS1.p7.3.m3.1.2.cmml" xref="S3.SS1.p7.3.m3.1.2"><times id="S3.SS1.p7.3.m3.1.2.1.cmml" xref="S3.SS1.p7.3.m3.1.2.1"></times><apply id="S3.SS1.p7.3.m3.1.2.2.cmml" xref="S3.SS1.p7.3.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.1.2.2.1.cmml" xref="S3.SS1.p7.3.m3.1.2.2">subscript</csymbol><ci id="S3.SS1.p7.3.m3.1.2.2.2.cmml" xref="S3.SS1.p7.3.m3.1.2.2.2">ğ‘„</ci><ci id="S3.SS1.p7.3.m3.1.2.2.3.cmml" xref="S3.SS1.p7.3.m3.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.p7.3.m3.1.1.cmml" xref="S3.SS1.p7.3.m3.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.3.m3.1c">Q_{t}(a)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.3.m3.1d">italic_Q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_a )</annotation></semantics></math> is the estimated value of arm <math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p7.4.m4.1"><semantics id="S3.SS1.p7.4.m4.1a"><mi id="S3.SS1.p7.4.m4.1.1" xref="S3.SS1.p7.4.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.4.m4.1b"><ci id="S3.SS1.p7.4.m4.1.1.cmml" xref="S3.SS1.p7.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.4.m4.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.4.m4.1d">italic_a</annotation></semantics></math> at <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p7.5.m5.1"><semantics id="S3.SS1.p7.5.m5.1a"><mi id="S3.SS1.p7.5.m5.1.1" xref="S3.SS1.p7.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.5.m5.1b"><ci id="S3.SS1.p7.5.m5.1.1.cmml" xref="S3.SS1.p7.5.m5.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.5.m5.1d">italic_t</annotation></semantics></math>. The square-root term quantifies the uncertainty. <math alttext="N_{a}(t)" class="ltx_Math" display="inline" id="S3.SS1.p7.6.m6.1"><semantics id="S3.SS1.p7.6.m6.1a"><mrow id="S3.SS1.p7.6.m6.1.2" xref="S3.SS1.p7.6.m6.1.2.cmml"><msub id="S3.SS1.p7.6.m6.1.2.2" xref="S3.SS1.p7.6.m6.1.2.2.cmml"><mi id="S3.SS1.p7.6.m6.1.2.2.2" xref="S3.SS1.p7.6.m6.1.2.2.2.cmml">N</mi><mi id="S3.SS1.p7.6.m6.1.2.2.3" xref="S3.SS1.p7.6.m6.1.2.2.3.cmml">a</mi></msub><mo id="S3.SS1.p7.6.m6.1.2.1" xref="S3.SS1.p7.6.m6.1.2.1.cmml">â¢</mo><mrow id="S3.SS1.p7.6.m6.1.2.3.2" xref="S3.SS1.p7.6.m6.1.2.cmml"><mo id="S3.SS1.p7.6.m6.1.2.3.2.1" stretchy="false" xref="S3.SS1.p7.6.m6.1.2.cmml">(</mo><mi id="S3.SS1.p7.6.m6.1.1" xref="S3.SS1.p7.6.m6.1.1.cmml">t</mi><mo id="S3.SS1.p7.6.m6.1.2.3.2.2" stretchy="false" xref="S3.SS1.p7.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.6.m6.1b"><apply id="S3.SS1.p7.6.m6.1.2.cmml" xref="S3.SS1.p7.6.m6.1.2"><times id="S3.SS1.p7.6.m6.1.2.1.cmml" xref="S3.SS1.p7.6.m6.1.2.1"></times><apply id="S3.SS1.p7.6.m6.1.2.2.cmml" xref="S3.SS1.p7.6.m6.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p7.6.m6.1.2.2.1.cmml" xref="S3.SS1.p7.6.m6.1.2.2">subscript</csymbol><ci id="S3.SS1.p7.6.m6.1.2.2.2.cmml" xref="S3.SS1.p7.6.m6.1.2.2.2">ğ‘</ci><ci id="S3.SS1.p7.6.m6.1.2.2.3.cmml" xref="S3.SS1.p7.6.m6.1.2.2.3">ğ‘</ci></apply><ci id="S3.SS1.p7.6.m6.1.1.cmml" xref="S3.SS1.p7.6.m6.1.1">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.6.m6.1c">N_{a}(t)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.6.m6.1d">italic_N start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_t )</annotation></semantics></math> represents the number of times arm <math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p7.7.m7.1"><semantics id="S3.SS1.p7.7.m7.1a"><mi id="S3.SS1.p7.7.m7.1.1" xref="S3.SS1.p7.7.m7.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.7.m7.1b"><ci id="S3.SS1.p7.7.m7.1.1.cmml" xref="S3.SS1.p7.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.7.m7.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.7.m7.1d">italic_a</annotation></semantics></math> has been selected, and <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p7.8.m8.1"><semantics id="S3.SS1.p7.8.m8.1a"><mi id="S3.SS1.p7.8.m8.1.1" xref="S3.SS1.p7.8.m8.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.8.m8.1b"><ci id="S3.SS1.p7.8.m8.1.1.cmml" xref="S3.SS1.p7.8.m8.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.8.m8.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.8.m8.1d">italic_Î±</annotation></semantics></math> is the hyper-parameter adjusting the balance between exploration and exploitation. During the iteration, both <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.p7.9.m9.1"><semantics id="S3.SS1.p7.9.m9.1a"><mi id="S3.SS1.p7.9.m9.1.1" xref="S3.SS1.p7.9.m9.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.9.m9.1b"><ci id="S3.SS1.p7.9.m9.1.1.cmml" xref="S3.SS1.p7.9.m9.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.9.m9.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.9.m9.1d">italic_Q</annotation></semantics></math> and the upper confidence bound (the square-root term) for each arm are updated to guide the selection of arms.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">Thompson Sampling (TS)Â <cite class="ltx_cite ltx_citemacro_cite">Chapelle and Li (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib9" title="">2011</a>)</cite> is another popular optimization algorithm in MAB. It balances exploration and exploitation by sampling from the posterior distribution of each armâ€™s reward.
Arms are chosen based on the highest sampled reward.</p>
</div>
<div class="ltx_para" id="S3.SS1.p9">
<p class="ltx_p" id="S3.SS1.p9.1">In summary, the objective of MAB is to maximize the total reward over a series of selections, even when the probability distribution of rewards for each arm is unknown. After a number of trials, the arm with the highest cumulative reward becomes the desired RAG hyper-parameter. This approach is particularly suitable for cold start problems, where prior estimation of user data is unavailable, and leveraging the MAB framework enables rapid tuning of hyper-parameters in RAG.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Two-level Hierarchical MAB</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Applying the above standard formulation of MAB to hyper-parameter tuning in RAG can lead to the issue of having too many arms when jointly optimizing several hyper-parameters, resulting in an excessively large search space since it requires flattening the search space to obtain discrete arms. To mitigate this issue, we propose a two-level hierarchical MAB (Hier-MAB) where we first select which hyper-parameter to tune and then select one of its possible values.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="795" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An example of two-level hierarchical MAB.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.3">In FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.F2" title="Figure 2 â€£ 3.2 Two-level Hierarchical MAB â€£ 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>, we show an example of two-level Hier-MAB in the context of jointly tuning of top-k (<math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">caligraphic_K</annotation></semantics></math>), embedding model (<math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">caligraphic_E</annotation></semantics></math>), and compression ratio (<math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">caligraphic_C</annotation></semantics></math>) hyper-parameters. The high-level arm is responsible for selecting which hyper-parameter to tune, while the lower-level arms control the hyper-parameter selection within the search space of each hyper-parameter. Thus, instead of having a single MAB, we now have four MABs: one for the high-level arm selection and the other three for the individual hyper-parameters. This hierarchical structure ensures that each MAB has a reasonable number of arms to select from, while all MABs combined can cover a large search space. This contrasts with the single MAB approach, which needs to enumerate all possible combinations when tuning multiple hyper-parameters.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">The optimization process of Hier-MAB can be demonstrated by the trial shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.F2" title="Figure 2 â€£ 3.2 Two-level Hierarchical MAB â€£ 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>. A high-level arm (top-k) is pulled, and within this hyper-parameter, the <math alttext="\mathcal{K}=3" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">ğ’¦</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><eq id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></eq><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ’¦</ci><cn id="S3.SS2.p3.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathcal{K}=3</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">caligraphic_K = 3</annotation></semantics></math> arm is pulled (with other hyper-parameters remaining the same as in the previous trial). After pulling the two-level arms and observing the associated reward, the algorithm updates its estimate of the selected armâ€™s reward distribution using the new information, <em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.1.1">i.e.</em>, updating the mean reward estimation and the confidence interval based on the observed reward. For the example in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.F2" title="Figure 2 â€£ 3.2 Two-level Hierarchical MAB â€£ 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>, the positive reward updates the reward distribution of the pulled arms to reflect a higher estimated reward. Meanwhile, the reward distributions of other high- and low-level arms pulled in previous iterations also get updated. This process repeats for a predetermined number of iterations or until a stopping criterion is met.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Setup</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Dataset</span> We utilize the ALCE-ASQAÂ <cite class="ltx_cite ltx_citemacro_cite">Gao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib12" title="">2023</a>)</cite> and Natural Questions (NQ) datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">Kwiatkowski etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib19" title="">2019</a>)</cite> for our experiments. Both datasets are in QA format and include candidate document chunks for each question. We use their evaluators to assess the accuracy of generated responses. To ensure LLMs do not have prior knowledge of the benchmark questions, we exclude questions that can be answered correctly without context (<em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.2">i.e.</em>, zero-shot). From the remaining questions, we take 350 questions from each benchmark as our experiment datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Base LLMs</span> We adopt GPT3.5-Turbo and GPT-4 models as base LLMs. Although the API parameters are tunableÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib39" title="">2023a</a>)</cite>, we opt to fix them by setting the temperature to zero and using default settings for all other parameters.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.3.1">Search Space</span> We examine the RAG setting as demonstrated in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.F1" title="Figure 1 â€£ 3.1 Problem Formulation â€£ 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>. In the retrieval module, we evaluate the effects of the top-k hyper-parameter (<math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">caligraphic_K</annotation></semantics></math>) and the embedding model (<math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">caligraphic_E</annotation></semantics></math>) by considering three different choices, <em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.3.2">i.e.</em>, â€œmpnetâ€ <cite class="ltx_cite ltx_citemacro_cite">Song etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib35" title="">2020</a>)</cite>, â€œada_002â€ <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib29" title="">2022</a>)</cite>, and â€œcontrieverâ€ <cite class="ltx_cite ltx_citemacro_cite">Izacard etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib14" title="">2021</a>)</cite>. The compression module is implemented using the method outlined in the LLMLingua-2 workÂ <cite class="ltx_cite ltx_citemacro_cite">Pan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib32" title="">2024</a>)</cite>, with the compression ratio denoted as <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">caligraphic_C</annotation></semantics></math>. Specifically, we consider two optimization tasks based on the number of hyper-parameters:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.3">Joint optimization of <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.I1.i1.p1.1.m1.2"><semantics id="S4.I1.i1.p1.1.m1.2a"><mrow id="S4.I1.i1.p1.1.m1.2.3.2" xref="S4.I1.i1.p1.1.m1.2.3.1.cmml"><mo id="S4.I1.i1.p1.1.m1.2.3.2.1" stretchy="false" xref="S4.I1.i1.p1.1.m1.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.I1.i1.p1.1.m1.2.3.2.2" xref="S4.I1.i1.p1.1.m1.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I1.i1.p1.1.m1.2.2" xref="S4.I1.i1.p1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.I1.i1.p1.1.m1.2.3.2.3" stretchy="false" xref="S4.I1.i1.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.2b"><interval closure="open" id="S4.I1.i1.p1.1.m1.2.3.1.cmml" xref="S4.I1.i1.p1.1.m1.2.3.2"><ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">ğ’¦</ci><ci id="S4.I1.i1.p1.1.m1.2.2.cmml" xref="S4.I1.i1.p1.1.m1.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i1.p1.1.m1.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math>: They take discrete values from <math alttext="\mathcal{K}\in[1,3,5,7,9]" class="ltx_Math" display="inline" id="S4.I1.i1.p1.2.m2.5"><semantics id="S4.I1.i1.p1.2.m2.5a"><mrow id="S4.I1.i1.p1.2.m2.5.6" xref="S4.I1.i1.p1.2.m2.5.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i1.p1.2.m2.5.6.2" xref="S4.I1.i1.p1.2.m2.5.6.2.cmml">ğ’¦</mi><mo id="S4.I1.i1.p1.2.m2.5.6.1" xref="S4.I1.i1.p1.2.m2.5.6.1.cmml">âˆˆ</mo><mrow id="S4.I1.i1.p1.2.m2.5.6.3.2" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml"><mo id="S4.I1.i1.p1.2.m2.5.6.3.2.1" stretchy="false" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml">[</mo><mn id="S4.I1.i1.p1.2.m2.1.1" xref="S4.I1.i1.p1.2.m2.1.1.cmml">1</mn><mo id="S4.I1.i1.p1.2.m2.5.6.3.2.2" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.2.m2.2.2" xref="S4.I1.i1.p1.2.m2.2.2.cmml">3</mn><mo id="S4.I1.i1.p1.2.m2.5.6.3.2.3" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.2.m2.3.3" xref="S4.I1.i1.p1.2.m2.3.3.cmml">5</mn><mo id="S4.I1.i1.p1.2.m2.5.6.3.2.4" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.2.m2.4.4" xref="S4.I1.i1.p1.2.m2.4.4.cmml">7</mn><mo id="S4.I1.i1.p1.2.m2.5.6.3.2.5" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.2.m2.5.5" xref="S4.I1.i1.p1.2.m2.5.5.cmml">9</mn><mo id="S4.I1.i1.p1.2.m2.5.6.3.2.6" stretchy="false" xref="S4.I1.i1.p1.2.m2.5.6.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.m2.5b"><apply id="S4.I1.i1.p1.2.m2.5.6.cmml" xref="S4.I1.i1.p1.2.m2.5.6"><in id="S4.I1.i1.p1.2.m2.5.6.1.cmml" xref="S4.I1.i1.p1.2.m2.5.6.1"></in><ci id="S4.I1.i1.p1.2.m2.5.6.2.cmml" xref="S4.I1.i1.p1.2.m2.5.6.2">ğ’¦</ci><list id="S4.I1.i1.p1.2.m2.5.6.3.1.cmml" xref="S4.I1.i1.p1.2.m2.5.6.3.2"><cn id="S4.I1.i1.p1.2.m2.1.1.cmml" type="integer" xref="S4.I1.i1.p1.2.m2.1.1">1</cn><cn id="S4.I1.i1.p1.2.m2.2.2.cmml" type="integer" xref="S4.I1.i1.p1.2.m2.2.2">3</cn><cn id="S4.I1.i1.p1.2.m2.3.3.cmml" type="integer" xref="S4.I1.i1.p1.2.m2.3.3">5</cn><cn id="S4.I1.i1.p1.2.m2.4.4.cmml" type="integer" xref="S4.I1.i1.p1.2.m2.4.4">7</cn><cn id="S4.I1.i1.p1.2.m2.5.5.cmml" type="integer" xref="S4.I1.i1.p1.2.m2.5.5">9</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.m2.5c">\mathcal{K}\in[1,3,5,7,9]</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i1.p1.2.m2.5d">caligraphic_K âˆˆ [ 1 , 3 , 5 , 7 , 9 ]</annotation></semantics></math> and <math alttext="\mathcal{C}\in[0.3,0.5,0.7,0.9,1]" class="ltx_Math" display="inline" id="S4.I1.i1.p1.3.m3.5"><semantics id="S4.I1.i1.p1.3.m3.5a"><mrow id="S4.I1.i1.p1.3.m3.5.6" xref="S4.I1.i1.p1.3.m3.5.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i1.p1.3.m3.5.6.2" xref="S4.I1.i1.p1.3.m3.5.6.2.cmml">ğ’</mi><mo id="S4.I1.i1.p1.3.m3.5.6.1" xref="S4.I1.i1.p1.3.m3.5.6.1.cmml">âˆˆ</mo><mrow id="S4.I1.i1.p1.3.m3.5.6.3.2" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml"><mo id="S4.I1.i1.p1.3.m3.5.6.3.2.1" stretchy="false" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml">[</mo><mn id="S4.I1.i1.p1.3.m3.1.1" xref="S4.I1.i1.p1.3.m3.1.1.cmml">0.3</mn><mo id="S4.I1.i1.p1.3.m3.5.6.3.2.2" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.3.m3.2.2" xref="S4.I1.i1.p1.3.m3.2.2.cmml">0.5</mn><mo id="S4.I1.i1.p1.3.m3.5.6.3.2.3" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.3.m3.3.3" xref="S4.I1.i1.p1.3.m3.3.3.cmml">0.7</mn><mo id="S4.I1.i1.p1.3.m3.5.6.3.2.4" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.3.m3.4.4" xref="S4.I1.i1.p1.3.m3.4.4.cmml">0.9</mn><mo id="S4.I1.i1.p1.3.m3.5.6.3.2.5" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml">,</mo><mn id="S4.I1.i1.p1.3.m3.5.5" xref="S4.I1.i1.p1.3.m3.5.5.cmml">1</mn><mo id="S4.I1.i1.p1.3.m3.5.6.3.2.6" stretchy="false" xref="S4.I1.i1.p1.3.m3.5.6.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.3.m3.5b"><apply id="S4.I1.i1.p1.3.m3.5.6.cmml" xref="S4.I1.i1.p1.3.m3.5.6"><in id="S4.I1.i1.p1.3.m3.5.6.1.cmml" xref="S4.I1.i1.p1.3.m3.5.6.1"></in><ci id="S4.I1.i1.p1.3.m3.5.6.2.cmml" xref="S4.I1.i1.p1.3.m3.5.6.2">ğ’</ci><list id="S4.I1.i1.p1.3.m3.5.6.3.1.cmml" xref="S4.I1.i1.p1.3.m3.5.6.3.2"><cn id="S4.I1.i1.p1.3.m3.1.1.cmml" type="float" xref="S4.I1.i1.p1.3.m3.1.1">0.3</cn><cn id="S4.I1.i1.p1.3.m3.2.2.cmml" type="float" xref="S4.I1.i1.p1.3.m3.2.2">0.5</cn><cn id="S4.I1.i1.p1.3.m3.3.3.cmml" type="float" xref="S4.I1.i1.p1.3.m3.3.3">0.7</cn><cn id="S4.I1.i1.p1.3.m3.4.4.cmml" type="float" xref="S4.I1.i1.p1.3.m3.4.4">0.9</cn><cn id="S4.I1.i1.p1.3.m3.5.5.cmml" type="integer" xref="S4.I1.i1.p1.3.m3.5.5">1</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.3.m3.5c">\mathcal{C}\in[0.3,0.5,0.7,0.9,1]</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i1.p1.3.m3.5d">caligraphic_C âˆˆ [ 0.3 , 0.5 , 0.7 , 0.9 , 1 ]</annotation></semantics></math> while the embedding model is fixed to â€œmpnetâ€.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.3">Joint optimization of <math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.I1.i2.p1.1.m1.3"><semantics id="S4.I1.i2.p1.1.m1.3a"><mrow id="S4.I1.i2.p1.1.m1.3.4.2" xref="S4.I1.i2.p1.1.m1.3.4.1.cmml"><mo id="S4.I1.i2.p1.1.m1.3.4.2.1" stretchy="false" xref="S4.I1.i2.p1.1.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.I1.i2.p1.1.m1.3.4.2.2" xref="S4.I1.i2.p1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I1.i2.p1.1.m1.2.2" xref="S4.I1.i2.p1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.I1.i2.p1.1.m1.3.4.2.3" xref="S4.I1.i2.p1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I1.i2.p1.1.m1.3.3" xref="S4.I1.i2.p1.1.m1.3.3.cmml">â„°</mi><mo id="S4.I1.i2.p1.1.m1.3.4.2.4" stretchy="false" xref="S4.I1.i2.p1.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.3b"><vector id="S4.I1.i2.p1.1.m1.3.4.1.cmml" xref="S4.I1.i2.p1.1.m1.3.4.2"><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">ğ’¦</ci><ci id="S4.I1.i2.p1.1.m1.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2">ğ’</ci><ci id="S4.I1.i2.p1.1.m1.3.3.cmml" xref="S4.I1.i2.p1.1.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.3c">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.1.m1.3d">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math>: We allow the embedding model to be tuned from the list of [â€œmpnetâ€, â€œada_002â€, â€œcontrieverâ€], maintaining the same settings for <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S4.I1.i2.p1.2.m2.1"><semantics id="S4.I1.i2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i2.p1.2.m2.1.1" xref="S4.I1.i2.p1.2.m2.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.1b"><ci id="S4.I1.i2.p1.2.m2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.2.m2.1d">caligraphic_K</annotation></semantics></math> and <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S4.I1.i2.p1.3.m3.1"><semantics id="S4.I1.i2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i2.p1.3.m3.1.1" xref="S4.I1.i2.p1.3.m3.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.3.m3.1b"><ci id="S4.I1.i2.p1.3.m3.1.1.cmml" xref="S4.I1.i2.p1.3.m3.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.3.m3.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.3.m3.1d">caligraphic_C</annotation></semantics></math> as in the two-parameter case.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.4"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.4.1">Reward Setting</span> As outlined in the Methodology section, we introduce the weight parameter <math alttext="w" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">italic_w</annotation></semantics></math> to balance the tradeoff between token length and accuracy. Our experiments evaluate three values of <math alttext="w" class="ltx_Math" display="inline" id="S4.SS1.p4.2.m2.1"><semantics id="S4.SS1.p4.2.m2.1a"><mi id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">w</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.2.m2.1d">italic_w</annotation></semantics></math>= 0.1, 0.5, and 0.9, corresponding to â€œcost-centralâ€, â€œbalanceâ€, and â€œaccuracy-centralâ€ regimes, respectively. The maximal token length <math alttext="t_{max}" class="ltx_Math" display="inline" id="S4.SS1.p4.3.m3.1"><semantics id="S4.SS1.p4.3.m3.1a"><msub id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml"><mi id="S4.SS1.p4.3.m3.1.1.2" xref="S4.SS1.p4.3.m3.1.1.2.cmml">t</mi><mrow id="S4.SS1.p4.3.m3.1.1.3" xref="S4.SS1.p4.3.m3.1.1.3.cmml"><mi id="S4.SS1.p4.3.m3.1.1.3.2" xref="S4.SS1.p4.3.m3.1.1.3.2.cmml">m</mi><mo id="S4.SS1.p4.3.m3.1.1.3.1" xref="S4.SS1.p4.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS1.p4.3.m3.1.1.3.3" xref="S4.SS1.p4.3.m3.1.1.3.3.cmml">a</mi><mo id="S4.SS1.p4.3.m3.1.1.3.1a" xref="S4.SS1.p4.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS1.p4.3.m3.1.1.3.4" xref="S4.SS1.p4.3.m3.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><apply id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.p4.3.m3.1.1.2">ğ‘¡</ci><apply id="S4.SS1.p4.3.m3.1.1.3.cmml" xref="S4.SS1.p4.3.m3.1.1.3"><times id="S4.SS1.p4.3.m3.1.1.3.1.cmml" xref="S4.SS1.p4.3.m3.1.1.3.1"></times><ci id="S4.SS1.p4.3.m3.1.1.3.2.cmml" xref="S4.SS1.p4.3.m3.1.1.3.2">ğ‘š</ci><ci id="S4.SS1.p4.3.m3.1.1.3.3.cmml" xref="S4.SS1.p4.3.m3.1.1.3.3">ğ‘</ci><ci id="S4.SS1.p4.3.m3.1.1.3.4.cmml" xref="S4.SS1.p4.3.m3.1.1.3.4">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">t_{max}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.3.m3.1d">italic_t start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT</annotation></semantics></math> is set to be 1585 (2205) for ASQA (NQ) dataset.
For better fit with MAB, we impose penalty for inaccurate response, <em class="ltx_emph ltx_font_italic" id="S4.SS1.p4.4.2">i.e.</em>, setting the accuracy <math alttext="acc" class="ltx_Math" display="inline" id="S4.SS1.p4.4.m4.1"><semantics id="S4.SS1.p4.4.m4.1a"><mrow id="S4.SS1.p4.4.m4.1.1" xref="S4.SS1.p4.4.m4.1.1.cmml"><mi id="S4.SS1.p4.4.m4.1.1.2" xref="S4.SS1.p4.4.m4.1.1.2.cmml">a</mi><mo id="S4.SS1.p4.4.m4.1.1.1" xref="S4.SS1.p4.4.m4.1.1.1.cmml">â¢</mo><mi id="S4.SS1.p4.4.m4.1.1.3" xref="S4.SS1.p4.4.m4.1.1.3.cmml">c</mi><mo id="S4.SS1.p4.4.m4.1.1.1a" xref="S4.SS1.p4.4.m4.1.1.1.cmml">â¢</mo><mi id="S4.SS1.p4.4.m4.1.1.4" xref="S4.SS1.p4.4.m4.1.1.4.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.4.m4.1b"><apply id="S4.SS1.p4.4.m4.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1"><times id="S4.SS1.p4.4.m4.1.1.1.cmml" xref="S4.SS1.p4.4.m4.1.1.1"></times><ci id="S4.SS1.p4.4.m4.1.1.2.cmml" xref="S4.SS1.p4.4.m4.1.1.2">ğ‘</ci><ci id="S4.SS1.p4.4.m4.1.1.3.cmml" xref="S4.SS1.p4.4.m4.1.1.3">ğ‘</ci><ci id="S4.SS1.p4.4.m4.1.1.4.cmml" xref="S4.SS1.p4.4.m4.1.1.4">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.4.m4.1c">acc</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.4.m4.1d">italic_a italic_c italic_c</annotation></semantics></math> to be -1.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.4"><span class="ltx_text ltx_font_bold" id="S4.SS1.p5.4.1">Hier-MAB Setting</span> We adopt UCB as the optimization algorithm for each arm selection in Hier-MAB, naming the approach as <span class="ltx_text ltx_font_bold" id="S4.SS1.p5.4.2">Hier-UCB</span>. The parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS1.p5.1.m1.1"><semantics id="S4.SS1.p5.1.m1.1a"><mi id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><ci id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.1.m1.1d">italic_Î±</annotation></semantics></math> for high-level and low-level arm selection with UCB are denoted as <math alttext="\alpha^{h}" class="ltx_Math" display="inline" id="S4.SS1.p5.2.m2.1"><semantics id="S4.SS1.p5.2.m2.1a"><msup id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml"><mi id="S4.SS1.p5.2.m2.1.1.2" xref="S4.SS1.p5.2.m2.1.1.2.cmml">Î±</mi><mi id="S4.SS1.p5.2.m2.1.1.3" xref="S4.SS1.p5.2.m2.1.1.3.cmml">h</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><apply id="S4.SS1.p5.2.m2.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p5.2.m2.1.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p5.2.m2.1.1.2.cmml" xref="S4.SS1.p5.2.m2.1.1.2">ğ›¼</ci><ci id="S4.SS1.p5.2.m2.1.1.3.cmml" xref="S4.SS1.p5.2.m2.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">\alpha^{h}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.2.m2.1d">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\alpha^{l}" class="ltx_Math" display="inline" id="S4.SS1.p5.3.m3.1"><semantics id="S4.SS1.p5.3.m3.1a"><msup id="S4.SS1.p5.3.m3.1.1" xref="S4.SS1.p5.3.m3.1.1.cmml"><mi id="S4.SS1.p5.3.m3.1.1.2" xref="S4.SS1.p5.3.m3.1.1.2.cmml">Î±</mi><mi id="S4.SS1.p5.3.m3.1.1.3" xref="S4.SS1.p5.3.m3.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.3.m3.1b"><apply id="S4.SS1.p5.3.m3.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p5.3.m3.1.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1">superscript</csymbol><ci id="S4.SS1.p5.3.m3.1.1.2.cmml" xref="S4.SS1.p5.3.m3.1.1.2">ğ›¼</ci><ci id="S4.SS1.p5.3.m3.1.1.3.cmml" xref="S4.SS1.p5.3.m3.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.3.m3.1c">\alpha^{l}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.3.m3.1d">italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math>, respectively, and are fixed at 1. To reduce sample variance during optimization, we use a batch size of <math alttext="B=4" class="ltx_Math" display="inline" id="S4.SS1.p5.4.m4.1"><semantics id="S4.SS1.p5.4.m4.1a"><mrow id="S4.SS1.p5.4.m4.1.1" xref="S4.SS1.p5.4.m4.1.1.cmml"><mi id="S4.SS1.p5.4.m4.1.1.2" xref="S4.SS1.p5.4.m4.1.1.2.cmml">B</mi><mo id="S4.SS1.p5.4.m4.1.1.1" xref="S4.SS1.p5.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.p5.4.m4.1.1.3" xref="S4.SS1.p5.4.m4.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.4.m4.1b"><apply id="S4.SS1.p5.4.m4.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1"><eq id="S4.SS1.p5.4.m4.1.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1.1"></eq><ci id="S4.SS1.p5.4.m4.1.1.2.cmml" xref="S4.SS1.p5.4.m4.1.1.2">ğµ</ci><cn id="S4.SS1.p5.4.m4.1.1.3.cmml" type="integer" xref="S4.SS1.p5.4.m4.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.4.m4.1c">B=4</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p5.4.m4.1d">italic_B = 4</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p6.1.1">Baseline Methods</span> To compare with the proposed Hier-UCB approach, we evaluate three other online learning methods as follows:</p>
</div>
<div class="ltx_para" id="S4.SS1.p7">
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">UCB</span>Â <cite class="ltx_cite ltx_citemacro_cite">Auer (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib2" title="">2002</a>)</cite>: In this standard form, the search space is flattened out and a single UCB-based MAB is used for optimal hyper-parameter search. For consistency, <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.I2.i1.p1.1.m1.1"><semantics id="S4.I2.i1.p1.1.m1.1a"><mi id="S4.I2.i1.p1.1.m1.1.1" xref="S4.I2.i1.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.1.m1.1b"><ci id="S4.I2.i1.p1.1.m1.1.1.cmml" xref="S4.I2.i1.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.I2.i1.p1.1.m1.1d">italic_Î±</annotation></semantics></math> is also set to 1.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Thompson Sampling</span>Â <cite class="ltx_cite ltx_citemacro_cite">Agrawal and Goyal (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib1" title="">2013</a>)</cite>: TS samples arms from the posterior distribution of armsâ€™ rewards, with no pre-determined parameters.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">Random Search</span>Â <cite class="ltx_cite ltx_citemacro_cite">Bergstra and Bengio (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib7" title="">2012b</a>)</cite>: This baseline selects arms uniformly at random, ensuring even exploration but without leveraging past rewards for guidance.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p8.1.1">Ground-Truth and Evaluation Metric</span> The ground-truth parameter combinations are determined using the <span class="ltx_text ltx_font_bold" id="S4.SS1.p8.1.2">Grid Search</span> method <cite class="ltx_cite ltx_citemacro_cite">Lecun etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#bib.bib21" title="">1998</a>)</cite>, which exhaustively evaluates all hyper-parameter combinations on the entire dataset. Grid Search serves as an offline benchmark against which the online learning methods are evaluated.</p>
</div>
<div class="ltx_para" id="S4.SS1.p9">
<p class="ltx_p" id="S4.SS1.p9.8">For the evaluation metric at a given timestamp <math alttext="t" class="ltx_Math" display="inline" id="S4.SS1.p9.1.m1.1"><semantics id="S4.SS1.p9.1.m1.1a"><mi id="S4.SS1.p9.1.m1.1.1" xref="S4.SS1.p9.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.1.m1.1b"><ci id="S4.SS1.p9.1.m1.1.1.cmml" xref="S4.SS1.p9.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.1.m1.1d">italic_t</annotation></semantics></math>, we identify the top <math alttext="x" class="ltx_Math" display="inline" id="S4.SS1.p9.2.m2.1"><semantics id="S4.SS1.p9.2.m2.1a"><mi id="S4.SS1.p9.2.m2.1.1" xref="S4.SS1.p9.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.2.m2.1b"><ci id="S4.SS1.p9.2.m2.1.1.cmml" xref="S4.SS1.p9.2.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.2.m2.1d">italic_x</annotation></semantics></math> hyper-parameter combinations from the evaluation method and calculate the percentage of these combinations that match the top <math alttext="x" class="ltx_Math" display="inline" id="S4.SS1.p9.3.m3.1"><semantics id="S4.SS1.p9.3.m3.1a"><mi id="S4.SS1.p9.3.m3.1.1" xref="S4.SS1.p9.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.3.m3.1b"><ci id="S4.SS1.p9.3.m3.1.1.cmml" xref="S4.SS1.p9.3.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.3.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.3.m3.1d">italic_x</annotation></semantics></math> hyper-parameter combinations identified by Grid Search. Similar to metrics used in recommendation systems, we refer to this metric as <span class="ltx_text ltx_font_bold" id="S4.SS1.p9.8.1">Recall</span>@x. Specifically, Recall@3 is used for the evaluation of the optimization of (<math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S4.SS1.p9.4.m4.1"><semantics id="S4.SS1.p9.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p9.4.m4.1.1" xref="S4.SS1.p9.4.m4.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.4.m4.1b"><ci id="S4.SS1.p9.4.m4.1.1.cmml" xref="S4.SS1.p9.4.m4.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.4.m4.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.4.m4.1d">caligraphic_K</annotation></semantics></math>, <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S4.SS1.p9.5.m5.1"><semantics id="S4.SS1.p9.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p9.5.m5.1.1" xref="S4.SS1.p9.5.m5.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.5.m5.1b"><ci id="S4.SS1.p9.5.m5.1.1.cmml" xref="S4.SS1.p9.5.m5.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.5.m5.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.5.m5.1d">caligraphic_C</annotation></semantics></math>) and Recall@5 is used for the (<math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S4.SS1.p9.6.m6.1"><semantics id="S4.SS1.p9.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p9.6.m6.1.1" xref="S4.SS1.p9.6.m6.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.6.m6.1b"><ci id="S4.SS1.p9.6.m6.1.1.cmml" xref="S4.SS1.p9.6.m6.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.6.m6.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.6.m6.1d">caligraphic_K</annotation></semantics></math>, <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S4.SS1.p9.7.m7.1"><semantics id="S4.SS1.p9.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p9.7.m7.1.1" xref="S4.SS1.p9.7.m7.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.7.m7.1b"><ci id="S4.SS1.p9.7.m7.1.1.cmml" xref="S4.SS1.p9.7.m7.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.7.m7.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.7.m7.1d">caligraphic_C</annotation></semantics></math>, <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.SS1.p9.8.m8.1"><semantics id="S4.SS1.p9.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p9.8.m8.1.1" xref="S4.SS1.p9.8.m8.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.8.m8.1b"><ci id="S4.SS1.p9.8.m8.1.1.cmml" xref="S4.SS1.p9.8.m8.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.8.m8.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.8.m8.1d">caligraphic_E</annotation></semantics></math>) case.
To mitigate statistical fluctuations, we conduct each experiment setting 10 times with different random seeds.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experiment Result</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Due to space constraints, we mainly present the experimental results for GPT-4 and leave the results for GPT-3.5-Turbo in the Appendix B. The following observations are similar for both cases.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Before diving into the evaluation results of various optimization methods, we first discuss the complexity of each optimization task.To illustrate this, we show the Grid Search results for ASQA dataset in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F3" title="Figure 3 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a>, presenting the accuracy and reward values across different weight settings for all three hyper-parameter combinations in search space. To show the sample variance during online learning, we plot the standard deviations of the accuracy and reward values across all batches as error bars.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="997" id="S4.F3.g1" src="extracted/5694705/figures/gt_asqa_4.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Grid search results for ASQA with GPT-4. Error bars represent the standard deviations of accuracy and reward values across all batches.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">By inspecting FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F3" title="Figure 3 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a> and the other Grid Search results in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A1.F11" title="Figure 11 â€£ Appendix A Grid Search Results â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">11</span></a> (shown in Appendix) for the NQ dataset, we make the following observations:</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1">The top-k and compression ratio have prominent impact on the response accuracy, while the effect of embedding model is more evident in ASQA as compared to NQ. This highlights the necessity of tuning those hyper-parameters, especially for the â€œaccuracy-centralâ€ scenario (<em class="ltx_emph ltx_font_italic" id="S4.I3.i1.p1.1.1">i.e.</em>, <math alttext="w=0.9" class="ltx_Math" display="inline" id="S4.I3.i1.p1.1.m1.1"><semantics id="S4.I3.i1.p1.1.m1.1a"><mrow id="S4.I3.i1.p1.1.m1.1.1" xref="S4.I3.i1.p1.1.m1.1.1.cmml"><mi id="S4.I3.i1.p1.1.m1.1.1.2" xref="S4.I3.i1.p1.1.m1.1.1.2.cmml">w</mi><mo id="S4.I3.i1.p1.1.m1.1.1.1" xref="S4.I3.i1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.I3.i1.p1.1.m1.1.1.3" xref="S4.I3.i1.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.1.m1.1b"><apply id="S4.I3.i1.p1.1.m1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1"><eq id="S4.I3.i1.p1.1.m1.1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1.1"></eq><ci id="S4.I3.i1.p1.1.m1.1.1.2.cmml" xref="S4.I3.i1.p1.1.m1.1.1.2">ğ‘¤</ci><cn id="S4.I3.i1.p1.1.m1.1.1.3.cmml" type="float" xref="S4.I3.i1.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.1.m1.1c">w=0.9</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i1.p1.1.m1.1d">italic_w = 0.9</annotation></semantics></math>).</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.6">By factoring in more weights for token length, the overall landscape of reward function changes. For the â€œcost-centralâ€ scenario (<math alttext="w=0.1" class="ltx_Math" display="inline" id="S4.I3.i2.p1.1.m1.1"><semantics id="S4.I3.i2.p1.1.m1.1a"><mrow id="S4.I3.i2.p1.1.m1.1.1" xref="S4.I3.i2.p1.1.m1.1.1.cmml"><mi id="S4.I3.i2.p1.1.m1.1.1.2" xref="S4.I3.i2.p1.1.m1.1.1.2.cmml">w</mi><mo id="S4.I3.i2.p1.1.m1.1.1.1" xref="S4.I3.i2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.I3.i2.p1.1.m1.1.1.3" xref="S4.I3.i2.p1.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.1.m1.1b"><apply id="S4.I3.i2.p1.1.m1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1"><eq id="S4.I3.i2.p1.1.m1.1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1.1"></eq><ci id="S4.I3.i2.p1.1.m1.1.1.2.cmml" xref="S4.I3.i2.p1.1.m1.1.1.2">ğ‘¤</ci><cn id="S4.I3.i2.p1.1.m1.1.1.3.cmml" type="float" xref="S4.I3.i2.p1.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.1.m1.1c">w=0.1</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i2.p1.1.m1.1d">italic_w = 0.1</annotation></semantics></math>), the preferred optimal settings would be small values of <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S4.I3.i2.p1.2.m2.1"><semantics id="S4.I3.i2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.I3.i2.p1.2.m2.1.1" xref="S4.I3.i2.p1.2.m2.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.2.m2.1b"><ci id="S4.I3.i2.p1.2.m2.1.1.cmml" xref="S4.I3.i2.p1.2.m2.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.2.m2.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i2.p1.2.m2.1d">caligraphic_K</annotation></semantics></math> and <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S4.I3.i2.p1.3.m3.1"><semantics id="S4.I3.i2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.I3.i2.p1.3.m3.1.1" xref="S4.I3.i2.p1.3.m3.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.3.m3.1b"><ci id="S4.I3.i2.p1.3.m3.1.1.cmml" xref="S4.I3.i2.p1.3.m3.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.3.m3.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i2.p1.3.m3.1d">caligraphic_C</annotation></semantics></math>. Due to reduced dependence on response accuracy, sample variance becomes much smaller and the reward function over <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.I3.i2.p1.4.m4.2"><semantics id="S4.I3.i2.p1.4.m4.2a"><mrow id="S4.I3.i2.p1.4.m4.2.3.2" xref="S4.I3.i2.p1.4.m4.2.3.1.cmml"><mo id="S4.I3.i2.p1.4.m4.2.3.2.1" stretchy="false" xref="S4.I3.i2.p1.4.m4.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i2.p1.4.m4.1.1" xref="S4.I3.i2.p1.4.m4.1.1.cmml">ğ’¦</mi><mo id="S4.I3.i2.p1.4.m4.2.3.2.2" xref="S4.I3.i2.p1.4.m4.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i2.p1.4.m4.2.2" xref="S4.I3.i2.p1.4.m4.2.2.cmml">ğ’</mi><mo id="S4.I3.i2.p1.4.m4.2.3.2.3" stretchy="false" xref="S4.I3.i2.p1.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.4.m4.2b"><interval closure="open" id="S4.I3.i2.p1.4.m4.2.3.1.cmml" xref="S4.I3.i2.p1.4.m4.2.3.2"><ci id="S4.I3.i2.p1.4.m4.1.1.cmml" xref="S4.I3.i2.p1.4.m4.1.1">ğ’¦</ci><ci id="S4.I3.i2.p1.4.m4.2.2.cmml" xref="S4.I3.i2.p1.4.m4.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.4.m4.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i2.p1.4.m4.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math> exhibits steeper gradients. This indicates that the tuning over <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.I3.i2.p1.5.m5.2"><semantics id="S4.I3.i2.p1.5.m5.2a"><mrow id="S4.I3.i2.p1.5.m5.2.3.2" xref="S4.I3.i2.p1.5.m5.2.3.1.cmml"><mo id="S4.I3.i2.p1.5.m5.2.3.2.1" stretchy="false" xref="S4.I3.i2.p1.5.m5.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i2.p1.5.m5.1.1" xref="S4.I3.i2.p1.5.m5.1.1.cmml">ğ’¦</mi><mo id="S4.I3.i2.p1.5.m5.2.3.2.2" xref="S4.I3.i2.p1.5.m5.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i2.p1.5.m5.2.2" xref="S4.I3.i2.p1.5.m5.2.2.cmml">ğ’</mi><mo id="S4.I3.i2.p1.5.m5.2.3.2.3" stretchy="false" xref="S4.I3.i2.p1.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.5.m5.2b"><interval closure="open" id="S4.I3.i2.p1.5.m5.2.3.1.cmml" xref="S4.I3.i2.p1.5.m5.2.3.2"><ci id="S4.I3.i2.p1.5.m5.1.1.cmml" xref="S4.I3.i2.p1.5.m5.1.1">ğ’¦</ci><ci id="S4.I3.i2.p1.5.m5.2.2.cmml" xref="S4.I3.i2.p1.5.m5.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.5.m5.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i2.p1.5.m5.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math> when <math alttext="w=0.1" class="ltx_Math" display="inline" id="S4.I3.i2.p1.6.m6.1"><semantics id="S4.I3.i2.p1.6.m6.1a"><mrow id="S4.I3.i2.p1.6.m6.1.1" xref="S4.I3.i2.p1.6.m6.1.1.cmml"><mi id="S4.I3.i2.p1.6.m6.1.1.2" xref="S4.I3.i2.p1.6.m6.1.1.2.cmml">w</mi><mo id="S4.I3.i2.p1.6.m6.1.1.1" xref="S4.I3.i2.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.I3.i2.p1.6.m6.1.1.3" xref="S4.I3.i2.p1.6.m6.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.6.m6.1b"><apply id="S4.I3.i2.p1.6.m6.1.1.cmml" xref="S4.I3.i2.p1.6.m6.1.1"><eq id="S4.I3.i2.p1.6.m6.1.1.1.cmml" xref="S4.I3.i2.p1.6.m6.1.1.1"></eq><ci id="S4.I3.i2.p1.6.m6.1.1.2.cmml" xref="S4.I3.i2.p1.6.m6.1.1.2">ğ‘¤</ci><cn id="S4.I3.i2.p1.6.m6.1.1.3.cmml" type="float" xref="S4.I3.i2.p1.6.m6.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.6.m6.1c">w=0.1</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i2.p1.6.m6.1d">italic_w = 0.1</annotation></semantics></math> can be relatively easy to achieve.</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I3.i3.p1">
<p class="ltx_p" id="S4.I3.i3.p1.7">With higher weights on accuracy (<math alttext="w=0.5" class="ltx_Math" display="inline" id="S4.I3.i3.p1.1.m1.1"><semantics id="S4.I3.i3.p1.1.m1.1a"><mrow id="S4.I3.i3.p1.1.m1.1.1" xref="S4.I3.i3.p1.1.m1.1.1.cmml"><mi id="S4.I3.i3.p1.1.m1.1.1.2" xref="S4.I3.i3.p1.1.m1.1.1.2.cmml">w</mi><mo id="S4.I3.i3.p1.1.m1.1.1.1" xref="S4.I3.i3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.I3.i3.p1.1.m1.1.1.3" xref="S4.I3.i3.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.1.m1.1b"><apply id="S4.I3.i3.p1.1.m1.1.1.cmml" xref="S4.I3.i3.p1.1.m1.1.1"><eq id="S4.I3.i3.p1.1.m1.1.1.1.cmml" xref="S4.I3.i3.p1.1.m1.1.1.1"></eq><ci id="S4.I3.i3.p1.1.m1.1.1.2.cmml" xref="S4.I3.i3.p1.1.m1.1.1.2">ğ‘¤</ci><cn id="S4.I3.i3.p1.1.m1.1.1.3.cmml" type="float" xref="S4.I3.i3.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.1.m1.1c">w=0.5</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.1.m1.1d">italic_w = 0.5</annotation></semantics></math> and <math alttext="0.9" class="ltx_Math" display="inline" id="S4.I3.i3.p1.2.m2.1"><semantics id="S4.I3.i3.p1.2.m2.1a"><mn id="S4.I3.i3.p1.2.m2.1.1" xref="S4.I3.i3.p1.2.m2.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.2.m2.1b"><cn id="S4.I3.i3.p1.2.m2.1.1.cmml" type="float" xref="S4.I3.i3.p1.2.m2.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.2.m2.1c">0.9</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.2.m2.1d">0.9</annotation></semantics></math>), reward function over <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.I3.i3.p1.3.m3.2"><semantics id="S4.I3.i3.p1.3.m3.2a"><mrow id="S4.I3.i3.p1.3.m3.2.3.2" xref="S4.I3.i3.p1.3.m3.2.3.1.cmml"><mo id="S4.I3.i3.p1.3.m3.2.3.2.1" stretchy="false" xref="S4.I3.i3.p1.3.m3.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.3.m3.1.1" xref="S4.I3.i3.p1.3.m3.1.1.cmml">ğ’¦</mi><mo id="S4.I3.i3.p1.3.m3.2.3.2.2" xref="S4.I3.i3.p1.3.m3.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.3.m3.2.2" xref="S4.I3.i3.p1.3.m3.2.2.cmml">ğ’</mi><mo id="S4.I3.i3.p1.3.m3.2.3.2.3" stretchy="false" xref="S4.I3.i3.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.3.m3.2b"><interval closure="open" id="S4.I3.i3.p1.3.m3.2.3.1.cmml" xref="S4.I3.i3.p1.3.m3.2.3.2"><ci id="S4.I3.i3.p1.3.m3.1.1.cmml" xref="S4.I3.i3.p1.3.m3.1.1">ğ’¦</ci><ci id="S4.I3.i3.p1.3.m3.2.2.cmml" xref="S4.I3.i3.p1.3.m3.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.3.m3.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.3.m3.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math> becomes less steep, accompanied by increased sample variance. This leads to many hyper-parameter combinations achieving similarly high rewards, a phenomenon known as search space degeneracy, which complicates the search for optimal settings. For instance, in the two-parameter case with <math alttext="w=0.9" class="ltx_Math" display="inline" id="S4.I3.i3.p1.4.m4.1"><semantics id="S4.I3.i3.p1.4.m4.1a"><mrow id="S4.I3.i3.p1.4.m4.1.1" xref="S4.I3.i3.p1.4.m4.1.1.cmml"><mi id="S4.I3.i3.p1.4.m4.1.1.2" xref="S4.I3.i3.p1.4.m4.1.1.2.cmml">w</mi><mo id="S4.I3.i3.p1.4.m4.1.1.1" xref="S4.I3.i3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.I3.i3.p1.4.m4.1.1.3" xref="S4.I3.i3.p1.4.m4.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.4.m4.1b"><apply id="S4.I3.i3.p1.4.m4.1.1.cmml" xref="S4.I3.i3.p1.4.m4.1.1"><eq id="S4.I3.i3.p1.4.m4.1.1.1.cmml" xref="S4.I3.i3.p1.4.m4.1.1.1"></eq><ci id="S4.I3.i3.p1.4.m4.1.1.2.cmml" xref="S4.I3.i3.p1.4.m4.1.1.2">ğ‘¤</ci><cn id="S4.I3.i3.p1.4.m4.1.1.3.cmml" type="float" xref="S4.I3.i3.p1.4.m4.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.4.m4.1c">w=0.9</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.4.m4.1d">italic_w = 0.9</annotation></semantics></math>, the panel in the last row and column of FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F3" title="Figure 3 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates that the higher reward parameter region is relatively â€œflatâ€, with clustered <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.I3.i3.p1.5.m5.2"><semantics id="S4.I3.i3.p1.5.m5.2a"><mrow id="S4.I3.i3.p1.5.m5.2.3.2" xref="S4.I3.i3.p1.5.m5.2.3.1.cmml"><mo id="S4.I3.i3.p1.5.m5.2.3.2.1" stretchy="false" xref="S4.I3.i3.p1.5.m5.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.5.m5.1.1" xref="S4.I3.i3.p1.5.m5.1.1.cmml">ğ’¦</mi><mo id="S4.I3.i3.p1.5.m5.2.3.2.2" xref="S4.I3.i3.p1.5.m5.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.5.m5.2.2" xref="S4.I3.i3.p1.5.m5.2.2.cmml">ğ’</mi><mo id="S4.I3.i3.p1.5.m5.2.3.2.3" stretchy="false" xref="S4.I3.i3.p1.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.5.m5.2b"><interval closure="open" id="S4.I3.i3.p1.5.m5.2.3.1.cmml" xref="S4.I3.i3.p1.5.m5.2.3.2"><ci id="S4.I3.i3.p1.5.m5.1.1.cmml" xref="S4.I3.i3.p1.5.m5.1.1">ğ’¦</ci><ci id="S4.I3.i3.p1.5.m5.2.2.cmml" xref="S4.I3.i3.p1.5.m5.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.5.m5.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.5.m5.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math> combinations yielding similar rewards. Further tuning on the embedding model <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.I3.i3.p1.6.m6.1"><semantics id="S4.I3.i3.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.6.m6.1.1" xref="S4.I3.i3.p1.6.m6.1.1.cmml">â„°</mi><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.6.m6.1b"><ci id="S4.I3.i3.p1.6.m6.1.1.cmml" xref="S4.I3.i3.p1.6.m6.1.1">â„°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.6.m6.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.6.m6.1d">caligraphic_E</annotation></semantics></math> in ASQA mitigates parameter degeneracy by enabling the distinction of <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.I3.i3.p1.7.m7.2"><semantics id="S4.I3.i3.p1.7.m7.2a"><mrow id="S4.I3.i3.p1.7.m7.2.3.2" xref="S4.I3.i3.p1.7.m7.2.3.1.cmml"><mo id="S4.I3.i3.p1.7.m7.2.3.2.1" stretchy="false" xref="S4.I3.i3.p1.7.m7.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.7.m7.1.1" xref="S4.I3.i3.p1.7.m7.1.1.cmml">ğ’¦</mi><mo id="S4.I3.i3.p1.7.m7.2.3.2.2" xref="S4.I3.i3.p1.7.m7.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.I3.i3.p1.7.m7.2.2" xref="S4.I3.i3.p1.7.m7.2.2.cmml">ğ’</mi><mo id="S4.I3.i3.p1.7.m7.2.3.2.3" stretchy="false" xref="S4.I3.i3.p1.7.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.I3.i3.p1.7.m7.2b"><interval closure="open" id="S4.I3.i3.p1.7.m7.2.3.1.cmml" xref="S4.I3.i3.p1.7.m7.2.3.2"><ci id="S4.I3.i3.p1.7.m7.1.1.cmml" xref="S4.I3.i3.p1.7.m7.1.1">ğ’¦</ci><ci id="S4.I3.i3.p1.7.m7.2.2.cmml" xref="S4.I3.i3.p1.7.m7.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i3.p1.7.m7.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.I3.i3.p1.7.m7.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math> combinations with similar rewards. Conversely, in NQ, where the embedding model is less influential, adding it exacerbates the problem.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T1.1.1.1.1"><math alttext="w" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.m1.1a"><mi id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.m1.1d">italic_w</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.2" rowspan="2"><span class="ltx_text" id="S4.T1.1.1.2.1">Param.</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.3" rowspan="2"><span class="ltx_text" id="S4.T1.1.1.3.1">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.4" rowspan="2"><span class="ltx_text" id="S4.T1.1.1.4.1">Complexity</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T1.1.1.5">Recall@x</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.6">Recall@x</td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.8.1">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.8.1.1">(All Avg.)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.8.1.2">(Hier-UCB)</td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2" rowspan="4"><span class="ltx_text" id="S4.T1.2.2.2.1">0.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.1" rowspan="2"><span class="ltx_text" id="S4.T1.2.2.1.1"><math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.T1.2.2.1.1.m1.2"><semantics id="S4.T1.2.2.1.1.m1.2a"><mrow id="S4.T1.2.2.1.1.m1.2.3.2" xref="S4.T1.2.2.1.1.m1.2.3.1.cmml"><mo id="S4.T1.2.2.1.1.m1.2.3.2.1" stretchy="false" xref="S4.T1.2.2.1.1.m1.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.2.2.1.1.m1.1.1" xref="S4.T1.2.2.1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.T1.2.2.1.1.m1.2.3.2.2" xref="S4.T1.2.2.1.1.m1.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.2.2.1.1.m1.2.2" xref="S4.T1.2.2.1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.T1.2.2.1.1.m1.2.3.2.3" stretchy="false" xref="S4.T1.2.2.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.1.1.m1.2b"><interval closure="open" id="S4.T1.2.2.1.1.m1.2.3.1.cmml" xref="S4.T1.2.2.1.1.m1.2.3.2"><ci id="S4.T1.2.2.1.1.m1.1.1.cmml" xref="S4.T1.2.2.1.1.m1.1.1">ğ’¦</ci><ci id="S4.T1.2.2.1.1.m1.2.2.cmml" xref="S4.T1.2.2.1.1.m1.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.1.1.m1.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.1.1.m1.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.3">ASQA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.4">Easy</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.5">0.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.6">0.76</td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.9.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.9.2.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.9.2.2">Easy</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.9.2.3">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.9.2.4">0.83</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.1" rowspan="2"><span class="ltx_text" id="S4.T1.3.3.1.1"><math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.T1.3.3.1.1.m1.3"><semantics id="S4.T1.3.3.1.1.m1.3a"><mrow id="S4.T1.3.3.1.1.m1.3.4.2" xref="S4.T1.3.3.1.1.m1.3.4.1.cmml"><mo id="S4.T1.3.3.1.1.m1.3.4.2.1" stretchy="false" xref="S4.T1.3.3.1.1.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.3.3.1.1.m1.1.1" xref="S4.T1.3.3.1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.T1.3.3.1.1.m1.3.4.2.2" xref="S4.T1.3.3.1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.3.3.1.1.m1.2.2" xref="S4.T1.3.3.1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.T1.3.3.1.1.m1.3.4.2.3" xref="S4.T1.3.3.1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.3.3.1.1.m1.3.3" xref="S4.T1.3.3.1.1.m1.3.3.cmml">â„°</mi><mo id="S4.T1.3.3.1.1.m1.3.4.2.4" stretchy="false" xref="S4.T1.3.3.1.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.1.1.m1.3b"><vector id="S4.T1.3.3.1.1.m1.3.4.1.cmml" xref="S4.T1.3.3.1.1.m1.3.4.2"><ci id="S4.T1.3.3.1.1.m1.1.1.cmml" xref="S4.T1.3.3.1.1.m1.1.1">ğ’¦</ci><ci id="S4.T1.3.3.1.1.m1.2.2.cmml" xref="S4.T1.3.3.1.1.m1.2.2">ğ’</ci><ci id="S4.T1.3.3.1.1.m1.3.3.cmml" xref="S4.T1.3.3.1.1.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.1.1.m1.3c">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.1.1.m1.3d">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.2">ASQA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.3">Easy</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.4">0.87</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.5">0.84</td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.10.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.10.3.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.10.3.2">Medium</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.10.3.3">0.68</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.10.3.4"><span class="ltx_text ltx_font_bold" id="S4.T1.7.10.3.4.1">0.72</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.2" rowspan="4"><span class="ltx_text" id="S4.T1.4.4.2.1">0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.1" rowspan="2"><span class="ltx_text" id="S4.T1.4.4.1.1"><math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.T1.4.4.1.1.m1.2"><semantics id="S4.T1.4.4.1.1.m1.2a"><mrow id="S4.T1.4.4.1.1.m1.2.3.2" xref="S4.T1.4.4.1.1.m1.2.3.1.cmml"><mo id="S4.T1.4.4.1.1.m1.2.3.2.1" stretchy="false" xref="S4.T1.4.4.1.1.m1.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.4.4.1.1.m1.1.1" xref="S4.T1.4.4.1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.T1.4.4.1.1.m1.2.3.2.2" xref="S4.T1.4.4.1.1.m1.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.4.4.1.1.m1.2.2" xref="S4.T1.4.4.1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.T1.4.4.1.1.m1.2.3.2.3" stretchy="false" xref="S4.T1.4.4.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.1.1.m1.2b"><interval closure="open" id="S4.T1.4.4.1.1.m1.2.3.1.cmml" xref="S4.T1.4.4.1.1.m1.2.3.2"><ci id="S4.T1.4.4.1.1.m1.1.1.cmml" xref="S4.T1.4.4.1.1.m1.1.1">ğ’¦</ci><ci id="S4.T1.4.4.1.1.m1.2.2.cmml" xref="S4.T1.4.4.1.1.m1.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.1.1.m1.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.1.1.m1.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.3">ASQA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.4">Hard</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.5">0.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.6">0.10</td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.11.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.11.4.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.11.4.2">Hard</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.11.4.3">0.24</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.11.4.4">0.17</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.5.1" rowspan="2"><span class="ltx_text" id="S4.T1.5.5.1.1"><math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.T1.5.5.1.1.m1.3"><semantics id="S4.T1.5.5.1.1.m1.3a"><mrow id="S4.T1.5.5.1.1.m1.3.4.2" xref="S4.T1.5.5.1.1.m1.3.4.1.cmml"><mo id="S4.T1.5.5.1.1.m1.3.4.2.1" stretchy="false" xref="S4.T1.5.5.1.1.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.5.5.1.1.m1.1.1" xref="S4.T1.5.5.1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.T1.5.5.1.1.m1.3.4.2.2" xref="S4.T1.5.5.1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.5.5.1.1.m1.2.2" xref="S4.T1.5.5.1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.T1.5.5.1.1.m1.3.4.2.3" xref="S4.T1.5.5.1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.5.5.1.1.m1.3.3" xref="S4.T1.5.5.1.1.m1.3.3.cmml">â„°</mi><mo id="S4.T1.5.5.1.1.m1.3.4.2.4" stretchy="false" xref="S4.T1.5.5.1.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.1.1.m1.3b"><vector id="S4.T1.5.5.1.1.m1.3.4.1.cmml" xref="S4.T1.5.5.1.1.m1.3.4.2"><ci id="S4.T1.5.5.1.1.m1.1.1.cmml" xref="S4.T1.5.5.1.1.m1.1.1">ğ’¦</ci><ci id="S4.T1.5.5.1.1.m1.2.2.cmml" xref="S4.T1.5.5.1.1.m1.2.2">ğ’</ci><ci id="S4.T1.5.5.1.1.m1.3.3.cmml" xref="S4.T1.5.5.1.1.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.1.1.m1.3c">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.1.1.m1.3d">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.5.2">ASQA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.5.3">Medium</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.5.4">0.59</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T1.5.5.5.1">0.64</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.12.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.12.5.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.12.5.2">Hard</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.12.5.3">0.25</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.12.5.4">0.32</td>
</tr>
<tr class="ltx_tr" id="S4.T1.6.6">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T1.6.6.2" rowspan="4"><span class="ltx_text" id="S4.T1.6.6.2.1">0.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.6.6.1" rowspan="2"><span class="ltx_text" id="S4.T1.6.6.1.1"><math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.T1.6.6.1.1.m1.2"><semantics id="S4.T1.6.6.1.1.m1.2a"><mrow id="S4.T1.6.6.1.1.m1.2.3.2" xref="S4.T1.6.6.1.1.m1.2.3.1.cmml"><mo id="S4.T1.6.6.1.1.m1.2.3.2.1" stretchy="false" xref="S4.T1.6.6.1.1.m1.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.6.6.1.1.m1.1.1" xref="S4.T1.6.6.1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.T1.6.6.1.1.m1.2.3.2.2" xref="S4.T1.6.6.1.1.m1.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.6.6.1.1.m1.2.2" xref="S4.T1.6.6.1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.T1.6.6.1.1.m1.2.3.2.3" stretchy="false" xref="S4.T1.6.6.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.1.1.m1.2b"><interval closure="open" id="S4.T1.6.6.1.1.m1.2.3.1.cmml" xref="S4.T1.6.6.1.1.m1.2.3.2"><ci id="S4.T1.6.6.1.1.m1.1.1.cmml" xref="S4.T1.6.6.1.1.m1.1.1">ğ’¦</ci><ci id="S4.T1.6.6.1.1.m1.2.2.cmml" xref="S4.T1.6.6.1.1.m1.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.1.1.m1.2c">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.1.1.m1.2d">( caligraphic_K , caligraphic_C )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.6.6.3">ASQA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.6.6.4">Hard</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.6.6.5">0.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.6.6.6">0.30</td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.13.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.13.6.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.13.6.2">Hard</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.7.13.6.3">0.38</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.13.6.4">0.47</td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T1.7.7.1" rowspan="2"><span class="ltx_text" id="S4.T1.7.7.1.1"><math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.T1.7.7.1.1.m1.3"><semantics id="S4.T1.7.7.1.1.m1.3a"><mrow id="S4.T1.7.7.1.1.m1.3.4.2" xref="S4.T1.7.7.1.1.m1.3.4.1.cmml"><mo id="S4.T1.7.7.1.1.m1.3.4.2.1" stretchy="false" xref="S4.T1.7.7.1.1.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.7.7.1.1.m1.1.1" xref="S4.T1.7.7.1.1.m1.1.1.cmml">ğ’¦</mi><mo id="S4.T1.7.7.1.1.m1.3.4.2.2" xref="S4.T1.7.7.1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.7.7.1.1.m1.2.2" xref="S4.T1.7.7.1.1.m1.2.2.cmml">ğ’</mi><mo id="S4.T1.7.7.1.1.m1.3.4.2.3" xref="S4.T1.7.7.1.1.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.7.7.1.1.m1.3.3" xref="S4.T1.7.7.1.1.m1.3.3.cmml">â„°</mi><mo id="S4.T1.7.7.1.1.m1.3.4.2.4" stretchy="false" xref="S4.T1.7.7.1.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.1.1.m1.3b"><vector id="S4.T1.7.7.1.1.m1.3.4.1.cmml" xref="S4.T1.7.7.1.1.m1.3.4.2"><ci id="S4.T1.7.7.1.1.m1.1.1.cmml" xref="S4.T1.7.7.1.1.m1.1.1">ğ’¦</ci><ci id="S4.T1.7.7.1.1.m1.2.2.cmml" xref="S4.T1.7.7.1.1.m1.2.2">ğ’</ci><ci id="S4.T1.7.7.1.1.m1.3.3.cmml" xref="S4.T1.7.7.1.1.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.1.1.m1.3c">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.1.1.m1.3d">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.7.7.2">ASQA</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.7.7.3">Medium</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.7.7.4">0.38</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T1.7.7.5.1">0.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.14.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.7.14.7.1">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.7.14.7.2">Hard</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.7.14.7.3">0.27</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.7.14.7.4">0.3</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Complexity of optimization task for the GPT-4 case. The evaluation metrics Recall@3 when <math alttext="T\times B=2000" class="ltx_Math" display="inline" id="S4.T1.12.m1.1"><semantics id="S4.T1.12.m1.1b"><mrow id="S4.T1.12.m1.1.1" xref="S4.T1.12.m1.1.1.cmml"><mrow id="S4.T1.12.m1.1.1.2" xref="S4.T1.12.m1.1.1.2.cmml"><mi id="S4.T1.12.m1.1.1.2.2" xref="S4.T1.12.m1.1.1.2.2.cmml">T</mi><mo id="S4.T1.12.m1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.T1.12.m1.1.1.2.1.cmml">Ã—</mo><mi id="S4.T1.12.m1.1.1.2.3" xref="S4.T1.12.m1.1.1.2.3.cmml">B</mi></mrow><mo id="S4.T1.12.m1.1.1.1" xref="S4.T1.12.m1.1.1.1.cmml">=</mo><mn id="S4.T1.12.m1.1.1.3" xref="S4.T1.12.m1.1.1.3.cmml">2000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.12.m1.1c"><apply id="S4.T1.12.m1.1.1.cmml" xref="S4.T1.12.m1.1.1"><eq id="S4.T1.12.m1.1.1.1.cmml" xref="S4.T1.12.m1.1.1.1"></eq><apply id="S4.T1.12.m1.1.1.2.cmml" xref="S4.T1.12.m1.1.1.2"><times id="S4.T1.12.m1.1.1.2.1.cmml" xref="S4.T1.12.m1.1.1.2.1"></times><ci id="S4.T1.12.m1.1.1.2.2.cmml" xref="S4.T1.12.m1.1.1.2.2">ğ‘‡</ci><ci id="S4.T1.12.m1.1.1.2.3.cmml" xref="S4.T1.12.m1.1.1.2.3">ğµ</ci></apply><cn id="S4.T1.12.m1.1.1.3.cmml" type="integer" xref="S4.T1.12.m1.1.1.3">2000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.m1.1d">T\times B=2000</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.m1.1e">italic_T Ã— italic_B = 2000</annotation></semantics></math> and Recall@5 when <math alttext="T\times B=6000" class="ltx_Math" display="inline" id="S4.T1.13.m2.1"><semantics id="S4.T1.13.m2.1b"><mrow id="S4.T1.13.m2.1.1" xref="S4.T1.13.m2.1.1.cmml"><mrow id="S4.T1.13.m2.1.1.2" xref="S4.T1.13.m2.1.1.2.cmml"><mi id="S4.T1.13.m2.1.1.2.2" xref="S4.T1.13.m2.1.1.2.2.cmml">T</mi><mo id="S4.T1.13.m2.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.T1.13.m2.1.1.2.1.cmml">Ã—</mo><mi id="S4.T1.13.m2.1.1.2.3" xref="S4.T1.13.m2.1.1.2.3.cmml">B</mi></mrow><mo id="S4.T1.13.m2.1.1.1" xref="S4.T1.13.m2.1.1.1.cmml">=</mo><mn id="S4.T1.13.m2.1.1.3" xref="S4.T1.13.m2.1.1.3.cmml">6000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.13.m2.1c"><apply id="S4.T1.13.m2.1.1.cmml" xref="S4.T1.13.m2.1.1"><eq id="S4.T1.13.m2.1.1.1.cmml" xref="S4.T1.13.m2.1.1.1"></eq><apply id="S4.T1.13.m2.1.1.2.cmml" xref="S4.T1.13.m2.1.1.2"><times id="S4.T1.13.m2.1.1.2.1.cmml" xref="S4.T1.13.m2.1.1.2.1"></times><ci id="S4.T1.13.m2.1.1.2.2.cmml" xref="S4.T1.13.m2.1.1.2.2">ğ‘‡</ci><ci id="S4.T1.13.m2.1.1.2.3.cmml" xref="S4.T1.13.m2.1.1.2.3">ğµ</ci></apply><cn id="S4.T1.13.m2.1.1.3.cmml" type="integer" xref="S4.T1.13.m2.1.1.3">6000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.m2.1d">T\times B=6000</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.m2.1e">italic_T Ã— italic_B = 6000</annotation></semantics></math> are used for <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.T1.14.m3.2"><semantics id="S4.T1.14.m3.2b"><mrow id="S4.T1.14.m3.2.3.2" xref="S4.T1.14.m3.2.3.1.cmml"><mo id="S4.T1.14.m3.2.3.2.1" stretchy="false" xref="S4.T1.14.m3.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.14.m3.1.1" xref="S4.T1.14.m3.1.1.cmml">ğ’¦</mi><mo id="S4.T1.14.m3.2.3.2.2" xref="S4.T1.14.m3.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.14.m3.2.2" xref="S4.T1.14.m3.2.2.cmml">ğ’</mi><mo id="S4.T1.14.m3.2.3.2.3" stretchy="false" xref="S4.T1.14.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.14.m3.2c"><interval closure="open" id="S4.T1.14.m3.2.3.1.cmml" xref="S4.T1.14.m3.2.3.2"><ci id="S4.T1.14.m3.1.1.cmml" xref="S4.T1.14.m3.1.1">ğ’¦</ci><ci id="S4.T1.14.m3.2.2.cmml" xref="S4.T1.14.m3.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.m3.2d">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.m3.2e">( caligraphic_K , caligraphic_C )</annotation></semantics></math> and <math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.T1.15.m4.3"><semantics id="S4.T1.15.m4.3b"><mrow id="S4.T1.15.m4.3.4.2" xref="S4.T1.15.m4.3.4.1.cmml"><mo id="S4.T1.15.m4.3.4.2.1" stretchy="false" xref="S4.T1.15.m4.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.15.m4.1.1" xref="S4.T1.15.m4.1.1.cmml">ğ’¦</mi><mo id="S4.T1.15.m4.3.4.2.2" xref="S4.T1.15.m4.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.15.m4.2.2" xref="S4.T1.15.m4.2.2.cmml">ğ’</mi><mo id="S4.T1.15.m4.3.4.2.3" xref="S4.T1.15.m4.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.T1.15.m4.3.3" xref="S4.T1.15.m4.3.3.cmml">â„°</mi><mo id="S4.T1.15.m4.3.4.2.4" stretchy="false" xref="S4.T1.15.m4.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.15.m4.3c"><vector id="S4.T1.15.m4.3.4.1.cmml" xref="S4.T1.15.m4.3.4.2"><ci id="S4.T1.15.m4.1.1.cmml" xref="S4.T1.15.m4.1.1">ğ’¦</ci><ci id="S4.T1.15.m4.2.2.cmml" xref="S4.T1.15.m4.2.2">ğ’</ci><ci id="S4.T1.15.m4.3.3.cmml" xref="S4.T1.15.m4.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.m4.3d">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.T1.15.m4.3e">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math>, respectively. The fifth column reports the metrics averaged over all methods, while the last column for the Hier-UCB only.
</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">Based on the qualitative analysis, we categorize the optimization tasks by complexity (â€œEasyâ€, â€œMediumâ€ and â€œHardâ€), as outlined in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.T1" title="Table 1 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>. Although the experiments are conducted on specific scenarios derived from various reward settings within two datasets, generalizing these scenarios by complexity levels provides insights into the broader applicability of the optimization method. In the following discussion, we will primarily reference the scenarios according to their complexity.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.5">In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.T1" title="Table 1 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a> we also show the average evaluation result across all optimization methods (<em class="ltx_emph ltx_font_italic" id="S4.SS2.p6.5.1">i.e.</em>, Hier-UCB, UCB, TS and Random) as well as the result solely for Hier-UCB. The average Recall@x values (the 5th column) align well with our qualitative assessment of task complexity, <em class="ltx_emph ltx_font_italic" id="S4.SS2.p6.5.2">i.e.</em>, achieving <math alttext="\sim 0.8" class="ltx_Math" display="inline" id="S4.SS2.p6.1.m1.1"><semantics id="S4.SS2.p6.1.m1.1a"><mrow id="S4.SS2.p6.1.m1.1.1" xref="S4.SS2.p6.1.m1.1.1.cmml"><mi id="S4.SS2.p6.1.m1.1.1.2" xref="S4.SS2.p6.1.m1.1.1.2.cmml"></mi><mo id="S4.SS2.p6.1.m1.1.1.1" xref="S4.SS2.p6.1.m1.1.1.1.cmml">âˆ¼</mo><mn id="S4.SS2.p6.1.m1.1.1.3" xref="S4.SS2.p6.1.m1.1.1.3.cmml">0.8</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.m1.1b"><apply id="S4.SS2.p6.1.m1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p6.1.m1.1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S4.SS2.p6.1.m1.1.1.2.cmml" xref="S4.SS2.p6.1.m1.1.1.2">absent</csymbol><cn id="S4.SS2.p6.1.m1.1.1.3.cmml" type="float" xref="S4.SS2.p6.1.m1.1.1.3">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.1c">\sim 0.8</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.1.m1.1d">âˆ¼ 0.8</annotation></semantics></math> for â€œEasyâ€ tasks, <math alttext="\sim 0.5" class="ltx_Math" display="inline" id="S4.SS2.p6.2.m2.1"><semantics id="S4.SS2.p6.2.m2.1a"><mrow id="S4.SS2.p6.2.m2.1.1" xref="S4.SS2.p6.2.m2.1.1.cmml"><mi id="S4.SS2.p6.2.m2.1.1.2" xref="S4.SS2.p6.2.m2.1.1.2.cmml"></mi><mo id="S4.SS2.p6.2.m2.1.1.1" xref="S4.SS2.p6.2.m2.1.1.1.cmml">âˆ¼</mo><mn id="S4.SS2.p6.2.m2.1.1.3" xref="S4.SS2.p6.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m2.1b"><apply id="S4.SS2.p6.2.m2.1.1.cmml" xref="S4.SS2.p6.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p6.2.m2.1.1.1.cmml" xref="S4.SS2.p6.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S4.SS2.p6.2.m2.1.1.2.cmml" xref="S4.SS2.p6.2.m2.1.1.2">absent</csymbol><cn id="S4.SS2.p6.2.m2.1.1.3.cmml" type="float" xref="S4.SS2.p6.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m2.1c">\sim 0.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.2.m2.1d">âˆ¼ 0.5</annotation></semantics></math> for â€œMediumâ€ tasks, and <math alttext="\lesssim 0.3" class="ltx_Math" display="inline" id="S4.SS2.p6.3.m3.1"><semantics id="S4.SS2.p6.3.m3.1a"><mrow id="S4.SS2.p6.3.m3.1.1" xref="S4.SS2.p6.3.m3.1.1.cmml"><mi id="S4.SS2.p6.3.m3.1.1.2" xref="S4.SS2.p6.3.m3.1.1.2.cmml"></mi><mo id="S4.SS2.p6.3.m3.1.1.1" xref="S4.SS2.p6.3.m3.1.1.1.cmml">â‰²</mo><mn id="S4.SS2.p6.3.m3.1.1.3" xref="S4.SS2.p6.3.m3.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.3.m3.1b"><apply id="S4.SS2.p6.3.m3.1.1.cmml" xref="S4.SS2.p6.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p6.3.m3.1.1.1.cmml" xref="S4.SS2.p6.3.m3.1.1.1">less-than-or-similar-to</csymbol><csymbol cd="latexml" id="S4.SS2.p6.3.m3.1.1.2.cmml" xref="S4.SS2.p6.3.m3.1.1.2">absent</csymbol><cn id="S4.SS2.p6.3.m3.1.1.3.cmml" type="float" xref="S4.SS2.p6.3.m3.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.3.m3.1c">\lesssim 0.3</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.3.m3.1d">â‰² 0.3</annotation></semantics></math> for â€œHardâ€ tasks. The iteration process concludes when <math alttext="T\times B=2000" class="ltx_Math" display="inline" id="S4.SS2.p6.4.m4.1"><semantics id="S4.SS2.p6.4.m4.1a"><mrow id="S4.SS2.p6.4.m4.1.1" xref="S4.SS2.p6.4.m4.1.1.cmml"><mrow id="S4.SS2.p6.4.m4.1.1.2" xref="S4.SS2.p6.4.m4.1.1.2.cmml"><mi id="S4.SS2.p6.4.m4.1.1.2.2" xref="S4.SS2.p6.4.m4.1.1.2.2.cmml">T</mi><mo id="S4.SS2.p6.4.m4.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p6.4.m4.1.1.2.1.cmml">Ã—</mo><mi id="S4.SS2.p6.4.m4.1.1.2.3" xref="S4.SS2.p6.4.m4.1.1.2.3.cmml">B</mi></mrow><mo id="S4.SS2.p6.4.m4.1.1.1" xref="S4.SS2.p6.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.p6.4.m4.1.1.3" xref="S4.SS2.p6.4.m4.1.1.3.cmml">2000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.4.m4.1b"><apply id="S4.SS2.p6.4.m4.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1"><eq id="S4.SS2.p6.4.m4.1.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1.1"></eq><apply id="S4.SS2.p6.4.m4.1.1.2.cmml" xref="S4.SS2.p6.4.m4.1.1.2"><times id="S4.SS2.p6.4.m4.1.1.2.1.cmml" xref="S4.SS2.p6.4.m4.1.1.2.1"></times><ci id="S4.SS2.p6.4.m4.1.1.2.2.cmml" xref="S4.SS2.p6.4.m4.1.1.2.2">ğ‘‡</ci><ci id="S4.SS2.p6.4.m4.1.1.2.3.cmml" xref="S4.SS2.p6.4.m4.1.1.2.3">ğµ</ci></apply><cn id="S4.SS2.p6.4.m4.1.1.3.cmml" type="integer" xref="S4.SS2.p6.4.m4.1.1.3">2000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.4.m4.1c">T\times B=2000</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.4.m4.1d">italic_T Ã— italic_B = 2000</annotation></semantics></math> (for the 2-parameter case) or <math alttext="6000" class="ltx_Math" display="inline" id="S4.SS2.p6.5.m5.1"><semantics id="S4.SS2.p6.5.m5.1a"><mn id="S4.SS2.p6.5.m5.1.1" xref="S4.SS2.p6.5.m5.1.1.cmml">6000</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.5.m5.1b"><cn id="S4.SS2.p6.5.m5.1.1.cmml" type="integer" xref="S4.SS2.p6.5.m5.1.1">6000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.5.m5.1c">6000</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.5.m5.1d">6000</annotation></semantics></math> (for the 3-parameter case), with the number of LLM API calls being roughly 20% of those required for Grid Search.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="498" id="S4.F4.g1" src="extracted/5694705/figures/ASQA_gpt4_2_param_alpha_1-NQ_gpt4_2_param_alpha_1_topk_3_interval_100.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evolution of Recall@3 in the optimization of <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="S4.F4.2.m1.2"><semantics id="S4.F4.2.m1.2b"><mrow id="S4.F4.2.m1.2.3.2" xref="S4.F4.2.m1.2.3.1.cmml"><mo id="S4.F4.2.m1.2.3.2.1" stretchy="false" xref="S4.F4.2.m1.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.F4.2.m1.1.1" xref="S4.F4.2.m1.1.1.cmml">ğ’¦</mi><mo id="S4.F4.2.m1.2.3.2.2" xref="S4.F4.2.m1.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F4.2.m1.2.2" xref="S4.F4.2.m1.2.2.cmml">ğ’</mi><mo id="S4.F4.2.m1.2.3.2.3" stretchy="false" xref="S4.F4.2.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.2.m1.2c"><interval closure="open" id="S4.F4.2.m1.2.3.1.cmml" xref="S4.F4.2.m1.2.3.2"><ci id="S4.F4.2.m1.1.1.cmml" xref="S4.F4.2.m1.1.1">ğ’¦</ci><ci id="S4.F4.2.m1.2.2.cmml" xref="S4.F4.2.m1.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.2.m1.2d">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="S4.F4.2.m1.2e">( caligraphic_K , caligraphic_C )</annotation></semantics></math> for the GPT-4 case.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="499" id="S4.F5.g1" src="extracted/5694705/figures/ASQA_gpt4_3_param_alpha_1-NQ_gpt4_3_param_alpha_1_topk_5_interval_100.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Evolution of Recall@5 in the optimization of <math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.F5.2.m1.3"><semantics id="S4.F5.2.m1.3b"><mrow id="S4.F5.2.m1.3.4.2" xref="S4.F5.2.m1.3.4.1.cmml"><mo id="S4.F5.2.m1.3.4.2.1" stretchy="false" xref="S4.F5.2.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.F5.2.m1.1.1" xref="S4.F5.2.m1.1.1.cmml">ğ’¦</mi><mo id="S4.F5.2.m1.3.4.2.2" xref="S4.F5.2.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F5.2.m1.2.2" xref="S4.F5.2.m1.2.2.cmml">ğ’</mi><mo id="S4.F5.2.m1.3.4.2.3" xref="S4.F5.2.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F5.2.m1.3.3" xref="S4.F5.2.m1.3.3.cmml">â„°</mi><mo id="S4.F5.2.m1.3.4.2.4" stretchy="false" xref="S4.F5.2.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.2.m1.3c"><vector id="S4.F5.2.m1.3.4.1.cmml" xref="S4.F5.2.m1.3.4.2"><ci id="S4.F5.2.m1.1.1.cmml" xref="S4.F5.2.m1.1.1">ğ’¦</ci><ci id="S4.F5.2.m1.2.2.cmml" xref="S4.F5.2.m1.2.2">ğ’</ci><ci id="S4.F5.2.m1.3.3.cmml" xref="S4.F5.2.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.2.m1.3d">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.F5.2.m1.3e">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math> for the GPT-4 case.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.1">Next, we compare Hier-UCBâ€™s performance with other baseline methods. In FiguresÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F4" title="Figure 4 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F5" title="Figure 5 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a>, we plot the evolution of Recall@x metric over the iteration process for the 2-parameter and 3-parameter optimization cases, respectively. With the identification of task complexity in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.T1" title="Table 1 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>, the following observations are made:</p>
</div>
<div class="ltx_para" id="S4.SS2.p8">
<ul class="ltx_itemize" id="S4.I4">
<li class="ltx_item" id="S4.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I4.i1.p1">
<p class="ltx_p" id="S4.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I4.i1.p1.1.1">Hier-UCB consistently outperforms other baselines for all â€œMediumâ€ complexity cases</span>, while demonstrating comparable performance in â€œEasyâ€ and â€œHardâ€ cases. Notably, Hier-UCB achieves faster convergence in â€œMediumâ€ cases, as evident in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F5" title="Figure 5 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a>. The last column of TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.T1" title="Table 1 â€£ 4.2 Experiment Result â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a> presents the Recall@x for Hier-UCB at the final timestamp, showing its competitive edge. However, this advantage is less pronounced compared to the mid-iteration timestamp (e.g., <math alttext="T\times B\approx 2500" class="ltx_Math" display="inline" id="S4.I4.i1.p1.1.m1.1"><semantics id="S4.I4.i1.p1.1.m1.1a"><mrow id="S4.I4.i1.p1.1.m1.1.1" xref="S4.I4.i1.p1.1.m1.1.1.cmml"><mrow id="S4.I4.i1.p1.1.m1.1.1.2" xref="S4.I4.i1.p1.1.m1.1.1.2.cmml"><mi id="S4.I4.i1.p1.1.m1.1.1.2.2" xref="S4.I4.i1.p1.1.m1.1.1.2.2.cmml">T</mi><mo id="S4.I4.i1.p1.1.m1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.I4.i1.p1.1.m1.1.1.2.1.cmml">Ã—</mo><mi id="S4.I4.i1.p1.1.m1.1.1.2.3" xref="S4.I4.i1.p1.1.m1.1.1.2.3.cmml">B</mi></mrow><mo id="S4.I4.i1.p1.1.m1.1.1.1" xref="S4.I4.i1.p1.1.m1.1.1.1.cmml">â‰ˆ</mo><mn id="S4.I4.i1.p1.1.m1.1.1.3" xref="S4.I4.i1.p1.1.m1.1.1.3.cmml">2500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I4.i1.p1.1.m1.1b"><apply id="S4.I4.i1.p1.1.m1.1.1.cmml" xref="S4.I4.i1.p1.1.m1.1.1"><approx id="S4.I4.i1.p1.1.m1.1.1.1.cmml" xref="S4.I4.i1.p1.1.m1.1.1.1"></approx><apply id="S4.I4.i1.p1.1.m1.1.1.2.cmml" xref="S4.I4.i1.p1.1.m1.1.1.2"><times id="S4.I4.i1.p1.1.m1.1.1.2.1.cmml" xref="S4.I4.i1.p1.1.m1.1.1.2.1"></times><ci id="S4.I4.i1.p1.1.m1.1.1.2.2.cmml" xref="S4.I4.i1.p1.1.m1.1.1.2.2">ğ‘‡</ci><ci id="S4.I4.i1.p1.1.m1.1.1.2.3.cmml" xref="S4.I4.i1.p1.1.m1.1.1.2.3">ğµ</ci></apply><cn id="S4.I4.i1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.I4.i1.p1.1.m1.1.1.3">2500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I4.i1.p1.1.m1.1c">T\times B\approx 2500</annotation><annotation encoding="application/x-llamapun" id="S4.I4.i1.p1.1.m1.1d">italic_T Ã— italic_B â‰ˆ 2500</annotation></semantics></math>).
</p>
</div>
</li>
<li class="ltx_item" id="S4.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I4.i2.p1">
<p class="ltx_p" id="S4.I4.i2.p1.1">All three baseline methods exhibit similar behavior. Although random exploration can be effective, its application in real-world online tuning requires caution. This approach is more likely to explore cases resulting in low rewards, thereby negatively impacting user experience.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Study</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.4">The results of Hier-UCB in the previous section are obtained with <math alttext="\alpha^{h}=\alpha^{l}=1" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><msup id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2.2" xref="S4.SS3.p1.1.m1.1.1.2.2.cmml">Î±</mi><mi id="S4.SS3.p1.1.m1.1.1.2.3" xref="S4.SS3.p1.1.m1.1.1.2.3.cmml">h</mi></msup><mo id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">=</mo><msup id="S4.SS3.p1.1.m1.1.1.4" xref="S4.SS3.p1.1.m1.1.1.4.cmml"><mi id="S4.SS3.p1.1.m1.1.1.4.2" xref="S4.SS3.p1.1.m1.1.1.4.2.cmml">Î±</mi><mi id="S4.SS3.p1.1.m1.1.1.4.3" xref="S4.SS3.p1.1.m1.1.1.4.3.cmml">l</mi></msup><mo id="S4.SS3.p1.1.m1.1.1.5" xref="S4.SS3.p1.1.m1.1.1.5.cmml">=</mo><mn id="S4.SS3.p1.1.m1.1.1.6" xref="S4.SS3.p1.1.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><and id="S4.SS3.p1.1.m1.1.1a.cmml" xref="S4.SS3.p1.1.m1.1.1"></and><apply id="S4.SS3.p1.1.m1.1.1b.cmml" xref="S4.SS3.p1.1.m1.1.1"><eq id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3"></eq><apply id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.p1.1.m1.1.1.2">superscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2.2">ğ›¼</ci><ci id="S4.SS3.p1.1.m1.1.1.2.3.cmml" xref="S4.SS3.p1.1.m1.1.1.2.3">â„</ci></apply><apply id="S4.SS3.p1.1.m1.1.1.4.cmml" xref="S4.SS3.p1.1.m1.1.1.4"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.4.1.cmml" xref="S4.SS3.p1.1.m1.1.1.4">superscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.4.2.cmml" xref="S4.SS3.p1.1.m1.1.1.4.2">ğ›¼</ci><ci id="S4.SS3.p1.1.m1.1.1.4.3.cmml" xref="S4.SS3.p1.1.m1.1.1.4.3">ğ‘™</ci></apply></apply><apply id="S4.SS3.p1.1.m1.1.1c.cmml" xref="S4.SS3.p1.1.m1.1.1"><eq id="S4.SS3.p1.1.m1.1.1.5.cmml" xref="S4.SS3.p1.1.m1.1.1.5"></eq><share href="https://arxiv.org/html/2406.19251v1#S4.SS3.p1.1.m1.1.1.4.cmml" id="S4.SS3.p1.1.m1.1.1d.cmml" xref="S4.SS3.p1.1.m1.1.1"></share><cn id="S4.SS3.p1.1.m1.1.1.6.cmml" type="integer" xref="S4.SS3.p1.1.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\alpha^{h}=\alpha^{l}=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT = italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 1</annotation></semantics></math> and a batch size of <math alttext="B=4" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">B</mi><mo id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><eq id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></eq><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">ğµ</ci><cn id="S4.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.p1.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">B=4</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">italic_B = 4</annotation></semantics></math>. We now examine the impact of varying these values on performance. For this analysis, we focus on the 3-parameter optimization case, which encompasses all three complexity levels. Specifically, we present ablation studies for <math alttext="\alpha^{h,l}" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.2"><semantics id="S4.SS3.p1.3.m3.2a"><msup id="S4.SS3.p1.3.m3.2.3" xref="S4.SS3.p1.3.m3.2.3.cmml"><mi id="S4.SS3.p1.3.m3.2.3.2" xref="S4.SS3.p1.3.m3.2.3.2.cmml">Î±</mi><mrow id="S4.SS3.p1.3.m3.2.2.2.4" xref="S4.SS3.p1.3.m3.2.2.2.3.cmml"><mi id="S4.SS3.p1.3.m3.1.1.1.1" xref="S4.SS3.p1.3.m3.1.1.1.1.cmml">h</mi><mo id="S4.SS3.p1.3.m3.2.2.2.4.1" xref="S4.SS3.p1.3.m3.2.2.2.3.cmml">,</mo><mi id="S4.SS3.p1.3.m3.2.2.2.2" xref="S4.SS3.p1.3.m3.2.2.2.2.cmml">l</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.2b"><apply id="S4.SS3.p1.3.m3.2.3.cmml" xref="S4.SS3.p1.3.m3.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.2.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3">superscript</csymbol><ci id="S4.SS3.p1.3.m3.2.3.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2">ğ›¼</ci><list id="S4.SS3.p1.3.m3.2.2.2.3.cmml" xref="S4.SS3.p1.3.m3.2.2.2.4"><ci id="S4.SS3.p1.3.m3.1.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1.1">â„</ci><ci id="S4.SS3.p1.3.m3.2.2.2.2.cmml" xref="S4.SS3.p1.3.m3.2.2.2.2">ğ‘™</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.2c">\alpha^{h,l}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.2d">italic_Î± start_POSTSUPERSCRIPT italic_h , italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F6" title="Figure 6 â€£ 4.3 Ablation Study â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a> and for the batch size <math alttext="B" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">italic_B</annotation></semantics></math> in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F7" title="Figure 7 â€£ 4.3 Ablation Study â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="497" id="S4.F6.g1" src="extracted/5694705/figures/ASQA_gpt4_3_param_ablation-NQ_gpt4_3_param_ablation_topk_5_interval_100.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Evolution of Recall@5 when optimizing <math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.F6.3.m1.3"><semantics id="S4.F6.3.m1.3b"><mrow id="S4.F6.3.m1.3.4.2" xref="S4.F6.3.m1.3.4.1.cmml"><mo id="S4.F6.3.m1.3.4.2.1" stretchy="false" xref="S4.F6.3.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.F6.3.m1.1.1" xref="S4.F6.3.m1.1.1.cmml">ğ’¦</mi><mo id="S4.F6.3.m1.3.4.2.2" xref="S4.F6.3.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F6.3.m1.2.2" xref="S4.F6.3.m1.2.2.cmml">ğ’</mi><mo id="S4.F6.3.m1.3.4.2.3" xref="S4.F6.3.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F6.3.m1.3.3" xref="S4.F6.3.m1.3.3.cmml">â„°</mi><mo id="S4.F6.3.m1.3.4.2.4" stretchy="false" xref="S4.F6.3.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.3.m1.3c"><vector id="S4.F6.3.m1.3.4.1.cmml" xref="S4.F6.3.m1.3.4.2"><ci id="S4.F6.3.m1.1.1.cmml" xref="S4.F6.3.m1.1.1">ğ’¦</ci><ci id="S4.F6.3.m1.2.2.cmml" xref="S4.F6.3.m1.2.2">ğ’</ci><ci id="S4.F6.3.m1.3.3.cmml" xref="S4.F6.3.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.3.m1.3d">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.F6.3.m1.3e">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math> with varying <math alttext="\alpha^{h,l}" class="ltx_Math" display="inline" id="S4.F6.4.m2.2"><semantics id="S4.F6.4.m2.2b"><msup id="S4.F6.4.m2.2.3" xref="S4.F6.4.m2.2.3.cmml"><mi id="S4.F6.4.m2.2.3.2" xref="S4.F6.4.m2.2.3.2.cmml">Î±</mi><mrow id="S4.F6.4.m2.2.2.2.4" xref="S4.F6.4.m2.2.2.2.3.cmml"><mi id="S4.F6.4.m2.1.1.1.1" xref="S4.F6.4.m2.1.1.1.1.cmml">h</mi><mo id="S4.F6.4.m2.2.2.2.4.1" xref="S4.F6.4.m2.2.2.2.3.cmml">,</mo><mi id="S4.F6.4.m2.2.2.2.2" xref="S4.F6.4.m2.2.2.2.2.cmml">l</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.F6.4.m2.2c"><apply id="S4.F6.4.m2.2.3.cmml" xref="S4.F6.4.m2.2.3"><csymbol cd="ambiguous" id="S4.F6.4.m2.2.3.1.cmml" xref="S4.F6.4.m2.2.3">superscript</csymbol><ci id="S4.F6.4.m2.2.3.2.cmml" xref="S4.F6.4.m2.2.3.2">ğ›¼</ci><list id="S4.F6.4.m2.2.2.2.3.cmml" xref="S4.F6.4.m2.2.2.2.4"><ci id="S4.F6.4.m2.1.1.1.1.cmml" xref="S4.F6.4.m2.1.1.1.1">â„</ci><ci id="S4.F6.4.m2.2.2.2.2.cmml" xref="S4.F6.4.m2.2.2.2.2">ğ‘™</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.m2.2d">\alpha^{h,l}</annotation><annotation encoding="application/x-llamapun" id="S4.F6.4.m2.2e">italic_Î± start_POSTSUPERSCRIPT italic_h , italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> settings of Hier-UCB in the GPT-4 case.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="499" id="S4.F7.g1" src="extracted/5694705/figures/ASQA_gpt4_3_param_ablation_batch-NQ_gpt4_3_param_ablation_batch_topk_5_interval_100.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Evolution of Recall@5 when optimizing <math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="S4.F7.3.m1.3"><semantics id="S4.F7.3.m1.3b"><mrow id="S4.F7.3.m1.3.4.2" xref="S4.F7.3.m1.3.4.1.cmml"><mo id="S4.F7.3.m1.3.4.2.1" stretchy="false" xref="S4.F7.3.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.F7.3.m1.1.1" xref="S4.F7.3.m1.1.1.cmml">ğ’¦</mi><mo id="S4.F7.3.m1.3.4.2.2" xref="S4.F7.3.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F7.3.m1.2.2" xref="S4.F7.3.m1.2.2.cmml">ğ’</mi><mo id="S4.F7.3.m1.3.4.2.3" xref="S4.F7.3.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S4.F7.3.m1.3.3" xref="S4.F7.3.m1.3.3.cmml">â„°</mi><mo id="S4.F7.3.m1.3.4.2.4" stretchy="false" xref="S4.F7.3.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F7.3.m1.3c"><vector id="S4.F7.3.m1.3.4.1.cmml" xref="S4.F7.3.m1.3.4.2"><ci id="S4.F7.3.m1.1.1.cmml" xref="S4.F7.3.m1.1.1">ğ’¦</ci><ci id="S4.F7.3.m1.2.2.cmml" xref="S4.F7.3.m1.2.2">ğ’</ci><ci id="S4.F7.3.m1.3.3.cmml" xref="S4.F7.3.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.3.m1.3d">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="S4.F7.3.m1.3e">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math> with varying batch sizes <math alttext="B" class="ltx_Math" display="inline" id="S4.F7.4.m2.1"><semantics id="S4.F7.4.m2.1b"><mi id="S4.F7.4.m2.1.1" xref="S4.F7.4.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.F7.4.m2.1c"><ci id="S4.F7.4.m2.1.1.cmml" xref="S4.F7.4.m2.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.m2.1d">B</annotation><annotation encoding="application/x-llamapun" id="S4.F7.4.m2.1e">italic_B</annotation></semantics></math> of Hier-UCB in the ASQA GPT-4 case.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.7">From FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F6" title="Figure 6 â€£ 4.3 Ablation Study â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a>, it can be observed that setting <math alttext="\alpha^{h}=\alpha^{l}=1" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><msup id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2.2" xref="S4.SS3.p2.1.m1.1.1.2.2.cmml">Î±</mi><mi id="S4.SS3.p2.1.m1.1.1.2.3" xref="S4.SS3.p2.1.m1.1.1.2.3.cmml">h</mi></msup><mo id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">=</mo><msup id="S4.SS3.p2.1.m1.1.1.4" xref="S4.SS3.p2.1.m1.1.1.4.cmml"><mi id="S4.SS3.p2.1.m1.1.1.4.2" xref="S4.SS3.p2.1.m1.1.1.4.2.cmml">Î±</mi><mi id="S4.SS3.p2.1.m1.1.1.4.3" xref="S4.SS3.p2.1.m1.1.1.4.3.cmml">l</mi></msup><mo id="S4.SS3.p2.1.m1.1.1.5" xref="S4.SS3.p2.1.m1.1.1.5.cmml">=</mo><mn id="S4.SS3.p2.1.m1.1.1.6" xref="S4.SS3.p2.1.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><and id="S4.SS3.p2.1.m1.1.1a.cmml" xref="S4.SS3.p2.1.m1.1.1"></and><apply id="S4.SS3.p2.1.m1.1.1b.cmml" xref="S4.SS3.p2.1.m1.1.1"><eq id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3"></eq><apply id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.2.1.cmml" xref="S4.SS3.p2.1.m1.1.1.2">superscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2.2">ğ›¼</ci><ci id="S4.SS3.p2.1.m1.1.1.2.3.cmml" xref="S4.SS3.p2.1.m1.1.1.2.3">â„</ci></apply><apply id="S4.SS3.p2.1.m1.1.1.4.cmml" xref="S4.SS3.p2.1.m1.1.1.4"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.4.1.cmml" xref="S4.SS3.p2.1.m1.1.1.4">superscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.4.2.cmml" xref="S4.SS3.p2.1.m1.1.1.4.2">ğ›¼</ci><ci id="S4.SS3.p2.1.m1.1.1.4.3.cmml" xref="S4.SS3.p2.1.m1.1.1.4.3">ğ‘™</ci></apply></apply><apply id="S4.SS3.p2.1.m1.1.1c.cmml" xref="S4.SS3.p2.1.m1.1.1"><eq id="S4.SS3.p2.1.m1.1.1.5.cmml" xref="S4.SS3.p2.1.m1.1.1.5"></eq><share href="https://arxiv.org/html/2406.19251v1#S4.SS3.p2.1.m1.1.1.4.cmml" id="S4.SS3.p2.1.m1.1.1d.cmml" xref="S4.SS3.p2.1.m1.1.1"></share><cn id="S4.SS3.p2.1.m1.1.1.6.cmml" type="integer" xref="S4.SS3.p2.1.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\alpha^{h}=\alpha^{l}=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT = italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 1</annotation></semantics></math> is robust across all cases. Furthermore, a large <math alttext="\alpha^{l}" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><msup id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">Î±</mi><mi id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">superscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">ğ›¼</ci><ci id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\alpha^{l}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> (e.g., <math alttext="\alpha^{l}=1.5" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><msup id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2.2" xref="S4.SS3.p2.3.m3.1.1.2.2.cmml">Î±</mi><mi id="S4.SS3.p2.3.m3.1.1.2.3" xref="S4.SS3.p2.3.m3.1.1.2.3.cmml">l</mi></msup><mo id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><eq id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></eq><apply id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.2.1.cmml" xref="S4.SS3.p2.3.m3.1.1.2">superscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2.2">ğ›¼</ci><ci id="S4.SS3.p2.3.m3.1.1.2.3.cmml" xref="S4.SS3.p2.3.m3.1.1.2.3">ğ‘™</ci></apply><cn id="S4.SS3.p2.3.m3.1.1.3.cmml" type="float" xref="S4.SS3.p2.3.m3.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\alpha^{l}=1.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 1.5</annotation></semantics></math>) can degrade performance in some cases, while setting a high value for <math alttext="\alpha^{h}" class="ltx_Math" display="inline" id="S4.SS3.p2.4.m4.1"><semantics id="S4.SS3.p2.4.m4.1a"><msup id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">Î±</mi><mi id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml">h</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">superscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">ğ›¼</ci><ci id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\alpha^{h}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.1d">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> and a low value for <math alttext="\alpha^{l}" class="ltx_Math" display="inline" id="S4.SS3.p2.5.m5.1"><semantics id="S4.SS3.p2.5.m5.1a"><msup id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">Î±</mi><mi id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">superscript</csymbol><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">ğ›¼</ci><ci id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">\alpha^{l}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.5.m5.1d">italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> (e.g., <math alttext="\alpha^{h}=1.5,\alpha^{l}=0.5" class="ltx_Math" display="inline" id="S4.SS3.p2.6.m6.2"><semantics id="S4.SS3.p2.6.m6.2a"><mrow id="S4.SS3.p2.6.m6.2.2.2" xref="S4.SS3.p2.6.m6.2.2.3.cmml"><mrow id="S4.SS3.p2.6.m6.1.1.1.1" xref="S4.SS3.p2.6.m6.1.1.1.1.cmml"><msup id="S4.SS3.p2.6.m6.1.1.1.1.2" xref="S4.SS3.p2.6.m6.1.1.1.1.2.cmml"><mi id="S4.SS3.p2.6.m6.1.1.1.1.2.2" xref="S4.SS3.p2.6.m6.1.1.1.1.2.2.cmml">Î±</mi><mi id="S4.SS3.p2.6.m6.1.1.1.1.2.3" xref="S4.SS3.p2.6.m6.1.1.1.1.2.3.cmml">h</mi></msup><mo id="S4.SS3.p2.6.m6.1.1.1.1.1" xref="S4.SS3.p2.6.m6.1.1.1.1.1.cmml">=</mo><mn id="S4.SS3.p2.6.m6.1.1.1.1.3" xref="S4.SS3.p2.6.m6.1.1.1.1.3.cmml">1.5</mn></mrow><mo id="S4.SS3.p2.6.m6.2.2.2.3" xref="S4.SS3.p2.6.m6.2.2.3a.cmml">,</mo><mrow id="S4.SS3.p2.6.m6.2.2.2.2" xref="S4.SS3.p2.6.m6.2.2.2.2.cmml"><msup id="S4.SS3.p2.6.m6.2.2.2.2.2" xref="S4.SS3.p2.6.m6.2.2.2.2.2.cmml"><mi id="S4.SS3.p2.6.m6.2.2.2.2.2.2" xref="S4.SS3.p2.6.m6.2.2.2.2.2.2.cmml">Î±</mi><mi id="S4.SS3.p2.6.m6.2.2.2.2.2.3" xref="S4.SS3.p2.6.m6.2.2.2.2.2.3.cmml">l</mi></msup><mo id="S4.SS3.p2.6.m6.2.2.2.2.1" xref="S4.SS3.p2.6.m6.2.2.2.2.1.cmml">=</mo><mn id="S4.SS3.p2.6.m6.2.2.2.2.3" xref="S4.SS3.p2.6.m6.2.2.2.2.3.cmml">0.5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.2b"><apply id="S4.SS3.p2.6.m6.2.2.3.cmml" xref="S4.SS3.p2.6.m6.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.6.m6.2.2.3a.cmml" xref="S4.SS3.p2.6.m6.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS3.p2.6.m6.1.1.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1.1.1"><eq id="S4.SS3.p2.6.m6.1.1.1.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1.1.1.1"></eq><apply id="S4.SS3.p2.6.m6.1.1.1.1.2.cmml" xref="S4.SS3.p2.6.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p2.6.m6.1.1.1.1.2.1.cmml" xref="S4.SS3.p2.6.m6.1.1.1.1.2">superscript</csymbol><ci id="S4.SS3.p2.6.m6.1.1.1.1.2.2.cmml" xref="S4.SS3.p2.6.m6.1.1.1.1.2.2">ğ›¼</ci><ci id="S4.SS3.p2.6.m6.1.1.1.1.2.3.cmml" xref="S4.SS3.p2.6.m6.1.1.1.1.2.3">â„</ci></apply><cn id="S4.SS3.p2.6.m6.1.1.1.1.3.cmml" type="float" xref="S4.SS3.p2.6.m6.1.1.1.1.3">1.5</cn></apply><apply id="S4.SS3.p2.6.m6.2.2.2.2.cmml" xref="S4.SS3.p2.6.m6.2.2.2.2"><eq id="S4.SS3.p2.6.m6.2.2.2.2.1.cmml" xref="S4.SS3.p2.6.m6.2.2.2.2.1"></eq><apply id="S4.SS3.p2.6.m6.2.2.2.2.2.cmml" xref="S4.SS3.p2.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.6.m6.2.2.2.2.2.1.cmml" xref="S4.SS3.p2.6.m6.2.2.2.2.2">superscript</csymbol><ci id="S4.SS3.p2.6.m6.2.2.2.2.2.2.cmml" xref="S4.SS3.p2.6.m6.2.2.2.2.2.2">ğ›¼</ci><ci id="S4.SS3.p2.6.m6.2.2.2.2.2.3.cmml" xref="S4.SS3.p2.6.m6.2.2.2.2.2.3">ğ‘™</ci></apply><cn id="S4.SS3.p2.6.m6.2.2.2.2.3.cmml" type="float" xref="S4.SS3.p2.6.m6.2.2.2.2.3">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.2c">\alpha^{h}=1.5,\alpha^{l}=0.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.6.m6.2d">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT = 1.5 , italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 0.5</annotation></semantics></math>) yields the best overall performance. This can be understood intuitively: a higher value for the high-level arm, responsible for hyper-parameter selection, promotes exploration at the high level, avoiding premature convergence to local minima. Conversely, a lower <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS3.p2.7.m7.1"><semantics id="S4.SS3.p2.7.m7.1a"><mi id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><ci id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.7.m7.1d">italic_Î±</annotation></semantics></math> value in the lower-level arm facilitates faster convergence.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.5">According to FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F7" title="Figure 7 â€£ 4.3 Ablation Study â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">7</span></a>, the batch size <math alttext="B" class="ltx_Math" display="inline" id="S4.SS3.p3.1.m1.1"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.1.m1.1d">italic_B</annotation></semantics></math> greatly affects the performance. Again, <math alttext="B=4" class="ltx_Math" display="inline" id="S4.SS3.p3.2.m2.1"><semantics id="S4.SS3.p3.2.m2.1a"><mrow id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mi id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">B</mi><mo id="S4.SS3.p3.2.m2.1.1.1" xref="S4.SS3.p3.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><eq id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1.1"></eq><ci id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2">ğµ</ci><cn id="S4.SS3.p3.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.p3.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">B=4</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.2.m2.1d">italic_B = 4</annotation></semantics></math> appears to be a robust choice across all cases. A smaller <math alttext="B" class="ltx_Math" display="inline" id="S4.SS3.p3.3.m3.1"><semantics id="S4.SS3.p3.3.m3.1a"><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.3.m3.1d">italic_B</annotation></semantics></math> may increase sample variance, particularly in the â€œaccuracy-centralâ€ case (<math alttext="w=0.9" class="ltx_Math" display="inline" id="S4.SS3.p3.4.m4.1"><semantics id="S4.SS3.p3.4.m4.1a"><mrow id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mi id="S4.SS3.p3.4.m4.1.1.2" xref="S4.SS3.p3.4.m4.1.1.2.cmml">w</mi><mo id="S4.SS3.p3.4.m4.1.1.1" xref="S4.SS3.p3.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.p3.4.m4.1.1.3" xref="S4.SS3.p3.4.m4.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><eq id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1.1"></eq><ci id="S4.SS3.p3.4.m4.1.1.2.cmml" xref="S4.SS3.p3.4.m4.1.1.2">ğ‘¤</ci><cn id="S4.SS3.p3.4.m4.1.1.3.cmml" type="float" xref="S4.SS3.p3.4.m4.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">w=0.9</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.4.m4.1d">italic_w = 0.9</annotation></semantics></math>), and a larger <math alttext="B" class="ltx_Math" display="inline" id="S4.SS3.p3.5.m5.1"><semantics id="S4.SS3.p3.5.m5.1a"><mi id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><ci id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.5.m5.1d">italic_B</annotation></semantics></math> reduces the number of iterations, impairing the exploration process.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Case Study: Upgrade Base LLM from GPT-3.5-Turbo to GPT-4</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.3">Lastly, we demonstrate the application of our proposed Hier-UCB method in a real-world scenario: the upgrade of base LLMs. Given the rapid advancements in LLMs, there is a strong motivation to upgrade to a more advanced version for improved performance. In our experiment, we first conduct online hyper-parameter tuning with GPT-3.5-Turbo for <math alttext="T\times B\in[0,6000]" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.2"><semantics id="S4.SS4.p1.1.m1.2a"><mrow id="S4.SS4.p1.1.m1.2.3" xref="S4.SS4.p1.1.m1.2.3.cmml"><mrow id="S4.SS4.p1.1.m1.2.3.2" xref="S4.SS4.p1.1.m1.2.3.2.cmml"><mi id="S4.SS4.p1.1.m1.2.3.2.2" xref="S4.SS4.p1.1.m1.2.3.2.2.cmml">T</mi><mo id="S4.SS4.p1.1.m1.2.3.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS4.p1.1.m1.2.3.2.1.cmml">Ã—</mo><mi id="S4.SS4.p1.1.m1.2.3.2.3" xref="S4.SS4.p1.1.m1.2.3.2.3.cmml">B</mi></mrow><mo id="S4.SS4.p1.1.m1.2.3.1" xref="S4.SS4.p1.1.m1.2.3.1.cmml">âˆˆ</mo><mrow id="S4.SS4.p1.1.m1.2.3.3.2" xref="S4.SS4.p1.1.m1.2.3.3.1.cmml"><mo id="S4.SS4.p1.1.m1.2.3.3.2.1" stretchy="false" xref="S4.SS4.p1.1.m1.2.3.3.1.cmml">[</mo><mn id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">0</mn><mo id="S4.SS4.p1.1.m1.2.3.3.2.2" xref="S4.SS4.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S4.SS4.p1.1.m1.2.2" xref="S4.SS4.p1.1.m1.2.2.cmml">6000</mn><mo id="S4.SS4.p1.1.m1.2.3.3.2.3" stretchy="false" xref="S4.SS4.p1.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.2b"><apply id="S4.SS4.p1.1.m1.2.3.cmml" xref="S4.SS4.p1.1.m1.2.3"><in id="S4.SS4.p1.1.m1.2.3.1.cmml" xref="S4.SS4.p1.1.m1.2.3.1"></in><apply id="S4.SS4.p1.1.m1.2.3.2.cmml" xref="S4.SS4.p1.1.m1.2.3.2"><times id="S4.SS4.p1.1.m1.2.3.2.1.cmml" xref="S4.SS4.p1.1.m1.2.3.2.1"></times><ci id="S4.SS4.p1.1.m1.2.3.2.2.cmml" xref="S4.SS4.p1.1.m1.2.3.2.2">ğ‘‡</ci><ci id="S4.SS4.p1.1.m1.2.3.2.3.cmml" xref="S4.SS4.p1.1.m1.2.3.2.3">ğµ</ci></apply><interval closure="closed" id="S4.SS4.p1.1.m1.2.3.3.1.cmml" xref="S4.SS4.p1.1.m1.2.3.3.2"><cn id="S4.SS4.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS4.p1.1.m1.1.1">0</cn><cn id="S4.SS4.p1.1.m1.2.2.cmml" type="integer" xref="S4.SS4.p1.1.m1.2.2">6000</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.2c">T\times B\in[0,6000]</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.2d">italic_T Ã— italic_B âˆˆ [ 0 , 6000 ]</annotation></semantics></math>. At <math alttext="T\times B=6000" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.1"><semantics id="S4.SS4.p1.2.m2.1a"><mrow id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml"><mrow id="S4.SS4.p1.2.m2.1.1.2" xref="S4.SS4.p1.2.m2.1.1.2.cmml"><mi id="S4.SS4.p1.2.m2.1.1.2.2" xref="S4.SS4.p1.2.m2.1.1.2.2.cmml">T</mi><mo id="S4.SS4.p1.2.m2.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS4.p1.2.m2.1.1.2.1.cmml">Ã—</mo><mi id="S4.SS4.p1.2.m2.1.1.2.3" xref="S4.SS4.p1.2.m2.1.1.2.3.cmml">B</mi></mrow><mo id="S4.SS4.p1.2.m2.1.1.1" xref="S4.SS4.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS4.p1.2.m2.1.1.3" xref="S4.SS4.p1.2.m2.1.1.3.cmml">6000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><apply id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1"><eq id="S4.SS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1.1"></eq><apply id="S4.SS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2"><times id="S4.SS4.p1.2.m2.1.1.2.1.cmml" xref="S4.SS4.p1.2.m2.1.1.2.1"></times><ci id="S4.SS4.p1.2.m2.1.1.2.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2.2">ğ‘‡</ci><ci id="S4.SS4.p1.2.m2.1.1.2.3.cmml" xref="S4.SS4.p1.2.m2.1.1.2.3">ğµ</ci></apply><cn id="S4.SS4.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS4.p1.2.m2.1.1.3">6000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">T\times B=6000</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.2.m2.1d">italic_T Ã— italic_B = 6000</annotation></semantics></math>, we switch the base LLM to GPT-4. During this transition, we evaluate two configurations: <span class="ltx_text ltx_font_bold" id="S4.SS4.p1.3.1">Continue</span> and <span class="ltx_text ltx_font_bold" id="S4.SS4.p1.3.2">Reset</span>. The Continue configuration maintains the internal state parameters (e.g., <math alttext="Q_{t}(a)" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.1"><semantics id="S4.SS4.p1.3.m3.1a"><mrow id="S4.SS4.p1.3.m3.1.2" xref="S4.SS4.p1.3.m3.1.2.cmml"><msub id="S4.SS4.p1.3.m3.1.2.2" xref="S4.SS4.p1.3.m3.1.2.2.cmml"><mi id="S4.SS4.p1.3.m3.1.2.2.2" xref="S4.SS4.p1.3.m3.1.2.2.2.cmml">Q</mi><mi id="S4.SS4.p1.3.m3.1.2.2.3" xref="S4.SS4.p1.3.m3.1.2.2.3.cmml">t</mi></msub><mo id="S4.SS4.p1.3.m3.1.2.1" xref="S4.SS4.p1.3.m3.1.2.1.cmml">â¢</mo><mrow id="S4.SS4.p1.3.m3.1.2.3.2" xref="S4.SS4.p1.3.m3.1.2.cmml"><mo id="S4.SS4.p1.3.m3.1.2.3.2.1" stretchy="false" xref="S4.SS4.p1.3.m3.1.2.cmml">(</mo><mi id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">a</mi><mo id="S4.SS4.p1.3.m3.1.2.3.2.2" stretchy="false" xref="S4.SS4.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><apply id="S4.SS4.p1.3.m3.1.2.cmml" xref="S4.SS4.p1.3.m3.1.2"><times id="S4.SS4.p1.3.m3.1.2.1.cmml" xref="S4.SS4.p1.3.m3.1.2.1"></times><apply id="S4.SS4.p1.3.m3.1.2.2.cmml" xref="S4.SS4.p1.3.m3.1.2.2"><csymbol cd="ambiguous" id="S4.SS4.p1.3.m3.1.2.2.1.cmml" xref="S4.SS4.p1.3.m3.1.2.2">subscript</csymbol><ci id="S4.SS4.p1.3.m3.1.2.2.2.cmml" xref="S4.SS4.p1.3.m3.1.2.2.2">ğ‘„</ci><ci id="S4.SS4.p1.3.m3.1.2.2.3.cmml" xref="S4.SS4.p1.3.m3.1.2.2.3">ğ‘¡</ci></apply><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">Q_{t}(a)</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.3.m3.1d">italic_Q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_a )</annotation></semantics></math>) from Eq.Â (<a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S3.E2" title="In 3.1 Problem Formulation â€£ 3 Methodology â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>), effectively providing a warm start for later parameter search in GPT-4. In contrast, the Reset configuration initializes these parameters anew, simulating a cold start.</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="184" id="S4.F8.g1" src="extracted/5694705/figures/demo_model_change_seed_0.png" width="419"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Evolution of an example three-parameter search in Hier-UCB when the base LLM is upgraded from GPT-3.5-Turbo (left) to GPT-4 (right), using the ASQA dataset, <math alttext="w=0.5" class="ltx_Math" display="inline" id="S4.F8.4.m1.1"><semantics id="S4.F8.4.m1.1b"><mrow id="S4.F8.4.m1.1.1" xref="S4.F8.4.m1.1.1.cmml"><mi id="S4.F8.4.m1.1.1.2" xref="S4.F8.4.m1.1.1.2.cmml">w</mi><mo id="S4.F8.4.m1.1.1.1" xref="S4.F8.4.m1.1.1.1.cmml">=</mo><mn id="S4.F8.4.m1.1.1.3" xref="S4.F8.4.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.4.m1.1c"><apply id="S4.F8.4.m1.1.1.cmml" xref="S4.F8.4.m1.1.1"><eq id="S4.F8.4.m1.1.1.1.cmml" xref="S4.F8.4.m1.1.1.1"></eq><ci id="S4.F8.4.m1.1.1.2.cmml" xref="S4.F8.4.m1.1.1.2">ğ‘¤</ci><cn id="S4.F8.4.m1.1.1.3.cmml" type="float" xref="S4.F8.4.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.4.m1.1d">w=0.5</annotation><annotation encoding="application/x-llamapun" id="S4.F8.4.m1.1e">italic_w = 0.5</annotation></semantics></math>, <math alttext="\alpha^{h}=\alpha^{l}=1" class="ltx_Math" display="inline" id="S4.F8.5.m2.1"><semantics id="S4.F8.5.m2.1b"><mrow id="S4.F8.5.m2.1.1" xref="S4.F8.5.m2.1.1.cmml"><msup id="S4.F8.5.m2.1.1.2" xref="S4.F8.5.m2.1.1.2.cmml"><mi id="S4.F8.5.m2.1.1.2.2" xref="S4.F8.5.m2.1.1.2.2.cmml">Î±</mi><mi id="S4.F8.5.m2.1.1.2.3" xref="S4.F8.5.m2.1.1.2.3.cmml">h</mi></msup><mo id="S4.F8.5.m2.1.1.3" xref="S4.F8.5.m2.1.1.3.cmml">=</mo><msup id="S4.F8.5.m2.1.1.4" xref="S4.F8.5.m2.1.1.4.cmml"><mi id="S4.F8.5.m2.1.1.4.2" xref="S4.F8.5.m2.1.1.4.2.cmml">Î±</mi><mi id="S4.F8.5.m2.1.1.4.3" xref="S4.F8.5.m2.1.1.4.3.cmml">l</mi></msup><mo id="S4.F8.5.m2.1.1.5" xref="S4.F8.5.m2.1.1.5.cmml">=</mo><mn id="S4.F8.5.m2.1.1.6" xref="S4.F8.5.m2.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.5.m2.1c"><apply id="S4.F8.5.m2.1.1.cmml" xref="S4.F8.5.m2.1.1"><and id="S4.F8.5.m2.1.1a.cmml" xref="S4.F8.5.m2.1.1"></and><apply id="S4.F8.5.m2.1.1b.cmml" xref="S4.F8.5.m2.1.1"><eq id="S4.F8.5.m2.1.1.3.cmml" xref="S4.F8.5.m2.1.1.3"></eq><apply id="S4.F8.5.m2.1.1.2.cmml" xref="S4.F8.5.m2.1.1.2"><csymbol cd="ambiguous" id="S4.F8.5.m2.1.1.2.1.cmml" xref="S4.F8.5.m2.1.1.2">superscript</csymbol><ci id="S4.F8.5.m2.1.1.2.2.cmml" xref="S4.F8.5.m2.1.1.2.2">ğ›¼</ci><ci id="S4.F8.5.m2.1.1.2.3.cmml" xref="S4.F8.5.m2.1.1.2.3">â„</ci></apply><apply id="S4.F8.5.m2.1.1.4.cmml" xref="S4.F8.5.m2.1.1.4"><csymbol cd="ambiguous" id="S4.F8.5.m2.1.1.4.1.cmml" xref="S4.F8.5.m2.1.1.4">superscript</csymbol><ci id="S4.F8.5.m2.1.1.4.2.cmml" xref="S4.F8.5.m2.1.1.4.2">ğ›¼</ci><ci id="S4.F8.5.m2.1.1.4.3.cmml" xref="S4.F8.5.m2.1.1.4.3">ğ‘™</ci></apply></apply><apply id="S4.F8.5.m2.1.1c.cmml" xref="S4.F8.5.m2.1.1"><eq id="S4.F8.5.m2.1.1.5.cmml" xref="S4.F8.5.m2.1.1.5"></eq><share href="https://arxiv.org/html/2406.19251v1#S4.F8.5.m2.1.1.4.cmml" id="S4.F8.5.m2.1.1d.cmml" xref="S4.F8.5.m2.1.1"></share><cn id="S4.F8.5.m2.1.1.6.cmml" type="integer" xref="S4.F8.5.m2.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.5.m2.1d">\alpha^{h}=\alpha^{l}=1</annotation><annotation encoding="application/x-llamapun" id="S4.F8.5.m2.1e">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT = italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 1</annotation></semantics></math>, and <math alttext="B=1" class="ltx_Math" display="inline" id="S4.F8.6.m3.1"><semantics id="S4.F8.6.m3.1b"><mrow id="S4.F8.6.m3.1.1" xref="S4.F8.6.m3.1.1.cmml"><mi id="S4.F8.6.m3.1.1.2" xref="S4.F8.6.m3.1.1.2.cmml">B</mi><mo id="S4.F8.6.m3.1.1.1" xref="S4.F8.6.m3.1.1.1.cmml">=</mo><mn id="S4.F8.6.m3.1.1.3" xref="S4.F8.6.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F8.6.m3.1c"><apply id="S4.F8.6.m3.1.1.cmml" xref="S4.F8.6.m3.1.1"><eq id="S4.F8.6.m3.1.1.1.cmml" xref="S4.F8.6.m3.1.1.1"></eq><ci id="S4.F8.6.m3.1.1.2.cmml" xref="S4.F8.6.m3.1.1.2">ğµ</ci><cn id="S4.F8.6.m3.1.1.3.cmml" type="integer" xref="S4.F8.6.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.6.m3.1d">B=1</annotation><annotation encoding="application/x-llamapun" id="S4.F8.6.m3.1e">italic_B = 1</annotation></semantics></math>. The Y-axis represents the ranking of parameter combinations for each base LLM taking from Grid Search, with lower values indicating higher rankings. Two different configurations of Continue and Reset are considered during the parameter search in GPT-4.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.3">FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F8" title="Figure 8 â€£ 4.4 Case Study: Upgrade Base LLM from GPT-3.5-Turbo to GPT-4 â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates a three-parameter search trajectory during the model transition from GPT-3.5-Turbo to GPT-4, using the ASQA dataset. The parameters are set as <math alttext="w=0.5" class="ltx_Math" display="inline" id="S4.SS4.p2.1.m1.1"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mi id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml">w</mi><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.p2.1.m1.1.1.3" xref="S4.SS4.p2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><eq id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1"></eq><ci id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">ğ‘¤</ci><cn id="S4.SS4.p2.1.m1.1.1.3.cmml" type="float" xref="S4.SS4.p2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">w=0.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.1.m1.1d">italic_w = 0.5</annotation></semantics></math>, <math alttext="\alpha^{h}=\alpha^{l}=1" class="ltx_Math" display="inline" id="S4.SS4.p2.2.m2.1"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml"><msup id="S4.SS4.p2.2.m2.1.1.2" xref="S4.SS4.p2.2.m2.1.1.2.cmml"><mi id="S4.SS4.p2.2.m2.1.1.2.2" xref="S4.SS4.p2.2.m2.1.1.2.2.cmml">Î±</mi><mi id="S4.SS4.p2.2.m2.1.1.2.3" xref="S4.SS4.p2.2.m2.1.1.2.3.cmml">h</mi></msup><mo id="S4.SS4.p2.2.m2.1.1.3" xref="S4.SS4.p2.2.m2.1.1.3.cmml">=</mo><msup id="S4.SS4.p2.2.m2.1.1.4" xref="S4.SS4.p2.2.m2.1.1.4.cmml"><mi id="S4.SS4.p2.2.m2.1.1.4.2" xref="S4.SS4.p2.2.m2.1.1.4.2.cmml">Î±</mi><mi id="S4.SS4.p2.2.m2.1.1.4.3" xref="S4.SS4.p2.2.m2.1.1.4.3.cmml">l</mi></msup><mo id="S4.SS4.p2.2.m2.1.1.5" xref="S4.SS4.p2.2.m2.1.1.5.cmml">=</mo><mn id="S4.SS4.p2.2.m2.1.1.6" xref="S4.SS4.p2.2.m2.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><apply id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1"><and id="S4.SS4.p2.2.m2.1.1a.cmml" xref="S4.SS4.p2.2.m2.1.1"></and><apply id="S4.SS4.p2.2.m2.1.1b.cmml" xref="S4.SS4.p2.2.m2.1.1"><eq id="S4.SS4.p2.2.m2.1.1.3.cmml" xref="S4.SS4.p2.2.m2.1.1.3"></eq><apply id="S4.SS4.p2.2.m2.1.1.2.cmml" xref="S4.SS4.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.p2.2.m2.1.1.2.1.cmml" xref="S4.SS4.p2.2.m2.1.1.2">superscript</csymbol><ci id="S4.SS4.p2.2.m2.1.1.2.2.cmml" xref="S4.SS4.p2.2.m2.1.1.2.2">ğ›¼</ci><ci id="S4.SS4.p2.2.m2.1.1.2.3.cmml" xref="S4.SS4.p2.2.m2.1.1.2.3">â„</ci></apply><apply id="S4.SS4.p2.2.m2.1.1.4.cmml" xref="S4.SS4.p2.2.m2.1.1.4"><csymbol cd="ambiguous" id="S4.SS4.p2.2.m2.1.1.4.1.cmml" xref="S4.SS4.p2.2.m2.1.1.4">superscript</csymbol><ci id="S4.SS4.p2.2.m2.1.1.4.2.cmml" xref="S4.SS4.p2.2.m2.1.1.4.2">ğ›¼</ci><ci id="S4.SS4.p2.2.m2.1.1.4.3.cmml" xref="S4.SS4.p2.2.m2.1.1.4.3">ğ‘™</ci></apply></apply><apply id="S4.SS4.p2.2.m2.1.1c.cmml" xref="S4.SS4.p2.2.m2.1.1"><eq id="S4.SS4.p2.2.m2.1.1.5.cmml" xref="S4.SS4.p2.2.m2.1.1.5"></eq><share href="https://arxiv.org/html/2406.19251v1#S4.SS4.p2.2.m2.1.1.4.cmml" id="S4.SS4.p2.2.m2.1.1d.cmml" xref="S4.SS4.p2.2.m2.1.1"></share><cn id="S4.SS4.p2.2.m2.1.1.6.cmml" type="integer" xref="S4.SS4.p2.2.m2.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">\alpha^{h}=\alpha^{l}=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.2.m2.1d">italic_Î± start_POSTSUPERSCRIPT italic_h end_POSTSUPERSCRIPT = italic_Î± start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 1</annotation></semantics></math>, and <math alttext="B=1" class="ltx_Math" display="inline" id="S4.SS4.p2.3.m3.1"><semantics id="S4.SS4.p2.3.m3.1a"><mrow id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml"><mi id="S4.SS4.p2.3.m3.1.1.2" xref="S4.SS4.p2.3.m3.1.1.2.cmml">B</mi><mo id="S4.SS4.p2.3.m3.1.1.1" xref="S4.SS4.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS4.p2.3.m3.1.1.3" xref="S4.SS4.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><apply id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1"><eq id="S4.SS4.p2.3.m3.1.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1.1"></eq><ci id="S4.SS4.p2.3.m3.1.1.2.cmml" xref="S4.SS4.p2.3.m3.1.1.2">ğµ</ci><cn id="S4.SS4.p2.3.m3.1.1.3.cmml" type="integer" xref="S4.SS4.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">B=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.3.m3.1d">italic_B = 1</annotation></semantics></math>. The Y-axis represents the ranking of parameter combinations for each base LLM taking from Grid Search, with lower values indicating higher rankings. In the first half of the process (left subplot), the Hier-UCB method effectively identifies optimal parameter combinations, evidenced by the clustering of parameters at the top in later timestamps. After transitioning to GPT-4, the Hier-UCB method quickly adapts under the Continue configuration, focusing on higher-ranked parameter combinations. However, under the Reset configuration, it explores more lower-ranked combinations, suggesting a need for additional exploration to find the optimal parameters.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">To highlight the superior performance of the Continue configuration, FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F9" title="Figure 9 â€£ 4.4 Case Study: Upgrade Base LLM from GPT-3.5-Turbo to GPT-4 â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">9</span></a> presents the mean Recall@5 metric for 10 random trials. It reveals that the Continue configuration not only converges faster but also achieves significantly higher Recall@5 values. In summary, this experiment indicates that maintaining internal parameters during system changes can enhance the Hier-UCB methodâ€™s adaptability and effectiveness.</p>
</div>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="225" id="S4.F9.g1" src="extracted/5694705/figures/demo_model_change_metric.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Evolution of the mean Recall@5 metric for 10 random trials. The other settings are the same as those in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#S4.F8" title="Figure 8 â€£ 4.4 Case Study: Upgrade Base LLM from GPT-3.5-Turbo to GPT-4 â€£ 4 Evaluation â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">8</span></a>.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we address online optimization in RAG systems by framing hyper-parameter tuning as an online Multi-Armed Bandit problem. Our proposed Hier-MAB approach can be extended to offline hyper-parameter tuning, demonstrating greater efficiency than traditional Grid Search methods, especially in scenarios with large search spaces with steep gradients. Hier-MAB can also serve as an initial step to filter the search space, followed by a more extensive parameter scan.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Our approach can be applied to a broader range of tunable hyper-parameters. While we focus on hyper-parameters in retrieval and prompt compression modules, it is extendable to other RAG modules such as document chunk size in indexing module, LLM API settings, or other LLM-based solutions (e.g., agent frameworks). Due to computational constraints, exhaustive searches for optimal configurations as the ground-truth are challenging, limiting the feasibility of experiments across broader hyper-parameter combinations.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">The reward settings in our work can also be expanded. Currently, we assume the reward is a linear combination of accuracy and input token length, with a user-defined weight parameter allowing users to adjust the weight parameter <math alttext="w" class="ltx_Math" display="inline" id="S5.p3.1.m1.1"><semantics id="S5.p3.1.m1.1a"><mi id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><ci id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S5.p3.1.m1.1d">italic_w</annotation></semantics></math>. However, determining the right parameter to balance accuracy and LLM API cost is challenging in reality. An alternative is to set LLM API cost constraints and optimize accuracy within these constraints, incorporating cost constraints as penalty terms in the reward function. This converts a multi-objective optimization problem into a single-objective one, though exploring Pareto optimization within RAG could also yield valuable insights.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Our current reward framework only considers feedback from the correctness of the final response. In practice, feedback might also come from intermediate steps (e.g., document relevance evaluation in retrieval modules) or multiple sources in multi-turn dialogues. Thus, automatically and efficiently integrating these additional feedback sources into the reward definition is also worth exploration.</p>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">Beyond hyper-parameter tuning, developing a comprehensive AutoML framework for RAG involves identifying the optimal combination of available RAG modules, automated prompt tuning and other query-dependent parameters, such as those in a routing module that directs queries to appropriate base LLMs. Additionally, an ideal AutoRAG system should auto-generate evaluation data for tuning as needed, supporting the â€œBring Your Dataâ€ vision where users provide their data, and the platform autonomously configures the entire pipeline to meet their specific requirements. Future work will explore these areas.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Summary</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Inspired by traditional AutoML practices designed to simplify and automate ML/AI development, we introduce the AutoRAG-HP framework. This framework addresses the critical need for efficient and effortless hyper-parameter tuning within the Retrieval-Augmented Generation (RAG) system in the context of LLMs. To address challenges posed by extensive search spaces and the need for online tuning, we formulate hyper-parameter selection in RAG as a multi-armed bandit problem and introduce a novel two-level hierarchical Upper Confidence Bound (Hier-UCB) method for efficient parameter space exploration.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.2">Our experiments on simultaneously tuning three hyper-parameters demonstrate that multi-armed bandit-based online learning methods (Hier-UCB, UCB, and TS) can achieve Recall@5 <math alttext="\approx 0.8" class="ltx_Math" display="inline" id="S6.p2.1.m1.1"><semantics id="S6.p2.1.m1.1a"><mrow id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml"><mi id="S6.p2.1.m1.1.1.2" xref="S6.p2.1.m1.1.1.2.cmml"></mi><mo id="S6.p2.1.m1.1.1.1" xref="S6.p2.1.m1.1.1.1.cmml">â‰ˆ</mo><mn id="S6.p2.1.m1.1.1.3" xref="S6.p2.1.m1.1.1.3.cmml">0.8</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><apply id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1"><approx id="S6.p2.1.m1.1.1.1.cmml" xref="S6.p2.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S6.p2.1.m1.1.1.2.cmml" xref="S6.p2.1.m1.1.1.2">absent</csymbol><cn id="S6.p2.1.m1.1.1.3.cmml" type="float" xref="S6.p2.1.m1.1.1.3">0.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">\approx 0.8</annotation><annotation encoding="application/x-llamapun" id="S6.p2.1.m1.1d">â‰ˆ 0.8</annotation></semantics></math> for scenarios with prominent gradients in search space, using only <math alttext="\sim 20\%" class="ltx_Math" display="inline" id="S6.p2.2.m2.1"><semantics id="S6.p2.2.m2.1a"><mrow id="S6.p2.2.m2.1.1" xref="S6.p2.2.m2.1.1.cmml"><mi id="S6.p2.2.m2.1.1.2" xref="S6.p2.2.m2.1.1.2.cmml"></mi><mo id="S6.p2.2.m2.1.1.1" xref="S6.p2.2.m2.1.1.1.cmml">âˆ¼</mo><mrow id="S6.p2.2.m2.1.1.3" xref="S6.p2.2.m2.1.1.3.cmml"><mn id="S6.p2.2.m2.1.1.3.2" xref="S6.p2.2.m2.1.1.3.2.cmml">20</mn><mo id="S6.p2.2.m2.1.1.3.1" xref="S6.p2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p2.2.m2.1b"><apply id="S6.p2.2.m2.1.1.cmml" xref="S6.p2.2.m2.1.1"><csymbol cd="latexml" id="S6.p2.2.m2.1.1.1.cmml" xref="S6.p2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.p2.2.m2.1.1.2.cmml" xref="S6.p2.2.m2.1.1.2">absent</csymbol><apply id="S6.p2.2.m2.1.1.3.cmml" xref="S6.p2.2.m2.1.1.3"><csymbol cd="latexml" id="S6.p2.2.m2.1.1.3.1.cmml" xref="S6.p2.2.m2.1.1.3.1">percent</csymbol><cn id="S6.p2.2.m2.1.1.3.2.cmml" type="integer" xref="S6.p2.2.m2.1.1.3.2">20</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.2.m2.1c">\sim 20\%</annotation><annotation encoding="application/x-llamapun" id="S6.p2.2.m2.1d">âˆ¼ 20 %</annotation></semantics></math> of the LLM API calls required by the Grid Search approach. Additionally, the proposed Hier-UCB approach outperforms other baselines in more challenging optimization scenarios. These promising results motivate further exploration into automatic tuning of the RAG system to achieve the full vision of AutoRAG.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We acknowledge the limitations of this paper.
First, we evaluate AutoRAG-HP using only two LLMs as backbones. Additional experiments can be done to assess AutoRAG-HPâ€™s performance with other LLMs as well as small language models. Secondly, our experiments are limited to two public datasets in QA format. Further testing can be done across diverse tasks and datasets.
Finally, we only explore jointly tuning of up to three hyper-parameters and further exploration can be extended to include tuning a greater number of hyper-parameters, which we will leave for future work.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This paper focuses on hyper-parameter optimization and does not inherently address potential risks associated with the underlying LLMs, such as unethical outputs, toxicity, and biases. We strongly recommend integrating Responsible AI modules within the RAG pipeline and conducting a comprehensive evaluation of these potential issues prior to deployment in practice.</p>
</div>
</section>
<section class="ltx_section" id="Sx3">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">We would like to thank Henry Zeng and Victor RÃ¼hle for insightful discussion on building efficient RAG solutions. We are also indebted to Qianhui Wu, Huiqiang Jiang and Bo Qiao for their help in establishing the prompt compression API.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal and Goyal (2013)</span>
<span class="ltx_bibblock">
Shipra Agrawal and Navin Goyal. 2013.

</span>
<span class="ltx_bibblock">Thompson sampling for contextual bandits with linear payoffs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">International conference on machine learning</em>, pages 127â€“135. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Auer (2002)</span>
<span class="ltx_bibblock">
Peter Auer. 2002.

</span>
<span class="ltx_bibblock">Using confidence bounds for exploitation-exploration trade-offs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Journal of Machine Learning Research</em>, 3(Nov):397â€“422.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Auer etÂ al. (2002)</span>
<span class="ltx_bibblock">
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002.

</span>
<span class="ltx_bibblock">Finite-time analysis of the multiarmed bandit problem.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Machine learning</em>, 47:235â€“256.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra etÂ al. (2011a)</span>
<span class="ltx_bibblock">
James Bergstra, RÃ©mi Bardenet, Yoshua Bengio, and BalÃ¡zs KÃ©gl. 2011a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:11688126" title="">Algorithms for hyper-parameter optimization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Neural Information Processing Systems</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra etÂ al. (2011b)</span>
<span class="ltx_bibblock">
James Bergstra, RÃ©mi Bardenet, Yoshua Bengio, and BalÃ¡zs KÃ©gl. 2011b.

</span>
<span class="ltx_bibblock">Algorithms for hyper-parameter optimization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 24th International Conference on Neural Information Processing Systems</em>, NIPSâ€™11, page 2546â€“2554, Red Hook, NY, USA. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra and Bengio (2012a)</span>
<span class="ltx_bibblock">
James Bergstra and Yoshua Bengio. 2012a.

</span>
<span class="ltx_bibblock">Random search for hyper-parameter optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">J. Mach. Learn. Res.</em>, 13(null):281â€“305.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra and Bengio (2012b)</span>
<span class="ltx_bibblock">
James Bergstra and Yoshua Bengio. 2012b.

</span>
<span class="ltx_bibblock">Random search for hyper-parameter optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Journal of machine learning research</em>, 13(2).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 33, pages 1877â€“1901. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chapelle and Li (2011)</span>
<span class="ltx_bibblock">
Olivier Chapelle and Lihong Li. 2011.

</span>
<span class="ltx_bibblock">An empirical evaluation of thompson sampling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Advances in neural information processing systems</em>, 24.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding etÂ al. (2024)</span>
<span class="ltx_bibblock">
Dujian Ding, Ankur Mallick, Chi Wang, Robert Sim, Subhabrata Mukherjee, Victor Ruehle, Laks V.Â S. Lakshmanan, and Ahmed Awadallah. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.microsoft.com/en-us/research/publication/hybrid-llm-cost-efficient-and-quality-aware-query-routing/" title="">Hybrid llm: Cost-efficient and quality-aware query routing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">ICLR 2024</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feurer etÂ al. (2015)</span>
<span class="ltx_bibblock">
Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, and Frank Hutter. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf" title="">Efficient and robust automated machine learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 28. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.398" title="">Enabling large language models to generate text with citations</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 6465â€“6488.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hutter etÂ al. (2019)</span>
<span class="ltx_bibblock">
Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:263984018" title="">Automated machine learning: Methods, systems, challenges</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Automated Machine Learning</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard etÂ al. (2021)</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2112.09118" title="">Unsupervised dense information retrieval with contrastive learning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2208.03299" title="">Atlas: Few-shot learning with retrieval augmented language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.05736" title="">Llmlingua: Compressing prompts for accelerated inference of large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Preprint</em>, arXiv:2310.05736.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, FrankÂ F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2305.06983" title="">Active retrieval augmented generation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Haifeng Jin, FranÃ§ois Chollet, Qingquan Song, and Xia Hu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v24/20-1355.html" title="">Autokeras: An automl library for deep learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Journal of Machine Learning Research</em>, 24(6):1â€“6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski etÂ al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, AndrewÂ M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00276" title="">Natural Questions: A Benchmark for Question Answering Research</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Transactions of the Association for Computational Linguistics</em>, 7:453â€“466.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai and Robbins (1985)</span>
<span class="ltx_bibblock">
TzeÂ Leung Lai and Herbert Robbins. 1985.

</span>
<span class="ltx_bibblock">Asymptotically efficient adaptive allocation rules.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in applied mathematics</em>, 6(1):4â€“22.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lecun etÂ al. (1998)</span>
<span class="ltx_bibblock">
Y.Â Lecun, L.Â Bottou, Y.Â Bengio, and P.Â Haffner. 1998.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/5.726791" title="">Gradient-based learning applied to document recognition</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the IEEE</em>, 86(11):2278â€“2324.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf" title="">Retrieval-augmented generation for knowledge-intensive nlp tasks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 33, pages 9459â€“9474. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2010)</span>
<span class="ltx_bibblock">
Lihong Li, Wei Chu, John Langford, and RobertÂ E Schapire. 2010.

</span>
<span class="ltx_bibblock">A contextual-bandit approach to personalized news article recommendation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 19th international conference on World wide web</em>, pages 661â€“670.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Wang (2021)</span>
<span class="ltx_bibblock">
Xueqing Liu and Chi Wang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:235458576" title="">An empirical study on hyperparameter optimization for fine-tuning pre-trained language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Yuanjie Lyu, Zhiyu Li, Simin Niu, Feiyu Xiong, BoÂ Tang, Wenjin Wang, Hao Wu, Huanyong Liu, Tong Xu, Enhong Chen, YiÂ Luo, Peng Cheng, Haiying Deng, Zhonghao Wang, and Zijia Lu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.17043" title="">Crud-rag: A comprehensive chinese benchmark for retrieval-augmented generation of large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2401.17043.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2023)</span>
<span class="ltx_bibblock">
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2305.14283" title="">Query rewriting for retrieval-augmented large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marker-Inc-Korea (2024)</span>
<span class="ltx_bibblock">
Marker-Inc-Korea. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/Marker-Inc-Korea/AutoRAG" title="">https://github.com/marker-inc-korea/autorag</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olson etÂ al. (2016)</span>
<span class="ltx_bibblock">
RandalÂ S. Olson, Nathan Bartley, RyanÂ J. Urbanowicz, and JasonÂ H. Moore. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2908812.2908918" title="">Evaluation of a tree-based pipeline optimization tool for automating data science</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the Genetic and Evolutionary Computation Conference 2016</em>, GECCO â€™16, pages 485â€“492, New York, NY, USA. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openai.com/index/new-and-improved-embedding-model/" title="">https://openai.com/index/new-and-improved-embedding-model/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.08774" title="">Gpt-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Preprint</em>, arXiv:2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, XuÂ Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, PaulÂ F Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf" title="">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Advances in Neural Information Processing Systems</em>, volumeÂ 35, pages 27730â€“27744. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan etÂ al. (2024)</span>
<span class="ltx_bibblock">
Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor RÃ¼hle, Yuqing Yang, Chin-Yew Lin, H.Â Vicky Zhao, Lili Qiu, Dongmei Zhang, Karl Cobbe, Vineet Kosaraju, MoÂ Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, and Reiichiro Nakano. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:268531237" title="">Llmlingua-2: Data distillation for efficient and faithful task-agnostic prompt compression</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">ArXiv</em>, abs/2403.12968.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pryzant etÂ al. (2023)</span>
<span class="ltx_bibblock">
Reid Pryzant, Dan Iter, Jerry Li, Yin Lee, Chenguang Zhu, and Michael Zeng. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.494" title="">Automatic prompt optimization with â€œgradient descentâ€ and beam search</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 7957â€“7968, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarah etÂ al. (2024)</span>
<span class="ltx_bibblock">
Anthony Sarah, SharathÂ Nittur Sridhar, Maciej Szankin, and Sairam Sundaresan. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2405.18377" title="">Llama-nas: Efficient neural architecture search for large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kaitao Song, XuÂ Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2004.09297" title="">Mpnet: Masked and permuted pre-training for language understanding</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tornede etÂ al. (2024)</span>
<span class="ltx_bibblock">
Alexander Tornede, Difan Deng, Theresa Eimer, Joseph Giovanelli, Aditya Mohan, Tim Ruhkopf, Sarah Segel, Daphne Theodorakopoulos, Tanja Tornede, Henning Wachsmuth, and Marius Lindauer. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=cAthubStyG" title="">AutoML in the age of large language models: Current challenges, future opportunities and risks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Transactions on Machine Learning Research</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Treviso etÂ al. (2022)</span>
<span class="ltx_bibblock">
Marcos Treviso, Ji-Ung Lee, Tianchu Ji, Betty van Aken, Qingqing Cao, ManuelÂ R. Ciosici, Michael Hassid, Kenneth Heafield, Sara Hooker, Colin Raffel, PedroÂ H. Martins, AndrÃ© F.Â T. Martins, JessicaÂ Zosa Forde, Peter Milder, Edwin Simpson, Noam Slonim, Jesse Dodge, Emma Strubell, Niranjan Balasubramanian, Leon Derczynski, Iryna Gurevych, and Roy Schwartz. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2209.00099" title="">Efficient methods for natural language processing: A survey</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vermorel and Mohri (2005)</span>
<span class="ltx_bibblock">
Joannes Vermorel and Mehryar Mohri. 2005.

</span>
<span class="ltx_bibblock">Multi-armed bandit algorithms and empirical evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">European conference on machine learning</em>, pages 437â€“448. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Chi Wang, SusanÂ Xueqing Liu, and AhmedÂ H. Awadallah. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:2303.04673" title="">Cost-effective hyperparameter optimization for large language model generation inference</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Chi Wang, Qingyun Wu, Silu Huang, and Amin Saied. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=VbLH04pRA3" title="">ECONOMIC HYPERPARAMETER OPTIMIZATION WITH BLENDED SEARCH STRATEGY</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/arXiv:1911.04706" title="">Flaml: A fast and lightweight automl library</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, and Furu Wei. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.585" title="">Query2doc: Query expansion with large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 9414â€“9423, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zimmer etÂ al. (2021)</span>
<span class="ltx_bibblock">
Lucas Zimmer, Marius Lindauer, and Frank Hutter. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TPAMI.2021.3067763" title="">Auto-pytorch: Multi-fidelity metalearning for efficient and robust autodl</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 43(9):3079â€“3090.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Grid Search Results</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Grid Search results for the ASQA dataset with GPT-3.5-Turbo is shown in FiguresÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A1.F10" title="Figure 10 â€£ Appendix A Grid Search Results â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">10</span></a>. Grid Search results for the NQ dataset with GPT-4 and GPT-3.5-Turbo are shown in FiguresÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A1.F11" title="Figure 11 â€£ Appendix A Grid Search Results â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">11</span></a> and FiguresÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A1.F12" title="Figure 12 â€£ Appendix A Grid Search Results â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">12</span></a>, respectively.</p>
</div>
<figure class="ltx_figure" id="A1.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="997" id="A1.F10.g1" src="extracted/5694705/figures/gt_asqa_35.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Grid search results for ASQA with GPT-3.5-Turbo. Error bars represent the standard deviations of accuracy and reward values across all batches.</figcaption>
</figure>
<figure class="ltx_figure" id="A1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="997" id="A1.F11.g1" src="extracted/5694705/figures/gt_nq_4.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Grid search results for NQ with GPT-4. Error bars represent the standard deviations of accuracy and reward values across all batches.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_figure" id="A1.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="997" id="A1.F12.g1" src="extracted/5694705/figures/gt_nq_35.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Grid search results for NQ with GPT-3.5-Turbo. Error bars represent the standard deviations of accuracy and reward values across all batches.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experiment Result with GPT-3.5</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">In FiguresÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A2.F13" title="Figure 13 â€£ Appendix B Experiment Result with GPT-3.5 â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">13</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A2.F14" title="Figure 14 â€£ Appendix B Experiment Result with GPT-3.5 â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">14</span></a>, we plot the the experimental results with GPT-3.5, <em class="ltx_emph ltx_font_italic" id="A2.p1.1.1">i.e.</em>, evolution of Recall@x metric over the iteration process for the 2-parameter and 3-parameter optimization cases, respectively.</p>
</div>
<figure class="ltx_figure" id="A2.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="498" id="A2.F13.g1" src="extracted/5694705/figures/ASQA_gpt35_2_param_alpha_1-NQ_gpt35_2_param_alpha_1_topk_3_interval_100.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Evolution of Recall@3 in the optimization of <math alttext="(\mathcal{K},\mathcal{C})" class="ltx_Math" display="inline" id="A2.F13.2.m1.2"><semantics id="A2.F13.2.m1.2b"><mrow id="A2.F13.2.m1.2.3.2" xref="A2.F13.2.m1.2.3.1.cmml"><mo id="A2.F13.2.m1.2.3.2.1" stretchy="false" xref="A2.F13.2.m1.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="A2.F13.2.m1.1.1" xref="A2.F13.2.m1.1.1.cmml">ğ’¦</mi><mo id="A2.F13.2.m1.2.3.2.2" xref="A2.F13.2.m1.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="A2.F13.2.m1.2.2" xref="A2.F13.2.m1.2.2.cmml">ğ’</mi><mo id="A2.F13.2.m1.2.3.2.3" stretchy="false" xref="A2.F13.2.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.F13.2.m1.2c"><interval closure="open" id="A2.F13.2.m1.2.3.1.cmml" xref="A2.F13.2.m1.2.3.2"><ci id="A2.F13.2.m1.1.1.cmml" xref="A2.F13.2.m1.1.1">ğ’¦</ci><ci id="A2.F13.2.m1.2.2.cmml" xref="A2.F13.2.m1.2.2">ğ’</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A2.F13.2.m1.2d">(\mathcal{K},\mathcal{C})</annotation><annotation encoding="application/x-llamapun" id="A2.F13.2.m1.2e">( caligraphic_K , caligraphic_C )</annotation></semantics></math> for the GPT-3.5-Turbo case.</figcaption>
</figure>
<figure class="ltx_figure" id="A2.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="499" id="A2.F14.g1" src="extracted/5694705/figures/ASQA_gpt35_3_param_alpha_1-NQ_gpt35_3_param_alpha_1_topk_5_interval_100.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Evolution of Recall@5 in the optimization of <math alttext="(\mathcal{K},\mathcal{C},\mathcal{E})" class="ltx_Math" display="inline" id="A2.F14.2.m1.3"><semantics id="A2.F14.2.m1.3b"><mrow id="A2.F14.2.m1.3.4.2" xref="A2.F14.2.m1.3.4.1.cmml"><mo id="A2.F14.2.m1.3.4.2.1" stretchy="false" xref="A2.F14.2.m1.3.4.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="A2.F14.2.m1.1.1" xref="A2.F14.2.m1.1.1.cmml">ğ’¦</mi><mo id="A2.F14.2.m1.3.4.2.2" xref="A2.F14.2.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="A2.F14.2.m1.2.2" xref="A2.F14.2.m1.2.2.cmml">ğ’</mi><mo id="A2.F14.2.m1.3.4.2.3" xref="A2.F14.2.m1.3.4.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="A2.F14.2.m1.3.3" xref="A2.F14.2.m1.3.3.cmml">â„°</mi><mo id="A2.F14.2.m1.3.4.2.4" stretchy="false" xref="A2.F14.2.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.F14.2.m1.3c"><vector id="A2.F14.2.m1.3.4.1.cmml" xref="A2.F14.2.m1.3.4.2"><ci id="A2.F14.2.m1.1.1.cmml" xref="A2.F14.2.m1.1.1">ğ’¦</ci><ci id="A2.F14.2.m1.2.2.cmml" xref="A2.F14.2.m1.2.2">ğ’</ci><ci id="A2.F14.2.m1.3.3.cmml" xref="A2.F14.2.m1.3.3">â„°</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="A2.F14.2.m1.3d">(\mathcal{K},\mathcal{C},\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="A2.F14.2.m1.3e">( caligraphic_K , caligraphic_C , caligraphic_E )</annotation></semantics></math> for the GPT-3.5-Turbo case.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prompts</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.2">Examples of prompts for the evaluation of ASQA and NQ datasets are in TablesÂ <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A3.T2" title="Table 2 â€£ Appendix C Prompts â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.19251v1#A3.T3" title="Table 3 â€£ Appendix C Prompts â€£ AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a> respectively. The examples shown here are with the (<math alttext="\mathcal{K}=3" class="ltx_Math" display="inline" id="A3.p1.1.m1.1"><semantics id="A3.p1.1.m1.1a"><mrow id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A3.p1.1.m1.1.1.2" xref="A3.p1.1.m1.1.1.2.cmml">ğ’¦</mi><mo id="A3.p1.1.m1.1.1.1" xref="A3.p1.1.m1.1.1.1.cmml">=</mo><mn id="A3.p1.1.m1.1.1.3" xref="A3.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><eq id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1.1"></eq><ci id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">ğ’¦</ci><cn id="A3.p1.1.m1.1.1.3.cmml" type="integer" xref="A3.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">\mathcal{K}=3</annotation><annotation encoding="application/x-llamapun" id="A3.p1.1.m1.1d">caligraphic_K = 3</annotation></semantics></math> and <math alttext="\mathcal{C}=1" class="ltx_Math" display="inline" id="A3.p1.2.m2.1"><semantics id="A3.p1.2.m2.1a"><mrow id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A3.p1.2.m2.1.1.2" xref="A3.p1.2.m2.1.1.2.cmml">ğ’</mi><mo id="A3.p1.2.m2.1.1.1" xref="A3.p1.2.m2.1.1.1.cmml">=</mo><mn id="A3.p1.2.m2.1.1.3" xref="A3.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><apply id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1"><eq id="A3.p1.2.m2.1.1.1.cmml" xref="A3.p1.2.m2.1.1.1"></eq><ci id="A3.p1.2.m2.1.1.2.cmml" xref="A3.p1.2.m2.1.1.2">ğ’</ci><cn id="A3.p1.2.m2.1.1.3.cmml" type="integer" xref="A3.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">\mathcal{C}=1</annotation><annotation encoding="application/x-llamapun" id="A3.p1.2.m2.1d">caligraphic_C = 1</annotation></semantics></math>) setting.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_table" id="A3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T2.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T2.5.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T2.5.1.1.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.5.1.1.1.1">
<span class="ltx_p" id="A3.T2.5.1.1.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.5.1.1.1.1.1.1">Instruction</span>: Write an accurate, engaging, and concise answer for the given question using only the provided search results (some of which might be irrelevant) and cite them properly. Use an unbiased and journalistic tone. Always cite for any factual claim. When citing several search results, use [1][2][3]. Cite at least one document and at most three documents in each sentence. If multiple documents support the sentence, only cite a minimum sufficient subset of the documents.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.5.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T2.5.2.2.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.5.2.2.1.1">
<span class="ltx_p" id="A3.T2.5.2.2.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.5.2.2.1.1.1.1">Question</span>: Who has the highest goals in world football?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.5.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T2.5.3.3.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.5.3.3.1.1">
<span class="ltx_p" id="A3.T2.5.3.3.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.5.3.3.1.1.1.1">Document [1]</span>(Title: Argentinaâ€“Brazil football rivalry): "Football Player of the Century", by IFFHS International Federation of Football History and Statistics, 1999, "South America Football Player of the Century", by IFFHS International Federation of Football History and Statistics. PelÃ©â€™s 1281 goals are recognized by FIFA as the highest total achieved by a professional footballer, although the Soccer Statistic Foundation (rssf) recognizes only 767 goals in official mode, occupying the third place after Josef Bican (805) and Romario (772). For his part, Maradona has been named the best soccer player in World Cup history both by The Times and FourFourTwo, publication that also rewarded him as the "Best</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.5.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T2.5.4.4.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.5.4.4.1.1">
<span class="ltx_p" id="A3.T2.5.4.4.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.5.4.4.1.1.1.1">Document [2]</span>(Title: Godfrey Chitalu): have beaten Gerd MÃ¼llerâ€™s record of 85 goals in a year, the Football Association of Zambia claimed that the world record actually pertained to Godfrey Chitalu who had scored 116 goals (possibly 117) during the 1972 calendar year and 107 during the 1972 season. The difference of goals is due to first 9 goals being scored before the season officially started. The Football Association of Zambia presented the evidence to FIFA but a spokesperson responded that they would ratify neither Lionel Messiâ€™s nor Chitaluâ€™s records as they do not keep statistical track of domestic competitions. Nonetheless, it could constitute the</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T2.5.5.5.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.5.5.5.1.1">
<span class="ltx_p" id="A3.T2.5.5.5.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.5.5.5.1.1.1.1">Document [3]</span>(Title: Godfrey Chitalu): highest official tally claimed by a national football association. Chitalu made his international debut on 29 June 1968 in a friendly match against Uganda in Lusaka which Zambia won 2â€“1. He scored his first goal in a 2â€“2 draw against the same team five days later. Chitalu played a prominent role during the World Cup qualification matches against Sudan with Zambia being eliminated on a strange rule which was peculiar to Africa and favoured the team that won the second leg. Despite the aggregate score being tied at 6â€“6 after Zambia won the first leg 4â€“2 and lost the return</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T2.5.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A3.T2.5.6.6.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T2.5.6.6.1.1">
<span class="ltx_p" id="A3.T2.5.6.6.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T2.5.6.6.1.1.1.1">Answer</span>:</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Prompt for ASQA. The prompt consists of Instruction, Question, and <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="A3.T2.3.m1.1"><semantics id="A3.T2.3.m1.1b"><mi class="ltx_font_mathcaligraphic" id="A3.T2.3.m1.1.1" xref="A3.T2.3.m1.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="A3.T2.3.m1.1c"><ci id="A3.T2.3.m1.1.1.cmml" xref="A3.T2.3.m1.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T2.3.m1.1d">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="A3.T2.3.m1.1e">caligraphic_K</annotation></semantics></math> retrieved Documents, where <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="A3.T2.4.m2.1"><semantics id="A3.T2.4.m2.1b"><mi class="ltx_font_mathcaligraphic" id="A3.T2.4.m2.1.1" xref="A3.T2.4.m2.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="A3.T2.4.m2.1c"><ci id="A3.T2.4.m2.1.1.cmml" xref="A3.T2.4.m2.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T2.4.m2.1d">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="A3.T2.4.m2.1e">caligraphic_K</annotation></semantics></math> in the table example is equal to 3 and without prompt compression.</figcaption>
</figure>
<figure class="ltx_table" id="A3.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T3.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T3.5.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T3.5.1.1.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T3.5.1.1.1.1">
<span class="ltx_p" id="A3.T3.5.1.1.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T3.5.1.1.1.1.1.1">Instruction</span>: Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T3.5.2.2.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T3.5.2.2.1.1">
<span class="ltx_p" id="A3.T3.5.2.2.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T3.5.2.2.1.1.1.1">Question</span>: which is the default file extension for an audio file in windows media player</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T3.5.3.3.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T3.5.3.3.1.1">
<span class="ltx_p" id="A3.T3.5.3.3.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T3.5.3.3.1.1.1.1">Document [1]</span>(Title: Windows Media Player) Windows Media Player 11 is available for Windows XP and included in Windows Vista and Windows Server 2008. The default file formats are Windows Media Video (WMV), Windows Media Audio (WMA), and Advanced Systems Format (ASF), and its own XML based playlist format called Windows Playlist (WPL). The player is also able to utilize a digital rights management service in the form of Windows Media DRM.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T3.5.4.4.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T3.5.4.4.1.1">
<span class="ltx_p" id="A3.T3.5.4.4.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T3.5.4.4.1.1.1.1">Document [2]</span>(Title: Windows Media Player) as data discs with playlists such as an MP3 CD, synchronize content with a digital audio player (MP3 player) or other mobile devices, and enable users to purchase or rent music from a number of online music stores. Windows Media Player replaced an earlier application called Media Player, adding features beyond simple video or audio playback. Windows Media Player 11 is available for Windows XP and included in Windows Vista and Windows Server 2008. The default file formats are Windows Media Video (WMV), Windows Media Audio (WMA), and Advanced Systems Format (ASF), and its own XML based playlist format called</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T3.5.5.5.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T3.5.5.5.1.1">
<span class="ltx_p" id="A3.T3.5.5.5.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T3.5.5.5.1.1.1.1">Document [3]</span>(Title: Windows Media Audio) Windows Media DRM cannot play DRM-protected files. Windows Media Audio Windows Media Audio (WMA) is the name of a series of audio codecs and their corresponding audio coding formats developed by Microsoft. It is a proprietary technology that forms part of the Windows Media framework. WMA consists of four distinct codecs. The original WMA codec, known simply as "WMA", was conceived as a competitor to the popular MP3 and RealAudio codecs. "WMA Pro", a newer and more advanced codec, supports multichannel and high resolution audio. A lossless codec, "WMA Lossless", compresses audio data without loss of audio fidelity</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A3.T3.5.6.6.1" style="padding-bottom:5.0pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T3.5.6.6.1.1">
<span class="ltx_p" id="A3.T3.5.6.6.1.1.1" style="width:433.6pt;"><span class="ltx_text ltx_font_bold" id="A3.T3.5.6.6.1.1.1.1">Answer</span>:</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Prompt for Natural Question. The prompt consists of Instruction, Question, and <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="A3.T3.3.m1.1"><semantics id="A3.T3.3.m1.1b"><mi class="ltx_font_mathcaligraphic" id="A3.T3.3.m1.1.1" xref="A3.T3.3.m1.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="A3.T3.3.m1.1c"><ci id="A3.T3.3.m1.1.1.cmml" xref="A3.T3.3.m1.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.3.m1.1d">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="A3.T3.3.m1.1e">caligraphic_K</annotation></semantics></math> retrieved Documents, where <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="A3.T3.4.m2.1"><semantics id="A3.T3.4.m2.1b"><mi class="ltx_font_mathcaligraphic" id="A3.T3.4.m2.1.1" xref="A3.T3.4.m2.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="A3.T3.4.m2.1c"><ci id="A3.T3.4.m2.1.1.cmml" xref="A3.T3.4.m2.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.4.m2.1d">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="A3.T3.4.m2.1e">caligraphic_K</annotation></semantics></math> in the table example is equal to 3 and without prompt compression.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jun 27 04:19:10 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
