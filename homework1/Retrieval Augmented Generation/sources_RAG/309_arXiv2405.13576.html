<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research</title>
<!--Generated on Fri May 24 15:36:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2405.13576v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S1" title="In FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S2" title="In FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3" title="In FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>The Toolkit: FlashRAG</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.SS1" title="In 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Component Module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.SS2" title="In 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Pipeline Module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.SS3" title="In 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Datasets and Corpus</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.SS3.SSS1" title="In 3.3 Datasets and Corpus ‣ 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.SS3.SSS2" title="In 3.3 Datasets and Corpus ‣ 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Corpus</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.SS4" title="In 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4" title="In FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Result and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4.SS1" title="In 4 Experimental Result and Discussion ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Main results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4.SS2" title="In 4 Experimental Result and Discussion ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Impact of Retrieval on RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S5" title="In FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S6" title="In FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang, Zhicheng Dou 
<br class="ltx_break"/>Gaoling School of Artificial Intelligence
<br class="ltx_break"/>Renmin University of China
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{jinjiajie, dou}@ruc.edu.cn, yutaozhu94@gmail.com</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id2.2.id2">\AND</span>
</span><span class="ltx_author_notes">Corresponding author</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">With the advent of Large Language Models (LLMs), the potential of Retrieval Augmented Generation (RAG) techniques have garnered considerable research attention. Numerous novel algorithms and models have been introduced to enhance various aspects of RAG systems. However, the absence of a standardized framework for implementation, coupled with the inherently intricate RAG process, makes it challenging and time-consuming for researchers to compare and evaluate these approaches in a consistent environment. Existing RAG toolkits like LangChain and LlamaIndex, while available, are often heavy and unwieldy, failing to meet the personalized needs of researchers. In response to this challenge, we propose FlashRAG, an efficient and modular open-source toolkit designed to assist researchers in reproducing existing RAG methods and in developing their own RAG algorithms within a unified framework. Our toolkit implements 12 advanced RAG methods and has gathered and organized 32 benchmark datasets. Our toolkit has various features, including customizable modular framework, rich collection of pre-implemented RAG works, comprehensive datasets, efficient auxiliary pre-processing scripts, and extensive and standard evaluation metrics. Our toolkit and resources are available at <a class="ltx_ref ltx_href" href="https://github.com/RUC-NLPIR/FlashRAG" title="">https://github.com/RUC-NLPIR/FlashRAG</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In the era of large language models (LLMs), retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib2" title="">2</a>]</cite> has emerged as a robust solution to mitigate hallucination issues in LLMs by leveraging external knowledge bases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib3" title="">3</a>]</cite>. The substantial applications and the potential of RAG technology have attracted considerable research attention.
With the introduction of a large number of new algorithms and models to improve various facets of RAG systems in recent years, comparing and evaluating these methods under a consistent setting has become increasingly challenging.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Many works are not open-source or have fixed settings in their open-source code, making it difficult to adapt to new data or innovative components.
Besides, the datasets and retrieval corpus used often vary, with resources being scattered, which can lead researchers to spend excessive time on pre-processing steps instead of focusing on optimizing their methods. Furthermore, due to the complexity of RAG systems, involving multiple steps such as indexing, retrieval, and generation, researchers often need to implement many parts of the system themselves.
Although there are some existing RAG toolkits like LangChain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib4" title="">4</a>]</cite> and LlamaIndex <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib5" title="">5</a>]</cite>, they are typically large and cumbersome, hindering researchers from implementing customized processes and failing to address the aforementioned issues. Thus, a unified, researcher-oriented RAG toolkit is urgently needed to streamline methodological development and comparative studies.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address the issue mentioned above, we introduce FlashRAG, an open-source library designed to enable researchers to easily reproduce existing RAG methods and develop their own RAG algorithms. This library allows researchers to utilize built pipelines to replicate existing work, employ provided RAG components to construct their own RAG processes, or simply use organized datasets and corpora to accelerate their own RAG workflow. Compared to existing RAG toolkits, FlashRAG is more suited for researchers.
To summarize, the key features and capabilities of our FlashRAG library can be outlined in the following four aspects:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.p4.1.1">Extensive and Customizable Modular RAG Framework.</span>  To facilitate an easily expandable RAG process, we implemented modular RAG at two levels. At the component level, we offer comprehensive RAG components, including 13 components across four major categories: judger, retriever, refiner, and generator. These components can be used individually in one’s code or combined to form a cohesive pipeline. At the pipeline level, after reviewing the current state of RAG development, we implemented 8 common RAG processes. Based on this framework, existing methods can be easily replicated, and RAG processes can be run and evaluated under different settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Pre-Implemented advanced RAG algorithms.</span> To our knowledge, the implementation of existing work provided by FlashRAG is the most extensive. So far, based on our framework, we have implemented 12 advanced RAG algorithms, such as Self-RAG and FLARE, covering Sequential RAG, Conditional RAG, Branching RAG, and Loop RAG categories. These methods have been evaluated under a unified setting, and a benchmark report is available. With our framework, researchers can easily evaluate these methods under various settings and fairly compare them with their own methods, enhancing overall reproducibility. More methods are planned to be incorporated into our library.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.p6.1.1">Comprehensive benchmark datasets.</span> To improve the consistency and reusability of datasets in RAG research, we have compiled 32 common RAG benchmark datasets and preprocessed them into a unified format. Some of these datasets, such as asqa and wikiasp, have undergone specific adjustments for RAG scenarios to ensure consistency. We have hosted these datasets on the Hugging Face platform for easy access and use.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text ltx_font_bold" id="S1.p7.1.1">Efficient Helping Scripts for RAG.</span> To minimize the setup time in RAG experiments, we offer a comprehensive suite of helping scripts, including downloading and slicing Wikipedia for corpus creation, building indexes for retrieval, and prepare retrieval results in advance. These steps are important for the subsequent process, but they are often tedious and can take up a lot of time. Our user-friendly scripts are designed to be intuitive, ensuring researchers can easily navigate the preparatory stages of RAG-related research.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The RAG process often involves various components and complex preliminary handling (such as constructing corpus and building indexes). Due to the lack of a dedicated RAG library for research, most open-source codes tend to use their preferred implementation and entail intricate environment configurations. Therefore, it is often time-consuming to run others’ code and difficult to migrate to your own settings.
Simultaneously, the processing and use of datasets and corpus lack standardization, enhancing the challenge of making a fair comparison between oneself and existing methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In recent years, numerous open-source toolkits pertaining to RAG have been developed, providing rich RAG components. Langchain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib4" title="">4</a>]</cite>, LlamaIndex <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib5" title="">5</a>]</cite>, and Haystack <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib6" title="">6</a>]</cite> are among the widely adopted works. These libraries provide a range of advanced APIs related to LLM, such as vector databases and embedding models, which greatly streamline the interaction with LLM and facilitate running a RAG process effortlessly. Despite the many advantages, these libraries lack support for researchers. On one hand, they tend to overlook the implementation of existing works including methods, widely used retrieval corpus, and benchmark datasets. On the other hand, they are often too hefty and heavily encapsulated, obscuring operational details or necessitating complex document searches, thereby lacking flexibility for customization.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Given these issues, several specialized toolkits for RAG have been introduced that are lighter and more customizable. For instance, FastRAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib7" title="">7</a>]</cite> optimizes based on Haystack’s api and provides a limited number of support methods and benchmark datasets. LocalRQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib8" title="">8</a>]</cite> focuses on the training stage in the RAG process, providing comprehensive scripts for training various components (such as retrievers, generators) that might be involved in the RAG process during research. AutoRAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib9" title="">9</a>]</cite> adopts a similar design philosophy to ours, implementing modular RAG process. This library represents each component in RAG as a node, and the RAG process is achieved by connecting the nodes. Although AutoRAG encompasses a variety of evaluation metrics and benchmarks, it falls short concerning the direct implementation of existing works. Therefore, in our library, we have not only designed an exhaustive assortment of RAG components to implement a wide array of RAG processes but also implemented various RAG works so that the effects of existing works under various settings can be replicated directly with a few lines of code.
Furthermore, we offer a wealth of resources, including a large number of processed datasets, scripts for obtaining and pre-processing widely-used corpus, among others, to expedite researchers’ preparation time as much as possible.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison with other RAG toolkits. <span class="ltx_text ltx_font_italic" id="S2.T1.4.1">Modular Component</span> refers to whether the toolkit is composed of modular components. <span class="ltx_text ltx_font_italic" id="S2.T1.5.2">Automatic Evaluation</span> indicates if the toolkit provides automated evaluation capabilities to assess the performance of various datasets. <span class="ltx_text ltx_font_italic" id="S2.T1.6.3">Corpus Helper</span> shows if the toolkit offers auxiliary tools for processing corpus, including cleaning and chunking.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.7" style="width:433.6pt;height:93.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-117.7pt,25.3pt) scale(0.648106260369506,0.648106260369506) ;">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.7.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.7.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.7.1.1.1.1" style="padding:0.5pt 5.0pt;">Toolkit</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.7.1.1.1.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.1.1.2.1">Modular Component</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.7.1.1.1.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.1.1.3.1">Automatic Evaluation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.7.1.1.1.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.1.1.4.1">Corpus Helper</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.7.1.1.1.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.1.1.5.1"># Provided Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.7.1.1.1.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.1.1.6.1"># Support Work</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.7.1.2.2.1" style="padding:0.5pt 5.0pt;">Langchain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib4" title="">4</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.7.1.2.2.2" style="padding:0.5pt 5.0pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.7.1.2.2.3" style="padding:0.5pt 5.0pt;">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.7.1.2.2.4" style="padding:0.5pt 5.0pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.7.1.2.2.5" style="padding:0.5pt 5.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.7.1.2.2.6" style="padding:0.5pt 5.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.3.3" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_left" id="S2.T1.7.1.3.3.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.3.3.1.1" style="background-color:#EBEBEB;">LlamaIndex <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib5" title="">5</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.3.3.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.3.3.2.1" style="background-color:#EBEBEB;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.3.3.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.3.3.3.1" style="background-color:#EBEBEB;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.3.3.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.3.3.4.1" style="background-color:#EBEBEB;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.3.3.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.3.3.5.1" style="background-color:#EBEBEB;">-</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.3.3.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.3.3.6.1" style="background-color:#EBEBEB;">2</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.4.4" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="S2.T1.7.1.4.4.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.4.4.1.1" style="background-color:#FFFFFF;">Haystack <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib6" title="">6</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.4.4.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.4.4.2.1" style="background-color:#FFFFFF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.4.4.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.4.4.3.1" style="background-color:#FFFFFF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.4.4.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.4.4.4.1" style="background-color:#FFFFFF;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.4.4.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.4.4.5.1" style="background-color:#FFFFFF;">-</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.4.4.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.4.4.6.1" style="background-color:#FFFFFF;">-</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.5.5" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_left" id="S2.T1.7.1.5.5.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.5.5.1.1" style="background-color:#EBEBEB;">FastRAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib7" title="">7</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.5.5.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.5.5.2.1" style="background-color:#EBEBEB;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.5.5.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.5.5.3.1" style="background-color:#EBEBEB;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.5.5.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.5.5.4.1" style="background-color:#EBEBEB;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.5.5.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.5.5.5.1" style="background-color:#EBEBEB;">2</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.5.5.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.5.5.6.1" style="background-color:#EBEBEB;">1</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.6.6" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="S2.T1.7.1.6.6.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.6.6.1.1" style="background-color:#FFFFFF;">LocalRQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib8" title="">8</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.6.6.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.6.6.2.1" style="background-color:#FFFFFF;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.6.6.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.6.6.3.1" style="background-color:#FFFFFF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.6.6.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.6.6.4.1" style="background-color:#FFFFFF;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.6.6.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.6.6.5.1" style="background-color:#FFFFFF;">3</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.6.6.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.6.6.6.1" style="background-color:#FFFFFF;">-</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.7.7" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_left" id="S2.T1.7.1.7.7.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.7.7.1.1" style="background-color:#EBEBEB;">AutoRAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib9" title="">9</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.7.7.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.7.7.2.1" style="background-color:#EBEBEB;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.7.7.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.7.7.3.1" style="background-color:#EBEBEB;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.7.7.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.7.7.4.1" style="background-color:#EBEBEB;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.7.7.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.7.7.5.1" style="background-color:#EBEBEB;">4</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.7.1.7.7.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.7.7.6.1" style="background-color:#EBEBEB;">-</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.7.1.8.8" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.7.1.8.8.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.8.8.1.1" style="background-color:#FFFFFF;">FlashRAG<span class="ltx_text ltx_font_medium" id="S2.T1.7.1.8.8.1.1.1"> (ours)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.7.1.8.8.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.8.8.2.1" style="background-color:#FFFFFF;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.7.1.8.8.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.8.8.3.1" style="background-color:#FFFFFF;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.7.1.8.8.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S2.T1.7.1.8.8.4.1" style="background-color:#FFFFFF;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.7.1.8.8.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.8.8.5.1" style="background-color:#FFFFFF;">32</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.7.1.8.8.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.7.1.8.8.6.1" style="background-color:#FFFFFF;">12</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The Toolkit: FlashRAG</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The FlashRAG is designed to facilitate RAG-related research for researchers. As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.F1" title="Figure 1 ‣ 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_tag">1</span></a>, the overall structure of the FlashRAG toolkit comprises three hierarchical modules: the environment module, the component module, and the pipeline module. The environment module is fundamental to the toolkit, establishing the requisite datasets, hyperparameters, and evaluation metrics necessary for experimentation. Building upon the environment module, the component module consists of various RAG components, each endowed with its specific role (e.g., retrieval and generation). The pipeline module synthesizes an assortment of component modules with the purpose of effectuating a complete RAG process.
In this paper, we will introduce the component and pipeline modules. Additional details are available in the documentation of our library.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F1.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of the FlashRAG toolkit.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Component Module</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The Component Module consolidates all elements involved in the RAG process into a unified framework. Each component is equipped with autonomous functionality, enabling standalone application. Currently, the Component Module encompasses five main components: Judger, Retriever, Reranker, Refiner, and Generator.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Judger</span> functions as a preliminary component that assesses whether a query necessitates retrieval. Given the limited work and models in this domain, we presently offer a judger based on the SKR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib10" title="">10</a>]</cite> method, which determines the necessity of retrieval using a curated set of LLM self-knowledge data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Retriever</span> implementations are extensively covered by our toolkit. For sparse retrieval, we have integrated the Pyserini library <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib11" title="">11</a>]</cite> to facilitate the BM25 method. For dense retrieval, we provide support for various BERT-based embedding models such as DPR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib12" title="">12</a>]</cite>, E5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib13" title="">13</a>]</cite> and BGE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib14" title="">14</a>]</cite>. FlashRAG also support models based on the T5 architecture like ANCE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib15" title="">15</a>]</cite>. We employ FAISS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib17" title="">17</a>]</cite> for vector database computations to ensure retrieval efficiency and utilize the HuggingFace’s datasets library to enhance corpus loading speed.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">To enhance the reusability of retrieval results and accommodate non-open source retrievers, our library supports the use of pre-retrieved results termed "retrieval cache". During each retrieval instance, the system automatically searches the retrieval cache for relevant results using the current query, presenting them as the return value. Using our retrievers, user can set automatic saving of retrieval caches as JSONL files for future use. For non-open source retrievers, user can format the retrieval results to fit our cache structure for loading.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Reranker</span> aims at refining the order of results returned by the retriever to enhance retrieval accuracy. Currently, FlashRAG supports a variety of widely-used Cross-Encoder models, such as the bge-reranker and jina-reranker. In scenarios where embedding models are used for reranking (e.g., employing BM25 as the retriever), we also facilitate the use of Bi-Encoder models like E5 as rerankers. In practice, the reranker is integrated into the retriever’s retrieval function via a decorator, enabling seamless combination with any retriever. Users can assemble any retriever and reranker with just one line of code.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p6.1.1">Refiner</span> refines the input text for generators to reduce token usage and reduce noise from retrieved documents, improving the final RAG responses. Serving as an essential part of the RAG process, various studies focus on developing superior refinements. We have reviewed the existing literature and implemented four types of refiners, each performing differently in handling retrieved documents. The Extractive Refiner employs an embedding model to extract semantic units, like sentences or phrases, from the retrieved text that hold higher semantic similarity with the query. The Abstractive Refiner utilizes a seq2seq model to directly summarize the retrieved text, supporting dedicated models like RECOMP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib18" title="">18</a>]</cite>, as well as the general summarizer models with similar structures available on HuggingFace. Furthermore, we also facilitate the use of LLMLingua <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib20" title="">20</a>]</cite> Refiner and Selective-Context <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib21" title="">21</a>]</cite> Refiner, both perplexity-based refiners.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p7.1.1">Generator</span> is the final component in the RAG process, thoroughly covered within our toolkit. In the generator module, we’ve integrated two leading LLM acceleration libraries, vllm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib22" title="">22</a>]</cite> and FastChat <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib23" title="">23</a>]</cite>, hence, a myriad of mainstream LLMs are supported. Furthermore, we provide the native interface of the Transformers library <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib24" title="">24</a>]</cite> to enhance robustness. We also support various encoder-decoder models, such as Flan-T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib25" title="">25</a>]</cite>. For these models, we facilitate the use of Fusion in Decoder (FiD) techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib26" title="">26</a>]</cite>, further optimizing efficiency when dealing with retrieved documents.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Pipeline Module</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Building on the diverse components outlined earlier, we are able to decouple the algorithmic flow of the RAG process from the specific implementations of each component, facilitating the assembly of the entire pipeline.
The entire pipeline processes the dataset provided by the user, executes the corresponding RAG process on it, and delivers both the final evaluation outcomes and intermediate results.
In constructing the pipeline, one only needs to consider which components are required for the entire RAG process and the logic of data flow between these components. Specifically, within each pipeline, it is necessary to load the required components in the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">init(.)</span> function and implement the corresponding logic in the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.2">run(.)</span> function according to each component’s interface.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">To systematically execute the operational logic of various RAG tasks, we conducted an in-depth survey of RAG-related literature. Drawing on the summaries from the RAG survey <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib27" title="">27</a>]</cite>, we categorized all RAG process flows into four types: Sequential, Branching, Conditional, and Loop. So far, we have implemented 8 different pipelines, covering a range of advancing RAG works.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Sequential Pipeline</span> implements a linear execution path for the query, formally represented as query -&gt; retriever -&gt; post-retrieval (reranker, refiner) -&gt; generator. Once the user has configured their settings, the library automatically loads the necessary components along with their corresponding process logic.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Branching Pipeline</span> executes multiple paths in parallel for a single query (often one path per retrieved document) and merges the results from all paths to form the ultimate output. Currently, our library supports two advancing branching methods: REPLUG pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib28" title="">28</a>]</cite> and SuRe pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib29" title="">29</a>]</cite>. The REPLUG pipeline processes each retrieved document in parallel and combines the generation probabilities from all documents to produce the final answer. The SuRe pipeline generates a candidate answer from each retrieved document and then ranks all candidate answers. In implementing SuRe, we adhere to the original paper’s prompt and processing flow to ensure accuracy and comparability of the results.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Conditional Pipeline</span> utilizes a judger to direct the query into different execution paths based on the judgement outcome. In the current framework, queries deemed in need of retrieval are sent into the normal sequential process, while the rest bypass retrieval and proceed directly to generation.
We offer utility functions to split and merge the input dataset based on the judger’s determination, ensuring that all processing can be conducted in batches, which enhances the efficiency of the pipeline. Moreover, the conditional pipeline supports integration with various types of pipelines, meaning it can execute different pipelines for queries based on different judger outcomes.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Loop Pipeline</span> involves complex interactions between retrieval and generation processes, often encompassing multiple cycles of retrieval and generation. Compared to the previous three types of pipelines, this type offers greater flexibility and improved outcomes. We support four widely recognized methods, including Iterative <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib31" title="">31</a>]</cite>, Self-Ask <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib32" title="">32</a>]</cite>, Self-RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib33" title="">33</a>]</cite>, and FlARE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib34" title="">34</a>]</cite>.
For each of these methods, we support flexible adjustments to the retrievers and generators to test their performances in different scenarios.
</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Datasets and Corpus</h3>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Datasets</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S3.T2" title="Table 2 ‣ 3.3.1 Datasets ‣ 3.3 Datasets and Corpus ‣ 3 The Toolkit: FlashRAG ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_tag">2</span></a>, we collects and pre-processes 32 benchmark datasets, covering the majority of the datasets utilized in RAG works.
We researched and listed the sources of answers in each dataset for reference. For most datasets, the knowledge comes from Wikipedia, underscoring its importance in RAG tasks.
All datasets have been formatted into a unified JSONL structure, typically encapsulating four fields: ID, question, golden answer, and metadata. For multiple-choice datasets like MMLU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib36" title="">36</a>]</cite> and OpenBookQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib37" title="">37</a>]</cite>, an additional "choices" field is provided as options. We have hosted the processed datasets on HuggingFace for easy access. Details on dataset processing can be found in the appendix.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Summary of datasets. FlashRAG currently includes a variety of datasets of different tasks. The sample size of each dataset and the knowledge source of the answer are listed as references. "-" indicates that the knowledge source is common sense. The <math alttext="\ast" class="ltx_Math" display="inline" id="S3.T2.2.m1.1"><semantics id="S3.T2.2.m1.1b"><mo id="S3.T2.2.m1.1.1" xref="S3.T2.2.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.m1.1c"><ci id="S3.T2.2.m1.1.1.cmml" xref="S3.T2.2.m1.1.1">∗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.m1.1d">\ast</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.m1.1e">∗</annotation></semantics></math> symbol represents that the task of this dataset has been modified to fit the RAG scene.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.3" style="width:433.6pt;height:389.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-113.7pt,102.2pt) scale(0.655913848197771,0.655913848197771) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.3.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.2.1.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.2.1.1.1" style="background-color:#FFFFFF;">Task</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.3.1.2.1.2" style="padding:0.5pt 5.0pt;">Dataset Name</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.3.1.2.1.3" style="padding:0.5pt 5.0pt;">Knowledge Source</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.2.1.4" style="padding:0.5pt 5.0pt;"># Train</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.2.1.5" style="padding:0.5pt 5.0pt;"># Dev</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.2.1.6" style="padding:0.5pt 5.0pt;"># Test</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.3.2">
<td class="ltx_td ltx_border_t" id="S3.T2.3.1.3.2.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.3.2.2" style="padding:0.5pt 5.0pt;">NQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib38" title="">38</a>]</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.3.2.3" style="padding:0.5pt 5.0pt;">Wiki</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.3.2.4" style="padding:0.5pt 5.0pt;">79,168</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.3.2.5" style="padding:0.5pt 5.0pt;">8,757</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.3.2.6" style="padding:0.5pt 5.0pt;">3,610</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.4.3">
<td class="ltx_td" id="S3.T2.3.1.4.3.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.4.3.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.4.3.2.1" style="background-color:#EBEBEB;">TriviaQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib39" title="">39</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.4.3.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.4.3.3.1" style="background-color:#EBEBEB;">Wiki &amp; Web</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.4.3.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.4.3.4.1" style="background-color:#EBEBEB;">78,785</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.4.3.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.4.3.5.1" style="background-color:#EBEBEB;">8,837</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.4.3.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.4.3.6.1" style="background-color:#EBEBEB;">11,313</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.5.4">
<td class="ltx_td" id="S3.T2.3.1.5.4.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.5.4.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.5.4.2.1" style="background-color:#FFFFFF;">PopQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib40" title="">40</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.5.4.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.5.4.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.5.4.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.5.4.4.1" style="background-color:#FFFFFF;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.5.4.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.5.4.5.1" style="background-color:#FFFFFF;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.5.4.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.5.4.6.1" style="background-color:#FFFFFF;">14,267</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.6.5">
<td class="ltx_td" id="S3.T2.3.1.6.5.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.6.5.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.6.5.2.1" style="background-color:#EBEBEB;">SQuAD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib41" title="">41</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.6.5.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.6.5.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.6.5.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.6.5.4.1" style="background-color:#EBEBEB;">87,599</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.6.5.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.6.5.5.1" style="background-color:#EBEBEB;">10,570</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.6.5.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.6.5.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.7.6">
<td class="ltx_td" id="S3.T2.3.1.7.6.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.7.6.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.7.6.2.1" style="background-color:#FFFFFF;">MSMARCO-QA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib42" title="">42</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.7.6.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.7.6.3.1" style="background-color:#FFFFFF;">Web</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.7.6.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.7.6.4.1" style="background-color:#FFFFFF;">808,731</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.7.6.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.7.6.5.1" style="background-color:#FFFFFF;">101,093</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.7.6.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.7.6.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.8.7">
<td class="ltx_td" id="S3.T2.3.1.8.7.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.8.7.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.8.7.2.1" style="background-color:#EBEBEB;">NarrativeQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib43" title="">43</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.8.7.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.8.7.3.1" style="background-color:#EBEBEB;">Books, movie scripts</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.8.7.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.8.7.4.1" style="background-color:#EBEBEB;">32,747</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.8.7.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.8.7.5.1" style="background-color:#EBEBEB;">3,461</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.8.7.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.8.7.6.1" style="background-color:#EBEBEB;">10,557</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.9.8">
<td class="ltx_td" id="S3.T2.3.1.9.8.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.9.8.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.9.8.2.1" style="background-color:#FFFFFF;">WikiQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib44" title="">44</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.9.8.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.9.8.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.9.8.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.9.8.4.1" style="background-color:#FFFFFF;">20,360</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.9.8.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.9.8.5.1" style="background-color:#FFFFFF;">2,733</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.9.8.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.9.8.6.1" style="background-color:#FFFFFF;">6,165</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.10.9">
<td class="ltx_td" id="S3.T2.3.1.10.9.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.10.9.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.10.9.2.1" style="background-color:#EBEBEB;">WebQuestions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib45" title="">45</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.10.9.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.10.9.3.1" style="background-color:#EBEBEB;">Google Freebase</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.10.9.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.10.9.4.1" style="background-color:#EBEBEB;">3,778</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.10.9.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.10.9.5.1" style="background-color:#EBEBEB;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.10.9.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.10.9.6.1" style="background-color:#EBEBEB;">2,032</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.11.10">
<td class="ltx_td" id="S3.T2.3.1.11.10.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.11.10.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.11.10.2.1" style="background-color:#FFFFFF;">AmbigQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib38" title="">38</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.11.10.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.11.10.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.11.10.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.11.10.4.1" style="background-color:#FFFFFF;">10,036</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.11.10.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.11.10.5.1" style="background-color:#FFFFFF;">2,002</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.11.10.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.11.10.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.12.11">
<td class="ltx_td" id="S3.T2.3.1.12.11.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.12.11.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.12.11.2.1" style="background-color:#EBEBEB;">SIQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib47" title="">47</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.12.11.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.12.11.3.1" style="background-color:#EBEBEB;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.12.11.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.12.11.4.1" style="background-color:#EBEBEB;">33,410</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.12.11.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.12.11.5.1" style="background-color:#EBEBEB;">1,954</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.12.11.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.12.11.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.13.12">
<td class="ltx_td" id="S3.T2.3.1.13.12.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.13.12.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.13.12.2.1" style="background-color:#FFFFFF;">CommenseQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib48" title="">48</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.13.12.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.13.12.3.1" style="background-color:#FFFFFF;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.13.12.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.13.12.4.1" style="background-color:#FFFFFF;">9,741</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.13.12.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.13.12.5.1" style="background-color:#FFFFFF;">1,221</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.13.12.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.13.12.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.14.13">
<td class="ltx_td" id="S3.T2.3.1.14.13.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.14.13.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.14.13.2.1" style="background-color:#EBEBEB;">BoolQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib49" title="">49</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.14.13.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.14.13.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.14.13.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.14.13.4.1" style="background-color:#EBEBEB;">9,427</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.14.13.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.14.13.5.1" style="background-color:#EBEBEB;">3,270</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.14.13.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.14.13.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.15.14">
<td class="ltx_td" id="S3.T2.3.1.15.14.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.15.14.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.15.14.2.1" style="background-color:#FFFFFF;">PIQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib50" title="">50</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.15.14.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.15.14.3.1" style="background-color:#FFFFFF;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.15.14.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.15.14.4.1" style="background-color:#FFFFFF;">16,113</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.15.14.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.15.14.5.1" style="background-color:#FFFFFF;">1,838</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.15.14.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.15.14.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.16.15" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.16.15.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.16.15.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.16.15.1.1.1">QA</span></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.16.15.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.16.15.2.1" style="background-color:#EBEBEB;">Fermi <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib51" title="">51</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.16.15.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.16.15.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.16.15.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.16.15.4.1" style="background-color:#EBEBEB;">8,000</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.16.15.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.16.15.5.1" style="background-color:#EBEBEB;">1,000</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.16.15.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.16.15.6.1" style="background-color:#EBEBEB;">1,000</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.17.16">
<td class="ltx_td ltx_border_t" id="S3.T2.3.1.17.16.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.17.16.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.17.16.2.1" style="background-color:#FFFFFF;">HotpotQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib52" title="">52</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.17.16.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.17.16.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.17.16.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.17.16.4.1" style="background-color:#FFFFFF;">90,447</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.17.16.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.17.16.5.1" style="background-color:#FFFFFF;">7,405</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.17.16.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.17.16.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.18.17">
<td class="ltx_td" id="S3.T2.3.1.18.17.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.18.17.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.18.17.2.1" style="background-color:#EBEBEB;">2WikiMultiHopQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib53" title="">53</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.18.17.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.18.17.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.18.17.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.18.17.4.1" style="background-color:#EBEBEB;">15,000</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.18.17.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.18.17.5.1" style="background-color:#EBEBEB;">12,576</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.18.17.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.18.17.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.19.18">
<td class="ltx_td" id="S3.T2.3.1.19.18.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.19.18.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.19.18.2.1" style="background-color:#FFFFFF;">Musique <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib54" title="">54</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.19.18.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.19.18.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.19.18.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.19.18.4.1" style="background-color:#FFFFFF;">19,938</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.19.18.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.19.18.5.1" style="background-color:#FFFFFF;">2,417</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.19.18.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.19.18.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.20.19" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.20.19.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.20.19.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.20.19.1.1.1">Multi-Hop QA</span></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.20.19.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.20.19.2.1" style="background-color:#EBEBEB;">Bamboogle <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib32" title="">32</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.20.19.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.20.19.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.20.19.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.20.19.4.1" style="background-color:#EBEBEB;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.20.19.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.20.19.5.1" style="background-color:#EBEBEB;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.20.19.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.20.19.6.1" style="background-color:#EBEBEB;">125</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.21.20">
<td class="ltx_td ltx_border_t" id="S3.T2.3.1.21.20.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.21.20.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.21.20.2.1" style="background-color:#FFFFFF;">ASQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib55" title="">55</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.21.20.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.21.20.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.21.20.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.21.20.4.1" style="background-color:#FFFFFF;">4,353</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.21.20.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.21.20.5.1" style="background-color:#FFFFFF;">948</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.21.20.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.21.20.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.22.21" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.22.21.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.22.21.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.22.21.1.1.1">Long-Form QA</span></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.22.21.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.22.21.2.1" style="background-color:#EBEBEB;">ELI5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib56" title="">56</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.22.21.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.22.21.3.1" style="background-color:#EBEBEB;">Reddit</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.22.21.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.22.21.4.1" style="background-color:#EBEBEB;">272,634</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.22.21.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.22.21.5.1" style="background-color:#EBEBEB;">1,507</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.22.21.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.22.21.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.23.22">
<td class="ltx_td ltx_border_t" id="S3.T2.3.1.23.22.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.23.22.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.23.22.2.1" style="background-color:#FFFFFF;">MMLU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib36" title="">36</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.23.22.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.23.22.3.1" style="background-color:#FFFFFF;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.23.22.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.23.22.4.1" style="background-color:#FFFFFF;">99,842</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.23.22.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.23.22.5.1" style="background-color:#FFFFFF;">1,531</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.23.22.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.23.22.6.1" style="background-color:#FFFFFF;">14,042</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.24.23">
<td class="ltx_td" id="S3.T2.3.1.24.23.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.24.23.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.24.23.2.1" style="background-color:#EBEBEB;">TruthfulQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib57" title="">57</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.24.23.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.24.23.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.24.23.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.24.23.4.1" style="background-color:#EBEBEB;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.24.23.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.24.23.5.1" style="background-color:#EBEBEB;">817</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.24.23.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.24.23.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.25.24">
<td class="ltx_td" id="S3.T2.3.1.25.24.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.25.24.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.25.24.2.1" style="background-color:#FFFFFF;">HellaSwag <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib58" title="">58</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.25.24.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.25.24.3.1" style="background-color:#FFFFFF;">ActivityNet</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.25.24.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.25.24.4.1" style="background-color:#FFFFFF;">39,905</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.25.24.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.25.24.5.1" style="background-color:#FFFFFF;">10,042</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.25.24.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.25.24.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.26.25">
<td class="ltx_td" id="S3.T2.3.1.26.25.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.26.25.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.26.25.2.1" style="background-color:#EBEBEB;">ARC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib59" title="">59</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.26.25.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.26.25.3.1" style="background-color:#EBEBEB;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.26.25.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.26.25.4.1" style="background-color:#EBEBEB;">3,370</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.26.25.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.26.25.5.1" style="background-color:#EBEBEB;">869</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.26.25.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.26.25.6.1" style="background-color:#EBEBEB;">3,548</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.27.26" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.27.26.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.27.26.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.27.26.1.1.1">Multiple-Choice</span></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.27.26.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.27.26.2.1" style="background-color:#FFFFFF;">OpenBookQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib37" title="">37</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.27.26.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.27.26.3.1" style="background-color:#FFFFFF;">-</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.27.26.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.27.26.4.1" style="background-color:#FFFFFF;">4,957</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.27.26.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.27.26.5.1" style="background-color:#FFFFFF;">500</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.27.26.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.27.26.6.1" style="background-color:#FFFFFF;">500</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.28.27">
<td class="ltx_td ltx_border_t" id="S3.T2.3.1.28.27.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.28.27.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.28.27.2.1" style="background-color:#EBEBEB;">AIDA CoNLL-YAGO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.28.27.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.28.27.3.1" style="background-color:#EBEBEB;">Wiki &amp; Freebase</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.28.27.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.28.27.4.1" style="background-color:#EBEBEB;">18,395</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.28.27.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.28.27.5.1" style="background-color:#EBEBEB;">4,784</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.28.27.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.28.27.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.29.28" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.29.28.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.29.28.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.29.28.1.1.1">Entity-linking</span></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.29.28.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.29.28.2.1" style="background-color:#FFFFFF;">WNED <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.29.28.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.29.28.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.29.28.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.29.28.4.1" style="background-color:#FFFFFF;">/</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.29.28.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.29.28.5.1" style="background-color:#FFFFFF;">8,995</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.29.28.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.29.28.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.30.29">
<td class="ltx_td ltx_border_t" id="S3.T2.3.1.30.29.1" style="padding:0.5pt 5.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.30.29.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.30.29.2.1" style="background-color:#EBEBEB;">T-REx <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.30.29.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.30.29.3.1" style="background-color:#EBEBEB;">DBPedia</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.30.29.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.30.29.4.1" style="background-color:#EBEBEB;">2,284,168</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.30.29.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.30.29.5.1" style="background-color:#EBEBEB;">5,000</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.30.29.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.30.29.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.31.30" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.31.30.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.31.30.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.31.30.1.1.1">Slot filling</span></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.31.30.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.31.30.2.1" style="background-color:#FFFFFF;">Zero-shot RE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite></span></td>
<td class="ltx_td ltx_align_left" id="S3.T2.3.1.31.30.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.31.30.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.31.30.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.31.30.4.1" style="background-color:#FFFFFF;">147,909</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.31.30.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.31.30.5.1" style="background-color:#FFFFFF;">3,724</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.1.31.30.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.31.30.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.32.31" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.32.31.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.32.31.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.32.31.1.1.1">Fact Verification</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.32.31.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.32.31.2.1" style="background-color:#EBEBEB;">FEVER <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.32.31.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.32.31.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.32.31.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.32.31.4.1" style="background-color:#EBEBEB;">104,966</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.32.31.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.32.31.5.1" style="background-color:#EBEBEB;">10,444</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.32.31.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.32.31.6.1" style="background-color:#EBEBEB;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.33.32" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.33.32.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.33.32.1.1" style="background-color:#FFFFFF;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.33.32.1.1.1">Dialog Generation</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.33.32.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.33.32.2.1" style="background-color:#FFFFFF;">WOW <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib66" title="">66</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.1.33.32.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.33.32.3.1" style="background-color:#FFFFFF;">Wiki</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.33.32.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.33.32.4.1" style="background-color:#FFFFFF;">63,734</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.33.32.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.33.32.5.1" style="background-color:#FFFFFF;">3,054</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.1.33.32.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.33.32.6.1" style="background-color:#FFFFFF;">/</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.1.1" style="background-color:#EBEBEB;">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.1.1.1" style="background-color:#FFFFFF;padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.1.1.1" style="background-color:#FFFFFF;"><math alttext="\text{Open-domain Summarization}^{\ast}" class="ltx_Math" display="inline" id="S3.T2.3.1.1.1.1.m1.1"><semantics id="S3.T2.3.1.1.1.1.m1.1a"><msup id="S3.T2.3.1.1.1.1.m1.1.1" xref="S3.T2.3.1.1.1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.T2.3.1.1.1.1.m1.1.1.2" mathbackground="#FFFFFF" xref="S3.T2.3.1.1.1.1.m1.1.1.2a.cmml">Open-domain Summarization</mtext><mo id="S3.T2.3.1.1.1.1.m1.1.1.3" mathbackground="#FFFFFF" xref="S3.T2.3.1.1.1.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T2.3.1.1.1.1.m1.1b"><apply id="S3.T2.3.1.1.1.1.m1.1.1.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.3.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S3.T2.3.1.1.1.1.m1.1.1.2a.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.T2.3.1.1.1.1.m1.1.1.2.cmml" mathbackground="#FFFFFF" xref="S3.T2.3.1.1.1.1.m1.1.1.2">Open-domain Summarization</mtext></ci><ci id="S3.T2.3.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1.3">∗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.1.1.1.1.m1.1c">\text{Open-domain Summarization}^{\ast}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.1.1.1.1.m1.1d">Open-domain Summarization start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T2.3.1.1.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.1.2.1" style="background-color:#EBEBEB;">WikiAsp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib67" title="">67</a>]</cite></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T2.3.1.1.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.1.3.1" style="background-color:#EBEBEB;">Wiki</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.1.1.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.1.4.1" style="background-color:#EBEBEB;">300,636</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.1.1.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.1.5.1" style="background-color:#EBEBEB;">37,046</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.1.1.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S3.T2.3.1.1.6.1" style="background-color:#EBEBEB;">37,368</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1">Besides the datasets, we offer a variety of dataset filtering tools for user to filter the entire dataset. For instance, user can choose a certain number of samples from the entire dataset, either randomly or sequentially for evaluation, or select a subset of the dataset through the dataset’s metadata. These methods are unified within a dataset loading function, which is accessible through a standard interface. Users are also allowed to implement their own filtering functions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Corpus</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">Besides datasets, the corpus used for retrieval, also known as the knowledge base, is another vital preparation of experiments. In various research works, the following two types of corpus are often used: Wikipedia dump and MS MARCO passage.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p2">
<p class="ltx_p" id="S3.SS3.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p2.1.1">Wikipedia passages:</span> The Wikipedia passages comprises a collection of documents from English Wikipedia entries, serving as the knowledge source for many datasets, such as KILT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib61" title="">61</a>]</cite>. It was first introduced as a retrieval corpus in DrQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib68" title="">68</a>]</cite>, and subsequently utilized in previous works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib34" title="">34</a>]</cite>. Acquiring the Wikipedia dump involves a complex process, including downloading Wikipedia snapshots in XML format, cleaning the text to remove redundant HTML tags and extracting the corresponding textual content, and segmenting the entire document text into individual passages for retrieval.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p3">
<p class="ltx_p" id="S3.SS3.SSS2.p3.1">For various reasons, there are several different versions of Wikipedia used in existing work, increasing the difficulty of reproduction. To address this, we provide easy-to-use scripts for automatically downloading and pre-processing any required Wikipedia version. Additionally, we offer various chunking functions to support custom segmentation methods, enabling researchers to align their corpus with others’ works or to establish a standard corpus for use. We also provide the widely utilized Wikipedia dump presented by DPR from December 20, 2018, as a fundamental resource.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS2.p4">
<p class="ltx_p" id="S3.SS3.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.SSS2.p4.1.1">MS MARCO passages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib42" title="">42</a>]</cite>:</span> The MS MARCO passage includes 8.8 million passages, sourced from Bing search engine retrievals. Compared to the Wikipedia dump, it contains fewer passages. Fortunately, this corpus has undergone pre-processing, allowing for its direct use. Since this dataset is already hosted on Hugging Face and matches our required format, we provide its original link for ease of download.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Our library supports a variety of evaluation metrics to assess the quality of RAG process. Depending on the subject of evaluation, our supporting metrics can be divided into two categories: retrieval-aspect metrics and generation-aspect metrics.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.1">Retrieval-aspect metrics:</span> To evaluate the quality of the retrieval, we support four metrics including recall@k, precision@k, F1@k, and mean average precision (MAP). Unlike assessing standalone retrieval systems, the documents retrieved in the RAG process often lack golden labels (e.g., related or unrelated tags). Therefore, we facilitate these evaluations by considering whether the golden answer is present within the retrieved documents as an indicator of relevance. Other types of metrics can be obtained by inheriting existing metrics and modifying the calculation methods inside.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">Generation-aspect metrics:</span> For evaluating the quality of generation, we support five metrics including token-level F1 score, exact match, accuracy, BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib69" title="">69</a>]</cite>, and ROUGE-L <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib70" title="">70</a>]</cite>. Moreover, we support evaluating the number of tokens used in generation, to facilitate the analysis of the overall process cost.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">To accommodate custom evaluation metrics, our library provides a metric template for users to implement. As our library automatically saves intermediate results of the execution, users can conveniently evaluate the outcomes produced by intermediate components. For example, users might compare the number of tokens before and after the refiner runs, or the precision differences between multiple rounds of retrieval results.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Result and Discussion</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">FlashRAG can enable researchers to benchmark RAG methods, evaluate their own RAG approaches, and conduct investigations within the RAG field. To demonstrate the capabilities of FlashRAG, we conducted several experiments for providing reproducible benchmarks and exploration.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Experimental Setup.</span> In our main experiment, we employed the latest LLAMA3-8B-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib71" title="">71</a>]</cite> as the generator and the E5-base-v2 as the retriever, utilizing Wikipedia data from December 2018 as the retrieval corpus. The max input length of generator model is set to 4096. For each query, we retrieved five documents. For approaches not utilizing custom-defined prompts, we applied a consistent default prompt, which is shown in the appendix. Methods requiring specific settings and hyperparameters are marked with asterisks in our tables, with their specific configurations noted in the appendix. All experiments are carried out on 8 NVIDIA A100 GPUs.
We conducted experiments on six common datasets: Natural Questions(NQ) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib38" title="">38</a>]</cite>, TriviaQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib39" title="">39</a>]</cite>, HotpotQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib52" title="">52</a>]</cite>, 2WikiMultihopQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib53" title="">53</a>]</cite>, PopQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib40" title="">40</a>]</cite> and WebQuestions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib45" title="">45</a>]</cite>. We use exact match as the metric on NQ,TriviaQA,Web Questions, and token level F1 as the metric on HotpotQA, 2WikiMultihopQA and PopQA.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Methods.</span> We conducted experiments on all supported RAG methods. These methods are categorized based on the RAG component they primarily focused on optimizing: AAR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib72" title="">72</a>]</cite> aims at optimizing the retriever; LongLLMLingua <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib20" title="">20</a>]</cite>, RECOMP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib18" title="">18</a>]</cite>, and Selective-Context <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib21" title="">21</a>]</cite> focus on the refiner to compress input prompts; Ret-Robust <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib73" title="">73</a>]</cite> and REPLUG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib28" title="">28</a>]</cite> focus on optimizing the generator and its related decoding methods; SKR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib10" title="">10</a>]</cite> enhances the judger that decides whether to retrieve for a query; SuRe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib29" title="">29</a>]</cite>, Self-RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib33" title="">33</a>]</cite>, FLARE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib34" title="">34</a>]</cite>, Iter-RetGen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib30" title="">30</a>]</cite>, and ITRG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib31" title="">31</a>]</cite> optimize the entire RAG flow, including multiple retrievals and generation processes.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Main results</h3>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>The performance evaluation of RAG methods was carried out on three datasets. <span class="ltx_text ltx_font_italic" id="S4.T3.7.1">Optimize component</span> represents the primary component optimized by the method, while <span class="ltx_text ltx_font_italic" id="S4.T3.8.2">flow</span> indicates optimization of the entire RAG process. Methods marked with <math alttext="\ast" class="ltx_Math" display="inline" id="S4.T3.2.m1.1"><semantics id="S4.T3.2.m1.1b"><mo id="S4.T3.2.m1.1.1" xref="S4.T3.2.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.m1.1c"><ci id="S4.T3.2.m1.1.1.cmml" xref="S4.T3.2.m1.1.1">∗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.m1.1d">\ast</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.m1.1e">∗</annotation></semantics></math> denote the use of a trained generator.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.4" style="width:433.6pt;height:164.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-138.1pt,52.5pt) scale(0.610922489364484,0.610922489364484) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.4.2.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T3.4.2.3.1.1" style="padding:0.5pt 5.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.2" style="padding:0.5pt 5.0pt;">Optimize</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.3" style="padding:0.5pt 5.0pt;">Pipeline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.4" style="padding:0.5pt 5.0pt;">NQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.5" style="padding:0.5pt 5.0pt;">TriviaQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.6" style="padding:0.5pt 5.0pt;">HotpotQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.7" style="padding:0.5pt 5.0pt;">2Wiki</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.8" style="padding:0.5pt 5.0pt;">PopQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.2.3.1.9" style="padding:0.5pt 5.0pt;">WebQA</th>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T3.4.2.4.2.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.4.2.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.2" style="padding:0.5pt 5.0pt;">component</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.3" style="padding:0.5pt 5.0pt;">type</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.4" style="padding:0.5pt 5.0pt;">(EM)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.5" style="padding:0.5pt 5.0pt;">(EM)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.6" style="padding:0.5pt 5.0pt;">(F1)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.7" style="padding:0.5pt 5.0pt;">(F1)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.8" style="padding:0.5pt 5.0pt;">(F1)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.4.2.4.2.9" style="padding:0.5pt 5.0pt;">(EM)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.4.2.5.1" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.4.2.5.1.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.1.1" style="background-color:#EBEBEB;">Naive Generation</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.2.1" style="background-color:#EBEBEB;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.3.1" style="background-color:#EBEBEB;">Sequential</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.4.1" style="background-color:#EBEBEB;">22.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.5.1" style="background-color:#EBEBEB;">55.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.6.1" style="background-color:#EBEBEB;">28.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.7.1" style="background-color:#EBEBEB;">33.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.8.1" style="background-color:#EBEBEB;">21.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.2.5.1.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.5.1.9.1" style="background-color:#EBEBEB;">18.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.6.2" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.6.2.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.1.1" style="background-color:#FFFFFF;">Standard RAG</span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.2.1" style="background-color:#FFFFFF;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.3.1" style="background-color:#FFFFFF;">Sequential</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.4.1" style="background-color:#FFFFFF;">35.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.5.1" style="background-color:#FFFFFF;">58.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.6.1" style="background-color:#FFFFFF;">35.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.7.1" style="background-color:#FFFFFF;">21.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.8.1" style="background-color:#FFFFFF;">36.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.6.2.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.6.2.9.1" style="background-color:#FFFFFF;">15.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.7.3" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.7.3.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.1.1" style="background-color:#EBEBEB;">AAR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib72" title="">72</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.2.1" style="background-color:#EBEBEB;">Retriever</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.3.1" style="background-color:#EBEBEB;">Sequential</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.4.1" style="background-color:#EBEBEB;">30.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.5.1" style="background-color:#EBEBEB;">56.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.6.1" style="background-color:#EBEBEB;">33.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.7.1" style="background-color:#EBEBEB;">19.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.8.1" style="background-color:#EBEBEB;">36.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.7.3.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.7.3.9.1" style="background-color:#EBEBEB;">16.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.8.4" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.8.4.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.1.1" style="background-color:#FFFFFF;">LongLLMLingua <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib20" title="">20</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.2.1" style="background-color:#FFFFFF;">Refiner</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.3.1" style="background-color:#FFFFFF;">Sequential</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.4.1" style="background-color:#FFFFFF;">32.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.5.1" style="background-color:#FFFFFF;">59.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.6.1" style="background-color:#FFFFFF;">37.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.7.1" style="background-color:#FFFFFF;">25.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.8.1" style="background-color:#FFFFFF;">38.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.8.4.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.8.4.9.1" style="background-color:#FFFFFF;">17.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.9.5" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.9.5.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.1.1" style="background-color:#EBEBEB;">RECOMP-abstractive <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib18" title="">18</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.2.1" style="background-color:#EBEBEB;">Refiner</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.3.1" style="background-color:#EBEBEB;">Sequential</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.4.1" style="background-color:#EBEBEB;">33.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.5.1" style="background-color:#EBEBEB;">56.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.6.1" style="background-color:#EBEBEB;">37.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.7.1" style="background-color:#EBEBEB;">32.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.8.1" style="background-color:#EBEBEB;">39.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.9.5.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.9.5.9.1" style="background-color:#EBEBEB;">20.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.10.6" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.10.6.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.1.1" style="background-color:#FFFFFF;">Selective-Context <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib21" title="">21</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.2.1" style="background-color:#FFFFFF;">Refiner</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.3.1" style="background-color:#FFFFFF;">Sequential</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.4.1" style="background-color:#FFFFFF;">30.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.5.1" style="background-color:#FFFFFF;">55.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.6.1" style="background-color:#FFFFFF;">34.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.7.1" style="background-color:#FFFFFF;">18.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.8.1" style="background-color:#FFFFFF;">33.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.10.6.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.10.6.9.1" style="background-color:#FFFFFF;">17.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.1.1" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.3.1.1.1" style="padding:0.5pt 5.0pt;">
<math alttext="\text{Ret-Robust}^{\ast}" class="ltx_Math" display="inline" id="S4.T3.3.1.1.1.m1.1" style="background-color:#EBEBEB;"><semantics id="S4.T3.3.1.1.1.m1.1a"><msup id="S4.T3.3.1.1.1.m1.1.1" xref="S4.T3.3.1.1.1.m1.1.1.cmml"><mtext id="S4.T3.3.1.1.1.m1.1.1.2" mathbackground="#EBEBEB" xref="S4.T3.3.1.1.1.m1.1.1.2a.cmml">Ret-Robust</mtext><mo id="S4.T3.3.1.1.1.m1.1.1.3" mathbackground="#EBEBEB" xref="S4.T3.3.1.1.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.3.1.1.1.m1.1b"><apply id="S4.T3.3.1.1.1.m1.1.1.cmml" xref="S4.T3.3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.3.1.1.1.m1.1.1">superscript</csymbol><ci id="S4.T3.3.1.1.1.m1.1.1.2a.cmml" xref="S4.T3.3.1.1.1.m1.1.1.2"><mtext id="S4.T3.3.1.1.1.m1.1.1.2.cmml" mathbackground="#EBEBEB" xref="S4.T3.3.1.1.1.m1.1.1.2">Ret-Robust</mtext></ci><ci id="S4.T3.3.1.1.1.m1.1.1.3.cmml" xref="S4.T3.3.1.1.1.m1.1.1.3">∗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.1.1.1.m1.1c">\text{Ret-Robust}^{\ast}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.1.1.1.m1.1d">Ret-Robust start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.T3.3.1.1.1.1" style="background-color:#EBEBEB;"> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib73" title="">73</a>]</cite></span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.2.1" style="background-color:#EBEBEB;">Generator</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.3.1" style="background-color:#EBEBEB;">Sequential</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.4.1" style="background-color:#EBEBEB;">42.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.5.1" style="background-color:#EBEBEB;">68.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.6.1" style="background-color:#EBEBEB;">35.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.7.1" style="background-color:#EBEBEB;">43.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.8.1" style="background-color:#EBEBEB;">57.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.3.1.1.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.3.1.1.9.1" style="background-color:#EBEBEB;">9.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.11.7" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.11.7.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.1.1" style="background-color:#FFFFFF;">SuRe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib29" title="">29</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.2.1" style="background-color:#FFFFFF;">Flow</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.3.1" style="background-color:#FFFFFF;">Branching</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.4.1" style="background-color:#FFFFFF;">37.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.5.1" style="background-color:#FFFFFF;">53.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.6.1" style="background-color:#FFFFFF;">33.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.7.1" style="background-color:#FFFFFF;">20.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.8.1" style="background-color:#FFFFFF;">48.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.11.7.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.11.7.9.1" style="background-color:#FFFFFF;">24.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.12.8" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.12.8.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.1.1" style="background-color:#EBEBEB;">REPLUG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib28" title="">28</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.2.1" style="background-color:#EBEBEB;">Generator</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.3.1" style="background-color:#EBEBEB;">Branching</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.4.1" style="background-color:#EBEBEB;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.5.1" style="background-color:#EBEBEB;">57.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.6.1" style="background-color:#EBEBEB;">31.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.7.1" style="background-color:#EBEBEB;">21.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.8.1" style="background-color:#EBEBEB;">27.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.12.8.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.12.8.9.1" style="background-color:#EBEBEB;">20.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.13.9" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.13.9.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.1.1" style="background-color:#FFFFFF;">SKR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib10" title="">10</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.2.1" style="background-color:#FFFFFF;">Judger</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.3.1" style="background-color:#FFFFFF;">Conditional</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.4.1" style="background-color:#FFFFFF;">25.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.5.1" style="background-color:#FFFFFF;">55.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.6.1" style="background-color:#FFFFFF;">29.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.7.1" style="background-color:#FFFFFF;">28.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.8.1" style="background-color:#FFFFFF;">24.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.13.9.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.13.9.9.1" style="background-color:#FFFFFF;">18.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.2" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.2.1" style="padding:0.5pt 5.0pt;">
<math alttext="\text{Self-RAG}^{\ast}" class="ltx_Math" display="inline" id="S4.T3.4.2.2.1.m1.1" style="background-color:#EBEBEB;"><semantics id="S4.T3.4.2.2.1.m1.1a"><msup id="S4.T3.4.2.2.1.m1.1.1" xref="S4.T3.4.2.2.1.m1.1.1.cmml"><mtext id="S4.T3.4.2.2.1.m1.1.1.2" mathbackground="#EBEBEB" xref="S4.T3.4.2.2.1.m1.1.1.2a.cmml">Self-RAG</mtext><mo id="S4.T3.4.2.2.1.m1.1.1.3" mathbackground="#EBEBEB" xref="S4.T3.4.2.2.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.4.2.2.1.m1.1b"><apply id="S4.T3.4.2.2.1.m1.1.1.cmml" xref="S4.T3.4.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.2.2.1.m1.1.1.1.cmml" xref="S4.T3.4.2.2.1.m1.1.1">superscript</csymbol><ci id="S4.T3.4.2.2.1.m1.1.1.2a.cmml" xref="S4.T3.4.2.2.1.m1.1.1.2"><mtext id="S4.T3.4.2.2.1.m1.1.1.2.cmml" mathbackground="#EBEBEB" xref="S4.T3.4.2.2.1.m1.1.1.2">Self-RAG</mtext></ci><ci id="S4.T3.4.2.2.1.m1.1.1.3.cmml" xref="S4.T3.4.2.2.1.m1.1.1.3">∗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.2.2.1.m1.1c">\text{Self-RAG}^{\ast}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.2.2.1.m1.1d">Self-RAG start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.T3.4.2.2.1.1" style="background-color:#EBEBEB;"> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib33" title="">33</a>]</cite></span>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.2.1" style="background-color:#EBEBEB;">Flow</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.3.1" style="background-color:#EBEBEB;">Loop</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.4.1" style="background-color:#EBEBEB;">36.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.5.1" style="background-color:#EBEBEB;">38.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.6.1" style="background-color:#EBEBEB;">29.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.7.1" style="background-color:#EBEBEB;">25.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.8.1" style="background-color:#EBEBEB;">32.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.2.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.2.9.1" style="background-color:#EBEBEB;">21.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.14.10" style="background-color:#FFFFFF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.2.14.10.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.1.1" style="background-color:#FFFFFF;">FLARE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib34" title="">34</a>]</cite></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.2.1" style="background-color:#FFFFFF;">Flow</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.3.1" style="background-color:#FFFFFF;">Loop</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.4.1" style="background-color:#FFFFFF;">22.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.5.1" style="background-color:#FFFFFF;">55.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.6.1" style="background-color:#FFFFFF;">28.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.7.1" style="background-color:#FFFFFF;">33.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.8.1" style="background-color:#FFFFFF;">20.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.2.14.10.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.14.10.9.1" style="background-color:#FFFFFF;">20.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.2.15.11" style="background-color:#EBEBEB;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.4.2.15.11.1" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.1.1" style="background-color:#EBEBEB;">Iter-RetGen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib30" title="">30</a>]</cite>, ITRG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#bib.bib31" title="">31</a>]</cite></span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.2" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.2.1" style="background-color:#EBEBEB;">Flow</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.3" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.3.1" style="background-color:#EBEBEB;">Loop</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.4" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.4.1" style="background-color:#EBEBEB;">36.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.5" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.5.1" style="background-color:#EBEBEB;">60.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.6" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.6.1" style="background-color:#EBEBEB;">38.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.7" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.7.1" style="background-color:#EBEBEB;">21.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.8" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.8.1" style="background-color:#EBEBEB;">37.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.2.15.11.9" style="padding:0.5pt 5.0pt;"><span class="ltx_text" id="S4.T3.4.2.15.11.9.1" style="background-color:#EBEBEB;">18.2</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The main results of various methods are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4.T3" title="Table 3 ‣ 4.1 Main results ‣ 4 Experimental Result and Discussion ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_tag">3</span></a>. Overall, RAG methods significantly improve compared to the direct generation baseline.
Standard RAG, with advanced retrievers and generators, is a strong baseline, performing well across six datasets. AAR improves retrievers by training the contriever model, and get comparable result to the e5 baseline on multiple datasets.
For refiners, all three methods show notable improvements. Refiners perform especially well on multi-hop datasets like HotpotQA and 2WikiMultihopQA. This is likely because complex problems lead to less accurate document retrieval, creating more noise and requiring refiner optimization.
In generator optimization method , Ret-Robust uses the Llama2-13B model with a lora module, greatly enhancing the generator’s understanding of retrieved documents and outperforming other training-free methods.
The effectiveness of optimizing the RAG process varies by dataset. On simpler datasets like NQ and TriviaQA, FLARE and Iter-RetGen are on par with or slightly below standard RAG. However, on complex datasets that requiring multi-step reasoning, like HotpotQA, there are significant improvements over the baseline. This suggests adaptive retrieval methods are more suited for complex problems, while on simpler tasks, they may incur higher costs with only modest benefits.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Impact of Retrieval on RAG</h3>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F2.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The results of standard RAG process under different number of retrieved documents and retrievers. <span class="ltx_text ltx_font_bold" id="S4.F2.3.1">Left:</span> Average results on six datasets using three different retrievers with varying numbers of retrieved documents. <span class="ltx_text ltx_font_bold" id="S4.F2.4.2">Right:</span> Individual results on six datasets using E5 as the retriever.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In RAG process, the retriever is a crucial component that significantly impacts the results. The quantity and quality of input retrieved documents determine the final answer. However, due to considerations such as cost, existing research works often employs a fixed retriever and a fixed number of retrieved documents, neglecting exploration in this area. To thoroughly investigate the influence of the retrieval process on overall RAG results, we conducted a series of experiments.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4.F2" title="Figure 2 ‣ 4.2 Impact of Retrieval on RAG ‣ 4 Experimental Result and Discussion ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_tag">2</span></a>, we present the results for varying numbers of retrieved documents.
As shown in the left part of Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4.F2" title="Figure 2 ‣ 4.2 Impact of Retrieval on RAG ‣ 4 Experimental Result and Discussion ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_tag">2</span></a>, the overall performance is optimal when the number of retrieved documents is 3 or 5. Both an excessive and insufficient number of retrieved documents lead to a significant decrease in performance, with a drop of up to 40%. This trend is consistent across different retrievers, including both dense and sparse retrieval methods. Additionally, we observe that when the number of retrieved documents is large, the results of the three different quality retrievers converge. In contrast, for the top1 results, there is a substantial gap between dense methods (E5, Bge) and BM25, indicating that the fewer documents retrieved, the greater the impact of the retriever’s quality on the final result.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">In the right part of Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.13576v1#S4.F2" title="Figure 2 ‣ 4.2 Impact of Retrieval on RAG ‣ 4 Experimental Result and Discussion ‣ FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research"><span class="ltx_text ltx_ref_tag">2</span></a>, we plot the impact of the number of retrieved documents on different datasets. It can be seen that on most datasets, using top3 or top5 retrieved results yields the best performance, suggesting that this may represent a good balance between the quality of retrieved documents and noise.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our toolkit currently has some limitations, which we plan to gradually improve in the future. (1) Although we strive to encompass many representative RAG methods, due to time and cost considerations, we have not included all existing RAG works. This may require contributions from the open-source community in the future. (2) Our toolkit lacks support for training RAG-related components. We considered training during the initial design, but given the diversity of training methods and the presence of many repositories specifically dedicated to the training of retrievers and generators, we did not include this part. In the future, we may add some helping scripts to provide some assistance for researchers’ training needs.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">To address the challenges researchers face in replicating studies and the high development costs associated with research in the RAG domain, we introduce a modular RAG toolkit. Our toolkit includes comprehensive RAG benchmark datasets, implementations of advanced RAG methods, and code for pre-processing corpus and multiple evaluation metrics.
It enable researchers to easily reproduce existing RAG methods, develop new algorithms, and focus on optimizing their research.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al.

</span>
<span class="ltx_bibblock">Improving language models by retrieving from trillions of tokens.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">International Conference on Machine Learning</span>, pages 2206–2240. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang.

</span>
<span class="ltx_bibblock">REALM: Retrieval-augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">International Conference on Machine Learning</span>. JMLR.org, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung.

</span>
<span class="ltx_bibblock">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Harrison Chase.

</span>
<span class="ltx_bibblock">LangChain, October 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Jerry Liu.

</span>
<span class="ltx_bibblock">LlamaIndex, November 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Malte Pietsch, Timo Möller, Bogdan Kostic, Julian Risch, Massimiliano Pippi, Mayank Jobanputra, Sara Zanzottera, Silvano Cerza, Vladimir Blagojevic, Thomas Stadelmann, Tanay Soni, and Sebastian Lee.

</span>
<span class="ltx_bibblock">Haystack: the end-to-end NLP framework for pragmatic builders, November 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Peter Izsak, Moshe Berchansky, Daniel Fleischer, and Ronen Laperdon.

</span>
<span class="ltx_bibblock">fastRAG: Efficient Retrieval Augmentation and Generation Framework, February 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Xiao Yu, Yunan Lu, and Zhou Yu.

</span>
<span class="ltx_bibblock">Localrqa: From generating data to locally training, testing, and deploying retrieval-augmented qa systems, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jeffrey Kim Bwook Kim.

</span>
<span class="ltx_bibblock">AutoRAG, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Yile Wang, Peng Li, Maosong Sun, and Yang Liu.

</span>
<span class="ltx_bibblock">Self-knowledge guided retrieval augmentation for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 10303–10315, Singapore, December 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.

</span>
<span class="ltx_bibblock">Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)</span>, pages 2356–2362, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 6769–6781, Online, November 2020. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei.

</span>
<span class="ltx_bibblock">Text embeddings by weakly-supervised contrastive pre-training.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2212.03533</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, and Arnold Overwijk.

</span>
<span class="ltx_bibblock">Approximate nearest neighbor negative contrastive learning for dense text retrieval.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">International Conference on Learning Representations</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou.

</span>
<span class="ltx_bibblock">The faiss library.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Jeff Johnson, Matthijs Douze, and Hervé Jégou.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with GPUs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">IEEE Transactions on Big Data</span>, 7(3):535–547, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Fangyuan Xu, Weijia Shi, and Eunsol Choi.

</span>
<span class="ltx_bibblock">Recomp: Improving retrieval-augmented lms with compression and selective augmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2310.04408</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu.

</span>
<span class="ltx_bibblock">LLMLingua: Compressing prompts for accelerated inference of large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 13358–13376. Association for Computational Linguistics, December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, , Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, and Lili Qiu.

</span>
<span class="ltx_bibblock">LongLLMLingua: Accelerating and enhancing llms in long context scenarios via prompt compression.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">ArXiv preprint</span>, abs/2310.06839, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Yucheng Li.

</span>
<span class="ltx_bibblock">Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2304.12102</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</span>, pages 38–45, Online, October 2020. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">International Conference on Learning Representations</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave.

</span>
<span class="ltx_bibblock">Leveraging passage retrieval with generative models for open domain question answering.

</span>
<span class="ltx_bibblock">In Paola Merlo, Jorg Tiedemann, and Reut Tsarfaty, editors, <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</span>, pages 874–880, Online, April 2021. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen tau Yih.

</span>
<span class="ltx_bibblock">Replug: Retrieval-augmented black-box language models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha, and Jinwoo Shin.

</span>
<span class="ltx_bibblock">Sure: Summarizing retrievals using answer candidates for open-domain QA of LLMs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali, editors, <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 9248–9274, Singapore, December 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Zhangyin Feng, Xiaocheng Feng, Dezhi Zhao, Maojin Yang, and Bing Qin.

</span>
<span class="ltx_bibblock">Retrieval-generation synergy augmented large language models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah Smith, and Mike Lewis.

</span>
<span class="ltx_bibblock">Measuring and narrowing the compositionality gap in language models.

</span>
<span class="ltx_bibblock">In Houda Bouamor, Juan Pino, and Kalika Bali, editors, <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 5687–5711, Singapore, December 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-RAG: Learning to retrieve, generate, and critique through self-reflection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig.

</span>
<span class="ltx_bibblock">Active retrieval augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2305.06983</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Aligning ai with shared human values.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Can a suit of armor conduct electricity? a new dataset for open book question answering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">EMNLP</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.

</span>
<span class="ltx_bibblock">Natural questions: A benchmark for question answering research.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">Transactions of the Association for Computational Linguistics</span>, 7:452–466, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension.

</span>
<span class="ltx_bibblock">In Regina Barzilay and Min-Yen Kan, editors, <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 1601–1611, Vancouver, Canada, July 2017. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Hannaneh Hajishirzi, and Daniel Khashabi.

</span>
<span class="ltx_bibblock">When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">arXiv preprint</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ questions for machine comprehension of text.

</span>
<span class="ltx_bibblock">In Jian Su, Kevin Duh, and Xavier Carreras, editors, <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</span>, pages 2383–2392, Austin, Texas, November 2016. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.

</span>
<span class="ltx_bibblock">MS MARCO: A human-generated MAchine reading COmprehension dataset, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Tomáš Koˇciský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette.

</span>
<span class="ltx_bibblock">The NarrativeQA reading comprehension challenge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">Transactions of the Association for Computational Linguistics</span>, TBD:TBD, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Yi Yang, Wen-tau Yih, and Christopher Meek.

</span>
<span class="ltx_bibblock">WikiQA: A challenge dataset for open-domain question answering.

</span>
<span class="ltx_bibblock">In Lluís Màrquez, Chris Callison-Burch, and Jian Su, editors, <span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</span>, pages 2013–2018, Lisbon, Portugal, September 2015. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang.

</span>
<span class="ltx_bibblock">Semantic parsing on Freebase from question-answer pairs.

</span>
<span class="ltx_bibblock">In David Yarowsky, Timothy Baldwin, Anna Korhonen, Karen Livescu, and Steven Bethard, editors, <span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</span>, pages 1533–1544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Sewon Min, Julian Michael, Hannaneh Hajishirzi, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">AmbigQA: Answering ambiguous open-domain questions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">EMNLP</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi.

</span>
<span class="ltx_bibblock">Social IQa: Commonsense reasoning about social interactions.

</span>
<span class="ltx_bibblock">In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan, editors, <span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</span>, pages 4463–4473, Hong Kong, China, November 2019. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant.

</span>
<span class="ltx_bibblock">CommonsenseQA: A question answering challenge targeting commonsense knowledge.

</span>
<span class="ltx_bibblock">In Jill Burstein, Christy Doran, and Thamar Solorio, editors, <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</span>, pages 4149–4158, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Boolq: Exploring the surprising difficulty of natural yes/no questions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">NAACL</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi.

</span>
<span class="ltx_bibblock">Piqa: Reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">AAAI Conference on Artificial Intelligence</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Ashwin Kalyan, Abhinav Kumar, Arjun Chandrasekaran, Ashish Sabharwal, and Peter Clark.

</span>
<span class="ltx_bibblock">How much coffee was consumed during emnlp 2019? fermi problems: A new reasoning challenge for ai.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2110.14207</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.

</span>
<span class="ltx_bibblock">HotpotQA: A dataset for diverse, explainable multi-hop question answering.

</span>
<span class="ltx_bibblock">In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii, editors, <span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</span>, pages 2369–2380, Brussels, Belgium, October-November 2018. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa.

</span>
<span class="ltx_bibblock">Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">Proceedings of the 28th International Conference on Computational Linguistics</span>, pages 6609–6625, Barcelona, Spain (Online), December 2020. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">MuSiQue: Multihop questions via single-hop question composition.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">Transactions of the Association for Computational Linguistics</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-Wei Chang.

</span>
<span class="ltx_bibblock">ASQA: Factoid questions meet long-form answers.

</span>
<span class="ltx_bibblock">In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, <span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, pages 8273–8288, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli.

</span>
<span class="ltx_bibblock">ELI5: Long form question answering.

</span>
<span class="ltx_bibblock">In Anna Korhonen, David Traum, and Lluís Màrquez, editors, <span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</span>, pages 3558–3567, Florence, Italy, July 2019. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">TruthfulQA: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, <span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 3214–3252, Dublin, Ireland, May 2022. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the AI2 reasoning challenge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">CoRR</span>, abs/1803.05457, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Fürstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum.

</span>
<span class="ltx_bibblock">Robust disambiguation of named entities in text.

</span>
<span class="ltx_bibblock">In Regina Barzilay and Mark Johnson, editors, <span class="ltx_text ltx_font_italic" id="bib.bib60.1.1">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</span>, pages 782–792, Edinburgh, Scotland, UK., July 2011. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rocktäschel, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">KILT: a benchmark for knowledge intensive language tasks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib61.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</span>, pages 2523–2544, Online, June 2021. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Simone Tedeschi, Simone Conia, Francesco Cecconi, and Roberto Navigli.

</span>
<span class="ltx_bibblock">Named Entity Recognition for Entity Linking: What works and what’s next.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib62.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</span>, pages 2584–2596, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Hady ElSahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon S. Hare, Frédérique Laforest, and Elena Simperl.

</span>
<span class="ltx_bibblock">T-rex: A large scale alignment of natural language with knowledge base triples.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018, Miyazaki, Japan, May 7-12, 2018.</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Zero-shot relation extraction via reading comprehension.

</span>
<span class="ltx_bibblock">In Roger Levy and Lucia Specia, editors, <span class="ltx_text ltx_font_italic" id="bib.bib64.1.1">Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</span>, pages 333–342, Vancouver, Canada, August 2017. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.

</span>
<span class="ltx_bibblock">FEVER: a large-scale dataset for fact extraction and VERification.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">NAACL-HLT</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston.

</span>
<span class="ltx_bibblock">Wizard of Wikipedia: Knowledge-powered conversational agents.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">International Conference on Learning Representations</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Hiroaki Hayashi, Prashant Budania, Peng Wang, Chris Ackerson, Raj Neervannan, and Graham Neubig.

</span>
<span class="ltx_bibblock">Wikiasp: A dataset for multi-domain aspect-based summarization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">Transactions of the Association for Computational Linguistics (TACL)</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes.

</span>
<span class="ltx_bibblock">Reading Wikipedia to answer open-domain questions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">Association for Computational Linguistics (ACL)</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</span>, ACL ’02, page 311–318, USA, 2002. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">Text Summarization Branches Out</span>, pages 74–81, Barcelona, Spain, July 2004. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
AI@Meta.

</span>
<span class="ltx_bibblock">Llama 3 model card.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Zichun Yu, Chenyan Xiong, Shi Yu, and Zhiyuan Liu.

</span>
<span class="ltx_bibblock">Augmentation-adapted retriever improves generalization of language models as generic plug-in.

</span>
<span class="ltx_bibblock">In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, <span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 2421–2436, Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Berant.

</span>
<span class="ltx_bibblock">Making retrieval-augmented language models robust to irrelevant context, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri May 24 15:36:14 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
