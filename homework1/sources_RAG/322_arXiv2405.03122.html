<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases</title>
<!--Generated on Tue Oct 15 09:12:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
6G,  LLM,  Retrieval-augmented Generation
" lang="en" name="keywords"/>
<base href="/html/2405.03122v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S1" title="In Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2" title="In Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">6G Capabilities, Services, and Use Cases</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2.SS1" title="In II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">6G Network Capabilities</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2.SS2" title="In II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">B2B 6G Services and Use Cases</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2.SS3" title="In II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">Native Services in O-RAN</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S3" title="In Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">LLMs and 6G</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S3.SS1" title="In III LLMs and 6G ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Introduction to LLMs</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S3.SS2" title="In III LLMs and 6G ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">LLMs and 6G</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4" title="In Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Prototype Operation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.SS1" title="In IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Phase 1 Knowledge Database Initialisation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.SS2" title="In IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Phase 2 Global Innovator Application and Contribution</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.SS3" title="In IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Phase 3 Feedback-driven Platform and Network Optimization</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S5" title="In Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Community Engagement &amp; Future</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S6" title="In Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yun Tang, Weisi Guo
</span><span class="ltx_author_notes">Authors are with Cranfield University, UK. This work is supported by EPSRC CHEDDAR: Communications Hub For Empowering Distributed ClouD Computing Applications And Research (EP/X040518/1) (EP/Y037421/1).
All community-contributed use cases and specifications are openly available at our website: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ntutangyun.github.io/llm_6g_frontend" title="">https://ntutangyun.github.io/llm_6g_frontend</a>.
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">6G Open Radio Access Networks (O-RAN) promises to open data interfaces to enable plug-and-play service Apps, many of which are consumer and business-facing. Opening up 6G access lowers the barrier to innovation but raises the challenge that the required communication specifications are not fully known to all service designers. As such, business innovators must either be familiar with 6G standards or consult with experts. Enabling consistent, unbiased, rapid, and low-cost requirement assessment and specification generation is crucial to the O-RAN innovation ecosystem.</p>
<p class="ltx_p" id="id2.id2">Here, we discuss our initiative to bridge service specification gaps between network service providers and business innovators leveraging Large Language Models (LLMs). We first review the state-of-the-art and motivation in 6G plug-and-play services, capabilities, potential use cases and LLMs. We identify an ample innovation space for hybrid use cases that may require diverse and variational wireless functionalities across its operating time. We show that the network specification can be automated and present the first automatic retrieval-augmented network service specification framework for 6G use cases. To enable public acceptance and feedback, a website interface is published for the research and industrial community to experiment with the framework. We hope this review highlights the need for emerging foundation models for this area and motivates researcher engagement and contribution to the community through our framework.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
6G, LLM, Retrieval-augmented Generation

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The future generation (6G) of communication networks are envisioned to push the boundary of networking and computation capabilities, supporting cutting-edge services such as Hyper-reliable Low-Latency Communication, Massive Communication and Ubiquitous Connectivity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib2" title="">2</a>]</cite>. One major proposed area is the opening up of data interfaces in the Radio Access Network.
The O-RAN ecosystem enables a wide range of internal RAN management and external B2B services for diverse use cases, encouraging innovation from start-ups and smaller enterprises <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib4" title="">4</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The open challenge is that some innovators may not understand the detailed 6G network specifications available based on their business needs. Each use case may have several sub-tasks that require different and evolving 6G network specifications. Traditionally, the designer of these use cases would need to seek in-house or external consultancy with telecommunication experts (e.g., Ericsson). However, this can prove costly, incur delays, and may result in variational advice, deterring many innovators.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="312" id="S1.F1.g1" src="x1.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Functional overview of the full-stack platform with a website frontend and knowledge database backend bridging and assisting network service providers and networked use case innovators.</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">On the other hand, the network service providers must thoroughly consider the expected use case demands when planning the optimal allocation of network infrastructures (edge nodes and base stations) and resources (bandwidth and data rate). While existing use cases are categorized <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib2" title="">2</a>]</cite> based on the predominant network specifications (e.g., <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">telemedicine</span> is often placed under <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">hyper-reliable low-latency communication</span> category), the emergence of hybrid or rare use cases with mixed or dynamic network requirements poses open challenges.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">From the use case innovator’s point of view, an automated process of identifying the appropriate balance of network specifications based on the use case description and the current accessible networking capabilities would aid in the innovation and development of user applications. Meanwhile, from the network service provider’s point of view, a collection of concrete use cases with comprehensive network service specifications would also significantly benefit the implementation of resource management plans.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Addressing the demand above, this article presents our initiative to construct a knowledge database with a public interface for the design of future diverse and dynamic networked use cases, leveraging the power of retrieval-augmented Large Language Modes (LLMs) as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S1.F1" title="Figure 1 ‣ I Introduction ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, we first review the potential 6G use cases, corresponding network service specifications, and the limitations of the current specification descriptions (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2" title="II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">II</span></a>). Then, we review the state-of-the-art (SOTA) LLMs and their applications in the 6G network (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S3" title="III LLMs and 6G ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">III</span></a>). Informed by the literature review, we design a crowd-sourced knowledge database of use cases with their specifications that powers a RAG framework to enable automatic use case extraction and specification generation (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4" title="IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">IV</span></a>).</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">6G Capabilities, Services, and Use Cases</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">6G Network Capabilities</span>
</h3>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="482" id="S2.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>6G network capabilities and service categories with a use case example and primary network capability specifications highlighted. Adapted from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib1" title="">1</a>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">As discussed in the IMT 2030 standard <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib1" title="">1</a>]</cite> (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2.F2" title="Figure 2 ‣ II-A 6G Network Capabilities ‣ II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">2</span></a>) and many other literature, 6G is envisioned to excel in many networking capabilities compared to precedent generations, specifically:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">Peak data rate: the highest data rate achievable per device can be up to 200 Gbit/s.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">User experienced data rate: ubiquitously available data rate per device can be up to 500Mbit/s.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">Area traffic capacity: total traffic throughput per geographic area can be up to 50 Mbit/s/m<sup class="ltx_sup" id="S2.I1.i3.p1.1.1">2</sup>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.2">Connection density: total number of connected devices per unit area can be up to <math alttext="10^{8}" class="ltx_Math" display="inline" id="S2.I1.i4.p1.1.m1.1"><semantics id="S2.I1.i4.p1.1.m1.1a"><msup id="S2.I1.i4.p1.1.m1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.cmml"><mn id="S2.I1.i4.p1.1.m1.1.1.2" xref="S2.I1.i4.p1.1.m1.1.1.2.cmml">10</mn><mn id="S2.I1.i4.p1.1.m1.1.1.3" xref="S2.I1.i4.p1.1.m1.1.1.3.cmml">8</mn></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.1.m1.1b"><apply id="S2.I1.i4.p1.1.m1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1">superscript</csymbol><cn id="S2.I1.i4.p1.1.m1.1.1.2.cmml" type="integer" xref="S2.I1.i4.p1.1.m1.1.1.2">10</cn><cn id="S2.I1.i4.p1.1.m1.1.1.3.cmml" type="integer" xref="S2.I1.i4.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.1c">10^{8}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i4.p1.1.m1.1d">10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT</annotation></semantics></math> devices/km<sup class="ltx_sup" id="S2.I1.i4.p1.2.1">2</sup>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1">Mobility: the maximum speed with defined QoS can be up to 1000 km/h.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i6.p1">
<p class="ltx_p" id="S2.I1.i6.p1.1">Latency: the minimum latency over the air interface can be as small as 0.1 ms.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i7.p1">
<p class="ltx_p" id="S2.I1.i7.p1.1">Reliability: the probability for successfully transmitting a predefined amount of data within a predetermined time duration can be as high as <math alttext="1-10^{-7}" class="ltx_Math" display="inline" id="S2.I1.i7.p1.1.m1.1"><semantics id="S2.I1.i7.p1.1.m1.1a"><mrow id="S2.I1.i7.p1.1.m1.1.1" xref="S2.I1.i7.p1.1.m1.1.1.cmml"><mn id="S2.I1.i7.p1.1.m1.1.1.2" xref="S2.I1.i7.p1.1.m1.1.1.2.cmml">1</mn><mo id="S2.I1.i7.p1.1.m1.1.1.1" xref="S2.I1.i7.p1.1.m1.1.1.1.cmml">−</mo><msup id="S2.I1.i7.p1.1.m1.1.1.3" xref="S2.I1.i7.p1.1.m1.1.1.3.cmml"><mn id="S2.I1.i7.p1.1.m1.1.1.3.2" xref="S2.I1.i7.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S2.I1.i7.p1.1.m1.1.1.3.3" xref="S2.I1.i7.p1.1.m1.1.1.3.3.cmml"><mo id="S2.I1.i7.p1.1.m1.1.1.3.3a" xref="S2.I1.i7.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S2.I1.i7.p1.1.m1.1.1.3.3.2" xref="S2.I1.i7.p1.1.m1.1.1.3.3.2.cmml">7</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i7.p1.1.m1.1b"><apply id="S2.I1.i7.p1.1.m1.1.1.cmml" xref="S2.I1.i7.p1.1.m1.1.1"><minus id="S2.I1.i7.p1.1.m1.1.1.1.cmml" xref="S2.I1.i7.p1.1.m1.1.1.1"></minus><cn id="S2.I1.i7.p1.1.m1.1.1.2.cmml" type="integer" xref="S2.I1.i7.p1.1.m1.1.1.2">1</cn><apply id="S2.I1.i7.p1.1.m1.1.1.3.cmml" xref="S2.I1.i7.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i7.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i7.p1.1.m1.1.1.3">superscript</csymbol><cn id="S2.I1.i7.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S2.I1.i7.p1.1.m1.1.1.3.2">10</cn><apply id="S2.I1.i7.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i7.p1.1.m1.1.1.3.3"><minus id="S2.I1.i7.p1.1.m1.1.1.3.3.1.cmml" xref="S2.I1.i7.p1.1.m1.1.1.3.3"></minus><cn id="S2.I1.i7.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="S2.I1.i7.p1.1.m1.1.1.3.3.2">7</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i7.p1.1.m1.1c">1-10^{-7}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i7.p1.1.m1.1d">1 - 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i8.p1">
<p class="ltx_p" id="S2.I1.i8.p1.1">Positioning accuracy: the approximated position of connected devices can be as accurate as 1 cm.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i9.p1">
<p class="ltx_p" id="S2.I1.i9.p1.1">Other: details of other non-user-facing capabilities such as spectrum efficiency can be found in the standard <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib1" title="">1</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">In addition to the enhanced networking capabilities, we will in future (see Section <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S5" title="V Community Engagement &amp; Future ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">V</span></a>) also include 6G capabilities in AI, privacy, security, and sensing.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.5.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.6.2">B2B 6G Services and Use Cases</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The major driving forces pushing the capability boundaries are the use cases. Different use cases demand different sets of networking capabilities. Although it might be uncommon, if not infeasible, for a single use case to have the highest requirement in every specification facet, it is pretty common to have a group (i.e., a service category) of use cases sharing the same specification pattern, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2.F2" title="Figure 2 ‣ II-A 6G Network Capabilities ‣ II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">2</span></a>, where the service categories are often named by the predominant capability specifications. For example, the <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">Immersive Communication</span> category contains use cases such as immersive XR and holographic telepresence requiring the transmission of high-resolution video, audio, holograms or haptic-type data and accurate position/gesture estimations at real-time latency. As a result, the use cases of this category share the same specification pattern of high data rate, high positioning accuracy, and real-time low latency. In contrast, the use cases of the <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.2">Massive Communication</span> category highly depend on the connection density with relatively softer latency and reliability constraints.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Such a high-level categorization approach helps identify the most stringent network service requirements. However, mapping a use case with a single requirement pattern, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S2.F2" title="Figure 2 ‣ II-A 6G Network Capabilities ‣ II 6G Capabilities, Services, and Use Cases ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">2</span></a>, would hinder optimal networking and computation resource allocation due to the limitations below.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">Limitation 1: Disregard for Functional Diversity</span> New use cases may arise which do not belong to any specific category but, instead, have hybrid specification patterns as a single use case often initiates multiple wireless connections for different functionalities. For example, an autonomous vehicle may have one <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.2">integrated sensing and communication</span> connection with edge nodes for collaborative sensing, one <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.3">hyper-reliable low-latency communication</span> connection with surrounding traffic participants for collaborative motion planning and another regular connection for occasional system monitoring. It would be a waste of resources if the monitoring function shared the same hyper-reliable, low-latency connection channel.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p4.1.1">Limitation 2: Disregard for Temporal Diversity</span> networking specifications may vary over time as new functional connections arise during the use case life-cycle. Take the autonomous driving use case, for example. An ad hoc <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.2">immersive communication</span> connection with a remote fallback operator may be established upon encountering emergencies with entirely different networking specifications from the existing connections above. Such temporal diversity requires dynamic reallocation of networking resources in real-time for optimal QoS and economy and hence also demands due consideration.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.5.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.6.2">Native Services in O-RAN</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">It is expected that many of the native services will be implemented as xApps or rApps in the O-RAN, with the primary goal of optimizing the networking resources based on the real-time use case specifications. xApps are installed on near real-time RAN intelligent controllers (Near-RT RIC) and perform sub-second network optimization tasks such as connection management <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib5" title="">5</a>]</cite>. On the other hand, rApps are installed on non-real-time RIC (Non-RT RIC) and focus on broader network management strategy and longer-term network planning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib6" title="">6</a>]</cite>. Regardless of the implemented optimization algorithms, whether pre-fixed control policies from look-up tables or ML/AI techniques, we identify the following limitation during the current O-RAN app development process.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">Limitation 3 Limited sharing of design references</span> Current O-RAN apps are often designed based on a limited set of manually crafted hypothetical use cases, which cannot reflect the diverse demands of the use case innovation community. Such a lack of up-to-date references hinders the design and deployment process and thus leads to poor performance for early adopters.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">LLMs and 6G</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Introduction to LLMs</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">LLMs are language models for natural language processing (understanding natural language input and generating natural language output). Modelled by billions of parameters and trained on vast corpora of text data, LLMs can learn intricate patterns of language usage and knowledge across disciplines. As a result, they have shown remarkable performance across a wide range of tasks, including machine translation, text summarization, sentiment analysis, and even more complex applications like conversational AI and code generation, and thus garnered widespread adoption across numerous application domains. Worth noting is that they can convert unstructured natural language into formal specifications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib7" title="">7</a>]</cite>. Through fine-tuning and a human-in-the-loop, it can pave a pathway towards being compliant with IEEE property specification language (PSL), Signal Temporal Logic (STL), or System Verilog Assertions.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">New LLMs are developed and released almost weekly and the SOTA LLMs are GPT-4o, Llama 3.1 405B, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3.1 (70B) and Mistral Large 2, demonstrating exceptional capabilities across various benchmarks on general language tasks<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>See example comparison of AI models across quality, performance and price: artificialanalysis.ai</span></span></span>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Even the best LLMs make mistakes due to inevitable misinformation in the training data. In addition, LLMs are known to hallucinate, generating plausible but incorrect or nonsensical information, which can be particularly problematic when they confidently present fabricated facts or details that have no basis in reality. Leveraging the in-context learning capability, the input prompt to LLMs can be augmented with validated references (i.e., retrieval-augmented generation) which can significantly mitigate the hallucination issue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib8" title="">8</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">LLMs and 6G</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Researchers have made efforts to harness the power of LLMs in the era of 6G networks focusing on three main application topics:</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Topic 1: 6G Network Design for LLMs</span> where the 6G network architecture is explicitly customised for embedding LLMs. For example, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib9" title="">9</a>]</cite> envisioned a 6G mobile edge computing (MEC) architecture consisting of <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">network management component</span> for thering global network knowledge and orchestrating model training/inference across the edge nodes and <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.3">edge model caching component</span> for caching LLM models at edge nodes, and discussed techniques such as distributed learning and split inference to enable training and inference at RAN nodes with limited computation resources.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.2.1">Topic 2: LLM for B2B 6G Services</span> where the 6G network empowers LLMs to offer intelligence services to 6G customer’s use cases. For example, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib10" title="">10</a>]</cite> proposes a split learning framework where small LLMs (<math alttext="\leq" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mo id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><leq id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\leq</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">≤</annotation></semantics></math>10B) are installed through RAN connection on end user’s mobile devices to provide multi-modal user input interface and execute the intelligence tasks allocated by large LLMs (<math alttext="&gt;" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mo id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><gt id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">&gt;</annotation></semantics></math>10B) installed on edge (or cloud) servers. The large LLMs maintain a Digital Twin (DT) connected to an internal and external knowledge database for decision grounding. In general, this application topic mainly focuses on the following areas <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib10" title="">10</a>]</cite>:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">How do distributed LLM services across the O-RAN enable user access?</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">How can LLMs enable reliable digital twins (DTs) that capture reasoning, planning, verification and reflection?</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">How to create context-aware (e.g., semantic, task-aware) communication or integrated sensing?</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Topic 3: LLM for Native 6G Services</span> where LLMs are utilised (e.g., in xApps and rApps) for autonomous 6G network management. The general workflow is that: first, the LLMs perceive the communication environment semantics by parsing the multi-modal input data either from user input or network sensors; then, LLMs make informed decisions in real-time to adjust networking parameters or allocate networking resources to improve communication QoS; and last, LLMs keep evolving themselves by distributed learning techniques from past experiences and new scenarios.</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">In fact, works under Topic 3 can be regarded as indirect enablers for those in Topic 2 since, after all, the 6G network capabilities are enhanced for and evaluated by the QoS of serviced use cases. Hence, the focal point is the definition of networked use cases and their dynamic networking specifications, and we hereby identify the following limitation:</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Limitation 4 Absence of Automated Network Specification Tool</span> In all these cases, the general assumption is that 6G already has a set of services (semantic-aware ISAC, DTs, edge LLM access) and well-defined specifications (data rate, latency, reliability), and the use cases engage with these services and capabilities in well-defined ways. We expect 6G O-RAN to attract many innovators with <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.2">plug-and-play</span> business use cases of a diverse range of demands <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib3" title="">3</a>]</cite>. However, what if the use case innovators do not know what services or capabilities they need or are available in the designing or operating phase? Reading the network specification documents does not solve this due to the following limitations: 1) the documents do not cover every diverse use case; 2) the existing documents are often network service provider-oriented discussing the network architecture designs instead of use case innovator-focused discussing concrete use case networking requirements, and 3) the documents cannot offer live resource information available in the network. In these situations, we may need LLMs to play a different role, one where they help the use case innovators to specify 6G network requirements in real time based on the usage context and up-to-date network knowledge.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Prototype Operation</span>
</h2>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="378" id="S4.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Overview of platform operation phases (green for network service providers and blue for use case innovators): (Phase 1) network service provider initializes the knowledge database; (Phase 2) the community benefits from the automated specification generation and contributes with new use cases and feedbacks; and (Phase 3) the network service operator benefits from the community contributions for platform update and network development.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To address the limitations above, we initiate a crowd-sourced knowledge database for 6G use cases and implement an extensible user interface for engaging the stakeholders. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.F3" title="Figure 3 ‣ IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">3</span></a> details the three operation phases of the platform for both network service providers (Phase 1 and 3) and use case innovators (Phase 2), which are discussed in a top-down fashion in the following subsections. The RAG pipeline is built with the open-source LlamaIndex library and the knowledge database is powered by MongoDB Atlas Database.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Phase 1 Knowledge Database Initialisation</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">This phase constructs the knowledge database with seed use cases and corresponding network specifications. LLMs are utilised via prompt engineering to extract the use case knowledge from the given documents (network standards, white papers, publications, etc.) and format them according to the use case ontology.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="401" id="S4.F4.g1" src="x4.png" width="321"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Use case ontology presented as UML class diagrams.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Use Case Ontology</span> As discussed in Limitations 1 and 2, a single use case comprises a dynamic list of networked communication sub-processes, each requiring distinct network specifications tailored to its individual needs. To embrace such flexibility, we design a minimalist ontology presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.F4" title="Figure 4 ‣ IV-A Phase 1 Knowledge Database Initialisation ‣ IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">4</span></a> for use cases and their networked communication processes, modelled in Unified Modeling Language (UML) for easy implementation and extension.
The ontology can be customized manually by networking experts or automatically using LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib11" title="">11</a>]</cite>.
Both use cases and their communication processes are indexed by the <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.2">id</span> attribute and described by the <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.3">name</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.4">description</span> attributes, which are essential for semantic matching in the RAG retrieval phase. A use case contains multiple communication processes. Each communication process represents a single wireless connection served by a single network slice for a single communication purpose established at any time (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.5">is_real_time</span>) during the use case life-cycle for either transmitting or receiving (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.6">direction</span>) messages of a specific type (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.7">message_type</span>). These three metadata attributes (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.8">is_real_time</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.9">direction</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.10">message_type</span>) are explicitly introduced to assist the inference of the remaining network specification attribute values leveraging the chain-of-thought philosophy. Eight typical network specification metrics for wireless use cases are considered, i.e., <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.11">user_experienced_data_rate_mbps</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.12">latency_ms</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.13">mobility_kmps</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.14">reliability_percentage</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.15">connectivity_density_per_m2</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.16">area_traffic_capacity_mbps_per_m2</span>, <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.17">position_accuracy_cm</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.18">peak_data_rate_gbps</span>, whose value ranges can be configured by network service providers or automatically derived from the initialisation documents utilising LLMs.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Knowledge Database Design</span> The knowledge database comprises a regular and a vector database, storing the raw textual data and their corresponding vector embedding, respectively. Hence, the vector database is used for semantic matching during the RAG retrieval process, and the raw textual data of the matched use cases are then extracted from the regular database to compose the final prompt context.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">UI/UX Design</span> A website-based user interface aims to facilitate the use case ontology configuration, document submission, LLM selection, prompt customisation and use case validation in the initialisation phase.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Phase 2 Global Innovator Application and Contribution</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Through the website interface, use case innovators can 1) view and comment (or vote) the published use cases and extracted knowledge; 2) share their peer-reviewed papers for knowledge extraction; 3) query the network specification through RAG with their use case description; and 4) contribute their use cases. The user-contributed use cases and documents aim to be automatically verified by LLMs or manually by domain experts before being merged into the knowledge database, to ensure the authenticity of the knowledge database, and based on this, the trustworthiness of the generated specification.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="313" id="S4.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Illustration of the core RAG workflow for automatic network specification generation for user-described use cases.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Automatic Use Case Specification Generation</span> For novice use case developers, a concise description of the intended networked application is all the system needs to suggest the necessary communication processes and infer the corresponding network specifications. In addition, similar use cases matched during the RAG retrieval process will also be returned to the developer for reference.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.F5" title="Figure 5 ‣ IV-B Phase 2 Global Innovator Application and Contribution ‣ IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the core workflow of the RAG process during automatic network specification generation including the following steps:</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">The name and description of the use case are embedded into numeric vectors via embedding models (e.g., <span class="ltx_text ltx_font_italic" id="S4.I1.i1.p1.1.1">text-embedding-ada-002</span> model by OpenAI). The vector captures the semantic meaning of the queried use case description.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">All the use cases stored in the knowledge database are matched with the query and sorted by the semantic distance (e.g., via cosine similarity). Due to the limited context length, only the top N matched use cases from the knowledge database are selected as the final retrieval results.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">Appropriate prompt engineering (e.g., templates) can be applied to integrate the queried and retrieved use cases into a single LLM prompt and feed into an LLM for RAG-informed generation.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">The use case ontology is used to derive the desired LLM output format and implement the output parser, which returns a list of structured communication processes.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">Radar (or spider) charts are used to visualise each communication process’s numerical network specification metrics.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">Advanced prompt engineering techniques such as user query pre-processing and retrieval result post-process (e.g., re-ranking, transformation, filtering) are applicable but omitted for brevity in the illustration.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Phase 3 Feedback-driven Platform and Network Optimization</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The knowledge database aims to bridge the communication gap between network service providers and use case innovators in both ways. The community-contributed use cases and feedback are valuable references for process updates of the platform in the short run and the network in the long run. For example, network service providers can fix errors or reorganize the network specification documents and use case ontology based on the retrieval statistics and user comments on the extracted knowledge; LLMs can be trained or fine-tuned through reinforcement learning with human feedback. The network service provider may also develop on-demand northbound APIs (as specified in 3GPP CAPIF Framework, TMF IF 1167, and other publications of 5G-PPP Software Network WG and The Linux Foundation Telco Global API Appliance Project) for sharing the network’s resource availability or allocation data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib12" title="">12</a>]</cite> for better generation of use case specifications. In the long run, the collected use cases and specifications offer first-hand insights into network infrastructure provisioning and network resource allocation plans.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Community Engagement &amp; Future</span>
</h2>
<figure class="ltx_figure" id="S5.F6">
<p class="ltx_p ltx_align_center" id="S5.F6.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S5.F6.1.1" style="border-color: #000000;padding:2.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1064" id="S5.F6.1.1.g1" src="extracted/5928054/materials/website_screenshot.png" width="580"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Screenshot of our website (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ntutangyun.github.io/llm_6g_frontend" title="">https://ntutangyun.github.io/llm_6g_frontend</a>) allowing the website user to perform RAG-informed automatic network specification generation and visualization for the described use case and contribute the use case to the public knowledge database.</figcaption>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Different from existing tools such as Nvidia O-RAN ChatBot <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib13" title="">13</a>]</cite> or Telco-RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib14" title="">14</a>]</cite> which focus on answering factual questions of the telecom documents, our goal is to showcase RAG-based automation for future O-RAN 6G service innovation. Currently, website users can perform automatic specification retrieval-augmented generation of their described use cases utilizing the knowledge database. We expect the full-stack website, along with the knowledge database, to be rolled out in the following four stages of functionality:</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Stage I - User Trials (public): Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S5.F6" title="Figure 6 ‣ V Community Engagement &amp; Future ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">6</span></a> shows the screenshots of our tool for community trial. One may check out the existing RAG knowledge database, including all the current use cases, their associated telecommunication processes and specifications. One may also contribute their own use cases, which will undergo an automatic RAG-based evaluation and manual confirmation before merging into the knowledge database. Currently, it requires an OpenAI API account, and in the future, we may develop and publish our own locally trained or fine-tuned LLM as we gather a sufficient amount of knowledge in the database to reduce the cost barrier for non-commercial users.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Stage II - Crowd-sourcing Knowledge Contributions (available but not published yet): Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#S4.F3" title="Figure 3 ‣ IV Prototype Operation ‣ Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases"><span class="ltx_text ltx_ref_tag">3</span></a> shows the crowd-sourcing element, whereby expert users can upload technical papers, specifications, and evidence of how different use cases map to 6G functionalities and specifications. This would enrich the RAG and provide more fine-scale tuning of the LLM performance. Currently, this functionality is available but not visible on the website because we need to develop appropriate mechanisms to moderate and ensure high-quality content.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Stage III - Tertiary Requirements: we will add tertiary requirements to the system related to cyber security and AI. Some of these have formal specifications and requirements, and some do not, and the challenge is to design appropriate RAG databases to reflect this.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1">Stage IV - Comprehensive Evaluation: current quantitative metrics such as hallucination or BLEU scores only evaluate the RAG performance of (different) LLMs in terms of retrieval-wise accuracy according to the indexed documents in the knowledge database. However, the retrieval-wise accuracy of RAG on the generated specifications (e.g., latency, reliability or security) does not necessarily mean optimal performance after deployment as the indexed knowledge can be obsolete or sub-optimal. We will extend the feedback loop to use case deployment and explore evaluation methodologies for operation-wise accuracy. In addition, we also plan to conduct extensive studies to evaluate the time-saving and cost-saving benefits compared to specification documents reading and telecom expert consulting.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">We call for community feedback with votes and comments, as well as the contribution of novel use case specifications and documentation to enrich the shared knowledge database in subsequent phases.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Looking into the future, we hope the research can inform real-time network control capabilities where dynamic service specifications can be generated faster and drive semantic-based network optimisation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2405.03122v2#bib.bib15" title="">15</a>]</cite>. For example, the LLM outputs may inform/contextualise the attention space of reinforcement-based RAN Intelligent Controller (RIC).</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">6G future networks are envisioned to surpass previous generations in many networking capabilities and provide ubiquitous computation resources for the network and the networked use cases. However, there is a knowledge gap between the network service providers and the use case innovators regarding the detailed network service specifications for the ever-changing use cases. To bridge the gap, we propose a public future use case knowledge database initiative and implement a RAG-empowered automatic network specification generation prototype for the telecommunication community. We have shown not only the relevant literature around the technologies in this area (ORAN Apps, 6G, RAG-based LLMs) but also designed and publicly released a prototype.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">We hope the framework will prove beneficial to network service providers in infrastructure planning and resource allocation, use case innovators in the development of future use cases, and the entire telecommunication community towards knowledge-empowered autonomous future networks.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
ITU, “M.2160: Framework and overall objectives of the future development of IMT for 2030 and beyond,” 2023, accessed on 14.08.2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.itu.int/rec/R-REC-M.2160-0-202311-I/en" title="">https://www.itu.int/rec/R-REC-M.2160-0-202311-I/en</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
NGMN, “6G use cases and analysis,” 2023, accessed on 14.08.2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.ngmn.org/publications/6g-use-cases-and-analysis.html" title="">https://www.ngmn.org/publications/6g-use-cases-and-analysis.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Polese, M. Dohler, F. Dressler, M. Erol-Kantarci, R. Jana, R. Knopp, and T. Melodia, “Empowering the 6g cellular architecture with open ran,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IEEE Journal on Selected Areas in Communications</em>, vol. 42, no. 2, pp. 245–262, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
F. A. Bimo, R.-G. Cheng, C.-C. Tseng, C.-R. Chiang, C.-H. Huang, and X.-W. Lin, “Design and implementation of next-generation research platforms,” in <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">IEEE Globecom</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
O. Orhan, V. N. Swamy, T. Tetzlaff, M. Nassar, H. Nikopour, and S. Talwar, “Connection management xAPP for O-RAN RIC: A graph neural network and reinforcement learning approach,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE International Conference on Machine Learning and Applications</em>, 2021, pp. 936–941.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. M. Qazzaz, Ł. Kułacz, A. Kliks, S. A. Zaidi, M. Dryjanski, and D. McLernon, “Machine learning-based xapp for dynamic resource allocation in o-ran networks,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2401.07643</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Cosler, C. Hahn, D. Mendoza, F. Schmitt, and C. Trippel, “nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">International Conference on Computer Aided Verification</em>, 2023, p. 383–396.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">et al.</em>, “Retrieval-augmented generation for knowledge-intensive nlp tasks,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.2.2">Advances in Neural Information Processing Systems</em>, vol. 33, pp. 9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Z. Lin, G. Qu, Q. Chen, X. Chen, Z. Chen, and K. Huang, “Pushing large language models to the 6g edge: Vision, challenges, and opportunities,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2309.16739</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
M. Xu, D. Niyato, J. Kang, Z. Xiong, S. Mao, Z. Han, D. Kim, and K. Lataief, “When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv: 2401.07764</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y. Tang, A. A. B. Da Costa, X. Zhang, I. Patrick, S. Khastgir, and P. Jennings, “Domain knowledge distillation from large language model: An empirical study in the autonomous driving domain,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">IEEE International Conference on Intelligent Transportation Systems (ITSC)</em>, 2023, pp. 3893–3900.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A.-S. Charismiadis, J. M. Salcines, D. Tsolkas, D. A. Guillen, and J. G. Rodrigo, “The 3gpp common api framework: Open-source release and application use cases,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">2023 Joint European Conference on Networks and Communications &amp; 6G Summit (EuCNC/6G Summit)</em>.   IEEE, 2023, pp. 472–477.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Nvidia, “Multimodal O-RAN RAG Chatbot with NVIDIA AI Foundation Endpoints or NVIDIA NIM for LLMs,” 2024, accessed on 14.08.2024. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/NVIDIA/GenerativeAIExamples/tree/main/experimental/oran-chatbot-multimodal" title="">https://github.com/NVIDIA/GenerativeAIExamples/tree/main/experimental/oran-chatbot-multimodal</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A.-L. Bornea, F. Ayed, A. De Domenico, N. Piovesan, and A. Maatouk, “Telco-rag: Navigating the challenges of retrieval-augmented language models for telecommunications,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2404.15939</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
B. Rong and H. Rutagemwa, “Leveraging Large Language Models for Intelligent Control of 6G Integrated TN-NTN with IoT Service,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">IEEE Network</em>, pp. 1–1, 2024.

</span>
</li>
</ul>
</section>
<figure class="ltx_float biography" id="tab1">
<table class="ltx_tabular" id="tab1.1">
<tr class="ltx_tr" id="tab1.1.1">
<td class="ltx_td" id="tab1.1.1.1">
<span class="ltx_inline-block" id="tab1.1.1.1.1">
<span class="ltx_p" id="tab1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="tab1.1.1.1.1.1.1">YUN TANG (Member, IEEE)</span> 
is a post-doctoral research fellow with Cranfield University from March 2024. He obtained PhD in Jan 2023 at Nanyang Technological University, Singapore and joined the University of Warwick as a research fellow from Feb 2023 to Mar 2024. His works have been published at several top-tier international conferences, such as IEEE ITSC, IEEE ICRA, and ASE, and in journals such as IEEE TSE and IEEE TIV. Currently, his research focuses on distributed intelligence in future networks.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_float biography" id="tab2">
<table class="ltx_tabular" id="tab2.1">
<tr class="ltx_tr" id="tab2.1.1">
<td class="ltx_td" id="tab2.1.1.1">
<span class="ltx_inline-block" id="tab2.1.1.1.1">
<span class="ltx_p" id="tab2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="tab2.1.1.1.1.1.1">WEISI GUO (Senior Member, IEEE)</span> 
is a Professor of Human Machine Interface at Cranfield University and also with the Alan Turing Institute. Previously, he was with the University of Cambridge, the University of Sheffield, and the University of Warwick. He is the winner of several IEEE Best Paper and IET Innovation awards in communications and currently co-leads the EPSRC 6G Future Communications Hubs in Distributed Computing and EPSRC Trustworthy Autonomous Systems Node in Security. He has published over 150 journal papers, mostly on networking and autonomy, with papers in Nature, Nature Comm., and Nature Machine Intelligence. He serves as editor of 3 IEEE and 1 Royal Society journals and contributes to emerging standards in wireless and AI.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct 15 09:12:44 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
