<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales</title>
<!--Generated on Tue Aug 20 15:40:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.13629v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S1" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Our Method: <span class="ltx_text ltx_font_smallcaps">InstructRAG</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS1" title="In 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Problem Setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS2" title="In 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Rationale Generation via Instruction-Following</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS3" title="In 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Learning Denoising Rationales in RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS1" title="In 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS2" title="In 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Main Result</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS3" title="In 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS4" title="In 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S4" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S4.SS1" title="In 4 Related Work ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Retrieval-augmented Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S4.SS2" title="In 4 Related Work ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Eliciting Reasoning in Large Language Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S5" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S5.SS0.SSS0.Px1" title="In 5 Conclusion ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title">Limitations.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S5.SS0.SSS0.Px2" title="In 5 Conclusion ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title">Future Work.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A1" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A2" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Case Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3" title="In InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Prompt Templates</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_smallcaps" id="id1.id1">InstructRAG</span>: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhepei Wei Wei-Lin Chen Yu Meng
<br class="ltx_break"/>Department of Computer Science
<br class="ltx_break"/>University of Virginia 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">{zhepei.wei,tuy8sy,yumeng5}@virginia.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Retrieval-augmented generation (RAG) has shown promising potential to enhance the accuracy and factuality of language models (LMs).
However, imperfect retrievers or noisy corpora can introduce misleading or even erroneous information to the retrieved contents, posing a significant challenge to the generation quality.
Existing RAG methods typically address this challenge by directly predicting final answers despite potentially noisy inputs, resulting in an <em class="ltx_emph ltx_font_italic" id="id3.id1.1">implicit</em> denoising process that is difficult to interpret and verify.
On the other hand, the acquisition of explicit denoising supervision is often costly, involving significant human efforts.
In this work, we propose <span class="ltx_text ltx_font_smallcaps" id="id3.id1.2">InstructRAG</span>, where LMs <em class="ltx_emph ltx_font_italic" id="id3.id1.3">explicitly</em> learn the denoising process through self-synthesized rationales — First, we instruct the LM to explain how the ground-truth answer is derived from retrieved documents.
Then, these rationales can be used either as demonstrations for in-context learning of explicit denoising or as supervised fine-tuning data to train the model.
Compared to standard RAG approaches, <span class="ltx_text ltx_font_smallcaps" id="id3.id1.4">InstructRAG</span> requires no additional supervision, allows for easier verification of the predicted answers, and effectively improves generation accuracy.
Experiments show <span class="ltx_text ltx_font_smallcaps" id="id3.id1.5">InstructRAG</span> consistently outperforms existing RAG methods in both training-free and trainable scenarios, achieving a relative improvement of 8.3% over the best baseline method on average across five knowledge-intensive benchmarks.
Extensive analysis indicates that <span class="ltx_text ltx_font_smallcaps" id="id3.id1.6">InstructRAG</span> scales well with increased numbers of retrieved documents and consistently exhibits robust denoising ability even in out-of-domain datasets, demonstrating strong generalizability.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our code is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/weizhepei/InstructRAG" title="">https://github.com/weizhepei/InstructRAG</a>.</span></span></span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">While large language models (LMs) have demonstrated remarkable text generation abilities <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib81" title="">81</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib82" title="">82</a>]</cite>, they may occasionally produce factually incorrect contents <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib79" title="">79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib110" title="">110</a>]</cite>, particularly when the task at hand requires the most current information or out-of-domain knowledge not adequately represented in the pre-training corpus <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib106" title="">106</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib113" title="">113</a>]</cite>.
This limitation significantly hinders the reliable deployment of LMs in high-stakes domains where factuality is crucial <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib93" title="">93</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib94" title="">94</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In light of this, retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib52" title="">52</a>]</cite> has been introduced to enhance the generation accuracy of LMs in knowledge-intensive tasks by leveraging the most up-to-date information and specialized knowledge from external sources <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib83" title="">83</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib102" title="">102</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib117" title="">117</a>]</cite>.
However, the retrieved contents are typically mixed with irrelevant or even erroneous information due to the absence of perfect retrieval solutions <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib74" title="">74</a>]</cite> and the presence of noisy data in the retrieval corpus <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib105" title="">105</a>]</cite>, posing a long-standing challenge to almost all RAG systems.
Typically, vanilla RAG approaches address this issue <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">implicitly</em> by training LMs to directly predict correct answers despite potentially noisy inputs.
Such latent processes are not only difficult to interpret and verify but also vulnerable to higher noise ratios, especially when the number of retrieved documents is large <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib91" title="">91</a>]</cite>.
On the other hand, obtaining high-quality explicit denoising supervision often requires substantial human efforts, which is time-consuming and costly.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we introduce a new RAG framework, <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.1">InstructRAG</span>, which enables the LM to <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">explicitly</span> denoise retrieved information and justify its predicted final answers by generating denoising responses (<span class="ltx_text ltx_font_slanted" id="S1.p3.1.3">i.e.</span>, <em class="ltx_emph ltx_font_italic" id="S1.p3.1.4">rationales</em>), as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">1</span></a>.
Compared to vanilla RAG approaches, <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.5">InstructRAG</span> does not require any additional supervision, while enjoying improved generation accuracy and trustworthiness.
Specifically, our method consists of two steps.
First, given a set of question-answer pairs and potentially noisy retrieved documents, we prompt an instruction-tuned LM to synthesize denoising rationales that analyze the documents and articulate how they lead to the ground-truth answers (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS2" title="2.2 Rationale Generation via Instruction-Following ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.2</span></a>).
Then, these synthetic rationales can be utilized as in-context learning examples or as supervised fine-tuning data, allowing the LM to explicitly learn to denoise retrieved contents (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS3" title="2.3 Learning Denoising Rationales in RAG ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.3</span></a>).
The effectiveness of <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.6">InstructRAG</span> can be attributed to the strong instruction-following ability of LMs <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib88" title="">88</a>]</cite>, a significant feature that still remains underexplored in the context of RAG.
We show that such self-synthesized rationales not only provide high-quality explicit denoising supervision for in-domain RAG tasks, but also facilitate superior out-of-domain generalization.
This finding underscores how instruction-tuned LMs can synthesize generalizable
supervision to effectively overcome the inevitable noise in RAG.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The main contributions of this work are as follows:
(1) We propose <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">InstructRAG</span>, a simple yet effective RAG framework that allows LMs to explicitly denoise retrieved contents by generating rationales for better verifiability and trustworthiness.
(2) <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">InstructRAG</span> is a self-synthesis method that does not require additional supervision compared to standard RAG methods, and can be seamlessly applied to both in-context learning and supervised fine-tuning settings.
(3) <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.3">InstructRAG</span> consistently outperforms state-of-the-art RAG approaches, yielding a relative improvement of 8.3% on average compared to the best baseline method across five knowledge-intensive benchmarks.
Extensive analysis and ablation studies further confirm the superiority of self-synthesized denoising rationales, and demonstrate <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.4">InstructRAG</span>’s robust denoising ability against increased noise ratios and strong task transferability in various training-free and trainable scenarios.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="197" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.4.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.5.2" style="font-size:90%;">Comparison between vanilla RAG and our <span class="ltx_text ltx_font_smallcaps" id="S1.F1.5.2.1">InstructRAG</span>.
In vanilla RAG, the model is tasked to directly predict answers given user queries and potentially noisy retrieved documents, without explicit denoising processes or explanations for how the answer is derived.
In contrast, our proposed <span class="ltx_text ltx_font_smallcaps" id="S1.F1.5.2.2">InstructRAG</span> generates rationales that explicitly denoise the retrieved documents and justify the predicted answers, enhancing both the generation accuracy and trustworthiness.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Our Method: <span class="ltx_text ltx_font_smallcaps" id="S2.1.1">InstructRAG</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.2">In this section, we first introduce our problem setting (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS1" title="2.1 Problem Setting ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.1</span></a>) and then present the proposed framework <span class="ltx_text ltx_font_smallcaps" id="S2.p1.2.1">InstructRAG</span> that enables LMs to explicitly denoise retrieved contents.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.F2" title="Figure 2 ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2</span></a>, our method consists of two steps.
First, we prompt an
instruction-tuned LM (<span class="ltx_text ltx_font_slanted" id="S2.p1.2.2">i.e.</span>, rationale generator <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><msub id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">ℳ</mi><mi id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">ℳ</ci><ci id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math>) to synthesize rationales that provide denoising supervisions (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS2" title="2.2 Rationale Generation via Instruction-Following ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.2</span></a>).
These rationales aim to explain how to derive the correct answer from potentially noisy retrieved documents for each training sample.
Then, we guide the LM (<span class="ltx_text ltx_font_slanted" id="S2.p1.2.3">i.e.</span>, rationale learner <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">ℳ</mi><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">ℳ</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>) to learn explicit denoising by leveraging these rationales as either in-context learning demonstrations or as supervised fine-tuning data (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS3" title="2.3 Learning Denoising Rationales in RAG ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.3</span></a>).</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.4">As detailed in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#alg1" title="Algorithm 1 ‣ 2.3 Learning Denoising Rationales in RAG ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">1</span></a>, during the entire process, <span class="ltx_text ltx_font_smallcaps" id="S2.p2.4.1">InstructRAG</span> does not require any additional supervisions beyond standard RAG methods.
By default, we instantiate both <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><msub id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">ℳ</mi><mi id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2">ℳ</ci><ci id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><msub id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p2.2.m2.1.1.2" xref="S2.p2.2.m2.1.1.2.cmml">ℳ</mi><mi id="S2.p2.2.m2.1.1.3" xref="S2.p2.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><apply id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p2.2.m2.1.1.1.cmml" xref="S2.p2.2.m2.1.1">subscript</csymbol><ci id="S2.p2.2.m2.1.1.2.cmml" xref="S2.p2.2.m2.1.1.2">ℳ</ci><ci id="S2.p2.2.m2.1.1.3.cmml" xref="S2.p2.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> with the same off-the-shelf instruction-tuned model (<span class="ltx_text ltx_font_slanted" id="S2.p2.4.2">i.e.</span>, <a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" title="">meta-llama/Meta-Llama-3-8B-Instruct</a>), making <span class="ltx_text ltx_font_smallcaps" id="S2.p2.4.3">InstructRAG</span> a fully <em class="ltx_emph ltx_font_italic" id="S2.p2.4.4">self-synthesis</em> method.
We also experiment with different instantiations of <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.p2.3.m3.1"><semantics id="S2.p2.3.m3.1a"><msub id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">ℳ</mi><mi id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1">subscript</csymbol><ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">ℳ</ci><ci id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.3.m3.1d">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.p2.4.m4.1"><semantics id="S2.p2.4.m4.1a"><msub id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p2.4.m4.1.1.2" xref="S2.p2.4.m4.1.1.2.cmml">ℳ</mi><mi id="S2.p2.4.m4.1.1.3" xref="S2.p2.4.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><apply id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p2.4.m4.1.1.1.cmml" xref="S2.p2.4.m4.1.1">subscript</csymbol><ci id="S2.p2.4.m4.1.1.2.cmml" xref="S2.p2.4.m4.1.1.2">ℳ</ci><ci id="S2.p2.4.m4.1.1.3.cmml" xref="S2.p2.4.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.p2.4.m4.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> and conduct ablation study in both training-free and trainable settings (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS3" title="3.3 Ablation Study ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3.3</span></a>).
For simplicity, we use placeholders to represent omitted instructions in the prompts presented in this section, while the full list of complete prompt templates is provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3" title="Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="225" id="S2.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.21.9.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.16.8" style="font-size:90%;">An overview of <span class="ltx_text ltx_font_smallcaps" id="S2.F2.16.8.1">InstructRAG</span>.
In step one, given the question <math alttext="q" class="ltx_Math" display="inline" id="S2.F2.9.1.m1.1"><semantics id="S2.F2.9.1.m1.1b"><mi id="S2.F2.9.1.m1.1.1" xref="S2.F2.9.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.F2.9.1.m1.1c"><ci id="S2.F2.9.1.m1.1.1.cmml" xref="S2.F2.9.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.1.m1.1d">q</annotation><annotation encoding="application/x-llamapun" id="S2.F2.9.1.m1.1e">italic_q</annotation></semantics></math>, retrieved documents <math alttext="\{d_{1},\cdots,d_{K}\}" class="ltx_Math" display="inline" id="S2.F2.10.2.m2.3"><semantics id="S2.F2.10.2.m2.3b"><mrow id="S2.F2.10.2.m2.3.3.2" xref="S2.F2.10.2.m2.3.3.3.cmml"><mo id="S2.F2.10.2.m2.3.3.2.3" stretchy="false" xref="S2.F2.10.2.m2.3.3.3.cmml">{</mo><msub id="S2.F2.10.2.m2.2.2.1.1" xref="S2.F2.10.2.m2.2.2.1.1.cmml"><mi id="S2.F2.10.2.m2.2.2.1.1.2" xref="S2.F2.10.2.m2.2.2.1.1.2.cmml">d</mi><mn id="S2.F2.10.2.m2.2.2.1.1.3" xref="S2.F2.10.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.F2.10.2.m2.3.3.2.4" xref="S2.F2.10.2.m2.3.3.3.cmml">,</mo><mi id="S2.F2.10.2.m2.1.1" mathvariant="normal" xref="S2.F2.10.2.m2.1.1.cmml">⋯</mi><mo id="S2.F2.10.2.m2.3.3.2.5" xref="S2.F2.10.2.m2.3.3.3.cmml">,</mo><msub id="S2.F2.10.2.m2.3.3.2.2" xref="S2.F2.10.2.m2.3.3.2.2.cmml"><mi id="S2.F2.10.2.m2.3.3.2.2.2" xref="S2.F2.10.2.m2.3.3.2.2.2.cmml">d</mi><mi id="S2.F2.10.2.m2.3.3.2.2.3" xref="S2.F2.10.2.m2.3.3.2.2.3.cmml">K</mi></msub><mo id="S2.F2.10.2.m2.3.3.2.6" stretchy="false" xref="S2.F2.10.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.10.2.m2.3c"><set id="S2.F2.10.2.m2.3.3.3.cmml" xref="S2.F2.10.2.m2.3.3.2"><apply id="S2.F2.10.2.m2.2.2.1.1.cmml" xref="S2.F2.10.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.F2.10.2.m2.2.2.1.1.1.cmml" xref="S2.F2.10.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.F2.10.2.m2.2.2.1.1.2.cmml" xref="S2.F2.10.2.m2.2.2.1.1.2">𝑑</ci><cn id="S2.F2.10.2.m2.2.2.1.1.3.cmml" type="integer" xref="S2.F2.10.2.m2.2.2.1.1.3">1</cn></apply><ci id="S2.F2.10.2.m2.1.1.cmml" xref="S2.F2.10.2.m2.1.1">⋯</ci><apply id="S2.F2.10.2.m2.3.3.2.2.cmml" xref="S2.F2.10.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.F2.10.2.m2.3.3.2.2.1.cmml" xref="S2.F2.10.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.F2.10.2.m2.3.3.2.2.2.cmml" xref="S2.F2.10.2.m2.3.3.2.2.2">𝑑</ci><ci id="S2.F2.10.2.m2.3.3.2.2.3.cmml" xref="S2.F2.10.2.m2.3.3.2.2.3">𝐾</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.2.m2.3d">\{d_{1},\cdots,d_{K}\}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.10.2.m2.3e">{ italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_d start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math> and ground-truth answer <math alttext="a" class="ltx_Math" display="inline" id="S2.F2.11.3.m3.1"><semantics id="S2.F2.11.3.m3.1b"><mi id="S2.F2.11.3.m3.1.1" xref="S2.F2.11.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S2.F2.11.3.m3.1c"><ci id="S2.F2.11.3.m3.1.1.cmml" xref="S2.F2.11.3.m3.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.11.3.m3.1d">a</annotation><annotation encoding="application/x-llamapun" id="S2.F2.11.3.m3.1e">italic_a</annotation></semantics></math> from the training set, we prompt an instruction-tuned LM (<span class="ltx_text ltx_font_slanted" id="S2.F2.16.8.2">i.e.</span>, rationale generator <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.F2.12.4.m4.1"><semantics id="S2.F2.12.4.m4.1b"><msub id="S2.F2.12.4.m4.1.1" xref="S2.F2.12.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.F2.12.4.m4.1.1.2" xref="S2.F2.12.4.m4.1.1.2.cmml">ℳ</mi><mi id="S2.F2.12.4.m4.1.1.3" xref="S2.F2.12.4.m4.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.12.4.m4.1c"><apply id="S2.F2.12.4.m4.1.1.cmml" xref="S2.F2.12.4.m4.1.1"><csymbol cd="ambiguous" id="S2.F2.12.4.m4.1.1.1.cmml" xref="S2.F2.12.4.m4.1.1">subscript</csymbol><ci id="S2.F2.12.4.m4.1.1.2.cmml" xref="S2.F2.12.4.m4.1.1.2">ℳ</ci><ci id="S2.F2.12.4.m4.1.1.3.cmml" xref="S2.F2.12.4.m4.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.12.4.m4.1d">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.12.4.m4.1e">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math>) to generate rationale <math alttext="r" class="ltx_Math" display="inline" id="S2.F2.13.5.m5.1"><semantics id="S2.F2.13.5.m5.1b"><mi id="S2.F2.13.5.m5.1.1" xref="S2.F2.13.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.F2.13.5.m5.1c"><ci id="S2.F2.13.5.m5.1.1.cmml" xref="S2.F2.13.5.m5.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.13.5.m5.1d">r</annotation><annotation encoding="application/x-llamapun" id="S2.F2.13.5.m5.1e">italic_r</annotation></semantics></math> that explains how the answer can be derived from the potentially noisy input.
In step two, we utilize the synthesized rationales from the first step to guide the LM (<span class="ltx_text ltx_font_slanted" id="S2.F2.16.8.3">i.e.</span>, rationale learner <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.F2.14.6.m6.1"><semantics id="S2.F2.14.6.m6.1b"><msub id="S2.F2.14.6.m6.1.1" xref="S2.F2.14.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.F2.14.6.m6.1.1.2" xref="S2.F2.14.6.m6.1.1.2.cmml">ℳ</mi><mi id="S2.F2.14.6.m6.1.1.3" xref="S2.F2.14.6.m6.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.14.6.m6.1c"><apply id="S2.F2.14.6.m6.1.1.cmml" xref="S2.F2.14.6.m6.1.1"><csymbol cd="ambiguous" id="S2.F2.14.6.m6.1.1.1.cmml" xref="S2.F2.14.6.m6.1.1">subscript</csymbol><ci id="S2.F2.14.6.m6.1.1.2.cmml" xref="S2.F2.14.6.m6.1.1.2">ℳ</ci><ci id="S2.F2.14.6.m6.1.1.3.cmml" xref="S2.F2.14.6.m6.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.14.6.m6.1d">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.14.6.m6.1e">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>) to explicitly learn denoising of the retrieved documents, either through in-context learning or supervised learning. By default, we use the same model for both <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.F2.15.7.m7.1"><semantics id="S2.F2.15.7.m7.1b"><msub id="S2.F2.15.7.m7.1.1" xref="S2.F2.15.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.F2.15.7.m7.1.1.2" xref="S2.F2.15.7.m7.1.1.2.cmml">ℳ</mi><mi id="S2.F2.15.7.m7.1.1.3" xref="S2.F2.15.7.m7.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.15.7.m7.1c"><apply id="S2.F2.15.7.m7.1.1.cmml" xref="S2.F2.15.7.m7.1.1"><csymbol cd="ambiguous" id="S2.F2.15.7.m7.1.1.1.cmml" xref="S2.F2.15.7.m7.1.1">subscript</csymbol><ci id="S2.F2.15.7.m7.1.1.2.cmml" xref="S2.F2.15.7.m7.1.1.2">ℳ</ci><ci id="S2.F2.15.7.m7.1.1.3.cmml" xref="S2.F2.15.7.m7.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.15.7.m7.1d">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.15.7.m7.1e">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.F2.16.8.m8.1"><semantics id="S2.F2.16.8.m8.1b"><msub id="S2.F2.16.8.m8.1.1" xref="S2.F2.16.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.F2.16.8.m8.1.1.2" xref="S2.F2.16.8.m8.1.1.2.cmml">ℳ</mi><mi id="S2.F2.16.8.m8.1.1.3" xref="S2.F2.16.8.m8.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.16.8.m8.1c"><apply id="S2.F2.16.8.m8.1.1.cmml" xref="S2.F2.16.8.m8.1.1"><csymbol cd="ambiguous" id="S2.F2.16.8.m8.1.1.1.cmml" xref="S2.F2.16.8.m8.1.1">subscript</csymbol><ci id="S2.F2.16.8.m8.1.1.2.cmml" xref="S2.F2.16.8.m8.1.1.2">ℳ</ci><ci id="S2.F2.16.8.m8.1.1.3.cmml" xref="S2.F2.16.8.m8.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.16.8.m8.1d">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.F2.16.8.m8.1e">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, but they can be instantiated with different models as well (see ablation study § <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS3" title="3.3 Ablation Study ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</span></figcaption>
</figure>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.4.2.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S2.T1.2.1" style="font-size:90%;">Rationale generation prompt for the <math alttext="i" class="ltx_Math" display="inline" id="S2.T1.2.1.m1.1"><semantics id="S2.T1.2.1.m1.1b"><mi id="S2.T1.2.1.m1.1.1" xref="S2.T1.2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.T1.2.1.m1.1c"><ci id="S2.T1.2.1.m1.1.1.cmml" xref="S2.T1.2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.1.m1.1d">i</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.1.m1.1e">italic_i</annotation></semantics></math>-th training sample.</span></figcaption><svg class="ltx_picture" height="201.94" id="S2.T1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,201.94) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 196.62 C 0 199.56 2.38 201.94 5.32 201.94 L 594.68 201.94 C 597.62 201.94 600 199.56 600 196.62 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 175.73 L 598.62 175.73 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 177.11 L 1.38 196.62 C 1.38 198.8 3.15 200.56 5.32 200.56 L 594.68 200.56 C 596.85 200.56 598.62 198.8 598.62 196.62 L 598.62 177.11 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 184.03)"><foreignobject color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S2.T1.pic1.8.8.8.1.1" style="width:421.6pt;">
<span class="ltx_p" id="S2.T1.pic1.8.8.8.1.1.1">Rationale Generation</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="160.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" style="width:421.6pt;">
<span class="ltx_p" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7"><span class="ltx_text ltx_font_bold" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" style="font-size:80%;">Input:<span class="ltx_text ltx_font_medium" id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6">
Read the following documents relevant to the given question: {<math alttext="q_{i}" class="ltx_Math" display="inline" id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">q</mi><mi id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">𝑞</ci><ci id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>} 
<br class="ltx_break"/>
<br class="ltx_break"/>Document [1] (Title: <math alttext="\dotsm" class="ltx_Math" display="inline" id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1"><semantics id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">\dotsm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">⋯</annotation></semantics></math>): {contents of <math alttext="d^{1}_{i}" class="ltx_Math" display="inline" id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1"><semantics id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a"><msubsup id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.2" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.2.cmml">d</mi><mi id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml">i</mi><mn id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.3" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.3.cmml">1</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><apply id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.1.cmml" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">subscript</csymbol><apply id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.1.cmml" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">superscript</csymbol><ci id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.2.cmml" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.2">𝑑</ci><cn id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.3.cmml" type="integer" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.3">1</cn></apply><ci id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml" xref="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">d^{1}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1d">italic_d start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>}
<br class="ltx_break"/><math alttext="~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm" class="ltx_Math" display="inline" id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1"><semantics id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1a"><mi id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1" mathvariant="normal" xref="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1b"><ci id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml" xref="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1c">~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1d">⋯</annotation></semantics></math>
<br class="ltx_break"/>Please identify documents that are useful to answer the given question: {<math alttext="q_{i}" class="ltx_Math" display="inline" id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1"><semantics id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1a"><msub id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.cmml"><mi id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.2" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.2.cmml">q</mi><mi id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.3" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1b"><apply id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.cmml" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1"><csymbol cd="ambiguous" id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.1.cmml" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1">subscript</csymbol><ci id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.2.cmml" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.2">𝑞</ci><ci id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.3.cmml" xref="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>}, and explain how the contents lead to the answer: {<math alttext="a_{i}" class="ltx_Math" display="inline" id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1"><semantics id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1a"><msub id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.cmml"><mi id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2.cmml">a</mi><mi id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1b"><apply id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.cmml" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1"><csymbol cd="ambiguous" id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.1.cmml" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1">subscript</csymbol><ci id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2.cmml" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.2">𝑎</ci><ci id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3.cmml" xref="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>}
<br class="ltx_break"/>
<br class="ltx_break"/>{task-specific instruction} 
<br class="ltx_break"/>
<br class="ltx_break"/></span>Output:<span class="ltx_text ltx_font_medium" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7"> {rationale <math alttext="r_{i}" class="ltx_Math" display="inline" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1"><semantics id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1a"><msub id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.cmml"><mi id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.2" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.2.cmml">r</mi><mi id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.3" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1b"><apply id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.1.cmml" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1">subscript</csymbol><ci id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.2.cmml" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.2">𝑟</ci><ci id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.3.cmml" xref="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1c">r_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>}</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Problem Setting</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.10">We adopt the standard RAG setting where the LM <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><msub id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">ℳ</mi><mi id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">ℳ</ci><ci id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> has access to annotated datasets of downstream tasks (<span class="ltx_text ltx_font_slanted" id="S2.SS1.p1.10.1">e.g.</span>, question-answering task <math alttext="\mathcal{T}=\{\mbox{$\langle$}q,a\mbox{$\rangle$}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.5"><semantics id="S2.SS1.p1.2.m2.5a"><mrow id="S2.SS1.p1.2.m2.5.5" xref="S2.SS1.p1.2.m2.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.2.m2.5.5.3" xref="S2.SS1.p1.2.m2.5.5.3.cmml">𝒯</mi><mo id="S2.SS1.p1.2.m2.5.5.2" xref="S2.SS1.p1.2.m2.5.5.2.cmml">=</mo><mrow id="S2.SS1.p1.2.m2.5.5.1.1" xref="S2.SS1.p1.2.m2.5.5.1.2.cmml"><mo id="S2.SS1.p1.2.m2.5.5.1.1.2" stretchy="false" xref="S2.SS1.p1.2.m2.5.5.1.2.cmml">{</mo><mrow id="S2.SS1.p1.2.m2.5.5.1.1.1.2" xref="S2.SS1.p1.2.m2.5.5.1.1.1.1.cmml"><mo id="S2.SS1.p1.2.m2.5.5.1.1.1.2.1" stretchy="false" xref="S2.SS1.p1.2.m2.5.5.1.1.1.1.cmml">⟨</mo><mi id="S2.SS1.p1.2.m2.3.3" xref="S2.SS1.p1.2.m2.3.3.cmml">q</mi><mo id="S2.SS1.p1.2.m2.5.5.1.1.1.2.2" xref="S2.SS1.p1.2.m2.5.5.1.1.1.1.cmml">,</mo><mi id="S2.SS1.p1.2.m2.4.4" xref="S2.SS1.p1.2.m2.4.4.cmml">a</mi><mo id="S2.SS1.p1.2.m2.5.5.1.1.1.2.3" stretchy="false" xref="S2.SS1.p1.2.m2.5.5.1.1.1.1.cmml">⟩</mo></mrow><mo id="S2.SS1.p1.2.m2.5.5.1.1.3" stretchy="false" xref="S2.SS1.p1.2.m2.5.5.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.5b"><apply id="S2.SS1.p1.2.m2.5.5.cmml" xref="S2.SS1.p1.2.m2.5.5"><eq id="S2.SS1.p1.2.m2.5.5.2.cmml" xref="S2.SS1.p1.2.m2.5.5.2"></eq><ci id="S2.SS1.p1.2.m2.5.5.3.cmml" xref="S2.SS1.p1.2.m2.5.5.3">𝒯</ci><set id="S2.SS1.p1.2.m2.5.5.1.2.cmml" xref="S2.SS1.p1.2.m2.5.5.1.1"><list id="S2.SS1.p1.2.m2.5.5.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.5.5.1.1.1.2"><ci id="S2.SS1.p1.2.m2.3.3.cmml" xref="S2.SS1.p1.2.m2.3.3">𝑞</ci><ci id="S2.SS1.p1.2.m2.4.4.cmml" xref="S2.SS1.p1.2.m2.4.4">𝑎</ci></list></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.5c">\mathcal{T}=\{\mbox{$\langle$}q,a\mbox{$\rangle$}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.5d">caligraphic_T = { ⟨ italic_q , italic_a ⟩ }</annotation></semantics></math>), and an external knowledge base with the off-the-shelf retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">caligraphic_R</annotation></semantics></math> for retrieval.
Different from previous works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib105" title="">105</a>]</cite>
which leverage additional supervisions from GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib6" title="">6</a>]</cite> or GPT-4 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib1" title="">1</a>]</cite>, we assume the model has strictly limited access to the above two information sources.
Given a question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_q</annotation></semantics></math>, the retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">caligraphic_R</annotation></semantics></math> returns a set of potentially noisy documents <math alttext="D=\{d_{1},\cdots,d_{K}\}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.3"><semantics id="S2.SS1.p1.6.m6.3a"><mrow id="S2.SS1.p1.6.m6.3.3" xref="S2.SS1.p1.6.m6.3.3.cmml"><mi id="S2.SS1.p1.6.m6.3.3.4" xref="S2.SS1.p1.6.m6.3.3.4.cmml">D</mi><mo id="S2.SS1.p1.6.m6.3.3.3" xref="S2.SS1.p1.6.m6.3.3.3.cmml">=</mo><mrow id="S2.SS1.p1.6.m6.3.3.2.2" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml"><mo id="S2.SS1.p1.6.m6.3.3.2.2.3" stretchy="false" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">{</mo><msub id="S2.SS1.p1.6.m6.2.2.1.1.1" xref="S2.SS1.p1.6.m6.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.6.m6.2.2.1.1.1.2" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2.cmml">d</mi><mn id="S2.SS1.p1.6.m6.2.2.1.1.1.3" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.6.m6.3.3.2.2.4" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">,</mo><mi id="S2.SS1.p1.6.m6.1.1" mathvariant="normal" xref="S2.SS1.p1.6.m6.1.1.cmml">⋯</mi><mo id="S2.SS1.p1.6.m6.3.3.2.2.5" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">,</mo><msub id="S2.SS1.p1.6.m6.3.3.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.2" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2.cmml">d</mi><mi id="S2.SS1.p1.6.m6.3.3.2.2.2.3" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml">K</mi></msub><mo id="S2.SS1.p1.6.m6.3.3.2.2.6" stretchy="false" xref="S2.SS1.p1.6.m6.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.3b"><apply id="S2.SS1.p1.6.m6.3.3.cmml" xref="S2.SS1.p1.6.m6.3.3"><eq id="S2.SS1.p1.6.m6.3.3.3.cmml" xref="S2.SS1.p1.6.m6.3.3.3"></eq><ci id="S2.SS1.p1.6.m6.3.3.4.cmml" xref="S2.SS1.p1.6.m6.3.3.4">𝐷</ci><set id="S2.SS1.p1.6.m6.3.3.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2"><apply id="S2.SS1.p1.6.m6.2.2.1.1.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m6.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.6.m6.2.2.1.1.1.2">𝑑</ci><cn id="S2.SS1.p1.6.m6.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.6.m6.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">⋯</ci><apply id="S2.SS1.p1.6.m6.3.3.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.2">𝑑</ci><ci id="S2.SS1.p1.6.m6.3.3.2.2.2.3.cmml" xref="S2.SS1.p1.6.m6.3.3.2.2.2.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.3c">D=\{d_{1},\cdots,d_{K}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.3d">italic_D = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_d start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math> from the external knowledge base.
The model is then tasked to predict the correct answer <math alttext="a" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m7.1"><semantics id="S2.SS1.p1.7.m7.1a"><mi id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><ci id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">a</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m7.1d">italic_a</annotation></semantics></math> to the given question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m8.1"><semantics id="S2.SS1.p1.8.m8.1a"><mi id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.1b"><ci id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m8.1d">italic_q</annotation></semantics></math> based on <math alttext="D" class="ltx_Math" display="inline" id="S2.SS1.p1.9.m9.1"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.9.m9.1d">italic_D</annotation></semantics></math> and its own parametric knowledge, denoted as <math alttext="p_{\theta}(a|q,D)" class="ltx_Math" display="inline" id="S2.SS1.p1.10.m10.3"><semantics id="S2.SS1.p1.10.m10.3a"><mrow id="S2.SS1.p1.10.m10.3.3" xref="S2.SS1.p1.10.m10.3.3.cmml"><msub id="S2.SS1.p1.10.m10.3.3.3" xref="S2.SS1.p1.10.m10.3.3.3.cmml"><mi id="S2.SS1.p1.10.m10.3.3.3.2" xref="S2.SS1.p1.10.m10.3.3.3.2.cmml">p</mi><mi id="S2.SS1.p1.10.m10.3.3.3.3" xref="S2.SS1.p1.10.m10.3.3.3.3.cmml">θ</mi></msub><mo id="S2.SS1.p1.10.m10.3.3.2" xref="S2.SS1.p1.10.m10.3.3.2.cmml">⁢</mo><mrow id="S2.SS1.p1.10.m10.3.3.1.1" xref="S2.SS1.p1.10.m10.3.3.1.1.1.cmml"><mo id="S2.SS1.p1.10.m10.3.3.1.1.2" stretchy="false" xref="S2.SS1.p1.10.m10.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS1.p1.10.m10.3.3.1.1.1" xref="S2.SS1.p1.10.m10.3.3.1.1.1.cmml"><mi id="S2.SS1.p1.10.m10.3.3.1.1.1.2" xref="S2.SS1.p1.10.m10.3.3.1.1.1.2.cmml">a</mi><mo fence="false" id="S2.SS1.p1.10.m10.3.3.1.1.1.1" xref="S2.SS1.p1.10.m10.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS1.p1.10.m10.3.3.1.1.1.3.2" xref="S2.SS1.p1.10.m10.3.3.1.1.1.3.1.cmml"><mi id="S2.SS1.p1.10.m10.1.1" xref="S2.SS1.p1.10.m10.1.1.cmml">q</mi><mo id="S2.SS1.p1.10.m10.3.3.1.1.1.3.2.1" xref="S2.SS1.p1.10.m10.3.3.1.1.1.3.1.cmml">,</mo><mi id="S2.SS1.p1.10.m10.2.2" xref="S2.SS1.p1.10.m10.2.2.cmml">D</mi></mrow></mrow><mo id="S2.SS1.p1.10.m10.3.3.1.1.3" stretchy="false" xref="S2.SS1.p1.10.m10.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m10.3b"><apply id="S2.SS1.p1.10.m10.3.3.cmml" xref="S2.SS1.p1.10.m10.3.3"><times id="S2.SS1.p1.10.m10.3.3.2.cmml" xref="S2.SS1.p1.10.m10.3.3.2"></times><apply id="S2.SS1.p1.10.m10.3.3.3.cmml" xref="S2.SS1.p1.10.m10.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.10.m10.3.3.3.1.cmml" xref="S2.SS1.p1.10.m10.3.3.3">subscript</csymbol><ci id="S2.SS1.p1.10.m10.3.3.3.2.cmml" xref="S2.SS1.p1.10.m10.3.3.3.2">𝑝</ci><ci id="S2.SS1.p1.10.m10.3.3.3.3.cmml" xref="S2.SS1.p1.10.m10.3.3.3.3">𝜃</ci></apply><apply id="S2.SS1.p1.10.m10.3.3.1.1.1.cmml" xref="S2.SS1.p1.10.m10.3.3.1.1"><csymbol cd="latexml" id="S2.SS1.p1.10.m10.3.3.1.1.1.1.cmml" xref="S2.SS1.p1.10.m10.3.3.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p1.10.m10.3.3.1.1.1.2.cmml" xref="S2.SS1.p1.10.m10.3.3.1.1.1.2">𝑎</ci><list id="S2.SS1.p1.10.m10.3.3.1.1.1.3.1.cmml" xref="S2.SS1.p1.10.m10.3.3.1.1.1.3.2"><ci id="S2.SS1.p1.10.m10.1.1.cmml" xref="S2.SS1.p1.10.m10.1.1">𝑞</ci><ci id="S2.SS1.p1.10.m10.2.2.cmml" xref="S2.SS1.p1.10.m10.2.2">𝐷</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m10.3c">p_{\theta}(a|q,D)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.10.m10.3d">italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_a | italic_q , italic_D )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Our work focuses on investigating the noise robustness of LMs and developing efficient denoising techniques for RAG.
Hence, we directly employ off-the-shelf retrievers instead of training our own, and prepend all retrieved documents to the question as input to the model, without any filtering or re-ranking.
This setting is orthogonal to existing research efforts centered on optimizing the retriever or performing adaptive retrieval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib102" title="">102</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Rationale Generation via Instruction-Following</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.6">Recent studies <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib51" title="">51</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib67" title="">67</a>]</cite> have made encouraging progress in aligning LMs with human preferences and intentions, enabling the synthesis of high-quality data that closely follows user instructions <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib98" title="">98</a>]</cite>.
Inspired by these advances, we propose to leverage the LM’s strong instruction-following ability to generate explicit denoising responses (<span class="ltx_text ltx_font_slanted" id="S2.SS2.p1.6.1">i.e.</span>, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.6.2">rationales</em>) for RAG.
As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.T1" title="Table 1 ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">1</span></a>, given a QA pair <math alttext="\mbox{$\langle$}q_{i},a_{i}\mbox{$\rangle$}\in\mathcal{T}" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.4"><semantics id="S2.SS2.p1.1.m1.4a"><mrow id="S2.SS2.p1.1.m1.4.4" xref="S2.SS2.p1.1.m1.4.4.cmml"><mrow id="S2.SS2.p1.1.m1.4.4.2.2" xref="S2.SS2.p1.1.m1.4.4.2.3.cmml"><mo id="S2.SS2.p1.1.m1.4.4.2.2.3" stretchy="false" xref="S2.SS2.p1.1.m1.4.4.2.3.cmml">⟨</mo><msub id="S2.SS2.p1.1.m1.3.3.1.1.1" xref="S2.SS2.p1.1.m1.3.3.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.3.3.1.1.1.2" xref="S2.SS2.p1.1.m1.3.3.1.1.1.2.cmml">q</mi><mi id="S2.SS2.p1.1.m1.3.3.1.1.1.3" xref="S2.SS2.p1.1.m1.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS2.p1.1.m1.4.4.2.2.4" xref="S2.SS2.p1.1.m1.4.4.2.3.cmml">,</mo><msub id="S2.SS2.p1.1.m1.4.4.2.2.2" xref="S2.SS2.p1.1.m1.4.4.2.2.2.cmml"><mi id="S2.SS2.p1.1.m1.4.4.2.2.2.2" xref="S2.SS2.p1.1.m1.4.4.2.2.2.2.cmml">a</mi><mi id="S2.SS2.p1.1.m1.4.4.2.2.2.3" xref="S2.SS2.p1.1.m1.4.4.2.2.2.3.cmml">i</mi></msub><mo id="S2.SS2.p1.1.m1.4.4.2.2.5" stretchy="false" xref="S2.SS2.p1.1.m1.4.4.2.3.cmml">⟩</mo></mrow><mo id="S2.SS2.p1.1.m1.4.4.3" xref="S2.SS2.p1.1.m1.4.4.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.1.m1.4.4.4" xref="S2.SS2.p1.1.m1.4.4.4.cmml">𝒯</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.4b"><apply id="S2.SS2.p1.1.m1.4.4.cmml" xref="S2.SS2.p1.1.m1.4.4"><in id="S2.SS2.p1.1.m1.4.4.3.cmml" xref="S2.SS2.p1.1.m1.4.4.3"></in><list id="S2.SS2.p1.1.m1.4.4.2.3.cmml" xref="S2.SS2.p1.1.m1.4.4.2.2"><apply id="S2.SS2.p1.1.m1.3.3.1.1.1.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.3.3.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1.2">𝑞</ci><ci id="S2.SS2.p1.1.m1.3.3.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.3.3.1.1.1.3">𝑖</ci></apply><apply id="S2.SS2.p1.1.m1.4.4.2.2.2.cmml" xref="S2.SS2.p1.1.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.4.4.2.2.2.1.cmml" xref="S2.SS2.p1.1.m1.4.4.2.2.2">subscript</csymbol><ci id="S2.SS2.p1.1.m1.4.4.2.2.2.2.cmml" xref="S2.SS2.p1.1.m1.4.4.2.2.2.2">𝑎</ci><ci id="S2.SS2.p1.1.m1.4.4.2.2.2.3.cmml" xref="S2.SS2.p1.1.m1.4.4.2.2.2.3">𝑖</ci></apply></list><ci id="S2.SS2.p1.1.m1.4.4.4.cmml" xref="S2.SS2.p1.1.m1.4.4.4">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.4c">\mbox{$\langle$}q_{i},a_{i}\mbox{$\rangle$}\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.4d">⟨ italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⟩ ∈ caligraphic_T</annotation></semantics></math> and a set of retrieved documents <math alttext="\{d^{1}_{i},\cdots,d^{K}_{i}\}" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.3"><semantics id="S2.SS2.p1.2.m2.3a"><mrow id="S2.SS2.p1.2.m2.3.3.2" xref="S2.SS2.p1.2.m2.3.3.3.cmml"><mo id="S2.SS2.p1.2.m2.3.3.2.3" stretchy="false" xref="S2.SS2.p1.2.m2.3.3.3.cmml">{</mo><msubsup id="S2.SS2.p1.2.m2.2.2.1.1" xref="S2.SS2.p1.2.m2.2.2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.2.2.1.1.2.2" xref="S2.SS2.p1.2.m2.2.2.1.1.2.2.cmml">d</mi><mi id="S2.SS2.p1.2.m2.2.2.1.1.3" xref="S2.SS2.p1.2.m2.2.2.1.1.3.cmml">i</mi><mn id="S2.SS2.p1.2.m2.2.2.1.1.2.3" xref="S2.SS2.p1.2.m2.2.2.1.1.2.3.cmml">1</mn></msubsup><mo id="S2.SS2.p1.2.m2.3.3.2.4" xref="S2.SS2.p1.2.m2.3.3.3.cmml">,</mo><mi id="S2.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S2.SS2.p1.2.m2.1.1.cmml">⋯</mi><mo id="S2.SS2.p1.2.m2.3.3.2.5" xref="S2.SS2.p1.2.m2.3.3.3.cmml">,</mo><msubsup id="S2.SS2.p1.2.m2.3.3.2.2" xref="S2.SS2.p1.2.m2.3.3.2.2.cmml"><mi id="S2.SS2.p1.2.m2.3.3.2.2.2.2" xref="S2.SS2.p1.2.m2.3.3.2.2.2.2.cmml">d</mi><mi id="S2.SS2.p1.2.m2.3.3.2.2.3" xref="S2.SS2.p1.2.m2.3.3.2.2.3.cmml">i</mi><mi id="S2.SS2.p1.2.m2.3.3.2.2.2.3" xref="S2.SS2.p1.2.m2.3.3.2.2.2.3.cmml">K</mi></msubsup><mo id="S2.SS2.p1.2.m2.3.3.2.6" stretchy="false" xref="S2.SS2.p1.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.3b"><set id="S2.SS2.p1.2.m2.3.3.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2"><apply id="S2.SS2.p1.2.m2.2.2.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1">subscript</csymbol><apply id="S2.SS2.p1.2.m2.2.2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.2.2.1.1.2.1.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1">superscript</csymbol><ci id="S2.SS2.p1.2.m2.2.2.1.1.2.2.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.2.2">𝑑</ci><cn id="S2.SS2.p1.2.m2.2.2.1.1.2.3.cmml" type="integer" xref="S2.SS2.p1.2.m2.2.2.1.1.2.3">1</cn></apply><ci id="S2.SS2.p1.2.m2.2.2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.2.2.1.1.3">𝑖</ci></apply><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">⋯</ci><apply id="S2.SS2.p1.2.m2.3.3.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.3.3.2.2.1.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2">subscript</csymbol><apply id="S2.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2">superscript</csymbol><ci id="S2.SS2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.2.2">𝑑</ci><ci id="S2.SS2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.2.3">𝐾</ci></apply><ci id="S2.SS2.p1.2.m2.3.3.2.2.3.cmml" xref="S2.SS2.p1.2.m2.3.3.2.2.3">𝑖</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.3c">\{d^{1}_{i},\cdots,d^{K}_{i}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.3d">{ italic_d start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , ⋯ , italic_d start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }</annotation></semantics></math>, we prompt an off-the-shelf LM <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.1"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">ℳ</mi><mi id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">ℳ</ci><ci id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.1d">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math> (as the rationale generator) with denoising instructions to produce the corresponding rationale <math alttext="r_{i}" class="ltx_Math" display="inline" id="S2.SS2.p1.4.m4.1"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">r</mi><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">𝑟</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">r_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.4.m4.1d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> that distinguishes useful documents from noisy ones and explains how the contexts lead to the ground-truth answer <math alttext="a_{i}" class="ltx_Math" display="inline" id="S2.SS2.p1.5.m5.1"><semantics id="S2.SS2.p1.5.m5.1a"><msub id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2.cmml">a</mi><mi id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">𝑎</ci><ci id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">a_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.5.m5.1d">italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
To ensure the synthetic rationales are aligned with the ground-truth answers, we use a simple substring match to assess their consistency.
The consistency ratio on training samples with at least one relevant document containing the ground-truth answer is 98% on average across five benchmarks, supporting the reliability of synthetic rationales as a sanity check.
This allows us to effectively augment the standard dataset <math alttext="\mathcal{T}=\{\mbox{$\langle$}q,a\mbox{$\rangle$}\}\rightarrow\mathcal{T}^{+}=%
\{\mbox{$\langle$}q,r\mbox{$\rangle$}\}" class="ltx_Math" display="inline" id="S2.SS2.p1.6.m6.10"><semantics id="S2.SS2.p1.6.m6.10a"><mrow id="S2.SS2.p1.6.m6.10.10" xref="S2.SS2.p1.6.m6.10.10.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.6.m6.10.10.4" xref="S2.SS2.p1.6.m6.10.10.4.cmml">𝒯</mi><mo id="S2.SS2.p1.6.m6.10.10.5" xref="S2.SS2.p1.6.m6.10.10.5.cmml">=</mo><mrow id="S2.SS2.p1.6.m6.9.9.1.1" xref="S2.SS2.p1.6.m6.9.9.1.2.cmml"><mo id="S2.SS2.p1.6.m6.9.9.1.1.2" stretchy="false" xref="S2.SS2.p1.6.m6.9.9.1.2.cmml">{</mo><mrow id="S2.SS2.p1.6.m6.9.9.1.1.1.2" xref="S2.SS2.p1.6.m6.9.9.1.1.1.1.cmml"><mo id="S2.SS2.p1.6.m6.9.9.1.1.1.2.1" stretchy="false" xref="S2.SS2.p1.6.m6.9.9.1.1.1.1.cmml">⟨</mo><mi id="S2.SS2.p1.6.m6.5.5" xref="S2.SS2.p1.6.m6.5.5.cmml">q</mi><mo id="S2.SS2.p1.6.m6.9.9.1.1.1.2.2" xref="S2.SS2.p1.6.m6.9.9.1.1.1.1.cmml">,</mo><mi id="S2.SS2.p1.6.m6.6.6" xref="S2.SS2.p1.6.m6.6.6.cmml">a</mi><mo id="S2.SS2.p1.6.m6.9.9.1.1.1.2.3" stretchy="false" xref="S2.SS2.p1.6.m6.9.9.1.1.1.1.cmml">⟩</mo></mrow><mo id="S2.SS2.p1.6.m6.9.9.1.1.3" stretchy="false" xref="S2.SS2.p1.6.m6.9.9.1.2.cmml">}</mo></mrow><mo id="S2.SS2.p1.6.m6.10.10.6" stretchy="false" xref="S2.SS2.p1.6.m6.10.10.6.cmml">→</mo><msup id="S2.SS2.p1.6.m6.10.10.7" xref="S2.SS2.p1.6.m6.10.10.7.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.6.m6.10.10.7.2" xref="S2.SS2.p1.6.m6.10.10.7.2.cmml">𝒯</mi><mo id="S2.SS2.p1.6.m6.10.10.7.3" xref="S2.SS2.p1.6.m6.10.10.7.3.cmml">+</mo></msup><mo id="S2.SS2.p1.6.m6.10.10.8" xref="S2.SS2.p1.6.m6.10.10.8.cmml">=</mo><mrow id="S2.SS2.p1.6.m6.10.10.2.1" xref="S2.SS2.p1.6.m6.10.10.2.2.cmml"><mo id="S2.SS2.p1.6.m6.10.10.2.1.2" stretchy="false" xref="S2.SS2.p1.6.m6.10.10.2.2.cmml">{</mo><mrow id="S2.SS2.p1.6.m6.10.10.2.1.1.2" xref="S2.SS2.p1.6.m6.10.10.2.1.1.1.cmml"><mo id="S2.SS2.p1.6.m6.10.10.2.1.1.2.1" stretchy="false" xref="S2.SS2.p1.6.m6.10.10.2.1.1.1.cmml">⟨</mo><mi id="S2.SS2.p1.6.m6.7.7" xref="S2.SS2.p1.6.m6.7.7.cmml">q</mi><mo id="S2.SS2.p1.6.m6.10.10.2.1.1.2.2" xref="S2.SS2.p1.6.m6.10.10.2.1.1.1.cmml">,</mo><mi id="S2.SS2.p1.6.m6.8.8" xref="S2.SS2.p1.6.m6.8.8.cmml">r</mi><mo id="S2.SS2.p1.6.m6.10.10.2.1.1.2.3" stretchy="false" xref="S2.SS2.p1.6.m6.10.10.2.1.1.1.cmml">⟩</mo></mrow><mo id="S2.SS2.p1.6.m6.10.10.2.1.3" stretchy="false" xref="S2.SS2.p1.6.m6.10.10.2.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.10b"><apply id="S2.SS2.p1.6.m6.10.10.cmml" xref="S2.SS2.p1.6.m6.10.10"><and id="S2.SS2.p1.6.m6.10.10a.cmml" xref="S2.SS2.p1.6.m6.10.10"></and><apply id="S2.SS2.p1.6.m6.10.10b.cmml" xref="S2.SS2.p1.6.m6.10.10"><eq id="S2.SS2.p1.6.m6.10.10.5.cmml" xref="S2.SS2.p1.6.m6.10.10.5"></eq><ci id="S2.SS2.p1.6.m6.10.10.4.cmml" xref="S2.SS2.p1.6.m6.10.10.4">𝒯</ci><set id="S2.SS2.p1.6.m6.9.9.1.2.cmml" xref="S2.SS2.p1.6.m6.9.9.1.1"><list id="S2.SS2.p1.6.m6.9.9.1.1.1.1.cmml" xref="S2.SS2.p1.6.m6.9.9.1.1.1.2"><ci id="S2.SS2.p1.6.m6.5.5.cmml" xref="S2.SS2.p1.6.m6.5.5">𝑞</ci><ci id="S2.SS2.p1.6.m6.6.6.cmml" xref="S2.SS2.p1.6.m6.6.6">𝑎</ci></list></set></apply><apply id="S2.SS2.p1.6.m6.10.10c.cmml" xref="S2.SS2.p1.6.m6.10.10"><ci id="S2.SS2.p1.6.m6.10.10.6.cmml" xref="S2.SS2.p1.6.m6.10.10.6">→</ci><share href="https://arxiv.org/html/2406.13629v2#S2.SS2.p1.6.m6.9.9.1.cmml" id="S2.SS2.p1.6.m6.10.10d.cmml" xref="S2.SS2.p1.6.m6.10.10"></share><apply id="S2.SS2.p1.6.m6.10.10.7.cmml" xref="S2.SS2.p1.6.m6.10.10.7"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.10.10.7.1.cmml" xref="S2.SS2.p1.6.m6.10.10.7">superscript</csymbol><ci id="S2.SS2.p1.6.m6.10.10.7.2.cmml" xref="S2.SS2.p1.6.m6.10.10.7.2">𝒯</ci><plus id="S2.SS2.p1.6.m6.10.10.7.3.cmml" xref="S2.SS2.p1.6.m6.10.10.7.3"></plus></apply></apply><apply id="S2.SS2.p1.6.m6.10.10e.cmml" xref="S2.SS2.p1.6.m6.10.10"><eq id="S2.SS2.p1.6.m6.10.10.8.cmml" xref="S2.SS2.p1.6.m6.10.10.8"></eq><share href="https://arxiv.org/html/2406.13629v2#S2.SS2.p1.6.m6.10.10.7.cmml" id="S2.SS2.p1.6.m6.10.10f.cmml" xref="S2.SS2.p1.6.m6.10.10"></share><set id="S2.SS2.p1.6.m6.10.10.2.2.cmml" xref="S2.SS2.p1.6.m6.10.10.2.1"><list id="S2.SS2.p1.6.m6.10.10.2.1.1.1.cmml" xref="S2.SS2.p1.6.m6.10.10.2.1.1.2"><ci id="S2.SS2.p1.6.m6.7.7.cmml" xref="S2.SS2.p1.6.m6.7.7">𝑞</ci><ci id="S2.SS2.p1.6.m6.8.8.cmml" xref="S2.SS2.p1.6.m6.8.8">𝑟</ci></list></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.10c">\mathcal{T}=\{\mbox{$\langle$}q,a\mbox{$\rangle$}\}\rightarrow\mathcal{T}^{+}=%
\{\mbox{$\langle$}q,r\mbox{$\rangle$}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.6.m6.10d">caligraphic_T = { ⟨ italic_q , italic_a ⟩ } → caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT = { ⟨ italic_q , italic_r ⟩ }</annotation></semantics></math> with self-synthesized denoising rationales solely by instructing the LM, without any additional supervision.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">We also validate the necessity of using an LM-based generator (<span class="ltx_text ltx_font_slanted" id="S2.SS2.p2.1.1">i.e.</span>, <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><msub id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">ℳ</mi><mi id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">ℳ</ci><ci id="S2.SS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math>) to create the rationales instead of employing simple heuristics — without the generator, rationales can be created in a template-based manner (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T6" title="Table 6 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">6</span></a>), by roughly identifying relevant retrieved documents through simple substring-matching with the ground-truth answer.
However, as demonstrated in our ablation study, this approach suffers from semantically inaccurate matching of relevant documents, leading to significant performance degradation.
Another advantage of the LM-based generator is that it can produce high-quality rationales even <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.1.2">without referring to the ground-truth answer</em>, which only results in a minor performance drop.
More detailed analyses on rationale generation design can be found in our ablation study (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS3" title="3.3 Ablation Study ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Learning Denoising Rationales in RAG</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.2">With the rationale-augmented dataset <math alttext="\mathcal{T}^{+}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><msup id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">𝒯</mi><mo id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml">+</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">𝒯</ci><plus id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\mathcal{T}^{+}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math>, it becomes possible to develop a rationale learner <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><msub id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml">ℳ</mi><mi id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2">ℳ</ci><ci id="S2.SS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> that directly learns explicit denoising for RAG tasks with efficient learning strategies.
Next, we introduce two simple yet effective learning methods in the <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.2.1">training-free</em> and <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.2.2">trainable</em> RAG settings, namely, <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.2.3">InstructRAG</span>-ICL and <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.2.4">InstructRAG</span>-FT.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.5"><span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p2.5.1">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.5.2">-ICL</span> is a training-free instantiation of <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p2.5.3">InstructRAG</span> where the model learns denoising rationales via in-context learning (ICL).
As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T10" title="Table 10 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">10</span></a>, given a test question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">italic_q</annotation></semantics></math> and a set of retrieved documents <math alttext="D=\{d_{1},\cdots,d_{K}\}" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.3"><semantics id="S2.SS3.p2.2.m2.3a"><mrow id="S2.SS3.p2.2.m2.3.3" xref="S2.SS3.p2.2.m2.3.3.cmml"><mi id="S2.SS3.p2.2.m2.3.3.4" xref="S2.SS3.p2.2.m2.3.3.4.cmml">D</mi><mo id="S2.SS3.p2.2.m2.3.3.3" xref="S2.SS3.p2.2.m2.3.3.3.cmml">=</mo><mrow id="S2.SS3.p2.2.m2.3.3.2.2" xref="S2.SS3.p2.2.m2.3.3.2.3.cmml"><mo id="S2.SS3.p2.2.m2.3.3.2.2.3" stretchy="false" xref="S2.SS3.p2.2.m2.3.3.2.3.cmml">{</mo><msub id="S2.SS3.p2.2.m2.2.2.1.1.1" xref="S2.SS3.p2.2.m2.2.2.1.1.1.cmml"><mi id="S2.SS3.p2.2.m2.2.2.1.1.1.2" xref="S2.SS3.p2.2.m2.2.2.1.1.1.2.cmml">d</mi><mn id="S2.SS3.p2.2.m2.2.2.1.1.1.3" xref="S2.SS3.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.p2.2.m2.3.3.2.2.4" xref="S2.SS3.p2.2.m2.3.3.2.3.cmml">,</mo><mi id="S2.SS3.p2.2.m2.1.1" mathvariant="normal" xref="S2.SS3.p2.2.m2.1.1.cmml">⋯</mi><mo id="S2.SS3.p2.2.m2.3.3.2.2.5" xref="S2.SS3.p2.2.m2.3.3.2.3.cmml">,</mo><msub id="S2.SS3.p2.2.m2.3.3.2.2.2" xref="S2.SS3.p2.2.m2.3.3.2.2.2.cmml"><mi id="S2.SS3.p2.2.m2.3.3.2.2.2.2" xref="S2.SS3.p2.2.m2.3.3.2.2.2.2.cmml">d</mi><mi id="S2.SS3.p2.2.m2.3.3.2.2.2.3" xref="S2.SS3.p2.2.m2.3.3.2.2.2.3.cmml">K</mi></msub><mo id="S2.SS3.p2.2.m2.3.3.2.2.6" stretchy="false" xref="S2.SS3.p2.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.3b"><apply id="S2.SS3.p2.2.m2.3.3.cmml" xref="S2.SS3.p2.2.m2.3.3"><eq id="S2.SS3.p2.2.m2.3.3.3.cmml" xref="S2.SS3.p2.2.m2.3.3.3"></eq><ci id="S2.SS3.p2.2.m2.3.3.4.cmml" xref="S2.SS3.p2.2.m2.3.3.4">𝐷</ci><set id="S2.SS3.p2.2.m2.3.3.2.3.cmml" xref="S2.SS3.p2.2.m2.3.3.2.2"><apply id="S2.SS3.p2.2.m2.2.2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS3.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.SS3.p2.2.m2.2.2.1.1.1.2.cmml" xref="S2.SS3.p2.2.m2.2.2.1.1.1.2">𝑑</ci><cn id="S2.SS3.p2.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS3.p2.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">⋯</ci><apply id="S2.SS3.p2.2.m2.3.3.2.2.2.cmml" xref="S2.SS3.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS3.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S2.SS3.p2.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS3.p2.2.m2.3.3.2.2.2.2">𝑑</ci><ci id="S2.SS3.p2.2.m2.3.3.2.2.2.3.cmml" xref="S2.SS3.p2.2.m2.3.3.2.2.2.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.3c">D=\{d_{1},\cdots,d_{K}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.3d">italic_D = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_d start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math>, we first randomly sample <math alttext="N" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><mi id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><ci id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">italic_N</annotation></semantics></math> demonstrations <math alttext="\mbox{$\langle$}q_{i},r_{i}\mbox{$\rangle$}\in\mathcal{T}^{+}" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m4.4"><semantics id="S2.SS3.p2.4.m4.4a"><mrow id="S2.SS3.p2.4.m4.4.4" xref="S2.SS3.p2.4.m4.4.4.cmml"><mrow id="S2.SS3.p2.4.m4.4.4.2.2" xref="S2.SS3.p2.4.m4.4.4.2.3.cmml"><mo id="S2.SS3.p2.4.m4.4.4.2.2.3" stretchy="false" xref="S2.SS3.p2.4.m4.4.4.2.3.cmml">⟨</mo><msub id="S2.SS3.p2.4.m4.3.3.1.1.1" xref="S2.SS3.p2.4.m4.3.3.1.1.1.cmml"><mi id="S2.SS3.p2.4.m4.3.3.1.1.1.2" xref="S2.SS3.p2.4.m4.3.3.1.1.1.2.cmml">q</mi><mi id="S2.SS3.p2.4.m4.3.3.1.1.1.3" xref="S2.SS3.p2.4.m4.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS3.p2.4.m4.4.4.2.2.4" xref="S2.SS3.p2.4.m4.4.4.2.3.cmml">,</mo><msub id="S2.SS3.p2.4.m4.4.4.2.2.2" xref="S2.SS3.p2.4.m4.4.4.2.2.2.cmml"><mi id="S2.SS3.p2.4.m4.4.4.2.2.2.2" xref="S2.SS3.p2.4.m4.4.4.2.2.2.2.cmml">r</mi><mi id="S2.SS3.p2.4.m4.4.4.2.2.2.3" xref="S2.SS3.p2.4.m4.4.4.2.2.2.3.cmml">i</mi></msub><mo id="S2.SS3.p2.4.m4.4.4.2.2.5" stretchy="false" xref="S2.SS3.p2.4.m4.4.4.2.3.cmml">⟩</mo></mrow><mo id="S2.SS3.p2.4.m4.4.4.3" xref="S2.SS3.p2.4.m4.4.4.3.cmml">∈</mo><msup id="S2.SS3.p2.4.m4.4.4.4" xref="S2.SS3.p2.4.m4.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.4.m4.4.4.4.2" xref="S2.SS3.p2.4.m4.4.4.4.2.cmml">𝒯</mi><mo id="S2.SS3.p2.4.m4.4.4.4.3" xref="S2.SS3.p2.4.m4.4.4.4.3.cmml">+</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.4b"><apply id="S2.SS3.p2.4.m4.4.4.cmml" xref="S2.SS3.p2.4.m4.4.4"><in id="S2.SS3.p2.4.m4.4.4.3.cmml" xref="S2.SS3.p2.4.m4.4.4.3"></in><list id="S2.SS3.p2.4.m4.4.4.2.3.cmml" xref="S2.SS3.p2.4.m4.4.4.2.2"><apply id="S2.SS3.p2.4.m4.3.3.1.1.1.cmml" xref="S2.SS3.p2.4.m4.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.3.3.1.1.1.1.cmml" xref="S2.SS3.p2.4.m4.3.3.1.1.1">subscript</csymbol><ci id="S2.SS3.p2.4.m4.3.3.1.1.1.2.cmml" xref="S2.SS3.p2.4.m4.3.3.1.1.1.2">𝑞</ci><ci id="S2.SS3.p2.4.m4.3.3.1.1.1.3.cmml" xref="S2.SS3.p2.4.m4.3.3.1.1.1.3">𝑖</ci></apply><apply id="S2.SS3.p2.4.m4.4.4.2.2.2.cmml" xref="S2.SS3.p2.4.m4.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.4.4.2.2.2.1.cmml" xref="S2.SS3.p2.4.m4.4.4.2.2.2">subscript</csymbol><ci id="S2.SS3.p2.4.m4.4.4.2.2.2.2.cmml" xref="S2.SS3.p2.4.m4.4.4.2.2.2.2">𝑟</ci><ci id="S2.SS3.p2.4.m4.4.4.2.2.2.3.cmml" xref="S2.SS3.p2.4.m4.4.4.2.2.2.3">𝑖</ci></apply></list><apply id="S2.SS3.p2.4.m4.4.4.4.cmml" xref="S2.SS3.p2.4.m4.4.4.4"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.4.4.4.1.cmml" xref="S2.SS3.p2.4.m4.4.4.4">superscript</csymbol><ci id="S2.SS3.p2.4.m4.4.4.4.2.cmml" xref="S2.SS3.p2.4.m4.4.4.4.2">𝒯</ci><plus id="S2.SS3.p2.4.m4.4.4.4.3.cmml" xref="S2.SS3.p2.4.m4.4.4.4.3"></plus></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.4c">\mbox{$\langle$}q_{i},r_{i}\mbox{$\rangle$}\in\mathcal{T}^{+}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m4.4d">⟨ italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⟩ ∈ caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math> from the rationale-augmented training dataset, and then prompt the model to follow the exemplars and generate rationale <math alttext="r" class="ltx_Math" display="inline" id="S2.SS3.p2.5.m5.1"><semantics id="S2.SS3.p2.5.m5.1a"><mi id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><ci id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.5.m5.1d">italic_r</annotation></semantics></math>.
To save memory and enhance inference efficiency, we only show exemplary questions and their corresponding rationales in such ICL demonstrations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.3"><span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p3.3.1">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S2.SS3.p3.3.2">-FT</span> is a trainable instantiation of <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p3.3.3">InstructRAG</span> that learns denoising rationales via supervised fine-tuning (FT) with standard language modeling objective.
As defined in Eq. (<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.E1" title="In 2.3 Learning Denoising Rationales in RAG ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">1</span></a>), it maximizes the likelihood of rationale <math alttext="r" class="ltx_Math" display="inline" id="S2.SS3.p3.1.m1.1"><semantics id="S2.SS3.p3.1.m1.1a"><mi id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><ci id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.1.m1.1d">italic_r</annotation></semantics></math> conditioned on question <math alttext="q" class="ltx_Math" display="inline" id="S2.SS3.p3.2.m2.1"><semantics id="S2.SS3.p3.2.m2.1a"><mi id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.1b"><ci id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.2.m2.1d">italic_q</annotation></semantics></math> and retrieved documents <math alttext="D" class="ltx_Math" display="inline" id="S2.SS3.p3.3.m3.1"><semantics id="S2.SS3.p3.3.m3.1a"><mi id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.1b"><ci id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.3.m3.1d">italic_D</annotation></semantics></math>.</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\vspace{-.8em}\max_{\mathcal{\theta}}\mathbb{E}_{(q,r)\sim\mathcal{T}^{+}}\log
p%
_{\mathcal{\theta}}(r|q,D)." class="ltx_Math" display="block" id="S2.E1.m1.5"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1.3" xref="S2.E1.m1.5.5.1.1.3.cmml"><munder id="S2.E1.m1.5.5.1.1.3.1" xref="S2.E1.m1.5.5.1.1.3.1.cmml"><mi id="S2.E1.m1.5.5.1.1.3.1.2" xref="S2.E1.m1.5.5.1.1.3.1.2.cmml">max</mi><mi id="S2.E1.m1.5.5.1.1.3.1.3" xref="S2.E1.m1.5.5.1.1.3.1.3.cmml">θ</mi></munder><mo id="S2.E1.m1.5.5.1.1.3a" lspace="0.167em" xref="S2.E1.m1.5.5.1.1.3.cmml">⁡</mo><mrow id="S2.E1.m1.5.5.1.1.3.2" xref="S2.E1.m1.5.5.1.1.3.2.cmml"><msub id="S2.E1.m1.5.5.1.1.3.2.2" xref="S2.E1.m1.5.5.1.1.3.2.2.cmml"><mi id="S2.E1.m1.5.5.1.1.3.2.2.2" xref="S2.E1.m1.5.5.1.1.3.2.2.2.cmml">𝔼</mi><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><mrow id="S2.E1.m1.2.2.2.4.2" xref="S2.E1.m1.2.2.2.4.1.cmml"><mo id="S2.E1.m1.2.2.2.4.2.1" stretchy="false" xref="S2.E1.m1.2.2.2.4.1.cmml">(</mo><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">q</mi><mo id="S2.E1.m1.2.2.2.4.2.2" xref="S2.E1.m1.2.2.2.4.1.cmml">,</mo><mi id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">r</mi><mo id="S2.E1.m1.2.2.2.4.2.3" stretchy="false" xref="S2.E1.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml">∼</mo><msup id="S2.E1.m1.2.2.2.5" xref="S2.E1.m1.2.2.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.2.5.2" xref="S2.E1.m1.2.2.2.5.2.cmml">𝒯</mi><mo id="S2.E1.m1.2.2.2.5.3" xref="S2.E1.m1.2.2.2.5.3.cmml">+</mo></msup></mrow></msub><mo id="S2.E1.m1.5.5.1.1.3.2.1" lspace="0.167em" xref="S2.E1.m1.5.5.1.1.3.2.1.cmml">⁢</mo><mrow id="S2.E1.m1.5.5.1.1.3.2.3" xref="S2.E1.m1.5.5.1.1.3.2.3.cmml"><mi id="S2.E1.m1.5.5.1.1.3.2.3.1" xref="S2.E1.m1.5.5.1.1.3.2.3.1.cmml">log</mi><mo id="S2.E1.m1.5.5.1.1.3.2.3a" lspace="0.167em" xref="S2.E1.m1.5.5.1.1.3.2.3.cmml">⁡</mo><msub id="S2.E1.m1.5.5.1.1.3.2.3.2" xref="S2.E1.m1.5.5.1.1.3.2.3.2.cmml"><mi id="S2.E1.m1.5.5.1.1.3.2.3.2.2" xref="S2.E1.m1.5.5.1.1.3.2.3.2.2.cmml">p</mi><mi id="S2.E1.m1.5.5.1.1.3.2.3.2.3" xref="S2.E1.m1.5.5.1.1.3.2.3.2.3.cmml">θ</mi></msub></mrow></mrow></mrow><mo id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.5.5.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.cmml"><mo id="S2.E1.m1.5.5.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.5.5.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.cmml"><mi id="S2.E1.m1.5.5.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.2.cmml">r</mi><mo fence="false" id="S2.E1.m1.5.5.1.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.cmml">|</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1.3.2" xref="S2.E1.m1.5.5.1.1.1.1.1.3.1.cmml"><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">q</mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.3.2.1" xref="S2.E1.m1.5.5.1.1.1.1.1.3.1.cmml">,</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">D</mi></mrow></mrow><mo id="S2.E1.m1.5.5.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.5.5.1.2" lspace="0em" xref="S2.E1.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><times id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"></times><apply id="S2.E1.m1.5.5.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3"><apply id="S2.E1.m1.5.5.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.1.1.cmml" xref="S2.E1.m1.5.5.1.1.3.1">subscript</csymbol><max id="S2.E1.m1.5.5.1.1.3.1.2.cmml" xref="S2.E1.m1.5.5.1.1.3.1.2"></max><ci id="S2.E1.m1.5.5.1.1.3.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3.1.3">𝜃</ci></apply><apply id="S2.E1.m1.5.5.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2"><times id="S2.E1.m1.5.5.1.1.3.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.1"></times><apply id="S2.E1.m1.5.5.1.1.3.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.3.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2.2">𝔼</ci><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><csymbol cd="latexml" id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3">similar-to</csymbol><interval closure="open" id="S2.E1.m1.2.2.2.4.1.cmml" xref="S2.E1.m1.2.2.2.4.2"><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">𝑞</ci><ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">𝑟</ci></interval><apply id="S2.E1.m1.2.2.2.5.cmml" xref="S2.E1.m1.2.2.2.5"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.5.1.cmml" xref="S2.E1.m1.2.2.2.5">superscript</csymbol><ci id="S2.E1.m1.2.2.2.5.2.cmml" xref="S2.E1.m1.2.2.2.5.2">𝒯</ci><plus id="S2.E1.m1.2.2.2.5.3.cmml" xref="S2.E1.m1.2.2.2.5.3"></plus></apply></apply></apply><apply id="S2.E1.m1.5.5.1.1.3.2.3.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3"><log id="S2.E1.m1.5.5.1.1.3.2.3.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3.1"></log><apply id="S2.E1.m1.5.5.1.1.3.2.3.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.3.2.3.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.3.2.3.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3.2.2">𝑝</ci><ci id="S2.E1.m1.5.5.1.1.3.2.3.2.3.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3.2.3">𝜃</ci></apply></apply></apply></apply><apply id="S2.E1.m1.5.5.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E1.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2">𝑟</ci><list id="S2.E1.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.3.2"><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝑞</ci><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">𝐷</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\vspace{-.8em}\max_{\mathcal{\theta}}\mathbb{E}_{(q,r)\sim\mathcal{T}^{+}}\log
p%
_{\mathcal{\theta}}(r|q,D).</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.5d">roman_max start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT ( italic_q , italic_r ) ∼ caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT roman_log italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_r | italic_q , italic_D ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p3.5">where <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS3.p3.4.m1.1"><semantics id="S2.SS3.p3.4.m1.1a"><mi id="S2.SS3.p3.4.m1.1.1" xref="S2.SS3.p3.4.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.4.m1.1b"><ci id="S2.SS3.p3.4.m1.1.1.cmml" xref="S2.SS3.p3.4.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.4.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.4.m1.1d">italic_θ</annotation></semantics></math> represents the model parameters.
Both the training and inference of <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p3.5.1">InstructRAG</span>-FT share the same data format.
As depicted in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T11" title="Table 11 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">11</span></a>, it takes as input the retrieved documents followed by the question, and outputs the denoising rationale <math alttext="r" class="ltx_Math" display="inline" id="S2.SS3.p3.5.m2.1"><semantics id="S2.SS3.p3.5.m2.1a"><mi id="S2.SS3.p3.5.m2.1.1" xref="S2.SS3.p3.5.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.5.m2.1b"><ci id="S2.SS3.p3.5.m2.1.1.cmml" xref="S2.SS3.p3.5.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.5.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.5.m2.1d">italic_r</annotation></semantics></math>.</p>
</div>
<figure class="ltx_figure" id="S2.SS3.fig1">
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.3.1.1">Algorithm 1</span> </span> <span class="ltx_text ltx_font_smallcaps" id="alg1.4.2">InstructRAG</span> </figcaption>
<div class="ltx_listing ltx_listing" id="alg1.5">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span>Retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">caligraphic_R</annotation></semantics></math>, Rationale Generator <math alttext="\mathcal{M}_{\phi}" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><msub id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m2.1.1.2" xref="alg1.l1.m2.1.1.2.cmml">ℳ</mi><mi id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1">subscript</csymbol><ci id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">ℳ</ci><ci id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\mathcal{M}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math>, Rationale Learner <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="alg1.l1.m3.1"><semantics id="alg1.l1.m3.1a"><msub id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m3.1.1.2" xref="alg1.l1.m3.1.1.2.cmml">ℳ</mi><mi id="alg1.l1.m3.1.1.3" xref="alg1.l1.m3.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><apply id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1"><csymbol cd="ambiguous" id="alg1.l1.m3.1.1.1.cmml" xref="alg1.l1.m3.1.1">subscript</csymbol><ci id="alg1.l1.m3.1.1.2.cmml" xref="alg1.l1.m3.1.1.2">ℳ</ci><ci id="alg1.l1.m3.1.1.3.cmml" xref="alg1.l1.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, Training data
<math alttext="\mathcal{T}=\{\mbox{$\langle$}q,a\mbox{$\rangle$}\}" class="ltx_Math" display="inline" id="alg1.l1.m4.5"><semantics id="alg1.l1.m4.5a"><mrow id="alg1.l1.m4.5.5" xref="alg1.l1.m4.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m4.5.5.3" xref="alg1.l1.m4.5.5.3.cmml">𝒯</mi><mo id="alg1.l1.m4.5.5.2" xref="alg1.l1.m4.5.5.2.cmml">=</mo><mrow id="alg1.l1.m4.5.5.1.1" xref="alg1.l1.m4.5.5.1.2.cmml"><mo id="alg1.l1.m4.5.5.1.1.2" stretchy="false" xref="alg1.l1.m4.5.5.1.2.cmml">{</mo><mrow id="alg1.l1.m4.5.5.1.1.1.2" xref="alg1.l1.m4.5.5.1.1.1.1.cmml"><mo id="alg1.l1.m4.5.5.1.1.1.2.1" stretchy="false" xref="alg1.l1.m4.5.5.1.1.1.1.cmml">⟨</mo><mi id="alg1.l1.m4.3.3" xref="alg1.l1.m4.3.3.cmml">q</mi><mo id="alg1.l1.m4.5.5.1.1.1.2.2" xref="alg1.l1.m4.5.5.1.1.1.1.cmml">,</mo><mi id="alg1.l1.m4.4.4" xref="alg1.l1.m4.4.4.cmml">a</mi><mo id="alg1.l1.m4.5.5.1.1.1.2.3" stretchy="false" xref="alg1.l1.m4.5.5.1.1.1.1.cmml">⟩</mo></mrow><mo id="alg1.l1.m4.5.5.1.1.3" stretchy="false" xref="alg1.l1.m4.5.5.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.5b"><apply id="alg1.l1.m4.5.5.cmml" xref="alg1.l1.m4.5.5"><eq id="alg1.l1.m4.5.5.2.cmml" xref="alg1.l1.m4.5.5.2"></eq><ci id="alg1.l1.m4.5.5.3.cmml" xref="alg1.l1.m4.5.5.3">𝒯</ci><set id="alg1.l1.m4.5.5.1.2.cmml" xref="alg1.l1.m4.5.5.1.1"><list id="alg1.l1.m4.5.5.1.1.1.1.cmml" xref="alg1.l1.m4.5.5.1.1.1.2"><ci id="alg1.l1.m4.3.3.cmml" xref="alg1.l1.m4.3.3">𝑞</ci><ci id="alg1.l1.m4.4.4.cmml" xref="alg1.l1.m4.4.4">𝑎</ci></list></set></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.5c">\mathcal{T}=\{\mbox{$\langle$}q,a\mbox{$\rangle$}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m4.5d">caligraphic_T = { ⟨ italic_q , italic_a ⟩ }</annotation></semantics></math>
<span class="ltx_text ltx_font_typewriter" id="alg1.l1.2" style="color:#0000FF;">/* Training data generation */</span>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l2.2">for</span> each <math alttext="\mbox{$\langle$}q,a\mbox{$\rangle$}\in\mathcal{T}" class="ltx_Math" display="inline" id="alg1.l2.m1.4"><semantics id="alg1.l2.m1.4a"><mrow id="alg1.l2.m1.4.5" xref="alg1.l2.m1.4.5.cmml"><mrow id="alg1.l2.m1.4.5.2.2" xref="alg1.l2.m1.4.5.2.1.cmml"><mo id="alg1.l2.m1.4.5.2.2.1" stretchy="false" xref="alg1.l2.m1.4.5.2.1.cmml">⟨</mo><mi id="alg1.l2.m1.3.3" xref="alg1.l2.m1.3.3.cmml">q</mi><mo id="alg1.l2.m1.4.5.2.2.2" xref="alg1.l2.m1.4.5.2.1.cmml">,</mo><mi id="alg1.l2.m1.4.4" xref="alg1.l2.m1.4.4.cmml">a</mi><mo id="alg1.l2.m1.4.5.2.2.3" stretchy="false" xref="alg1.l2.m1.4.5.2.1.cmml">⟩</mo></mrow><mo id="alg1.l2.m1.4.5.1" xref="alg1.l2.m1.4.5.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l2.m1.4.5.3" xref="alg1.l2.m1.4.5.3.cmml">𝒯</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.4b"><apply id="alg1.l2.m1.4.5.cmml" xref="alg1.l2.m1.4.5"><in id="alg1.l2.m1.4.5.1.cmml" xref="alg1.l2.m1.4.5.1"></in><list id="alg1.l2.m1.4.5.2.1.cmml" xref="alg1.l2.m1.4.5.2.2"><ci id="alg1.l2.m1.3.3.cmml" xref="alg1.l2.m1.3.3">𝑞</ci><ci id="alg1.l2.m1.4.4.cmml" xref="alg1.l2.m1.4.4">𝑎</ci></list><ci id="alg1.l2.m1.4.5.3.cmml" xref="alg1.l2.m1.4.5.3">𝒯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.4c">\mbox{$\langle$}q,a\mbox{$\rangle$}\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.4d">⟨ italic_q , italic_a ⟩ ∈ caligraphic_T</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l2.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>     Retrieve <math alttext="D=\{d_{1},\cdots,d_{K}\}\leftarrow\mathcal{R}(q)" class="ltx_Math" display="inline" id="alg1.l3.m1.4"><semantics id="alg1.l3.m1.4a"><mrow id="alg1.l3.m1.4.4" xref="alg1.l3.m1.4.4.cmml"><mi id="alg1.l3.m1.4.4.4" xref="alg1.l3.m1.4.4.4.cmml">D</mi><mo id="alg1.l3.m1.4.4.5" xref="alg1.l3.m1.4.4.5.cmml">=</mo><mrow id="alg1.l3.m1.4.4.2.2" xref="alg1.l3.m1.4.4.2.3.cmml"><mo id="alg1.l3.m1.4.4.2.2.3" stretchy="false" xref="alg1.l3.m1.4.4.2.3.cmml">{</mo><msub id="alg1.l3.m1.3.3.1.1.1" xref="alg1.l3.m1.3.3.1.1.1.cmml"><mi id="alg1.l3.m1.3.3.1.1.1.2" xref="alg1.l3.m1.3.3.1.1.1.2.cmml">d</mi><mn id="alg1.l3.m1.3.3.1.1.1.3" xref="alg1.l3.m1.3.3.1.1.1.3.cmml">1</mn></msub><mo id="alg1.l3.m1.4.4.2.2.4" xref="alg1.l3.m1.4.4.2.3.cmml">,</mo><mi id="alg1.l3.m1.1.1" mathvariant="normal" xref="alg1.l3.m1.1.1.cmml">⋯</mi><mo id="alg1.l3.m1.4.4.2.2.5" xref="alg1.l3.m1.4.4.2.3.cmml">,</mo><msub id="alg1.l3.m1.4.4.2.2.2" xref="alg1.l3.m1.4.4.2.2.2.cmml"><mi id="alg1.l3.m1.4.4.2.2.2.2" xref="alg1.l3.m1.4.4.2.2.2.2.cmml">d</mi><mi id="alg1.l3.m1.4.4.2.2.2.3" xref="alg1.l3.m1.4.4.2.2.2.3.cmml">K</mi></msub><mo id="alg1.l3.m1.4.4.2.2.6" stretchy="false" xref="alg1.l3.m1.4.4.2.3.cmml">}</mo></mrow><mo id="alg1.l3.m1.4.4.6" stretchy="false" xref="alg1.l3.m1.4.4.6.cmml">←</mo><mrow id="alg1.l3.m1.4.4.7" xref="alg1.l3.m1.4.4.7.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l3.m1.4.4.7.2" xref="alg1.l3.m1.4.4.7.2.cmml">ℛ</mi><mo id="alg1.l3.m1.4.4.7.1" xref="alg1.l3.m1.4.4.7.1.cmml">⁢</mo><mrow id="alg1.l3.m1.4.4.7.3.2" xref="alg1.l3.m1.4.4.7.cmml"><mo id="alg1.l3.m1.4.4.7.3.2.1" stretchy="false" xref="alg1.l3.m1.4.4.7.cmml">(</mo><mi id="alg1.l3.m1.2.2" xref="alg1.l3.m1.2.2.cmml">q</mi><mo id="alg1.l3.m1.4.4.7.3.2.2" stretchy="false" xref="alg1.l3.m1.4.4.7.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.4b"><apply id="alg1.l3.m1.4.4.cmml" xref="alg1.l3.m1.4.4"><and id="alg1.l3.m1.4.4a.cmml" xref="alg1.l3.m1.4.4"></and><apply id="alg1.l3.m1.4.4b.cmml" xref="alg1.l3.m1.4.4"><eq id="alg1.l3.m1.4.4.5.cmml" xref="alg1.l3.m1.4.4.5"></eq><ci id="alg1.l3.m1.4.4.4.cmml" xref="alg1.l3.m1.4.4.4">𝐷</ci><set id="alg1.l3.m1.4.4.2.3.cmml" xref="alg1.l3.m1.4.4.2.2"><apply id="alg1.l3.m1.3.3.1.1.1.cmml" xref="alg1.l3.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.3.3.1.1.1.1.cmml" xref="alg1.l3.m1.3.3.1.1.1">subscript</csymbol><ci id="alg1.l3.m1.3.3.1.1.1.2.cmml" xref="alg1.l3.m1.3.3.1.1.1.2">𝑑</ci><cn id="alg1.l3.m1.3.3.1.1.1.3.cmml" type="integer" xref="alg1.l3.m1.3.3.1.1.1.3">1</cn></apply><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">⋯</ci><apply id="alg1.l3.m1.4.4.2.2.2.cmml" xref="alg1.l3.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="alg1.l3.m1.4.4.2.2.2.1.cmml" xref="alg1.l3.m1.4.4.2.2.2">subscript</csymbol><ci id="alg1.l3.m1.4.4.2.2.2.2.cmml" xref="alg1.l3.m1.4.4.2.2.2.2">𝑑</ci><ci id="alg1.l3.m1.4.4.2.2.2.3.cmml" xref="alg1.l3.m1.4.4.2.2.2.3">𝐾</ci></apply></set></apply><apply id="alg1.l3.m1.4.4c.cmml" xref="alg1.l3.m1.4.4"><ci id="alg1.l3.m1.4.4.6.cmml" xref="alg1.l3.m1.4.4.6">←</ci><share href="https://arxiv.org/html/2406.13629v2#alg1.l3.m1.4.4.2.cmml" id="alg1.l3.m1.4.4d.cmml" xref="alg1.l3.m1.4.4"></share><apply id="alg1.l3.m1.4.4.7.cmml" xref="alg1.l3.m1.4.4.7"><times id="alg1.l3.m1.4.4.7.1.cmml" xref="alg1.l3.m1.4.4.7.1"></times><ci id="alg1.l3.m1.4.4.7.2.cmml" xref="alg1.l3.m1.4.4.7.2">ℛ</ci><ci id="alg1.l3.m1.2.2.cmml" xref="alg1.l3.m1.2.2">𝑞</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.4c">D=\{d_{1},\cdots,d_{K}\}\leftarrow\mathcal{R}(q)</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.4d">italic_D = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_d start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT } ← caligraphic_R ( italic_q )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.2.1.1" style="font-size:80%;">4:</span></span>     Synthesize denoising rationale <math alttext="r\leftarrow\mathcal{M}_{\phi}(q,a,D)" class="ltx_Math" display="inline" id="alg1.l4.m1.3"><semantics id="alg1.l4.m1.3a"><mrow id="alg1.l4.m1.3.4" xref="alg1.l4.m1.3.4.cmml"><mi id="alg1.l4.m1.3.4.2" xref="alg1.l4.m1.3.4.2.cmml">r</mi><mo id="alg1.l4.m1.3.4.1" stretchy="false" xref="alg1.l4.m1.3.4.1.cmml">←</mo><mrow id="alg1.l4.m1.3.4.3" xref="alg1.l4.m1.3.4.3.cmml"><msub id="alg1.l4.m1.3.4.3.2" xref="alg1.l4.m1.3.4.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.3.4.3.2.2" xref="alg1.l4.m1.3.4.3.2.2.cmml">ℳ</mi><mi id="alg1.l4.m1.3.4.3.2.3" xref="alg1.l4.m1.3.4.3.2.3.cmml">ϕ</mi></msub><mo id="alg1.l4.m1.3.4.3.1" xref="alg1.l4.m1.3.4.3.1.cmml">⁢</mo><mrow id="alg1.l4.m1.3.4.3.3.2" xref="alg1.l4.m1.3.4.3.3.1.cmml"><mo id="alg1.l4.m1.3.4.3.3.2.1" stretchy="false" xref="alg1.l4.m1.3.4.3.3.1.cmml">(</mo><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">q</mi><mo id="alg1.l4.m1.3.4.3.3.2.2" xref="alg1.l4.m1.3.4.3.3.1.cmml">,</mo><mi id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">a</mi><mo id="alg1.l4.m1.3.4.3.3.2.3" xref="alg1.l4.m1.3.4.3.3.1.cmml">,</mo><mi id="alg1.l4.m1.3.3" xref="alg1.l4.m1.3.3.cmml">D</mi><mo id="alg1.l4.m1.3.4.3.3.2.4" stretchy="false" xref="alg1.l4.m1.3.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.3b"><apply id="alg1.l4.m1.3.4.cmml" xref="alg1.l4.m1.3.4"><ci id="alg1.l4.m1.3.4.1.cmml" xref="alg1.l4.m1.3.4.1">←</ci><ci id="alg1.l4.m1.3.4.2.cmml" xref="alg1.l4.m1.3.4.2">𝑟</ci><apply id="alg1.l4.m1.3.4.3.cmml" xref="alg1.l4.m1.3.4.3"><times id="alg1.l4.m1.3.4.3.1.cmml" xref="alg1.l4.m1.3.4.3.1"></times><apply id="alg1.l4.m1.3.4.3.2.cmml" xref="alg1.l4.m1.3.4.3.2"><csymbol cd="ambiguous" id="alg1.l4.m1.3.4.3.2.1.cmml" xref="alg1.l4.m1.3.4.3.2">subscript</csymbol><ci id="alg1.l4.m1.3.4.3.2.2.cmml" xref="alg1.l4.m1.3.4.3.2.2">ℳ</ci><ci id="alg1.l4.m1.3.4.3.2.3.cmml" xref="alg1.l4.m1.3.4.3.2.3">italic-ϕ</ci></apply><vector id="alg1.l4.m1.3.4.3.3.1.cmml" xref="alg1.l4.m1.3.4.3.3.2"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">𝑞</ci><ci id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">𝑎</ci><ci id="alg1.l4.m1.3.3.cmml" xref="alg1.l4.m1.3.3">𝐷</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.3c">r\leftarrow\mathcal{M}_{\phi}(q,a,D)</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.3d">italic_r ← caligraphic_M start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( italic_q , italic_a , italic_D )</annotation></semantics></math> <span class="ltx_text" id="alg1.l4.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l4.1.m1.1"><semantics id="alg1.l4.1.m1.1a"><mo id="alg1.l4.1.m1.1.1" xref="alg1.l4.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.1.m1.1b"><ci id="alg1.l4.1.m1.1.1.cmml" xref="alg1.l4.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.1.m1.1d">▷</annotation></semantics></math> <span class="ltx_text" id="alg1.l4.1.1" style="color:#0000FF;">Rationale Generation (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS2" title="2.2 Rationale Generation via Instruction-Following ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.2</span></a>)</span>
</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>Augment training data <math alttext="\mathcal{T}\rightarrow\mathcal{T}^{+}=\{\mbox{$\langle$}q,r\mbox{$\rangle$}\}" class="ltx_Math" display="inline" id="alg1.l5.m1.5"><semantics id="alg1.l5.m1.5a"><mrow id="alg1.l5.m1.5.5" xref="alg1.l5.m1.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m1.5.5.3" xref="alg1.l5.m1.5.5.3.cmml">𝒯</mi><mo id="alg1.l5.m1.5.5.4" stretchy="false" xref="alg1.l5.m1.5.5.4.cmml">→</mo><msup id="alg1.l5.m1.5.5.5" xref="alg1.l5.m1.5.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m1.5.5.5.2" xref="alg1.l5.m1.5.5.5.2.cmml">𝒯</mi><mo id="alg1.l5.m1.5.5.5.3" xref="alg1.l5.m1.5.5.5.3.cmml">+</mo></msup><mo id="alg1.l5.m1.5.5.6" xref="alg1.l5.m1.5.5.6.cmml">=</mo><mrow id="alg1.l5.m1.5.5.1.1" xref="alg1.l5.m1.5.5.1.2.cmml"><mo id="alg1.l5.m1.5.5.1.1.2" stretchy="false" xref="alg1.l5.m1.5.5.1.2.cmml">{</mo><mrow id="alg1.l5.m1.5.5.1.1.1.2" xref="alg1.l5.m1.5.5.1.1.1.1.cmml"><mo id="alg1.l5.m1.5.5.1.1.1.2.1" stretchy="false" xref="alg1.l5.m1.5.5.1.1.1.1.cmml">⟨</mo><mi id="alg1.l5.m1.3.3" xref="alg1.l5.m1.3.3.cmml">q</mi><mo id="alg1.l5.m1.5.5.1.1.1.2.2" xref="alg1.l5.m1.5.5.1.1.1.1.cmml">,</mo><mi id="alg1.l5.m1.4.4" xref="alg1.l5.m1.4.4.cmml">r</mi><mo id="alg1.l5.m1.5.5.1.1.1.2.3" stretchy="false" xref="alg1.l5.m1.5.5.1.1.1.1.cmml">⟩</mo></mrow><mo id="alg1.l5.m1.5.5.1.1.3" stretchy="false" xref="alg1.l5.m1.5.5.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.5b"><apply id="alg1.l5.m1.5.5.cmml" xref="alg1.l5.m1.5.5"><and id="alg1.l5.m1.5.5a.cmml" xref="alg1.l5.m1.5.5"></and><apply id="alg1.l5.m1.5.5b.cmml" xref="alg1.l5.m1.5.5"><ci id="alg1.l5.m1.5.5.4.cmml" xref="alg1.l5.m1.5.5.4">→</ci><ci id="alg1.l5.m1.5.5.3.cmml" xref="alg1.l5.m1.5.5.3">𝒯</ci><apply id="alg1.l5.m1.5.5.5.cmml" xref="alg1.l5.m1.5.5.5"><csymbol cd="ambiguous" id="alg1.l5.m1.5.5.5.1.cmml" xref="alg1.l5.m1.5.5.5">superscript</csymbol><ci id="alg1.l5.m1.5.5.5.2.cmml" xref="alg1.l5.m1.5.5.5.2">𝒯</ci><plus id="alg1.l5.m1.5.5.5.3.cmml" xref="alg1.l5.m1.5.5.5.3"></plus></apply></apply><apply id="alg1.l5.m1.5.5c.cmml" xref="alg1.l5.m1.5.5"><eq id="alg1.l5.m1.5.5.6.cmml" xref="alg1.l5.m1.5.5.6"></eq><share href="https://arxiv.org/html/2406.13629v2#alg1.l5.m1.5.5.5.cmml" id="alg1.l5.m1.5.5d.cmml" xref="alg1.l5.m1.5.5"></share><set id="alg1.l5.m1.5.5.1.2.cmml" xref="alg1.l5.m1.5.5.1.1"><list id="alg1.l5.m1.5.5.1.1.1.1.cmml" xref="alg1.l5.m1.5.5.1.1.1.2"><ci id="alg1.l5.m1.3.3.cmml" xref="alg1.l5.m1.3.3">𝑞</ci><ci id="alg1.l5.m1.4.4.cmml" xref="alg1.l5.m1.4.4">𝑟</ci></list></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.5c">\mathcal{T}\rightarrow\mathcal{T}^{+}=\{\mbox{$\langle$}q,r\mbox{$\rangle$}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.5d">caligraphic_T → caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT = { ⟨ italic_q , italic_r ⟩ }</annotation></semantics></math>
<span class="ltx_text ltx_font_typewriter" id="alg1.l5.2" style="color:#0000FF;">/* Two learning modes */</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.2.1.1" style="font-size:80%;">6:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l6.3">if</span>  <span class="ltx_text ltx_font_typewriter" id="alg1.l6.4">LearningMode</span> == <span class="ltx_text ltx_font_typewriter" id="alg1.l6.5">In-Context Learning</span> <span class="ltx_text ltx_font_bold" id="alg1.l6.6">then</span> <span class="ltx_text" id="alg1.l6.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l6.1.m1.1"><semantics id="alg1.l6.1.m1.1a"><mo id="alg1.l6.1.m1.1.1" xref="alg1.l6.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l6.1.m1.1b"><ci id="alg1.l6.1.m1.1.1.cmml" xref="alg1.l6.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.1.m1.1d">▷</annotation></semantics></math> <span class="ltx_text ltx_font_smallcaps" id="alg1.l6.1.1" style="color:#0000FF;">InstructRAG<span class="ltx_text ltx_font_upright" id="alg1.l6.1.1.1">-ICL</span></span>
</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>     Sample ICL examples <math alttext="\mathcal{E}=\{\mbox{$\langle$}q,r\mbox{$\rangle$}\}\subseteq\mathcal{T}^{+}" class="ltx_Math" display="inline" id="alg1.l7.m1.5"><semantics id="alg1.l7.m1.5a"><mrow id="alg1.l7.m1.5.5" xref="alg1.l7.m1.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l7.m1.5.5.3" xref="alg1.l7.m1.5.5.3.cmml">ℰ</mi><mo id="alg1.l7.m1.5.5.4" xref="alg1.l7.m1.5.5.4.cmml">=</mo><mrow id="alg1.l7.m1.5.5.1.1" xref="alg1.l7.m1.5.5.1.2.cmml"><mo id="alg1.l7.m1.5.5.1.1.2" stretchy="false" xref="alg1.l7.m1.5.5.1.2.cmml">{</mo><mrow id="alg1.l7.m1.5.5.1.1.1.2" xref="alg1.l7.m1.5.5.1.1.1.1.cmml"><mo id="alg1.l7.m1.5.5.1.1.1.2.1" stretchy="false" xref="alg1.l7.m1.5.5.1.1.1.1.cmml">⟨</mo><mi id="alg1.l7.m1.3.3" xref="alg1.l7.m1.3.3.cmml">q</mi><mo id="alg1.l7.m1.5.5.1.1.1.2.2" xref="alg1.l7.m1.5.5.1.1.1.1.cmml">,</mo><mi id="alg1.l7.m1.4.4" xref="alg1.l7.m1.4.4.cmml">r</mi><mo id="alg1.l7.m1.5.5.1.1.1.2.3" stretchy="false" xref="alg1.l7.m1.5.5.1.1.1.1.cmml">⟩</mo></mrow><mo id="alg1.l7.m1.5.5.1.1.3" stretchy="false" xref="alg1.l7.m1.5.5.1.2.cmml">}</mo></mrow><mo id="alg1.l7.m1.5.5.5" xref="alg1.l7.m1.5.5.5.cmml">⊆</mo><msup id="alg1.l7.m1.5.5.6" xref="alg1.l7.m1.5.5.6.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l7.m1.5.5.6.2" xref="alg1.l7.m1.5.5.6.2.cmml">𝒯</mi><mo id="alg1.l7.m1.5.5.6.3" xref="alg1.l7.m1.5.5.6.3.cmml">+</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.5b"><apply id="alg1.l7.m1.5.5.cmml" xref="alg1.l7.m1.5.5"><and id="alg1.l7.m1.5.5a.cmml" xref="alg1.l7.m1.5.5"></and><apply id="alg1.l7.m1.5.5b.cmml" xref="alg1.l7.m1.5.5"><eq id="alg1.l7.m1.5.5.4.cmml" xref="alg1.l7.m1.5.5.4"></eq><ci id="alg1.l7.m1.5.5.3.cmml" xref="alg1.l7.m1.5.5.3">ℰ</ci><set id="alg1.l7.m1.5.5.1.2.cmml" xref="alg1.l7.m1.5.5.1.1"><list id="alg1.l7.m1.5.5.1.1.1.1.cmml" xref="alg1.l7.m1.5.5.1.1.1.2"><ci id="alg1.l7.m1.3.3.cmml" xref="alg1.l7.m1.3.3">𝑞</ci><ci id="alg1.l7.m1.4.4.cmml" xref="alg1.l7.m1.4.4">𝑟</ci></list></set></apply><apply id="alg1.l7.m1.5.5c.cmml" xref="alg1.l7.m1.5.5"><subset id="alg1.l7.m1.5.5.5.cmml" xref="alg1.l7.m1.5.5.5"></subset><share href="https://arxiv.org/html/2406.13629v2#alg1.l7.m1.5.5.1.cmml" id="alg1.l7.m1.5.5d.cmml" xref="alg1.l7.m1.5.5"></share><apply id="alg1.l7.m1.5.5.6.cmml" xref="alg1.l7.m1.5.5.6"><csymbol cd="ambiguous" id="alg1.l7.m1.5.5.6.1.cmml" xref="alg1.l7.m1.5.5.6">superscript</csymbol><ci id="alg1.l7.m1.5.5.6.2.cmml" xref="alg1.l7.m1.5.5.6.2">𝒯</ci><plus id="alg1.l7.m1.5.5.6.3.cmml" xref="alg1.l7.m1.5.5.6.3"></plus></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.5c">\mathcal{E}=\{\mbox{$\langle$}q,r\mbox{$\rangle$}\}\subseteq\mathcal{T}^{+}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.5d">caligraphic_E = { ⟨ italic_q , italic_r ⟩ } ⊆ caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.2.1.1" style="font-size:80%;">8:</span></span>     <math alttext="r\leftarrow\mathcal{M}_{\theta}(r|q,\mathcal{R}(q),\mathcal{E})" class="ltx_Math" display="inline" id="alg1.l8.m1.4"><semantics id="alg1.l8.m1.4a"><mrow id="alg1.l8.m1.4.4" xref="alg1.l8.m1.4.4.cmml"><mi id="alg1.l8.m1.4.4.3" xref="alg1.l8.m1.4.4.3.cmml">r</mi><mo id="alg1.l8.m1.4.4.2" stretchy="false" xref="alg1.l8.m1.4.4.2.cmml">←</mo><mrow id="alg1.l8.m1.4.4.1" xref="alg1.l8.m1.4.4.1.cmml"><msub id="alg1.l8.m1.4.4.1.3" xref="alg1.l8.m1.4.4.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l8.m1.4.4.1.3.2" xref="alg1.l8.m1.4.4.1.3.2.cmml">ℳ</mi><mi id="alg1.l8.m1.4.4.1.3.3" xref="alg1.l8.m1.4.4.1.3.3.cmml">θ</mi></msub><mo id="alg1.l8.m1.4.4.1.2" xref="alg1.l8.m1.4.4.1.2.cmml">⁢</mo><mrow id="alg1.l8.m1.4.4.1.1.1" xref="alg1.l8.m1.4.4.1.1.1.1.cmml"><mo id="alg1.l8.m1.4.4.1.1.1.2" stretchy="false" xref="alg1.l8.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="alg1.l8.m1.4.4.1.1.1.1" xref="alg1.l8.m1.4.4.1.1.1.1.cmml"><mi id="alg1.l8.m1.4.4.1.1.1.1.3" xref="alg1.l8.m1.4.4.1.1.1.1.3.cmml">r</mi><mo fence="false" id="alg1.l8.m1.4.4.1.1.1.1.2" xref="alg1.l8.m1.4.4.1.1.1.1.2.cmml">|</mo><mrow id="alg1.l8.m1.4.4.1.1.1.1.1.1" xref="alg1.l8.m1.4.4.1.1.1.1.1.2.cmml"><mi id="alg1.l8.m1.2.2" xref="alg1.l8.m1.2.2.cmml">q</mi><mo id="alg1.l8.m1.4.4.1.1.1.1.1.1.2" xref="alg1.l8.m1.4.4.1.1.1.1.1.2.cmml">,</mo><mrow id="alg1.l8.m1.4.4.1.1.1.1.1.1.1" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.2" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.2.cmml">ℛ</mi><mo id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.1" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.3.2" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.cmml"><mo id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.cmml">(</mo><mi id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml">q</mi><mo id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l8.m1.4.4.1.1.1.1.1.1.3" xref="alg1.l8.m1.4.4.1.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l8.m1.3.3" xref="alg1.l8.m1.3.3.cmml">ℰ</mi></mrow></mrow><mo id="alg1.l8.m1.4.4.1.1.1.3" stretchy="false" xref="alg1.l8.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.4b"><apply id="alg1.l8.m1.4.4.cmml" xref="alg1.l8.m1.4.4"><ci id="alg1.l8.m1.4.4.2.cmml" xref="alg1.l8.m1.4.4.2">←</ci><ci id="alg1.l8.m1.4.4.3.cmml" xref="alg1.l8.m1.4.4.3">𝑟</ci><apply id="alg1.l8.m1.4.4.1.cmml" xref="alg1.l8.m1.4.4.1"><times id="alg1.l8.m1.4.4.1.2.cmml" xref="alg1.l8.m1.4.4.1.2"></times><apply id="alg1.l8.m1.4.4.1.3.cmml" xref="alg1.l8.m1.4.4.1.3"><csymbol cd="ambiguous" id="alg1.l8.m1.4.4.1.3.1.cmml" xref="alg1.l8.m1.4.4.1.3">subscript</csymbol><ci id="alg1.l8.m1.4.4.1.3.2.cmml" xref="alg1.l8.m1.4.4.1.3.2">ℳ</ci><ci id="alg1.l8.m1.4.4.1.3.3.cmml" xref="alg1.l8.m1.4.4.1.3.3">𝜃</ci></apply><apply id="alg1.l8.m1.4.4.1.1.1.1.cmml" xref="alg1.l8.m1.4.4.1.1.1"><csymbol cd="latexml" id="alg1.l8.m1.4.4.1.1.1.1.2.cmml" xref="alg1.l8.m1.4.4.1.1.1.1.2">conditional</csymbol><ci id="alg1.l8.m1.4.4.1.1.1.1.3.cmml" xref="alg1.l8.m1.4.4.1.1.1.1.3">𝑟</ci><list id="alg1.l8.m1.4.4.1.1.1.1.1.2.cmml" xref="alg1.l8.m1.4.4.1.1.1.1.1.1"><ci id="alg1.l8.m1.2.2.cmml" xref="alg1.l8.m1.2.2">𝑞</ci><apply id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.cmml" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1"><times id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.1"></times><ci id="alg1.l8.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="alg1.l8.m1.4.4.1.1.1.1.1.1.1.2">ℛ</ci><ci id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1">𝑞</ci></apply><ci id="alg1.l8.m1.3.3.cmml" xref="alg1.l8.m1.3.3">ℰ</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.4c">r\leftarrow\mathcal{M}_{\theta}(r|q,\mathcal{R}(q),\mathcal{E})</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.4d">italic_r ← caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_r | italic_q , caligraphic_R ( italic_q ) , caligraphic_E )</annotation></semantics></math> given inference query <math alttext="q" class="ltx_Math" display="inline" id="alg1.l8.m2.1"><semantics id="alg1.l8.m2.1a"><mi id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><ci id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m2.1d">italic_q</annotation></semantics></math> <span class="ltx_text" id="alg1.l8.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l8.1.m1.1"><semantics id="alg1.l8.1.m1.1a"><mo id="alg1.l8.1.m1.1.1" xref="alg1.l8.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l8.1.m1.1b"><ci id="alg1.l8.1.m1.1.1.cmml" xref="alg1.l8.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.1.m1.1d">▷</annotation></semantics></math> <span class="ltx_text" id="alg1.l8.1.1" style="color:#808080;">Detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T10" title="Table 10 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">10</span></a></span>
</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.2.1.1" style="font-size:80%;">9:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l9.3">else</span> <span class="ltx_text ltx_font_bold" id="alg1.l9.4">if</span>  <span class="ltx_text ltx_font_typewriter" id="alg1.l9.5">LearningMode</span> == <span class="ltx_text ltx_font_typewriter" id="alg1.l9.6">Fine-Tuning</span> <span class="ltx_text ltx_font_bold" id="alg1.l9.7">then</span> <span class="ltx_text" id="alg1.l9.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l9.1.m1.1"><semantics id="alg1.l9.1.m1.1a"><mo id="alg1.l9.1.m1.1.1" xref="alg1.l9.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l9.1.m1.1b"><ci id="alg1.l9.1.m1.1.1.cmml" xref="alg1.l9.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.1.m1.1d">▷</annotation></semantics></math> <span class="ltx_text ltx_font_smallcaps" id="alg1.l9.1.1" style="color:#0000FF;">InstructRAG<span class="ltx_text ltx_font_upright" id="alg1.l9.1.1.1">-FT</span></span>
</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>     Fine-tune <math alttext="\mathcal{M}_{\theta}" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><msub id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.1.1.2" xref="alg1.l10.m1.1.1.2.cmml">ℳ</mi><mi id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1">subscript</csymbol><ci id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.2">ℳ</ci><ci id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">\mathcal{M}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.1d">caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> on <math alttext="\mathcal{T}^{+}" class="ltx_Math" display="inline" id="alg1.l10.m2.1"><semantics id="alg1.l10.m2.1a"><msup id="alg1.l10.m2.1.1" xref="alg1.l10.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m2.1.1.2" xref="alg1.l10.m2.1.1.2.cmml">𝒯</mi><mo id="alg1.l10.m2.1.1.3" xref="alg1.l10.m2.1.1.3.cmml">+</mo></msup><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.1b"><apply id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1"><csymbol cd="ambiguous" id="alg1.l10.m2.1.1.1.cmml" xref="alg1.l10.m2.1.1">superscript</csymbol><ci id="alg1.l10.m2.1.1.2.cmml" xref="alg1.l10.m2.1.1.2">𝒯</ci><plus id="alg1.l10.m2.1.1.3.cmml" xref="alg1.l10.m2.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.1c">\mathcal{T}^{+}</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m2.1d">caligraphic_T start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math> with retrieved documents <math alttext="\{\mbox{$\langle$}q,r,D\mbox{$\rangle$}\}" class="ltx_Math" display="inline" id="alg1.l10.m3.6"><semantics id="alg1.l10.m3.6a"><mrow id="alg1.l10.m3.6.6.1" xref="alg1.l10.m3.6.6.2.cmml"><mo id="alg1.l10.m3.6.6.1.2" stretchy="false" xref="alg1.l10.m3.6.6.2.cmml">{</mo><mrow id="alg1.l10.m3.6.6.1.1.2" xref="alg1.l10.m3.6.6.1.1.1.cmml"><mo id="alg1.l10.m3.6.6.1.1.2.1" stretchy="false" xref="alg1.l10.m3.6.6.1.1.1.cmml">⟨</mo><mi id="alg1.l10.m3.3.3" xref="alg1.l10.m3.3.3.cmml">q</mi><mo id="alg1.l10.m3.6.6.1.1.2.2" xref="alg1.l10.m3.6.6.1.1.1.cmml">,</mo><mi id="alg1.l10.m3.4.4" xref="alg1.l10.m3.4.4.cmml">r</mi><mo id="alg1.l10.m3.6.6.1.1.2.3" xref="alg1.l10.m3.6.6.1.1.1.cmml">,</mo><mi id="alg1.l10.m3.5.5" xref="alg1.l10.m3.5.5.cmml">D</mi><mo id="alg1.l10.m3.6.6.1.1.2.4" stretchy="false" xref="alg1.l10.m3.6.6.1.1.1.cmml">⟩</mo></mrow><mo id="alg1.l10.m3.6.6.1.3" stretchy="false" xref="alg1.l10.m3.6.6.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m3.6b"><set id="alg1.l10.m3.6.6.2.cmml" xref="alg1.l10.m3.6.6.1"><list id="alg1.l10.m3.6.6.1.1.1.cmml" xref="alg1.l10.m3.6.6.1.1.2"><ci id="alg1.l10.m3.3.3.cmml" xref="alg1.l10.m3.3.3">𝑞</ci><ci id="alg1.l10.m3.4.4.cmml" xref="alg1.l10.m3.4.4">𝑟</ci><ci id="alg1.l10.m3.5.5.cmml" xref="alg1.l10.m3.5.5">𝐷</ci></list></set></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m3.6c">\{\mbox{$\langle$}q,r,D\mbox{$\rangle$}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m3.6d">{ ⟨ italic_q , italic_r , italic_D ⟩ }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.2.1.1" style="font-size:80%;">11:</span></span>     <math alttext="r\leftarrow\mathcal{M}_{\theta}(r|q,\mathcal{R}(q))" class="ltx_Math" display="inline" id="alg1.l11.m1.3"><semantics id="alg1.l11.m1.3a"><mrow id="alg1.l11.m1.3.3" xref="alg1.l11.m1.3.3.cmml"><mi id="alg1.l11.m1.3.3.3" xref="alg1.l11.m1.3.3.3.cmml">r</mi><mo id="alg1.l11.m1.3.3.2" stretchy="false" xref="alg1.l11.m1.3.3.2.cmml">←</mo><mrow id="alg1.l11.m1.3.3.1" xref="alg1.l11.m1.3.3.1.cmml"><msub id="alg1.l11.m1.3.3.1.3" xref="alg1.l11.m1.3.3.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.m1.3.3.1.3.2" xref="alg1.l11.m1.3.3.1.3.2.cmml">ℳ</mi><mi id="alg1.l11.m1.3.3.1.3.3" xref="alg1.l11.m1.3.3.1.3.3.cmml">θ</mi></msub><mo id="alg1.l11.m1.3.3.1.2" xref="alg1.l11.m1.3.3.1.2.cmml">⁢</mo><mrow id="alg1.l11.m1.3.3.1.1.1" xref="alg1.l11.m1.3.3.1.1.1.1.cmml"><mo id="alg1.l11.m1.3.3.1.1.1.2" stretchy="false" xref="alg1.l11.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="alg1.l11.m1.3.3.1.1.1.1" xref="alg1.l11.m1.3.3.1.1.1.1.cmml"><mi id="alg1.l11.m1.3.3.1.1.1.1.3" xref="alg1.l11.m1.3.3.1.1.1.1.3.cmml">r</mi><mo fence="false" id="alg1.l11.m1.3.3.1.1.1.1.2" xref="alg1.l11.m1.3.3.1.1.1.1.2.cmml">|</mo><mrow id="alg1.l11.m1.3.3.1.1.1.1.1.1" xref="alg1.l11.m1.3.3.1.1.1.1.1.2.cmml"><mi id="alg1.l11.m1.2.2" xref="alg1.l11.m1.2.2.cmml">q</mi><mo id="alg1.l11.m1.3.3.1.1.1.1.1.1.2" xref="alg1.l11.m1.3.3.1.1.1.1.1.2.cmml">,</mo><mrow id="alg1.l11.m1.3.3.1.1.1.1.1.1.1" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.2" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.2.cmml">ℛ</mi><mo id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.1" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.3.2" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.cmml"><mo id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mi id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">q</mi><mo id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="alg1.l11.m1.3.3.1.1.1.3" stretchy="false" xref="alg1.l11.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.3b"><apply id="alg1.l11.m1.3.3.cmml" xref="alg1.l11.m1.3.3"><ci id="alg1.l11.m1.3.3.2.cmml" xref="alg1.l11.m1.3.3.2">←</ci><ci id="alg1.l11.m1.3.3.3.cmml" xref="alg1.l11.m1.3.3.3">𝑟</ci><apply id="alg1.l11.m1.3.3.1.cmml" xref="alg1.l11.m1.3.3.1"><times id="alg1.l11.m1.3.3.1.2.cmml" xref="alg1.l11.m1.3.3.1.2"></times><apply id="alg1.l11.m1.3.3.1.3.cmml" xref="alg1.l11.m1.3.3.1.3"><csymbol cd="ambiguous" id="alg1.l11.m1.3.3.1.3.1.cmml" xref="alg1.l11.m1.3.3.1.3">subscript</csymbol><ci id="alg1.l11.m1.3.3.1.3.2.cmml" xref="alg1.l11.m1.3.3.1.3.2">ℳ</ci><ci id="alg1.l11.m1.3.3.1.3.3.cmml" xref="alg1.l11.m1.3.3.1.3.3">𝜃</ci></apply><apply id="alg1.l11.m1.3.3.1.1.1.1.cmml" xref="alg1.l11.m1.3.3.1.1.1"><csymbol cd="latexml" id="alg1.l11.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l11.m1.3.3.1.1.1.1.2">conditional</csymbol><ci id="alg1.l11.m1.3.3.1.1.1.1.3.cmml" xref="alg1.l11.m1.3.3.1.1.1.1.3">𝑟</ci><list id="alg1.l11.m1.3.3.1.1.1.1.1.2.cmml" xref="alg1.l11.m1.3.3.1.1.1.1.1.1"><ci id="alg1.l11.m1.2.2.cmml" xref="alg1.l11.m1.2.2">𝑞</ci><apply id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.cmml" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1"><times id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.1"></times><ci id="alg1.l11.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="alg1.l11.m1.3.3.1.1.1.1.1.1.1.2">ℛ</ci><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">𝑞</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.3c">r\leftarrow\mathcal{M}_{\theta}(r|q,\mathcal{R}(q))</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.3d">italic_r ← caligraphic_M start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_r | italic_q , caligraphic_R ( italic_q ) )</annotation></semantics></math> given inference query <math alttext="q" class="ltx_Math" display="inline" id="alg1.l11.m2.1"><semantics id="alg1.l11.m2.1a"><mi id="alg1.l11.m2.1.1" xref="alg1.l11.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg1.l11.m2.1b"><ci id="alg1.l11.m2.1.1.cmml" xref="alg1.l11.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m2.1d">italic_q</annotation></semantics></math> <span class="ltx_text" id="alg1.l11.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l11.1.m1.1"><semantics id="alg1.l11.1.m1.1a"><mo id="alg1.l11.1.m1.1.1" xref="alg1.l11.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l11.1.m1.1b"><ci id="alg1.l11.1.m1.1.1.cmml" xref="alg1.l11.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.1.m1.1d">▷</annotation></semantics></math> <span class="ltx_text" id="alg1.l11.1.1" style="color:#808080;">Detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T11" title="Table 11 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">11</span></a></span>
</span>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l12.2">return</span> <math alttext="r" class="ltx_Math" display="inline" id="alg1.l12.m1.1"><semantics id="alg1.l12.m1.1a"><mi id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><ci id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.1d">italic_r</annotation></semantics></math>
</div>
</div>
</figure>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setting</h3>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.4.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S3.T2.5.2" style="font-size:90%;">Dataset statistics and retrieval setting.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.2.3">Dataset</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.2.4">Train</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.2.5">Test</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.2.6">Retriever</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1">Top-<math alttext="K" class="ltx_Math" display="inline" id="S3.T2.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.m1.1a"><mi id="S3.T2.1.1.1.m1.1.1" xref="S3.T2.1.1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.m1.1d">italic_K</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.2.2.2">Recall@<math alttext="K" class="ltx_Math" display="inline" id="S3.T2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.m1.1a"><mi id="S3.T2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.m1.1d">italic_K</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.2.3.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.3.1.1">PopQA</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.2">12,868</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.3">1,399</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.4">Contriever</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.5">5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.6">68.7</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.4.2">
<td class="ltx_td ltx_align_left" id="S3.T2.2.4.2.1">TriviaQA</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.2.2">78,785</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.2.3">11,313</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.2.4">Contriever</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.2.5">5</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.2.6">73.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.5.3">
<td class="ltx_td ltx_align_left" id="S3.T2.2.5.3.1">Natural Questions</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.5.3.2">79,168</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.5.3.3">3,610</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.5.3.4">DPR</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.5.3.5">5</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.5.3.6">68.8</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.6.4">
<td class="ltx_td ltx_align_left" id="S3.T2.2.6.4.1">ASQA</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.6.4.2">4,353</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.6.4.3">948</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.6.4.4">GTR</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.6.4.5">5</td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.6.4.6">82.2</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.7.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.7.5.1">2WikiMultiHopQA</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.7.5.2">167,454</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.7.5.3">12,576</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.7.5.4">BM25</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.7.5.5">10</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.7.5.6">40.7</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.2"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.2.1">RAG tasks and evaluation metrics.</span> We extensively validate the effectiveness of <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p1.2.2">InstructRAG</span> on five knowledge-intensive benchmarks, including PopQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib61" title="">61</a>]</cite>, TriviaQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib38" title="">38</a>]</cite>, Natural Questions <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib47" title="">47</a>]</cite>, ASQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib78" title="">78</a>]</cite>, and 2WikiMultiHopQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib24" title="">24</a>]</cite>.
We use Wikipedia corpus as the retrieval source, and test our method with both sparse and dense off-the-shelf retrievers, including BM25 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib71" title="">71</a>]</cite>, DPR <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib39" title="">39</a>]</cite>, GTR <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib65" title="">65</a>]</cite> and Contriver <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib27" title="">27</a>]</cite>.
The retrieval quality is measured by Recall@<math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_K</annotation></semantics></math>, indicating whether the retrieved <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math> documents contain the correct answer.
Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.T2" title="Table 2 ‣ 3.1 Experimental Setting ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2</span></a> shows the detailed dataset statistics.
Following standard evaluation settings <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>]</cite>, we adopt the official metric of correctness (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.2.3">str-em</em>), citation precision (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.2.4">pre</em>) and recall (<em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.2.5">rec</em>) for ASQA <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib18" title="">18</a>]</cite>, and use <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.2.6">accuracy</em> for the other tasks, which measures whether the ground-truth answers are included in the model generations <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib61" title="">61</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib73" title="">73</a>]</cite>.
Additionally, we also adopt LLM-as-a-judge for further evaluation (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.SS4" title="3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3.4</span></a>), as the above standard metrics are subject to the limitations of pattern-matching, which cannot accurately handle semantic equivalence.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Baselines.</span> We compare our method with a wide range of RAG baselines under both training-free and trainable settings.
Given that state-of-the-art LMs have incorporated a large amount of world-knowledge during the pre-training stage, we also report the performance of a non-retrieval baseline (namely, <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.2">vanilla zero-shot prompting</span>) for reference.
Specifically, the training-free RAG baselines includes: (1) <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.3">in-context retrieval-augmented language modeling (RALM)</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib70" title="">70</a>]</cite>, a prompting method that extends the non-retrieval baseline by presenting the model with retrieved documents; (2) <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.4">few-shot demonstration with instruction</span>, an ICL method using ground-truth question-answer pairs sampled from the training set as demonstration exemplars.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The trainable RAG baselines include: (1) <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">vanilla supervised fine-tuning (SFT)</span>, a supervised method with the training objective of maximizing the data likelihood of ground-truth answer given potentially noisy input; (2) <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.2">RetRobust</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib105" title="">105</a>]</cite>, which fine-tunes the RAG model on a mixture of relevant and irrelevant contexts to make it robust to irrelevant contexts; (3) <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.3">Self-RAG</span> <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>]</cite>, a strong trainable baseline, focusing on adaptive retrieval controlled by special reflection tokens.
Both RetRobust and Self-RAG were originally built on Llama-2 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib82" title="">82</a>]</cite> with additional supervisions.
For example, RetRobust augments the training data for multi-hop reasoning tasks (<span class="ltx_text ltx_font_slanted" id="S3.SS1.p3.1.4">e.g.</span>, 2WikiMultiHopQA) by prompting GPT-3 to decompose the original query and generate intermediate subqueries, and Self-RAG requires GPT-4 to generate additional reflective tokens to augment training samples.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.3">For a fair comparison, we re-implement the two methods on Llama-2<math alttext="{}_{\textsc{7B}}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1a" xref="S3.SS1.p4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS1.p4.1.m1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1a.cmml">7B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><ci id="S3.SS1.p4.1.m1.1.1.1a.cmml" xref="S3.SS1.p4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS1.p4.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.SS1.p4.1.m1.1.1.1">7B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">{}_{\textsc{7B}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">start_FLOATSUBSCRIPT 7B end_FLOATSUBSCRIPT</annotation></semantics></math> and/or Llama-2<math alttext="{}_{\textsc{13B}}" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><msub id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1a" xref="S3.SS1.p4.2.m2.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1a.cmml">13B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><ci id="S3.SS1.p4.2.m2.1.1.1a.cmml" xref="S3.SS1.p4.2.m2.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS1.p4.2.m2.1.1.1.cmml" mathsize="70%" xref="S3.SS1.p4.2.m2.1.1.1">13B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">{}_{\textsc{13B}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">start_FLOATSUBSCRIPT 13B end_FLOATSUBSCRIPT</annotation></semantics></math> with augmented training data released by their authors, and report their performance as the higher one between the original scores and our reproduced results.
As our method adopts instruction-tuned Llama-3 as the backbone model, we also train RetRobust and Self-RAG with Llama-3-Instruct<math alttext="{}_{\textsc{8B}}" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><msub id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1a" xref="S3.SS1.p4.3.m3.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS1.p4.3.m3.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1a.cmml">8B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><ci id="S3.SS1.p4.3.m3.1.1.1a.cmml" xref="S3.SS1.p4.3.m3.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS1.p4.3.m3.1.1.1.cmml" mathsize="70%" xref="S3.SS1.p4.3.m3.1.1.1">8B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">{}_{\textsc{8B}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">start_FLOATSUBSCRIPT 8B end_FLOATSUBSCRIPT</annotation></semantics></math> and optimize their performance through extensive hyper-parameters search.
More details on implementation, including training, inference, and prompt design are available in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A1" title="Appendix A Implementation Details ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">A</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3" title="Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Main Result</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.T3" title="Table 3 ‣ 3.2 Main Result ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3</span></a> shows the overall experimental results, providing a comprehensive comparison between our <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p1.1.1">InstructRAG</span> and baseline methods in both training-free and trainable RAG settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.2.1">Baselines without retrieval.</span>
As shown in the first block, the basic instruction-tuned models (Llama-3-Instruct<math alttext="{}_{\textsc{8B}}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1a" xref="S3.SS2.p2.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1a.cmml">8B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><ci id="S3.SS2.p2.1.m1.1.1.1a.cmml" xref="S3.SS2.p2.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS2.p2.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.SS2.p2.1.m1.1.1.1">8B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">{}_{\textsc{8B}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">start_FLOATSUBSCRIPT 8B end_FLOATSUBSCRIPT</annotation></semantics></math> and Llama-3-Instruct<math alttext="{{}_{\textsc{70B}}}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1a" xref="S3.SS2.p2.2.m2.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1a.cmml">70B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><ci id="S3.SS2.p2.2.m2.1.1.1a.cmml" xref="S3.SS2.p2.2.m2.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS2.p2.2.m2.1.1.1.cmml" mathsize="70%" xref="S3.SS2.p2.2.m2.1.1.1">70B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">{{}_{\textsc{70B}}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">start_FLOATSUBSCRIPT 70B end_FLOATSUBSCRIPT</annotation></semantics></math>) already achieve notable performance across all five benchmarks, with the 70B model exhibiting a surprisingly competitive performance of 80.6% on the TriviaQA.
This observation suggests that the required knowledge for these tasks mostly falls within the LM’s parametric knowledge, probably due to what is known as <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.2.2">data contamination</em> (<span class="ltx_text ltx_font_slanted" id="S3.SS2.p2.2.3">i.e.</span>, the presence of test data of downstream tasks in the pre-training data of LMs) <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib59" title="">59</a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T3.28.1.1" style="font-size:113%;">Table 3</span>: </span><span class="ltx_text" id="S3.T3.29.2" style="font-size:113%;">
Overall results of <span class="ltx_text ltx_font_smallcaps" id="S3.T3.29.2.1">InstructRAG</span> and baselines on five knowledge-intensive benchmarks in training-free and trainable RAG settings. We re-implement baselines and report their performance as the higher one between the original scores and our reproduced results. * indicates the results copied from <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>]</cite> for reference. “–” indicates the results are not reported in the original paper or not applicable (<span class="ltx_text ltx_font_slanted" id="S3.T3.29.2.2">e.g.</span>, some methods cannot produce citations). The best performance is highlighted in <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S3.T3.29.2.3">bold</em><span class="ltx_text ltx_font_bold" id="S3.T3.29.2.4">.</span></span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T3.15">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.15.16.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T3.15.16.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.15.16.1.2"><span class="ltx_text" id="S3.T3.15.16.1.2.1" style="font-size:80%;">PopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.15.16.1.3"><span class="ltx_text" id="S3.T3.15.16.1.3.1" style="font-size:80%;">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.15.16.1.4"><span class="ltx_text" id="S3.T3.15.16.1.4.1" style="font-size:80%;">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.15.16.1.5"><span class="ltx_text" id="S3.T3.15.16.1.5.1" style="font-size:80%;">MultiHopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T3.15.16.1.6"><span class="ltx_text" id="S3.T3.15.16.1.6.1" style="font-size:80%;">ASQA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.17.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.17.2.1"><span class="ltx_text" id="S3.T3.15.17.2.1.1" style="font-size:80%;">Method</span></th>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.2"><span class="ltx_text" id="S3.T3.15.17.2.2.1" style="font-size:80%;">(acc)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.3"><span class="ltx_text" id="S3.T3.15.17.2.3.1" style="font-size:80%;">(acc)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.4"><span class="ltx_text" id="S3.T3.15.17.2.4.1" style="font-size:80%;">(acc)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.5"><span class="ltx_text" id="S3.T3.15.17.2.5.1" style="font-size:80%;">(acc)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.6"><span class="ltx_text" id="S3.T3.15.17.2.6.1" style="font-size:80%;">(em)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.7"><span class="ltx_text" id="S3.T3.15.17.2.7.1" style="font-size:80%;">(pre)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.17.2.8"><span class="ltx_text" id="S3.T3.15.17.2.8.1" style="font-size:80%;">(rec)</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.18.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="8" id="S3.T3.15.18.3.1"><span class="ltx_text ltx_font_italic" id="S3.T3.15.18.3.1.1" style="font-size:80%;">Baselines w/o Retrieval</span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.15.19.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="8" id="S3.T3.15.19.4.1"><span class="ltx_text ltx_font_bold" id="S3.T3.15.19.4.1.1" style="font-size:80%;">Vanilla Zero-shot Prompting</span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.15.20.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.20.5.1"><span class="ltx_text" id="S3.T3.15.20.5.1.1" style="font-size:80%;">ChatGPT*</span></th>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.2"><span class="ltx_text" id="S3.T3.15.20.5.2.1" style="font-size:80%;color:#808080;">29.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.3"><span class="ltx_text" id="S3.T3.15.20.5.3.1" style="font-size:80%;color:#808080;">74.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.4"><span class="ltx_text" id="S3.T3.15.20.5.4.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.5"><span class="ltx_text" id="S3.T3.15.20.5.5.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.6"><span class="ltx_text" id="S3.T3.15.20.5.6.1" style="font-size:80%;color:#808080;">35.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.7"><span class="ltx_text" id="S3.T3.15.20.5.7.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.20.5.8"><span class="ltx_text" id="S3.T3.15.20.5.8.1" style="font-size:80%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.1.1.1">
<span class="ltx_text" id="S3.T3.1.1.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.1.1.1.m1.1"><semantics id="S3.T3.1.1.1.m1.1a"><msub id="S3.T3.1.1.1.m1.1.1" xref="S3.T3.1.1.1.m1.1.1.cmml"><mi id="S3.T3.1.1.1.m1.1.1a" xref="S3.T3.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.1.1.1.m1.1.1.1" mathsize="80%" xref="S3.T3.1.1.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.m1.1b"><apply id="S3.T3.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.m1.1.1"><ci id="S3.T3.1.1.1.m1.1.1.1a.cmml" xref="S3.T3.1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.1.1.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.1.1.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.1.1.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.2"><span class="ltx_text" id="S3.T3.1.1.2.1" style="font-size:80%;">22.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.3"><span class="ltx_text" id="S3.T3.1.1.3.1" style="font-size:80%;">69.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4"><span class="ltx_text" id="S3.T3.1.1.4.1" style="font-size:80%;">46.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.5"><span class="ltx_text" id="S3.T3.1.1.5.1" style="font-size:80%;">45.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.6"><span class="ltx_text" id="S3.T3.1.1.6.1" style="font-size:80%;">30.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.7"><span class="ltx_text" id="S3.T3.1.1.7.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.8"><span class="ltx_text" id="S3.T3.1.1.8.1" style="font-size:80%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.2.2.1">
<span class="ltx_text" id="S3.T3.2.2.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{70b}}" class="ltx_Math" display="inline" id="S3.T3.2.2.1.m1.1"><semantics id="S3.T3.2.2.1.m1.1a"><msub id="S3.T3.2.2.1.m1.1.1" xref="S3.T3.2.2.1.m1.1.1.cmml"><mi id="S3.T3.2.2.1.m1.1.1a" xref="S3.T3.2.2.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.2.2.1.m1.1.1.1" mathsize="80%" xref="S3.T3.2.2.1.m1.1.1.1a.cmml">70b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.1.m1.1b"><apply id="S3.T3.2.2.1.m1.1.1.cmml" xref="S3.T3.2.2.1.m1.1.1"><ci id="S3.T3.2.2.1.m1.1.1.1a.cmml" xref="S3.T3.2.2.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.2.2.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.2.2.1.m1.1.1.1">70b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.1.m1.1c">{}_{\textsc{70b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.2.2.1.m1.1d">start_FLOATSUBSCRIPT 70b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.2"><span class="ltx_text" id="S3.T3.2.2.2.1" style="font-size:80%;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.3"><span class="ltx_text" id="S3.T3.2.2.3.1" style="font-size:80%;">80.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.4"><span class="ltx_text" id="S3.T3.2.2.4.1" style="font-size:80%;">57.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.5"><span class="ltx_text" id="S3.T3.2.2.5.1" style="font-size:80%;">57.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.6"><span class="ltx_text" id="S3.T3.2.2.6.1" style="font-size:80%;">39.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.7"><span class="ltx_text" id="S3.T3.2.2.7.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.8"><span class="ltx_text" id="S3.T3.2.2.8.1" style="font-size:80%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.21.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="8" id="S3.T3.15.21.6.1"><span class="ltx_text ltx_font_italic" id="S3.T3.15.21.6.1.1" style="font-size:80%;">RAG w/o Training</span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.15.22.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.22.7.1">
<span class="ltx_text ltx_font_bold" id="S3.T3.15.22.7.1.1" style="font-size:80%;">In-Context RALM</span><span class="ltx_text" id="S3.T3.15.22.7.1.2" style="font-size:80%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T3.15.22.7.1.3.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib70" title="">70</a><span class="ltx_text" id="S3.T3.15.22.7.1.4.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td" id="S3.T3.15.22.7.2"></td>
<td class="ltx_td" id="S3.T3.15.22.7.3"></td>
<td class="ltx_td" id="S3.T3.15.22.7.4"></td>
<td class="ltx_td" id="S3.T3.15.22.7.5"></td>
<td class="ltx_td" id="S3.T3.15.22.7.6"></td>
<td class="ltx_td" id="S3.T3.15.22.7.7"></td>
<td class="ltx_td" id="S3.T3.15.22.7.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.23.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.23.8.1"><span class="ltx_text" id="S3.T3.15.23.8.1.1" style="font-size:80%;">ChatGPT*</span></th>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.2"><span class="ltx_text" id="S3.T3.15.23.8.2.1" style="font-size:80%;color:#808080;">50.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.3"><span class="ltx_text" id="S3.T3.15.23.8.3.1" style="font-size:80%;color:#808080;">65.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.4"><span class="ltx_text" id="S3.T3.15.23.8.4.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.5"><span class="ltx_text" id="S3.T3.15.23.8.5.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.6"><span class="ltx_text" id="S3.T3.15.23.8.6.1" style="font-size:80%;color:#808080;">40.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.7"><span class="ltx_text" id="S3.T3.15.23.8.7.1" style="font-size:80%;color:#808080;">65.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.15.23.8.8"><span class="ltx_text" id="S3.T3.15.23.8.8.1" style="font-size:80%;color:#808080;">76.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.3.3.1">
<span class="ltx_text" id="S3.T3.3.3.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.3.3.1.m1.1"><semantics id="S3.T3.3.3.1.m1.1a"><msub id="S3.T3.3.3.1.m1.1.1" xref="S3.T3.3.3.1.m1.1.1.cmml"><mi id="S3.T3.3.3.1.m1.1.1a" xref="S3.T3.3.3.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.3.3.1.m1.1.1.1" mathsize="80%" xref="S3.T3.3.3.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.1.m1.1b"><apply id="S3.T3.3.3.1.m1.1.1.cmml" xref="S3.T3.3.3.1.m1.1.1"><ci id="S3.T3.3.3.1.m1.1.1.1a.cmml" xref="S3.T3.3.3.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.3.3.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.3.3.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.3.3.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.2"><span class="ltx_text" id="S3.T3.3.3.2.1" style="font-size:80%;">62.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.3"><span class="ltx_text" id="S3.T3.3.3.3.1" style="font-size:80%;">71.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.4"><span class="ltx_text" id="S3.T3.3.3.4.1" style="font-size:80%;">56.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.5"><span class="ltx_text" id="S3.T3.3.3.5.1" style="font-size:80%;">43.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.6"><span class="ltx_text" id="S3.T3.3.3.6.1" style="font-size:80%;">40.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.7"><span class="ltx_text" id="S3.T3.3.3.7.1" style="font-size:80%;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.3.3.8"><span class="ltx_text" id="S3.T3.3.3.8.1" style="font-size:80%;">66.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.4.4.1">
<span class="ltx_text" id="S3.T3.4.4.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{70b}}" class="ltx_Math" display="inline" id="S3.T3.4.4.1.m1.1"><semantics id="S3.T3.4.4.1.m1.1a"><msub id="S3.T3.4.4.1.m1.1.1" xref="S3.T3.4.4.1.m1.1.1.cmml"><mi id="S3.T3.4.4.1.m1.1.1a" xref="S3.T3.4.4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.4.4.1.m1.1.1.1" mathsize="80%" xref="S3.T3.4.4.1.m1.1.1.1a.cmml">70b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.1.m1.1b"><apply id="S3.T3.4.4.1.m1.1.1.cmml" xref="S3.T3.4.4.1.m1.1.1"><ci id="S3.T3.4.4.1.m1.1.1.1a.cmml" xref="S3.T3.4.4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.4.4.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.4.4.1.m1.1.1.1">70b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.1.m1.1c">{}_{\textsc{70b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.4.4.1.m1.1d">start_FLOATSUBSCRIPT 70b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.2"><span class="ltx_text" id="S3.T3.4.4.2.1" style="font-size:80%;">63.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.3"><span class="ltx_text" id="S3.T3.4.4.3.1" style="font-size:80%;">76.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.4"><span class="ltx_text" id="S3.T3.4.4.4.1" style="font-size:80%;">60.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.5"><span class="ltx_text" id="S3.T3.4.4.5.1" style="font-size:80%;">51.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.6"><span class="ltx_text" id="S3.T3.4.4.6.1" style="font-size:80%;">43.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.7"><span class="ltx_text" id="S3.T3.4.4.7.1" style="font-size:80%;">62.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.8"><span class="ltx_text" id="S3.T3.4.4.8.1" style="font-size:80%;">67.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.24.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.24.9.1"><span class="ltx_text ltx_font_bold" id="S3.T3.15.24.9.1.1" style="font-size:80%;">Few-Shot Demo. w/ Instruction</span></th>
<td class="ltx_td" id="S3.T3.15.24.9.2"></td>
<td class="ltx_td" id="S3.T3.15.24.9.3"></td>
<td class="ltx_td" id="S3.T3.15.24.9.4"></td>
<td class="ltx_td" id="S3.T3.15.24.9.5"></td>
<td class="ltx_td" id="S3.T3.15.24.9.6"></td>
<td class="ltx_td" id="S3.T3.15.24.9.7"></td>
<td class="ltx_td" id="S3.T3.15.24.9.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.5.5.1">
<span class="ltx_text" id="S3.T3.5.5.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.5.5.1.m1.1"><semantics id="S3.T3.5.5.1.m1.1a"><msub id="S3.T3.5.5.1.m1.1.1" xref="S3.T3.5.5.1.m1.1.1.cmml"><mi id="S3.T3.5.5.1.m1.1.1a" xref="S3.T3.5.5.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.5.5.1.m1.1.1.1" mathsize="80%" xref="S3.T3.5.5.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.1.m1.1b"><apply id="S3.T3.5.5.1.m1.1.1.cmml" xref="S3.T3.5.5.1.m1.1.1"><ci id="S3.T3.5.5.1.m1.1.1.1a.cmml" xref="S3.T3.5.5.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.5.5.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.5.5.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.5.5.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.2"><span class="ltx_text" id="S3.T3.5.5.2.1" style="font-size:80%;">63.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.3"><span class="ltx_text" id="S3.T3.5.5.3.1" style="font-size:80%;">74.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.4"><span class="ltx_text" id="S3.T3.5.5.4.1" style="font-size:80%;">60.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.5"><span class="ltx_text" id="S3.T3.5.5.5.1" style="font-size:80%;">45.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.6"><span class="ltx_text" id="S3.T3.5.5.6.1" style="font-size:80%;">42.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.7"><span class="ltx_text" id="S3.T3.5.5.7.1" style="font-size:80%;">55.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.5.5.8"><span class="ltx_text" id="S3.T3.5.5.8.1" style="font-size:80%;">64.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.6.6.1">
<span class="ltx_text" id="S3.T3.6.6.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{70b}}" class="ltx_Math" display="inline" id="S3.T3.6.6.1.m1.1"><semantics id="S3.T3.6.6.1.m1.1a"><msub id="S3.T3.6.6.1.m1.1.1" xref="S3.T3.6.6.1.m1.1.1.cmml"><mi id="S3.T3.6.6.1.m1.1.1a" xref="S3.T3.6.6.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.6.6.1.m1.1.1.1" mathsize="80%" xref="S3.T3.6.6.1.m1.1.1.1a.cmml">70b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.1.m1.1b"><apply id="S3.T3.6.6.1.m1.1.1.cmml" xref="S3.T3.6.6.1.m1.1.1"><ci id="S3.T3.6.6.1.m1.1.1.1a.cmml" xref="S3.T3.6.6.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.6.6.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.6.6.1.m1.1.1.1">70b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.1.m1.1c">{}_{\textsc{70b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.6.6.1.m1.1d">start_FLOATSUBSCRIPT 70b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.2"><span class="ltx_text" id="S3.T3.6.6.2.1" style="font-size:80%;">63.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.3"><span class="ltx_text" id="S3.T3.6.6.3.1" style="font-size:80%;">79.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.4"><span class="ltx_text" id="S3.T3.6.6.4.1" style="font-size:80%;">62.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.5"><span class="ltx_text" id="S3.T3.6.6.5.1" style="font-size:80%;">53.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.6"><span class="ltx_text" id="S3.T3.6.6.6.1" style="font-size:80%;">45.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.7"><span class="ltx_text" id="S3.T3.6.6.7.1" style="font-size:80%;">49.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.6.6.8"><span class="ltx_text" id="S3.T3.6.6.8.1" style="font-size:80%;">57.1</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.25.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.25.10.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T3.15.25.10.1.1" style="font-size:80%;">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.T3.15.25.10.1.2" style="font-size:80%;">-ICL</span>
</th>
<td class="ltx_td" id="S3.T3.15.25.10.2"></td>
<td class="ltx_td" id="S3.T3.15.25.10.3"></td>
<td class="ltx_td" id="S3.T3.15.25.10.4"></td>
<td class="ltx_td" id="S3.T3.15.25.10.5"></td>
<td class="ltx_td" id="S3.T3.15.25.10.6"></td>
<td class="ltx_td" id="S3.T3.15.25.10.7"></td>
<td class="ltx_td" id="S3.T3.15.25.10.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.7.7.1">
<span class="ltx_text" id="S3.T3.7.7.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.7.7.1.m1.1"><semantics id="S3.T3.7.7.1.m1.1a"><msub id="S3.T3.7.7.1.m1.1.1" xref="S3.T3.7.7.1.m1.1.1.cmml"><mi id="S3.T3.7.7.1.m1.1.1a" xref="S3.T3.7.7.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.7.7.1.m1.1.1.1" mathsize="80%" xref="S3.T3.7.7.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.1.m1.1b"><apply id="S3.T3.7.7.1.m1.1.1.cmml" xref="S3.T3.7.7.1.m1.1.1"><ci id="S3.T3.7.7.1.m1.1.1.1a.cmml" xref="S3.T3.7.7.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.7.7.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.7.7.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.7.7.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.2"><span class="ltx_text" id="S3.T3.7.7.2.1" style="font-size:80%;">64.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.3"><span class="ltx_text" id="S3.T3.7.7.3.1" style="font-size:80%;">76.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.4"><span class="ltx_text" id="S3.T3.7.7.4.1" style="font-size:80%;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.5"><span class="ltx_text" id="S3.T3.7.7.5.1" style="font-size:80%;">50.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.6"><span class="ltx_text" id="S3.T3.7.7.6.1" style="font-size:80%;">44.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.7"><span class="ltx_text ltx_font_bold" id="S3.T3.7.7.7.1" style="font-size:80%;">70.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.8"><span class="ltx_text ltx_font_bold" id="S3.T3.7.7.8.1" style="font-size:80%;">74.1</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.8.8.1">
<span class="ltx_text" id="S3.T3.8.8.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{70b}}" class="ltx_Math" display="inline" id="S3.T3.8.8.1.m1.1"><semantics id="S3.T3.8.8.1.m1.1a"><msub id="S3.T3.8.8.1.m1.1.1" xref="S3.T3.8.8.1.m1.1.1.cmml"><mi id="S3.T3.8.8.1.m1.1.1a" xref="S3.T3.8.8.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.8.8.1.m1.1.1.1" mathsize="80%" xref="S3.T3.8.8.1.m1.1.1.1a.cmml">70b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.1.m1.1b"><apply id="S3.T3.8.8.1.m1.1.1.cmml" xref="S3.T3.8.8.1.m1.1.1"><ci id="S3.T3.8.8.1.m1.1.1.1a.cmml" xref="S3.T3.8.8.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.8.8.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.8.8.1.m1.1.1.1">70b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.1.m1.1c">{}_{\textsc{70b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.8.8.1.m1.1d">start_FLOATSUBSCRIPT 70b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.2"><span class="ltx_text ltx_font_bold" id="S3.T3.8.8.2.1" style="font-size:80%;">65.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.3"><span class="ltx_text ltx_font_bold" id="S3.T3.8.8.3.1" style="font-size:80%;">81.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.4"><span class="ltx_text ltx_font_bold" id="S3.T3.8.8.4.1" style="font-size:80%;">66.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.5"><span class="ltx_text ltx_font_bold" id="S3.T3.8.8.5.1" style="font-size:80%;">57.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.6"><span class="ltx_text ltx_font_bold" id="S3.T3.8.8.6.1" style="font-size:80%;">47.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.7"><span class="ltx_text" id="S3.T3.8.8.7.1" style="font-size:80%;">69.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.8"><span class="ltx_text" id="S3.T3.8.8.8.1" style="font-size:80%;">71.2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.26.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="8" id="S3.T3.15.26.11.1"><span class="ltx_text ltx_font_italic" id="S3.T3.15.26.11.1.1" style="font-size:80%;">RAG w/ Training</span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.15.27.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.27.12.1"><span class="ltx_text ltx_font_bold" id="S3.T3.15.27.12.1.1" style="font-size:80%;">Vanilla Supervised Fine-tuning</span></th>
<td class="ltx_td" id="S3.T3.15.27.12.2"></td>
<td class="ltx_td" id="S3.T3.15.27.12.3"></td>
<td class="ltx_td" id="S3.T3.15.27.12.4"></td>
<td class="ltx_td" id="S3.T3.15.27.12.5"></td>
<td class="ltx_td" id="S3.T3.15.27.12.6"></td>
<td class="ltx_td" id="S3.T3.15.27.12.7"></td>
<td class="ltx_td" id="S3.T3.15.27.12.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.9.9.1">
<span class="ltx_text" id="S3.T3.9.9.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.9.9.1.m1.1"><semantics id="S3.T3.9.9.1.m1.1a"><msub id="S3.T3.9.9.1.m1.1.1" xref="S3.T3.9.9.1.m1.1.1.cmml"><mi id="S3.T3.9.9.1.m1.1.1a" xref="S3.T3.9.9.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.9.9.1.m1.1.1.1" mathsize="80%" xref="S3.T3.9.9.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.1.m1.1b"><apply id="S3.T3.9.9.1.m1.1.1.cmml" xref="S3.T3.9.9.1.m1.1.1"><ci id="S3.T3.9.9.1.m1.1.1.1a.cmml" xref="S3.T3.9.9.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.9.9.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.9.9.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.9.9.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.2"><span class="ltx_text" id="S3.T3.9.9.2.1" style="font-size:80%;">61.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.3"><span class="ltx_text" id="S3.T3.9.9.3.1" style="font-size:80%;">73.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.4"><span class="ltx_text" id="S3.T3.9.9.4.1" style="font-size:80%;">56.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.5"><span class="ltx_text" id="S3.T3.9.9.5.1" style="font-size:80%;">56.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.6"><span class="ltx_text" id="S3.T3.9.9.6.1" style="font-size:80%;">43.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.7"><span class="ltx_text" id="S3.T3.9.9.7.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.9.9.8"><span class="ltx_text" id="S3.T3.9.9.8.1" style="font-size:80%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.28.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.28.13.1">
<span class="ltx_text ltx_font_bold" id="S3.T3.15.28.13.1.1" style="font-size:80%;">Self-RAG</span><span class="ltx_text" id="S3.T3.15.28.13.1.2" style="font-size:80%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T3.15.28.13.1.3.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a><span class="ltx_text" id="S3.T3.15.28.13.1.4.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td" id="S3.T3.15.28.13.2"></td>
<td class="ltx_td" id="S3.T3.15.28.13.3"></td>
<td class="ltx_td" id="S3.T3.15.28.13.4"></td>
<td class="ltx_td" id="S3.T3.15.28.13.5"></td>
<td class="ltx_td" id="S3.T3.15.28.13.6"></td>
<td class="ltx_td" id="S3.T3.15.28.13.7"></td>
<td class="ltx_td" id="S3.T3.15.28.13.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.10.10.1">
<span class="ltx_text" id="S3.T3.10.10.1.1" style="font-size:80%;">Llama-2</span><math alttext="{}_{\textsc{7b}}" class="ltx_Math" display="inline" id="S3.T3.10.10.1.m1.1"><semantics id="S3.T3.10.10.1.m1.1a"><msub id="S3.T3.10.10.1.m1.1.1" xref="S3.T3.10.10.1.m1.1.1.cmml"><mi id="S3.T3.10.10.1.m1.1.1a" xref="S3.T3.10.10.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.10.10.1.m1.1.1.1" mathsize="80%" xref="S3.T3.10.10.1.m1.1.1.1a.cmml">7b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.1.m1.1b"><apply id="S3.T3.10.10.1.m1.1.1.cmml" xref="S3.T3.10.10.1.m1.1.1"><ci id="S3.T3.10.10.1.m1.1.1.1a.cmml" xref="S3.T3.10.10.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.10.10.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.10.10.1.m1.1.1.1">7b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.1.m1.1c">{}_{\textsc{7b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.10.10.1.m1.1d">start_FLOATSUBSCRIPT 7b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.2"><span class="ltx_text" id="S3.T3.10.10.2.1" style="font-size:80%;">55.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.3"><span class="ltx_text" id="S3.T3.10.10.3.1" style="font-size:80%;">68.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.4"><span class="ltx_text" id="S3.T3.10.10.4.1" style="font-size:80%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.5"><span class="ltx_text" id="S3.T3.10.10.5.1" style="font-size:80%;">35.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.6"><span class="ltx_text" id="S3.T3.10.10.6.1" style="font-size:80%;">30.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.7"><span class="ltx_text" id="S3.T3.10.10.7.1" style="font-size:80%;">66.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.10.10.8"><span class="ltx_text" id="S3.T3.10.10.8.1" style="font-size:80%;">67.8</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.11.11.1">
<span class="ltx_text" id="S3.T3.11.11.1.1" style="font-size:80%;">Llama-2</span><math alttext="{}_{\textsc{13b}}" class="ltx_Math" display="inline" id="S3.T3.11.11.1.m1.1"><semantics id="S3.T3.11.11.1.m1.1a"><msub id="S3.T3.11.11.1.m1.1.1" xref="S3.T3.11.11.1.m1.1.1.cmml"><mi id="S3.T3.11.11.1.m1.1.1a" xref="S3.T3.11.11.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.11.11.1.m1.1.1.1" mathsize="80%" xref="S3.T3.11.11.1.m1.1.1.1a.cmml">13b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.1.m1.1b"><apply id="S3.T3.11.11.1.m1.1.1.cmml" xref="S3.T3.11.11.1.m1.1.1"><ci id="S3.T3.11.11.1.m1.1.1.1a.cmml" xref="S3.T3.11.11.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.11.11.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.11.11.1.m1.1.1.1">13b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.1.m1.1c">{}_{\textsc{13b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.11.11.1.m1.1d">start_FLOATSUBSCRIPT 13b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.2"><span class="ltx_text" id="S3.T3.11.11.2.1" style="font-size:80%;">56.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.3"><span class="ltx_text" id="S3.T3.11.11.3.1" style="font-size:80%;">70.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.4"><span class="ltx_text" id="S3.T3.11.11.4.1" style="font-size:80%;">46.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.5"><span class="ltx_text" id="S3.T3.11.11.5.1" style="font-size:80%;">36.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.6"><span class="ltx_text" id="S3.T3.11.11.6.1" style="font-size:80%;">31.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.7"><span class="ltx_text ltx_font_bold" id="S3.T3.11.11.7.1" style="font-size:80%;">70.3</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.11.11.8"><span class="ltx_text ltx_font_bold" id="S3.T3.11.11.8.1" style="font-size:80%;">71.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.12.12.1">
<span class="ltx_text" id="S3.T3.12.12.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.12.12.1.m1.1"><semantics id="S3.T3.12.12.1.m1.1a"><msub id="S3.T3.12.12.1.m1.1.1" xref="S3.T3.12.12.1.m1.1.1.cmml"><mi id="S3.T3.12.12.1.m1.1.1a" xref="S3.T3.12.12.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.12.12.1.m1.1.1.1" mathsize="80%" xref="S3.T3.12.12.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.12.12.1.m1.1b"><apply id="S3.T3.12.12.1.m1.1.1.cmml" xref="S3.T3.12.12.1.m1.1.1"><ci id="S3.T3.12.12.1.m1.1.1.1a.cmml" xref="S3.T3.12.12.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.12.12.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.12.12.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.12.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.12.12.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.2"><span class="ltx_text" id="S3.T3.12.12.2.1" style="font-size:80%;">55.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.3"><span class="ltx_text" id="S3.T3.12.12.3.1" style="font-size:80%;">71.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.4"><span class="ltx_text" id="S3.T3.12.12.4.1" style="font-size:80%;">42.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.5"><span class="ltx_text" id="S3.T3.12.12.5.1" style="font-size:80%;">32.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.6"><span class="ltx_text" id="S3.T3.12.12.6.1" style="font-size:80%;">36.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.7"><span class="ltx_text" id="S3.T3.12.12.7.1" style="font-size:80%;">69.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.12.12.8"><span class="ltx_text" id="S3.T3.12.12.8.1" style="font-size:80%;">69.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.29.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.29.14.1">
<span class="ltx_text ltx_font_bold" id="S3.T3.15.29.14.1.1" style="font-size:80%;">RetRobust</span><span class="ltx_text" id="S3.T3.15.29.14.1.2" style="font-size:80%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.T3.15.29.14.1.3.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib105" title="">105</a><span class="ltx_text" id="S3.T3.15.29.14.1.4.2" style="font-size:80%;">]</span></cite>
</th>
<td class="ltx_td" id="S3.T3.15.29.14.2"></td>
<td class="ltx_td" id="S3.T3.15.29.14.3"></td>
<td class="ltx_td" id="S3.T3.15.29.14.4"></td>
<td class="ltx_td" id="S3.T3.15.29.14.5"></td>
<td class="ltx_td" id="S3.T3.15.29.14.6"></td>
<td class="ltx_td" id="S3.T3.15.29.14.7"></td>
<td class="ltx_td" id="S3.T3.15.29.14.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.13.13.1">
<span class="ltx_text" id="S3.T3.13.13.1.1" style="font-size:80%;">Llama-2</span><math alttext="{}_{\textsc{13b}}" class="ltx_Math" display="inline" id="S3.T3.13.13.1.m1.1"><semantics id="S3.T3.13.13.1.m1.1a"><msub id="S3.T3.13.13.1.m1.1.1" xref="S3.T3.13.13.1.m1.1.1.cmml"><mi id="S3.T3.13.13.1.m1.1.1a" xref="S3.T3.13.13.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.13.13.1.m1.1.1.1" mathsize="80%" xref="S3.T3.13.13.1.m1.1.1.1a.cmml">13b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.13.13.1.m1.1b"><apply id="S3.T3.13.13.1.m1.1.1.cmml" xref="S3.T3.13.13.1.m1.1.1"><ci id="S3.T3.13.13.1.m1.1.1.1a.cmml" xref="S3.T3.13.13.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.13.13.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.13.13.1.m1.1.1.1">13b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.13.1.m1.1c">{}_{\textsc{13b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.13.13.1.m1.1d">start_FLOATSUBSCRIPT 13b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.2"><span class="ltx_text" id="S3.T3.13.13.2.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.3"><span class="ltx_text" id="S3.T3.13.13.3.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.4"><span class="ltx_text" id="S3.T3.13.13.4.1" style="font-size:80%;">39.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.5"><span class="ltx_text" id="S3.T3.13.13.5.1" style="font-size:80%;">51.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.6"><span class="ltx_text" id="S3.T3.13.13.6.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.7"><span class="ltx_text" id="S3.T3.13.13.7.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.13.13.8"><span class="ltx_text" id="S3.T3.13.13.8.1" style="font-size:80%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.14.14.1">
<span class="ltx_text" id="S3.T3.14.14.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.14.14.1.m1.1"><semantics id="S3.T3.14.14.1.m1.1a"><msub id="S3.T3.14.14.1.m1.1.1" xref="S3.T3.14.14.1.m1.1.1.cmml"><mi id="S3.T3.14.14.1.m1.1.1a" xref="S3.T3.14.14.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.14.14.1.m1.1.1.1" mathsize="80%" xref="S3.T3.14.14.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.14.14.1.m1.1b"><apply id="S3.T3.14.14.1.m1.1.1.cmml" xref="S3.T3.14.14.1.m1.1.1"><ci id="S3.T3.14.14.1.m1.1.1.1a.cmml" xref="S3.T3.14.14.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.14.14.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.14.14.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.14.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.14.14.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.2"><span class="ltx_text" id="S3.T3.14.14.2.1" style="font-size:80%;">56.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.3"><span class="ltx_text" id="S3.T3.14.14.3.1" style="font-size:80%;">71.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.4"><span class="ltx_text" id="S3.T3.14.14.4.1" style="font-size:80%;">54.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.5"><span class="ltx_text" id="S3.T3.14.14.5.1" style="font-size:80%;">54.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.6"><span class="ltx_text" id="S3.T3.14.14.6.1" style="font-size:80%;">40.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.7"><span class="ltx_text" id="S3.T3.14.14.7.1" style="font-size:80%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.14.14.8"><span class="ltx_text" id="S3.T3.14.14.8.1" style="font-size:80%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.30.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T3.15.30.15.1">
<span class="ltx_text ltx_font_smallcaps" id="S3.T3.15.30.15.1.1" style="font-size:80%;">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.T3.15.30.15.1.2" style="font-size:80%;">-FT</span>
</th>
<td class="ltx_td" id="S3.T3.15.30.15.2"></td>
<td class="ltx_td" id="S3.T3.15.30.15.3"></td>
<td class="ltx_td" id="S3.T3.15.30.15.4"></td>
<td class="ltx_td" id="S3.T3.15.30.15.5"></td>
<td class="ltx_td" id="S3.T3.15.30.15.6"></td>
<td class="ltx_td" id="S3.T3.15.30.15.7"></td>
<td class="ltx_td" id="S3.T3.15.30.15.8"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T3.15.15.1">
<span class="ltx_text" id="S3.T3.15.15.1.1" style="font-size:80%;">Llama-3-Instruct</span><math alttext="{}_{\textsc{8b}}" class="ltx_Math" display="inline" id="S3.T3.15.15.1.m1.1"><semantics id="S3.T3.15.15.1.m1.1a"><msub id="S3.T3.15.15.1.m1.1.1" xref="S3.T3.15.15.1.m1.1.1.cmml"><mi id="S3.T3.15.15.1.m1.1.1a" xref="S3.T3.15.15.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.T3.15.15.1.m1.1.1.1" mathsize="80%" xref="S3.T3.15.15.1.m1.1.1.1a.cmml">8b</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.15.15.1.m1.1b"><apply id="S3.T3.15.15.1.m1.1.1.cmml" xref="S3.T3.15.15.1.m1.1.1"><ci id="S3.T3.15.15.1.m1.1.1.1a.cmml" xref="S3.T3.15.15.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.T3.15.15.1.m1.1.1.1.cmml" mathsize="56%" xref="S3.T3.15.15.1.m1.1.1.1">8b</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.15.15.1.m1.1c">{}_{\textsc{8b}}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.15.15.1.m1.1d">start_FLOATSUBSCRIPT 8b end_FLOATSUBSCRIPT</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.2"><span class="ltx_text ltx_font_bold" id="S3.T3.15.15.2.1" style="font-size:80%;">66.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.3"><span class="ltx_text ltx_font_bold" id="S3.T3.15.15.3.1" style="font-size:80%;">78.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.4"><span class="ltx_text ltx_font_bold" id="S3.T3.15.15.4.1" style="font-size:80%;">65.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.5"><span class="ltx_text ltx_font_bold" id="S3.T3.15.15.5.1" style="font-size:80%;">57.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.6"><span class="ltx_text ltx_font_bold" id="S3.T3.15.15.6.1" style="font-size:80%;">47.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.7"><span class="ltx_text" id="S3.T3.15.15.7.1" style="font-size:80%;">65.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.15.15.8"><span class="ltx_text" id="S3.T3.15.15.8.1" style="font-size:80%;">70.5</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">RAG without training.</span>
The second block shows the comparison among training-free RAG methods.
In-context RALM and few-shot demonstration with instruction methods generally achieve higher performance than the non-retrieval baseline, highlighting the importance of retrieval for knowledge-intensive tasks.
Encouragingly, our <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.2">InstructRAG</span>-ICL consistently outperforms all training-free baselines across various metrics, confirming the effectiveness of self-synthesized denoising rationales.
Moreover, the boost from 8B to 70B model also demonstrates that <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.3">InstructRAG</span>-ICL scales effectively with larger backbone models, validating the generalizability of our method.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">RAG with training.</span> As present in the bottom block of Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.T3" title="Table 3 ‣ 3.2 Main Result ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3</span></a>, our <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p4.1.2">InstructRAG</span>-FT not only surpasses all non-retrieval and training-free baselines across all five benchmarks, but also significantly outperforms trainable RAG baselines on almost every metric.
The only exception is in the ASQA task, where our method slightly underperforms Self-RAG in terms of citation (<span class="ltx_text ltx_font_slanted" id="S3.SS2.p4.1.3">i.e.</span>, <em class="ltx_emph ltx_font_italic" id="S3.SS2.p4.1.4">pre</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS2.p4.1.5">rec</em>).
This is because our work primarily focuses on explicit denoising for RAG to improve the correctness of generations, which is measured by <em class="ltx_emph ltx_font_italic" id="S3.SS2.p4.1.6">em</em>.
Despite not being explicitly optimized for citation metrics, our method still achieves competitive citation performance, significantly enhancing both generation accuracy and trustworthiness.
Note that RetRobust achieves competitive performance on 2WikiMultiHopQA, which involves multi-hop reasoning.
We attribute this to the additional training supervision provided by GPT-3, which enables the model to explicitly generate intermediate sub-queries and sub-answers.
Another interesting finding is that Self-RAG consistently exhibits inferior performance compared to vanilla SFT, and even underperforms the training-free in-context RALM baseline across all benchmarks.
We speculate the reason might be that these RAG tasks favor more domain-specific knowledge than general knowledge.
However, it is challenging for Self-RAG to directly leverage in-domain features from existing training data as it requires GPT-4 to generate reflection tokens on these benchmarks, which is not available in our problem (§ <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S2.SS1" title="2.1 Problem Setting ‣ 2 Our Method: InstructRAG ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">2.1</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Ablation Study</h3>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T4.28.1.1" style="font-size:113%;">Table 4</span>: </span><span class="ltx_text" id="S3.T4.29.2" style="font-size:113%;">Ablation study on the impact of ground-truth answer, retrieved documents, and model size on rationale generation, and the use of demonstrations during model inference. The results of our default setting in <span class="ltx_text ltx_font_smallcaps" id="S3.T4.29.2.1">InstructRAG</span> are <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.29.2.2">underlined</span>.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T4.20">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T4.20.21.1">
<td class="ltx_td ltx_border_tt" id="S3.T4.20.21.1.1"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="2" id="S3.T4.20.21.1.2"><span class="ltx_text" id="S3.T4.20.21.1.2.1" style="font-size:80%;">Trainable RAG Setting</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="2" id="S3.T4.20.21.1.3"><span class="ltx_text" id="S3.T4.20.21.1.3.1" style="font-size:80%;">Training-free RAG Setting</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.22.2">
<td class="ltx_td ltx_align_left" id="S3.T4.20.22.2.1"><span class="ltx_text" id="S3.T4.20.22.2.1.1" style="font-size:80%;">Method</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.22.2.2"><span class="ltx_text" id="S3.T4.20.22.2.2.1" style="font-size:80%;">PopQA</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.22.2.3"><span class="ltx_text" id="S3.T4.20.22.2.3.1" style="font-size:80%;">ASQA</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.22.2.4"><span class="ltx_text" id="S3.T4.20.22.2.4.1" style="font-size:80%;">PopQA</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.22.2.5"><span class="ltx_text" id="S3.T4.20.22.2.5.1" style="font-size:80%;">ASQA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.23.3">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S3.T4.20.23.3.1"><span class="ltx_text ltx_font_italic" id="S3.T4.20.23.3.1.1" style="font-size:80%;">Rationale Generation Design</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.24.4">
<td class="ltx_td ltx_align_left" id="S3.T4.20.24.4.1"><span class="ltx_text" id="S3.T4.20.24.4.1.1" style="font-size:80%;">with both</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.24.4.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.24.4.2.1" style="font-size:80%;">66.2</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.24.4.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.24.4.3.1" style="font-size:80%;">47.6</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.24.4.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.24.4.4.1" style="font-size:80%;">64.2</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.24.4.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.24.4.5.1" style="font-size:80%;">44.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.4.4">
<td class="ltx_td ltx_align_left" id="S3.T4.4.4.5"><span class="ltx_text" id="S3.T4.4.4.5.1" style="font-size:80%;">w/o ground-truth answer</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.1.1.1">
<span class="ltx_text" id="S3.T4.1.1.1.2" style="font-size:80%;">65.2 </span><span class="ltx_text" id="S3.T4.1.1.1.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 1.5\%" class="ltx_Math" display="inline" id="S3.T4.1.1.1.1.m1.1"><semantics id="S3.T4.1.1.1.1.m1.1a"><mrow id="S3.T4.1.1.1.1.m1.1.1" xref="S3.T4.1.1.1.1.m1.1.1.cmml"><mi id="S3.T4.1.1.1.1.m1.1.1.2" xref="S3.T4.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.1.1.1.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.1.1.1.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.1.1.1.1.m1.1.1.3" xref="S3.T4.1.1.1.1.m1.1.1.3.cmml"><mn id="S3.T4.1.1.1.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.1.1.1.1.m1.1.1.3.2.cmml">1.5</mn><mo id="S3.T4.1.1.1.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.1.1.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.1.m1.1b"><apply id="S3.T4.1.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.1.m1.1.1"><ci id="S3.T4.1.1.1.1.m1.1.1.1.cmml" xref="S3.T4.1.1.1.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.1.1.1.1.m1.1.1.2.cmml" xref="S3.T4.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.1.1.1.1.m1.1.1.3.cmml" xref="S3.T4.1.1.1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T4.1.1.1.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.1.1.1.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.1.1.1.1.m1.1.1.3.2">1.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.1.m1.1c">\downarrow 1.5\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.1.1.1.1.m1.1d">↓ 1.5 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.2.2.2">
<span class="ltx_text" id="S3.T4.2.2.2.2" style="font-size:80%;">46.4 </span><span class="ltx_text" id="S3.T4.2.2.2.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 2.5\%" class="ltx_Math" display="inline" id="S3.T4.2.2.2.1.m1.1"><semantics id="S3.T4.2.2.2.1.m1.1a"><mrow id="S3.T4.2.2.2.1.m1.1.1" xref="S3.T4.2.2.2.1.m1.1.1.cmml"><mi id="S3.T4.2.2.2.1.m1.1.1.2" xref="S3.T4.2.2.2.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.2.2.2.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.2.2.2.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.2.2.2.1.m1.1.1.3" xref="S3.T4.2.2.2.1.m1.1.1.3.cmml"><mn id="S3.T4.2.2.2.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.2.2.2.1.m1.1.1.3.2.cmml">2.5</mn><mo id="S3.T4.2.2.2.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.2.2.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.1.m1.1b"><apply id="S3.T4.2.2.2.1.m1.1.1.cmml" xref="S3.T4.2.2.2.1.m1.1.1"><ci id="S3.T4.2.2.2.1.m1.1.1.1.cmml" xref="S3.T4.2.2.2.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.2.2.2.1.m1.1.1.2.cmml" xref="S3.T4.2.2.2.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.2.2.2.1.m1.1.1.3.cmml" xref="S3.T4.2.2.2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.2.2.2.1.m1.1.1.3.1.cmml" xref="S3.T4.2.2.2.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.2.2.2.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.2.2.2.1.m1.1.1.3.2">2.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.1.m1.1c">\downarrow 2.5\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.2.2.2.1.m1.1d">↓ 2.5 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.3.3.3">
<span class="ltx_text" id="S3.T4.3.3.3.2" style="font-size:80%;">64.0 </span><span class="ltx_text" id="S3.T4.3.3.3.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 0.3\%" class="ltx_Math" display="inline" id="S3.T4.3.3.3.1.m1.1"><semantics id="S3.T4.3.3.3.1.m1.1a"><mrow id="S3.T4.3.3.3.1.m1.1.1" xref="S3.T4.3.3.3.1.m1.1.1.cmml"><mi id="S3.T4.3.3.3.1.m1.1.1.2" xref="S3.T4.3.3.3.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.3.3.3.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.3.3.3.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.3.3.3.1.m1.1.1.3" xref="S3.T4.3.3.3.1.m1.1.1.3.cmml"><mn id="S3.T4.3.3.3.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.3.3.3.1.m1.1.1.3.2.cmml">0.3</mn><mo id="S3.T4.3.3.3.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.3.3.3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.3.3.3.1.m1.1b"><apply id="S3.T4.3.3.3.1.m1.1.1.cmml" xref="S3.T4.3.3.3.1.m1.1.1"><ci id="S3.T4.3.3.3.1.m1.1.1.1.cmml" xref="S3.T4.3.3.3.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.3.3.3.1.m1.1.1.2.cmml" xref="S3.T4.3.3.3.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.3.3.3.1.m1.1.1.3.cmml" xref="S3.T4.3.3.3.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.3.3.3.1.m1.1.1.3.1.cmml" xref="S3.T4.3.3.3.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.3.3.3.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.3.3.3.1.m1.1.1.3.2">0.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.3.3.3.1.m1.1c">\downarrow 0.3\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.3.3.3.1.m1.1d">↓ 0.3 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.4.4.4">
<span class="ltx_text" id="S3.T4.4.4.4.2" style="font-size:80%;">44.5 </span><span class="ltx_text" id="S3.T4.4.4.4.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 0.4\%" class="ltx_Math" display="inline" id="S3.T4.4.4.4.1.m1.1"><semantics id="S3.T4.4.4.4.1.m1.1a"><mrow id="S3.T4.4.4.4.1.m1.1.1" xref="S3.T4.4.4.4.1.m1.1.1.cmml"><mi id="S3.T4.4.4.4.1.m1.1.1.2" xref="S3.T4.4.4.4.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.4.4.4.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.4.4.4.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.4.4.4.1.m1.1.1.3" xref="S3.T4.4.4.4.1.m1.1.1.3.cmml"><mn id="S3.T4.4.4.4.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.4.4.4.1.m1.1.1.3.2.cmml">0.4</mn><mo id="S3.T4.4.4.4.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.4.4.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.4.4.4.1.m1.1b"><apply id="S3.T4.4.4.4.1.m1.1.1.cmml" xref="S3.T4.4.4.4.1.m1.1.1"><ci id="S3.T4.4.4.4.1.m1.1.1.1.cmml" xref="S3.T4.4.4.4.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.4.4.4.1.m1.1.1.2.cmml" xref="S3.T4.4.4.4.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.4.4.4.1.m1.1.1.3.cmml" xref="S3.T4.4.4.4.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.4.4.4.1.m1.1.1.3.1.cmml" xref="S3.T4.4.4.4.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.4.4.4.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.4.4.4.1.m1.1.1.3.2">0.4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.4.4.1.m1.1c">\downarrow 0.4\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.4.4.4.1.m1.1d">↓ 0.4 %</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T4.8.8">
<td class="ltx_td ltx_align_left" id="S3.T4.8.8.5"><span class="ltx_text" id="S3.T4.8.8.5.1" style="font-size:80%;">w/o retrieved documents</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.5.5.1">
<span class="ltx_text" id="S3.T4.5.5.1.2" style="font-size:80%;">64.5 </span><span class="ltx_text" id="S3.T4.5.5.1.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 2.6\%" class="ltx_Math" display="inline" id="S3.T4.5.5.1.1.m1.1"><semantics id="S3.T4.5.5.1.1.m1.1a"><mrow id="S3.T4.5.5.1.1.m1.1.1" xref="S3.T4.5.5.1.1.m1.1.1.cmml"><mi id="S3.T4.5.5.1.1.m1.1.1.2" xref="S3.T4.5.5.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.5.5.1.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.5.5.1.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.5.5.1.1.m1.1.1.3" xref="S3.T4.5.5.1.1.m1.1.1.3.cmml"><mn id="S3.T4.5.5.1.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.5.5.1.1.m1.1.1.3.2.cmml">2.6</mn><mo id="S3.T4.5.5.1.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.5.5.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.5.5.1.1.m1.1b"><apply id="S3.T4.5.5.1.1.m1.1.1.cmml" xref="S3.T4.5.5.1.1.m1.1.1"><ci id="S3.T4.5.5.1.1.m1.1.1.1.cmml" xref="S3.T4.5.5.1.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.5.5.1.1.m1.1.1.2.cmml" xref="S3.T4.5.5.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.5.5.1.1.m1.1.1.3.cmml" xref="S3.T4.5.5.1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.5.5.1.1.m1.1.1.3.1.cmml" xref="S3.T4.5.5.1.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.5.5.1.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.5.5.1.1.m1.1.1.3.2">2.6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.5.1.1.m1.1c">\downarrow 2.6\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.5.5.1.1.m1.1d">↓ 2.6 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.6.6.2">
<span class="ltx_text" id="S3.T4.6.6.2.2" style="font-size:80%;">45.2 </span><span class="ltx_text" id="S3.T4.6.6.2.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 5.0\%" class="ltx_Math" display="inline" id="S3.T4.6.6.2.1.m1.1"><semantics id="S3.T4.6.6.2.1.m1.1a"><mrow id="S3.T4.6.6.2.1.m1.1.1" xref="S3.T4.6.6.2.1.m1.1.1.cmml"><mi id="S3.T4.6.6.2.1.m1.1.1.2" xref="S3.T4.6.6.2.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.6.6.2.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.6.6.2.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.6.6.2.1.m1.1.1.3" xref="S3.T4.6.6.2.1.m1.1.1.3.cmml"><mn id="S3.T4.6.6.2.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.6.6.2.1.m1.1.1.3.2.cmml">5.0</mn><mo id="S3.T4.6.6.2.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.6.6.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.6.6.2.1.m1.1b"><apply id="S3.T4.6.6.2.1.m1.1.1.cmml" xref="S3.T4.6.6.2.1.m1.1.1"><ci id="S3.T4.6.6.2.1.m1.1.1.1.cmml" xref="S3.T4.6.6.2.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.6.6.2.1.m1.1.1.2.cmml" xref="S3.T4.6.6.2.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.6.6.2.1.m1.1.1.3.cmml" xref="S3.T4.6.6.2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.6.6.2.1.m1.1.1.3.1.cmml" xref="S3.T4.6.6.2.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.6.6.2.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.6.6.2.1.m1.1.1.3.2">5.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.6.2.1.m1.1c">\downarrow 5.0\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.6.6.2.1.m1.1d">↓ 5.0 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.7.7.3">
<span class="ltx_text" id="S3.T4.7.7.3.2" style="font-size:80%;">64.1 </span><span class="ltx_text" id="S3.T4.7.7.3.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 0.2\%" class="ltx_Math" display="inline" id="S3.T4.7.7.3.1.m1.1"><semantics id="S3.T4.7.7.3.1.m1.1a"><mrow id="S3.T4.7.7.3.1.m1.1.1" xref="S3.T4.7.7.3.1.m1.1.1.cmml"><mi id="S3.T4.7.7.3.1.m1.1.1.2" xref="S3.T4.7.7.3.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.7.7.3.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.7.7.3.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.7.7.3.1.m1.1.1.3" xref="S3.T4.7.7.3.1.m1.1.1.3.cmml"><mn id="S3.T4.7.7.3.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.7.7.3.1.m1.1.1.3.2.cmml">0.2</mn><mo id="S3.T4.7.7.3.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.7.7.3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.7.7.3.1.m1.1b"><apply id="S3.T4.7.7.3.1.m1.1.1.cmml" xref="S3.T4.7.7.3.1.m1.1.1"><ci id="S3.T4.7.7.3.1.m1.1.1.1.cmml" xref="S3.T4.7.7.3.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.7.7.3.1.m1.1.1.2.cmml" xref="S3.T4.7.7.3.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.7.7.3.1.m1.1.1.3.cmml" xref="S3.T4.7.7.3.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.7.7.3.1.m1.1.1.3.1.cmml" xref="S3.T4.7.7.3.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.7.7.3.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.7.7.3.1.m1.1.1.3.2">0.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.7.7.3.1.m1.1c">\downarrow 0.2\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.7.7.3.1.m1.1d">↓ 0.2 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.8.8.4">
<span class="ltx_text" id="S3.T4.8.8.4.2" style="font-size:80%;">44.3 </span><span class="ltx_text" id="S3.T4.8.8.4.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 0.9\%" class="ltx_Math" display="inline" id="S3.T4.8.8.4.1.m1.1"><semantics id="S3.T4.8.8.4.1.m1.1a"><mrow id="S3.T4.8.8.4.1.m1.1.1" xref="S3.T4.8.8.4.1.m1.1.1.cmml"><mi id="S3.T4.8.8.4.1.m1.1.1.2" xref="S3.T4.8.8.4.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.8.8.4.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.8.8.4.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.8.8.4.1.m1.1.1.3" xref="S3.T4.8.8.4.1.m1.1.1.3.cmml"><mn id="S3.T4.8.8.4.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.8.8.4.1.m1.1.1.3.2.cmml">0.9</mn><mo id="S3.T4.8.8.4.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.8.8.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.8.8.4.1.m1.1b"><apply id="S3.T4.8.8.4.1.m1.1.1.cmml" xref="S3.T4.8.8.4.1.m1.1.1"><ci id="S3.T4.8.8.4.1.m1.1.1.1.cmml" xref="S3.T4.8.8.4.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.8.8.4.1.m1.1.1.2.cmml" xref="S3.T4.8.8.4.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.8.8.4.1.m1.1.1.3.cmml" xref="S3.T4.8.8.4.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.8.8.4.1.m1.1.1.3.1.cmml" xref="S3.T4.8.8.4.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.8.8.4.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.8.8.4.1.m1.1.1.3.2">0.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.8.8.4.1.m1.1c">\downarrow 0.9\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.8.8.4.1.m1.1d">↓ 0.9 %</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.25.5">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S3.T4.20.25.5.1"><span class="ltx_text ltx_font_italic" id="S3.T4.20.25.5.1.1" style="font-size:80%;">Model Size of Rationale Generator</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.12.12">
<td class="ltx_td ltx_align_left" id="S3.T4.12.12.5"><span class="ltx_text" id="S3.T4.12.12.5.1" style="font-size:80%;">rationale template (no generator)</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.9.9.1">
<span class="ltx_text" id="S3.T4.9.9.1.2" style="font-size:80%;">59.6 </span><span class="ltx_text" id="S3.T4.9.9.1.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 10.0\%" class="ltx_Math" display="inline" id="S3.T4.9.9.1.1.m1.1"><semantics id="S3.T4.9.9.1.1.m1.1a"><mrow id="S3.T4.9.9.1.1.m1.1.1" xref="S3.T4.9.9.1.1.m1.1.1.cmml"><mi id="S3.T4.9.9.1.1.m1.1.1.2" xref="S3.T4.9.9.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.9.9.1.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.9.9.1.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.9.9.1.1.m1.1.1.3" xref="S3.T4.9.9.1.1.m1.1.1.3.cmml"><mn id="S3.T4.9.9.1.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.9.9.1.1.m1.1.1.3.2.cmml">10.0</mn><mo id="S3.T4.9.9.1.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.9.9.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.9.9.1.1.m1.1b"><apply id="S3.T4.9.9.1.1.m1.1.1.cmml" xref="S3.T4.9.9.1.1.m1.1.1"><ci id="S3.T4.9.9.1.1.m1.1.1.1.cmml" xref="S3.T4.9.9.1.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.9.9.1.1.m1.1.1.2.cmml" xref="S3.T4.9.9.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.9.9.1.1.m1.1.1.3.cmml" xref="S3.T4.9.9.1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.9.9.1.1.m1.1.1.3.1.cmml" xref="S3.T4.9.9.1.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.9.9.1.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.9.9.1.1.m1.1.1.3.2">10.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.9.9.1.1.m1.1c">\downarrow 10.0\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.9.9.1.1.m1.1d">↓ 10.0 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.10.10.2">
<span class="ltx_text" id="S3.T4.10.10.2.2" style="font-size:80%;">46.3 </span><span class="ltx_text" id="S3.T4.10.10.2.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 2.7\%" class="ltx_Math" display="inline" id="S3.T4.10.10.2.1.m1.1"><semantics id="S3.T4.10.10.2.1.m1.1a"><mrow id="S3.T4.10.10.2.1.m1.1.1" xref="S3.T4.10.10.2.1.m1.1.1.cmml"><mi id="S3.T4.10.10.2.1.m1.1.1.2" xref="S3.T4.10.10.2.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.10.10.2.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.10.10.2.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.10.10.2.1.m1.1.1.3" xref="S3.T4.10.10.2.1.m1.1.1.3.cmml"><mn id="S3.T4.10.10.2.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.10.10.2.1.m1.1.1.3.2.cmml">2.7</mn><mo id="S3.T4.10.10.2.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.10.10.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.10.10.2.1.m1.1b"><apply id="S3.T4.10.10.2.1.m1.1.1.cmml" xref="S3.T4.10.10.2.1.m1.1.1"><ci id="S3.T4.10.10.2.1.m1.1.1.1.cmml" xref="S3.T4.10.10.2.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.10.10.2.1.m1.1.1.2.cmml" xref="S3.T4.10.10.2.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.10.10.2.1.m1.1.1.3.cmml" xref="S3.T4.10.10.2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.10.10.2.1.m1.1.1.3.1.cmml" xref="S3.T4.10.10.2.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.10.10.2.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.10.10.2.1.m1.1.1.3.2">2.7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.10.10.2.1.m1.1c">\downarrow 2.7\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.10.10.2.1.m1.1d">↓ 2.7 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.11.11.3">
<span class="ltx_text" id="S3.T4.11.11.3.2" style="font-size:80%;">60.0 </span><span class="ltx_text" id="S3.T4.11.11.3.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 6.5\%" class="ltx_Math" display="inline" id="S3.T4.11.11.3.1.m1.1"><semantics id="S3.T4.11.11.3.1.m1.1a"><mrow id="S3.T4.11.11.3.1.m1.1.1" xref="S3.T4.11.11.3.1.m1.1.1.cmml"><mi id="S3.T4.11.11.3.1.m1.1.1.2" xref="S3.T4.11.11.3.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.11.11.3.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.11.11.3.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.11.11.3.1.m1.1.1.3" xref="S3.T4.11.11.3.1.m1.1.1.3.cmml"><mn id="S3.T4.11.11.3.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.11.11.3.1.m1.1.1.3.2.cmml">6.5</mn><mo id="S3.T4.11.11.3.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.11.11.3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.11.11.3.1.m1.1b"><apply id="S3.T4.11.11.3.1.m1.1.1.cmml" xref="S3.T4.11.11.3.1.m1.1.1"><ci id="S3.T4.11.11.3.1.m1.1.1.1.cmml" xref="S3.T4.11.11.3.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.11.11.3.1.m1.1.1.2.cmml" xref="S3.T4.11.11.3.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.11.11.3.1.m1.1.1.3.cmml" xref="S3.T4.11.11.3.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.11.11.3.1.m1.1.1.3.1.cmml" xref="S3.T4.11.11.3.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.11.11.3.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.11.11.3.1.m1.1.1.3.2">6.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.11.11.3.1.m1.1c">\downarrow 6.5\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.11.11.3.1.m1.1d">↓ 6.5 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.12.12.4">
<span class="ltx_text" id="S3.T4.12.12.4.2" style="font-size:80%;">41.4 </span><span class="ltx_text" id="S3.T4.12.12.4.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 7.4\%" class="ltx_Math" display="inline" id="S3.T4.12.12.4.1.m1.1"><semantics id="S3.T4.12.12.4.1.m1.1a"><mrow id="S3.T4.12.12.4.1.m1.1.1" xref="S3.T4.12.12.4.1.m1.1.1.cmml"><mi id="S3.T4.12.12.4.1.m1.1.1.2" xref="S3.T4.12.12.4.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.12.12.4.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.12.12.4.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.12.12.4.1.m1.1.1.3" xref="S3.T4.12.12.4.1.m1.1.1.3.cmml"><mn id="S3.T4.12.12.4.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.12.12.4.1.m1.1.1.3.2.cmml">7.4</mn><mo id="S3.T4.12.12.4.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.12.12.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.12.12.4.1.m1.1b"><apply id="S3.T4.12.12.4.1.m1.1.1.cmml" xref="S3.T4.12.12.4.1.m1.1.1"><ci id="S3.T4.12.12.4.1.m1.1.1.1.cmml" xref="S3.T4.12.12.4.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.12.12.4.1.m1.1.1.2.cmml" xref="S3.T4.12.12.4.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.12.12.4.1.m1.1.1.3.cmml" xref="S3.T4.12.12.4.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.12.12.4.1.m1.1.1.3.1.cmml" xref="S3.T4.12.12.4.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.12.12.4.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.12.12.4.1.m1.1.1.3.2">7.4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.12.12.4.1.m1.1c">\downarrow 7.4\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.12.12.4.1.m1.1d">↓ 7.4 %</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.26.6">
<td class="ltx_td ltx_align_left" id="S3.T4.20.26.6.1"><span class="ltx_text" id="S3.T4.20.26.6.1.1" style="font-size:80%;">Llama-3-Instruct (8B)</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.26.6.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.26.6.2.1" style="font-size:80%;">66.2</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.26.6.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.26.6.3.1" style="font-size:80%;">47.6</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.26.6.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.26.6.4.1" style="font-size:80%;">64.2</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.20.26.6.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.26.6.5.1" style="font-size:80%;">44.7</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.16.16">
<td class="ltx_td ltx_align_left" id="S3.T4.16.16.5"><span class="ltx_text" id="S3.T4.16.16.5.1" style="font-size:80%;">Llama-3-Instruct (70B)</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.13.13.1">
<span class="ltx_text" id="S3.T4.13.13.1.2" style="font-size:80%;">67.0 </span><span class="ltx_text" id="S3.T4.13.13.1.1" style="font-size:80%;color:#008080;">(<math alttext="\uparrow 1.2\%" class="ltx_Math" display="inline" id="S3.T4.13.13.1.1.m1.1"><semantics id="S3.T4.13.13.1.1.m1.1a"><mrow id="S3.T4.13.13.1.1.m1.1.1" xref="S3.T4.13.13.1.1.m1.1.1.cmml"><mi id="S3.T4.13.13.1.1.m1.1.1.2" xref="S3.T4.13.13.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.13.13.1.1.m1.1.1.1" mathcolor="#008080" stretchy="false" xref="S3.T4.13.13.1.1.m1.1.1.1.cmml">↑</mo><mrow id="S3.T4.13.13.1.1.m1.1.1.3" xref="S3.T4.13.13.1.1.m1.1.1.3.cmml"><mn id="S3.T4.13.13.1.1.m1.1.1.3.2" mathcolor="#008080" xref="S3.T4.13.13.1.1.m1.1.1.3.2.cmml">1.2</mn><mo id="S3.T4.13.13.1.1.m1.1.1.3.1" mathcolor="#008080" xref="S3.T4.13.13.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.13.13.1.1.m1.1b"><apply id="S3.T4.13.13.1.1.m1.1.1.cmml" xref="S3.T4.13.13.1.1.m1.1.1"><ci id="S3.T4.13.13.1.1.m1.1.1.1.cmml" xref="S3.T4.13.13.1.1.m1.1.1.1">↑</ci><csymbol cd="latexml" id="S3.T4.13.13.1.1.m1.1.1.2.cmml" xref="S3.T4.13.13.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.13.13.1.1.m1.1.1.3.cmml" xref="S3.T4.13.13.1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.13.13.1.1.m1.1.1.3.1.cmml" xref="S3.T4.13.13.1.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.13.13.1.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.13.13.1.1.m1.1.1.3.2">1.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.13.13.1.1.m1.1c">\uparrow 1.2\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.13.13.1.1.m1.1d">↑ 1.2 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.14.14.2">
<span class="ltx_text" id="S3.T4.14.14.2.2" style="font-size:80%;">49.1 </span><span class="ltx_text" id="S3.T4.14.14.2.1" style="font-size:80%;color:#008080;">(<math alttext="\uparrow 3.2\%" class="ltx_Math" display="inline" id="S3.T4.14.14.2.1.m1.1"><semantics id="S3.T4.14.14.2.1.m1.1a"><mrow id="S3.T4.14.14.2.1.m1.1.1" xref="S3.T4.14.14.2.1.m1.1.1.cmml"><mi id="S3.T4.14.14.2.1.m1.1.1.2" xref="S3.T4.14.14.2.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.14.14.2.1.m1.1.1.1" mathcolor="#008080" stretchy="false" xref="S3.T4.14.14.2.1.m1.1.1.1.cmml">↑</mo><mrow id="S3.T4.14.14.2.1.m1.1.1.3" xref="S3.T4.14.14.2.1.m1.1.1.3.cmml"><mn id="S3.T4.14.14.2.1.m1.1.1.3.2" mathcolor="#008080" xref="S3.T4.14.14.2.1.m1.1.1.3.2.cmml">3.2</mn><mo id="S3.T4.14.14.2.1.m1.1.1.3.1" mathcolor="#008080" xref="S3.T4.14.14.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.14.14.2.1.m1.1b"><apply id="S3.T4.14.14.2.1.m1.1.1.cmml" xref="S3.T4.14.14.2.1.m1.1.1"><ci id="S3.T4.14.14.2.1.m1.1.1.1.cmml" xref="S3.T4.14.14.2.1.m1.1.1.1">↑</ci><csymbol cd="latexml" id="S3.T4.14.14.2.1.m1.1.1.2.cmml" xref="S3.T4.14.14.2.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.14.14.2.1.m1.1.1.3.cmml" xref="S3.T4.14.14.2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.14.14.2.1.m1.1.1.3.1.cmml" xref="S3.T4.14.14.2.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.14.14.2.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.14.14.2.1.m1.1.1.3.2">3.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.14.14.2.1.m1.1c">\uparrow 3.2\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.14.14.2.1.m1.1d">↑ 3.2 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.15.15.3">
<span class="ltx_text" id="S3.T4.15.15.3.2" style="font-size:80%;">64.8 </span><span class="ltx_text" id="S3.T4.15.15.3.1" style="font-size:80%;color:#008080;">(<math alttext="\uparrow 0.9\%" class="ltx_Math" display="inline" id="S3.T4.15.15.3.1.m1.1"><semantics id="S3.T4.15.15.3.1.m1.1a"><mrow id="S3.T4.15.15.3.1.m1.1.1" xref="S3.T4.15.15.3.1.m1.1.1.cmml"><mi id="S3.T4.15.15.3.1.m1.1.1.2" xref="S3.T4.15.15.3.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.15.15.3.1.m1.1.1.1" mathcolor="#008080" stretchy="false" xref="S3.T4.15.15.3.1.m1.1.1.1.cmml">↑</mo><mrow id="S3.T4.15.15.3.1.m1.1.1.3" xref="S3.T4.15.15.3.1.m1.1.1.3.cmml"><mn id="S3.T4.15.15.3.1.m1.1.1.3.2" mathcolor="#008080" xref="S3.T4.15.15.3.1.m1.1.1.3.2.cmml">0.9</mn><mo id="S3.T4.15.15.3.1.m1.1.1.3.1" mathcolor="#008080" xref="S3.T4.15.15.3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.15.15.3.1.m1.1b"><apply id="S3.T4.15.15.3.1.m1.1.1.cmml" xref="S3.T4.15.15.3.1.m1.1.1"><ci id="S3.T4.15.15.3.1.m1.1.1.1.cmml" xref="S3.T4.15.15.3.1.m1.1.1.1">↑</ci><csymbol cd="latexml" id="S3.T4.15.15.3.1.m1.1.1.2.cmml" xref="S3.T4.15.15.3.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.15.15.3.1.m1.1.1.3.cmml" xref="S3.T4.15.15.3.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.15.15.3.1.m1.1.1.3.1.cmml" xref="S3.T4.15.15.3.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.15.15.3.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.15.15.3.1.m1.1.1.3.2">0.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.15.15.3.1.m1.1c">\uparrow 0.9\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.15.15.3.1.m1.1d">↑ 0.9 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.16.16.4">
<span class="ltx_text" id="S3.T4.16.16.4.2" style="font-size:80%;">47.9 </span><span class="ltx_text" id="S3.T4.16.16.4.1" style="font-size:80%;color:#008080;">(<math alttext="\uparrow 7.1\%" class="ltx_Math" display="inline" id="S3.T4.16.16.4.1.m1.1"><semantics id="S3.T4.16.16.4.1.m1.1a"><mrow id="S3.T4.16.16.4.1.m1.1.1" xref="S3.T4.16.16.4.1.m1.1.1.cmml"><mi id="S3.T4.16.16.4.1.m1.1.1.2" xref="S3.T4.16.16.4.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.16.16.4.1.m1.1.1.1" mathcolor="#008080" stretchy="false" xref="S3.T4.16.16.4.1.m1.1.1.1.cmml">↑</mo><mrow id="S3.T4.16.16.4.1.m1.1.1.3" xref="S3.T4.16.16.4.1.m1.1.1.3.cmml"><mn id="S3.T4.16.16.4.1.m1.1.1.3.2" mathcolor="#008080" xref="S3.T4.16.16.4.1.m1.1.1.3.2.cmml">7.1</mn><mo id="S3.T4.16.16.4.1.m1.1.1.3.1" mathcolor="#008080" xref="S3.T4.16.16.4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.16.16.4.1.m1.1b"><apply id="S3.T4.16.16.4.1.m1.1.1.cmml" xref="S3.T4.16.16.4.1.m1.1.1"><ci id="S3.T4.16.16.4.1.m1.1.1.1.cmml" xref="S3.T4.16.16.4.1.m1.1.1.1">↑</ci><csymbol cd="latexml" id="S3.T4.16.16.4.1.m1.1.1.2.cmml" xref="S3.T4.16.16.4.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.16.16.4.1.m1.1.1.3.cmml" xref="S3.T4.16.16.4.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.16.16.4.1.m1.1.1.3.1.cmml" xref="S3.T4.16.16.4.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.16.16.4.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.16.16.4.1.m1.1.1.3.2">7.1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.16.16.4.1.m1.1c">\uparrow 7.1\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.16.16.4.1.m1.1d">↑ 7.1 %</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.27.7">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="5" id="S3.T4.20.27.7.1"><span class="ltx_text ltx_font_italic" id="S3.T4.20.27.7.1.1" style="font-size:80%;">Inference Strategy Comparison</span></td>
</tr>
<tr class="ltx_tr" id="S3.T4.18.18">
<td class="ltx_td ltx_align_left" id="S3.T4.18.18.3"><span class="ltx_text" id="S3.T4.18.18.3.1" style="font-size:80%;">w/o demonstration</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.18.18.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.18.18.4.1" style="font-size:80%;">66.2</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.18.18.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.18.18.5.1" style="font-size:80%;">47.6</span></td>
<td class="ltx_td ltx_align_left" id="S3.T4.17.17.1">
<span class="ltx_text" id="S3.T4.17.17.1.2" style="font-size:80%;">63.0 </span><span class="ltx_text" id="S3.T4.17.17.1.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 1.9\%" class="ltx_Math" display="inline" id="S3.T4.17.17.1.1.m1.1"><semantics id="S3.T4.17.17.1.1.m1.1a"><mrow id="S3.T4.17.17.1.1.m1.1.1" xref="S3.T4.17.17.1.1.m1.1.1.cmml"><mi id="S3.T4.17.17.1.1.m1.1.1.2" xref="S3.T4.17.17.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.17.17.1.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.17.17.1.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.17.17.1.1.m1.1.1.3" xref="S3.T4.17.17.1.1.m1.1.1.3.cmml"><mn id="S3.T4.17.17.1.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.17.17.1.1.m1.1.1.3.2.cmml">1.9</mn><mo id="S3.T4.17.17.1.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.17.17.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.17.17.1.1.m1.1b"><apply id="S3.T4.17.17.1.1.m1.1.1.cmml" xref="S3.T4.17.17.1.1.m1.1.1"><ci id="S3.T4.17.17.1.1.m1.1.1.1.cmml" xref="S3.T4.17.17.1.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.17.17.1.1.m1.1.1.2.cmml" xref="S3.T4.17.17.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.17.17.1.1.m1.1.1.3.cmml" xref="S3.T4.17.17.1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.17.17.1.1.m1.1.1.3.1.cmml" xref="S3.T4.17.17.1.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.17.17.1.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.17.17.1.1.m1.1.1.3.2">1.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.17.17.1.1.m1.1c">\downarrow 1.9\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.17.17.1.1.m1.1d">↓ 1.9 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left" id="S3.T4.18.18.2">
<span class="ltx_text" id="S3.T4.18.18.2.2" style="font-size:80%;">43.1 </span><span class="ltx_text" id="S3.T4.18.18.2.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 3.6\%" class="ltx_Math" display="inline" id="S3.T4.18.18.2.1.m1.1"><semantics id="S3.T4.18.18.2.1.m1.1a"><mrow id="S3.T4.18.18.2.1.m1.1.1" xref="S3.T4.18.18.2.1.m1.1.1.cmml"><mi id="S3.T4.18.18.2.1.m1.1.1.2" xref="S3.T4.18.18.2.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.18.18.2.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.18.18.2.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.18.18.2.1.m1.1.1.3" xref="S3.T4.18.18.2.1.m1.1.1.3.cmml"><mn id="S3.T4.18.18.2.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.18.18.2.1.m1.1.1.3.2.cmml">3.6</mn><mo id="S3.T4.18.18.2.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.18.18.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.18.18.2.1.m1.1b"><apply id="S3.T4.18.18.2.1.m1.1.1.cmml" xref="S3.T4.18.18.2.1.m1.1.1"><ci id="S3.T4.18.18.2.1.m1.1.1.1.cmml" xref="S3.T4.18.18.2.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.18.18.2.1.m1.1.1.2.cmml" xref="S3.T4.18.18.2.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.18.18.2.1.m1.1.1.3.cmml" xref="S3.T4.18.18.2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.18.18.2.1.m1.1.1.3.1.cmml" xref="S3.T4.18.18.2.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.18.18.2.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.18.18.2.1.m1.1.1.3.2">3.6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.18.18.2.1.m1.1c">\downarrow 3.6\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.18.18.2.1.m1.1d">↓ 3.6 %</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T4.20.20">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.20.20.3"><span class="ltx_text" id="S3.T4.20.20.3.1" style="font-size:80%;">w/ demonstration</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.19.19.1">
<span class="ltx_text" id="S3.T4.19.19.1.2" style="font-size:80%;">66.1 </span><span class="ltx_text" id="S3.T4.19.19.1.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 0.2\%" class="ltx_Math" display="inline" id="S3.T4.19.19.1.1.m1.1"><semantics id="S3.T4.19.19.1.1.m1.1a"><mrow id="S3.T4.19.19.1.1.m1.1.1" xref="S3.T4.19.19.1.1.m1.1.1.cmml"><mi id="S3.T4.19.19.1.1.m1.1.1.2" xref="S3.T4.19.19.1.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.19.19.1.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.19.19.1.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.19.19.1.1.m1.1.1.3" xref="S3.T4.19.19.1.1.m1.1.1.3.cmml"><mn id="S3.T4.19.19.1.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.19.19.1.1.m1.1.1.3.2.cmml">0.2</mn><mo id="S3.T4.19.19.1.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.19.19.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.19.19.1.1.m1.1b"><apply id="S3.T4.19.19.1.1.m1.1.1.cmml" xref="S3.T4.19.19.1.1.m1.1.1"><ci id="S3.T4.19.19.1.1.m1.1.1.1.cmml" xref="S3.T4.19.19.1.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.19.19.1.1.m1.1.1.2.cmml" xref="S3.T4.19.19.1.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.19.19.1.1.m1.1.1.3.cmml" xref="S3.T4.19.19.1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.19.19.1.1.m1.1.1.3.1.cmml" xref="S3.T4.19.19.1.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.19.19.1.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.19.19.1.1.m1.1.1.3.2">0.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.19.19.1.1.m1.1c">\downarrow 0.2\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.19.19.1.1.m1.1d">↓ 0.2 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.20.20.2">
<span class="ltx_text" id="S3.T4.20.20.2.2" style="font-size:80%;">44.7 </span><span class="ltx_text" id="S3.T4.20.20.2.1" style="font-size:80%;color:#BF0040;">(<math alttext="\downarrow 6.1\%" class="ltx_Math" display="inline" id="S3.T4.20.20.2.1.m1.1"><semantics id="S3.T4.20.20.2.1.m1.1a"><mrow id="S3.T4.20.20.2.1.m1.1.1" xref="S3.T4.20.20.2.1.m1.1.1.cmml"><mi id="S3.T4.20.20.2.1.m1.1.1.2" xref="S3.T4.20.20.2.1.m1.1.1.2.cmml"></mi><mo id="S3.T4.20.20.2.1.m1.1.1.1" mathcolor="#BF0040" stretchy="false" xref="S3.T4.20.20.2.1.m1.1.1.1.cmml">↓</mo><mrow id="S3.T4.20.20.2.1.m1.1.1.3" xref="S3.T4.20.20.2.1.m1.1.1.3.cmml"><mn id="S3.T4.20.20.2.1.m1.1.1.3.2" mathcolor="#BF0040" xref="S3.T4.20.20.2.1.m1.1.1.3.2.cmml">6.1</mn><mo id="S3.T4.20.20.2.1.m1.1.1.3.1" mathcolor="#BF0040" xref="S3.T4.20.20.2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T4.20.20.2.1.m1.1b"><apply id="S3.T4.20.20.2.1.m1.1.1.cmml" xref="S3.T4.20.20.2.1.m1.1.1"><ci id="S3.T4.20.20.2.1.m1.1.1.1.cmml" xref="S3.T4.20.20.2.1.m1.1.1.1">↓</ci><csymbol cd="latexml" id="S3.T4.20.20.2.1.m1.1.1.2.cmml" xref="S3.T4.20.20.2.1.m1.1.1.2">absent</csymbol><apply id="S3.T4.20.20.2.1.m1.1.1.3.cmml" xref="S3.T4.20.20.2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.T4.20.20.2.1.m1.1.1.3.1.cmml" xref="S3.T4.20.20.2.1.m1.1.1.3.1">percent</csymbol><cn id="S3.T4.20.20.2.1.m1.1.1.3.2.cmml" type="float" xref="S3.T4.20.20.2.1.m1.1.1.3.2">6.1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.20.20.2.1.m1.1c">\downarrow 6.1\%</annotation><annotation encoding="application/x-llamapun" id="S3.T4.20.20.2.1.m1.1d">↓ 6.1 %</annotation></semantics></math>)</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.20.20.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.20.4.1" style="font-size:80%;">64.2</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.20.20.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T4.20.20.5.1" style="font-size:80%;">44.7</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">Providing ground-truth answers and retrieved documents is important for rationale generation.</span>
As depicted in the first block of Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.T4" title="Table 4 ‣ 3.3 Ablation Study ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">4</span></a>, we ablate the rationale generation design from two aspects: (1) <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.2">w/o ground-truth answer</em>, where the model has no access to the ground-truth answer during rational generation and must predict the answer and explain how it is derived solely based on retrieved documents; (2) <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.3">w/o retrieved documents</em>, where the model is not provided with any retrieved documents during rational generation, and in this case, it has to explain the given answer based on its own knowledge.
Although it is not surprising that our default design consistently outperforms the two ablations, it is encouraging to find that our method still works well even without access to the retrieved documents or ground-truth answers.
This finding suggests the great potential of our <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p1.1.4">InstructRAG</span> to operate in a fully unsupervised manner, which we believe is an exciting direction for future work.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.2.1">Larger rationale generator leads to better results.</span> The middle block shows how different sizes of rationale generators impact the performance of our method.
It is evident that the template-based rationale generation method significantly underperforms our method, highlighting the necessity of rationale generator.
This is because the template-based method relies on pattern matching to identify relevant documents containing the ground-truth answer, which only considers lexical similarity while ignoring semantic meaning.
The neglect of semantics inevitably introduces noise in template-generated rationales, making them less effective compared to rationales generated by LMs.
Moreover, we also compare two variants of <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p2.2.2">InstructRAG</span> using Llama-3-Instruct<math alttext="{}_{\textsc{8B}}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1a" xref="S3.SS3.p2.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1a.cmml">8B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><ci id="S3.SS3.p2.1.m1.1.1.1a.cmml" xref="S3.SS3.p2.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS3.p2.1.m1.1.1.1.cmml" mathsize="70%" xref="S3.SS3.p2.1.m1.1.1.1">8B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">{}_{\textsc{8B}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">start_FLOATSUBSCRIPT 8B end_FLOATSUBSCRIPT</annotation></semantics></math> and Llama-3-Instruct<math alttext="{}_{\textsc{70B}}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1a" xref="S3.SS3.p2.2.m2.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1a.cmml">70B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><ci id="S3.SS3.p2.2.m2.1.1.1a.cmml" xref="S3.SS3.p2.2.m2.1.1.1"><mtext class="ltx_font_smallcaps" id="S3.SS3.p2.2.m2.1.1.1.cmml" mathsize="70%" xref="S3.SS3.p2.2.m2.1.1.1">70B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">{}_{\textsc{70B}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">start_FLOATSUBSCRIPT 70B end_FLOATSUBSCRIPT</annotation></semantics></math> as rationale generators.
The results show that the one with a 70B generator consistently outperforms its 8B counterpart in both training-free and trainable settings, indicating that the self-synthesized denoising rationales can provide better supervision when generated by stronger models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Inference with demonstrations should only be applied to </span><span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.2">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.3">-ICL.</span>
In the bottom block, we study the use of demonstrations during the model inference. While demonstrations play an important role for <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.4">InstructRAG</span>-ICL, we find that they actually hurt the performance of <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.5">InstructRAG</span>-FT.
We attribute this to the fact that <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.6">InstructRAG</span>-FT is optimized to directly generate denoising rationales given potentially noisy input, without referring to any demonstrations.
Therefore, providing in-context demonstrations for <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.7">InstructRAG</span>-FT is redundant and may compromise its capability due to the discrepancy between training and inference.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Analysis</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p1.1.1">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.2">-ICL consistently benefits from more demonstrations.</span>
Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.F3.sf1" title="In Figure 3 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3(a)</span></a> shows the demonstration sensitivity of <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p1.1.3">InstructRAG</span>-ICL and the few-shot demonstration with instruction baseline.
It is interesting to find that the baseline method achieves its best performance with only one demonstration, and presenting more demonstrations actually harms its performance.
In contrast, our method consistently improves with the increasing number of demonstrations, confirming the superiority of self-synthesized rationales over plain answers in terms of denoising.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1"><span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p2.1.1">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.2">-ICL and </span><span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p2.1.3">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.1.4">-FT are robust to increased noise ratios.</span> Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.F3.sf2" title="In Figure 3 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3(b)</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.F3.sf3" title="In Figure 3 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">3(c)</span></a> show the generation accuracy of <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p2.1.5">InstructRAG</span>-ICL and <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p2.1.6">InstructRAG</span>-FT and the corresponding retrieval precision under an increasing number of retrieved documents.
While retrieving more documents provides richer external knowledge to the RAG model, it also introduces more noise and lowers the retrieval precision.
As a result, both the training-free and trainable baselines show diminishing improvements or even degrade as the number of documents increases, reflecting their vulnerability to high noisy ratios.
In contrast, our <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p2.1.7">InstructRAG</span>-ICL and <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p2.1.8">InstructRAG</span>-FT are not negatively affected by this increased noise ratio but rather gain further improvement, demonstrating their robust denoising ability.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S3.F3.sf1">
<p class="ltx_p ltx_align_center" id="S3.F3.sf1.1"><span class="ltx_text" id="S3.F3.sf1.1.1" style="position:relative; bottom:0.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="549" id="S3.F3.sf1.1.1.g1" src="x3.png" width="831"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf1.3.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S3.F3.sf1.4.2" style="font-size:90%;">Training-free RAG setting. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S3.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="479" id="S3.F3.sf2.g1" src="x4.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S3.F3.sf2.3.2" style="font-size:90%;">Training-free RAG setting. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S3.F3.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="479" id="S3.F3.sf3.g1" src="x5.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S3.F3.sf3.3.2" style="font-size:90%;">Trainable RAG setting. </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.5.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.6.2" style="font-size:90%;">Impact of different number of demonstrations and retrieved documents. (a) Demonstration sensitivity study of <span class="ltx_text ltx_font_smallcaps" id="S3.F3.6.2.1">InstructRAG</span>-ICL. (b) Noise robustness study of <span class="ltx_text ltx_font_smallcaps" id="S3.F3.6.2.2">InstructRAG</span>-ICL. (c) Noise robustness study of <span class="ltx_text ltx_font_smallcaps" id="S3.F3.6.2.3">InstructRAG</span>-FT. </span></figcaption>
</figure>
<figure class="ltx_figure" id="S3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S3.F4.sf1">
<p class="ltx_p ltx_align_center" id="S3.F4.sf1.1"><span class="ltx_text" id="S3.F4.sf1.1.1" style="position:relative; bottom:0.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="474" id="S3.F4.sf1.1.1.g1" src="x6.png" width="831"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.sf1.3.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S3.F4.sf1.4.2" style="font-size:90%;">Short-form to long-form QA. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S3.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="473" id="S3.F4.sf2.g1" src="x7.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S3.F4.sf2.3.2" style="font-size:90%;">Long-form to short-form QA. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel" id="S3.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="473" id="S3.F4.sf3.g1" src="x8.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S3.F4.sf3.3.2" style="font-size:90%;">Single-hop to multi-hop QA. </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.5.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S3.F4.6.2" style="font-size:90%;">Generalizing <span class="ltx_text ltx_font_smallcaps" id="S3.F4.6.2.1">InstructRAG</span> from source domain task to target domain task, where ID and OOD denote in-domain and out-of-domain settings. (a) PopQA (short-form QA task) as source domain and ASQA (long-form QA task) as target domain. (b) ASQA as source domain and PopQA as target domain. (c) PopQA (single-hop QA task) as source domain and 2WikiMultiHopQA (multi-hop QA task) as target domain.
We adopt <em class="ltx_emph ltx_font_italic" id="S3.F4.6.2.2">few-shot demonstration with instruction</em> and <em class="ltx_emph ltx_font_italic" id="S3.F4.6.2.3">vanilla supervised fine-tuning</em> as the training-free and trainable baselines.
</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p3.1.1">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.2">-ICL and </span><span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p3.1.3">InstructRAG</span><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.4">-FT generalize well to unseen tasks.</span>
Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.F4" title="Figure 4 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates the generalization ability of our method in both training-free and trainable settings.
For the in-domain (ID) method, it directly utilizes target domain demonstrations (in training-free settings) or is trained on the target domain task (in trainable settings).
In contrast, the out-of-domain (OOD) method can only learn from demonstrations or training data in the source domain, and have no prior knowledge of the target domain.
In this case, the model must leverage the knowledge learned from the source domain task to solve the unseen target domain task.
The results show that our method (<span class="ltx_text ltx_font_slanted" id="S3.SS4.p3.1.5">i.e.</span>, <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p3.1.6">InstructRAG</span>-ICL and <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p3.1.7">InstructRAG</span>-FT) consistently outperforms the baselines across various scenarios in both in-domain and out-of-domain settings, demonstrating strong task generalizability.
One counter-intuitive finding is that in the scenario of generalizing from long-form to short-form QA task (Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.F4.sf2" title="In Figure 4 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">4(b)</span></a>), the training-free OOD method substantially outperforms its in-domain counterpart.
We speculate that the training-free OOD method achieves better performance because it benefits from the demonstrations with long answers from the source domain (ASQA).
The reason is that the questions in ASQA are ambiguous and can have multiple interpretations, and ground-truth long answers often address the questions from various perspectives, which can be regarded as a form of chain-of-thought demonstration.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">Furthermore, we also study the generalizability of <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p4.1.1">InstructRAG</span> to a non-QA knowledge-intensive task such as code generation. As presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.T5.st1" title="In Table 5 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, we directly apply <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p4.1.2">InstructRAG</span>-FT trained on the QA task (PopQA) to solve the unseen code generation task (HumanEval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib12" title="">12</a>]</cite>), following the CodeRAG-Bench setup <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib87" title="">87</a>]</cite>.
We evaluate the code generation performance
using the standard pass@k metric and compare our method with the off-the-shelf Llama-3-8B-Instruct as the baseline.
It can be observed that our method consistently achieves better generalization performance in the unseen code generation task in both non-retrieval and RAG settings. This finding aligns with our observation that InstructRAG trained on QA tasks tends to generate more text-based comments that articulate the design of coding solutions compared to the off-the-shelf Llama-3-8B-Instruct, thereby leading to more accurate code generation.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p5.1.1">Evaluation with LLM-as-a-judge.</span> Despite being standard evaluation metrics for question-answering, accuracy or exact match are known to be imperfect <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib13" title="">13</a>]</cite> as they mainly rely on pattern-matching to judge whether the predicted answer aligns with the ground-truth answer. Such metrics cannot handle cases where the predicted answer and ground-truth answer are synonyms (<span class="ltx_text ltx_font_slanted" id="S3.SS4.p5.1.2">e.g.</span>, “Donald Trump” vs “Donald J. Trump” cannot be correctly recognized as a match), leading to biased evaluation results.</p>
</div>
<div class="ltx_para" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.1">Therefore, we adopt the LLM-as-a-judge <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib115" title="">115</a>]</cite> approach to evaluate whether the model response aligns with the ground-truth answer using GPT-4o <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib66" title="">66</a>]</cite>, which allows the judge to consider semantic equivalence and is expected to yield a more fair evaluation.
As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#S3.T5.st2" title="In Table 5 ‣ 3.4 Analysis ‣ 3 Experiments ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">5(b)</span></a>, we evaluate our method and baseline models on the open-domain Natural Questions benchmark in both training-free and trainable RAG settings.
Compared to pattern-matching based metrics, LLM-as-a-judge generally leads to higher evaluation results, mostly due to its capability to accurately match semantically equivalent phrasings.
Notably, our method consistently outperforms baselines under both pattern-matching based and LLM-based evaluation metrics, further validating the effectiveness of <span class="ltx_text ltx_font_smallcaps" id="S3.SS4.p6.1.1">InstructRAG</span>.</p>
</div>
<figure class="ltx_table" id="S3.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T5.3.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S3.T5.4.2" style="font-size:90%;">(a) Transfer from the QA task (PopQA) to the code generation task (HumanEval). Our method <span class="ltx_text ltx_font_smallcaps" id="S3.T5.4.2.1">InstructRAG</span>-FT is fine-tuned only on the QA task and is evaluated for solving the unseen code generation task. We compare it with off-the-shelf LLaMA-3-8B-Instruct in both non-retrieval and retrieval-augmented generation settings, and report the standard evaluation metrics pass@k <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib12" title="">12</a>]</cite>. (b) Evaluation with GPT-4o as the judge. Compared to pattern-matching based metrics, it allows the judge to consider semantic equivalence and is expected to yield a more fair evaluation.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel ltx_align_center" id="S3.T5.st1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T5.st1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T5.st1.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T5.st1.2.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.1.1.1.1" style="font-size:80%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T5.st1.2.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.1.1.2.1" style="font-size:80%;">pass@1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T5.st1.2.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.1.1.3.1" style="font-size:80%;">pass@10</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.st1.2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3" id="S3.T5.st1.2.2.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S3.T5.st1.2.2.2.1.1" style="font-size:80%;">Without Retrieval</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.st1.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.st1.2.3.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.3.1.1.1" style="font-size:80%;">Llama-3-8B-Instruct</span></th>
<td class="ltx_td ltx_align_center" id="S3.T5.st1.2.3.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.3.1.2.1" style="font-size:80%;">58.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.st1.2.3.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.3.1.3.1" style="font-size:80%;">64.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.st1.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.st1.2.4.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T5.st1.2.4.2.1.1" style="font-size:80%;">InstructRAG</span><span class="ltx_text" id="S3.T5.st1.2.4.2.1.2" style="font-size:80%;">-FT</span>
</th>
<td class="ltx_td ltx_align_center" id="S3.T5.st1.2.4.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.4.2.2.1" style="font-size:80%;">60.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.st1.2.4.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.4.2.3.1" style="font-size:80%;">65.2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.st1.2.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3" id="S3.T5.st1.2.5.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S3.T5.st1.2.5.3.1.1" style="font-size:80%;">With Retrieval</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.st1.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.st1.2.6.4.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.6.4.1.1" style="font-size:80%;">Llama-3-8B-Instruct</span></th>
<td class="ltx_td ltx_align_center" id="S3.T5.st1.2.6.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.6.4.2.1" style="font-size:80%;">59.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.st1.2.6.4.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.6.4.3.1" style="font-size:80%;">69.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.st1.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T5.st1.2.7.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T5.st1.2.7.5.1.1" style="font-size:80%;">InstructRAG</span><span class="ltx_text" id="S3.T5.st1.2.7.5.1.2" style="font-size:80%;">-FT</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.st1.2.7.5.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.7.5.2.1" style="font-size:80%;">64.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.st1.2.7.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st1.2.7.5.3.1" style="font-size:80%;">71.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T5.st1.5.1.1" style="font-size:113%;">(a)</span> </span><span class="ltx_text" id="S3.T5.st1.6.2" style="font-size:113%;">Transfer from QA task to code generation task.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_table ltx_figure_panel ltx_align_center" id="S3.T5.st2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T5.st2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T5.st2.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T5.st2.2.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.1.1.1.1" style="font-size:80%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T5.st2.2.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.1.1.2.1" style="font-size:80%;">Pattern-based</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T5.st2.2.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.1.1.3.1" style="font-size:80%;">LLM-based</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.st2.2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3" id="S3.T5.st2.2.2.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S3.T5.st2.2.2.2.1.1" style="font-size:80%;">RAG w/o Training</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T5.st2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.st2.2.3.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.3.1.1.1" style="font-size:80%;">In-Context RALM</span></th>
<td class="ltx_td ltx_align_center" id="S3.T5.st2.2.3.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.3.1.2.1" style="font-size:80%;">56.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.st2.2.3.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.3.1.3.1" style="font-size:80%;">64.5</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.st2.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.st2.2.4.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T5.st2.2.4.2.1.1" style="font-size:80%;">InstructRAG</span><span class="ltx_text" id="S3.T5.st2.2.4.2.1.2" style="font-size:80%;">-ICL</span>
</th>
<td class="ltx_td ltx_align_center" id="S3.T5.st2.2.4.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.4.2.2.1" style="font-size:80%;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.st2.2.4.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.4.2.3.1" style="font-size:80%;">67.6</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.st2.2.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3" id="S3.T5.st2.2.5.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_italic" id="S3.T5.st2.2.5.3.1.1" style="font-size:80%;">RAG w/ Training</span></th>
</tr>
<tr class="ltx_tr" id="S3.T5.st2.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T5.st2.2.6.4.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.6.4.1.1" style="font-size:80%;">Vanilla SFT</span></th>
<td class="ltx_td ltx_align_center" id="S3.T5.st2.2.6.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.6.4.2.1" style="font-size:80%;">56.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T5.st2.2.6.4.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.6.4.3.1" style="font-size:80%;">65.1</span></td>
</tr>
<tr class="ltx_tr" id="S3.T5.st2.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T5.st2.2.7.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text ltx_font_smallcaps" id="S3.T5.st2.2.7.5.1.1" style="font-size:80%;">InstructRAG</span><span class="ltx_text" id="S3.T5.st2.2.7.5.1.2" style="font-size:80%;">-FT</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.st2.2.7.5.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.7.5.2.1" style="font-size:80%;">65.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T5.st2.2.7.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T5.st2.2.7.5.3.1" style="font-size:80%;">69.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T5.st2.5.1.1" style="font-size:113%;">(b)</span> </span><span class="ltx_text" id="S3.T5.st2.6.2" style="font-size:113%;">Evaluation with GPT-4o as the judge.</span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Work</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Retrieval-augmented Generation</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Retrieval-augmented generation (RAG) is a widely adopted approach to enhance large language models (LLMs) with external knowledge <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib74" title="">74</a>]</cite>, demonstrating promising potential to reduce hallucinations and enhance the generation accuracy of LLMs across various real-world applications <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib77" title="">77</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib80" title="">80</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib117" title="">117</a>]</cite>.
Recently, a growing research effort has been devoted to enhancing RAG from various aspects, such as improving decoding efficiency <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib57" title="">57</a>]</cite>, exploring long-context retrieval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib96" title="">96</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib104" title="">104</a>]</cite>, compressing prompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib95" title="">95</a>]</cite>, and addressing practical concerns such as adversarial retrieval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib92" title="">92</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib116" title="">116</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib118" title="">118</a>]</cite> and privacy leakage <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib108" title="">108</a>]</cite>.
Despite their advantages, these RAG systems inevitably suffer from irrelevant information introduced by imperfect retrievers or noisy retrieval corpora.
However, most existing works typically address this issue by improving the retrieval quality and reducing noise exposure to the model <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib100" title="">100</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib102" title="">102</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib109" title="">109</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib111" title="">111</a>]</cite>.
Notable methods include adaptive retrieval <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib103" title="">103</a>]</cite> and query rewriting <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib62" title="">62</a>]</cite>.
In contrast, our work focuses on an orthogonal direction of developing explicit denoising methods for RAG, thereby enhancing the model’s noise robustness and generation accuracy, even in highly noisy contexts.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Eliciting Reasoning in Large Language Models</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Recent studies have extensively explored the reasoning capability of LMs, but typically not in the context of RAG where potentially noisy retrieved contents may mislead the reasoning if not properly addressed.
Chain-of-thought (CoT) prompting <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib89" title="">89</a>]</cite> is an effective method to elicit step-by-step reasoning from LMs by showing exemplars with detailed explanations (<span class="ltx_text ltx_font_slanted" id="S4.SS2.p1.1.1">i.e.</span>, rationales <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib107" title="">107</a>]</cite>) that lead to the final answer.
However, such works often requires manually crafted demonstrations <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib84" title="">84</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib97" title="">97</a>]</cite>, which is costly and requires extensive efforts and domain knowledge <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib114" title="">114</a>]</cite>.
To mitigate this limitation, automatic chain-of-thought prompting (Auto-CoT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib112" title="">112</a>]</cite> is introduced to automatically select instances from the corpus coupled with zero-shot CoT <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib46" title="">46</a>]</cite>, where the rationales are generated by LMs.
Furthermore, it has been shown that CoT reasoning can be elicited even without explicit prompting, particularly for instruction-tuned LMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib85" title="">85</a>]</cite>.
Another related work shows rationales generated by small models can help large models reason better <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib50" title="">50</a>]</cite>.
Although rationalization has been extensively investigated in many NLP tasks <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib68" title="">68</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib90" title="">90</a>]</cite>, none of them are designed for RAG, and how to leverage the instruction-following abilities of LMs for explicit denoising in the context of RAG is still underexplored.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we presented <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.1">InstructRAG</span>, a simple retrieval-augmented generation (RAG) approach that explicitly denoises retrieved contents and produces accurate generations.
By leveraging the strong instruction-following abilities of large language models, <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.2">InstructRAG</span> generates detailed rationales that articulate how the ground-truth answers can be derived from the retrieved documents. These synthetic rationales can serve as either in-context learning examples or supervised fine-tuning data, enabling the model to learn an explicit denoising process.
Experiments on five knowledge-intensive benchmarks show <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.3">InstructRAG</span> consistently outperforms state-of-the-art RAG approaches with significant improvements in both training-free and trainable settings.
Compared to the best baseline method, <span class="ltx_text ltx_font_smallcaps" id="S5.p1.1.4">InstructRAG</span> achieves an average improvement of 8.3% across all benchmarks, demonstrating its effectiveness in enhancing the noise robustness of retrieval-augmented generation.</p>
</div>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Limitations.</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">In this work, we mainly conduct experiments on question answering-type tasks, and it remains unclear how our method may generalize to other scenarios (<span class="ltx_text ltx_font_slanted" id="S5.SS0.SSS0.Px1.p1.1.1">e.g.</span>, open-ended generation).
Moreover, despite being the standard evaluation metrics, both accuracy and exact match are biased and cannot perfectly reflect the quality of the model’s generations.
For instance, such metrics heavily rely on string matching, which assesses correctness at the lexical level rather than the semantic level, thereby failing to recognize different phrasings that convey identical meanings.
The evaluation results also suffer from length bias, as longer generations tend to achieve higher accuracy.
Exploring more advanced metrics like using LLMs as judges would better evaluate RAG model generations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib102" title="">102</a>]</cite>.
Another potential limitation is that our model might be subject to sample bias in the training data. Incorporating bias mitigation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib101" title="">101</a>]</cite> would be helpful for further improving our work.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Future Work.</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">Future research directions include exploring more advanced techniques for generating high-quality rationales, such as incorporating domain-specific knowledge or leveraging multi-task learning to enable better generalization across various tasks.
For instance, although the consistency ratio between synthetic rationales and ground-truth answers on training samples with at least one relevant document achieves 98%, the overall consistency ratio on all training samples is only 89%. This is because for some samples, none of the retrieved documents is relevant to the question, which significantly compromises the quality of the generated rationales.
Therefore, it will be interesting to fully explore the potential of our method by incorporating additional designs such as a filtering mechanism, which we leave as future work.
Additionally, investigating the scalability of our method to larger datasets and models could further demonstrate its generalizability and robustness.
It will also be interesting to evaluate the model performance under long-context settings with a dynamic or extremely large number of retrieved documents.
Finally, integrating our method with other advanced retrieval techniques, such as active retrieval, could potentially lead to even better performance on knowledge-intensive tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The authors would like to thank Xinyu Zhu from University of Virginia, Tianyu Gao and Zexuan Zhong from Princeton NLP group for their valuable feedback and discussions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.

</span>
<span class="ltx_bibblock">GPT-4 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen.

</span>
<span class="ltx_bibblock">Retrieval-based language models and applications.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 6: Tutorial Abstracts)</span>, pages 41–46, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-RAG: Learning to retrieve, generate, and critique through self-reflection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">The Twelfth International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Akari Asai, Zexuan Zhong, Danqi Chen, Pang Wei Koh, Luke Zettlemoyer, Hannaneh Hajishirzi, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">Reliable, adaptable, and attributable language models with retrieval.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2403.03187</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al.

</span>
<span class="ltx_bibblock">Improving language models by retrieving from trillions of tokens.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">International conference on machine learning</span>, pages 2206–2240. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Advances in neural information processing systems</span>, 33:1877–1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.

</span>
<span class="ltx_bibblock">Sparks of artificial general intelligence: Early experiments with gpt-4.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2303.12712</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, and Jie Fu.

</span>
<span class="ltx_bibblock">RQ-RAG: Learning to refine queries for retrieval augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2404.00610</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Harrison Chase.

</span>
<span class="ltx_bibblock">LangChain, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Howard Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen.

</span>
<span class="ltx_bibblock">Can rationalization improve robustness?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</span>, pages 3792–3805, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.

</span>
<span class="ltx_bibblock">Benchmarking large language models in retrieval-augmented generation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</span>, volume 38, pages 17754–17762, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2107.03374</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, and Fabrizio Silvestri.

</span>
<span class="ltx_bibblock">The power of noise: Redefining retrieval for rag systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</span>, pages 719–729, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Tri Dao.

</span>
<span class="ltx_bibblock">FlashAttention-2: Faster attention with better parallelism and work partitioning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2307.08691</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston.

</span>
<span class="ltx_bibblock">Chain-of-verification reduces hallucination in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2309.11495</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Yunlong Feng, Yang Xu, Libo Qin, Yasheng Wang, and Wanxiang Che.

</span>
<span class="ltx_bibblock">Improving language model reasoning with self-motivated learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</span>, pages 8840–8852, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K Ahmed.

</span>
<span class="ltx_bibblock">Bias and fairness in large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Computational Linguistics</span>, pages 1–79, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.

</span>
<span class="ltx_bibblock">Enabling large language models to generate text with citations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 6465–6488, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2312.10997</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Asish Ghoshal, Srinivasan Iyer, Bhargavi Paranjape, Kushal Lakhotia, Scott Wen-tau Yih, and Yashar Mehdad.

</span>
<span class="ltx_bibblock">Quaser: Question answering with scalable extractive rationalization.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</span>, pages 1208–1218, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Shahriar Golchin and Mihai Surdeanu.

</span>
<span class="ltx_bibblock">Time travel in LLMs: Tracing data contamination in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">The Twelfth International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Aman Gupta, Anup Shirgaonkar, Angels de Luis Balaguer, Bruno Silva, Daniel Holstein, Dawei Li, Jennifer Marsman, Leonardo O Nunes, Mahsa Rouzbahman, Morris Sharp, et al.

</span>
<span class="ltx_bibblock">RAG vs Fine-tuning: Pipelines, tradeoffs, and a case study on agriculture.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2401.08406</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang.

</span>
<span class="ltx_bibblock">Retrieval augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">International conference on machine learning</span>, pages 3929–3938. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa.

</span>
<span class="ltx_bibblock">Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps.

</span>
<span class="ltx_bibblock">In Donia Scott, Nuria Bel, and Chengqing Zong, editors, <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 28th International Conference on Computational Linguistics</span>, pages 6609–6625, Barcelona, Spain (Online), December 2020. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al.

</span>
<span class="ltx_bibblock">A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2311.05232</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, and Danqi Chen.

</span>
<span class="ltx_bibblock">Privacy implications of retrieval-based language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 14887–14902, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave.

</span>
<span class="ltx_bibblock">Unsupervised dense information retrieval with contrastive learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2112.09118</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Gautier Izacard and Édouard Grave.

</span>
<span class="ltx_bibblock">Leveraging passage retrieval with generative models for open domain question answering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</span>, pages 874–880, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave.

</span>
<span class="ltx_bibblock">Atlas: Few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">Journal of Machine Learning Research</span>, 24(251):1–43, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Alon Jacovi, Avi Caciularu, Omer Goldman, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Stop uploading test data in plain text: Practical strategies for mitigating data contamination by evaluation benchmarks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">The 2023 Conference on Empirical Methods in Natural Language Processing</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung.

</span>
<span class="ltx_bibblock">Survey of hallucination in natural language generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">ACM Computing Surveys</span>, 55(12):1–38, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu.

</span>
<span class="ltx_bibblock">Llmlingua: Compressing prompts for accelerated inference of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2310.05736</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Wenqi Jiang, Shuai Zhang, Boran Han, Jie Wang, Bernie Wang, and Tim Kraska.

</span>
<span class="ltx_bibblock">PipeRAG: Fast retrieval-augmented generation via algorithm-system co-design.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2403.05676</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Zhiqing Sun, Weijia Shi, Pedro Rodriguez, Chunting Zhou, Graham Neubig, Xi Victoria Lin, Wen-tau Yih, and Srinivasan Iyer.

</span>
<span class="ltx_bibblock">Instruction-tuned language models are better knowledge learners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2402.12847</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig.

</span>
<span class="ltx_bibblock">Active retrieval augmented generation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 7969–7992, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe Liu, and Xin Jin.

</span>
<span class="ltx_bibblock">RAGCache: Efficient knowledge caching for retrieval-augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2404.12457</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang, and Zhicheng Dou.

</span>
<span class="ltx_bibblock">FlashRAG: A modular toolkit for efficient retrieval-augmented generation research.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2405.13576</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 1601–1611, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 6769–6781, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Jungo Kasai, Keisuke Sakaguchi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah A Smith, Yejin Choi, Kentaro Inui, et al.

</span>
<span class="ltx_bibblock">RealTime QA: What’s the answer right now?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Noriaki Kawamae.

</span>
<span class="ltx_bibblock">Friendly conditional text generator.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining</span>, pages 420–428, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis.

</span>
<span class="ltx_bibblock">Generalization through memorization: Nearest neighbor language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">International Conference on Learning Representations</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia.

</span>
<span class="ltx_bibblock">Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2212.14024</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T Joshi, Hanna Moazam, et al.

</span>
<span class="ltx_bibblock">DSPy: Compiling declarative language model calls into self-improving pipelines.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2310.03714</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Diederik P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:1412.6980</span>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">Advances in neural information processing systems</span>, 35:22199–22213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.

</span>
<span class="ltx_bibblock">Natural Questions: A benchmark for question answering research.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">Transactions of the Association for Computational Linguistics</span>, 7:452–466, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 29th Symposium on Operating Systems Principles</span>, pages 611–626, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Andrew Lampinen, Ishita Dasgupta, Stephanie Chan, Kory Mathewson, Mh Tessler, Antonia Creswell, James McClelland, Jane Wang, and Felix Hill.

</span>
<span class="ltx_bibblock">Can language models learn from explanations in context?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</span>, pages 537–563, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Jooyoung Lee, Fan Yang, Thanh Tran, Qian Hu, Emre Barut, and Kai-Wei Chang.

</span>
<span class="ltx_bibblock">Can small language models help large language models reason better?: LM-guided chain-of-thought.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</span>, pages 2835–2843, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Jan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, and Shane Legg.

</span>
<span class="ltx_bibblock">Scalable agent alignment via reward modeling: a research direction.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:1811.07871</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive NLP tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">Advances in Neural Information Processing Systems</span>, 33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix Yu, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Large language models with controllable working memory.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">Findings of the Association for Computational Linguistics: ACL 2023</span>, pages 1774–1793, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.

</span>
<span class="ltx_bibblock">Pyserini: An easy-to-use Python toolkit to support replicable IR research with sparse and dense representations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2102.10073</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Jerry Liu.

</span>
<span class="ltx_bibblock">LlamaIndex, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang.

</span>
<span class="ltx_bibblock">Lost in the middle: How language models use long contexts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib56.1.1">Transactions of the Association for Computational Linguistics</span>, 12, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Yuhan Liu, Hanchen Li, Kuntai Du, Jiayi Yao, Yihua Cheng, Yuyang Huang, Shan Lu, Michael Maire, Henry Hoffmann, Ari Holtzman, et al.

</span>
<span class="ltx_bibblock">CacheGen: Fast context loading for language model applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2310.07240</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, and Alexey Svyatkovskiy.

</span>
<span class="ltx_bibblock">ReACC: A retrieval-augmented code completion framework.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 6227–6240, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Inbal Magar and Roy Schwartz.

</span>
<span class="ltx_bibblock">Data contamination: From memorization to exploitation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib59.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</span>, pages 157–165, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Varun Magesh, Faiz Surani, Matthew Dahl, Mirac Suzgun, Christopher D Manning, and Daniel E Ho.

</span>
<span class="ltx_bibblock">Hallucination-free? Assessing the reliability of leading AI legal research tools.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2405.20362</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib61.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 9802–9822, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun Xie, Fei Huang, Huajun Chen, and Ningyu Zhang.

</span>
<span class="ltx_bibblock">RaFe: Ranking feedback improves query rewriting for RAG.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2405.14431</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Yu Meng, Mengzhou Xia, and Danqi Chen.

</span>
<span class="ltx_bibblock">SimPO: Simple preference optimization with a reference-free reward.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2405.14734</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Thomas Merth, Qichen Fu, Mohammad Rastegari, and Mahyar Najibi.

</span>
<span class="ltx_bibblock">Improving and accelerating retrieval-augmented generation with superposition prompting.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib64.1.1">Forty-first International Conference on Machine Learning</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan, Keith Hall, Ming-Wei Chang, et al.

</span>
<span class="ltx_bibblock">Large dual encoders are generalizable retrievers.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib65.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, pages 9844–9855, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Hello GPT-4o.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib67.1.1">Advances in neural information processing systems</span>, 35:27730–27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Bhargavi Paranjape, Mandar Joshi, John Thickstun, Hannaneh Hajishirzi, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">An information bottleneck approach for controlling conciseness in rationale extraction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib68.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 1938–1952, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher.

</span>
<span class="ltx_bibblock">Explain yourself! leveraging language models for commonsense reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib69.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</span>, pages 4932–4942, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.

</span>
<span class="ltx_bibblock">In-context retrieval-augmented language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib70.1.1">Transactions of the Association for Computational Linguistics</span>, 11:1316–1331, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Stephen E Robertson and Steve Walker.

</span>
<span class="ltx_bibblock">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib71.1.1">SIGIR’94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, organised by Dublin City University</span>, pages 232–241. Springer, 1994.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie, and Christopher D Manning.

</span>
<span class="ltx_bibblock">RAPTOR: Recursive abstractive processing for tree-organized retrieval.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">arXiv preprint arXiv:2401.18059</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.

</span>
<span class="ltx_bibblock">Toolformer: Language models can teach themselves to use tools.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib73.1.1">Thirty-seventh Conference on Neural Information Processing Systems</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">REPLUG: Retrieval-augmented black-box language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib74.1.1">arXiv preprint arXiv:2301.12652</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston.

</span>
<span class="ltx_bibblock">Retrieval augmentation reduces hallucination in conversation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib75.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</span>, pages 3784–3803, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib76.1.1">Nature</span>, 620(7972):172–180, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kaluarachchi, Rajib Rana, and Suranga Nanayakkara.

</span>
<span class="ltx_bibblock">Improving the domain adaptation of retrieval augmented generation (RAG) models for open domain question answering.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib77.1.1">Transactions of the Association for Computational Linguistics</span>, 11:1–17, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-Wei Chang.

</span>
<span class="ltx_bibblock">ASQA: Factoid questions meet long-form answers.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib78.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, pages 8273–8288, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, and Xin Luna Dong.

</span>
<span class="ltx_bibblock">Head-to-tail: How knowledgeable are large language models (LLM)? A.K.A will llms replace knowledge graphs?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib79.1.1">arXiv preprint arXiv:2308.10168</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Hanzhuo Tan, Qi Luo, Ling Jiang, Zizheng Zhan, Jing Li, Haotian Zhang, and Yuqun Zhang.

</span>
<span class="ltx_bibblock">Prompt-based code completion via multi-retrieval augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib80.1.1">arXiv preprint arXiv:2405.07530</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib81.1.1">arXiv preprint arXiv:2312.11805</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib82.1.1">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry Wei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny Zhou, Quoc Le, et al.

</span>
<span class="ltx_bibblock">FreshLLMs: Refreshing large language models with search engine augmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib83.1.1">arXiv preprint arXiv:2310.03214</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib84.1.1">arXiv preprint arXiv:2203.11171</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Xuezhi Wang and Denny Zhou.

</span>
<span class="ltx_bibblock">Chain-of-thought reasoning without prompting.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib85.1.1">arXiv preprint arXiv:2402.10200</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Zihao Wang, Anji Liu, Haowei Lin, Jiaqi Li, Xiaojian Ma, and Yitao Liang.

</span>
<span class="ltx_bibblock">RAT: Retrieval augmented thoughts elicit context-aware reasoning in long-horizon generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib86.1.1">arXiv preprint arXiv:2403.05313</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Zora Zhiruo Wang, Akari Asai, Xinyan Velocity Yu, Frank F Xu, Yiqing Xie, Graham Neubig, and Daniel Fried.

</span>
<span class="ltx_bibblock">Coderag-bench: Can retrieval augment code generation?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib87.1.1">arXiv preprint arXiv:2406.14497</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib88.1.1">International Conference on Learning Representations</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib89.1.1">Advances in neural information processing systems</span>, 35:24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Sarah Wiegreffe, Ana Marasović, and Noah A Smith.

</span>
<span class="ltx_bibblock">Measuring association between labels and free-text rationales.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib90.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</span>, pages 10266–10284, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Kevin Wu, Eric Wu, and James Zou.

</span>
<span class="ltx_bibblock">How faithful are RAG models? quantifying the tug-of-war between RAG and LLMs’ internal prior.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib91.1.1">arXiv preprint arXiv:2404.10198</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, and Prateek Mittal.

</span>
<span class="ltx_bibblock">Certifiably robust RAG against retrieval corruption.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib92.1.1">arXiv preprint arXiv:2405.15556</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun.

</span>
<span class="ltx_bibblock">Lawformer: A pre-trained language model for Chinese legal long documents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib93.1.1">AI Open</span>, 2:79–84, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Guangzhi Xiong, Qiao Jin, Zhiyong Lu, and Aidong Zhang.

</span>
<span class="ltx_bibblock">Benchmarking retrieval-augmented generation for medicine.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib94.1.1">arXiv preprint arXiv:2402.13178</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Fangyuan Xu, Weijia Shi, and Eunsol Choi.

</span>
<span class="ltx_bibblock">Recomp: Improving retrieval-augmented lms with compression and selective augmentation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib95.1.1">arXiv preprint arXiv:2310.04408</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Peng Xu, Wei Ping, Xianchao Wu, Lawrence McAfee, Chen Zhu, Zihan Liu, Sandeep Subramanian, Evelina Bakhturina, Mohammad Shoeybi, and Bryan Catanzaro.

</span>
<span class="ltx_bibblock">Retrieval meets long context large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib96.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng, and Tat-Seng Chua.

</span>
<span class="ltx_bibblock">Search-in-the-chain: Interactively enhancing large language models with search for knowledge-intensive tasks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib97.1.1">Proceedings of the ACM on Web Conference 2024</span>, pages 1362–1373, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin.

</span>
<span class="ltx_bibblock">Magpie: Alignment data synthesis from scratch by prompting aligned llms with nothing, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Ziwei Xu, Sanjay Jain, and Mohan Kankanhalli.

</span>
<span class="ltx_bibblock">Hallucination is inevitable: An innate limitation of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib99.1.1">arXiv preprint arXiv:2401.11817</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, and Zhen-Hua Ling.

</span>
<span class="ltx_bibblock">Corrective retrieval augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib100.1.1">arXiv preprint arXiv:2401.15884</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Ke Yang, Charles Yu, Yi R Fung, Manling Li, and Heng Ji.

</span>
<span class="ltx_bibblock">Adept: A debiasing prompt framework.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib101.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</span>, volume 37, pages 10780–10788, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen tau Yih, and Xin Luna Dong.

</span>
<span class="ltx_bibblock">CRAG – comprehensive RAG benchmark.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:2406.04744</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao.

</span>
<span class="ltx_bibblock">ReAct: Synergizing reasoning and acting in language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib103.1.1">The Eleventh International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Howard Yen, Tianyu Gao, and Danqi Chen.

</span>
<span class="ltx_bibblock">Long-context language modeling with parallel context encoding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib104.1.1">arXiv preprint arXiv:2402.16617</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Berant.

</span>
<span class="ltx_bibblock">Making retrieval-augmented language models robust to irrelevant context.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib105.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Improving language models via plug-and-play retrieval feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib106.1.1">arXiv preprint arXiv:2305.14002</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, and Noah D Goodman.

</span>
<span class="ltx_bibblock">Quiet-STaR: Language models can teach themselves to think before speaking.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib107.1.1">arXiv preprint arXiv:2403.09629</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Shenglai Zeng, Jiankun Zhang, Pengfei He, Yue Xing, Yiding Liu, Han Xu, Jie Ren, Shuaiqiang Wang, Dawei Yin, Yi Chang, et al.

</span>
<span class="ltx_bibblock">The good and the bad: Exploring privacy issues in retrieval-augmented generation (RAG).

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib108.1.1">arXiv preprint arXiv:2402.16893</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
Jinghan Zhang, Xiting Wang, Weijieying Ren, Lu Jiang, Dongjie Wang, and Kunpeng Liu.

</span>
<span class="ltx_bibblock">RATT: A thought structure for coherent and correct LLM reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib109.1.1">arXiv preprint arXiv:2406.02746</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah A Smith.

</span>
<span class="ltx_bibblock">How language model hallucinations can snowball.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib110.1.1">arXiv preprint arXiv:2305.13534</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
Tianjun Zhang, Shishir G Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, and Joseph E Gonzalez.

</span>
<span class="ltx_bibblock">RAFT: Adapting language model to domain specific RAG.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib111.1.1">arXiv preprint arXiv:2403.10131</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola.

</span>
<span class="ltx_bibblock">Automatic chain of thought prompting in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib112.1.1">The Eleventh International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing.

</span>
<span class="ltx_bibblock">Verify-and-edit: A knowledge-enhanced chain-of-thought framework.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib113.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 5823–5840, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H. Chi, Quoc V Le, and Denny Zhou.

</span>
<span class="ltx_bibblock">Take a step back: Evoking reasoning via abstraction in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib114.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib115.1.1">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Zexuan Zhong, Ziqing Huang, Alexander Wettig, and Danqi Chen.

</span>
<span class="ltx_bibblock">Poisoning retrieval corpora by injecting adversarial passages.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib116.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 13764–13775, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
Shuyan Zhou, Uri Alon, Frank F Xu, Zhengbao Jiang, and Graham Neubig.

</span>
<span class="ltx_bibblock">DocPrompting: Generating code by retrieving the docs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib117.1.1">The Eleventh International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Wei Zou, Runpeng Geng, Binghui Wang, and Jinyuan Jia.

</span>
<span class="ltx_bibblock">PoisonedRAG: Knowledge poisoning attacks to retrieval-augmented generation of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib118.1.1">arXiv preprint arXiv:2402.07867</span>, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p" id="A1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1">Retrieval setup.</span>
Following <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib70" title="">70</a>]</cite>, we use the Wikipedia dump from <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib39" title="">39</a>]</cite> as the external retrieval corpus for all five benchmarks studied in this work, where each document is a disjoint text block of up to 100 words extracted from a Wikipedia article.
We compared all RAG methods under a diverse retrieval environment with various sparse and dense retrievers and number of retrieved documents.
Specifically, we use Contriever-MS MARCO as the retriever for PopQA and TriviaQA, DPR for Natural Questions, GTR for ASQA, and BM25 for 2WikiMultiHopQA.
By default, we retrieve the top 5 documents from the retrieval corpus for each query in all tasks except 2WikiMultiHopQA, where the top 10 documents are retrieved.
We use the official weights for all dense retrievers and the implementation from Pyserini <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib54" title="">54</a>]</cite> for the sparse retriever BM25.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p2">
<p class="ltx_p" id="A1.p2.1"><span class="ltx_text ltx_font_bold" id="A1.p2.1.1">Training details.</span>
Our models are trained on 4 Nvidia H100 GPUs with 80GB memory via full-parameter fine-tuning.
We use fully sharded data parallelism (FSDP) for distributed training, along with
FlashAttention <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib14" title="">14</a>]</cite> and bf16 mixed precision training enabled for computation efficiency.
By default, all models are trained using the Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib45" title="">45</a>]</cite> for 2 epochs, with a batch size of 128, a learning rate of 2.5e-5, and a cosine learning rate schedule with 3% warmup steps.
For the trainable baseline vanilla SFT, we use a slightly different learning rate of 2e-5 based on our hyper-parameter search results.
To fairly compare with Self-RAG and RetRobust, we re-implement them using Llama-3-Instruct-8B.
We also optimize their performance through an extensive hyper-parameter search with learning rates in [8e-6, 1e-5, 2e-5] and training epochs in [1, 2, 3].
For Self-RAG, we use a learning rate of 1e-5 with a single training epoch.
For RetRobust, we use a learning rate of 2e-5 with two training epochs.
The only exception is the training for RetRobust on 2WikiMultiHopQA, where we train the model for 5 epochs on the augmented training set released by the original authors.
The maximum token length for all models is fixed at 4096.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p3">
<p class="ltx_p" id="A1.p3.1"><span class="ltx_text ltx_font_bold" id="A1.p3.1.1">Inference details.</span> By default, the number of demonstrations used in <span class="ltx_text ltx_font_smallcaps" id="A1.p3.1.2">InstructRAG</span>-ICL and the baseline method few-shot demonstration with instruction is set to be 2.
We use vLLM <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib48" title="">48</a>]</cite> to load models for memory-efficient inference and adopt the greedy decoding strategy for model generation.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Case Study</h2>
<figure class="ltx_figure" id="A2.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel" id="A2.F5.sf1">
<p class="ltx_p ltx_align_center" id="A2.F5.sf1.1"><span class="ltx_text" id="A2.F5.sf1.1.1" style="position:relative; bottom:0.6pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="405" id="A2.F5.sf1.1.1.g1" src="x9.png" width="830"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F5.sf1.3.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="A2.F5.sf1.4.2" style="font-size:90%;">Vanilla SFT. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel" id="A2.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="405" id="A2.F5.sf2.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F5.sf2.3.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text ltx_font_smallcaps" id="A2.F5.sf2.4.2" style="font-size:90%;">InstructRAG<span class="ltx_text ltx_font_upright" id="A2.F5.sf2.4.2.1">-FT. </span></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="A2.F5.3.2" style="font-size:90%;">Visualization of model attention from answer to retrieved documents on a random sample from the ASQA task, where Doc 2 is the only relevant document that contains the correct answer. </span></figcaption>
</figure>
<figure class="ltx_figure" id="A2.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="396" id="A2.F6.1.g1" src="x11.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F6.4.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="A2.F6.5.2" style="font-size:90%;">A case study of <span class="ltx_text ltx_font_smallcaps" id="A2.F6.5.2.1">InstructRAG</span>-FT compared with in-context RALM and vanilla SFT. The red texts denote irrelevant or inaccurate model generations, while the green texts denote contents relevant to the question. This study shows that our model can effectively identify relevant information from noisy input and leverage its own knowledge to correctly answer questions when required.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.p1.1.1">Attention visualization.</span>
To intuitively understand the denoising process of our <span class="ltx_text ltx_font_smallcaps" id="A2.p1.1.2">InstructRAG</span>, we visualize its attention from the answer to retrieved documents.
As pointed out by a recent work <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#bib.bib106" title="">106</a>]</cite>, only attention distributions from deep layers can accurately reflect the LM’s retrieval behavior and focus on key information, while attention from shallow layers usually do not imply meaningful patterns.
Therefore, we only plot the attention weights of the last 10 layers (Layer 22 to Layer 31).
As presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A2.F5" title="Figure 5 ‣ Appendix B Case Study ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">5</span></a>, our model accurately identifies the only benign document from noisy input, showing a strong denoising signal compared to vanilla SFT.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.p2">
<p class="ltx_p" id="A2.p2.1"><span class="ltx_text ltx_font_bold" id="A2.p2.1.1">Generation comparison.</span> Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A2.F6" title="Figure 6 ‣ Appendix B Case Study ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">6</span></a> compares the generated responses of in-context RALM, vanilla SFT, and our <span class="ltx_text ltx_font_smallcaps" id="A2.p2.1.2">InstructRAG</span>-FT for an actual question from the ASQA task.
Among them, only our method can correctly answer this question while providing comprehensive denoising details.
Specifically, it first identifies potentially relevant documents from noisy inputs, and then lays out the candidate information.
More encouragingly, we find that <span class="ltx_text ltx_font_smallcaps" id="A2.p2.1.3">InstructRAG</span>-FT is able to refer to its own parametric knowledge when no relevant document is present in the context after denoising, demonstrating its superiority over existing RAG approaches.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prompt Templates</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">In this work, we instantiate the proposed <span class="ltx_text ltx_font_smallcaps" id="A3.p1.1.1">InstructRAG</span> with off-the-shelf instruction-tuned LMs (<span class="ltx_text ltx_font_slanted" id="A3.p1.1.2">i.e.</span>, <a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" title="">meta-llama/Meta-Llama-3-8B-Instruct</a> and <a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct" title="">meta-llama/Meta-Llama-3-70B-Instruct</a>), and apply the official <a class="ltx_ref ltx_href" href="https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3" title="">Meta-Llama-3-Instruct chat template</a> (marked in gray) in all prompts.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.p2">
<p class="ltx_p" id="A3.p2.1"><span class="ltx_text ltx_font_bold" id="A3.p2.1.1">Rationale generation.</span> Below are the prompt templates for rationale generation used in all five tasks.
Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T6" title="Table 6 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">6</span></a> shows the rationale template used in the ablation study.
For simplicity, we use the same prompt structure (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T7" title="Table 7 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">7</span></a>) for all tasks with minor differences in task-specific instructions (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T8" title="Table 8 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">8</span></a>).</p>
</div>
<figure class="ltx_table" id="A3.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T6.2.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="A3.T6.3.2" style="font-size:90%;">Rationale template used in ablation study.</span></figcaption><svg class="ltx_picture" height="121.61" id="A3.T6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,121.61) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 116.29 C 0 119.23 2.38 121.61 5.32 121.61 L 594.68 121.61 C 597.62 121.61 600 119.23 600 116.29 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 92.71 L 598.62 92.71 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 94.09 L 1.38 116.29 C 1.38 118.47 3.15 120.23 5.32 120.23 L 594.68 120.23 C 596.85 120.23 598.62 118.47 598.62 116.29 L 598.62 94.09 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 101.01)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T6.pic1.1.1.1.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T6.pic1.1.1.1.1.1.1">Rationale Template</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="77.49" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T6.pic1.2.2.2.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T6.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T6.pic1.2.2.2.1.1.1.1" style="font-size:80%;">Positive Template:<span class="ltx_text ltx_font_medium" id="A3.T6.pic1.2.2.2.1.1.1.1.1"> After reviewing the provided document, I found that only documents {documents} contain relevant information to answer the question. Based on my knowledge and the provided contents, the answer is: {answer}.
<br class="ltx_break"/>
<br class="ltx_break"/></span>Negative Template:<span class="ltx_text ltx_font_medium" id="A3.T6.pic1.2.2.2.1.1.1.1.2"> After reviewing the provided document, I found that none of them contain relevant information to answer the question. Based on my knowledge and the provided contents, the answer is: {answer}.</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<figure class="ltx_table" id="A3.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T7.2.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="A3.T7.3.2" style="font-size:90%;">Rationale generation prompt template.</span></figcaption><svg class="ltx_picture" height="268.36" id="A3.T7.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,268.36) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 263.04 C 0 265.98 2.38 268.36 5.32 268.36 L 594.68 268.36 C 597.62 268.36 600 265.98 600 263.04 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 242.15 L 598.62 242.15 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 243.53 L 1.38 263.04 C 1.38 265.21 3.15 266.98 5.32 266.98 L 594.68 266.98 C 596.85 266.98 598.62 265.21 598.62 263.04 L 598.62 243.53 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 250.45)"><foreignobject color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T7.pic1.3.3.3.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T7.pic1.3.3.3.1.1.1">Rationale Generation</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="226.93" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_p" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="font-size:80%;">Input:<span class="ltx_text ltx_font_medium" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2"> &lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
<br class="ltx_break"/>Read the following documents relevant to the given question: {question} 
<br class="ltx_break"/>
<br class="ltx_break"/>Document [1] (Title: <math alttext="\dotsm" class="ltx_Math" display="inline" id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">⋯</annotation></semantics></math>): {contents}
<br class="ltx_break"/><math alttext="~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm" class="ltx_Math" display="inline" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1"><semantics id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">⋯</annotation></semantics></math>
<br class="ltx_break"/>Please identify documents that are useful to answer the given question: “{question}”, and explain how the contents lead to the answer: {answer}.
<br class="ltx_break"/>
<br class="ltx_break"/>If none of the documents is aligned with the answer, in that case, you have to explain the answer only based on your own knowledge, without referring to the provided information.
<br class="ltx_break"/>
<br class="ltx_break"/></span>{task-specific instruction}<span class="ltx_text ltx_font_medium" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3">&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;
<br class="ltx_break"/>
<br class="ltx_break"/></span>Output:<span class="ltx_text ltx_font_medium" id="A3.T7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.4"> {rationale}</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<figure class="ltx_table" id="A3.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T8.2.1.1" style="font-size:90%;">Table 8</span>: </span><span class="ltx_text" id="A3.T8.3.2" style="font-size:90%;">Task-specific instruction used in rationale generation prompt.</span></figcaption><svg class="ltx_picture" height="203.4" id="A3.T8.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,203.4) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 198.08 C 0 201.02 2.38 203.4 5.32 203.4 L 594.68 203.4 C 597.62 203.4 600 201.02 600 198.08 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 174.5 L 598.62 174.5 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 175.88 L 1.38 198.08 C 1.38 200.26 3.15 202.02 5.32 202.02 L 594.68 202.02 C 596.85 202.02 598.62 200.26 598.62 198.08 L 598.62 175.88 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 182.8)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T8.pic1.1.1.1.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T8.pic1.1.1.1.1.1.1">Task-specific Instruction for Rationale Generation</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="159.28" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T8.pic1.2.2.2.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T8.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T8.pic1.2.2.2.1.1.1.1" style="font-size:80%;">ASQA:<span class="ltx_text ltx_font_medium" id="A3.T8.pic1.2.2.2.1.1.1.1.1"> Note that the question may be ambiguous and have multiple correct answers. Make sure your response includes all correct answers and provides clear reasoning details followed by a concise conclusion.
<br class="ltx_break"/>
<br class="ltx_break"/></span>PopQA:<span class="ltx_text ltx_font_medium" id="A3.T8.pic1.2.2.2.1.1.1.1.2"> Note that the question mainly asks about the object entity that holds a certain relationship with the given subject entity. There may be multiple correct answers. Make sure your response includes all correct answers and provides clear reasoning details followed by a concise conclusion.
<br class="ltx_break"/>
<br class="ltx_break"/></span>TriviaQA / Natural Questions / 2WikiMultiHopQA:<span class="ltx_text ltx_font_medium" id="A3.T8.pic1.2.2.2.1.1.1.1.3"> Note that the question may be compositional and require intermediate analysis to deduce the final answer. Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="A3.p3">
<p class="ltx_p" id="A3.p3.2"><span class="ltx_text ltx_font_bold" id="A3.p3.2.1">Inference prompts</span>. Below we present the inference prompts for both training-free and trainable RAG methods used in this work, including in-context RALM (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T9" title="Table 9 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">9</span></a>), few-shot demonstrations with instruction (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T10" title="Table 10 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">10</span></a>), and vanilla supervised fine-tuning (Table <a class="ltx_ref" href="https://arxiv.org/html/2406.13629v2#A3.T11" title="Table 11 ‣ Appendix C Prompt Templates ‣ InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales"><span class="ltx_text ltx_ref_tag">11</span></a>).
Note that for a fair comparison, the inference prompt for our <span class="ltx_text ltx_font_smallcaps" id="A3.p3.2.2">InstructRAG</span>-FT is exactly the same as vanilla SFT.
Similarly, the inference prompt for <span class="ltx_text ltx_font_smallcaps" id="A3.p3.2.3">InstructRAG</span>-ICL shares the same inference instruction as the few-shot demonstrations with instruction.
The only difference between the prompts of these two methods lies in the demonstrations where <span class="ltx_text ltx_font_smallcaps" id="A3.p3.2.4">InstructRAG</span>-ICL employs denoising question-rationale <math alttext="{\mbox{$\langle$}q,r\mbox{$\rangle$}}" class="ltx_Math" display="inline" id="A3.p3.1.m1.4"><semantics id="A3.p3.1.m1.4a"><mrow id="A3.p3.1.m1.4.5.2" xref="A3.p3.1.m1.4.5.1.cmml"><mo id="A3.p3.1.m1.4.5.2.1" stretchy="false" xref="A3.p3.1.m1.4.5.1.cmml">⟨</mo><mi id="A3.p3.1.m1.3.3" xref="A3.p3.1.m1.3.3.cmml">q</mi><mo id="A3.p3.1.m1.4.5.2.2" xref="A3.p3.1.m1.4.5.1.cmml">,</mo><mi id="A3.p3.1.m1.4.4" xref="A3.p3.1.m1.4.4.cmml">r</mi><mo id="A3.p3.1.m1.4.5.2.3" stretchy="false" xref="A3.p3.1.m1.4.5.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p3.1.m1.4b"><list id="A3.p3.1.m1.4.5.1.cmml" xref="A3.p3.1.m1.4.5.2"><ci id="A3.p3.1.m1.3.3.cmml" xref="A3.p3.1.m1.3.3">𝑞</ci><ci id="A3.p3.1.m1.4.4.cmml" xref="A3.p3.1.m1.4.4">𝑟</ci></list></annotation-xml><annotation encoding="application/x-tex" id="A3.p3.1.m1.4c">{\mbox{$\langle$}q,r\mbox{$\rangle$}}</annotation><annotation encoding="application/x-llamapun" id="A3.p3.1.m1.4d">⟨ italic_q , italic_r ⟩</annotation></semantics></math> pairs, while few-shot demonstrations with instruction uses plain question-answer <math alttext="{\mbox{$\langle$}q,a\mbox{$\rangle$}}" class="ltx_Math" display="inline" id="A3.p3.2.m2.4"><semantics id="A3.p3.2.m2.4a"><mrow id="A3.p3.2.m2.4.5.2" xref="A3.p3.2.m2.4.5.1.cmml"><mo id="A3.p3.2.m2.4.5.2.1" stretchy="false" xref="A3.p3.2.m2.4.5.1.cmml">⟨</mo><mi id="A3.p3.2.m2.3.3" xref="A3.p3.2.m2.3.3.cmml">q</mi><mo id="A3.p3.2.m2.4.5.2.2" xref="A3.p3.2.m2.4.5.1.cmml">,</mo><mi id="A3.p3.2.m2.4.4" xref="A3.p3.2.m2.4.4.cmml">a</mi><mo id="A3.p3.2.m2.4.5.2.3" stretchy="false" xref="A3.p3.2.m2.4.5.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p3.2.m2.4b"><list id="A3.p3.2.m2.4.5.1.cmml" xref="A3.p3.2.m2.4.5.2"><ci id="A3.p3.2.m2.3.3.cmml" xref="A3.p3.2.m2.3.3">𝑞</ci><ci id="A3.p3.2.m2.4.4.cmml" xref="A3.p3.2.m2.4.4">𝑎</ci></list></annotation-xml><annotation encoding="application/x-tex" id="A3.p3.2.m2.4c">{\mbox{$\langle$}q,a\mbox{$\rangle$}}</annotation><annotation encoding="application/x-llamapun" id="A3.p3.2.m2.4d">⟨ italic_q , italic_a ⟩</annotation></semantics></math> pairs.</p>
</div>
<figure class="ltx_table" id="A3.T9">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T9.2.1.1" style="font-size:90%;">Table 9</span>: </span><span class="ltx_text" id="A3.T9.3.2" style="font-size:90%;">Inference prompt for In-Context RALM.</span></figcaption><svg class="ltx_picture" height="151.98" id="A3.T9.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,151.98) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 146.66 C 0 149.59 2.38 151.98 5.32 151.98 L 594.68 151.98 C 597.62 151.98 600 149.59 600 146.66 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 125.92 L 598.62 125.92 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 127.3 L 1.38 146.66 C 1.38 148.83 3.15 150.59 5.32 150.59 L 594.68 150.59 C 596.85 150.59 598.62 148.83 598.62 146.66 L 598.62 127.3 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 134.22)"><foreignobject color="#FFFFFF" height="9.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T9.pic1.3.3.3.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T9.pic1.3.3.3.1.1.1">In-Context RALM</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="110.7" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_p" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="font-size:80%;">Input:<span class="ltx_text ltx_font_medium" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
<br class="ltx_break"/>Document [1] (Title: <math alttext="\dotsm" class="ltx_Math" display="inline" id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T9.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">⋯</annotation></semantics></math>): {contents}
<br class="ltx_break"/><math alttext="~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm" class="ltx_Math" display="inline" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1"><semantics id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">⋯</annotation></semantics></math>
<br class="ltx_break"/>Based on your knowledge and the provided information, answer the question: {question}
<br class="ltx_break"/>&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;

<br class="ltx_break"/>
<br class="ltx_break"/></span>Output:<span class="ltx_text ltx_font_medium" id="A3.T9.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3"> {answer}</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<figure class="ltx_table" id="A3.T10">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T10.3.1.1" style="font-size:90%;">Table 10</span>: </span><span class="ltx_text" id="A3.T10.4.2" style="font-size:90%;">Inference prompt for <span class="ltx_text ltx_font_smallcaps" id="A3.T10.4.2.1">InstructRAG</span>-ICL and few-shot demonstrations with instruction.</span></figcaption><svg class="ltx_picture" height="289.19" id="A3.T10.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,289.19) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 283.87 C 0 286.81 2.38 289.19 5.32 289.19 L 594.68 289.19 C 597.62 289.19 600 286.81 600 283.87 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 258.75 L 598.62 258.75 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 260.14 L 1.38 283.87 C 1.38 286.05 3.15 287.81 5.32 287.81 L 594.68 287.81 C 596.85 287.81 598.62 286.05 598.62 283.87 L 598.62 260.14 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 267.05)"><foreignobject color="#FFFFFF" height="13.84" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T10.pic1.7.7.7.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T10.pic1.7.7.7.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="A3.T10.pic1.7.7.7.1.1.1.1">InstructRAG</span>-ICL / Few-shot Demonstrations with instruction</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="243.53" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" style="width:421.6pt;">
<span class="ltx_p" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6"><span class="ltx_text ltx_font_bold" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" style="font-size:80%;">Input:<span class="ltx_text ltx_font_medium" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6">
&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
<br class="ltx_break"/>Your task is to analyze the provided documents and answer the given question. Please generate a brief explanation of how the contents of these documents lead to your answer. If the provided information is not helpful to answer the question, you only need to respond based on your own knowledge, without referring to the documents.
<br class="ltx_break"/>
<br class="ltx_break"/>Below are some examples of how to answer the question:
<br class="ltx_break"/>{example question <math alttext="q_{1}" class="ltx_Math" display="inline" id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">q</mi><mn id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">𝑞</ci><cn id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">q_{1}</annotation><annotation encoding="application/x-llamapun" id="A3.T10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>}
<br class="ltx_break"/>{example answer <math alttext="a_{1}" class="ltx_Math" display="inline" id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1"><semantics id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><msub id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml"><mi id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.2" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.2.cmml">a</mi><mn id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.3" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><apply id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.1.cmml" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">subscript</csymbol><ci id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.2.cmml" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.2">𝑎</ci><cn id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.3.cmml" type="integer" xref="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">a_{1}</annotation><annotation encoding="application/x-llamapun" id="A3.T10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> / rationale <math alttext="r_{1}" class="ltx_Math" display="inline" id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1"><semantics id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a"><msub id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml">r</mi><mn id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><apply id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.1.cmml" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">subscript</csymbol><ci id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2">𝑟</ci><cn id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml" type="integer" xref="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">r_{1}</annotation><annotation encoding="application/x-llamapun" id="A3.T10.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1d">italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>}
<br class="ltx_break"/><math alttext="~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm" class="ltx_Math" display="inline" id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1"><semantics id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1a"><mi id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1" mathvariant="normal" xref="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1b"><ci id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml" xref="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1c">~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T10.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1d">⋯</annotation></semantics></math>
<br class="ltx_break"/>Document [1] (Title: <math alttext="\dotsm" class="ltx_Math" display="inline" id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1"><semantics id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1a"><mi id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1" mathvariant="normal" xref="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1b"><ci id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1.cmml" xref="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1c">\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T10.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m5.1d">⋯</annotation></semantics></math>): {contents}
<br class="ltx_break"/><math alttext="~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm" class="ltx_Math" display="inline" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1"><semantics id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1a"><mi id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1" mathvariant="normal" xref="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1b"><ci id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1.cmml" xref="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1c">~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m6.1d">⋯</annotation></semantics></math>
<br class="ltx_break"/>Based on your knowledge and the provided information, answer the question: {question}
<br class="ltx_break"/>&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;

<br class="ltx_break"/>
<br class="ltx_break"/></span>Output:<span class="ltx_text ltx_font_medium" id="A3.T10.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.7"> {answer}</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<figure class="ltx_table" id="A3.T11">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A3.T11.3.1.1" style="font-size:90%;">Table 11</span>: </span><span class="ltx_text" id="A3.T11.4.2" style="font-size:90%;">Inference prompt for <span class="ltx_text ltx_font_smallcaps" id="A3.T11.4.2.1">InstructRAG</span>-FT and vanilla supervised fine-tuning.</span></figcaption><svg class="ltx_picture" height="156.36" id="A3.T11.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,156.36) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 151.04 C 0 153.98 2.38 156.36 5.32 156.36 L 594.68 156.36 C 597.62 156.36 600 153.98 600 151.04 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 125.92 L 598.62 125.92 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 127.3 L 1.38 151.04 C 1.38 153.21 3.15 154.97 5.32 154.97 L 594.68 154.97 C 596.85 154.97 598.62 153.21 598.62 151.04 L 598.62 127.3 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 134.22)"><foreignobject color="#FFFFFF" height="13.84" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T11.pic1.3.3.3.1.1" style="width:421.6pt;">
<span class="ltx_p" id="A3.T11.pic1.3.3.3.1.1.1"><span class="ltx_text ltx_font_smallcaps" id="A3.T11.pic1.3.3.3.1.1.1.1">InstructRAG</span>-FT / Vanilla Supervised Fine-tuning</span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject color="#000000" height="110.7" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_p" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="font-size:80%;">Input:<span class="ltx_text ltx_font_medium" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2"> &lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
<br class="ltx_break"/>Document [1] (Title: <math alttext="\dotsm" class="ltx_Math" display="inline" id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">⋯</annotation></semantics></math>): {contents}
<br class="ltx_break"/><math alttext="~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm" class="ltx_Math" display="inline" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1"><semantics id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\dotsm</annotation><annotation encoding="application/x-llamapun" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">⋯</annotation></semantics></math>
<br class="ltx_break"/>Based on your knowledge and the provided information, answer the question: {question}
<br class="ltx_break"/>&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt; 
<br class="ltx_break"/>
<br class="ltx_break"/></span>Output:<span class="ltx_text ltx_font_medium" id="A3.T11.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3"> {answer}</span></span></span>
</span></foreignobject></g></g></svg>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Aug 20 15:40:31 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
