<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language</title>
<!--Generated on Thu May 30 12:17:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.18350v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S1" title="In Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S2" title="In Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Literature review</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3" title="In Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Evaluation Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS1" title="In 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS2" title="In 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Evaluation Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS2.SSS1" title="In 3.2 Evaluation Metrics â€£ 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Normalized Discounted Cumulative Gain (nDCG)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS2.SSS2" title="In 3.2 Evaluation Metrics â€£ 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Mean Reciprocal Rank (MRR)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS2.SSS3" title="In 3.2 Evaluation Metrics â€£ 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Mean Average Precision (mAP)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS3" title="In 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Semantic Search Approach</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS3.SSS1" title="In 3.3 Semantic Search Approach â€£ 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Assessment of Encoders</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS4" title="In 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>RAG Evaluation Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS4.SSS1" title="In 3.4 RAG Evaluation Setup â€£ 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.1 </span>Dataset Creation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S3.SS4.SSS2" title="In 3.4 RAG Evaluation Setup â€£ 3 Evaluation Methodology â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.2 </span>RAG Pipeline Implementation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S4" title="In Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S4.SS1" title="In 4 Results â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Semantic Search Evaluation results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S4.SS2" title="In 4 Results â€£ Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Correlation between Semantic search accuracy and RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#S5" title="In Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ali Mahboub, Muhy Eddin Zaâ€™ter, Bashar Al-Rfooh, Yazan Estaitia, Adnan Jaljuli, Asma Hakouz 
<br class="ltx_break"/>Maqsam 
<br class="ltx_break"/>Amman, Jordan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{ali.mahbob, muhyeddin, bashar.alrfooh, yazan.estaitia, adnan.jaljuli, asma}@maqsam.com</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">The latest advancements in machine learning and deep learning have brought forth the concept of semantic similarity, which has proven immensely beneficial in multiple applications and has largely replaced keyword search. However, evaluating semantic similarity and conducting searches for a specific query across various documents continue to be a complicated task. This complexity is due to the multifaceted nature of the task, the lack of standard benchmarks, whereas these challenges are further amplified for Arabic language. This paper endeavors to establish a straightforward yet potent benchmark for semantic search in Arabic. Moreover, to precisely evaluate the effectiveness of these metrics and the dataset, we conduct our assessment of semantic search within the framework of retrieval augmented generation (RAG).</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.2"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="p1.2.1">K</em><span class="ltx_text ltx_font_bold" id="p1.2.2">eywords</span>â€‚Semantic Search Â <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.1.m1.1"><semantics id="p1.1.m1.1a"><mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p1.1.m1.1d">â‹…</annotation></semantics></math>
Retrieved Augmented Generation (RAG) Â <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.2.m2.1"><semantics id="p1.2.m2.1a"><mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">\cdot</annotation><annotation encoding="application/x-llamapun" id="p1.2.m2.1d">â‹…</annotation></semantics></math>
Arabic Natural Language Processing</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The abundance of information has driven the development of semantic search technologies that surpass traditional keyword-based search engines by understanding the context and intent of user queries through natural language processing (NLP) and machine learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib1" title="">1</a>]</cite>. Unlike conventional search methods that focus on matching keywords, semantic search interprets the meaning and relationships between words, aiming to mimic human understanding. This advancement enhances user experience across various applications, including web search engines, knowledge discovery, and personalized content recommendation systems, and most recently Retriever-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib2" title="">2</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">RAG represents an innovative approach at the crossroads of information retrieval and natural language generation, leveraging the strengths of both fields to refine Artificial Intelligence (AI) based systems ability to comprehend and generate human-like text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib4" title="">4</a>]</cite>. By combining a sophisticated retrieval mechanism with a powerful generation model, RAG systems can produce detailed, contextually relevant responses that significantly improve standalone language models limitations in terms of precision and human-like generation. The integration of semantic search into RAG systems is crucial, particularly for processing complex queries or those requiring deep contextual understanding, making it a cornerstone for enhancing retrieval accuracy and the quality of generated content.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Similar to the majority of research endeavors and NLP tasks, the Arabic language semantic search and RAG lags behind other languages due to the challenges posed by the Arabic language, including its complex morphology the diversity of its dialects and the shortage of datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib6" title="">6</a>]</cite>. The above-mentioned challenges underscore the need for NLP techniques and studies tailored to Arabic in the context of semantic search and RAG systems. This paper aims to evaluate semantic searchÅ› effectiveness in processing Arabic alongside its impact on the performance of RAG systems specifically designed for Arabic Question Answering use-case. By evaluating the effect of different text encoders on the performance of RAG systems, the study seeks to provide insights into optimizing NLP applications for Arabic-speaking users and advancing the development of linguistically inclusive AI systems.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The rest of the paper is presented as follows; section 2 presents a simple overview of the previous literature, followed by section 3 which describes the methodology and experiment designed to evaluate the semantic search in context of RAG, while section 4 presents the results and the discussion finally followed by the conclusion.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Literature review</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The evolution of semantic search can be traced back to before the widespread adoption of machine learning, initially relying on keyword-based methods and statistical techniques like latent semantic indexing (LSI) in the late 1990s <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib7" title="">7</a>]</cite>. These early methods aimed to understand document similarity beyond exact keyword matches, setting the stage for more sophisticated approaches.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In the 2000s, machine learning transformed semantic search with algorithms like support vector machines (SVMs)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib8" title="">8</a>]</cite>, moving beyond keyword matching to a deeper understanding of queries through the use of more advanced and sophisticated textual features. However, these techniques had their limitations regarding the contextual meaning it is capable of grasping, therefore more advanced technique that are capable of leveraging the increasing influx of data were required.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Therefore, deep learning was introduced to semantic search which marked a significant milestone, with techniques like Word2Vec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib9" title="">9</a>]</cite> and GloVe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib10" title="">10</a>]</cite> enhancing the understanding of word relationships through unsupervised learning of huge corpus. This era also saw the development of advanced neural networks based architecture, such as attention mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib11" title="">11</a>]</cite> and transformers (e.g., BERT, GPT)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib12" title="">12</a>]</cite>, revolutionizing the field by enabling a deeper grasp of query intent and contextual relevance, which played a pivotal role the advancements of deep learning.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Parallel to the advancements of text encoders using deep learning, the use of approximate nearest neighbors (ANN) techniques became crucial for semantic search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib13" title="">13</a>]</cite>. ANN algorithms, emerging in the early 2010s, facilitated efficient similarity search in high-dimensional spaces, essential for managing the vast data processed by deep learning models, which allowed users to replace slow unscalable techniques such as cosine similarity.
The integration of ANN with state-of-the-art language models has continuously improved of semantic search, enhancing its scalability and efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib14" title="">14</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Significant progress has been made in Arabic semantic search thanks to deep learning technologies, especially with the creation of Arabic-focused encoders employing various frameworks like Word2Vec and Transformer-based models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib17" title="">17</a>]</cite>. Additionally, incorporating Arabic into universal encoders has also proved beneficial, utilizing patterns from other languages to improve understanding. This study highlights the effectiveness of using advanced deep learning methods to better grasp the semantic nuances of Arabic inquiries, leading to high precision in recognizing comparable questions in a customer support setting.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Conversely, RAGâ€”Retrieved Augmented Generationâ€”remains an emerging field within the burgeoning domain of generative artificial intelligence. The particular challenges associated with Arabic, such as its complex morphology and the relative paucity of resources, have hindered the attention and research it has received. Arabic RAG has not yet emerged as a focal point of scholarly inquiry to the degree that perhaps it warrants <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.18350v2#bib.bib19" title="">19</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">This study endeavors to assess the current landscape of semantic search capabilities within the Arabic language, addressing the notable lack of benchmarks and baseline data. Additionally, we seek to explore the impact of semantic search on the efficacy of retrieved augmented generation, positing that enhanced search mechanisms could significantly bolster the generation process.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Evaluation Methodology</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we present the procedures employed for the evaluation of various semantic search modules. Our methodological framework is structured around three core components: dataset generation, evaluation metrics, and the configuration of semantic search modules.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset Generation</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The structure of the dataset required for the effective evaluation of semantic search ranking is pivotal. The dataset needs to encompass:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">A collection of documents, which, in our study, consist of Arabic summaries of customer support calls for real-world companies.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">A set of user search queries, where each query is associated with all or a subset of the documents.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">A relevance score or label for each (query, document) pair, indicating the documentÅ› relevance to the query. This can be a binary label (relevant/irrelevant) or a score value with higher scores indicating higher relevance.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">To circumvent the resource-intensive process of data collection and labeling, we leverage the capabilities of Large Language Models (LLMs), notably GPT-4, to generate search queries that:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Mimic realistic searches as might be conducted by customer support agents.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Assign each query to a set of five summaries.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1">Assign a relevance label/score to each (query, document) pair, with the scoring system of (irrelevant, somewhat relevant, very relevant) designated as (0, 1, 2) respectively.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">A prompt was devised to meet these requirements and to generate an Arabic search query for every set of five summaries, ensuring that at least one summary is highly relevant.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1">The evaluation dataset comprises 2030 customer support call summaries and 406 search queries. A manual inspection of 10% of the dataset (205 summaries with 41 queries) revealed only 2 misclassifications between very relevant and irrelevant summaries, suggesting the dataset is in a highly accurate state. Further validation on another set of randomized samples confirmed the datasetÅ› robustness, qualifying it for semantic search evaluation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation Metrics</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Assessing the proficiency and effectiveness of various semantic search methodologies necessitates the use of specific evaluation metrics. Our attention centers on the pivotal metrics: Normalized Discounted Cumulative Gain (nDCG), Mean Reciprocal Rank (MRR), and Mean Average Precision (mAP). Each metric is integral to an in-depth evaluation of the ability of semantic search methods to accurately retrieve and rank documents. The formulas for calculating these metrics are delineated below:</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Normalized Discounted Cumulative Gain (nDCG)</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">This metric quantifies the ranking efficacy across search outputs, considering the varying degrees of relevance each document holds. It takes into account the weighted relevance of documents, giving precedence to those at the top of the list. A superior nDCG value signifies that documents of relevance are appropriately prioritized in the rankings, thus underscoring the significance of their order in the search results. The nDCG is calculated using the following equation:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="nDCG@k=\frac{DCG@k}{IDCG@k}" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mrow id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">n</mi><mo id="S3.E1.m1.1.1.2.1" xref="S3.E1.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml">D</mi><mo id="S3.E1.m1.1.1.2.1a" xref="S3.E1.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.2.4" xref="S3.E1.m1.1.1.2.4.cmml">C</mi><mo id="S3.E1.m1.1.1.2.1b" xref="S3.E1.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.2.5" xref="S3.E1.m1.1.1.2.5.cmml">G</mi><mo id="S3.E1.m1.1.1.2.1c" xref="S3.E1.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.2.6" mathvariant="normal" xref="S3.E1.m1.1.1.2.6.cmml">@</mi><mo id="S3.E1.m1.1.1.2.1d" xref="S3.E1.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.2.7" xref="S3.E1.m1.1.1.2.7.cmml">k</mi></mrow><mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">=</mo><mfrac id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2" xref="S3.E1.m1.1.1.3.2.2.cmml">D</mi><mo id="S3.E1.m1.1.1.3.2.1" xref="S3.E1.m1.1.1.3.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml">C</mi><mo id="S3.E1.m1.1.1.3.2.1a" xref="S3.E1.m1.1.1.3.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.2.4" xref="S3.E1.m1.1.1.3.2.4.cmml">G</mi><mo id="S3.E1.m1.1.1.3.2.1b" xref="S3.E1.m1.1.1.3.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.2.5" mathvariant="normal" xref="S3.E1.m1.1.1.3.2.5.cmml">@</mi><mo id="S3.E1.m1.1.1.3.2.1c" xref="S3.E1.m1.1.1.3.2.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.2.6" xref="S3.E1.m1.1.1.3.2.6.cmml">k</mi></mrow><mrow id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml">I</mi><mo id="S3.E1.m1.1.1.3.3.1" xref="S3.E1.m1.1.1.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml">D</mi><mo id="S3.E1.m1.1.1.3.3.1a" xref="S3.E1.m1.1.1.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.3.4" xref="S3.E1.m1.1.1.3.3.4.cmml">C</mi><mo id="S3.E1.m1.1.1.3.3.1b" xref="S3.E1.m1.1.1.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.3.5" xref="S3.E1.m1.1.1.3.3.5.cmml">G</mi><mo id="S3.E1.m1.1.1.3.3.1c" xref="S3.E1.m1.1.1.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.3.6" mathvariant="normal" xref="S3.E1.m1.1.1.3.3.6.cmml">@</mi><mo id="S3.E1.m1.1.1.3.3.1d" xref="S3.E1.m1.1.1.3.3.1.cmml">â¢</mo><mi id="S3.E1.m1.1.1.3.3.7" xref="S3.E1.m1.1.1.3.3.7.cmml">k</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"><times id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.2.1"></times><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">ğ‘›</ci><ci id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3">ğ·</ci><ci id="S3.E1.m1.1.1.2.4.cmml" xref="S3.E1.m1.1.1.2.4">ğ¶</ci><ci id="S3.E1.m1.1.1.2.5.cmml" xref="S3.E1.m1.1.1.2.5">ğº</ci><ci id="S3.E1.m1.1.1.2.6.cmml" xref="S3.E1.m1.1.1.2.6">@</ci><ci id="S3.E1.m1.1.1.2.7.cmml" xref="S3.E1.m1.1.1.2.7">ğ‘˜</ci></apply><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><divide id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3"></divide><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><times id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2.1"></times><ci id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2">ğ·</ci><ci id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3">ğ¶</ci><ci id="S3.E1.m1.1.1.3.2.4.cmml" xref="S3.E1.m1.1.1.3.2.4">ğº</ci><ci id="S3.E1.m1.1.1.3.2.5.cmml" xref="S3.E1.m1.1.1.3.2.5">@</ci><ci id="S3.E1.m1.1.1.3.2.6.cmml" xref="S3.E1.m1.1.1.3.2.6">ğ‘˜</ci></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><times id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2">ğ¼</ci><ci id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3">ğ·</ci><ci id="S3.E1.m1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.3.3.4">ğ¶</ci><ci id="S3.E1.m1.1.1.3.3.5.cmml" xref="S3.E1.m1.1.1.3.3.5">ğº</ci><ci id="S3.E1.m1.1.1.3.3.6.cmml" xref="S3.E1.m1.1.1.3.3.6">@</ci><ci id="S3.E1.m1.1.1.3.3.7.cmml" xref="S3.E1.m1.1.1.3.3.7">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">nDCG@k=\frac{DCG@k}{IDCG@k}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">italic_n italic_D italic_C italic_G @ italic_k = divide start_ARG italic_D italic_C italic_G @ italic_k end_ARG start_ARG italic_I italic_D italic_C italic_G @ italic_k end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.1">where <math alttext="DCG@k" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.1.m1.1"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mrow id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">D</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml">C</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1a" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.4" xref="S3.SS2.SSS1.p3.1.m1.1.1.4.cmml">G</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1b" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.5" mathvariant="normal" xref="S3.SS2.SSS1.p3.1.m1.1.1.5.cmml">@</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1c" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.6" xref="S3.SS2.SSS1.p3.1.m1.1.1.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><times id="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1"></times><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2">ğ·</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3">ğ¶</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.4.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.4">ğº</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.5.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.5">@</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.6.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.6">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">DCG@k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.1.m1.1d">italic_D italic_C italic_G @ italic_k</annotation></semantics></math> (Discounted Cumulative Gain at rank k) is defined as:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="DCG@k=\sum_{i=1}^{k}\frac{2^{rel_{i}}-1}{\log_{2}(i+1)}" class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.3" xref="S3.E2.m1.2.3.cmml"><mrow id="S3.E2.m1.2.3.2" xref="S3.E2.m1.2.3.2.cmml"><mi id="S3.E2.m1.2.3.2.2" xref="S3.E2.m1.2.3.2.2.cmml">D</mi><mo id="S3.E2.m1.2.3.2.1" xref="S3.E2.m1.2.3.2.1.cmml">â¢</mo><mi id="S3.E2.m1.2.3.2.3" xref="S3.E2.m1.2.3.2.3.cmml">C</mi><mo id="S3.E2.m1.2.3.2.1a" xref="S3.E2.m1.2.3.2.1.cmml">â¢</mo><mi id="S3.E2.m1.2.3.2.4" xref="S3.E2.m1.2.3.2.4.cmml">G</mi><mo id="S3.E2.m1.2.3.2.1b" xref="S3.E2.m1.2.3.2.1.cmml">â¢</mo><mi id="S3.E2.m1.2.3.2.5" mathvariant="normal" xref="S3.E2.m1.2.3.2.5.cmml">@</mi><mo id="S3.E2.m1.2.3.2.1c" xref="S3.E2.m1.2.3.2.1.cmml">â¢</mo><mi id="S3.E2.m1.2.3.2.6" xref="S3.E2.m1.2.3.2.6.cmml">k</mi></mrow><mo id="S3.E2.m1.2.3.1" rspace="0.111em" xref="S3.E2.m1.2.3.1.cmml">=</mo><mrow id="S3.E2.m1.2.3.3" xref="S3.E2.m1.2.3.3.cmml"><munderover id="S3.E2.m1.2.3.3.1" xref="S3.E2.m1.2.3.3.1.cmml"><mo id="S3.E2.m1.2.3.3.1.2.2" movablelimits="false" xref="S3.E2.m1.2.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.2.3.3.1.2.3" xref="S3.E2.m1.2.3.3.1.2.3.cmml"><mi id="S3.E2.m1.2.3.3.1.2.3.2" xref="S3.E2.m1.2.3.3.1.2.3.2.cmml">i</mi><mo id="S3.E2.m1.2.3.3.1.2.3.1" xref="S3.E2.m1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.3.3.1.2.3.3" xref="S3.E2.m1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.2.3.3.1.3" xref="S3.E2.m1.2.3.3.1.3.cmml">k</mi></munderover><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml"><msup id="S3.E2.m1.2.2.4.2" xref="S3.E2.m1.2.2.4.2.cmml"><mn id="S3.E2.m1.2.2.4.2.2" xref="S3.E2.m1.2.2.4.2.2.cmml">2</mn><mrow id="S3.E2.m1.2.2.4.2.3" xref="S3.E2.m1.2.2.4.2.3.cmml"><mi id="S3.E2.m1.2.2.4.2.3.2" xref="S3.E2.m1.2.2.4.2.3.2.cmml">r</mi><mo id="S3.E2.m1.2.2.4.2.3.1" xref="S3.E2.m1.2.2.4.2.3.1.cmml">â¢</mo><mi id="S3.E2.m1.2.2.4.2.3.3" xref="S3.E2.m1.2.2.4.2.3.3.cmml">e</mi><mo id="S3.E2.m1.2.2.4.2.3.1a" xref="S3.E2.m1.2.2.4.2.3.1.cmml">â¢</mo><msub id="S3.E2.m1.2.2.4.2.3.4" xref="S3.E2.m1.2.2.4.2.3.4.cmml"><mi id="S3.E2.m1.2.2.4.2.3.4.2" xref="S3.E2.m1.2.2.4.2.3.4.2.cmml">l</mi><mi id="S3.E2.m1.2.2.4.2.3.4.3" xref="S3.E2.m1.2.2.4.2.3.4.3.cmml">i</mi></msub></mrow></msup><mo id="S3.E2.m1.2.2.4.1" xref="S3.E2.m1.2.2.4.1.cmml">âˆ’</mo><mn id="S3.E2.m1.2.2.4.3" xref="S3.E2.m1.2.2.4.3.cmml">1</mn></mrow><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.3.cmml"><msub id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.2.cmml">log</mi><mn id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.3.cmml">2</mn></msub><mo id="S3.E2.m1.2.2.2.2a" xref="S3.E2.m1.2.2.2.3.cmml">â¡</mo><mrow id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.3.cmml"><mo id="S3.E2.m1.2.2.2.2.2.2" stretchy="false" xref="S3.E2.m1.2.2.2.3.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.2.1.cmml"><mi id="S3.E2.m1.2.2.2.2.2.1.2" xref="S3.E2.m1.2.2.2.2.2.1.2.cmml">i</mi><mo id="S3.E2.m1.2.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.2.1.1.cmml">+</mo><mn id="S3.E2.m1.2.2.2.2.2.1.3" xref="S3.E2.m1.2.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="S3.E2.m1.2.2.2.2.2.3" stretchy="false" xref="S3.E2.m1.2.2.2.3.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.3.cmml" xref="S3.E2.m1.2.3"><eq id="S3.E2.m1.2.3.1.cmml" xref="S3.E2.m1.2.3.1"></eq><apply id="S3.E2.m1.2.3.2.cmml" xref="S3.E2.m1.2.3.2"><times id="S3.E2.m1.2.3.2.1.cmml" xref="S3.E2.m1.2.3.2.1"></times><ci id="S3.E2.m1.2.3.2.2.cmml" xref="S3.E2.m1.2.3.2.2">ğ·</ci><ci id="S3.E2.m1.2.3.2.3.cmml" xref="S3.E2.m1.2.3.2.3">ğ¶</ci><ci id="S3.E2.m1.2.3.2.4.cmml" xref="S3.E2.m1.2.3.2.4">ğº</ci><ci id="S3.E2.m1.2.3.2.5.cmml" xref="S3.E2.m1.2.3.2.5">@</ci><ci id="S3.E2.m1.2.3.2.6.cmml" xref="S3.E2.m1.2.3.2.6">ğ‘˜</ci></apply><apply id="S3.E2.m1.2.3.3.cmml" xref="S3.E2.m1.2.3.3"><apply id="S3.E2.m1.2.3.3.1.cmml" xref="S3.E2.m1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.1.1.cmml" xref="S3.E2.m1.2.3.3.1">superscript</csymbol><apply id="S3.E2.m1.2.3.3.1.2.cmml" xref="S3.E2.m1.2.3.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.3.1.2.1.cmml" xref="S3.E2.m1.2.3.3.1">subscript</csymbol><sum id="S3.E2.m1.2.3.3.1.2.2.cmml" xref="S3.E2.m1.2.3.3.1.2.2"></sum><apply id="S3.E2.m1.2.3.3.1.2.3.cmml" xref="S3.E2.m1.2.3.3.1.2.3"><eq id="S3.E2.m1.2.3.3.1.2.3.1.cmml" xref="S3.E2.m1.2.3.3.1.2.3.1"></eq><ci id="S3.E2.m1.2.3.3.1.2.3.2.cmml" xref="S3.E2.m1.2.3.3.1.2.3.2">ğ‘–</ci><cn id="S3.E2.m1.2.3.3.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.3.3.1.3.cmml" xref="S3.E2.m1.2.3.3.1.3">ğ‘˜</ci></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><apply id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4"><minus id="S3.E2.m1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.4.1"></minus><apply id="S3.E2.m1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.4.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.4.2.1.cmml" xref="S3.E2.m1.2.2.4.2">superscript</csymbol><cn id="S3.E2.m1.2.2.4.2.2.cmml" type="integer" xref="S3.E2.m1.2.2.4.2.2">2</cn><apply id="S3.E2.m1.2.2.4.2.3.cmml" xref="S3.E2.m1.2.2.4.2.3"><times id="S3.E2.m1.2.2.4.2.3.1.cmml" xref="S3.E2.m1.2.2.4.2.3.1"></times><ci id="S3.E2.m1.2.2.4.2.3.2.cmml" xref="S3.E2.m1.2.2.4.2.3.2">ğ‘Ÿ</ci><ci id="S3.E2.m1.2.2.4.2.3.3.cmml" xref="S3.E2.m1.2.2.4.2.3.3">ğ‘’</ci><apply id="S3.E2.m1.2.2.4.2.3.4.cmml" xref="S3.E2.m1.2.2.4.2.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.4.2.3.4.1.cmml" xref="S3.E2.m1.2.2.4.2.3.4">subscript</csymbol><ci id="S3.E2.m1.2.2.4.2.3.4.2.cmml" xref="S3.E2.m1.2.2.4.2.3.4.2">ğ‘™</ci><ci id="S3.E2.m1.2.2.4.2.3.4.3.cmml" xref="S3.E2.m1.2.2.4.2.3.4.3">ğ‘–</ci></apply></apply></apply><cn id="S3.E2.m1.2.2.4.3.cmml" type="integer" xref="S3.E2.m1.2.2.4.3">1</cn></apply><apply id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1">subscript</csymbol><log id="S3.E2.m1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.2"></log><cn id="S3.E2.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E2.m1.1.1.1.1.1.3">2</cn></apply><apply id="S3.E2.m1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1"><plus id="S3.E2.m1.2.2.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1"></plus><ci id="S3.E2.m1.2.2.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.2">ğ‘–</ci><cn id="S3.E2.m1.2.2.2.2.2.1.3.cmml" type="integer" xref="S3.E2.m1.2.2.2.2.2.1.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">DCG@k=\sum_{i=1}^{k}\frac{2^{rel_{i}}-1}{\log_{2}(i+1)}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_D italic_C italic_G @ italic_k = âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG 2 start_POSTSUPERSCRIPT italic_r italic_e italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT - 1 end_ARG start_ARG roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_i + 1 ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p5">
<p class="ltx_p" id="S3.SS2.SSS1.p5.3">and <math alttext="IDCG@k" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p5.1.m1.1"><semantics id="S3.SS2.SSS1.p5.1.m1.1a"><mrow id="S3.SS2.SSS1.p5.1.m1.1.1" xref="S3.SS2.SSS1.p5.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p5.1.m1.1.1.2" xref="S3.SS2.SSS1.p5.1.m1.1.1.2.cmml">I</mi><mo id="S3.SS2.SSS1.p5.1.m1.1.1.1" xref="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p5.1.m1.1.1.3" xref="S3.SS2.SSS1.p5.1.m1.1.1.3.cmml">D</mi><mo id="S3.SS2.SSS1.p5.1.m1.1.1.1a" xref="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p5.1.m1.1.1.4" xref="S3.SS2.SSS1.p5.1.m1.1.1.4.cmml">C</mi><mo id="S3.SS2.SSS1.p5.1.m1.1.1.1b" xref="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p5.1.m1.1.1.5" xref="S3.SS2.SSS1.p5.1.m1.1.1.5.cmml">G</mi><mo id="S3.SS2.SSS1.p5.1.m1.1.1.1c" xref="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p5.1.m1.1.1.6" mathvariant="normal" xref="S3.SS2.SSS1.p5.1.m1.1.1.6.cmml">@</mi><mo id="S3.SS2.SSS1.p5.1.m1.1.1.1d" xref="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p5.1.m1.1.1.7" xref="S3.SS2.SSS1.p5.1.m1.1.1.7.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p5.1.m1.1b"><apply id="S3.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1"><times id="S3.SS2.SSS1.p5.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.1"></times><ci id="S3.SS2.SSS1.p5.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.2">ğ¼</ci><ci id="S3.SS2.SSS1.p5.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.3">ğ·</ci><ci id="S3.SS2.SSS1.p5.1.m1.1.1.4.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.4">ğ¶</ci><ci id="S3.SS2.SSS1.p5.1.m1.1.1.5.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.5">ğº</ci><ci id="S3.SS2.SSS1.p5.1.m1.1.1.6.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.6">@</ci><ci id="S3.SS2.SSS1.p5.1.m1.1.1.7.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1.7">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p5.1.m1.1c">IDCG@k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p5.1.m1.1d">italic_I italic_D italic_C italic_G @ italic_k</annotation></semantics></math> is the ideal DCG at k, representing the optimal ranking which maps to the maximum possible DCG up to position k, ensuring a fair comparison by normalizing the score. <math alttext="rel_{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p5.2.m2.1"><semantics id="S3.SS2.SSS1.p5.2.m2.1a"><mrow id="S3.SS2.SSS1.p5.2.m2.1.1" xref="S3.SS2.SSS1.p5.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p5.2.m2.1.1.2" xref="S3.SS2.SSS1.p5.2.m2.1.1.2.cmml">r</mi><mo id="S3.SS2.SSS1.p5.2.m2.1.1.1" xref="S3.SS2.SSS1.p5.2.m2.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS1.p5.2.m2.1.1.3" xref="S3.SS2.SSS1.p5.2.m2.1.1.3.cmml">e</mi><mo id="S3.SS2.SSS1.p5.2.m2.1.1.1a" xref="S3.SS2.SSS1.p5.2.m2.1.1.1.cmml">â¢</mo><msub id="S3.SS2.SSS1.p5.2.m2.1.1.4" xref="S3.SS2.SSS1.p5.2.m2.1.1.4.cmml"><mi id="S3.SS2.SSS1.p5.2.m2.1.1.4.2" xref="S3.SS2.SSS1.p5.2.m2.1.1.4.2.cmml">l</mi><mi id="S3.SS2.SSS1.p5.2.m2.1.1.4.3" xref="S3.SS2.SSS1.p5.2.m2.1.1.4.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p5.2.m2.1b"><apply id="S3.SS2.SSS1.p5.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1"><times id="S3.SS2.SSS1.p5.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.1"></times><ci id="S3.SS2.SSS1.p5.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S3.SS2.SSS1.p5.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.3">ğ‘’</ci><apply id="S3.SS2.SSS1.p5.2.m2.1.1.4.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p5.2.m2.1.1.4.1.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.4">subscript</csymbol><ci id="S3.SS2.SSS1.p5.2.m2.1.1.4.2.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.4.2">ğ‘™</ci><ci id="S3.SS2.SSS1.p5.2.m2.1.1.4.3.cmml" xref="S3.SS2.SSS1.p5.2.m2.1.1.4.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p5.2.m2.1c">rel_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p5.2.m2.1d">italic_r italic_e italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the graded relevance of the result at position <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p5.3.m3.1"><semantics id="S3.SS2.SSS1.p5.3.m3.1a"><mi id="S3.SS2.SSS1.p5.3.m3.1.1" xref="S3.SS2.SSS1.p5.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p5.3.m3.1b"><ci id="S3.SS2.SSS1.p5.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p5.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p5.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p5.3.m3.1d">italic_i</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Mean Reciprocal Rank (MRR)</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">MRR centers on the ranking of the first highly relevant document for a given search query, offering insights into the speed at which the ranking system is able to locate and display the most pertinent information. The calculation is as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="MRR=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{rank_{i}}" class="ltx_Math" display="block" id="S3.E3.m1.2"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.3" xref="S3.E3.m1.2.3.cmml"><mrow id="S3.E3.m1.2.3.2" xref="S3.E3.m1.2.3.2.cmml"><mi id="S3.E3.m1.2.3.2.2" xref="S3.E3.m1.2.3.2.2.cmml">M</mi><mo id="S3.E3.m1.2.3.2.1" xref="S3.E3.m1.2.3.2.1.cmml">â¢</mo><mi id="S3.E3.m1.2.3.2.3" xref="S3.E3.m1.2.3.2.3.cmml">R</mi><mo id="S3.E3.m1.2.3.2.1a" xref="S3.E3.m1.2.3.2.1.cmml">â¢</mo><mi id="S3.E3.m1.2.3.2.4" xref="S3.E3.m1.2.3.2.4.cmml">R</mi></mrow><mo id="S3.E3.m1.2.3.1" xref="S3.E3.m1.2.3.1.cmml">=</mo><mrow id="S3.E3.m1.2.3.3" xref="S3.E3.m1.2.3.3.cmml"><mfrac id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mn id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml">1</mn><mrow id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.2.cmml"><mo id="S3.E3.m1.1.1.1.3.1" stretchy="false" xref="S3.E3.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">Q</mi><mo id="S3.E3.m1.1.1.1.3.2" stretchy="false" xref="S3.E3.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S3.E3.m1.2.3.3.1" xref="S3.E3.m1.2.3.3.1.cmml">â¢</mo><mrow id="S3.E3.m1.2.3.3.2" xref="S3.E3.m1.2.3.3.2.cmml"><munderover id="S3.E3.m1.2.3.3.2.1" xref="S3.E3.m1.2.3.3.2.1.cmml"><mo id="S3.E3.m1.2.3.3.2.1.2.2" movablelimits="false" xref="S3.E3.m1.2.3.3.2.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.2.3.3.2.1.2.3" xref="S3.E3.m1.2.3.3.2.1.2.3.cmml"><mi id="S3.E3.m1.2.3.3.2.1.2.3.2" xref="S3.E3.m1.2.3.3.2.1.2.3.2.cmml">i</mi><mo id="S3.E3.m1.2.3.3.2.1.2.3.1" xref="S3.E3.m1.2.3.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E3.m1.2.3.3.2.1.2.3.3" xref="S3.E3.m1.2.3.3.2.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.2.2.1.2.cmml"><mo id="S3.E3.m1.2.2.1.3.1" stretchy="false" xref="S3.E3.m1.2.2.1.2.1.cmml">|</mo><mi id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml">Q</mi><mo id="S3.E3.m1.2.2.1.3.2" stretchy="false" xref="S3.E3.m1.2.2.1.2.1.cmml">|</mo></mrow></munderover><mfrac id="S3.E3.m1.2.3.3.2.2" xref="S3.E3.m1.2.3.3.2.2.cmml"><mn id="S3.E3.m1.2.3.3.2.2.2" xref="S3.E3.m1.2.3.3.2.2.2.cmml">1</mn><mrow id="S3.E3.m1.2.3.3.2.2.3" xref="S3.E3.m1.2.3.3.2.2.3.cmml"><mi id="S3.E3.m1.2.3.3.2.2.3.2" xref="S3.E3.m1.2.3.3.2.2.3.2.cmml">r</mi><mo id="S3.E3.m1.2.3.3.2.2.3.1" xref="S3.E3.m1.2.3.3.2.2.3.1.cmml">â¢</mo><mi id="S3.E3.m1.2.3.3.2.2.3.3" xref="S3.E3.m1.2.3.3.2.2.3.3.cmml">a</mi><mo id="S3.E3.m1.2.3.3.2.2.3.1a" xref="S3.E3.m1.2.3.3.2.2.3.1.cmml">â¢</mo><mi id="S3.E3.m1.2.3.3.2.2.3.4" xref="S3.E3.m1.2.3.3.2.2.3.4.cmml">n</mi><mo id="S3.E3.m1.2.3.3.2.2.3.1b" xref="S3.E3.m1.2.3.3.2.2.3.1.cmml">â¢</mo><msub id="S3.E3.m1.2.3.3.2.2.3.5" xref="S3.E3.m1.2.3.3.2.2.3.5.cmml"><mi id="S3.E3.m1.2.3.3.2.2.3.5.2" xref="S3.E3.m1.2.3.3.2.2.3.5.2.cmml">k</mi><mi id="S3.E3.m1.2.3.3.2.2.3.5.3" xref="S3.E3.m1.2.3.3.2.2.3.5.3.cmml">i</mi></msub></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.3.cmml" xref="S3.E3.m1.2.3"><eq id="S3.E3.m1.2.3.1.cmml" xref="S3.E3.m1.2.3.1"></eq><apply id="S3.E3.m1.2.3.2.cmml" xref="S3.E3.m1.2.3.2"><times id="S3.E3.m1.2.3.2.1.cmml" xref="S3.E3.m1.2.3.2.1"></times><ci id="S3.E3.m1.2.3.2.2.cmml" xref="S3.E3.m1.2.3.2.2">ğ‘€</ci><ci id="S3.E3.m1.2.3.2.3.cmml" xref="S3.E3.m1.2.3.2.3">ğ‘…</ci><ci id="S3.E3.m1.2.3.2.4.cmml" xref="S3.E3.m1.2.3.2.4">ğ‘…</ci></apply><apply id="S3.E3.m1.2.3.3.cmml" xref="S3.E3.m1.2.3.3"><times id="S3.E3.m1.2.3.3.1.cmml" xref="S3.E3.m1.2.3.3.1"></times><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><divide id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1"></divide><cn id="S3.E3.m1.1.1.3.cmml" type="integer" xref="S3.E3.m1.1.1.3">1</cn><apply id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.3"><abs id="S3.E3.m1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.3.1"></abs><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">ğ‘„</ci></apply></apply><apply id="S3.E3.m1.2.3.3.2.cmml" xref="S3.E3.m1.2.3.3.2"><apply id="S3.E3.m1.2.3.3.2.1.cmml" xref="S3.E3.m1.2.3.3.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.3.3.2.1.1.cmml" xref="S3.E3.m1.2.3.3.2.1">superscript</csymbol><apply id="S3.E3.m1.2.3.3.2.1.2.cmml" xref="S3.E3.m1.2.3.3.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.3.3.2.1.2.1.cmml" xref="S3.E3.m1.2.3.3.2.1">subscript</csymbol><sum id="S3.E3.m1.2.3.3.2.1.2.2.cmml" xref="S3.E3.m1.2.3.3.2.1.2.2"></sum><apply id="S3.E3.m1.2.3.3.2.1.2.3.cmml" xref="S3.E3.m1.2.3.3.2.1.2.3"><eq id="S3.E3.m1.2.3.3.2.1.2.3.1.cmml" xref="S3.E3.m1.2.3.3.2.1.2.3.1"></eq><ci id="S3.E3.m1.2.3.3.2.1.2.3.2.cmml" xref="S3.E3.m1.2.3.3.2.1.2.3.2">ğ‘–</ci><cn id="S3.E3.m1.2.3.3.2.1.2.3.3.cmml" type="integer" xref="S3.E3.m1.2.3.3.2.1.2.3.3">1</cn></apply></apply><apply id="S3.E3.m1.2.2.1.2.cmml" xref="S3.E3.m1.2.2.1.3"><abs id="S3.E3.m1.2.2.1.2.1.cmml" xref="S3.E3.m1.2.2.1.3.1"></abs><ci id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1">ğ‘„</ci></apply></apply><apply id="S3.E3.m1.2.3.3.2.2.cmml" xref="S3.E3.m1.2.3.3.2.2"><divide id="S3.E3.m1.2.3.3.2.2.1.cmml" xref="S3.E3.m1.2.3.3.2.2"></divide><cn id="S3.E3.m1.2.3.3.2.2.2.cmml" type="integer" xref="S3.E3.m1.2.3.3.2.2.2">1</cn><apply id="S3.E3.m1.2.3.3.2.2.3.cmml" xref="S3.E3.m1.2.3.3.2.2.3"><times id="S3.E3.m1.2.3.3.2.2.3.1.cmml" xref="S3.E3.m1.2.3.3.2.2.3.1"></times><ci id="S3.E3.m1.2.3.3.2.2.3.2.cmml" xref="S3.E3.m1.2.3.3.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.E3.m1.2.3.3.2.2.3.3.cmml" xref="S3.E3.m1.2.3.3.2.2.3.3">ğ‘</ci><ci id="S3.E3.m1.2.3.3.2.2.3.4.cmml" xref="S3.E3.m1.2.3.3.2.2.3.4">ğ‘›</ci><apply id="S3.E3.m1.2.3.3.2.2.3.5.cmml" xref="S3.E3.m1.2.3.3.2.2.3.5"><csymbol cd="ambiguous" id="S3.E3.m1.2.3.3.2.2.3.5.1.cmml" xref="S3.E3.m1.2.3.3.2.2.3.5">subscript</csymbol><ci id="S3.E3.m1.2.3.3.2.2.3.5.2.cmml" xref="S3.E3.m1.2.3.3.2.2.3.5.2">ğ‘˜</ci><ci id="S3.E3.m1.2.3.3.2.2.3.5.3.cmml" xref="S3.E3.m1.2.3.3.2.2.3.5.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">MRR=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{rank_{i}}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.2d">italic_M italic_R italic_R = divide start_ARG 1 end_ARG start_ARG | italic_Q | end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_Q | end_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_r italic_a italic_n italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.3">Here, <math alttext="|Q|" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.1.m1.1"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><mrow id="S3.SS2.SSS2.p3.1.m1.1.2.2" xref="S3.SS2.SSS2.p3.1.m1.1.2.1.cmml"><mo id="S3.SS2.SSS2.p3.1.m1.1.2.2.1" stretchy="false" xref="S3.SS2.SSS2.p3.1.m1.1.2.1.1.cmml">|</mo><mi id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml">Q</mi><mo id="S3.SS2.SSS2.p3.1.m1.1.2.2.2" stretchy="false" xref="S3.SS2.SSS2.p3.1.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><apply id="S3.SS2.SSS2.p3.1.m1.1.2.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.2.2"><abs id="S3.SS2.SSS2.p3.1.m1.1.2.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.2.2.1"></abs><ci id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">ğ‘„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">|Q|</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.1.m1.1d">| italic_Q |</annotation></semantics></math> is the total number of queries, and <math alttext="rank_{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.2.m2.1"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><mrow id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.1.1.2" xref="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml">r</mi><mo id="S3.SS2.SSS2.p3.2.m2.1.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS2.p3.2.m2.1.1.3" xref="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml">a</mi><mo id="S3.SS2.SSS2.p3.2.m2.1.1.1a" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS2.p3.2.m2.1.1.4" xref="S3.SS2.SSS2.p3.2.m2.1.1.4.cmml">n</mi><mo id="S3.SS2.SSS2.p3.2.m2.1.1.1b" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml">â¢</mo><msub id="S3.SS2.SSS2.p3.2.m2.1.1.5" xref="S3.SS2.SSS2.p3.2.m2.1.1.5.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.1.1.5.2" xref="S3.SS2.SSS2.p3.2.m2.1.1.5.2.cmml">k</mi><mi id="S3.SS2.SSS2.p3.2.m2.1.1.5.3" xref="S3.SS2.SSS2.p3.2.m2.1.1.5.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><apply id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1"><times id="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1"></times><ci id="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.3">ğ‘</ci><ci id="S3.SS2.SSS2.p3.2.m2.1.1.4.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.4">ğ‘›</ci><apply id="S3.SS2.SSS2.p3.2.m2.1.1.5.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.5"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.1.1.5.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.5">subscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.1.1.5.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.5.2">ğ‘˜</ci><ci id="S3.SS2.SSS2.p3.2.m2.1.1.5.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.5.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">rank_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.2.m2.1d">italic_r italic_a italic_n italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the rank position of the first very relevant document for the <math alttext="i^{th}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.3.m3.1"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><msup id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p3.3.m3.1.1.2" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml">i</mi><mrow id="S3.SS2.SSS2.p3.3.m3.1.1.3" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS2.p3.3.m3.1.1.3.2" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS2.p3.3.m3.1.1.3.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.SSS2.p3.3.m3.1.1.3.3" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><apply id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2">ğ‘–</ci><apply id="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3"><times id="S3.SS2.SSS2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.1"></times><ci id="S3.SS2.SSS2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.SSS2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">i^{th}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.3.m3.1d">italic_i start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> query.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Mean Average Precision (mAP)</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">mAP serves as a comprehensive indicator of precision for all pertinent documents associated with each query, with an average taken across all queries. Higher mAP scores signify the systemÅ› enhanced consistency in identifying and retrieving relevant documents across the entire ranking.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">The equation for the Average Precision (AP) for a single query is:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="AP=\frac{\sum_{k=1}^{n}(P(k)\times rel_{k}}{\text{\# relevant\_documents}}" class="ltx_math_unparsed" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.2"><mrow id="S3.E4.m1.1.2.2"><mi id="S3.E4.m1.1.2.2.2">A</mi><mo id="S3.E4.m1.1.2.2.1">â¢</mo><mi id="S3.E4.m1.1.2.2.3">P</mi></mrow><mo id="S3.E4.m1.1.2.1">=</mo><mfrac id="S3.E4.m1.1.1"><mrow id="S3.E4.m1.1.1.1"><msubsup id="S3.E4.m1.1.1.1.2"><mo id="S3.E4.m1.1.1.1.2.2.2">âˆ‘</mo><mrow id="S3.E4.m1.1.1.1.2.2.3"><mi id="S3.E4.m1.1.1.1.2.2.3.2">k</mi><mo id="S3.E4.m1.1.1.1.2.2.3.1">=</mo><mn id="S3.E4.m1.1.1.1.2.2.3.3">1</mn></mrow><mi id="S3.E4.m1.1.1.1.2.3">n</mi></msubsup><mrow id="S3.E4.m1.1.1.1.3"><mo id="S3.E4.m1.1.1.1.3.1" lspace="0em" stretchy="false">(</mo><mi id="S3.E4.m1.1.1.1.3.2">P</mi><mrow id="S3.E4.m1.1.1.1.3.3"><mo id="S3.E4.m1.1.1.1.3.3.1" stretchy="false">(</mo><mi id="S3.E4.m1.1.1.1.1">k</mi><mo id="S3.E4.m1.1.1.1.3.3.2" rspace="0.055em" stretchy="false">)</mo></mrow><mo id="S3.E4.m1.1.1.1.3.4" rspace="0.222em">Ã—</mo><mi id="S3.E4.m1.1.1.1.3.5">r</mi><mi id="S3.E4.m1.1.1.1.3.6">e</mi><msub id="S3.E4.m1.1.1.1.3.7"><mi id="S3.E4.m1.1.1.1.3.7.2">l</mi><mi id="S3.E4.m1.1.1.1.3.7.3">k</mi></msub></mrow></mrow><mtext id="S3.E4.m1.1.1.3"># relevant_documents</mtext></mfrac></mrow><annotation encoding="application/x-tex" id="S3.E4.m1.1b">AP=\frac{\sum_{k=1}^{n}(P(k)\times rel_{k}}{\text{\# relevant\_documents}}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1c">italic_A italic_P = divide start_ARG âˆ‘ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_P ( italic_k ) Ã— italic_r italic_e italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG start_ARG # relevant_documents end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.5">where:
- <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.1.m1.1"><semantics id="S3.SS2.SSS3.p3.1.m1.1a"><mi id="S3.SS2.SSS3.p3.1.m1.1.1" xref="S3.SS2.SSS3.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.1.m1.1b"><ci id="S3.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.1.m1.1d">italic_n</annotation></semantics></math> is the number of retrieved documents.
- <math alttext="P(k)" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.2.m2.1"><semantics id="S3.SS2.SSS3.p3.2.m2.1a"><mrow id="S3.SS2.SSS3.p3.2.m2.1.2" xref="S3.SS2.SSS3.p3.2.m2.1.2.cmml"><mi id="S3.SS2.SSS3.p3.2.m2.1.2.2" xref="S3.SS2.SSS3.p3.2.m2.1.2.2.cmml">P</mi><mo id="S3.SS2.SSS3.p3.2.m2.1.2.1" xref="S3.SS2.SSS3.p3.2.m2.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.SSS3.p3.2.m2.1.2.3.2" xref="S3.SS2.SSS3.p3.2.m2.1.2.cmml"><mo id="S3.SS2.SSS3.p3.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS2.SSS3.p3.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.SSS3.p3.2.m2.1.1" xref="S3.SS2.SSS3.p3.2.m2.1.1.cmml">k</mi><mo id="S3.SS2.SSS3.p3.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS2.SSS3.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.2.m2.1b"><apply id="S3.SS2.SSS3.p3.2.m2.1.2.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.2"><times id="S3.SS2.SSS3.p3.2.m2.1.2.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.2.1"></times><ci id="S3.SS2.SSS3.p3.2.m2.1.2.2.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.2.2">ğ‘ƒ</ci><ci id="S3.SS2.SSS3.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.2.m2.1c">P(k)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.2.m2.1d">italic_P ( italic_k )</annotation></semantics></math> is the precision at cutoff <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.3.m3.1"><semantics id="S3.SS2.SSS3.p3.3.m3.1a"><mi id="S3.SS2.SSS3.p3.3.m3.1.1" xref="S3.SS2.SSS3.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.3.m3.1b"><ci id="S3.SS2.SSS3.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.3.m3.1d">italic_k</annotation></semantics></math> in the list of retrieved documents.
- <math alttext="rel_{k}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.4.m4.1"><semantics id="S3.SS2.SSS3.p3.4.m4.1a"><mrow id="S3.SS2.SSS3.p3.4.m4.1.1" xref="S3.SS2.SSS3.p3.4.m4.1.1.cmml"><mi id="S3.SS2.SSS3.p3.4.m4.1.1.2" xref="S3.SS2.SSS3.p3.4.m4.1.1.2.cmml">r</mi><mo id="S3.SS2.SSS3.p3.4.m4.1.1.1" xref="S3.SS2.SSS3.p3.4.m4.1.1.1.cmml">â¢</mo><mi id="S3.SS2.SSS3.p3.4.m4.1.1.3" xref="S3.SS2.SSS3.p3.4.m4.1.1.3.cmml">e</mi><mo id="S3.SS2.SSS3.p3.4.m4.1.1.1a" xref="S3.SS2.SSS3.p3.4.m4.1.1.1.cmml">â¢</mo><msub id="S3.SS2.SSS3.p3.4.m4.1.1.4" xref="S3.SS2.SSS3.p3.4.m4.1.1.4.cmml"><mi id="S3.SS2.SSS3.p3.4.m4.1.1.4.2" xref="S3.SS2.SSS3.p3.4.m4.1.1.4.2.cmml">l</mi><mi id="S3.SS2.SSS3.p3.4.m4.1.1.4.3" xref="S3.SS2.SSS3.p3.4.m4.1.1.4.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.4.m4.1b"><apply id="S3.SS2.SSS3.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1"><times id="S3.SS2.SSS3.p3.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.1"></times><ci id="S3.SS2.SSS3.p3.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.2">ğ‘Ÿ</ci><ci id="S3.SS2.SSS3.p3.4.m4.1.1.3.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.3">ğ‘’</ci><apply id="S3.SS2.SSS3.p3.4.m4.1.1.4.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.4.m4.1.1.4.1.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.4">subscript</csymbol><ci id="S3.SS2.SSS3.p3.4.m4.1.1.4.2.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.4.2">ğ‘™</ci><ci id="S3.SS2.SSS3.p3.4.m4.1.1.4.3.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.4.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.4.m4.1c">rel_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.4.m4.1d">italic_r italic_e italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> is the relevancy score of the document at rank <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.5.m5.1"><semantics id="S3.SS2.SSS3.p3.5.m5.1a"><mi id="S3.SS2.SSS3.p3.5.m5.1.1" xref="S3.SS2.SSS3.p3.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.5.m5.1b"><ci id="S3.SS2.SSS3.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p3.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.5.m5.1d">italic_k</annotation></semantics></math> whether it is very relevant, somewhat relevant or irrelevant.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p4">
<p class="ltx_p" id="S3.SS2.SSS3.p4.1">To find the Mean Average Precision (MAP) we average the AP scores across all queries:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="MAP=\frac{\sum_{q=1}^{Q}AP_{q}}{Q}" class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><mrow id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.2.2" xref="S3.E5.m1.1.1.2.2.cmml">M</mi><mo id="S3.E5.m1.1.1.2.1" xref="S3.E5.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3.cmml">A</mi><mo id="S3.E5.m1.1.1.2.1a" xref="S3.E5.m1.1.1.2.1.cmml">â¢</mo><mi id="S3.E5.m1.1.1.2.4" xref="S3.E5.m1.1.1.2.4.cmml">P</mi></mrow><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">=</mo><mfrac id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><mrow id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml"><msubsup id="S3.E5.m1.1.1.3.2.1" xref="S3.E5.m1.1.1.3.2.1.cmml"><mo id="S3.E5.m1.1.1.3.2.1.2.2" xref="S3.E5.m1.1.1.3.2.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.1.1.3.2.1.2.3" xref="S3.E5.m1.1.1.3.2.1.2.3.cmml"><mi id="S3.E5.m1.1.1.3.2.1.2.3.2" xref="S3.E5.m1.1.1.3.2.1.2.3.2.cmml">q</mi><mo id="S3.E5.m1.1.1.3.2.1.2.3.1" xref="S3.E5.m1.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E5.m1.1.1.3.2.1.2.3.3" xref="S3.E5.m1.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E5.m1.1.1.3.2.1.3" xref="S3.E5.m1.1.1.3.2.1.3.cmml">Q</mi></msubsup><mrow id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml"><mi id="S3.E5.m1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.3.2.2.2.cmml">A</mi><mo id="S3.E5.m1.1.1.3.2.2.1" xref="S3.E5.m1.1.1.3.2.2.1.cmml">â¢</mo><msub id="S3.E5.m1.1.1.3.2.2.3" xref="S3.E5.m1.1.1.3.2.2.3.cmml"><mi id="S3.E5.m1.1.1.3.2.2.3.2" xref="S3.E5.m1.1.1.3.2.2.3.2.cmml">P</mi><mi id="S3.E5.m1.1.1.3.2.2.3.3" xref="S3.E5.m1.1.1.3.2.2.3.3.cmml">q</mi></msub></mrow></mrow><mi id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml">Q</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"></eq><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><times id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2.1"></times><ci id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2">ğ‘€</ci><ci id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3">ğ´</ci><ci id="S3.E5.m1.1.1.2.4.cmml" xref="S3.E5.m1.1.1.2.4">ğ‘ƒ</ci></apply><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><divide id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3"></divide><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2"><apply id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.1.1.cmml" xref="S3.E5.m1.1.1.3.2.1">superscript</csymbol><apply id="S3.E5.m1.1.1.3.2.1.2.cmml" xref="S3.E5.m1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.1.2.1.cmml" xref="S3.E5.m1.1.1.3.2.1">subscript</csymbol><sum id="S3.E5.m1.1.1.3.2.1.2.2.cmml" xref="S3.E5.m1.1.1.3.2.1.2.2"></sum><apply id="S3.E5.m1.1.1.3.2.1.2.3.cmml" xref="S3.E5.m1.1.1.3.2.1.2.3"><eq id="S3.E5.m1.1.1.3.2.1.2.3.1.cmml" xref="S3.E5.m1.1.1.3.2.1.2.3.1"></eq><ci id="S3.E5.m1.1.1.3.2.1.2.3.2.cmml" xref="S3.E5.m1.1.1.3.2.1.2.3.2">ğ‘</ci><cn id="S3.E5.m1.1.1.3.2.1.2.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.1.1.3.2.1.3.cmml" xref="S3.E5.m1.1.1.3.2.1.3">ğ‘„</ci></apply><apply id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2"><times id="S3.E5.m1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.1.1.3.2.2.1"></times><ci id="S3.E5.m1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2.2">ğ´</ci><apply id="S3.E5.m1.1.1.3.2.2.3.cmml" xref="S3.E5.m1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.2.3.1.cmml" xref="S3.E5.m1.1.1.3.2.2.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.2.3.2.cmml" xref="S3.E5.m1.1.1.3.2.2.3.2">ğ‘ƒ</ci><ci id="S3.E5.m1.1.1.3.2.2.3.3.cmml" xref="S3.E5.m1.1.1.3.2.2.3.3">ğ‘</ci></apply></apply></apply><ci id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3">ğ‘„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">MAP=\frac{\sum_{q=1}^{Q}AP_{q}}{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_M italic_A italic_P = divide start_ARG âˆ‘ start_POSTSUBSCRIPT italic_q = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT italic_A italic_P start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_ARG start_ARG italic_Q end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p6">
<p class="ltx_p" id="S3.SS2.SSS3.p6.3">where:
- <math alttext="AP_{q}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p6.1.m1.1"><semantics id="S3.SS2.SSS3.p6.1.m1.1a"><mrow id="S3.SS2.SSS3.p6.1.m1.1.1" xref="S3.SS2.SSS3.p6.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p6.1.m1.1.1.2" xref="S3.SS2.SSS3.p6.1.m1.1.1.2.cmml">A</mi><mo id="S3.SS2.SSS3.p6.1.m1.1.1.1" xref="S3.SS2.SSS3.p6.1.m1.1.1.1.cmml">â¢</mo><msub id="S3.SS2.SSS3.p6.1.m1.1.1.3" xref="S3.SS2.SSS3.p6.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p6.1.m1.1.1.3.2" xref="S3.SS2.SSS3.p6.1.m1.1.1.3.2.cmml">P</mi><mi id="S3.SS2.SSS3.p6.1.m1.1.1.3.3" xref="S3.SS2.SSS3.p6.1.m1.1.1.3.3.cmml">q</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p6.1.m1.1b"><apply id="S3.SS2.SSS3.p6.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1"><times id="S3.SS2.SSS3.p6.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.1"></times><ci id="S3.SS2.SSS3.p6.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.2">ğ´</ci><apply id="S3.SS2.SSS3.p6.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p6.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p6.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.3.2">ğ‘ƒ</ci><ci id="S3.SS2.SSS3.p6.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p6.1.m1.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.1.m1.1c">AP_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p6.1.m1.1d">italic_A italic_P start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> is the Average Precision for the <math alttext="q^{th}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p6.2.m2.1"><semantics id="S3.SS2.SSS3.p6.2.m2.1a"><msup id="S3.SS2.SSS3.p6.2.m2.1.1" xref="S3.SS2.SSS3.p6.2.m2.1.1.cmml"><mi id="S3.SS2.SSS3.p6.2.m2.1.1.2" xref="S3.SS2.SSS3.p6.2.m2.1.1.2.cmml">q</mi><mrow id="S3.SS2.SSS3.p6.2.m2.1.1.3" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS3.p6.2.m2.1.1.3.2" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.p6.2.m2.1.1.3.1" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.SSS3.p6.2.m2.1.1.3.3" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p6.2.m2.1b"><apply id="S3.SS2.SSS3.p6.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p6.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS3.p6.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.2">ğ‘</ci><apply id="S3.SS2.SSS3.p6.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.3"><times id="S3.SS2.SSS3.p6.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS3.p6.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.SSS3.p6.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p6.2.m2.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.2.m2.1c">q^{th}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p6.2.m2.1d">italic_q start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> query.
- <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p6.3.m3.1"><semantics id="S3.SS2.SSS3.p6.3.m3.1a"><mi id="S3.SS2.SSS3.p6.3.m3.1.1" xref="S3.SS2.SSS3.p6.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p6.3.m3.1b"><ci id="S3.SS2.SSS3.p6.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p6.3.m3.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.3.m3.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p6.3.m3.1d">italic_Q</annotation></semantics></math> is the total number of queries.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p7">
<p class="ltx_p" id="S3.SS2.SSS3.p7.1">Employing these metrics allows for the evaluation of different methodsâ€™ ranking effectiveness, taking into account essential aspects of accuracy and efficiency in document ranking that reflect their real-world use in semantic search scenarios.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Semantic Search Approach</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">As discussed in the Literature Review section, our evaluation framework is based on the idea of using encoders to convert documents and queries into embedding vectors that capture their content. We then determine the cosine similarity between the embedding vector of a query and those of the documents, ordering the documents based on these similarity scores.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Assessment of Encoders</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">The success of semantic search ranking relies significantly on the caliber of encoders used; higher-quality encoders produce more detailed embedding vectors, which in turn enable more accurate evaluations of similarity between search queries and documents. In our study, we chose encoders that show the best performance for Arabic by comparing their results against those obtained from random document rankings for each query (calculating average evaluation scores from 30 random rankings samples) and against the worst document rankings for each query (where documents are sorted by diminishing relevance to set a benchmark for the lowest achievable scores).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1">Evaluated encoders:</p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">Encoder #1: Paraphrase Mulitlingual MiniLM<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote1.1.1.1">1</span></span><span class="ltx_text ltx_font_medium" id="footnote1.5">https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2</span></span></span></span>:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.I3.i1.p2">
<p class="ltx_p" id="S3.I3.i1.p2.1">This is a multi-lingual embedding model that was taught on 50+ languages covering Arabic and outputs a 384 dimensional embedding vector of the given sentence. It is mainly implemented for clustering and semantic search.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">Encoder #2: Cmlm Multilingual <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote2.1.1.1">2</span></span><span class="ltx_text ltx_font_medium" id="footnote2.5">https://huggingface.co/sentence-transformers/use-cmlm-multilingual</span></span></span></span>:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.I3.i2.p2">
<p class="ltx_p" id="S3.I3.i2.p2.1">It is a universal sentence encoder, that is designed for mapping 109 languages to a common vector space. Leveraging LaBSE as its base model with embedding vector dimension of 768. Trained for multiple downstream tasks.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i3.p1">
<p class="ltx_p" id="S3.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i3.p1.1.1">Encoder #3: Paraphrase Mulitlingual Mpnet <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote3.1.1.1">3</span></span><span class="ltx_text ltx_font_medium" id="footnote3.5">https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2</span></span></span></span>:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.I3.i3.p2">
<p class="ltx_p" id="S3.I3.i3.p2.1">This embedding model maps sentences &amp; paragraphs to a 768 dimensional dense vector space, and it works on 50+ languages including Arabic. Trained for tasks like clustering and semantic similarity.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i4.p1">
<p class="ltx_p" id="S3.I3.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i4.p1.1.1">Encoder #4: Multilingual Distil Bert <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote4.1.1.1">4</span></span><span class="ltx_text ltx_font_medium" id="footnote4.5">https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v1</span></span></span></span>:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.I3.i4.p2">
<p class="ltx_p" id="S3.I3.i4.p2.1">It is an embedding model that operates by mapping sentences to a dense vector space with a dimensionality of 512. It is effective across 15 languages, including Arabic. Can be used for tasks like clustering or semantic search.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para ltx_noindent" id="S3.I3.i5.p1">
<p class="ltx_p" id="S3.I3.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i5.p1.1.1">Encoder #5: Xlm Roberta <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote5.1.1.1">5</span></span><span class="ltx_text ltx_font_medium" id="footnote5.5">https://huggingface.co/symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli</span></span></span></span>:</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.I3.i5.p2">
<p class="ltx_p" id="S3.I3.i5.p2.1">An embedding model that converts texts into a dense vector with 768 dimensions, it works well in Arabic and 12 other languages, it was trained on SNLI, MNLI, ANLI and XNLI corpora.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>RAG Evaluation Setup</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Retrieval-Augmented Generation for Arabic semantic search leverages both retrieval of relevant documents and generation of text to provide answers that are semantically aligned with the userÅ› query. The complete RAG pipeline is shown in figure 1.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="295" id="S3.F1.g1" src="extracted/5632190/Final.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Retrieved-Augmented-Generation with Semantic Search Pipeline</figcaption>
</figure>
<section class="ltx_subsubsection" id="S3.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Dataset Creation</h4>
<div class="ltx_para ltx_noindent" id="S3.SS4.SSS1.p1">
<p class="ltx_p" id="S3.SS4.SSS1.p1.1">In constructing a comprehensive dataset for Retrieval Augmented Generation (RAG), we curated an extensive collection of Frequently Asked Questions (FAQs)from four different domains. This compilation contains a total of 816 distinct questions accompanied by their verifiable answers. To build a test set and ensure its robustness, we employed the advanced capabilities of GPT-4, generating three nuanced variations for each original question. This approach yielded a synthesized dataset, optimally prepared for the subsequent testing of the Retrieval-Augmented Generation (RAG) framework.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>RAG Pipeline Implementation</h4>
<div class="ltx_para ltx_noindent" id="S3.SS4.SSS2.p1">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">The RAG framework was precisely designed to undertake a multi-step process, aiming to test the semantic search capabilities within the Arabic language domain. This process is outlined as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.SSS2.p2">
<ol class="ltx_enumerate" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i1.p1.1.1">Semantic Encoding:</span> Each generated query undergoes a semantic encoding process alongside all ground truth questions of the same domain. This step utilizes a semantic search encoder to identify and retrieve the three closest semantically relative to the input query.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">Knowledge-Based Answer Generation:</span> The answers corresponding to the semantically aligned questions, along with the generated query, are presented to a Large Language Model (LLM). For this purpose, GPT-3.5-turbo was selected to generate responses based on the knowledge extracted from the answers of the identified questions. This phase emphasizes the modelÅ› ability to synthesize and repurpose existing knowledge to address previously unseen queries.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i3.p1">
<p class="ltx_p" id="S3.I4.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i3.p1.1.1">Assessment Phase:</span> To fact checking of the generated responses, a subsequent LLM, specifically GPT-4-turbo, evaluates each response. This step involves comparing the generated answer, the original query, and the ground truth answer, thereby assessing whether the generated response properly addresses the query with the same information as the ground truth answer.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para ltx_noindent" id="S3.I4.i4.p1">
<p class="ltx_p" id="S3.I4.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i4.p1.1.1">Accuracy Calculation:</span> The final stage in the RAG evaluation framework is the quantification of accuracy. This metric is derived by calculating the proportion of queries for which the responses generated by the LLM were correct, based on the criteria established in the assessment phase.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.SSS2.p3">
<p class="ltx_p" id="S3.SS4.SSS2.p3.1">This systematic evaluation presents potential applicability of semantic search methods and comparing their performance to the Arabic RAG pipeline.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This section presents the results for the stand-alone evaluation of semantic search, followed by assessment of the RAG with the different encoders.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Semantic Search Evaluation results</h3>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Semantic Search Evaluation Results</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">NDCG@3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">MRR@3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">mAP @3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.5.1">Emb. Size</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.2.1.1.1">Encoder #1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.2">0.853</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.3">0.888</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.4">0.863</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.5">384</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.3.2.1.1">Encoder #2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.2">0.789</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.3">0.798</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.4">0.793</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.5">768</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.4.3.1.1">Encoder #3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.2">0.879</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.3">0.911</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.4">0.888</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.5">768</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.5.4.1.1">Encoder #4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.2">0.868</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.3">0.89</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.4">0.876</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.5">512</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.5">
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.6.5.1.1">Encoder #5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.2">0.837</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.3">0.848</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.4">0.854</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.5">768</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.6">
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.7.6.1.1">Random Ranking</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.2">0.669</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.3">0.623</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.4">0.703</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.5">â€”</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.7">
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.8.7.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.8.7.1.1">Worst Ranking</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.8.7.2">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.8.7.3">0.138</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.8.7.4">0.401</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.8.7.5">â€”</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">From results represented in Table 1, it is shown that Encoder #3 (paraphrase-multilingual-mpnet-base-v2) is performing best for Arabic semantic search, however it has the largest embedding size which allow it to carry more semantic information, yet require more computational &amp; memory costs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Correlation between Semantic search accuracy and RAG</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>RAG Using GPT-3.5 Evaluation</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">Encoder</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">Top 3 Accuracy</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">Top 1 Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.1.1.1">Encoder #1</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.2">59.31%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.3">61.15%</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.2.1.1">Encoder #2</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.2.2">62.01%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.2.3">63.23%</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.1.1">Encoder #3</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3.2">63.11%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3.3">63.84%</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.4.1.1">Encoder #4</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.4.2">62.5%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.4.3">63.24%</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T2.1.6.5.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.6.5.1.1">Encoder #5</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.5.2">57.84%</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.5.3">N/A</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b" id="S4.T2.1.7.6.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.7.6.1.1">Random Ranking</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.7.6.2">6.62%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.7.6.3">N/A</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In Table 2, some findings were observed. Initially, a minor decline in accuracy from top-1 to top-3 was detected, attributed to GPT-3.5 merging of information from the three outcomes of semantic search and failing to identify the correct answer for a subset of questions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Furthermore, while Encoder #1 demonstrated commendable performance in the Semantic Search Evaluation, its effectiveness diminished in the context of Retrieval Augmented Generation (RAG) evaluation. Contrarily, Encoder #2 exhibited an inverse pattern of performance. This discrepancy can be attributed to the nature of the semantic search evaluation, which closely resembles an <span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Asymmetric Semantic Search</span> scenario, where embeddings of extensive text summaries and brief queries, averaging four words, are compared. On the other hand, the RAG scenario aligns more with a <span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.2">Symmetric Semantic Search</span>, where the queries and the reference questions are nearly equal in length, thereby examining distinct facets and constraints of the semantic search component. The size of the embedding vector also plays a crucial role, as larger vectors can encapsulate more information, potentially enhancing overall performance, particularly for Arabic. This language poses greater challenges in language modeling compared to English.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The analysis presented above clearly demonstrates the viability and significance of incorporating semantic search into the Retrieval Augmented Generation (RAG) system. This integration has notably enhanced the quality and precision of generated content. Furthermore, employing semantic search for the retrieval of documents relevant to a query offers several advantages, such as the use of shorter prompts in terms of tokens. This not only contributes to more precise outcomes but also results in cost-effective and quicker inference. However, further investigations are still required to conclude that superior encoders lead to superior RAG results.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Po-Sen Huang, Xiaodong He, Jianfeng Gao, LiÂ Deng, Alex Acero, and Larry Heck.

</span>
<span class="ltx_bibblock">Learning deep structured semantic models for web search using clickthrough data.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</span>, pages 2333â€“2338, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Chetana Gavankar, Taniya Bhosale, Dhanashree Gunda, Anindita Chavan, and Shafa Hassan.

</span>
<span class="ltx_bibblock">A comparative study of semantic search systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">2020 International Conference on Computer Communication and Informatics (ICCCI)</span>, pages 1â€“7. IEEE, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, YiÂ Dai, Jiawei Sun, and Haofen Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2312.10997</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, etÂ al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Advances in Neural Information Processing Systems</span>, 33:9459â€“9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Khaled Shaalan, Sanjeera Siddiqui, Manar Alkhatib, and Azza AbdelÂ Monem.

</span>
<span class="ltx_bibblock">Challenges in arabic natural language processing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Computational linguistics, speech and image processing for arabic language</span>, pages 59â€“83. World Scientific, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Imane Guellil, Houda SaÃ¢dane, Faical Azouaou, Billel Gueni, and Damien Nouvel.

</span>
<span class="ltx_bibblock">Arabic natural language processing: An overview.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Journal of King Saud University-Computer and Information Sciences</span>, 33(5):497â€“507, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Thomas Hofmann.

</span>
<span class="ltx_bibblock">Probabilistic latent semantic indexing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</span>, pages 50â€“57, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Chung-Hong Lee and Hsin-Chang Yang.

</span>
<span class="ltx_bibblock">A classifier-based text mining approach for evaluating semantic relatedness using support vector machines.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">International Conference on Information Technology: Coding and Computing (ITCCâ€™05)-Volume II</span>, volumeÂ 1, pages 128â€“133. IEEE, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in vector space.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:1301.3781</span>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jeffrey Pennington, Richard Socher, and ChristopherÂ D Manning.

</span>
<span class="ltx_bibblock">Glove: Global vectors for word representation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</span>, pages 1532â€“1543, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Advances in neural information processing systems</span>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Wen Li, Ying Zhang, Yifang Sun, Wei Wang, Mingjie Li, Wenjie Zhang, and Xuemin Lin.

</span>
<span class="ltx_bibblock">Approximate nearest neighbor search on high dimensional dataâ€”experiments, analyses, and improvement.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">IEEE Transactions on Knowledge and Data Engineering</span>, 32(8):1475â€“1488, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel MazarÃ©, Maria Lomeli, Lucas Hosseini, and HervÃ© JÃ©gou.

</span>
<span class="ltx_bibblock">The faiss library.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2401.08281</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Mahmoud Al-Ayyoub, Aya Nuseir, Kholoud Alsmearat, Yaser Jararweh, and Brij Gupta.

</span>
<span class="ltx_bibblock">Deep learning for arabic nlp: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Journal of computational science</span>, 26:522â€“531, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Ons Meddeb, Mohsen Maraoui, and Mounir Zrigui.

</span>
<span class="ltx_bibblock">Deep learning based semantic approach for arabic textual documents recommendation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">2021 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)</span>, pages 1â€“6. IEEE, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
AyaÂ M Al-Zoghby and Khaled Shaalan.

</span>
<span class="ltx_bibblock">Semantic search for arabic.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">The Twenty-Eighth International Flairs Conference</span>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Hazem Abdelazim, Mohamed Tharwat, and Ammar Mohamed.

</span>
<span class="ltx_bibblock">Semantic embeddings for arabic retrieval augmented generation (arag).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.

</span>
<span class="ltx_bibblock">In-context retrieval-augmented language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">Transactions of the Association for Computational Linguistics</span>, 11:1316â€“1331, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu May 30 12:17:25 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
