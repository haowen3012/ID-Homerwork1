<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks</title>
<!--Generated on Mon Jun 24 06:57:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Relation Extraction, 
Language Models, 
Fine-tuning, 
Information Extraction" lang="en" name="keywords"/>
<base href="/html/2406.14745v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S1" title="In Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S2" title="In Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S2.SS1" title="In 2. Related Works ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Relation Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S2.SS2" title="In 2. Related Works ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Fine-Tuning of Large Language Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3" title="In Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.SS1" title="In 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Fine-tuning Language Models for Relation Extraction</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.SS1.SSS1" title="In 3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Prompt Dataset Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.SS1.SSS2" title="In 3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Parameter Efficient Fine-Tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.SS2" title="In 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Retrieval-Augmented Generation alongside Fine-tuned Language Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4" title="In Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1" title="In 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1.SSS1" title="In 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1.SSS2" title="In 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1.SSS3" title="In 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Settings for Fine-tuning Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1.SSS4" title="In 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.4 </span>Setting for Retrieval Augmented Generation-based Relation Extraction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS2" title="In 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS3" title="In 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Discussion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S5" title="In Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sefika Efeoglu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Freie Universitaet Berlin</span><span class="ltx_text ltx_affiliation_streetaddress" id="id2.2.id2">1 Thørväld Circle</span><span class="ltx_text ltx_affiliation_city" id="id3.3.id3">Berlin</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:sefika.efeoglu@fu-berlin.de">sefika.efeoglu@fu-berlin.de</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adrian Paschke
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:adrian.paschke@fokus.fraunhofer.de">adrian.paschke@fokus.fraunhofer.de</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Freie Universitaet Berlin</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Berlin</span><span class="ltx_text ltx_affiliation_country" id="id7.3.id3">Germany</span>
<br class="ltx_break"/><span class="ltx_text ltx_affiliation_institution" id="id8.4.id4">Data Analytic Center (DANA)
<br class="ltx_break"/>Fraunhofer Institute FOKUS</span><span class="ltx_text ltx_affiliation_city" id="id9.5.id5">Berlin</span><span class="ltx_text ltx_affiliation_country" id="id10.6.id6">Germany</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id11.id1">Information Extraction (IE) is crucial for converting unstructured data into structured formats like Knowledge Graphs (KGs). A key task within IE is Relation Extraction (RE), which identifies relationships between entities in text. Various RE methods exist, including supervised, unsupervised, weakly supervised, and rule-based approaches. Recent studies leveraging pre-trained language models (PLMs) have shown significant success in this area. In the current era dominated by Large Language Models (LLMs), fine-tuning these models can overcome limitations associated with zero-shot LLM prompting-based RE methods, especially regarding domain adaptation challenges and identifying implicit relations between entities in sentences. These implicit relations, which cannot be easily extracted from a sentence’s dependency tree, require logical inference for accurate identification. This work explores the performance of fine-tuned LLMs and their integration into the Retrieval Augmented-based (RAG) RE approach to address the challenges of identifying implicit relations at the sentence level, particularly when LLMs act as generators within the RAG framework. Empirical evaluations on the TACRED, TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant performance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B, and T5 (Large). Notably, our approach achieves substantial gains on SemEVAL, where implicit relations are common, surpassing previous results on this dataset. Additionally, our method outperforms previous works on TACRED, TACREV, and Re-TACRED, demonstrating exceptional performance across diverse evaluation scenarios.</p>
</div>
<div class="ltx_keywords">
Relation Extraction,
Language Models,
Fine-tuning,
Information Extraction
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Information Extraction (IE) is a significant process for representing unstructured data in a structured manner, such as Knowledge Graphs (KGs). One of the main tasks of the IE process is Relation Extraction (RE), which aims to identify (implicit or explicit) relations between entities in a given text data at either sentence or document level <cite class="ltx_cite ltx_citemacro_citep">(Grishman, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib12" title="">2015</a>)</cite>. Implicit relations cannot be directly extracted from the sentence’s tokens, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S1.F1" title="In 1. Introduction ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>, whereas the explicit relations between entities can easily be identified by taking into account the dependency tree of the sentence, as demonstrated in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S1.F2" title="In 1. Introduction ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>. Identification of implicit relations between entities requires semantic (or logical) inference, and
Large Language Models (LLMs), while powerful in many respects, lack the capability for logical inference.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="45" id="S1.F1.g1" src="x1.png" width="398"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Illustration of an implicit relation, Entity-Origin(e1,e2), between head (e1) and tail (e2) entities in a sentence from the SemEVAL dataset.</figcaption>
</figure>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="79" id="S1.F2.g1" src="x2.png" width="373"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Representation of an explicit relation, org:founded, between head and tail entities in a sentence from the TACRED dataset.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To identify the relations between entities in the sentence, various approaches, including rule-based, supervised, unsupervised, and weakly supervised RE approaches <cite class="ltx_cite ltx_citemacro_citep">(Aydar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib4" title="">2020</a>; Pawar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib24" title="">2017</a>)</cite>, have been applied so far. Well-performing RE approaches using supervised learning require a large amount of labeled training data. However, they have not achieved better performance compared to pre-trained language model (PLM)-based RE approaches <cite class="ltx_cite ltx_citemacro_citep">(Zhou and Chen, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib32" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib20" title="">2022</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib28" title="">2022</a>)</cite>. In the era of LLMs, various approaches using Retrieval-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib11" title="">2023</a>; Lewis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib19" title="">2020</a>)</cite>, in-context learning <cite class="ltx_cite ltx_citemacro_citep">(Pan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib23" title="">2024</a>)</cite>, and simple vanilla prompting <cite class="ltx_cite ltx_citemacro_citep">(Kai Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a>)</cite> might be applied to extract information from the text corpus without undergoing any model training process.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">RAG-based prompting approach achieves outstanding results when relations between entities can be easily extracted from sentence tokens <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. However, the RAG approach fails when relation types are implicit, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S1.F1" title="In 1. Introduction ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>. General-purpose LLMs, e.g., Mistral <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib16" title="">2023</a>)</cite>, Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib27" title="">2023</a>)</cite> and T5 <cite class="ltx_cite ltx_citemacro_citep">(Chung et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib6" title="">2022</a>)</cite> could not accomplish better performance on implicit relations in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>; Kai Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a>; Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib29" title="">2023</a>)</cite>, since they lack logical inference capabilities and domain knowledge about relation types. Introducing the relation types into the language models might tackle the problems of the RAG4RE approach using general-purpose LLMs <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. Therefore, we propose fine-tuning of language models, namely domain adaptation, to address the problem of identifying implicit relations (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S1.F1" title="In 1. Introduction ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>) between entities at the sentence level.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To evaluate the performance of our approach, we conduct experiments with LLMs, including Llama2-7B <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib27" title="">2023</a>)</cite>, Mistral-7b <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib16" title="">2023</a>)</cite> and T5 Large <cite class="ltx_cite ltx_citemacro_citep">(Chung et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib6" title="">2022</a>)</cite>, on four different RE benchmark datasets: TACRED <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib31" title="">2017</a>)</cite>, TACRED-Revisited (TACREV) <cite class="ltx_cite ltx_citemacro_citep">(Alt et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib3" title="">2020</a>)</cite>, Re-TACRED <cite class="ltx_cite ltx_citemacro_citep">(Stoica et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib26" title="">2021</a>)</cite>, and SemEVAL Task-8 <cite class="ltx_cite ltx_citemacro_citep">(Hendrickx et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib14" title="">2010</a>)</cite>.
In this work, fine-tuning addresses the performance problem of the zero-shot LLM prompting approach (e.g., RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>) in identifying implicit relations, namely semantic or logical relations, between entities in all the benchmark datasets mentioned above.
Our approach’s contributions are as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Fine-tuning mitigates the identification of implicit relation types in the sentence-level RE on SemEVAL.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Fine-tuning yields substantial enhancements in the performance of language models such as Mistral-7B, T5 Large, and Llama2-7B on the aforementioned benchmark datasets.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">This work also compares the performance of fine-tuned LLMs to RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> using fine-tuned LLMs.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">RAG4RE using our fine-tuned LLMs achieved outstanding performance on TACRED, TACREV and Re-TACRED.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The rest of this paper first summarizes language model-based RE approaches in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S2" title="2. Related Works ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2</span></a> and then introduces our proposed approach <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Source code is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sefeoglu/RAG4RE-extension" title="">https://github.com/sefeoglu/RAG4RE-extension</a></span></span></span> in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3" title="3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>. Afterwards, the experimental setup and results are presented and discussed in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4" title="4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>. Lastly, all concluding remarks and future works are summarized in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S5" title="5. Conclusion ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Works</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We categorize recent works into: (i) Relation Extraction and (ii) Fine-Tuning of Large Language Models in this section.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Relation Extraction</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Relation Extraction (RE) is one of the main tasks of IE and plays a significant role among natural language processing tasks. RE aims to identify or classify the relations between head and tail entities in a given text. We mostly focus on sentence-level relation extraction approaches.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">RE can be carried out with various types of approaches, including supervised techniques, unsupervised, distant supervision-based, weakly supervised and rule-based RE techniques <cite class="ltx_cite ltx_citemacro_citep">(Pawar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib24" title="">2017</a>)</cite>. Supervised techniques, needing large annotated datasets, are time-consuming and expensive <cite class="ltx_cite ltx_citemacro_citep">(Pawar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib24" title="">2017</a>)</cite>. Distant supervision, relying on existing knowledge bases, tackles the annotated data issue but suffers from wrongly labeled sentences and noise <cite class="ltx_cite ltx_citemacro_citep">(Aydar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib4" title="">2020</a>)</cite>. Weakly supervised RE is error-prone due to semantic drift in pattern sets per iteration <cite class="ltx_cite ltx_citemacro_citep">(Agichtein and Gravano, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib2" title="">2000</a>)</cite>. Rule-based RE is limited by predefined rules in relation discovery <cite class="ltx_cite ltx_citemacro_citep">(Pawar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib24" title="">2017</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">With respect to best-performing RE approach, based on fine-tuning the language models, Cohen et al. <cite class="ltx_cite ltx_citemacro_citep">(Cohen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib7" title="">2020</a>)</cite> introduced a novel approach for relation classification that utilizes span prediction, rather than relying on a single embedding, to represent the relationships between entities.
DeepStruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib28" title="">2022</a>)</cite> innovates by improving language models’ structural comprehension. With a pretrained model boasting 10 billion parameters, it smoothly transfers language models to structure prediction tasks. For RE, it provides structured output (head entity, relation, tail entity) from input text and entity pairs.
Zhou et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhou and Chen, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib32" title="">2022</a>)</cite> focused on tackling two pivotal challenges that impact the effectiveness of current sentence-level RE models: (i) refining Entity Representation and (ii) mitigating the impact of noisy or ambiguously defined labels. Their method extends the pretraining objective of masked language modeling to encompass entities and integrates an advanced entity-aware self-attention mechanism, thus facilitating more precise and resilient RE outcomes. Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib20" title="">2022</a>)</cite> devised a label graph technique to assess candidate labels within the top-K prediction set and to discern the connections among them. In their methodology for predicting the correct label, they initially ascertain that the top-K prediction set of a given sample contains valuable insights.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">Zhang et al.<cite class="ltx_cite ltx_citemacro_citep">(Kai Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a>)</cite> developed multiple-choice question prompts based on test sentences, featuring entity verbalizations and relation types as choices. Despite falling short of previous rule and ML-based methods, enriching prompt context improved prediction results on datasets like TACRED and Re-TACRED. Melz<cite class="ltx_cite ltx_citemacro_citep">(Melz, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib22" title="">2023</a>)</cite> enhances the RAG approach with Auxiliary Rationale Memory for RE, learning from successes without hefty training costs. Meanwhile, Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib5" title="">2024</a>)</cite> propose a Generative Context-Aware Prompt-tuning method, addressing prompt template engineering. Their prompt generator extracts context-aware tokens from entity pairs, evaluated on TACRED, TACREV, Re-TACRED, and SemEval datasets. RAG4RE<cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> constructs an embedding database from training datasets, regenerates prompts, and inputs them into general-purpose LLMs, especially for RE, evaluated on TACRED, TACREV, Re-TACRED, and SemEVAL benchmark datasets.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Fine-Tuning of Large Language Models</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Undoubtedly, Pretrained Language Models (PLMs) deliver outstanding results across various tasks, including text generation, translation, and question-answering. While zero-shot prompting of Large Language Models (LLMs) often yields impressive outcomes on many downstream tasks, fine-tuning is crucial for adapting LLMs to specific datasets and tasks <cite class="ltx_cite ltx_citemacro_citep">(Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib13" title="">2024</a>)</cite>.
Yang et al. <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib30" title="">2024</a>)</cite> conducted single-task fine-tuning with various settings, demonstrating that this approach outperforms zero-shot LLM prompting. However, their results indicate that single-task fine-tuning is prone to catastrophic forgetting. In contrast, Feng et al. <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib10" title="">2024</a>)</cite> proposed a multi-task fine-tuning method that incorporates a mixture of datasets and LoRAs. Their experiments clearly show that multi-task fine-tuning enhances performance over single-task fine-tuning, particularly with datasets from Finance, Medicine, and WebGPT. Additionally, Liu et al. <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib21" title="">2023</a>)</cite> applied multi-task fine-tuning to generate code from text data using different code-generation language models, such as StarCode, CodeLLama, and CodeGeex2, demonstrating effectiveness across various coding tasks. In addition to these attempts about LLM fine-tuning, there are parameter efficient fine-tuning approaches, which are focusing on only target modules of LLMs and freezing its remaining modules, such as Low Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib15" title="">2021</a>)</cite>, LoRA for quantized language models (QLoRA) <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib8" title="">2023</a>)</cite> and Direct Preference Optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib25" title="">2023</a>)</cite>.
LoRA fine-tunes models by adding trainable rank decomposition matrices to each transformer layer, reducing parameters and GPU memory needs <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib15" title="">2021</a>)</cite>. This approach maintains or improves performance while keeping pre-trained weights frozen.
QLORA <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib8" title="">2023</a>)</cite> introduces innovations to reduce memory use without sacrificing performance, including 4-bit Normal Float for optimal quantization, Double Quantization saving about 0.37 bits per parameter, and Paged Optimizers to manage memory spikes. DPO is a novel algorithm for aligning language models with human preferences without the need for explicit reward modeling or reinforcement learning <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib25" title="">2023</a>)</cite>. By increasing the relative log probability of preferred responses and incorporating dynamic importance weights, DPO effectively prevents model degeneration and simplifies the training process, making it a promising alternative to existing Reinforcement Learning from Human Feedback (RLHF) algorithms.
RLHF <cite class="ltx_cite ltx_citemacro_citep">(Lambert et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib18" title="">2022</a>)</cite> is a variant of reinforcement learning that learns from human input rather than an engineered reward function, enhancing the performance and alignment of intelligent systems with human values.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this work, we aim to address the issue of identifying implicit relations between entities in the sentence when using RAG with an LLM-based generation approach to identify these relations. We propose applying domain adaptation or transfer learning, specifically fine-tuning, to alleviate the weaknesses of general-purpose LLMs in identifying implicit relations between entities in the sentence.
We first introduce our proposed LLM fine-tuning approach for Relation Extraction (RE) in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.SS1" title="3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>, and then integrate the fine-tuned LLMs into the RAG4RE approach to evaluate whether the fine-tuned LLMs improve its results or not in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.SS2" title="3.2. Retrieval-Augmented Generation alongside Fine-tuned Language Models ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Fine-tuning Language Models for Relation Extraction</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We fine-tune both encoder-decoder, i.e., T5 and decoder only, e.g., Llama2-7B and Mistral-7B, LLMs on datasets by leveraging Supervised Fine-tuning Trainer <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>SFT: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/trl/sft_trainer" title="">https://huggingface.co/docs/trl/sft_trainer</a></span></span></span> (SFT), which is a crucial step in Reinforcement Learning from Human Feedback (RLHF), so that domain adaptation is applied to general-purpose LLMs.
SFT requires labeled training data and is easy to integrate and train.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">To leverage only specific parameters of the models for text-to-text generation, Low Rank Adaptation for quantized language models (QLoRA) <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib8" title="">2023</a>)</cite> method is also used to fine-tune LLMs on the datasets (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.F4" title="In 3.1.2. Parameter Efficient Fine-Tuning ‣ 3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>). QLoRA not only reduces the parameters of LLMs but also reduces the memory allocation of LLMs on GPU. Therefore, it is necessary when limited GPU memory resources are available. The format of simple query prompts proposed in RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> is used to prepare the training prompt dataset (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.F3" title="In 3.1.1. Prompt Dataset Generation ‣ 3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>Prompt Dataset Generation</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">The prompt dataset is constructed following the template outlined in a prior work by <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. This dataset is sourced from a single domain and task supervised dataset, utilizing a specific template depicted in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.F3" title="In 3.1.1. Prompt Dataset Generation ‣ 3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a> for fine-tuning purposes.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="215" id="S3.F3.g1" src="x3.png" width="373"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>A prompt template to create a prompt dataset for fine-tuning a language model.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Parameter Efficient Fine-Tuning</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">We leverage QLoRA, one of the parameter-efficient fine-tuning approaches. Firstly, quantization is applied to a pre-trained language model, reducing the high precision floating-point representation into low precision to reduce the memory footprint. This quantization is achieved using “4-bit NormalFloat (NF4)”. 4-bit NormalFloat is an information-theoretically optimal quantization data type, specifically designed for normally distributed data <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib8" title="">2023</a>)</cite>. This innovative format surpasses the performance of traditional 4-bit Integers and 4-bit Floats, delivering superior empirical results in a variety of applications <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib8" title="">2023</a>)</cite>. Afterwards, LoRA, focusing on targeted modules of the pre-trained language model, is added into the 4-bit quantized pre-trained language model. The fine-tuning process is carried out by using the Supervised Fine-Tuning Trainer (SFT). The model is fine-tuned on a single domain and task prompt dataset. <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.F4" title="In 3.1.2. Parameter Efficient Fine-Tuning ‣ 3.1. Fine-tuning Language Models for Relation Extraction ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a> illustrates how the pre-trained language model is fine-tuned along with QLoRA and SFT on a prompt dataset.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="277" id="S3.F4.g1" src="x4.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Fine-tuning a pre-trained model on a prompt dataset alongside the QLoRA adapter and SFT.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Retrieval-Augmented Generation alongside Fine-tuned Language Models</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We integrate our fine-tuned LLM on RE prompt dataset into the RAG4RE approach <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> in order to figure out the problem in identification of implicit relation between entities in sentences. In our work, the LLM used in the RAG4RE approach’s generation model <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> is exchanged with our fine-tuned LLMs as shown at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.F5" title="In 3.2. Retrieval-Augmented Generation alongside Fine-tuned Language Models ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a>. All other modules in RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> remained same.</p>
</div>
<figure class="ltx_figure" id="S3.F5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>
RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> with Fine-tuned LLMs<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We changed this figure from the original work <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> for integration of fine-tuned LLMs.</span></span></span></figcaption><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="172" id="S3.F5.g1" src="x5.png" width="373"/>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we present our evaluation process, conducted on four benchmark datasets, in conjunction with several language models. Firstly, we introduce the datasets, metrics, and settings for our approaches, including fine-tuning language models and Retrieval-Augmented Generation along with fine-tuned models separately, in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1" title="4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.1</span></a>. Subsequently, the results of experiments are presented and discussed alongside previous Relation Extraction (RE) approaches that achieved the highest performance on the datasets used in this work, in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS2" title="4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Sections</span> <span class="ltx_text ltx_ref_tag">4.2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS3" title="4.3. Discussion ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Experimental Setup</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Through this section, we initially introduce the datasets utilized for evaluation, followed by a detailed settings used on the fine-tuning and the RAG4RE framework <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> leveraging our fine-tuned language model within its generation module. All experiments in this work are conducted utilizing 48 GB of GPU memory.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Datasets</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">To examine the performance of our proposed approaches, we leverage four different RE benchmark datasets detailed in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>: TACRED <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib31" title="">2017</a>)</cite>, TACREV <cite class="ltx_cite ltx_citemacro_citep">(Alt et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib3" title="">2020</a>)</cite>, Re-TACRED <cite class="ltx_cite ltx_citemacro_citep">(Stoica et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib26" title="">2021</a>)</cite>, and SemEVAL <cite class="ltx_cite ltx_citemacro_citep">(Hendrickx et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib14" title="">2010</a>)</cite>. The prompt datasets listed in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> are generated from validation partition of the original dataset splits and different from the training sentences in TACRED and its variants. The training datasets in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> are utilized in the Embedding DB of RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. Test splits of all datasets in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> are employed for evaluation. Unfortunately, SemEVAL does not provide an additional dataset split, such as validation or development data, for creating a prompt dataset. As a result, we have to construct the prompt dataset directly from the training split. Consequently, we are unable to evaluate RAG4RE using our fine-tuned language models on SemEVAL. We strictly separate the training and test splits of the datasets in our evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.ix1.p1.1.1">TACRED</span> (TAC Relation Extraction Dataset) <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib31" title="">2017</a>)</cite> is a supervised RE dataset created through crowdsourcing, specifically aimed at TAC KBP (Text Analysis Conference Knowledge Base Population) relations. Notably, the dataset does not prescribe a direction for the predefined relations, allowing them to be extracted from the given sentence tokens. We utilized this licensed dataset directly from the Linguistic Data Consortium <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>The TAC Relation Extraction dataset catalog is accessible at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://catalog.ldc.upenn.edu/LDC2018T24" title="">https://catalog.ldc.upenn.edu/LDC2018T24</a></span></span></span> (LDC).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I1.ix2.p1">
<p class="ltx_p" id="S4.I1.ix2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.ix2.p1.1.1">TACREV</span> is a refined version of TACRED that minimizes noise in sentences labeled as ‘no_relation’. We generated this dataset from the original TACRED by utilizing the source codes <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>The TACREV source code repository is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/DFKI-NLP/tacrev" title="">https://github.com/DFKI-NLP/tacrev</a>.</span></span></span> provided at <cite class="ltx_cite ltx_citemacro_citep">(Alt et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib3" title="">2020</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I1.ix3.p1">
<p class="ltx_p" id="S4.I1.ix3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.ix3.p1.1.1">Re-TACRED <cite class="ltx_cite ltx_citemacro_citep">(Stoica et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib26" title="">2021</a>)</cite></span> is a re-annotated version of the TACRED dataset designed to enable reliable evaluations of relation extraction (RE) models. To create Re-TACRED, we employed the provided source codes <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>The Re-TACRED source code are at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/gstoica27/Re-TACRED" title="">https://github.com/gstoica27/Re-TACRED</a>.</span></span></span> given at <cite class="ltx_cite ltx_citemacro_citep">(Stoica et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib26" title="">2021</a>)</cite> to create this dataset.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.ix4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I1.ix4.p1">
<p class="ltx_p" id="S4.I1.ix4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.ix4.p1.1.1">SemEval</span> centers on multi-way classification of semantic relations between entity pairs. The predefined relations, referred to as target relation labels, are directional and cannot be extracted from the tokens of the test or train sentences in SemEVAL <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We utilized this dataset from HuggingFace: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/sem_eval_2010_task_8" title="">https://huggingface.co/datasets/sem_eval_2010_task_8</a>.</span></span></span>.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>Overview of benchmark datasets.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.3.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.3.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.3.1.1.1.1">
<span class="ltx_p" id="S4.T1.3.1.1.1.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.3.1.1.1.1.1.1" style="font-size:90%;">Split</span></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.3.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.1.1.2.1" style="font-size:90%;">TACRED</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.3.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.1.1.3.1" style="font-size:90%;">TACREV</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.3.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.3.1.1.4.1" style="font-size:90%;">Re-TACRED</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.3.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.3.1.1.5.1" style="font-size:90%;">SemEVAL</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.3.2.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S4.T1.3.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.3.2.1.1.1">
<span class="ltx_p" id="S4.T1.3.2.1.1.1.1" style="width:45.5pt;"><span class="ltx_text" id="S4.T1.3.2.1.1.1.1.1" style="font-size:90%;">Train</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.2.1.2"><span class="ltx_text" id="S4.T1.3.2.1.2.1" style="font-size:90%;">68124</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.2.1.3"><span class="ltx_text" id="S4.T1.3.2.1.3.1" style="font-size:90%;">68124</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.2.1.4"><span class="ltx_text" id="S4.T1.3.2.1.4.1" style="font-size:90%;">58465</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.2.1.5"><span class="ltx_text" id="S4.T1.3.2.1.5.1" style="font-size:90%;">8000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.2">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S4.T1.3.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.3.3.2.1.1">
<span class="ltx_p" id="S4.T1.3.3.2.1.1.1" style="width:45.5pt;"><span class="ltx_text" id="S4.T1.3.3.2.1.1.1.1" style="font-size:90%;">Test</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.2.2"><span class="ltx_text" id="S4.T1.3.3.2.2.1" style="font-size:90%;">15509</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.2.3"><span class="ltx_text" id="S4.T1.3.3.2.3.1" style="font-size:90%;">15509</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.2.4"><span class="ltx_text" id="S4.T1.3.3.2.4.1" style="font-size:90%;">13418</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.2.5"><span class="ltx_text" id="S4.T1.3.3.2.5.1" style="font-size:90%;">2717</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.4.3">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S4.T1.3.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.3.4.3.1.1">
<span class="ltx_p" id="S4.T1.3.4.3.1.1.1" style="width:45.5pt;"><span class="ltx_text" id="S4.T1.3.4.3.1.1.1.1" style="font-size:90%;">Prompt Dataset</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.3.2"><span class="ltx_text" id="S4.T1.3.4.3.2.1" style="font-size:90%;">22631</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.3.3"><span class="ltx_text" id="S4.T1.3.4.3.3.1" style="font-size:90%;">22631</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.3.4"><span class="ltx_text" id="S4.T1.3.4.3.4.1" style="font-size:90%;">19584</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.3.5"><span class="ltx_text" id="S4.T1.3.4.3.5.1" style="font-size:90%;">8000</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.5.4">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T1.3.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.3.5.4.1.1">
<span class="ltx_p" id="S4.T1.3.5.4.1.1.1" style="width:45.5pt;"><span class="ltx_text ltx_font_italic" id="S4.T1.3.5.4.1.1.1.1" style="font-size:90%;">#</span><span class="ltx_text" id="S4.T1.3.5.4.1.1.1.2" style="font-size:90%;"> of Relations</span></span>
</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.3.5.4.2"><span class="ltx_text" id="S4.T1.3.5.4.2.1" style="font-size:90%;">42</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.3.5.4.3"><span class="ltx_text" id="S4.T1.3.5.4.3.1" style="font-size:90%;">42</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.3.5.4.4"><span class="ltx_text" id="S4.T1.3.5.4.4.1" style="font-size:90%;">40</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.3.5.4.5"><span class="ltx_text" id="S4.T1.3.5.4.5.1" style="font-size:90%;">19</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Evaluation Metrics</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">The benchmark datasets used in this work, especially TACRED and its variants consisting of mostly ‘no_relation’ as a target relation <cite class="ltx_cite ltx_citemacro_citep">(Alt et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib3" title="">2020</a>; Stoica et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib26" title="">2021</a>)</cite>, are imbalanced, so micro metrics are considered. For instance, there are 12184 ‘no_relation’ out of 15509 relations in TACRED test split.
Micro F1-score, precision, and recall metrics have been computed in the evaluation of our experiments alongside LLMs on four different benchmark datasets.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Settings for Fine-tuning Language Models</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">Supervised Fine-tuning Trainer (SFT) <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>The information about how SFT works are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/trl/sft_trainer" title="">https://huggingface.co/docs/trl/sft_trainer</a>.</span></span></span>, based on RLRF <cite class="ltx_cite ltx_citemacro_citep">(Lambert et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib18" title="">2022</a>)</cite>, is utilized to fine-tune language models, e.g., T5 Large, Mistral-7B, and Llama2-7B on prompt datasets at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>.
Taking into account previous works using language model for relation extraction  <cite class="ltx_cite ltx_citemacro_citep">(Kai Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a>; Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>, we leverage the following language models.</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I2.ix1.p1">
<p class="ltx_p" id="S4.I2.ix1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.ix1.p1.1.1">T5 Large</span> is based on encoder-decoder model architecture <cite class="ltx_cite ltx_citemacro_citep">(Pan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib23" title="">2024</a>; Chung et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib6" title="">2022</a>)</cite> with 770 million parameters.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I2.ix2.p1">
<p class="ltx_p" id="S4.I2.ix2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.ix2.p1.1.1">Mistral-7B</span> is a type of decoder only model with 7B parameters <cite class="ltx_cite ltx_citemacro_citep">(Pan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib23" title="">2024</a>; Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib16" title="">2023</a>)</cite> and is used for RE task in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span>
<div class="ltx_para" id="S4.I2.ix3.p1">
<p class="ltx_p" id="S4.I2.ix3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.ix3.p1.1.1">Llama2-7B</span> has only decoder in its architecture <cite class="ltx_cite ltx_citemacro_citep">(Pan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib23" title="">2024</a>; Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib27" title="">2023</a>)</cite> and is utilized for identifying relations between entities in a sentence in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS1.SSS3.p1.2">Instead of fully fine-tuning language models, we integrate the Low Rank Adaptation (LoRA) approach <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib15" title="">2021</a>)</cite> into the language models and apply 4-bit quantization. In other words, we employ the QLoRA approach <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib8" title="">2023</a>)</cite> for fine-tuning language models. As mentioned in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S2" title="2. Related Works ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2</span></a>, LoRA and QLoRA are methods for conducting parameter-efficient fine-tuning and reducing the usage of GPU resources throughout the fine-tuning process. These methods focus solely on targeted modules of pre-trained language models and freeze the remaining modules. The language models are fine-tuned on a single GPU with 48 GB of memory. Throughout the fine-tuning process, parameters listed in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T2" title="In 4.1.3. Settings for Fine-tuning Language Models ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a> are utilized.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.7.8.1">
<td class="ltx_td ltx_border_tt" id="S4.T2.7.8.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S4.T2.7.8.1.2"></td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2" id="S4.T2.7.8.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.7.8.1.3.1">Value</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.9.2">
<td class="ltx_td" id="S4.T2.7.9.2.1"></td>
<td class="ltx_td ltx_align_left" id="S4.T2.7.9.2.2"><span class="ltx_text ltx_font_bold" id="S4.T2.7.9.2.2.1">Parameter</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.7.9.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.7.9.2.3.1">
<span class="ltx_p" id="S4.T2.7.9.2.3.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.7.9.2.3.1.1.1">Llama2-7B</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.T2.7.9.2.3.1.1.2">Mistral-7B</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.4"><span class="ltx_text ltx_font_bold" id="S4.T2.7.9.2.4.1">T5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1">
<td class="ltx_td ltx_border_t" id="S4.T2.1.1.2"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.3">Learning Rate</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.1">
<span class="ltx_p" id="S4.T2.1.1.1.1.1" style="width:56.9pt;"><math alttext="2e-4" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml"><mrow id="S4.T2.1.1.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.1.1.m1.1.1.2.cmml"><mn id="S4.T2.1.1.1.1.1.m1.1.1.2.2" xref="S4.T2.1.1.1.1.1.m1.1.1.2.2.cmml">2</mn><mo id="S4.T2.1.1.1.1.1.m1.1.1.2.1" xref="S4.T2.1.1.1.1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S4.T2.1.1.1.1.1.m1.1.1.2.3" xref="S4.T2.1.1.1.1.1.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S4.T2.1.1.1.1.1.m1.1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.1.cmml">−</mo><mn id="S4.T2.1.1.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.1.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1"><minus id="S4.T2.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1.1"></minus><apply id="S4.T2.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1.2"><times id="S4.T2.1.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1.2.1"></times><cn id="S4.T2.1.1.1.1.1.m1.1.1.2.2.cmml" type="integer" xref="S4.T2.1.1.1.1.1.m1.1.1.2.2">2</cn><ci id="S4.T2.1.1.1.1.1.m1.1.1.2.3.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1.2.3">𝑒</ci></apply><cn id="S4.T2.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S4.T2.1.1.1.1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">2e-4</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.1.m1.1d">2 italic_e - 4</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4">5e-5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3">
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.3.3.3.1">LLMs</span></td>
<td class="ltx_td ltx_align_left" id="S4.T2.3.3.4">Batch Size</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.2.2.1.1">
<span class="ltx_p" id="S4.T2.2.2.1.1.1" style="width:56.9pt;"><math alttext="4" class="ltx_Math" display="inline" id="S4.T2.2.2.1.1.1.m1.1"><semantics id="S4.T2.2.2.1.1.1.m1.1a"><mn id="S4.T2.2.2.1.1.1.m1.1.1" xref="S4.T2.2.2.1.1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.1.1.m1.1b"><cn id="S4.T2.2.2.1.1.1.m1.1.1.cmml" type="integer" xref="S4.T2.2.2.1.1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.1.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.1.1.1.m1.1d">4</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.2"><math alttext="8" class="ltx_Math" display="inline" id="S4.T2.3.3.2.m1.1"><semantics id="S4.T2.3.3.2.m1.1a"><mn id="S4.T2.3.3.2.m1.1.1" xref="S4.T2.3.3.2.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.2.m1.1b"><cn id="S4.T2.3.3.2.m1.1.1.cmml" type="integer" xref="S4.T2.3.3.2.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.2.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.2.m1.1d">8</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5">
<td class="ltx_td" id="S4.T2.5.5.3"></td>
<td class="ltx_td ltx_align_left" id="S4.T2.5.5.4">Epoch</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.4.4.1.1">
<span class="ltx_p" id="S4.T2.4.4.1.1.1" style="width:56.9pt;"><math alttext="1" class="ltx_Math" display="inline" id="S4.T2.4.4.1.1.1.m1.1"><semantics id="S4.T2.4.4.1.1.1.m1.1a"><mn id="S4.T2.4.4.1.1.1.m1.1.1" xref="S4.T2.4.4.1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.1.1.m1.1b"><cn id="S4.T2.4.4.1.1.1.m1.1.1.cmml" type="integer" xref="S4.T2.4.4.1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.1.1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.1.1.1.m1.1d">1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.2"><math alttext="1" class="ltx_Math" display="inline" id="S4.T2.5.5.2.m1.1"><semantics id="S4.T2.5.5.2.m1.1a"><mn id="S4.T2.5.5.2.m1.1.1" xref="S4.T2.5.5.2.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.2.m1.1b"><cn id="S4.T2.5.5.2.m1.1.1.cmml" type="integer" xref="S4.T2.5.5.2.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.2.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.2.m1.1d">1</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.10.3">
<td class="ltx_td" id="S4.T2.7.10.3.1"></td>
<td class="ltx_td ltx_align_left" id="S4.T2.7.10.3.2">Weight Decay</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.7.10.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.7.10.3.3.1">
<span class="ltx_p" id="S4.T2.7.10.3.3.1.1" style="width:56.9pt;">0.001</span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.4">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.6.2"><span class="ltx_text ltx_font_bold" id="S4.T2.6.6.2.1">LoRA</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.6.6.3">LoRA Alpha</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.6.6.1.1">
<span class="ltx_p" id="S4.T2.6.6.1.1.1" style="width:56.9pt;"><math alttext="16" class="ltx_Math" display="inline" id="S4.T2.6.6.1.1.1.m1.1"><semantics id="S4.T2.6.6.1.1.1.m1.1a"><mn id="S4.T2.6.6.1.1.1.m1.1.1" xref="S4.T2.6.6.1.1.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.1.1.1.m1.1b"><cn id="S4.T2.6.6.1.1.1.m1.1.1.cmml" type="integer" xref="S4.T2.6.6.1.1.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.1.1.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.1.1.1.m1.1d">16</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.6.4">32</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.7">
<td class="ltx_td" id="S4.T2.7.7.2"></td>
<td class="ltx_td ltx_align_left" id="S4.T2.7.7.3">LoRA Dropout</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.7.7.1.1">
<span class="ltx_p" id="S4.T2.7.7.1.1.1" style="width:56.9pt;"><math alttext="0.1" class="ltx_Math" display="inline" id="S4.T2.7.7.1.1.1.m1.1"><semantics id="S4.T2.7.7.1.1.1.m1.1a"><mn id="S4.T2.7.7.1.1.1.m1.1.1" xref="S4.T2.7.7.1.1.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.1.1.1.m1.1b"><cn id="S4.T2.7.7.1.1.1.m1.1.1.cmml" type="float" xref="S4.T2.7.7.1.1.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.1.1.1.m1.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.7.1.1.1.m1.1d">0.1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.7.4">0.01</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.11.4">
<td class="ltx_td ltx_border_bb" id="S4.T2.7.11.4.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.7.11.4.2">r</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T2.7.11.4.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.7.11.4.3.1">
<span class="ltx_p" id="S4.T2.7.11.4.3.1.1" style="width:56.9pt;">64</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.11.4.4">4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Parameters and settings are utilized in the fine-tuning process. <span class="ltx_text ltx_font_italic" id="S4.T2.9.1">r</span> in LoRA config refers to the rank of the update matrices.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4. </span>Setting for Retrieval Augmented Generation-based Relation Extraction</h4>
<div class="ltx_para" id="S4.SS1.SSS4.p1">
<p class="ltx_p" id="S4.SS1.SSS4.p1.1">Our language models fine-tuned on the prompt datasets at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>, are integrated into RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. All experimental settings are replicated from RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. Unfortunately, we are unable to fine-tune T5 XL model used in the original RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> due to limited GPU resources. Therefore, we replicate RAG4RE along with T5 Large and vanilla prompting (or simple query) as defined in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. We adhere to the experiments conducted in RAG4RE for our work.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Results</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We evaluated language models fine-tuned on prompt datasets detailed at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T1" title="In 4.1.1. Datasets ‣ 4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.SS1" title="4.1. Experimental Setup ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.1</span></a>. Furthermore, we integrated these fine-tuned language models into the RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. It is worth noting that due to constraints in GPU resources, we opted to utilize T5 Large instead of T5 XL or XXL for fine-tuning. Hence, we chose T5 Large and meticulously replicated the RAG4RE experiments within the confines of our work. In this section, we first introduce the results of our fine-tuned models and then the results of RAG4RE approach using our fine-tuned models.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">With regard to evaluation of fine-tuned LLMs alongside LoRA on four different datasets, fine-tuned Mistral-7B models accomplish outstanding performance (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.F6" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>). Notably, these fine-tuned Mistral-7B models achieve remarkable F1 scores of 89.64%, 94.61%, and 90.09% on TACRED, TACREV, and Re-TACRED, respectively (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.F6" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>). However, its performance on SemEVAL falls short of this excellence. Conversely, the fine-tuned T5 Large demonstrates the highest F1 with 79.94% (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>) on SemEVAL. The Llama2-7B models fine-tuned on TACRED and TACREV follow the fine-tuned Mistral-7B models with micro-F1 scores of 88.20% and 93.75%. Unfortunately, the fine-tuned Llama2-7B models could not exhibit the same performance on Re-TACRED and SemEVAL at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.F6" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>. The fine-tuned T5 Large model takes second place with a F1 score of 86.94% on Re-TACRED dataset (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.F6" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>). Moreover, fine-tuning LLMs outperformed simple query prompting and the previously introduced RAG4RE method <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Additionally, we integrated these fine-tuned LLMs into the RAG4RE approach <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> in order to explore their potential in addressing the limitations of general-purpose LLMs. However, due to the lack of an additional dataset split in SemEVAL, we could not examine whether integrating fine-tuned language models into RAG4RE improves the results of RAG4RE using general-purpose LLMs or not.
Remarkably, the integration of fine-tuned models into RAG4RE yielded significant improvements across all three datasets, including TACRED, TACREV and Re-TACRED, particularly when leveraging T5 Large (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.F6" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>). While we observed enhancements in RAG4RE’s performance, as detailed in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>, with the integration of fine-tuned Llama-7B on Re-TACRED, it is noteworthy that this improvement was not observed on TACRED and TACREV. Regrettably, the results indicate that the use of Mistral-7B as the fined-tuned LLM did not yield improvements in the results of RE. The reason why the performance of the RAG4RE approach could not be improved when fine-tuned decoder-only models are used as a generator in its architecture (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S3.F5" title="In 3.2. Retrieval-Augmented Generation alongside Fine-tuned Language Models ‣ 3. Methodology ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a>) might be related to catastrophic forgetting. Previous work fine-tuning language models on a single task is also dealing with the same forgetting problem <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib10" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">As a result, the fine-tuned T5 Large models consistently achieved the highest F1 scores among all the experiments conducted in this work, particularly when integrated into the RAG4RE framework proposed in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. However, fine-tuned Mistral is slightly better than RAG4RE using fine-tuned T5 on TACREV. In addition to the findings of the experiments using T5 Large, both fine-tuning language models on the dataset and integrating these fine-tuned models into RAG4RE outperformed zero-shot prompting approaches, such as simple queries and RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" id="S4.F6.1" style="width:216.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="412" id="S4.F6.1.g1" src="x6.png" width="747"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" id="S4.F6.2" style="width:216.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="440" id="S4.F6.2.g1" src="x7.png" width="747"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" id="S4.F6.3" style="width:216.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="412" id="S4.F6.3.g1" src="x8.png" width="747"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" id="S4.F6.4" style="width:216.8pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="446" id="S4.F6.4.g1" src="x9.png" width="747"/>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>The results of each dataset when three different language models are used along with different approaches. Each color refers to a language model. Blue, Red, and Green point out T5 Large, Mistral-7B, and Llama2-7B, respectively. In addition, <span class="ltx_text ltx_font_italic" id="S4.F6.6.1">f</span> on the gray curves of each figure points out the F1 score. Note that we could not replicate the experiments for finetuning+RAG4RE on SemEVAL dataset due to small dataset.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Results of the experiments conducted on four different benchmark datasets alongside different LLMs.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.144">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.144.145.1">
<th class="ltx_td ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2" id="S4.T3.144.145.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.144.145.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.144.145.1.2.1">TACRED</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.144.145.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.144.145.1.3.1">TACREV</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.144.145.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.144.145.1.4.1">Re-TACRED</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.144.145.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.144.145.1.5.1">SemEval</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.144.146.2">
<th class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_th_row" id="S4.T3.144.146.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.144.146.2.1.1">LLM</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T3.144.146.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.144.146.2.2.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.3">P(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.4">R(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.5">F1(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.6">P(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.7">R(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.8">F1(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.9">P(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.10">R(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.11">F1(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.12">P(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.13">R(%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.144.146.2.14">F1(%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.12.12">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.12.12.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.12.12.13.1">
<span class="ltx_p" id="S4.T3.12.12.13.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_italic" id="S4.T3.12.12.13.1.1.1">T5 Large</span></span>
</span>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.12.12.14">simple query</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.1.1.1"><math alttext="95.10" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mn id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">95.10</mn><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><cn id="S4.T3.1.1.1.m1.1.1.cmml" type="float" xref="S4.T3.1.1.1.m1.1.1">95.10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">95.10</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">95.10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.2.2.2"><math alttext="03.18" class="ltx_Math" display="inline" id="S4.T3.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.m1.1a"><mn id="S4.T3.2.2.2.m1.1.1" xref="S4.T3.2.2.2.m1.1.1.cmml">03.18</mn><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><cn id="S4.T3.2.2.2.m1.1.1.cmml" type="float" xref="S4.T3.2.2.2.m1.1.1">03.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">03.18</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.m1.1d">03.18</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.3.3.3"><math alttext="06.16" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.m1.1a"><mn id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml">06.16</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><cn id="S4.T3.3.3.3.m1.1.1.cmml" type="float" xref="S4.T3.3.3.3.m1.1.1">06.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">06.16</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.m1.1d">06.16</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.4.4.4"><math alttext="96.72" class="ltx_Math" display="inline" id="S4.T3.4.4.4.m1.1"><semantics id="S4.T3.4.4.4.m1.1a"><mn id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml">96.72</mn><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><cn id="S4.T3.4.4.4.m1.1.1.cmml" type="float" xref="S4.T3.4.4.4.m1.1.1">96.72</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">96.72</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.m1.1d">96.72</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.5.5.5"><math alttext="06.90" class="ltx_Math" display="inline" id="S4.T3.5.5.5.m1.1"><semantics id="S4.T3.5.5.5.m1.1a"><mn id="S4.T3.5.5.5.m1.1.1" xref="S4.T3.5.5.5.m1.1.1.cmml">06.90</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><cn id="S4.T3.5.5.5.m1.1.1.cmml" type="float" xref="S4.T3.5.5.5.m1.1.1">06.90</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">06.90</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.m1.1d">06.90</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.6.6.6"><math alttext="12.89" class="ltx_Math" display="inline" id="S4.T3.6.6.6.m1.1"><semantics id="S4.T3.6.6.6.m1.1a"><mn id="S4.T3.6.6.6.m1.1.1" xref="S4.T3.6.6.6.m1.1.1.cmml">12.89</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><cn id="S4.T3.6.6.6.m1.1.1.cmml" type="float" xref="S4.T3.6.6.6.m1.1.1">12.89</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">12.89</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.m1.1d">12.89</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.7.7.7"><math alttext="90.91" class="ltx_Math" display="inline" id="S4.T3.7.7.7.m1.1"><semantics id="S4.T3.7.7.7.m1.1a"><mn id="S4.T3.7.7.7.m1.1.1" xref="S4.T3.7.7.7.m1.1.1.cmml">90.91</mn><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.m1.1b"><cn id="S4.T3.7.7.7.m1.1.1.cmml" type="float" xref="S4.T3.7.7.7.m1.1.1">90.91</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.m1.1c">90.91</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.7.m1.1d">90.91</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.8.8.8"><math alttext="00.26" class="ltx_Math" display="inline" id="S4.T3.8.8.8.m1.1"><semantics id="S4.T3.8.8.8.m1.1a"><mn id="S4.T3.8.8.8.m1.1.1" xref="S4.T3.8.8.8.m1.1.1.cmml">00.26</mn><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.m1.1b"><cn id="S4.T3.8.8.8.m1.1.1.cmml" type="float" xref="S4.T3.8.8.8.m1.1.1">00.26</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.m1.1c">00.26</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.8.8.m1.1d">00.26</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.9.9.9"><math alttext="00.51" class="ltx_Math" display="inline" id="S4.T3.9.9.9.m1.1"><semantics id="S4.T3.9.9.9.m1.1a"><mn id="S4.T3.9.9.9.m1.1.1" xref="S4.T3.9.9.9.m1.1.1.cmml">00.51</mn><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.m1.1b"><cn id="S4.T3.9.9.9.m1.1.1.cmml" type="float" xref="S4.T3.9.9.9.m1.1.1">00.51</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.m1.1c">00.51</annotation><annotation encoding="application/x-llamapun" id="S4.T3.9.9.9.m1.1d">00.51</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.10.10.10"><math alttext="18.74" class="ltx_Math" display="inline" id="S4.T3.10.10.10.m1.1"><semantics id="S4.T3.10.10.10.m1.1a"><mn id="S4.T3.10.10.10.m1.1.1" xref="S4.T3.10.10.10.m1.1.1.cmml">18.74</mn><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.10.m1.1b"><cn id="S4.T3.10.10.10.m1.1.1.cmml" type="float" xref="S4.T3.10.10.10.m1.1.1">18.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.10.m1.1c">18.74</annotation><annotation encoding="application/x-llamapun" id="S4.T3.10.10.10.m1.1d">18.74</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.11.11.11"><math alttext="09.28" class="ltx_Math" display="inline" id="S4.T3.11.11.11.m1.1"><semantics id="S4.T3.11.11.11.m1.1a"><mn id="S4.T3.11.11.11.m1.1.1" xref="S4.T3.11.11.11.m1.1.1.cmml">09.28</mn><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.11.m1.1b"><cn id="S4.T3.11.11.11.m1.1.1.cmml" type="float" xref="S4.T3.11.11.11.m1.1.1">09.28</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.11.m1.1c">09.28</annotation><annotation encoding="application/x-llamapun" id="S4.T3.11.11.11.m1.1d">09.28</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.12.12.12"><math alttext="12.40" class="ltx_Math" display="inline" id="S4.T3.12.12.12.m1.1"><semantics id="S4.T3.12.12.12.m1.1a"><mn id="S4.T3.12.12.12.m1.1.1" xref="S4.T3.12.12.12.m1.1.1.cmml">12.40</mn><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.12.m1.1b"><cn id="S4.T3.12.12.12.m1.1.1.cmml" type="float" xref="S4.T3.12.12.12.m1.1.1">12.40</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.12.m1.1c">12.40</annotation><annotation encoding="application/x-llamapun" id="S4.T3.12.12.12.m1.1d">12.40</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.24.24">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.24.24.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.24.24.14">RAG4RE</th>
<td class="ltx_td ltx_align_right" id="S4.T3.13.13.1"><math alttext="85.99" class="ltx_Math" display="inline" id="S4.T3.13.13.1.m1.1"><semantics id="S4.T3.13.13.1.m1.1a"><mn id="S4.T3.13.13.1.m1.1.1" xref="S4.T3.13.13.1.m1.1.1.cmml">85.99</mn><annotation-xml encoding="MathML-Content" id="S4.T3.13.13.1.m1.1b"><cn id="S4.T3.13.13.1.m1.1.1.cmml" type="float" xref="S4.T3.13.13.1.m1.1.1">85.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.13.1.m1.1c">85.99</annotation><annotation encoding="application/x-llamapun" id="S4.T3.13.13.1.m1.1d">85.99</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.14.14.2"><math alttext="34.50" class="ltx_Math" display="inline" id="S4.T3.14.14.2.m1.1"><semantics id="S4.T3.14.14.2.m1.1a"><mn id="S4.T3.14.14.2.m1.1.1" xref="S4.T3.14.14.2.m1.1.1.cmml">34.50</mn><annotation-xml encoding="MathML-Content" id="S4.T3.14.14.2.m1.1b"><cn id="S4.T3.14.14.2.m1.1.1.cmml" type="float" xref="S4.T3.14.14.2.m1.1.1">34.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.14.2.m1.1c">34.50</annotation><annotation encoding="application/x-llamapun" id="S4.T3.14.14.2.m1.1d">34.50</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.15.15.3"><math alttext="49.20" class="ltx_Math" display="inline" id="S4.T3.15.15.3.m1.1"><semantics id="S4.T3.15.15.3.m1.1a"><mn id="S4.T3.15.15.3.m1.1.1" xref="S4.T3.15.15.3.m1.1.1.cmml">49.20</mn><annotation-xml encoding="MathML-Content" id="S4.T3.15.15.3.m1.1b"><cn id="S4.T3.15.15.3.m1.1.1.cmml" type="float" xref="S4.T3.15.15.3.m1.1.1">49.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.15.3.m1.1c">49.20</annotation><annotation encoding="application/x-llamapun" id="S4.T3.15.15.3.m1.1d">49.20</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.16.16.4"><math alttext="91.28" class="ltx_Math" display="inline" id="S4.T3.16.16.4.m1.1"><semantics id="S4.T3.16.16.4.m1.1a"><mn id="S4.T3.16.16.4.m1.1.1" xref="S4.T3.16.16.4.m1.1.1.cmml">91.28</mn><annotation-xml encoding="MathML-Content" id="S4.T3.16.16.4.m1.1b"><cn id="S4.T3.16.16.4.m1.1.1.cmml" type="float" xref="S4.T3.16.16.4.m1.1.1">91.28</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.16.4.m1.1c">91.28</annotation><annotation encoding="application/x-llamapun" id="S4.T3.16.16.4.m1.1d">91.28</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.17.17.5"><math alttext="08.20" class="ltx_Math" display="inline" id="S4.T3.17.17.5.m1.1"><semantics id="S4.T3.17.17.5.m1.1a"><mn id="S4.T3.17.17.5.m1.1.1" xref="S4.T3.17.17.5.m1.1.1.cmml">08.20</mn><annotation-xml encoding="MathML-Content" id="S4.T3.17.17.5.m1.1b"><cn id="S4.T3.17.17.5.m1.1.1.cmml" type="float" xref="S4.T3.17.17.5.m1.1.1">08.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.17.5.m1.1c">08.20</annotation><annotation encoding="application/x-llamapun" id="S4.T3.17.17.5.m1.1d">08.20</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.18.18.6"><math alttext="15.04" class="ltx_Math" display="inline" id="S4.T3.18.18.6.m1.1"><semantics id="S4.T3.18.18.6.m1.1a"><mn id="S4.T3.18.18.6.m1.1.1" xref="S4.T3.18.18.6.m1.1.1.cmml">15.04</mn><annotation-xml encoding="MathML-Content" id="S4.T3.18.18.6.m1.1b"><cn id="S4.T3.18.18.6.m1.1.1.cmml" type="float" xref="S4.T3.18.18.6.m1.1.1">15.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.18.6.m1.1c">15.04</annotation><annotation encoding="application/x-llamapun" id="S4.T3.18.18.6.m1.1d">15.04</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.19.19.7"><math alttext="80.77" class="ltx_Math" display="inline" id="S4.T3.19.19.7.m1.1"><semantics id="S4.T3.19.19.7.m1.1a"><mn id="S4.T3.19.19.7.m1.1.1" xref="S4.T3.19.19.7.m1.1.1.cmml">80.77</mn><annotation-xml encoding="MathML-Content" id="S4.T3.19.19.7.m1.1b"><cn id="S4.T3.19.19.7.m1.1.1.cmml" type="float" xref="S4.T3.19.19.7.m1.1.1">80.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.19.7.m1.1c">80.77</annotation><annotation encoding="application/x-llamapun" id="S4.T3.19.19.7.m1.1d">80.77</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.20.20.8"><math alttext="00.27" class="ltx_Math" display="inline" id="S4.T3.20.20.8.m1.1"><semantics id="S4.T3.20.20.8.m1.1a"><mn id="S4.T3.20.20.8.m1.1.1" xref="S4.T3.20.20.8.m1.1.1.cmml">00.27</mn><annotation-xml encoding="MathML-Content" id="S4.T3.20.20.8.m1.1b"><cn id="S4.T3.20.20.8.m1.1.1.cmml" type="float" xref="S4.T3.20.20.8.m1.1.1">00.27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.20.8.m1.1c">00.27</annotation><annotation encoding="application/x-llamapun" id="S4.T3.20.20.8.m1.1d">00.27</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.21.21.9"><math alttext="00.53" class="ltx_Math" display="inline" id="S4.T3.21.21.9.m1.1"><semantics id="S4.T3.21.21.9.m1.1a"><mn id="S4.T3.21.21.9.m1.1.1" xref="S4.T3.21.21.9.m1.1.1.cmml">00.53</mn><annotation-xml encoding="MathML-Content" id="S4.T3.21.21.9.m1.1b"><cn id="S4.T3.21.21.9.m1.1.1.cmml" type="float" xref="S4.T3.21.21.9.m1.1.1">00.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.21.9.m1.1c">00.53</annotation><annotation encoding="application/x-llamapun" id="S4.T3.21.21.9.m1.1d">00.53</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.22.22.10"><math alttext="07.39" class="ltx_Math" display="inline" id="S4.T3.22.22.10.m1.1"><semantics id="S4.T3.22.22.10.m1.1a"><mn id="S4.T3.22.22.10.m1.1.1" xref="S4.T3.22.22.10.m1.1.1.cmml">07.39</mn><annotation-xml encoding="MathML-Content" id="S4.T3.22.22.10.m1.1b"><cn id="S4.T3.22.22.10.m1.1.1.cmml" type="float" xref="S4.T3.22.22.10.m1.1.1">07.39</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.22.10.m1.1c">07.39</annotation><annotation encoding="application/x-llamapun" id="S4.T3.22.22.10.m1.1d">07.39</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.23.23.11"><math alttext="07.21" class="ltx_Math" display="inline" id="S4.T3.23.23.11.m1.1"><semantics id="S4.T3.23.23.11.m1.1a"><mn id="S4.T3.23.23.11.m1.1.1" xref="S4.T3.23.23.11.m1.1.1.cmml">07.21</mn><annotation-xml encoding="MathML-Content" id="S4.T3.23.23.11.m1.1b"><cn id="S4.T3.23.23.11.m1.1.1.cmml" type="float" xref="S4.T3.23.23.11.m1.1.1">07.21</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.23.23.11.m1.1c">07.21</annotation><annotation encoding="application/x-llamapun" id="S4.T3.23.23.11.m1.1d">07.21</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.24.24.12"><math alttext="07.30" class="ltx_Math" display="inline" id="S4.T3.24.24.12.m1.1"><semantics id="S4.T3.24.24.12.m1.1a"><mn id="S4.T3.24.24.12.m1.1.1" xref="S4.T3.24.24.12.m1.1.1.cmml">07.30</mn><annotation-xml encoding="MathML-Content" id="S4.T3.24.24.12.m1.1b"><cn id="S4.T3.24.24.12.m1.1.1.cmml" type="float" xref="S4.T3.24.24.12.m1.1.1">07.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.24.24.12.m1.1c">07.30</annotation><annotation encoding="application/x-llamapun" id="S4.T3.24.24.12.m1.1d">07.30</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.36.36">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.36.36.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.36.36.14">Fine-tuning (QLoRA)</th>
<td class="ltx_td ltx_align_right" id="S4.T3.25.25.1"><math alttext="86.74" class="ltx_Math" display="inline" id="S4.T3.25.25.1.m1.1"><semantics id="S4.T3.25.25.1.m1.1a"><mn id="S4.T3.25.25.1.m1.1.1" xref="S4.T3.25.25.1.m1.1.1.cmml">86.74</mn><annotation-xml encoding="MathML-Content" id="S4.T3.25.25.1.m1.1b"><cn id="S4.T3.25.25.1.m1.1.1.cmml" type="float" xref="S4.T3.25.25.1.m1.1.1">86.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.25.25.1.m1.1c">86.74</annotation><annotation encoding="application/x-llamapun" id="S4.T3.25.25.1.m1.1d">86.74</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.26.26.2"><math alttext="86.76" class="ltx_Math" display="inline" id="S4.T3.26.26.2.m1.1"><semantics id="S4.T3.26.26.2.m1.1a"><mn id="S4.T3.26.26.2.m1.1.1" xref="S4.T3.26.26.2.m1.1.1.cmml">86.76</mn><annotation-xml encoding="MathML-Content" id="S4.T3.26.26.2.m1.1b"><cn id="S4.T3.26.26.2.m1.1.1.cmml" type="float" xref="S4.T3.26.26.2.m1.1.1">86.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.26.26.2.m1.1c">86.76</annotation><annotation encoding="application/x-llamapun" id="S4.T3.26.26.2.m1.1d">86.76</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.27.27.3"><math alttext="86.74" class="ltx_Math" display="inline" id="S4.T3.27.27.3.m1.1"><semantics id="S4.T3.27.27.3.m1.1a"><mn id="S4.T3.27.27.3.m1.1.1" xref="S4.T3.27.27.3.m1.1.1.cmml">86.74</mn><annotation-xml encoding="MathML-Content" id="S4.T3.27.27.3.m1.1b"><cn id="S4.T3.27.27.3.m1.1.1.cmml" type="float" xref="S4.T3.27.27.3.m1.1.1">86.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.27.27.3.m1.1c">86.74</annotation><annotation encoding="application/x-llamapun" id="S4.T3.27.27.3.m1.1d">86.74</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.28.28.4"><math alttext="89.93" class="ltx_Math" display="inline" id="S4.T3.28.28.4.m1.1"><semantics id="S4.T3.28.28.4.m1.1a"><mn id="S4.T3.28.28.4.m1.1.1" xref="S4.T3.28.28.4.m1.1.1.cmml">89.93</mn><annotation-xml encoding="MathML-Content" id="S4.T3.28.28.4.m1.1b"><cn id="S4.T3.28.28.4.m1.1.1.cmml" type="float" xref="S4.T3.28.28.4.m1.1.1">89.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.28.28.4.m1.1c">89.93</annotation><annotation encoding="application/x-llamapun" id="S4.T3.28.28.4.m1.1d">89.93</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.29.29.5"><math alttext="90.13" class="ltx_Math" display="inline" id="S4.T3.29.29.5.m1.1"><semantics id="S4.T3.29.29.5.m1.1a"><mn id="S4.T3.29.29.5.m1.1.1" xref="S4.T3.29.29.5.m1.1.1.cmml">90.13</mn><annotation-xml encoding="MathML-Content" id="S4.T3.29.29.5.m1.1b"><cn id="S4.T3.29.29.5.m1.1.1.cmml" type="float" xref="S4.T3.29.29.5.m1.1.1">90.13</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.29.29.5.m1.1c">90.13</annotation><annotation encoding="application/x-llamapun" id="S4.T3.29.29.5.m1.1d">90.13</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.30.30.6"><math alttext="90.03" class="ltx_Math" display="inline" id="S4.T3.30.30.6.m1.1"><semantics id="S4.T3.30.30.6.m1.1a"><mn id="S4.T3.30.30.6.m1.1.1" xref="S4.T3.30.30.6.m1.1.1.cmml">90.03</mn><annotation-xml encoding="MathML-Content" id="S4.T3.30.30.6.m1.1b"><cn id="S4.T3.30.30.6.m1.1.1.cmml" type="float" xref="S4.T3.30.30.6.m1.1.1">90.03</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.30.30.6.m1.1c">90.03</annotation><annotation encoding="application/x-llamapun" id="S4.T3.30.30.6.m1.1d">90.03</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.31.31.7"><math alttext="86.27" class="ltx_Math" display="inline" id="S4.T3.31.31.7.m1.1"><semantics id="S4.T3.31.31.7.m1.1a"><mn id="S4.T3.31.31.7.m1.1.1" xref="S4.T3.31.31.7.m1.1.1.cmml">86.27</mn><annotation-xml encoding="MathML-Content" id="S4.T3.31.31.7.m1.1b"><cn id="S4.T3.31.31.7.m1.1.1.cmml" type="float" xref="S4.T3.31.31.7.m1.1.1">86.27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.31.31.7.m1.1c">86.27</annotation><annotation encoding="application/x-llamapun" id="S4.T3.31.31.7.m1.1d">86.27</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.32.32.8"><math alttext="87.62" class="ltx_Math" display="inline" id="S4.T3.32.32.8.m1.1"><semantics id="S4.T3.32.32.8.m1.1a"><mn id="S4.T3.32.32.8.m1.1.1" xref="S4.T3.32.32.8.m1.1.1.cmml">87.62</mn><annotation-xml encoding="MathML-Content" id="S4.T3.32.32.8.m1.1b"><cn id="S4.T3.32.32.8.m1.1.1.cmml" type="float" xref="S4.T3.32.32.8.m1.1.1">87.62</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.32.32.8.m1.1c">87.62</annotation><annotation encoding="application/x-llamapun" id="S4.T3.32.32.8.m1.1d">87.62</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.33.33.9"><math alttext="86.94" class="ltx_Math" display="inline" id="S4.T3.33.33.9.m1.1"><semantics id="S4.T3.33.33.9.m1.1a"><mn id="S4.T3.33.33.9.m1.1.1" xref="S4.T3.33.33.9.m1.1.1.cmml">86.94</mn><annotation-xml encoding="MathML-Content" id="S4.T3.33.33.9.m1.1b"><cn id="S4.T3.33.33.9.m1.1.1.cmml" type="float" xref="S4.T3.33.33.9.m1.1.1">86.94</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.33.33.9.m1.1c">86.94</annotation><annotation encoding="application/x-llamapun" id="S4.T3.33.33.9.m1.1d">86.94</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.34.34.10"><math alttext="79.94" class="ltx_Math" display="inline" id="S4.T3.34.34.10.m1.1"><semantics id="S4.T3.34.34.10.m1.1a"><mn id="S4.T3.34.34.10.m1.1.1" xref="S4.T3.34.34.10.m1.1.1.cmml">79.94</mn><annotation-xml encoding="MathML-Content" id="S4.T3.34.34.10.m1.1b"><cn id="S4.T3.34.34.10.m1.1.1.cmml" type="float" xref="S4.T3.34.34.10.m1.1.1">79.94</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.34.34.10.m1.1c">79.94</annotation><annotation encoding="application/x-llamapun" id="S4.T3.34.34.10.m1.1d">79.94</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.35.35.11"><math alttext="79.94" class="ltx_Math" display="inline" id="S4.T3.35.35.11.m1.1"><semantics id="S4.T3.35.35.11.m1.1a"><mn id="S4.T3.35.35.11.m1.1.1" xref="S4.T3.35.35.11.m1.1.1.cmml">79.94</mn><annotation-xml encoding="MathML-Content" id="S4.T3.35.35.11.m1.1b"><cn id="S4.T3.35.35.11.m1.1.1.cmml" type="float" xref="S4.T3.35.35.11.m1.1.1">79.94</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.35.35.11.m1.1c">79.94</annotation><annotation encoding="application/x-llamapun" id="S4.T3.35.35.11.m1.1d">79.94</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.36.36.12"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.36.36.12.1">79.94</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.48.48">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.48.48.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.48.48.14">RAG4RE+Fine-tuning</th>
<td class="ltx_td ltx_align_right" id="S4.T3.37.37.1"><math alttext="89.93" class="ltx_Math" display="inline" id="S4.T3.37.37.1.m1.1"><semantics id="S4.T3.37.37.1.m1.1a"><mn id="S4.T3.37.37.1.m1.1.1" xref="S4.T3.37.37.1.m1.1.1.cmml">89.93</mn><annotation-xml encoding="MathML-Content" id="S4.T3.37.37.1.m1.1b"><cn id="S4.T3.37.37.1.m1.1.1.cmml" type="float" xref="S4.T3.37.37.1.m1.1.1">89.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.37.37.1.m1.1c">89.93</annotation><annotation encoding="application/x-llamapun" id="S4.T3.37.37.1.m1.1d">89.93</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.38.38.2"><math alttext="94.17" class="ltx_Math" display="inline" id="S4.T3.38.38.2.m1.1"><semantics id="S4.T3.38.38.2.m1.1a"><mn id="S4.T3.38.38.2.m1.1.1" xref="S4.T3.38.38.2.m1.1.1.cmml">94.17</mn><annotation-xml encoding="MathML-Content" id="S4.T3.38.38.2.m1.1b"><cn id="S4.T3.38.38.2.m1.1.1.cmml" type="float" xref="S4.T3.38.38.2.m1.1.1">94.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.38.38.2.m1.1c">94.17</annotation><annotation encoding="application/x-llamapun" id="S4.T3.38.38.2.m1.1d">94.17</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.39.39.3"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.39.39.3.1">92.00</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.40.40.4"><math alttext="95.02" class="ltx_Math" display="inline" id="S4.T3.40.40.4.m1.1"><semantics id="S4.T3.40.40.4.m1.1a"><mn id="S4.T3.40.40.4.m1.1.1" xref="S4.T3.40.40.4.m1.1.1.cmml">95.02</mn><annotation-xml encoding="MathML-Content" id="S4.T3.40.40.4.m1.1b"><cn id="S4.T3.40.40.4.m1.1.1.cmml" type="float" xref="S4.T3.40.40.4.m1.1.1">95.02</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.40.40.4.m1.1c">95.02</annotation><annotation encoding="application/x-llamapun" id="S4.T3.40.40.4.m1.1d">95.02</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.41.41.5"><math alttext="93.66" class="ltx_Math" display="inline" id="S4.T3.41.41.5.m1.1"><semantics id="S4.T3.41.41.5.m1.1a"><mn id="S4.T3.41.41.5.m1.1.1" xref="S4.T3.41.41.5.m1.1.1.cmml">93.66</mn><annotation-xml encoding="MathML-Content" id="S4.T3.41.41.5.m1.1b"><cn id="S4.T3.41.41.5.m1.1.1.cmml" type="float" xref="S4.T3.41.41.5.m1.1.1">93.66</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.41.41.5.m1.1c">93.66</annotation><annotation encoding="application/x-llamapun" id="S4.T3.41.41.5.m1.1d">93.66</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.42.42.6"><math alttext="94.34" class="ltx_Math" display="inline" id="S4.T3.42.42.6.m1.1"><semantics id="S4.T3.42.42.6.m1.1a"><mn id="S4.T3.42.42.6.m1.1.1" xref="S4.T3.42.42.6.m1.1.1.cmml">94.34</mn><annotation-xml encoding="MathML-Content" id="S4.T3.42.42.6.m1.1b"><cn id="S4.T3.42.42.6.m1.1.1.cmml" type="float" xref="S4.T3.42.42.6.m1.1.1">94.34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.42.42.6.m1.1c">94.34</annotation><annotation encoding="application/x-llamapun" id="S4.T3.42.42.6.m1.1d">94.34</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.43.43.7"><math alttext="92.31" class="ltx_Math" display="inline" id="S4.T3.43.43.7.m1.1"><semantics id="S4.T3.43.43.7.m1.1a"><mn id="S4.T3.43.43.7.m1.1.1" xref="S4.T3.43.43.7.m1.1.1.cmml">92.31</mn><annotation-xml encoding="MathML-Content" id="S4.T3.43.43.7.m1.1b"><cn id="S4.T3.43.43.7.m1.1.1.cmml" type="float" xref="S4.T3.43.43.7.m1.1.1">92.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.43.43.7.m1.1c">92.31</annotation><annotation encoding="application/x-llamapun" id="S4.T3.43.43.7.m1.1d">92.31</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.44.44.8"><math alttext="93.73" class="ltx_Math" display="inline" id="S4.T3.44.44.8.m1.1"><semantics id="S4.T3.44.44.8.m1.1a"><mn id="S4.T3.44.44.8.m1.1.1" xref="S4.T3.44.44.8.m1.1.1.cmml">93.73</mn><annotation-xml encoding="MathML-Content" id="S4.T3.44.44.8.m1.1b"><cn id="S4.T3.44.44.8.m1.1.1.cmml" type="float" xref="S4.T3.44.44.8.m1.1.1">93.73</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.44.44.8.m1.1c">93.73</annotation><annotation encoding="application/x-llamapun" id="S4.T3.44.44.8.m1.1d">93.73</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.45.45.9"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.45.45.9.1">93.01</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.46.46.10"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.46.46.10.m1.1"><semantics id="S4.T3.46.46.10.m1.1a"><mo id="S4.T3.46.46.10.m1.1.1" xref="S4.T3.46.46.10.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.46.46.10.m1.1b"><minus id="S4.T3.46.46.10.m1.1.1.cmml" xref="S4.T3.46.46.10.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.46.46.10.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.46.46.10.m1.1d">-</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.47.47.11"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.47.47.11.m1.1"><semantics id="S4.T3.47.47.11.m1.1a"><mo id="S4.T3.47.47.11.m1.1.1" xref="S4.T3.47.47.11.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.47.47.11.m1.1b"><minus id="S4.T3.47.47.11.m1.1.1.cmml" xref="S4.T3.47.47.11.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.47.47.11.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.47.47.11.m1.1d">-</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.48.48.12"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.48.48.12.m1.1"><semantics id="S4.T3.48.48.12.m1.1a"><mo id="S4.T3.48.48.12.m1.1.1" xref="S4.T3.48.48.12.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.48.48.12.m1.1b"><minus id="S4.T3.48.48.12.m1.1.1.cmml" xref="S4.T3.48.48.12.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.48.48.12.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.48.48.12.m1.1d">-</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.60.60">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.60.60.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.60.60.13.1">
<span class="ltx_p" id="S4.T3.60.60.13.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_italic" id="S4.T3.60.60.13.1.1.1">Llama2-7B</span></span>
</span>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.60.60.14">simple query <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.49.49.1"><math alttext="84.97" class="ltx_Math" display="inline" id="S4.T3.49.49.1.m1.1"><semantics id="S4.T3.49.49.1.m1.1a"><mn id="S4.T3.49.49.1.m1.1.1" xref="S4.T3.49.49.1.m1.1.1.cmml">84.97</mn><annotation-xml encoding="MathML-Content" id="S4.T3.49.49.1.m1.1b"><cn id="S4.T3.49.49.1.m1.1.1.cmml" type="float" xref="S4.T3.49.49.1.m1.1.1">84.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.49.49.1.m1.1c">84.97</annotation><annotation encoding="application/x-llamapun" id="S4.T3.49.49.1.m1.1d">84.97</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.50.50.2"><math alttext="01.21" class="ltx_Math" display="inline" id="S4.T3.50.50.2.m1.1"><semantics id="S4.T3.50.50.2.m1.1a"><mn id="S4.T3.50.50.2.m1.1.1" xref="S4.T3.50.50.2.m1.1.1.cmml">01.21</mn><annotation-xml encoding="MathML-Content" id="S4.T3.50.50.2.m1.1b"><cn id="S4.T3.50.50.2.m1.1.1.cmml" type="float" xref="S4.T3.50.50.2.m1.1.1">01.21</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.50.50.2.m1.1c">01.21</annotation><annotation encoding="application/x-llamapun" id="S4.T3.50.50.2.m1.1d">01.21</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.51.51.3"><math alttext="02.38" class="ltx_Math" display="inline" id="S4.T3.51.51.3.m1.1"><semantics id="S4.T3.51.51.3.m1.1a"><mn id="S4.T3.51.51.3.m1.1.1" xref="S4.T3.51.51.3.m1.1.1.cmml">02.38</mn><annotation-xml encoding="MathML-Content" id="S4.T3.51.51.3.m1.1b"><cn id="S4.T3.51.51.3.m1.1.1.cmml" type="float" xref="S4.T3.51.51.3.m1.1.1">02.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.51.51.3.m1.1c">02.38</annotation><annotation encoding="application/x-llamapun" id="S4.T3.51.51.3.m1.1d">02.38</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.52.52.4"><math alttext="74.64" class="ltx_Math" display="inline" id="S4.T3.52.52.4.m1.1"><semantics id="S4.T3.52.52.4.m1.1a"><mn id="S4.T3.52.52.4.m1.1.1" xref="S4.T3.52.52.4.m1.1.1.cmml">74.64</mn><annotation-xml encoding="MathML-Content" id="S4.T3.52.52.4.m1.1b"><cn id="S4.T3.52.52.4.m1.1.1.cmml" type="float" xref="S4.T3.52.52.4.m1.1.1">74.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.52.52.4.m1.1c">74.64</annotation><annotation encoding="application/x-llamapun" id="S4.T3.52.52.4.m1.1d">74.64</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.53.53.5"><math alttext="00.44" class="ltx_Math" display="inline" id="S4.T3.53.53.5.m1.1"><semantics id="S4.T3.53.53.5.m1.1a"><mn id="S4.T3.53.53.5.m1.1.1" xref="S4.T3.53.53.5.m1.1.1.cmml">00.44</mn><annotation-xml encoding="MathML-Content" id="S4.T3.53.53.5.m1.1b"><cn id="S4.T3.53.53.5.m1.1.1.cmml" type="float" xref="S4.T3.53.53.5.m1.1.1">00.44</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.53.53.5.m1.1c">00.44</annotation><annotation encoding="application/x-llamapun" id="S4.T3.53.53.5.m1.1d">00.44</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.54.54.6"><math alttext="00.87" class="ltx_Math" display="inline" id="S4.T3.54.54.6.m1.1"><semantics id="S4.T3.54.54.6.m1.1a"><mn id="S4.T3.54.54.6.m1.1.1" xref="S4.T3.54.54.6.m1.1.1.cmml">00.87</mn><annotation-xml encoding="MathML-Content" id="S4.T3.54.54.6.m1.1b"><cn id="S4.T3.54.54.6.m1.1.1.cmml" type="float" xref="S4.T3.54.54.6.m1.1.1">00.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.54.54.6.m1.1c">00.87</annotation><annotation encoding="application/x-llamapun" id="S4.T3.54.54.6.m1.1d">00.87</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.55.55.7"><math alttext="80.2" class="ltx_Math" display="inline" id="S4.T3.55.55.7.m1.1"><semantics id="S4.T3.55.55.7.m1.1a"><mn id="S4.T3.55.55.7.m1.1.1" xref="S4.T3.55.55.7.m1.1.1.cmml">80.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.55.55.7.m1.1b"><cn id="S4.T3.55.55.7.m1.1.1.cmml" type="float" xref="S4.T3.55.55.7.m1.1.1">80.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.55.55.7.m1.1c">80.2</annotation><annotation encoding="application/x-llamapun" id="S4.T3.55.55.7.m1.1d">80.2</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.56.56.8"><math alttext="00.94" class="ltx_Math" display="inline" id="S4.T3.56.56.8.m1.1"><semantics id="S4.T3.56.56.8.m1.1a"><mn id="S4.T3.56.56.8.m1.1.1" xref="S4.T3.56.56.8.m1.1.1.cmml">00.94</mn><annotation-xml encoding="MathML-Content" id="S4.T3.56.56.8.m1.1b"><cn id="S4.T3.56.56.8.m1.1.1.cmml" type="float" xref="S4.T3.56.56.8.m1.1.1">00.94</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.56.56.8.m1.1c">00.94</annotation><annotation encoding="application/x-llamapun" id="S4.T3.56.56.8.m1.1d">00.94</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.57.57.9"><math alttext="01.86" class="ltx_Math" display="inline" id="S4.T3.57.57.9.m1.1"><semantics id="S4.T3.57.57.9.m1.1a"><mn id="S4.T3.57.57.9.m1.1.1" xref="S4.T3.57.57.9.m1.1.1.cmml">01.86</mn><annotation-xml encoding="MathML-Content" id="S4.T3.57.57.9.m1.1b"><cn id="S4.T3.57.57.9.m1.1.1.cmml" type="float" xref="S4.T3.57.57.9.m1.1.1">01.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.57.57.9.m1.1c">01.86</annotation><annotation encoding="application/x-llamapun" id="S4.T3.57.57.9.m1.1d">01.86</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.58.58.10"><math alttext="05.89" class="ltx_Math" display="inline" id="S4.T3.58.58.10.m1.1"><semantics id="S4.T3.58.58.10.m1.1a"><mn id="S4.T3.58.58.10.m1.1.1" xref="S4.T3.58.58.10.m1.1.1.cmml">05.89</mn><annotation-xml encoding="MathML-Content" id="S4.T3.58.58.10.m1.1b"><cn id="S4.T3.58.58.10.m1.1.1.cmml" type="float" xref="S4.T3.58.58.10.m1.1.1">05.89</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.58.58.10.m1.1c">05.89</annotation><annotation encoding="application/x-llamapun" id="S4.T3.58.58.10.m1.1d">05.89</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.59.59.11"><math alttext="05.08" class="ltx_Math" display="inline" id="S4.T3.59.59.11.m1.1"><semantics id="S4.T3.59.59.11.m1.1a"><mn id="S4.T3.59.59.11.m1.1.1" xref="S4.T3.59.59.11.m1.1.1.cmml">05.08</mn><annotation-xml encoding="MathML-Content" id="S4.T3.59.59.11.m1.1b"><cn id="S4.T3.59.59.11.m1.1.1.cmml" type="float" xref="S4.T3.59.59.11.m1.1.1">05.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.59.59.11.m1.1c">05.08</annotation><annotation encoding="application/x-llamapun" id="S4.T3.59.59.11.m1.1d">05.08</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.60.60.12"><math alttext="05.45" class="ltx_Math" display="inline" id="S4.T3.60.60.12.m1.1"><semantics id="S4.T3.60.60.12.m1.1a"><mn id="S4.T3.60.60.12.m1.1.1" xref="S4.T3.60.60.12.m1.1.1.cmml">05.45</mn><annotation-xml encoding="MathML-Content" id="S4.T3.60.60.12.m1.1b"><cn id="S4.T3.60.60.12.m1.1.1.cmml" type="float" xref="S4.T3.60.60.12.m1.1.1">05.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.60.60.12.m1.1c">05.45</annotation><annotation encoding="application/x-llamapun" id="S4.T3.60.60.12.m1.1d">05.45</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.72.72">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.72.72.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.72.72.14">RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right" id="S4.T3.61.61.1"><math alttext="81.23" class="ltx_Math" display="inline" id="S4.T3.61.61.1.m1.1"><semantics id="S4.T3.61.61.1.m1.1a"><mn id="S4.T3.61.61.1.m1.1.1" xref="S4.T3.61.61.1.m1.1.1.cmml">81.23</mn><annotation-xml encoding="MathML-Content" id="S4.T3.61.61.1.m1.1b"><cn id="S4.T3.61.61.1.m1.1.1.cmml" type="float" xref="S4.T3.61.61.1.m1.1.1">81.23</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.61.61.1.m1.1c">81.23</annotation><annotation encoding="application/x-llamapun" id="S4.T3.61.61.1.m1.1d">81.23</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.62.62.2"><math alttext="55.01" class="ltx_Math" display="inline" id="S4.T3.62.62.2.m1.1"><semantics id="S4.T3.62.62.2.m1.1a"><mn id="S4.T3.62.62.2.m1.1.1" xref="S4.T3.62.62.2.m1.1.1.cmml">55.01</mn><annotation-xml encoding="MathML-Content" id="S4.T3.62.62.2.m1.1b"><cn id="S4.T3.62.62.2.m1.1.1.cmml" type="float" xref="S4.T3.62.62.2.m1.1.1">55.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.62.62.2.m1.1c">55.01</annotation><annotation encoding="application/x-llamapun" id="S4.T3.62.62.2.m1.1d">55.01</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.63.63.3"><math alttext="65.59" class="ltx_Math" display="inline" id="S4.T3.63.63.3.m1.1"><semantics id="S4.T3.63.63.3.m1.1a"><mn id="S4.T3.63.63.3.m1.1.1" xref="S4.T3.63.63.3.m1.1.1.cmml">65.59</mn><annotation-xml encoding="MathML-Content" id="S4.T3.63.63.3.m1.1b"><cn id="S4.T3.63.63.3.m1.1.1.cmml" type="float" xref="S4.T3.63.63.3.m1.1.1">65.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.63.63.3.m1.1c">65.59</annotation><annotation encoding="application/x-llamapun" id="S4.T3.63.63.3.m1.1d">65.59</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.64.64.4"><math alttext="84.89" class="ltx_Math" display="inline" id="S4.T3.64.64.4.m1.1"><semantics id="S4.T3.64.64.4.m1.1a"><mn id="S4.T3.64.64.4.m1.1.1" xref="S4.T3.64.64.4.m1.1.1.cmml">84.89</mn><annotation-xml encoding="MathML-Content" id="S4.T3.64.64.4.m1.1b"><cn id="S4.T3.64.64.4.m1.1.1.cmml" type="float" xref="S4.T3.64.64.4.m1.1.1">84.89</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.64.64.4.m1.1c">84.89</annotation><annotation encoding="application/x-llamapun" id="S4.T3.64.64.4.m1.1d">84.89</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.65.65.5"><math alttext="54.57" class="ltx_Math" display="inline" id="S4.T3.65.65.5.m1.1"><semantics id="S4.T3.65.65.5.m1.1a"><mn id="S4.T3.65.65.5.m1.1.1" xref="S4.T3.65.65.5.m1.1.1.cmml">54.57</mn><annotation-xml encoding="MathML-Content" id="S4.T3.65.65.5.m1.1b"><cn id="S4.T3.65.65.5.m1.1.1.cmml" type="float" xref="S4.T3.65.65.5.m1.1.1">54.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.65.65.5.m1.1c">54.57</annotation><annotation encoding="application/x-llamapun" id="S4.T3.65.65.5.m1.1d">54.57</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.66.66.6"><math alttext="66.43" class="ltx_Math" display="inline" id="S4.T3.66.66.6.m1.1"><semantics id="S4.T3.66.66.6.m1.1a"><mn id="S4.T3.66.66.6.m1.1.1" xref="S4.T3.66.66.6.m1.1.1.cmml">66.43</mn><annotation-xml encoding="MathML-Content" id="S4.T3.66.66.6.m1.1b"><cn id="S4.T3.66.66.6.m1.1.1.cmml" type="float" xref="S4.T3.66.66.6.m1.1.1">66.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.66.66.6.m1.1c">66.43</annotation><annotation encoding="application/x-llamapun" id="S4.T3.66.66.6.m1.1d">66.43</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.67.67.7"><math alttext="55.93" class="ltx_Math" display="inline" id="S4.T3.67.67.7.m1.1"><semantics id="S4.T3.67.67.7.m1.1a"><mn id="S4.T3.67.67.7.m1.1.1" xref="S4.T3.67.67.7.m1.1.1.cmml">55.93</mn><annotation-xml encoding="MathML-Content" id="S4.T3.67.67.7.m1.1b"><cn id="S4.T3.67.67.7.m1.1.1.cmml" type="float" xref="S4.T3.67.67.7.m1.1.1">55.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.67.67.7.m1.1c">55.93</annotation><annotation encoding="application/x-llamapun" id="S4.T3.67.67.7.m1.1d">55.93</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.68.68.8"><math alttext="03.46" class="ltx_Math" display="inline" id="S4.T3.68.68.8.m1.1"><semantics id="S4.T3.68.68.8.m1.1a"><mn id="S4.T3.68.68.8.m1.1.1" xref="S4.T3.68.68.8.m1.1.1.cmml">03.46</mn><annotation-xml encoding="MathML-Content" id="S4.T3.68.68.8.m1.1b"><cn id="S4.T3.68.68.8.m1.1.1.cmml" type="float" xref="S4.T3.68.68.8.m1.1.1">03.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.68.68.8.m1.1c">03.46</annotation><annotation encoding="application/x-llamapun" id="S4.T3.68.68.8.m1.1d">03.46</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.69.69.9"><math alttext="06.52" class="ltx_Math" display="inline" id="S4.T3.69.69.9.m1.1"><semantics id="S4.T3.69.69.9.m1.1a"><mn id="S4.T3.69.69.9.m1.1.1" xref="S4.T3.69.69.9.m1.1.1.cmml">06.52</mn><annotation-xml encoding="MathML-Content" id="S4.T3.69.69.9.m1.1b"><cn id="S4.T3.69.69.9.m1.1.1.cmml" type="float" xref="S4.T3.69.69.9.m1.1.1">06.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.69.69.9.m1.1c">06.52</annotation><annotation encoding="application/x-llamapun" id="S4.T3.69.69.9.m1.1d">06.52</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.70.70.10"><math alttext="04.36" class="ltx_Math" display="inline" id="S4.T3.70.70.10.m1.1"><semantics id="S4.T3.70.70.10.m1.1a"><mn id="S4.T3.70.70.10.m1.1.1" xref="S4.T3.70.70.10.m1.1.1.cmml">04.36</mn><annotation-xml encoding="MathML-Content" id="S4.T3.70.70.10.m1.1b"><cn id="S4.T3.70.70.10.m1.1.1.cmml" type="float" xref="S4.T3.70.70.10.m1.1.1">04.36</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.70.70.10.m1.1c">04.36</annotation><annotation encoding="application/x-llamapun" id="S4.T3.70.70.10.m1.1d">04.36</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.71.71.11"><math alttext="04.20" class="ltx_Math" display="inline" id="S4.T3.71.71.11.m1.1"><semantics id="S4.T3.71.71.11.m1.1a"><mn id="S4.T3.71.71.11.m1.1.1" xref="S4.T3.71.71.11.m1.1.1.cmml">04.20</mn><annotation-xml encoding="MathML-Content" id="S4.T3.71.71.11.m1.1b"><cn id="S4.T3.71.71.11.m1.1.1.cmml" type="float" xref="S4.T3.71.71.11.m1.1.1">04.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.71.71.11.m1.1c">04.20</annotation><annotation encoding="application/x-llamapun" id="S4.T3.71.71.11.m1.1d">04.20</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.72.72.12"><math alttext="04.28" class="ltx_Math" display="inline" id="S4.T3.72.72.12.m1.1"><semantics id="S4.T3.72.72.12.m1.1a"><mn id="S4.T3.72.72.12.m1.1.1" xref="S4.T3.72.72.12.m1.1.1.cmml">04.28</mn><annotation-xml encoding="MathML-Content" id="S4.T3.72.72.12.m1.1b"><cn id="S4.T3.72.72.12.m1.1.1.cmml" type="float" xref="S4.T3.72.72.12.m1.1.1">04.28</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.72.72.12.m1.1c">04.28</annotation><annotation encoding="application/x-llamapun" id="S4.T3.72.72.12.m1.1d">04.28</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.84.84">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.84.84.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.84.84.14">Fine-tuning (QLoRA)</th>
<td class="ltx_td ltx_align_right" id="S4.T3.73.73.1"><math alttext="88.07" class="ltx_Math" display="inline" id="S4.T3.73.73.1.m1.1"><semantics id="S4.T3.73.73.1.m1.1a"><mn id="S4.T3.73.73.1.m1.1.1" xref="S4.T3.73.73.1.m1.1.1.cmml">88.07</mn><annotation-xml encoding="MathML-Content" id="S4.T3.73.73.1.m1.1b"><cn id="S4.T3.73.73.1.m1.1.1.cmml" type="float" xref="S4.T3.73.73.1.m1.1.1">88.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.73.73.1.m1.1c">88.07</annotation><annotation encoding="application/x-llamapun" id="S4.T3.73.73.1.m1.1d">88.07</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.74.74.2"><math alttext="88.34" class="ltx_Math" display="inline" id="S4.T3.74.74.2.m1.1"><semantics id="S4.T3.74.74.2.m1.1a"><mn id="S4.T3.74.74.2.m1.1.1" xref="S4.T3.74.74.2.m1.1.1.cmml">88.34</mn><annotation-xml encoding="MathML-Content" id="S4.T3.74.74.2.m1.1b"><cn id="S4.T3.74.74.2.m1.1.1.cmml" type="float" xref="S4.T3.74.74.2.m1.1.1">88.34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.74.74.2.m1.1c">88.34</annotation><annotation encoding="application/x-llamapun" id="S4.T3.74.74.2.m1.1d">88.34</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.75.75.3"><math alttext="88.20" class="ltx_Math" display="inline" id="S4.T3.75.75.3.m1.1"><semantics id="S4.T3.75.75.3.m1.1a"><mn id="S4.T3.75.75.3.m1.1.1" xref="S4.T3.75.75.3.m1.1.1.cmml">88.20</mn><annotation-xml encoding="MathML-Content" id="S4.T3.75.75.3.m1.1b"><cn id="S4.T3.75.75.3.m1.1.1.cmml" type="float" xref="S4.T3.75.75.3.m1.1.1">88.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.75.75.3.m1.1c">88.20</annotation><annotation encoding="application/x-llamapun" id="S4.T3.75.75.3.m1.1d">88.20</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.76.76.4"><math alttext="90.07" class="ltx_Math" display="inline" id="S4.T3.76.76.4.m1.1"><semantics id="S4.T3.76.76.4.m1.1a"><mn id="S4.T3.76.76.4.m1.1.1" xref="S4.T3.76.76.4.m1.1.1.cmml">90.07</mn><annotation-xml encoding="MathML-Content" id="S4.T3.76.76.4.m1.1b"><cn id="S4.T3.76.76.4.m1.1.1.cmml" type="float" xref="S4.T3.76.76.4.m1.1.1">90.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.76.76.4.m1.1c">90.07</annotation><annotation encoding="application/x-llamapun" id="S4.T3.76.76.4.m1.1d">90.07</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.77.77.5"><math alttext="97.73" class="ltx_Math" display="inline" id="S4.T3.77.77.5.m1.1"><semantics id="S4.T3.77.77.5.m1.1a"><mn id="S4.T3.77.77.5.m1.1.1" xref="S4.T3.77.77.5.m1.1.1.cmml">97.73</mn><annotation-xml encoding="MathML-Content" id="S4.T3.77.77.5.m1.1b"><cn id="S4.T3.77.77.5.m1.1.1.cmml" type="float" xref="S4.T3.77.77.5.m1.1.1">97.73</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.77.77.5.m1.1c">97.73</annotation><annotation encoding="application/x-llamapun" id="S4.T3.77.77.5.m1.1d">97.73</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.78.78.6"><math alttext="93.75" class="ltx_Math" display="inline" id="S4.T3.78.78.6.m1.1"><semantics id="S4.T3.78.78.6.m1.1a"><mn id="S4.T3.78.78.6.m1.1.1" xref="S4.T3.78.78.6.m1.1.1.cmml">93.75</mn><annotation-xml encoding="MathML-Content" id="S4.T3.78.78.6.m1.1b"><cn id="S4.T3.78.78.6.m1.1.1.cmml" type="float" xref="S4.T3.78.78.6.m1.1.1">93.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.78.78.6.m1.1c">93.75</annotation><annotation encoding="application/x-llamapun" id="S4.T3.78.78.6.m1.1d">93.75</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.79.79.7"><math alttext="87.54" class="ltx_Math" display="inline" id="S4.T3.79.79.7.m1.1"><semantics id="S4.T3.79.79.7.m1.1a"><mn id="S4.T3.79.79.7.m1.1.1" xref="S4.T3.79.79.7.m1.1.1.cmml">87.54</mn><annotation-xml encoding="MathML-Content" id="S4.T3.79.79.7.m1.1b"><cn id="S4.T3.79.79.7.m1.1.1.cmml" type="float" xref="S4.T3.79.79.7.m1.1.1">87.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.79.79.7.m1.1c">87.54</annotation><annotation encoding="application/x-llamapun" id="S4.T3.79.79.7.m1.1d">87.54</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.80.80.8"><math alttext="44.58" class="ltx_Math" display="inline" id="S4.T3.80.80.8.m1.1"><semantics id="S4.T3.80.80.8.m1.1a"><mn id="S4.T3.80.80.8.m1.1.1" xref="S4.T3.80.80.8.m1.1.1.cmml">44.58</mn><annotation-xml encoding="MathML-Content" id="S4.T3.80.80.8.m1.1b"><cn id="S4.T3.80.80.8.m1.1.1.cmml" type="float" xref="S4.T3.80.80.8.m1.1.1">44.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.80.80.8.m1.1c">44.58</annotation><annotation encoding="application/x-llamapun" id="S4.T3.80.80.8.m1.1d">44.58</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.81.81.9"><math alttext="59.08" class="ltx_Math" display="inline" id="S4.T3.81.81.9.m1.1"><semantics id="S4.T3.81.81.9.m1.1a"><mn id="S4.T3.81.81.9.m1.1.1" xref="S4.T3.81.81.9.m1.1.1.cmml">59.08</mn><annotation-xml encoding="MathML-Content" id="S4.T3.81.81.9.m1.1b"><cn id="S4.T3.81.81.9.m1.1.1.cmml" type="float" xref="S4.T3.81.81.9.m1.1.1">59.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.81.81.9.m1.1c">59.08</annotation><annotation encoding="application/x-llamapun" id="S4.T3.81.81.9.m1.1d">59.08</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.82.82.10"><math alttext="57.20" class="ltx_Math" display="inline" id="S4.T3.82.82.10.m1.1"><semantics id="S4.T3.82.82.10.m1.1a"><mn id="S4.T3.82.82.10.m1.1.1" xref="S4.T3.82.82.10.m1.1.1.cmml">57.20</mn><annotation-xml encoding="MathML-Content" id="S4.T3.82.82.10.m1.1b"><cn id="S4.T3.82.82.10.m1.1.1.cmml" type="float" xref="S4.T3.82.82.10.m1.1.1">57.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.82.82.10.m1.1c">57.20</annotation><annotation encoding="application/x-llamapun" id="S4.T3.82.82.10.m1.1d">57.20</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.83.83.11"><math alttext="50.13" class="ltx_Math" display="inline" id="S4.T3.83.83.11.m1.1"><semantics id="S4.T3.83.83.11.m1.1a"><mn id="S4.T3.83.83.11.m1.1.1" xref="S4.T3.83.83.11.m1.1.1.cmml">50.13</mn><annotation-xml encoding="MathML-Content" id="S4.T3.83.83.11.m1.1b"><cn id="S4.T3.83.83.11.m1.1.1.cmml" type="float" xref="S4.T3.83.83.11.m1.1.1">50.13</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.83.83.11.m1.1c">50.13</annotation><annotation encoding="application/x-llamapun" id="S4.T3.83.83.11.m1.1d">50.13</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.84.84.12"><math alttext="53.43" class="ltx_Math" display="inline" id="S4.T3.84.84.12.m1.1"><semantics id="S4.T3.84.84.12.m1.1a"><mn id="S4.T3.84.84.12.m1.1.1" xref="S4.T3.84.84.12.m1.1.1.cmml">53.43</mn><annotation-xml encoding="MathML-Content" id="S4.T3.84.84.12.m1.1b"><cn id="S4.T3.84.84.12.m1.1.1.cmml" type="float" xref="S4.T3.84.84.12.m1.1.1">53.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.84.84.12.m1.1c">53.43</annotation><annotation encoding="application/x-llamapun" id="S4.T3.84.84.12.m1.1d">53.43</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.96.96">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.96.96.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.96.96.14">RAG4RE+Fine-tuning</th>
<td class="ltx_td ltx_align_right" id="S4.T3.85.85.1"><math alttext="80.29" class="ltx_Math" display="inline" id="S4.T3.85.85.1.m1.1"><semantics id="S4.T3.85.85.1.m1.1a"><mn id="S4.T3.85.85.1.m1.1.1" xref="S4.T3.85.85.1.m1.1.1.cmml">80.29</mn><annotation-xml encoding="MathML-Content" id="S4.T3.85.85.1.m1.1b"><cn id="S4.T3.85.85.1.m1.1.1.cmml" type="float" xref="S4.T3.85.85.1.m1.1.1">80.29</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.85.85.1.m1.1c">80.29</annotation><annotation encoding="application/x-llamapun" id="S4.T3.85.85.1.m1.1d">80.29</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.86.86.2"><math alttext="89.18" class="ltx_Math" display="inline" id="S4.T3.86.86.2.m1.1"><semantics id="S4.T3.86.86.2.m1.1a"><mn id="S4.T3.86.86.2.m1.1.1" xref="S4.T3.86.86.2.m1.1.1.cmml">89.18</mn><annotation-xml encoding="MathML-Content" id="S4.T3.86.86.2.m1.1b"><cn id="S4.T3.86.86.2.m1.1.1.cmml" type="float" xref="S4.T3.86.86.2.m1.1.1">89.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.86.86.2.m1.1c">89.18</annotation><annotation encoding="application/x-llamapun" id="S4.T3.86.86.2.m1.1d">89.18</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.87.87.3"><math alttext="84.50" class="ltx_Math" display="inline" id="S4.T3.87.87.3.m1.1"><semantics id="S4.T3.87.87.3.m1.1a"><mn id="S4.T3.87.87.3.m1.1.1" xref="S4.T3.87.87.3.m1.1.1.cmml">84.50</mn><annotation-xml encoding="MathML-Content" id="S4.T3.87.87.3.m1.1b"><cn id="S4.T3.87.87.3.m1.1.1.cmml" type="float" xref="S4.T3.87.87.3.m1.1.1">84.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.87.87.3.m1.1c">84.50</annotation><annotation encoding="application/x-llamapun" id="S4.T3.87.87.3.m1.1d">84.50</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.88.88.4"><math alttext="84.10" class="ltx_Math" display="inline" id="S4.T3.88.88.4.m1.1"><semantics id="S4.T3.88.88.4.m1.1a"><mn id="S4.T3.88.88.4.m1.1.1" xref="S4.T3.88.88.4.m1.1.1.cmml">84.10</mn><annotation-xml encoding="MathML-Content" id="S4.T3.88.88.4.m1.1b"><cn id="S4.T3.88.88.4.m1.1.1.cmml" type="float" xref="S4.T3.88.88.4.m1.1.1">84.10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.88.88.4.m1.1c">84.10</annotation><annotation encoding="application/x-llamapun" id="S4.T3.88.88.4.m1.1d">84.10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.89.89.5"><math alttext="97.26" class="ltx_Math" display="inline" id="S4.T3.89.89.5.m1.1"><semantics id="S4.T3.89.89.5.m1.1a"><mn id="S4.T3.89.89.5.m1.1.1" xref="S4.T3.89.89.5.m1.1.1.cmml">97.26</mn><annotation-xml encoding="MathML-Content" id="S4.T3.89.89.5.m1.1b"><cn id="S4.T3.89.89.5.m1.1.1.cmml" type="float" xref="S4.T3.89.89.5.m1.1.1">97.26</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.89.89.5.m1.1c">97.26</annotation><annotation encoding="application/x-llamapun" id="S4.T3.89.89.5.m1.1d">97.26</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.90.90.6"><math alttext="90.22" class="ltx_Math" display="inline" id="S4.T3.90.90.6.m1.1"><semantics id="S4.T3.90.90.6.m1.1a"><mn id="S4.T3.90.90.6.m1.1.1" xref="S4.T3.90.90.6.m1.1.1.cmml">90.22</mn><annotation-xml encoding="MathML-Content" id="S4.T3.90.90.6.m1.1b"><cn id="S4.T3.90.90.6.m1.1.1.cmml" type="float" xref="S4.T3.90.90.6.m1.1.1">90.22</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.90.90.6.m1.1c">90.22</annotation><annotation encoding="application/x-llamapun" id="S4.T3.90.90.6.m1.1d">90.22</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.91.91.7"><math alttext="83.53" class="ltx_Math" display="inline" id="S4.T3.91.91.7.m1.1"><semantics id="S4.T3.91.91.7.m1.1a"><mn id="S4.T3.91.91.7.m1.1.1" xref="S4.T3.91.91.7.m1.1.1.cmml">83.53</mn><annotation-xml encoding="MathML-Content" id="S4.T3.91.91.7.m1.1b"><cn id="S4.T3.91.91.7.m1.1.1.cmml" type="float" xref="S4.T3.91.91.7.m1.1.1">83.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.91.91.7.m1.1c">83.53</annotation><annotation encoding="application/x-llamapun" id="S4.T3.91.91.7.m1.1d">83.53</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.92.92.8"><math alttext="68.16" class="ltx_Math" display="inline" id="S4.T3.92.92.8.m1.1"><semantics id="S4.T3.92.92.8.m1.1a"><mn id="S4.T3.92.92.8.m1.1.1" xref="S4.T3.92.92.8.m1.1.1.cmml">68.16</mn><annotation-xml encoding="MathML-Content" id="S4.T3.92.92.8.m1.1b"><cn id="S4.T3.92.92.8.m1.1.1.cmml" type="float" xref="S4.T3.92.92.8.m1.1.1">68.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.92.92.8.m1.1c">68.16</annotation><annotation encoding="application/x-llamapun" id="S4.T3.92.92.8.m1.1d">68.16</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.93.93.9"><math alttext="75.07" class="ltx_Math" display="inline" id="S4.T3.93.93.9.m1.1"><semantics id="S4.T3.93.93.9.m1.1a"><mn id="S4.T3.93.93.9.m1.1.1" xref="S4.T3.93.93.9.m1.1.1.cmml">75.07</mn><annotation-xml encoding="MathML-Content" id="S4.T3.93.93.9.m1.1b"><cn id="S4.T3.93.93.9.m1.1.1.cmml" type="float" xref="S4.T3.93.93.9.m1.1.1">75.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.93.93.9.m1.1c">75.07</annotation><annotation encoding="application/x-llamapun" id="S4.T3.93.93.9.m1.1d">75.07</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.94.94.10"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.94.94.10.m1.1"><semantics id="S4.T3.94.94.10.m1.1a"><mo id="S4.T3.94.94.10.m1.1.1" xref="S4.T3.94.94.10.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.94.94.10.m1.1b"><minus id="S4.T3.94.94.10.m1.1.1.cmml" xref="S4.T3.94.94.10.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.94.94.10.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.94.94.10.m1.1d">-</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.95.95.11"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.95.95.11.m1.1"><semantics id="S4.T3.95.95.11.m1.1a"><mo id="S4.T3.95.95.11.m1.1.1" xref="S4.T3.95.95.11.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.95.95.11.m1.1b"><minus id="S4.T3.95.95.11.m1.1.1.cmml" xref="S4.T3.95.95.11.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.95.95.11.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.95.95.11.m1.1d">-</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.96.96.12"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.96.96.12.m1.1"><semantics id="S4.T3.96.96.12.m1.1a"><mo id="S4.T3.96.96.12.m1.1.1" xref="S4.T3.96.96.12.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.96.96.12.m1.1b"><minus id="S4.T3.96.96.12.m1.1.1.cmml" xref="S4.T3.96.96.12.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.96.96.12.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.96.96.12.m1.1d">-</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.108.108">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.108.108.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T3.108.108.13.1">
<span class="ltx_p" id="S4.T3.108.108.13.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_italic" id="S4.T3.108.108.13.1.1.1">Mistral-7B</span></span>
</span>
</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.108.108.14">simple query <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.97.97.1"><math alttext="94.67" class="ltx_Math" display="inline" id="S4.T3.97.97.1.m1.1"><semantics id="S4.T3.97.97.1.m1.1a"><mn id="S4.T3.97.97.1.m1.1.1" xref="S4.T3.97.97.1.m1.1.1.cmml">94.67</mn><annotation-xml encoding="MathML-Content" id="S4.T3.97.97.1.m1.1b"><cn id="S4.T3.97.97.1.m1.1.1.cmml" type="float" xref="S4.T3.97.97.1.m1.1.1">94.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.97.97.1.m1.1c">94.67</annotation><annotation encoding="application/x-llamapun" id="S4.T3.97.97.1.m1.1d">94.67</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.98.98.2"><math alttext="11.96" class="ltx_Math" display="inline" id="S4.T3.98.98.2.m1.1"><semantics id="S4.T3.98.98.2.m1.1a"><mn id="S4.T3.98.98.2.m1.1.1" xref="S4.T3.98.98.2.m1.1.1.cmml">11.96</mn><annotation-xml encoding="MathML-Content" id="S4.T3.98.98.2.m1.1b"><cn id="S4.T3.98.98.2.m1.1.1.cmml" type="float" xref="S4.T3.98.98.2.m1.1.1">11.96</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.98.98.2.m1.1c">11.96</annotation><annotation encoding="application/x-llamapun" id="S4.T3.98.98.2.m1.1d">11.96</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.99.99.3"><math alttext="21.23" class="ltx_Math" display="inline" id="S4.T3.99.99.3.m1.1"><semantics id="S4.T3.99.99.3.m1.1a"><mn id="S4.T3.99.99.3.m1.1.1" xref="S4.T3.99.99.3.m1.1.1.cmml">21.23</mn><annotation-xml encoding="MathML-Content" id="S4.T3.99.99.3.m1.1b"><cn id="S4.T3.99.99.3.m1.1.1.cmml" type="float" xref="S4.T3.99.99.3.m1.1.1">21.23</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.99.99.3.m1.1c">21.23</annotation><annotation encoding="application/x-llamapun" id="S4.T3.99.99.3.m1.1d">21.23</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.100.100.4"><math alttext="92.34" class="ltx_Math" display="inline" id="S4.T3.100.100.4.m1.1"><semantics id="S4.T3.100.100.4.m1.1a"><mn id="S4.T3.100.100.4.m1.1.1" xref="S4.T3.100.100.4.m1.1.1.cmml">92.34</mn><annotation-xml encoding="MathML-Content" id="S4.T3.100.100.4.m1.1b"><cn id="S4.T3.100.100.4.m1.1.1.cmml" type="float" xref="S4.T3.100.100.4.m1.1.1">92.34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.100.100.4.m1.1c">92.34</annotation><annotation encoding="application/x-llamapun" id="S4.T3.100.100.4.m1.1d">92.34</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.101.101.5"><math alttext="05.15" class="ltx_Math" display="inline" id="S4.T3.101.101.5.m1.1"><semantics id="S4.T3.101.101.5.m1.1a"><mn id="S4.T3.101.101.5.m1.1.1" xref="S4.T3.101.101.5.m1.1.1.cmml">05.15</mn><annotation-xml encoding="MathML-Content" id="S4.T3.101.101.5.m1.1b"><cn id="S4.T3.101.101.5.m1.1.1.cmml" type="float" xref="S4.T3.101.101.5.m1.1.1">05.15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.101.101.5.m1.1c">05.15</annotation><annotation encoding="application/x-llamapun" id="S4.T3.101.101.5.m1.1d">05.15</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.102.102.6"><math alttext="09.75" class="ltx_Math" display="inline" id="S4.T3.102.102.6.m1.1"><semantics id="S4.T3.102.102.6.m1.1a"><mn id="S4.T3.102.102.6.m1.1.1" xref="S4.T3.102.102.6.m1.1.1.cmml">09.75</mn><annotation-xml encoding="MathML-Content" id="S4.T3.102.102.6.m1.1b"><cn id="S4.T3.102.102.6.m1.1.1.cmml" type="float" xref="S4.T3.102.102.6.m1.1.1">09.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.102.102.6.m1.1c">09.75</annotation><annotation encoding="application/x-llamapun" id="S4.T3.102.102.6.m1.1d">09.75</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.103.103.7"><math alttext="64.64" class="ltx_Math" display="inline" id="S4.T3.103.103.7.m1.1"><semantics id="S4.T3.103.103.7.m1.1a"><mn id="S4.T3.103.103.7.m1.1.1" xref="S4.T3.103.103.7.m1.1.1.cmml">64.64</mn><annotation-xml encoding="MathML-Content" id="S4.T3.103.103.7.m1.1b"><cn id="S4.T3.103.103.7.m1.1.1.cmml" type="float" xref="S4.T3.103.103.7.m1.1.1">64.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.103.103.7.m1.1c">64.64</annotation><annotation encoding="application/x-llamapun" id="S4.T3.103.103.7.m1.1d">64.64</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.104.104.8"><math alttext="05.48" class="ltx_Math" display="inline" id="S4.T3.104.104.8.m1.1"><semantics id="S4.T3.104.104.8.m1.1a"><mn id="S4.T3.104.104.8.m1.1.1" xref="S4.T3.104.104.8.m1.1.1.cmml">05.48</mn><annotation-xml encoding="MathML-Content" id="S4.T3.104.104.8.m1.1b"><cn id="S4.T3.104.104.8.m1.1.1.cmml" type="float" xref="S4.T3.104.104.8.m1.1.1">05.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.104.104.8.m1.1c">05.48</annotation><annotation encoding="application/x-llamapun" id="S4.T3.104.104.8.m1.1d">05.48</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S4.T3.105.105.9"><math alttext="10.11" class="ltx_Math" display="inline" id="S4.T3.105.105.9.m1.1"><semantics id="S4.T3.105.105.9.m1.1a"><mn id="S4.T3.105.105.9.m1.1.1" xref="S4.T3.105.105.9.m1.1.1.cmml">10.11</mn><annotation-xml encoding="MathML-Content" id="S4.T3.105.105.9.m1.1b"><cn id="S4.T3.105.105.9.m1.1.1.cmml" type="float" xref="S4.T3.105.105.9.m1.1.1">10.11</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.105.105.9.m1.1c">10.11</annotation><annotation encoding="application/x-llamapun" id="S4.T3.105.105.9.m1.1d">10.11</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.106.106.10"><math alttext="25.50" class="ltx_Math" display="inline" id="S4.T3.106.106.10.m1.1"><semantics id="S4.T3.106.106.10.m1.1a"><mn id="S4.T3.106.106.10.m1.1.1" xref="S4.T3.106.106.10.m1.1.1.cmml">25.50</mn><annotation-xml encoding="MathML-Content" id="S4.T3.106.106.10.m1.1b"><cn id="S4.T3.106.106.10.m1.1.1.cmml" type="float" xref="S4.T3.106.106.10.m1.1.1">25.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.106.106.10.m1.1c">25.50</annotation><annotation encoding="application/x-llamapun" id="S4.T3.106.106.10.m1.1d">25.50</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.107.107.11"><math alttext="24.37" class="ltx_Math" display="inline" id="S4.T3.107.107.11.m1.1"><semantics id="S4.T3.107.107.11.m1.1a"><mn id="S4.T3.107.107.11.m1.1.1" xref="S4.T3.107.107.11.m1.1.1.cmml">24.37</mn><annotation-xml encoding="MathML-Content" id="S4.T3.107.107.11.m1.1b"><cn id="S4.T3.107.107.11.m1.1.1.cmml" type="float" xref="S4.T3.107.107.11.m1.1.1">24.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.107.107.11.m1.1c">24.37</annotation><annotation encoding="application/x-llamapun" id="S4.T3.107.107.11.m1.1d">24.37</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.108.108.12"><math alttext="24.92" class="ltx_Math" display="inline" id="S4.T3.108.108.12.m1.1"><semantics id="S4.T3.108.108.12.m1.1a"><mn id="S4.T3.108.108.12.m1.1.1" xref="S4.T3.108.108.12.m1.1.1.cmml">24.92</mn><annotation-xml encoding="MathML-Content" id="S4.T3.108.108.12.m1.1b"><cn id="S4.T3.108.108.12.m1.1.1.cmml" type="float" xref="S4.T3.108.108.12.m1.1.1">24.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.108.108.12.m1.1c">24.92</annotation><annotation encoding="application/x-llamapun" id="S4.T3.108.108.12.m1.1d">24.92</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.120.120">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.120.120.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.120.120.14">RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_right" id="S4.T3.109.109.1"><math alttext="87.81" class="ltx_Math" display="inline" id="S4.T3.109.109.1.m1.1"><semantics id="S4.T3.109.109.1.m1.1a"><mn id="S4.T3.109.109.1.m1.1.1" xref="S4.T3.109.109.1.m1.1.1.cmml">87.81</mn><annotation-xml encoding="MathML-Content" id="S4.T3.109.109.1.m1.1b"><cn id="S4.T3.109.109.1.m1.1.1.cmml" type="float" xref="S4.T3.109.109.1.m1.1.1">87.81</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.109.109.1.m1.1c">87.81</annotation><annotation encoding="application/x-llamapun" id="S4.T3.109.109.1.m1.1d">87.81</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.110.110.2"><math alttext="30.10" class="ltx_Math" display="inline" id="S4.T3.110.110.2.m1.1"><semantics id="S4.T3.110.110.2.m1.1a"><mn id="S4.T3.110.110.2.m1.1.1" xref="S4.T3.110.110.2.m1.1.1.cmml">30.10</mn><annotation-xml encoding="MathML-Content" id="S4.T3.110.110.2.m1.1b"><cn id="S4.T3.110.110.2.m1.1.1.cmml" type="float" xref="S4.T3.110.110.2.m1.1.1">30.10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.110.110.2.m1.1c">30.10</annotation><annotation encoding="application/x-llamapun" id="S4.T3.110.110.2.m1.1d">30.10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.111.111.3"><math alttext="44.83" class="ltx_Math" display="inline" id="S4.T3.111.111.3.m1.1"><semantics id="S4.T3.111.111.3.m1.1a"><mn id="S4.T3.111.111.3.m1.1.1" xref="S4.T3.111.111.3.m1.1.1.cmml">44.83</mn><annotation-xml encoding="MathML-Content" id="S4.T3.111.111.3.m1.1b"><cn id="S4.T3.111.111.3.m1.1.1.cmml" type="float" xref="S4.T3.111.111.3.m1.1.1">44.83</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.111.111.3.m1.1c">44.83</annotation><annotation encoding="application/x-llamapun" id="S4.T3.111.111.3.m1.1d">44.83</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.112.112.4"><math alttext="93.23" class="ltx_Math" display="inline" id="S4.T3.112.112.4.m1.1"><semantics id="S4.T3.112.112.4.m1.1a"><mn id="S4.T3.112.112.4.m1.1.1" xref="S4.T3.112.112.4.m1.1.1.cmml">93.23</mn><annotation-xml encoding="MathML-Content" id="S4.T3.112.112.4.m1.1b"><cn id="S4.T3.112.112.4.m1.1.1.cmml" type="float" xref="S4.T3.112.112.4.m1.1.1">93.23</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.112.112.4.m1.1c">93.23</annotation><annotation encoding="application/x-llamapun" id="S4.T3.112.112.4.m1.1d">93.23</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.113.113.5"><math alttext="22.59" class="ltx_Math" display="inline" id="S4.T3.113.113.5.m1.1"><semantics id="S4.T3.113.113.5.m1.1a"><mn id="S4.T3.113.113.5.m1.1.1" xref="S4.T3.113.113.5.m1.1.1.cmml">22.59</mn><annotation-xml encoding="MathML-Content" id="S4.T3.113.113.5.m1.1b"><cn id="S4.T3.113.113.5.m1.1.1.cmml" type="float" xref="S4.T3.113.113.5.m1.1.1">22.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.113.113.5.m1.1c">22.59</annotation><annotation encoding="application/x-llamapun" id="S4.T3.113.113.5.m1.1d">22.59</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.114.114.6"><math alttext="36.36" class="ltx_Math" display="inline" id="S4.T3.114.114.6.m1.1"><semantics id="S4.T3.114.114.6.m1.1a"><mn id="S4.T3.114.114.6.m1.1.1" xref="S4.T3.114.114.6.m1.1.1.cmml">36.36</mn><annotation-xml encoding="MathML-Content" id="S4.T3.114.114.6.m1.1b"><cn id="S4.T3.114.114.6.m1.1.1.cmml" type="float" xref="S4.T3.114.114.6.m1.1.1">36.36</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.114.114.6.m1.1c">36.36</annotation><annotation encoding="application/x-llamapun" id="S4.T3.114.114.6.m1.1d">36.36</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.115.115.7"><math alttext="60.19" class="ltx_Math" display="inline" id="S4.T3.115.115.7.m1.1"><semantics id="S4.T3.115.115.7.m1.1a"><mn id="S4.T3.115.115.7.m1.1.1" xref="S4.T3.115.115.7.m1.1.1.cmml">60.19</mn><annotation-xml encoding="MathML-Content" id="S4.T3.115.115.7.m1.1b"><cn id="S4.T3.115.115.7.m1.1.1.cmml" type="float" xref="S4.T3.115.115.7.m1.1.1">60.19</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.115.115.7.m1.1c">60.19</annotation><annotation encoding="application/x-llamapun" id="S4.T3.115.115.7.m1.1d">60.19</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.116.116.8"><math alttext="30.08" class="ltx_Math" display="inline" id="S4.T3.116.116.8.m1.1"><semantics id="S4.T3.116.116.8.m1.1a"><mn id="S4.T3.116.116.8.m1.1.1" xref="S4.T3.116.116.8.m1.1.1.cmml">30.08</mn><annotation-xml encoding="MathML-Content" id="S4.T3.116.116.8.m1.1b"><cn id="S4.T3.116.116.8.m1.1.1.cmml" type="float" xref="S4.T3.116.116.8.m1.1.1">30.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.116.116.8.m1.1c">30.08</annotation><annotation encoding="application/x-llamapun" id="S4.T3.116.116.8.m1.1d">30.08</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.117.117.9"><math alttext="40.11" class="ltx_Math" display="inline" id="S4.T3.117.117.9.m1.1"><semantics id="S4.T3.117.117.9.m1.1a"><mn id="S4.T3.117.117.9.m1.1.1" xref="S4.T3.117.117.9.m1.1.1.cmml">40.11</mn><annotation-xml encoding="MathML-Content" id="S4.T3.117.117.9.m1.1b"><cn id="S4.T3.117.117.9.m1.1.1.cmml" type="float" xref="S4.T3.117.117.9.m1.1.1">40.11</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.117.117.9.m1.1c">40.11</annotation><annotation encoding="application/x-llamapun" id="S4.T3.117.117.9.m1.1d">40.11</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.118.118.10"><math alttext="24.10" class="ltx_Math" display="inline" id="S4.T3.118.118.10.m1.1"><semantics id="S4.T3.118.118.10.m1.1a"><mn id="S4.T3.118.118.10.m1.1.1" xref="S4.T3.118.118.10.m1.1.1.cmml">24.10</mn><annotation-xml encoding="MathML-Content" id="S4.T3.118.118.10.m1.1b"><cn id="S4.T3.118.118.10.m1.1.1.cmml" type="float" xref="S4.T3.118.118.10.m1.1.1">24.10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.118.118.10.m1.1c">24.10</annotation><annotation encoding="application/x-llamapun" id="S4.T3.118.118.10.m1.1d">24.10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.119.119.11"><math alttext="22.75" class="ltx_Math" display="inline" id="S4.T3.119.119.11.m1.1"><semantics id="S4.T3.119.119.11.m1.1a"><mn id="S4.T3.119.119.11.m1.1.1" xref="S4.T3.119.119.11.m1.1.1.cmml">22.75</mn><annotation-xml encoding="MathML-Content" id="S4.T3.119.119.11.m1.1b"><cn id="S4.T3.119.119.11.m1.1.1.cmml" type="float" xref="S4.T3.119.119.11.m1.1.1">22.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.119.119.11.m1.1c">22.75</annotation><annotation encoding="application/x-llamapun" id="S4.T3.119.119.11.m1.1d">22.75</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.120.120.12"><math alttext="23.41" class="ltx_Math" display="inline" id="S4.T3.120.120.12.m1.1"><semantics id="S4.T3.120.120.12.m1.1a"><mn id="S4.T3.120.120.12.m1.1.1" xref="S4.T3.120.120.12.m1.1.1.cmml">23.41</mn><annotation-xml encoding="MathML-Content" id="S4.T3.120.120.12.m1.1b"><cn id="S4.T3.120.120.12.m1.1.1.cmml" type="float" xref="S4.T3.120.120.12.m1.1.1">23.41</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.120.120.12.m1.1c">23.41</annotation><annotation encoding="application/x-llamapun" id="S4.T3.120.120.12.m1.1d">23.41</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.132.132">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_r" id="S4.T3.132.132.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.132.132.14">Fine-tuning (QLoRA)</th>
<td class="ltx_td ltx_align_right" id="S4.T3.121.121.1"><math alttext="94.73" class="ltx_Math" display="inline" id="S4.T3.121.121.1.m1.1"><semantics id="S4.T3.121.121.1.m1.1a"><mn id="S4.T3.121.121.1.m1.1.1" xref="S4.T3.121.121.1.m1.1.1.cmml">94.73</mn><annotation-xml encoding="MathML-Content" id="S4.T3.121.121.1.m1.1b"><cn id="S4.T3.121.121.1.m1.1.1.cmml" type="float" xref="S4.T3.121.121.1.m1.1.1">94.73</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.121.121.1.m1.1c">94.73</annotation><annotation encoding="application/x-llamapun" id="S4.T3.121.121.1.m1.1d">94.73</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.122.122.2"><math alttext="85.06" class="ltx_Math" display="inline" id="S4.T3.122.122.2.m1.1"><semantics id="S4.T3.122.122.2.m1.1a"><mn id="S4.T3.122.122.2.m1.1.1" xref="S4.T3.122.122.2.m1.1.1.cmml">85.06</mn><annotation-xml encoding="MathML-Content" id="S4.T3.122.122.2.m1.1b"><cn id="S4.T3.122.122.2.m1.1.1.cmml" type="float" xref="S4.T3.122.122.2.m1.1.1">85.06</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.122.122.2.m1.1c">85.06</annotation><annotation encoding="application/x-llamapun" id="S4.T3.122.122.2.m1.1d">85.06</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.123.123.3"><math alttext="89.64" class="ltx_Math" display="inline" id="S4.T3.123.123.3.m1.1"><semantics id="S4.T3.123.123.3.m1.1a"><mn id="S4.T3.123.123.3.m1.1.1" xref="S4.T3.123.123.3.m1.1.1.cmml">89.64</mn><annotation-xml encoding="MathML-Content" id="S4.T3.123.123.3.m1.1b"><cn id="S4.T3.123.123.3.m1.1.1.cmml" type="float" xref="S4.T3.123.123.3.m1.1.1">89.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.123.123.3.m1.1c">89.64</annotation><annotation encoding="application/x-llamapun" id="S4.T3.123.123.3.m1.1d">89.64</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.124.124.4"><math alttext="95.79" class="ltx_Math" display="inline" id="S4.T3.124.124.4.m1.1"><semantics id="S4.T3.124.124.4.m1.1a"><mn id="S4.T3.124.124.4.m1.1.1" xref="S4.T3.124.124.4.m1.1.1.cmml">95.79</mn><annotation-xml encoding="MathML-Content" id="S4.T3.124.124.4.m1.1b"><cn id="S4.T3.124.124.4.m1.1.1.cmml" type="float" xref="S4.T3.124.124.4.m1.1.1">95.79</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.124.124.4.m1.1c">95.79</annotation><annotation encoding="application/x-llamapun" id="S4.T3.124.124.4.m1.1d">95.79</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.125.125.5"><math alttext="93.48" class="ltx_Math" display="inline" id="S4.T3.125.125.5.m1.1"><semantics id="S4.T3.125.125.5.m1.1a"><mn id="S4.T3.125.125.5.m1.1.1" xref="S4.T3.125.125.5.m1.1.1.cmml">93.48</mn><annotation-xml encoding="MathML-Content" id="S4.T3.125.125.5.m1.1b"><cn id="S4.T3.125.125.5.m1.1.1.cmml" type="float" xref="S4.T3.125.125.5.m1.1.1">93.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.125.125.5.m1.1c">93.48</annotation><annotation encoding="application/x-llamapun" id="S4.T3.125.125.5.m1.1d">93.48</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.126.126.6"><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T3.126.126.6.1">94.61</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.127.127.7"><math alttext="92.40" class="ltx_Math" display="inline" id="S4.T3.127.127.7.m1.1"><semantics id="S4.T3.127.127.7.m1.1a"><mn id="S4.T3.127.127.7.m1.1.1" xref="S4.T3.127.127.7.m1.1.1.cmml">92.40</mn><annotation-xml encoding="MathML-Content" id="S4.T3.127.127.7.m1.1b"><cn id="S4.T3.127.127.7.m1.1.1.cmml" type="float" xref="S4.T3.127.127.7.m1.1.1">92.40</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.127.127.7.m1.1c">92.40</annotation><annotation encoding="application/x-llamapun" id="S4.T3.127.127.7.m1.1d">92.40</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.128.128.8"><math alttext="87.83" class="ltx_Math" display="inline" id="S4.T3.128.128.8.m1.1"><semantics id="S4.T3.128.128.8.m1.1a"><mn id="S4.T3.128.128.8.m1.1.1" xref="S4.T3.128.128.8.m1.1.1.cmml">87.83</mn><annotation-xml encoding="MathML-Content" id="S4.T3.128.128.8.m1.1b"><cn id="S4.T3.128.128.8.m1.1.1.cmml" type="float" xref="S4.T3.128.128.8.m1.1.1">87.83</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.128.128.8.m1.1c">87.83</annotation><annotation encoding="application/x-llamapun" id="S4.T3.128.128.8.m1.1d">87.83</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S4.T3.129.129.9"><math alttext="90.09" class="ltx_Math" display="inline" id="S4.T3.129.129.9.m1.1"><semantics id="S4.T3.129.129.9.m1.1a"><mn id="S4.T3.129.129.9.m1.1.1" xref="S4.T3.129.129.9.m1.1.1.cmml">90.09</mn><annotation-xml encoding="MathML-Content" id="S4.T3.129.129.9.m1.1b"><cn id="S4.T3.129.129.9.m1.1.1.cmml" type="float" xref="S4.T3.129.129.9.m1.1.1">90.09</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.129.129.9.m1.1c">90.09</annotation><annotation encoding="application/x-llamapun" id="S4.T3.129.129.9.m1.1d">90.09</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.130.130.10"><math alttext="76.99" class="ltx_Math" display="inline" id="S4.T3.130.130.10.m1.1"><semantics id="S4.T3.130.130.10.m1.1a"><mn id="S4.T3.130.130.10.m1.1.1" xref="S4.T3.130.130.10.m1.1.1.cmml">76.99</mn><annotation-xml encoding="MathML-Content" id="S4.T3.130.130.10.m1.1b"><cn id="S4.T3.130.130.10.m1.1.1.cmml" type="float" xref="S4.T3.130.130.10.m1.1.1">76.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.130.130.10.m1.1c">76.99</annotation><annotation encoding="application/x-llamapun" id="S4.T3.130.130.10.m1.1d">76.99</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.131.131.11"><math alttext="76.99" class="ltx_Math" display="inline" id="S4.T3.131.131.11.m1.1"><semantics id="S4.T3.131.131.11.m1.1a"><mn id="S4.T3.131.131.11.m1.1.1" xref="S4.T3.131.131.11.m1.1.1.cmml">76.99</mn><annotation-xml encoding="MathML-Content" id="S4.T3.131.131.11.m1.1b"><cn id="S4.T3.131.131.11.m1.1.1.cmml" type="float" xref="S4.T3.131.131.11.m1.1.1">76.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.131.131.11.m1.1c">76.99</annotation><annotation encoding="application/x-llamapun" id="S4.T3.131.131.11.m1.1d">76.99</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right" id="S4.T3.132.132.12"><math alttext="76.99" class="ltx_Math" display="inline" id="S4.T3.132.132.12.m1.1"><semantics id="S4.T3.132.132.12.m1.1a"><mn id="S4.T3.132.132.12.m1.1.1" xref="S4.T3.132.132.12.m1.1.1.cmml">76.99</mn><annotation-xml encoding="MathML-Content" id="S4.T3.132.132.12.m1.1b"><cn id="S4.T3.132.132.12.m1.1.1.cmml" type="float" xref="S4.T3.132.132.12.m1.1.1">76.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.132.132.12.m1.1c">76.99</annotation><annotation encoding="application/x-llamapun" id="S4.T3.132.132.12.m1.1d">76.99</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.144.144">
<th class="ltx_td ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T3.144.144.13"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T3.144.144.14">RAG4RE+Fine-tuning</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.133.133.1"><math alttext="86.57" class="ltx_Math" display="inline" id="S4.T3.133.133.1.m1.1"><semantics id="S4.T3.133.133.1.m1.1a"><mn id="S4.T3.133.133.1.m1.1.1" xref="S4.T3.133.133.1.m1.1.1.cmml">86.57</mn><annotation-xml encoding="MathML-Content" id="S4.T3.133.133.1.m1.1b"><cn id="S4.T3.133.133.1.m1.1.1.cmml" type="float" xref="S4.T3.133.133.1.m1.1.1">86.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.133.133.1.m1.1c">86.57</annotation><annotation encoding="application/x-llamapun" id="S4.T3.133.133.1.m1.1d">86.57</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.134.134.2"><math alttext="82.88" class="ltx_Math" display="inline" id="S4.T3.134.134.2.m1.1"><semantics id="S4.T3.134.134.2.m1.1a"><mn id="S4.T3.134.134.2.m1.1.1" xref="S4.T3.134.134.2.m1.1.1.cmml">82.88</mn><annotation-xml encoding="MathML-Content" id="S4.T3.134.134.2.m1.1b"><cn id="S4.T3.134.134.2.m1.1.1.cmml" type="float" xref="S4.T3.134.134.2.m1.1.1">82.88</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.134.134.2.m1.1c">82.88</annotation><annotation encoding="application/x-llamapun" id="S4.T3.134.134.2.m1.1d">82.88</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S4.T3.135.135.3"><math alttext="84.68" class="ltx_Math" display="inline" id="S4.T3.135.135.3.m1.1"><semantics id="S4.T3.135.135.3.m1.1a"><mn id="S4.T3.135.135.3.m1.1.1" xref="S4.T3.135.135.3.m1.1.1.cmml">84.68</mn><annotation-xml encoding="MathML-Content" id="S4.T3.135.135.3.m1.1b"><cn id="S4.T3.135.135.3.m1.1.1.cmml" type="float" xref="S4.T3.135.135.3.m1.1.1">84.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.135.135.3.m1.1c">84.68</annotation><annotation encoding="application/x-llamapun" id="S4.T3.135.135.3.m1.1d">84.68</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.136.136.4"><math alttext="97.58" class="ltx_Math" display="inline" id="S4.T3.136.136.4.m1.1"><semantics id="S4.T3.136.136.4.m1.1a"><mn id="S4.T3.136.136.4.m1.1.1" xref="S4.T3.136.136.4.m1.1.1.cmml">97.58</mn><annotation-xml encoding="MathML-Content" id="S4.T3.136.136.4.m1.1b"><cn id="S4.T3.136.136.4.m1.1.1.cmml" type="float" xref="S4.T3.136.136.4.m1.1.1">97.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.136.136.4.m1.1c">97.58</annotation><annotation encoding="application/x-llamapun" id="S4.T3.136.136.4.m1.1d">97.58</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.137.137.5"><math alttext="79.33" class="ltx_Math" display="inline" id="S4.T3.137.137.5.m1.1"><semantics id="S4.T3.137.137.5.m1.1a"><mn id="S4.T3.137.137.5.m1.1.1" xref="S4.T3.137.137.5.m1.1.1.cmml">79.33</mn><annotation-xml encoding="MathML-Content" id="S4.T3.137.137.5.m1.1b"><cn id="S4.T3.137.137.5.m1.1.1.cmml" type="float" xref="S4.T3.137.137.5.m1.1.1">79.33</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.137.137.5.m1.1c">79.33</annotation><annotation encoding="application/x-llamapun" id="S4.T3.137.137.5.m1.1d">79.33</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S4.T3.138.138.6"><math alttext="87.50" class="ltx_Math" display="inline" id="S4.T3.138.138.6.m1.1"><semantics id="S4.T3.138.138.6.m1.1a"><mn id="S4.T3.138.138.6.m1.1.1" xref="S4.T3.138.138.6.m1.1.1.cmml">87.50</mn><annotation-xml encoding="MathML-Content" id="S4.T3.138.138.6.m1.1b"><cn id="S4.T3.138.138.6.m1.1.1.cmml" type="float" xref="S4.T3.138.138.6.m1.1.1">87.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.138.138.6.m1.1c">87.50</annotation><annotation encoding="application/x-llamapun" id="S4.T3.138.138.6.m1.1d">87.50</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.139.139.7"><math alttext="90.86" class="ltx_Math" display="inline" id="S4.T3.139.139.7.m1.1"><semantics id="S4.T3.139.139.7.m1.1a"><mn id="S4.T3.139.139.7.m1.1.1" xref="S4.T3.139.139.7.m1.1.1.cmml">90.86</mn><annotation-xml encoding="MathML-Content" id="S4.T3.139.139.7.m1.1b"><cn id="S4.T3.139.139.7.m1.1.1.cmml" type="float" xref="S4.T3.139.139.7.m1.1.1">90.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.139.139.7.m1.1c">90.86</annotation><annotation encoding="application/x-llamapun" id="S4.T3.139.139.7.m1.1d">90.86</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.140.140.8"><math alttext="85.95" class="ltx_Math" display="inline" id="S4.T3.140.140.8.m1.1"><semantics id="S4.T3.140.140.8.m1.1a"><mn id="S4.T3.140.140.8.m1.1.1" xref="S4.T3.140.140.8.m1.1.1.cmml">85.95</mn><annotation-xml encoding="MathML-Content" id="S4.T3.140.140.8.m1.1b"><cn id="S4.T3.140.140.8.m1.1.1.cmml" type="float" xref="S4.T3.140.140.8.m1.1.1">85.95</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.140.140.8.m1.1c">85.95</annotation><annotation encoding="application/x-llamapun" id="S4.T3.140.140.8.m1.1d">85.95</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S4.T3.141.141.9"><math alttext="88.33" class="ltx_Math" display="inline" id="S4.T3.141.141.9.m1.1"><semantics id="S4.T3.141.141.9.m1.1a"><mn id="S4.T3.141.141.9.m1.1.1" xref="S4.T3.141.141.9.m1.1.1.cmml">88.33</mn><annotation-xml encoding="MathML-Content" id="S4.T3.141.141.9.m1.1b"><cn id="S4.T3.141.141.9.m1.1.1.cmml" type="float" xref="S4.T3.141.141.9.m1.1.1">88.33</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.141.141.9.m1.1c">88.33</annotation><annotation encoding="application/x-llamapun" id="S4.T3.141.141.9.m1.1d">88.33</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.142.142.10"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.142.142.10.m1.1"><semantics id="S4.T3.142.142.10.m1.1a"><mo id="S4.T3.142.142.10.m1.1.1" xref="S4.T3.142.142.10.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.142.142.10.m1.1b"><minus id="S4.T3.142.142.10.m1.1.1.cmml" xref="S4.T3.142.142.10.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.142.142.10.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.142.142.10.m1.1d">-</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.143.143.11"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.143.143.11.m1.1"><semantics id="S4.T3.143.143.11.m1.1a"><mo id="S4.T3.143.143.11.m1.1.1" xref="S4.T3.143.143.11.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.143.143.11.m1.1b"><minus id="S4.T3.143.143.11.m1.1.1.cmml" xref="S4.T3.143.143.11.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.143.143.11.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.143.143.11.m1.1d">-</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.144.144.12"><math alttext="-" class="ltx_Math" display="inline" id="S4.T3.144.144.12.m1.1"><semantics id="S4.T3.144.144.12.m1.1a"><mo id="S4.T3.144.144.12.m1.1.1" xref="S4.T3.144.144.12.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T3.144.144.12.m1.1b"><minus id="S4.T3.144.144.12.m1.1.1.cmml" xref="S4.T3.144.144.12.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.144.144.12.m1.1c">-</annotation><annotation encoding="application/x-llamapun" id="S4.T3.144.144.12.m1.1d">-</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Discussion</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In this work, we conducted two experiments: firstly, fine-tuning of language models, and secondly, integration of the fine-tuned language models into RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. Our findings indicate remarkable improvements on results of original RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> on TACRED, TACREV, Re-TACRED at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> when fine-tuned T5 Large models are integrated to RAG4RE approach. Regrettably, extending the same experiment to SemEVAL in conjunction with RAG4RE and fine-tuned language models proved unfeasible, given the absence of additional splits beyond the train and test sets in this dataset. The process of fine-tuning language models, particularly in context of the domain adaptation, demonstrated notable enhancements in the performance of both general-purpose language models and RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> (see <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.F6" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>). However, our fine-tuned language model obtained slightly better F1 score than the RAG4RE using our fine-tuned language model on TACREV dataset at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T4" title="In 4.3. Discussion ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">We analyzed the effectiveness of our fine-tuned language models in Relation Extraction (RE), comparing their F1 scores with both LLM-based methods and state-of-the-art (SoTA) RE techniques in the literature.
Our findings reveal that our approach consistently outperforms other LLM-based zero-shot methods <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>; Kai Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a>; Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib29" title="">2023</a>)</cite>, as demonstrated in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T4" title="In 4.3. Discussion ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>, across all benchmark datasets.
This superior performance can largely be attributed to the lack of domain-specific knowledge used by LLMQA4RE <cite class="ltx_cite ltx_citemacro_citep">(Kai Zhang, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a>)</cite> RationaleCL <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib29" title="">2023</a>)</cite> and RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. The reason why these LLM-based methods could not achieve better performance on these RE datasets, these works rely on zero-shot prompting with general-purpose LLMs, whereas we fine-tuned general-purpose LLMs using QLoRA on small part of datasets. Obviously, our fine-tuned language models outperformed all these zero-shot prompting approaches on all four datasets.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Moreover, we carried out a thorough comparison with existing works achieved remarkable results on these benchmarks in the literature. Remarkably, the best-performing results in our experiments at <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T3" title="In 4.2. Results ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> surpassed the SoTA results on the TACRED, TACREV, and Re-TACRED datasets, obtaining F1 scores of 92.00%, 94.61%, and 93.01%, respectively. All these models except for RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> are trained on train splits of these datasets, which means that they have domain knowledge of these datasets. Furthermore, our approach, Fine-tuning+RAG4RE, also outperformed to original RAG4RE using general-purpose LLMs. These achievements are detailed in <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#S4.T4" title="In 4.3. Discussion ‣ 4. Evaluation ‣ Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Consequently, our fine-tuned language models achieved outstanding results on the TACRED, TACREV, and Re-TACRED datasets when integrated into the RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. Nonetheless, we could not repeat the experiments with RAG4RE using our fine-tuned language models for SemEVAL. However, fine-tuning LLMs on the SemEVAL dataset outperformed all the methods using zero-shot prompting.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>A comparison of our best-performing results with those of prior works.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.20">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.20.21.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T4.20.21.1.1"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_tt" id="S4.T4.20.21.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.20.21.1.2.1">
<span class="ltx_p" id="S4.T4.20.21.1.2.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.20.21.1.2.1.1.1" style="font-size:90%;">Method</span></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S4.T4.20.21.1.3">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.20.21.1.3.1" style="width:6.1pt;height:38.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.4pt;transform:translate(-16.11pt,-16.11pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T4.20.21.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.20.21.1.3.1.1.1" style="font-size:90%;">TACRED</span></p>
</span></div>
</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.20.21.1.4">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.20.21.1.4.1" style="width:6.1pt;height:38.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:38.3pt;transform:translate(-16.05pt,-16.05pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T4.20.21.1.4.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.20.21.1.4.1.1.1" style="font-size:90%;">TACREV</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.20.21.1.5">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.20.21.1.5.1" style="width:6.1pt;height:52pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:52.0pt;transform:translate(-22.93pt,-22.93pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T4.20.21.1.5.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.20.21.1.5.1.1.1" style="font-size:90%;">Re-TACRED</span></p>
</span></div>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.20.21.1.6">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.20.21.1.6.1" style="width:6.3pt;height:33.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:33.9pt;transform:translate(-13.81pt,-13.81pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T4.20.21.1.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.20.21.1.6.1.1.1" style="font-size:90%;">SemEval</span></p>
</span></div>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T4.1.1.2"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S4.T4.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.1.1.3.1">
<span class="ltx_p" id="S4.T4.1.1.3.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.1.1.3.1.1.1" style="font-size:90%;">DeepStruct </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.1.1.3.1.1.2.1" style="font-size:90%;">(</span>Wang et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T4.1.1.3.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib28" title="">2022</a><span class="ltx_text" id="S4.T4.1.1.3.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T4.1.1.1"><math alttext="76.8\%" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.m1.1a"><mrow id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mn id="S4.T4.1.1.1.m1.1.1.2" mathsize="90%" xref="S4.T4.1.1.1.m1.1.1.2.cmml">76.8</mn><mo id="S4.T4.1.1.1.m1.1.1.1" mathsize="90%" xref="S4.T4.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.1.1.1.m1.1.1.2.cmml" type="float" xref="S4.T4.1.1.1.m1.1.1.2">76.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">76.8\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.m1.1d">76.8 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.4"><span class="ltx_text" id="S4.T4.1.1.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.5"><span class="ltx_text" id="S4.T4.1.1.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.6"><span class="ltx_text" id="S4.T4.1.1.6.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.2.2.2"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S4.T4.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.2.2.3.1">
<span class="ltx_p" id="S4.T4.2.2.3.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.2.2.3.1.1.1" style="font-size:90%;">EXOBRAIN </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.2.2.3.1.1.2.1" style="font-size:90%;">(</span>Zhou and Chen<span class="ltx_text" id="S4.T4.2.2.3.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib32" title="">2022</a><span class="ltx_text" id="S4.T4.2.2.3.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.2.2.1"><math alttext="75.0\%" class="ltx_Math" display="inline" id="S4.T4.2.2.1.m1.1"><semantics id="S4.T4.2.2.1.m1.1a"><mrow id="S4.T4.2.2.1.m1.1.1" xref="S4.T4.2.2.1.m1.1.1.cmml"><mn id="S4.T4.2.2.1.m1.1.1.2" mathsize="90%" xref="S4.T4.2.2.1.m1.1.1.2.cmml">75.0</mn><mo id="S4.T4.2.2.1.m1.1.1.1" mathsize="90%" xref="S4.T4.2.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.1.m1.1b"><apply id="S4.T4.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.2.2.1.m1.1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.2.2.1.m1.1.1.2.cmml" type="float" xref="S4.T4.2.2.1.m1.1.1.2">75.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.1.m1.1c">75.0\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.1.m1.1d">75.0 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.4"><span class="ltx_text" id="S4.T4.2.2.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.5"><span class="ltx_text" id="S4.T4.2.2.5.1" style="font-size:90%;">91.4%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.6"><span class="ltx_text" id="S4.T4.2.2.6.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.4.4.3"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.3.1" style="font-size:90%;">SoTA</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S4.T4.4.4.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.4.4.4.1">
<span class="ltx_p" id="S4.T4.4.4.4.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.4.4.4.1.1.1" style="font-size:90%;">KLG </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.4.4.4.1.1.2.1" style="font-size:90%;">(</span>Li et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T4.4.4.4.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib20" title="">2022</a><span class="ltx_text" id="S4.T4.4.4.4.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.4.4.5"><span class="ltx_text" id="S4.T4.4.4.5.1" style="font-size:90%;">-</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.1"><math alttext="84.1\%" class="ltx_Math" display="inline" id="S4.T4.3.3.1.m1.1"><semantics id="S4.T4.3.3.1.m1.1a"><mrow id="S4.T4.3.3.1.m1.1.1" xref="S4.T4.3.3.1.m1.1.1.cmml"><mn id="S4.T4.3.3.1.m1.1.1.2" mathsize="90%" xref="S4.T4.3.3.1.m1.1.1.2.cmml">84.1</mn><mo id="S4.T4.3.3.1.m1.1.1.1" mathsize="90%" xref="S4.T4.3.3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.m1.1b"><apply id="S4.T4.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.3.3.1.m1.1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.3.3.1.m1.1.1.2.cmml" type="float" xref="S4.T4.3.3.1.m1.1.1.2">84.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.m1.1c">84.1\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.1.m1.1d">84.1 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.6"><span class="ltx_text" id="S4.T4.4.4.6.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.2"><math alttext="90.5\%" class="ltx_Math" display="inline" id="S4.T4.4.4.2.m1.1"><semantics id="S4.T4.4.4.2.m1.1a"><mrow id="S4.T4.4.4.2.m1.1.1" xref="S4.T4.4.4.2.m1.1.1.cmml"><mn id="S4.T4.4.4.2.m1.1.1.2" mathsize="90%" xref="S4.T4.4.4.2.m1.1.1.2.cmml">90.5</mn><mo id="S4.T4.4.4.2.m1.1.1.1" mathsize="90%" xref="S4.T4.4.4.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.2.m1.1b"><apply id="S4.T4.4.4.2.m1.1.1.cmml" xref="S4.T4.4.4.2.m1.1.1"><csymbol cd="latexml" id="S4.T4.4.4.2.m1.1.1.1.cmml" xref="S4.T4.4.4.2.m1.1.1.1">percent</csymbol><cn id="S4.T4.4.4.2.m1.1.1.2.cmml" type="float" xref="S4.T4.4.4.2.m1.1.1.2">90.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.2.m1.1c">90.5\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.2.m1.1d">90.5 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.5.5.2"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S4.T4.5.5.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.5.5.3.1">
<span class="ltx_p" id="S4.T4.5.5.3.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.5.5.3.1.1.1" style="font-size:90%;">SP </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.5.5.3.1.1.2.1" style="font-size:90%;">(</span>Cohen et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T4.5.5.3.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib7" title="">2020</a><span class="ltx_text" id="S4.T4.5.5.3.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.5.5.1"><math alttext="74.8\%" class="ltx_Math" display="inline" id="S4.T4.5.5.1.m1.1"><semantics id="S4.T4.5.5.1.m1.1a"><mrow id="S4.T4.5.5.1.m1.1.1" xref="S4.T4.5.5.1.m1.1.1.cmml"><mn id="S4.T4.5.5.1.m1.1.1.2" mathsize="90%" xref="S4.T4.5.5.1.m1.1.1.2.cmml">74.8</mn><mo id="S4.T4.5.5.1.m1.1.1.1" mathsize="90%" xref="S4.T4.5.5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.1.m1.1b"><apply id="S4.T4.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.5.5.1.m1.1.1.1.cmml" xref="S4.T4.5.5.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.5.5.1.m1.1.1.2.cmml" type="float" xref="S4.T4.5.5.1.m1.1.1.2">74.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.1.m1.1c">74.8\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.1.m1.1d">74.8 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.4"><span class="ltx_text" id="S4.T4.5.5.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td" id="S4.T4.5.5.5"></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.6">
<span class="ltx_text ltx_font_bold" id="S4.T4.5.5.6.1" style="font-size:90%;">91.9</span><span class="ltx_text" id="S4.T4.5.5.6.2" style="font-size:90%;">%</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.7.7.3"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S4.T4.7.7.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.7.7.4.1">
<span class="ltx_p" id="S4.T4.7.7.4.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.7.7.4.1.1.1" style="font-size:90%;">GAP </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.7.7.4.1.1.2.1" style="font-size:90%;">(</span>Chen et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T4.7.7.4.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib5" title="">2024</a><span class="ltx_text" id="S4.T4.7.7.4.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.6.6.1"><math alttext="72.7\%" class="ltx_Math" display="inline" id="S4.T4.6.6.1.m1.1"><semantics id="S4.T4.6.6.1.m1.1a"><mrow id="S4.T4.6.6.1.m1.1.1" xref="S4.T4.6.6.1.m1.1.1.cmml"><mn id="S4.T4.6.6.1.m1.1.1.2" mathsize="90%" xref="S4.T4.6.6.1.m1.1.1.2.cmml">72.7</mn><mo id="S4.T4.6.6.1.m1.1.1.1" mathsize="90%" xref="S4.T4.6.6.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.1.m1.1b"><apply id="S4.T4.6.6.1.m1.1.1.cmml" xref="S4.T4.6.6.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.6.6.1.m1.1.1.1.cmml" xref="S4.T4.6.6.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.6.6.1.m1.1.1.2.cmml" type="float" xref="S4.T4.6.6.1.m1.1.1.2">72.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.1.m1.1c">72.7\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.1.m1.1d">72.7 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.5"><span class="ltx_text" id="S4.T4.7.7.5.1" style="font-size:90%;">82.7%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.6"><span class="ltx_text" id="S4.T4.7.7.6.1" style="font-size:90%;">91.4%</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.2"><math alttext="90.3\%" class="ltx_Math" display="inline" id="S4.T4.7.7.2.m1.1"><semantics id="S4.T4.7.7.2.m1.1a"><mrow id="S4.T4.7.7.2.m1.1.1" xref="S4.T4.7.7.2.m1.1.1.cmml"><mn id="S4.T4.7.7.2.m1.1.1.2" mathsize="90%" xref="S4.T4.7.7.2.m1.1.1.2.cmml">90.3</mn><mo id="S4.T4.7.7.2.m1.1.1.1" mathsize="90%" xref="S4.T4.7.7.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.2.m1.1b"><apply id="S4.T4.7.7.2.m1.1.1.cmml" xref="S4.T4.7.7.2.m1.1.1"><csymbol cd="latexml" id="S4.T4.7.7.2.m1.1.1.1.cmml" xref="S4.T4.7.7.2.m1.1.1.1">percent</csymbol><cn id="S4.T4.7.7.2.m1.1.1.2.cmml" type="float" xref="S4.T4.7.7.2.m1.1.1.2">90.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.2.m1.1c">90.3\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.7.2.m1.1d">90.3 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.11.11">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T4.11.11.5"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t" id="S4.T4.11.11.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.11.11.6.1">
<span class="ltx_p" id="S4.T4.11.11.6.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.11.11.6.1.1.1" style="font-size:90%;">LLMQA4RE </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.11.11.6.1.1.2.1" style="font-size:90%;">(</span>Kai Zhang<span class="ltx_text" id="S4.T4.11.11.6.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib17" title="">2023</a><span class="ltx_text" id="S4.T4.11.11.6.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T4.8.8.1"><math alttext="52.2\%" class="ltx_Math" display="inline" id="S4.T4.8.8.1.m1.1"><semantics id="S4.T4.8.8.1.m1.1a"><mrow id="S4.T4.8.8.1.m1.1.1" xref="S4.T4.8.8.1.m1.1.1.cmml"><mn id="S4.T4.8.8.1.m1.1.1.2" mathsize="90%" xref="S4.T4.8.8.1.m1.1.1.2.cmml">52.2</mn><mo id="S4.T4.8.8.1.m1.1.1.1" mathsize="90%" xref="S4.T4.8.8.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.1.m1.1b"><apply id="S4.T4.8.8.1.m1.1.1.cmml" xref="S4.T4.8.8.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.8.8.1.m1.1.1.1.cmml" xref="S4.T4.8.8.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.8.8.1.m1.1.1.2.cmml" type="float" xref="S4.T4.8.8.1.m1.1.1.2">52.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.1.m1.1c">52.2\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.8.1.m1.1d">52.2 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.9.9.2"><math alttext="53.4\%" class="ltx_Math" display="inline" id="S4.T4.9.9.2.m1.1"><semantics id="S4.T4.9.9.2.m1.1a"><mrow id="S4.T4.9.9.2.m1.1.1" xref="S4.T4.9.9.2.m1.1.1.cmml"><mn id="S4.T4.9.9.2.m1.1.1.2" mathsize="90%" xref="S4.T4.9.9.2.m1.1.1.2.cmml">53.4</mn><mo id="S4.T4.9.9.2.m1.1.1.1" mathsize="90%" xref="S4.T4.9.9.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.2.m1.1b"><apply id="S4.T4.9.9.2.m1.1.1.cmml" xref="S4.T4.9.9.2.m1.1.1"><csymbol cd="latexml" id="S4.T4.9.9.2.m1.1.1.1.cmml" xref="S4.T4.9.9.2.m1.1.1.1">percent</csymbol><cn id="S4.T4.9.9.2.m1.1.1.2.cmml" type="float" xref="S4.T4.9.9.2.m1.1.1.2">53.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.2.m1.1c">53.4\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.9.9.2.m1.1d">53.4 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.10.10.3"><math alttext="66.5\%" class="ltx_Math" display="inline" id="S4.T4.10.10.3.m1.1"><semantics id="S4.T4.10.10.3.m1.1a"><mrow id="S4.T4.10.10.3.m1.1.1" xref="S4.T4.10.10.3.m1.1.1.cmml"><mn id="S4.T4.10.10.3.m1.1.1.2" mathsize="90%" xref="S4.T4.10.10.3.m1.1.1.2.cmml">66.5</mn><mo id="S4.T4.10.10.3.m1.1.1.1" mathsize="90%" xref="S4.T4.10.10.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.3.m1.1b"><apply id="S4.T4.10.10.3.m1.1.1.cmml" xref="S4.T4.10.10.3.m1.1.1"><csymbol cd="latexml" id="S4.T4.10.10.3.m1.1.1.1.cmml" xref="S4.T4.10.10.3.m1.1.1.1">percent</csymbol><cn id="S4.T4.10.10.3.m1.1.1.2.cmml" type="float" xref="S4.T4.10.10.3.m1.1.1.2">66.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.3.m1.1c">66.5\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.10.10.3.m1.1d">66.5 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.11.11.4"><math alttext="43.5\%" class="ltx_Math" display="inline" id="S4.T4.11.11.4.m1.1"><semantics id="S4.T4.11.11.4.m1.1a"><mrow id="S4.T4.11.11.4.m1.1.1" xref="S4.T4.11.11.4.m1.1.1.cmml"><mn id="S4.T4.11.11.4.m1.1.1.2" mathsize="90%" xref="S4.T4.11.11.4.m1.1.1.2.cmml">43.5</mn><mo id="S4.T4.11.11.4.m1.1.1.1" mathsize="90%" xref="S4.T4.11.11.4.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.4.m1.1b"><apply id="S4.T4.11.11.4.m1.1.1.cmml" xref="S4.T4.11.11.4.m1.1.1"><csymbol cd="latexml" id="S4.T4.11.11.4.m1.1.1.1.cmml" xref="S4.T4.11.11.4.m1.1.1.1">percent</csymbol><cn id="S4.T4.11.11.4.m1.1.1.2.cmml" type="float" xref="S4.T4.11.11.4.m1.1.1.2">43.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.4.m1.1c">43.5\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.11.11.4.m1.1d">43.5 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.12.12.2"><span class="ltx_text ltx_font_bold" id="S4.T4.12.12.2.1" style="font-size:90%;">Zero-Shot</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S4.T4.12.12.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.12.12.3.1">
<span class="ltx_p" id="S4.T4.12.12.3.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.12.12.3.1.1.1" style="font-size:90%;">RationaleCL </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.12.12.3.1.1.2.1" style="font-size:90%;">(</span>Xiong et al<span class="ltx_text">.</span><span class="ltx_text" id="S4.T4.12.12.3.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib29" title="">2023</a><span class="ltx_text" id="S4.T4.12.12.3.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.12.12.1"><math alttext="80.8\%" class="ltx_Math" display="inline" id="S4.T4.12.12.1.m1.1"><semantics id="S4.T4.12.12.1.m1.1a"><mrow id="S4.T4.12.12.1.m1.1.1" xref="S4.T4.12.12.1.m1.1.1.cmml"><mn id="S4.T4.12.12.1.m1.1.1.2" mathsize="90%" xref="S4.T4.12.12.1.m1.1.1.2.cmml">80.8</mn><mo id="S4.T4.12.12.1.m1.1.1.1" mathsize="90%" xref="S4.T4.12.12.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.1.m1.1b"><apply id="S4.T4.12.12.1.m1.1.1.cmml" xref="S4.T4.12.12.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.12.12.1.m1.1.1.1.cmml" xref="S4.T4.12.12.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.12.12.1.m1.1.1.2.cmml" type="float" xref="S4.T4.12.12.1.m1.1.1.2">80.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.1.m1.1c">80.8\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.12.12.1.m1.1d">80.8 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T4.12.12.4"><span class="ltx_text" id="S4.T4.12.12.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.12.12.5"><span class="ltx_text" id="S4.T4.12.12.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.12.12.6"><span class="ltx_text" id="S4.T4.12.12.6.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.16.16">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.16.16.5"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row" id="S4.T4.16.16.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.16.16.6.1">
<span class="ltx_p" id="S4.T4.16.16.6.1.1" style="width:56.9pt;"><span class="ltx_text" id="S4.T4.16.16.6.1.1.1" style="font-size:90%;">RAG4RE </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T4.16.16.6.1.1.2.1" style="font-size:90%;">(</span>Efeoglu and Paschke<span class="ltx_text" id="S4.T4.16.16.6.1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a><span class="ltx_text" id="S4.T4.16.16.6.1.1.4.3" style="font-size:90%;">)</span></cite></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T4.13.13.1"><math alttext="86.6\%" class="ltx_Math" display="inline" id="S4.T4.13.13.1.m1.1"><semantics id="S4.T4.13.13.1.m1.1a"><mrow id="S4.T4.13.13.1.m1.1.1" xref="S4.T4.13.13.1.m1.1.1.cmml"><mn id="S4.T4.13.13.1.m1.1.1.2" mathsize="90%" xref="S4.T4.13.13.1.m1.1.1.2.cmml">86.6</mn><mo id="S4.T4.13.13.1.m1.1.1.1" mathsize="90%" xref="S4.T4.13.13.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.13.13.1.m1.1b"><apply id="S4.T4.13.13.1.m1.1.1.cmml" xref="S4.T4.13.13.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.13.13.1.m1.1.1.1.cmml" xref="S4.T4.13.13.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.13.13.1.m1.1.1.2.cmml" type="float" xref="S4.T4.13.13.1.m1.1.1.2">86.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.13.1.m1.1c">86.6\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.13.13.1.m1.1d">86.6 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center" id="S4.T4.14.14.2"><math alttext="88.3\%" class="ltx_Math" display="inline" id="S4.T4.14.14.2.m1.1"><semantics id="S4.T4.14.14.2.m1.1a"><mrow id="S4.T4.14.14.2.m1.1.1" xref="S4.T4.14.14.2.m1.1.1.cmml"><mn id="S4.T4.14.14.2.m1.1.1.2" mathsize="90%" xref="S4.T4.14.14.2.m1.1.1.2.cmml">88.3</mn><mo id="S4.T4.14.14.2.m1.1.1.1" mathsize="90%" xref="S4.T4.14.14.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.14.14.2.m1.1b"><apply id="S4.T4.14.14.2.m1.1.1.cmml" xref="S4.T4.14.14.2.m1.1.1"><csymbol cd="latexml" id="S4.T4.14.14.2.m1.1.1.1.cmml" xref="S4.T4.14.14.2.m1.1.1.1">percent</csymbol><cn id="S4.T4.14.14.2.m1.1.1.2.cmml" type="float" xref="S4.T4.14.14.2.m1.1.1.2">88.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.14.2.m1.1c">88.3\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.14.14.2.m1.1d">88.3 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.15.15.3"><math alttext="73.3\%" class="ltx_Math" display="inline" id="S4.T4.15.15.3.m1.1"><semantics id="S4.T4.15.15.3.m1.1a"><mrow id="S4.T4.15.15.3.m1.1.1" xref="S4.T4.15.15.3.m1.1.1.cmml"><mn id="S4.T4.15.15.3.m1.1.1.2" mathsize="90%" xref="S4.T4.15.15.3.m1.1.1.2.cmml">73.3</mn><mo id="S4.T4.15.15.3.m1.1.1.1" mathsize="90%" xref="S4.T4.15.15.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.15.15.3.m1.1b"><apply id="S4.T4.15.15.3.m1.1.1.cmml" xref="S4.T4.15.15.3.m1.1.1"><csymbol cd="latexml" id="S4.T4.15.15.3.m1.1.1.1.cmml" xref="S4.T4.15.15.3.m1.1.1.1">percent</csymbol><cn id="S4.T4.15.15.3.m1.1.1.2.cmml" type="float" xref="S4.T4.15.15.3.m1.1.1.2">73.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.15.15.3.m1.1c">73.3\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.15.15.3.m1.1d">73.3 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.16.16.4"><math alttext="23.41\%" class="ltx_Math" display="inline" id="S4.T4.16.16.4.m1.1"><semantics id="S4.T4.16.16.4.m1.1a"><mrow id="S4.T4.16.16.4.m1.1.1" xref="S4.T4.16.16.4.m1.1.1.cmml"><mn id="S4.T4.16.16.4.m1.1.1.2" mathsize="90%" xref="S4.T4.16.16.4.m1.1.1.2.cmml">23.41</mn><mo id="S4.T4.16.16.4.m1.1.1.1" mathsize="90%" xref="S4.T4.16.16.4.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.16.16.4.m1.1b"><apply id="S4.T4.16.16.4.m1.1.1.cmml" xref="S4.T4.16.16.4.m1.1.1"><csymbol cd="latexml" id="S4.T4.16.16.4.m1.1.1.1.cmml" xref="S4.T4.16.16.4.m1.1.1.1">percent</csymbol><cn id="S4.T4.16.16.4.m1.1.1.2.cmml" type="float" xref="S4.T4.16.16.4.m1.1.1.2">23.41</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.16.16.4.m1.1c">23.41\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.16.16.4.m1.1d">23.41 %</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T4.17.17">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T4.17.17.2"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_tt" id="S4.T4.17.17.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.17.17.3.1">
<span class="ltx_p" id="S4.T4.17.17.3.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.17.17.3.1.1.1" style="font-size:90%;">Fine-tuning</span><span class="ltx_text" id="S4.T4.17.17.3.1.1.2" style="font-size:90%;">+ </span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.T4.17.17.3.1.1.3" style="font-size:90%;">RAG4RE</span><span class="ltx_text" id="S4.T4.17.17.3.1.1.4" style="font-size:90%;">
(</span><span class="ltx_text ltx_font_bold" id="S4.T4.17.17.3.1.1.5" style="font-size:90%;">Ours</span><span class="ltx_text" id="S4.T4.17.17.3.1.1.6" style="font-size:90%;">)</span></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S4.T4.17.17.4"><span class="ltx_text ltx_font_bold" id="S4.T4.17.17.4.1" style="font-size:90%;">92.00%</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.17.17.1"><math alttext="94.34\%" class="ltx_Math" display="inline" id="S4.T4.17.17.1.m1.1"><semantics id="S4.T4.17.17.1.m1.1a"><mrow id="S4.T4.17.17.1.m1.1.1" xref="S4.T4.17.17.1.m1.1.1.cmml"><mn id="S4.T4.17.17.1.m1.1.1.2" mathsize="90%" xref="S4.T4.17.17.1.m1.1.1.2.cmml">94.34</mn><mo id="S4.T4.17.17.1.m1.1.1.1" mathsize="90%" xref="S4.T4.17.17.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.17.17.1.m1.1b"><apply id="S4.T4.17.17.1.m1.1.1.cmml" xref="S4.T4.17.17.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.17.17.1.m1.1.1.1.cmml" xref="S4.T4.17.17.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.17.17.1.m1.1.1.2.cmml" type="float" xref="S4.T4.17.17.1.m1.1.1.2">94.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.17.17.1.m1.1c">94.34\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.17.17.1.m1.1d">94.34 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.17.17.5"><span class="ltx_text ltx_font_bold" id="S4.T4.17.17.5.1" style="font-size:90%;">93.01%</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.17.17.6"><span class="ltx_text" id="S4.T4.17.17.6.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.20.20">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T4.20.20.4"></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T4.20.20.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T4.20.20.5.1">
<span class="ltx_p" id="S4.T4.20.20.5.1.1" style="width:56.9pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.20.20.5.1.1.1" style="font-size:90%;">Fine-tuning</span><span class="ltx_text" id="S4.T4.20.20.5.1.1.2" style="font-size:90%;"> </span>
<br class="ltx_break"/><span class="ltx_text" id="S4.T4.20.20.5.1.1.3" style="font-size:90%;">(</span><span class="ltx_text ltx_font_bold" id="S4.T4.20.20.5.1.1.4" style="font-size:90%;">Ours</span><span class="ltx_text" id="S4.T4.20.20.5.1.1.5" style="font-size:90%;">)</span></span>
</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T4.18.18.1"><math alttext="89.64\%" class="ltx_Math" display="inline" id="S4.T4.18.18.1.m1.1"><semantics id="S4.T4.18.18.1.m1.1a"><mrow id="S4.T4.18.18.1.m1.1.1" xref="S4.T4.18.18.1.m1.1.1.cmml"><mn id="S4.T4.18.18.1.m1.1.1.2" mathsize="90%" xref="S4.T4.18.18.1.m1.1.1.2.cmml">89.64</mn><mo id="S4.T4.18.18.1.m1.1.1.1" mathsize="90%" xref="S4.T4.18.18.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.18.18.1.m1.1b"><apply id="S4.T4.18.18.1.m1.1.1.cmml" xref="S4.T4.18.18.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.18.18.1.m1.1.1.1.cmml" xref="S4.T4.18.18.1.m1.1.1.1">percent</csymbol><cn id="S4.T4.18.18.1.m1.1.1.2.cmml" type="float" xref="S4.T4.18.18.1.m1.1.1.2">89.64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.18.18.1.m1.1c">89.64\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.18.18.1.m1.1d">89.64 %</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.20.20.6"><span class="ltx_text ltx_font_bold" id="S4.T4.20.20.6.1" style="font-size:90%;">94.61%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.19.19.2"><math alttext="90.09\%" class="ltx_Math" display="inline" id="S4.T4.19.19.2.m1.1"><semantics id="S4.T4.19.19.2.m1.1a"><mrow id="S4.T4.19.19.2.m1.1.1" xref="S4.T4.19.19.2.m1.1.1.cmml"><mn id="S4.T4.19.19.2.m1.1.1.2" mathsize="90%" xref="S4.T4.19.19.2.m1.1.1.2.cmml">90.09</mn><mo id="S4.T4.19.19.2.m1.1.1.1" mathsize="90%" xref="S4.T4.19.19.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.19.19.2.m1.1b"><apply id="S4.T4.19.19.2.m1.1.1.cmml" xref="S4.T4.19.19.2.m1.1.1"><csymbol cd="latexml" id="S4.T4.19.19.2.m1.1.1.1.cmml" xref="S4.T4.19.19.2.m1.1.1.1">percent</csymbol><cn id="S4.T4.19.19.2.m1.1.1.2.cmml" type="float" xref="S4.T4.19.19.2.m1.1.1.2">90.09</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.19.19.2.m1.1c">90.09\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.19.19.2.m1.1d">90.09 %</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.20.20.3"><math alttext="79.61\%" class="ltx_Math" display="inline" id="S4.T4.20.20.3.m1.1"><semantics id="S4.T4.20.20.3.m1.1a"><mrow id="S4.T4.20.20.3.m1.1.1" xref="S4.T4.20.20.3.m1.1.1.cmml"><mn id="S4.T4.20.20.3.m1.1.1.2" mathsize="90%" xref="S4.T4.20.20.3.m1.1.1.2.cmml">79.61</mn><mo id="S4.T4.20.20.3.m1.1.1.1" mathsize="90%" xref="S4.T4.20.20.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.20.20.3.m1.1b"><apply id="S4.T4.20.20.3.m1.1.1.cmml" xref="S4.T4.20.20.3.m1.1.1"><csymbol cd="latexml" id="S4.T4.20.20.3.m1.1.1.1.cmml" xref="S4.T4.20.20.3.m1.1.1.1">percent</csymbol><cn id="S4.T4.20.20.3.m1.1.1.2.cmml" type="float" xref="S4.T4.20.20.3.m1.1.1.2">79.61</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.20.20.3.m1.1c">79.61\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.20.20.3.m1.1d">79.61 %</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we propose to fine-tune Large Language Models (LLMs) to figure out the domain adaptation problem stemming from utilizing general-purpose LLMs, in particular identifying implicit relations between entities in a sentence.
To perform this, we conducted two approaches: fine-tuning language models and RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> along with fine-tuned language models on four benchmark datasets, including TACRED, TACREV, Re-TACRED, and SemEVAL, using T5 Large, Mistral-7B, and Llama2-7B. Our fine-tuned LLMs achieved remarkable results and mostly outperformed previous works <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib29" title="">2023</a>; Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>, including the original RAG4RE approach, on TACRED, TACREV and Re-TACRED.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Furthermore, we integrated our fine-tuned LLMs on relation extraction datasets into RAG4RE <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite> and evaluated this approach using three benchmark datasets: TACRED, TACREV, and Re-TACRED. We tested three distinct LLMs: Mistral-7B, T5 Large, and Llama2-7B. The results showed that integrating fine-tuned LLMs into the RAG4RE approach improved the original work’s performance due to domain adaptation, particularly with T5 Large. However, we did not observe consistent improvements when integrated our fine-tuned Llama2-7B and Mistral-7B models into RAG4RE. This issue might be related to catastrophic forgetting caused by single-task fine-tuning. Overall, RAG4RE with our fine-tuned models achieved remarkable results compared to RAG4RE using general-purpose LLMs as reported in <cite class="ltx_cite ltx_citemacro_citep">(Efeoglu and Paschke, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib9" title="">2024</a>)</cite>. Our proposed approach exhibited notable improvements on the benchmarks compared to the original RAG4RE and previous works. Unfortunately, we could not evaluate the performance on SemEVAL dataset, as it is quite small and lacks additional splits not used in the original RAG4RE, unlike TACRED and its variants.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">In our future work, we intend to extend our approach with multi-task fine-tuning for entity recognition and relation extraction, since single-task fine-tuning might encounter with catastrophic forgetting of learned knowledge and reduce the capabilities of LLMs <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib10" title="">2024</a>; Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib30" title="">2024</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2406.14745v2#bib.bib21" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_start_2_columns"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agichtein and Gravano (2000)</span>
<span class="ltx_bibblock">
Eugene Agichtein and Luis Gravano. 2000.

</span>
<span class="ltx_bibblock">Snowball: Extracting Relations from Large Plain-Text Collections. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the Fifth ACM Conference on Digital Libraries</em> (San Antonio, Texas, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib2.2.2">(DL ’00)</em>. Association for Computing Machinery, New York, NY, USA, 85–94.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alt et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Christoph Alt, Aleksandra Gabryszak, and Leonhard Hennig. 2020.

</span>
<span class="ltx_bibblock">TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 1558–1569.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.acl-main.142" title="">https://doi.org/10.18653/v1/2020.acl-main.142</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aydar et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Mehmet Aydar, Ozge Bozal, and Furkan Ozbay. 2020.

</span>
<span class="ltx_bibblock">Neural relation extraction: a survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Zhenbin Chen, Zhixin Li, Yufei Zeng, Canlong Zhang, and Huifang Ma. 2024.

</span>
<span class="ltx_bibblock">GAP: A novel Generative context-Aware Prompt-tuning method for relation extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Expert Systems with Applications</em> 248 (2024), 123478.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.eswa.2024.123478" title="">https://doi.org/10.1016/j.eswa.2024.123478</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei.
2022.

</span>
<span class="ltx_bibblock">Scaling Instruction-Finetuned Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2210.11416" title="">https://doi.org/10.48550/ARXIV.2210.11416</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Amir DN Cohen, Shachar Rosenman, and Yoav Goldberg. 2020.

</span>
<span class="ltx_bibblock">Relation classification as two-way span-prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">arXiv preprint arXiv:2010.04829</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock">QLoRA: Efficient Finetuning of Quantized LLMs.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.14314 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Efeoglu and Paschke (2024)</span>
<span class="ltx_bibblock">
Sefika Efeoglu and Adrian Paschke. 2024.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation-based Relation Extraction.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2404.13397 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Yu Han, and Hao Wang. 2024.

</span>
<span class="ltx_bibblock">Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2403.03432 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">arXiv preprint arXiv:2312.10997</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grishman (2015)</span>
<span class="ltx_bibblock">
Ralph Grishman. 2015.

</span>
<span class="ltx_bibblock">Information Extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE Expert</em> 30, 5 (1 Sept. 2015), 8–15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Zeyu Han, Chao Gao, Jinyang Liu, Sai Qian Zhang, et al<span class="ltx_text" id="bib.bib13.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">Parameter-efficient fine-tuning for large models: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.4.1">arXiv preprint arXiv:2403.14608</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrickx et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2010)</span>
<span class="ltx_bibblock">
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid Ó Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. 2010.

</span>
<span class="ltx_bibblock">SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the 5th International Workshop on Semantic Evaluation</em>, Katrin Erk and Carlo Strapparava (Eds.). Association for Computational Linguistics, Uppsala, Sweden, 33–38.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/S10-1006" title="">https://aclanthology.org/S10-1006</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2106.09685 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al<span class="ltx_text" id="bib.bib16.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Mistral 7B.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.4.1">arXiv preprint arXiv:2310.06825</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kai Zhang (2023)</span>
<span class="ltx_bibblock">
Yu Su Kai Zhang, Bernal Jiménez Gutiérrez. 2023.

</span>
<span class="ltx_bibblock">Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Findings of ACL</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lambert et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Nathan Lambert, Louis Castricato, Leandro von Werra, and Alex Havrilla. 2022.

</span>
<span class="ltx_bibblock">Illustrating Reinforcement Learning from Human Feedback (RLHF).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Hugging Face Blog</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">https://huggingface.co/blog/rlhf.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em> (Vancouver, BC, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib19.4.2">(NIPS’20)</em>. Curran Associates Inc., Red Hook, NY, USA, Article 793, 16 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Bo Li, Wei Ye, Jinglei Zhang, and Shikun Zhang. 2022.

</span>
<span class="ltx_bibblock">Reviewing Labels: Label Graph Network with Top-k Prediction Set for Relation Extraction.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2212.14270 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Bingchang Liu, Chaoyu Chen, Cong Liao, Zi Gong, Huan Wang, Zhichao Lei, Ming Liang, Dajun Chen, Min Shen, Hailian Zhou, Hang Yu, and Jianguo Li. 2023.

</span>
<span class="ltx_bibblock">MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2311.02303 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melz (2023)</span>
<span class="ltx_bibblock">
Eric Melz. 2023.

</span>
<span class="ltx_bibblock">Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv e-prints</em> (2023), arXiv–2311.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. 2024.

</span>
<span class="ltx_bibblock">Unifying large language models and knowledge graphs: A roadmap.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">IEEE Transactions on Knowledge and Data Engineering</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pawar et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Sachin Pawar, Girish K. Palshikar, and Pushpak Bhattacharyya. 2017.

</span>
<span class="ltx_bibblock">Relation Extraction : A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct Preference Optimization: Your Language Model is Secretly a Reward Model.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.18290 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stoica et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
George Stoica, Emmanouil Antonios Platanios, and Barnabas Poczos. 2021.

</span>
<span class="ltx_bibblock">Re-TACRED: Addressing Shortcomings of the TACRED Dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Proceedings of the AAAI Conference on Artificial Intelligence</em> 35, 15 (May 2021), 13843–13850.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1609/aaai.v35i15.17631" title="">https://doi.org/10.1609/aaai.v35i15.17631</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin R. Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cristian Cantón Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel M. Kloumann, A. V. Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, R. Subramanian, Xia Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang,
Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">ArXiv</em> abs/2307.09288 (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:259950998" title="">https://api.semanticscholar.org/CorpusID:259950998</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chenguang Wang, Xiao Liu, Zui Chen, Haoyun Hong, Jie Tang, and Dawn Song. 2022.

</span>
<span class="ltx_bibblock">DeepStruct: Pretraining of Language Models for Structure Prediction. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">Findings of the Association for Computational Linguistics: ACL 2022</em>, Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for Computational Linguistics, Dublin, Ireland, 803–823.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2022.findings-acl.67" title="">https://doi.org/10.18653/v1/2022.findings-acl.67</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Weimin Xiong, Yifan Song, Peiyi Wang, and Sujian Li. 2023.

</span>
<span class="ltx_bibblock">Rationale-Enhanced Language Models are Better Continual Relation Learners. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 15489–15497.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.emnlp-main.958" title="">https://doi.org/10.18653/v1/2023.emnlp-main.958</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Haoran Yang, Yumeng Zhang, Jiaqi Xu, Hongyuan Lu, Pheng Ann Heng, and Wai Lam. 2024.

</span>
<span class="ltx_bibblock">Unveiling the Generalization Power of Fine-Tuned Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2403.09162 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, and Christopher D. Manning. 2017.

</span>
<span class="ltx_bibblock">Position-aware Attention and Supervised Data Improve Slot Filling. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, Martha Palmer, Rebecca Hwa, and Sebastian Riedel (Eds.). Association for Computational Linguistics, Copenhagen, Denmark, 35–45.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D17-1004" title="">https://doi.org/10.18653/v1/D17-1004</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou and Chen (2022)</span>
<span class="ltx_bibblock">
Wenxuan Zhou and Muhao Chen. 2022.

</span>
<span class="ltx_bibblock">An Improved Baseline for Sentence-level Relation Extraction. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</em>, Yulan He, Heng Ji, Sujian Li, Yang Liu, and Chua-Hui Chang (Eds.). Association for Computational Linguistics, Online only, 161–168.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.aacl-short.21" title="">https://aclanthology.org/2022.aacl-short.21</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_end_2_columns"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Jun 24 06:57:00 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
