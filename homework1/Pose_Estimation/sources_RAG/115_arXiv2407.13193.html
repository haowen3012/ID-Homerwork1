<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Retrieval-Augmented Generation for Natural Language Processing: A Survey</title>
<!--Generated on Fri Jul 19 02:01:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.13193v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S1" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S2" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Overview of Retrieval-Augmented Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Retriever</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS1" title="In 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Building the Retriever</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS1.SSS1" title="In 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Chunking Corpus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS1.SSS2" title="In 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Encoding Chunks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS1.SSS3" title="In 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Building the Index</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS1.SSS4" title="In 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.4 </span>Building the Datastore with Key-Value Pairs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS1.SSS5" title="In 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.5 </span>Code Demonstrations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS2" title="In 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Querying the Retriever</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS2.SSS1" title="In 3.2. Querying the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Encoding Queries and ANN Search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS2.SSS2" title="In 3.2. Querying the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Post-Processing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.SS2.SSS3" title="In 3.2. Querying the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Code Demonstrations</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Retrieval Fusions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4.SS1" title="In 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Query-based Fusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4.SS2" title="In 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Logits-based Fusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4.SS3" title="In 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Latent Fusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S5" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Generators</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>RAG Training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6.SS1" title="In 6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>RAG without Datastore Update</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6.SS1.SSS1" title="In 6.1. RAG without Datastore Update ‣ 6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.1 </span>Training retriever.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6.SS1.SSS2" title="In 6.1. RAG without Datastore Update ‣ 6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.2 </span>Training generator.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6.SS1.SSS3" title="In 6.1. RAG without Datastore Update ‣ 6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1.3 </span>Jointly training the retriever and generator.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6.SS2" title="In 6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>RAG with Datastore Update</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS1" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Language Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS2" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS3" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Text Summarization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS4" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.4 </span>Question Answering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS5" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.5 </span>Information Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS6" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.6 </span>Text Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7.SS7" title="In 7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.7 </span>Dialogue Systems</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S8" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Applications</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S8.SS1" title="In 8. Applications ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>LLM-based Autonomous Agents</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S8.SS2" title="In 8. Applications ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Frameworks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Discussion and Future Direction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9.SS1" title="In 9. Discussion and Future Direction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.1 </span>Retrieval Quality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9.SS2" title="In 9. Discussion and Future Direction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.2 </span>RAG Efficiency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9.SS3" title="In 9. Discussion and Future Direction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.3 </span>Choices of Fusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9.SS4" title="In 9. Discussion and Future Direction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.4 </span>RAG Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9.SS5" title="In 9. Discussion and Future Direction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9.5 </span>Cross-Modality Retrieval</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S10" title="In Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Retrieval-Augmented Generation for Natural Language Processing: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shangyu Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">City University of Hong Kong, MBZUAI</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ying Xiong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">MBZUAI</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yufei Cui
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">McGill University, Mila</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haolun Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">McGill University, Mila</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Can Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">McGill University, Mila</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ye Yuan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">McGill University, Mila</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lianming Huang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">City University of Hong Kong</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xue Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id8.1.id1">McGill University, Mila</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tei-Wei Kuo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">National Taiwan University</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nan Guan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">City University of Hong Kong</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chun Jason Xue
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">MBZUAI</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id12.id1">Large language models (LLMs) have demonstrated great success in various fields, benefiting from their huge amount of parameters that store knowledge.
However, LLMs still suffer from several key issues, such as hallucination problems, knowledge update issues, and lacking domain-specific expertise.
The appearance of retrieval-augmented generation (RAG), which leverages an external knowledge database to augment LLMs, makes up those drawbacks of LLMs.
This paper reviews all significant techniques of RAG, especially in the retriever and the retrieval fusions.
Besides, tutorial codes are provided for implementing the representative techniques in RAG.
This paper further discusses the RAG training, including RAG with/without datastore update.
Then, we introduce the application of RAG in representative natural language processing tasks and industrial scenarios.
Finally, this paper discusses the future directions and challenges of RAG for promoting its development.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib139" title="">2023a</a>; Mesnard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib109" title="">2024</a>; Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib72" title="">2023a</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib115" title="">2023</a>; Zeng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib165" title="">2023</a>)</cite> have achieved significant advancements in recent years and have become the cornerstone of various applications in the field of natural language processing (NLP).
These LLMs are typically pre-trained on a large amount of natural language corpus and then fine-tuned on the specific downstream tasks’ datasets.
Recent works <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib118" title="">2019</a>; AlKhamissi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib4" title="">2022</a>; Meng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib107" title="">2022a</a>; He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib54" title="">2024</a>)</cite> demonstrate the success of LLMs can be explained by the fact that language models act as knowledge bases, which refers to implicitly storing the knowledge learned from training datasets in the parameters as internal memory and generating responses by retrieving answers from memory.
To store more knowledge for better generation performance, existing works generally enlarge the memory capacity by increasing the volume of parameters <cite class="ltx_cite ltx_citemacro_citep">(Abnar
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib2" title="">2022</a>; Brown
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib12" title="">2020</a>; Kaplan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib79" title="">2020</a>; Hoffmann et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib55" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Although existing LLMs have shown great power, there are still several challenges hindering the development of LLMs.
One of the most prominent challenges is the hallucination problem <cite class="ltx_cite ltx_citemacro_citep">(Ji et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib70" title="">2023a</a>; Dale et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib24" title="">2023</a>; Ji
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib71" title="">2023b</a>)</cite>, which refers to the tendency of LLMs to generate responses that are coherent and fluent but factually incorrect.
Another big challenge is the knowledge update issue.
To update the knowledge stored in the LLMs’ internal memory <cite class="ltx_cite ltx_citemacro_citep">(Meng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib107" title="">2022a</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib147" title="">2023f</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib169" title="">2024c</a>)</cite>, it is necessary to retrain/fine-tune LLMs with new data, which is a costly process.
Another challenge for general LLMs is lacking of domain-specific expertise <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib167" title="">2023a</a>; Singhal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib134" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib135" title="">b</a>; Colombo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib21" title="">2024</a>)</cite>.
Training a domain-specific LLM, however, demands considerable manpower for dataset collection.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address these challenges, recent works <cite class="ltx_cite ltx_citemacro_citep">(Lewis
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib88" title="">2020</a>; Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>; Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>)</cite> have proposed leveraging an external knowledge database to augment LLMs, known as retrieval-augmented generation (RAG).
By supplying LLMs with retrieved relevant factual information, the hallucination problem can be alleviated to some extent.
Besides, the knowledge update issue can also be addressed by updating the external knowledge database, which can augment LLMs with up-to-date knowledge.
RAG can also convert a general LLM into a domain-specific LLM by constructing and utilizing a domain-specific knowledge database.
Therefore, RAG plays an important role in augmenting the functionality of LLMs, making them more accurate, knowledgeable, and reliable in a wide range of applications.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.p4.1.1">Contributions:</span>
This paper reviews all techniques involved in RAG for natural language processing.
Although there are several survey papers for RAG <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib89" title="">2022b</a>; Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib42" title="">2023</a>; Hu and Lu, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib60" title="">2024</a>; Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib172" title="">2024</a>; Yu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib163" title="">2024</a>)</cite>, our survey still has some key insights,</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">This paper systematically introduces each component of RAG, including details about the retriever from building to querying, and techniques of the retrieval fusions with tutorial codes.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">This paper exhibits different RAG training strategies, including RAG with/without datastore update.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">This paper further discusses the applications of RAG on downstream NLP tasks and practical NLP scenarios.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">This paper finally identifies promising future directions for exploring and main challenges for addressing.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The remainder of this paper is organized as follows.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S2" title="2. Overview of Retrieval-Augmented Generation ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> gives an overview of RAG.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3" title="3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4" title="4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a> comprehensively introduce all technical details used in retrievers and retrieval fusions.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6" title="6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a> presents how to train the RAG with/without new knowledge.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S7" title="7. Tasks ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">7</span></a> presents the techniques used in representative NLP tasks.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S8" title="8. Applications ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">8</span></a> shows the applications of RAG in practical NLP scenarios.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S9" title="9. Discussion and Future Direction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">9</span></a> discusses the future directions of RAG.
Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S10" title="10. Conclusion ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">10</span></a> makes a final conclusion of this paper.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="471" id="S1.F1.g1" src="x1.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>The overview of retrieval-augmented generation for natural language processing.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Overview of Retrieval-Augmented Generation</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">This section gives an overview of RAG for NLP.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a>, RAG typically consists of three modules, the retriever, the generator, and retrieval fusions.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Retriever</span> module usually comprises three components:
an encoder for encoding inputs into embeddings,
an efficient indexing that supports approximate nearest neighbor search,
and the datastore for storing external knowledge in the form of key-value pairs.
The main challenge in the retriever module is <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">finding the optimal trade-off between retrieval efficiency and retrieval quality</span>.
The retrieval efficiency refers to how fast the relevant information can be obtained, which involves accelerating encoding, efficient indexing, batch querying in the datastore, etc.
The retrieval quality refers to how relevant the information can be retrieved, which involves chunk representation learning, advanced approximate nearest neighbor search algorithms, etc.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Retrieval Fusions</span> aims to leverage the retrieved information to augment the generation.
These fusion techniques can be categorized into three major types: query-based fusion, latent fusion, and logits-based fusion.
The query-based fusion augments inputs with retrievals before feeding them into the generators.
The logits-based fusion focuses on the output logits of generators and fuses the retrievals logits for more robust logits.
The latent fusion refers to introducing retrieval representations into the latent representations of generators, thus implicitly improving the models’ performance.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Generator</span> module can be classified into two branches of generators: default generators and retrieval-augmented (RA) generators.
The default generators include most pre-trained/fine-tuned large language models, such as GPT-series models <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib119" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib120" title="">2019</a>; Brown
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib12" title="">2020</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib115" title="">2023</a>)</cite>, Mistral models <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib72" title="">2023a</a>)</cite>, and Gemini-series models <cite class="ltx_cite ltx_citemacro_citep">(Anil et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib5" title="">2023</a>; Mesnard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib109" title="">2024</a>; Reid
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib125" title="">2024</a>)</cite>.
The RA generators refer to the pre-trained/fine-tuned generators that consist of modules for fusing retrievals, such RETRO <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>)</cite> and Enc-Dec <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib94" title="">2022a</a>)</cite>.
Those generators generate responses or make predictions.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">The workflow of RAG involves three steps:
(1) retrieving the relevant information from external databases based on given inputs;
(2) fusing the retrieved information with inputs or intermediate states based on the fusion techniques;
(3) making predictions by generators based on the input and corresponding retrievals.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Retriever</h2>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="330" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Two stages of using the retriever.</figcaption>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.F2" title="Figure 2 ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> shows the two stages for using the retriever, which involves first building the retriever and then querying the retriever.
The following sections will introduce details about each stage.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Building the Retriever</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">This section will explain how to build a retriever using a large natural language corpus.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.F2" title="Figure 2 ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> (a), the process involves three steps: chunking corpus, encoding chunks, and building the vector database.
Specifically, building the vector database includes building the ANN index and storing the data with key-value pairs.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>Chunking Corpus</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">Chunking techniques generally refer to dividing large documents into small text chunks <cite class="ltx_cite ltx_citemacro_citep">(Muszynska, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib112" title="">2016</a>; Ishiwatari et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib66" title="">2017</a>; Gong
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib44" title="">2020</a>; Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>; Chen
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib14" title="">2022a</a>)</cite>, which is an indispensable key step in the process of building the retriever.
The intuitions behind chunking techniques are,
(1) The texts or embeddings used for the indexing should be semantically independent, containing one core idea for models to encode. Short texts are more likely to be ambiguous, for example, the word “apple“ can refer to a fruit or a company.
(2) Encoding a long sequence document would result in considerable resource overheads when using existing transformer-based models, while processing shorter text chunks can significantly accelerate the encoding process and save memory costs.
Therefore, the main challenge of the chunking techniques is to find the best chunking size to make a better trade-off between text semantics and encoding efficiency.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">To solve the above challenge, there are three key points that need to be considered when determining the chunking size:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Task’s property.</span> Different tasks may benefit from different kinds of retrieval chunks. For example, question-answer tasks may prefer short phrases, while summarization tasks may prefer long documents.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Encoder’s property.</span> Different encoder models have varying encoding capabilities on texts with different lengths. For example, models in the sentence-transformer <cite class="ltx_cite ltx_citemacro_citep">(Reimers and
Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib126" title="">2019</a>)</cite> behave better on a single sentence, while the text-embedding-ada-002 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib114" title="">2022</a>)</cite> is good at longer texts.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Query’s property.</span> The length of the user’s queries should be aligned with the chunking size, which implicitly aligns the amount of contextual information in chunks with that in queries, thus improving the relevance between queries and retrievals. For example, a retrieval database built on short phrases may be useless for queries with long documents.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS1.SSS1.p2.2">Overall, there is no golden rule for determining the chunking size, and it depends on the specific RAG scenarios.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1">There are basically three types of chunking techniques, including <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p3.1.1">the chunking with fixed length</span>, <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p3.1.2">the semantic chunking</span>, and <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p3.1.3">the content-based chunking</span>.
Chunking with fixed length is the simplest way to split documents sequentially using a length hyperparameter.
The semantic chunking cuts documents based on semantics, such as the period character or the newline character that represents the end of the sentence.
Existing state-of-the-art natural language processing toolkits, such as NLTK <cite class="ltx_cite ltx_citemacro_citep">(NLTK, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib113" title="">2001</a>)</cite> and spaCy <cite class="ltx_cite ltx_citemacro_citep">(explosion, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib34" title="">2016</a>)</cite>, have provided convenient sentence-cutting methods.
The content-based chunking segments documents according to the unique structural characteristics.
For example, electronic medical records can be easily segmented based on the sections, or programming codes can be segmented based on function blocks.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Encoding Chunks</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">Encoding refers to numericalizing textual chunks as vector representations (embeddings).
These embeddings generally capture the semantics of the chunks, enabling the retriever to perform similarity searches based on content relevance rather than just keyword matching.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">According to the sparsity of the embeddings, there are two kinds of encoding methods, i.e., <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p2.1.1">sparse encoding</span> and <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p2.1.2">dense encoding</span>.
The sparse encoding represents text by creating high-dimensional vectors where most elements are zero.
The basic sparse encoding is one-hot encoding <cite class="ltx_cite ltx_citemacro_citep">(Harris and Harris, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib51" title="">2010</a>)</cite>, which represents a word with a high-dimensional vector as large as the vocabulary table size but only marks the value corresponding to the presence of the word as one.
The embeddings produced by such encodings are called the one-hot vector.
Other common sparse encodings include:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">Bag of Words (BoW) <cite class="ltx_cite ltx_citemacro_citep">(Harris, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib52" title="">1954</a>)</cite>.</span> This encoding improves one-hot encoding by replacing the zero-one counting with the frequency counting. However, BoW ignores the syntax and word order in the documents and focuses on statistical information, thus only expressing limited semantics.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">Term Frequency-Inverse Document Frequency (TF-IDF) <cite class="ltx_cite ltx_citemacro_citep">(Rajaraman and
Ullman, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib121" title="">2011</a>)</cite>.</span> This encoding not only counts the occurrence (frequency) of each word but also adjusts these counts based on how common the word is across all documents (inverse document frequency). TF-IDF helps emphasize words that are more descriptive of the document’s content.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS1.SSS2.p2.2">Sparse encoding is an efficient way to encode textual chunks.
However, such encodings may not capture deeper semantic meanings.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.1">The dense encoding generates vectors where each dimension can capture a range of semantic features, and most elements are non-zero floating points.
The dense embeddings are generally produced by (deep) neural network models,</p>
<ol class="ltx_enumerate" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib30" title="">2019</a>)</cite> and Variants.</span> Bidirectional Encoder Representation from Transformers (BERT) is a typical pre-trained transformer model, generating dense semantic embeddings that capture the contextual information. Other BERT variants, such as RoBERTa <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib100" title="">2019</a>)</cite>, DistilBERT <cite class="ltx_cite ltx_citemacro_citep">(Sanh
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib129" title="">2019</a>)</cite>, and ELECTRA <cite class="ltx_cite ltx_citemacro_citep">(Clark
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib20" title="">2020</a>)</cite>, further improve the semantic representations with advanced learning techniques.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">Siamese Encoders.</span> This is a type of neural network designed to learn the similarity between inputs, which is usually trained with contrastive learning. Existing state-of-the-art siamese encoders are DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib80" title="">2020</a>)</cite>, SimCSE <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib41" title="">2021</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p" id="S3.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i3.p1.1.1">LLM-based Encoders.</span> This type of encoder benefits from the powerful representation capability of LLMs. LLMs, which contain billions of parameters and are pre-trained on vast amounts of data covering a wide range of topics, have advanced semantic language understanding capabilities. Typical LLM-based encoders are text-embedding-ada-002 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib114" title="">2022</a>)</cite>, bge-embedding <cite class="ltx_cite ltx_citemacro_citep">(Xiao
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib157" title="">2023</a>)</cite>, mxbai-embedding <cite class="ltx_cite ltx_citemacro_citep">(Sean Lee, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib131" title="">2024</a>)</cite>.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS1.SSS2.p3.2">Compared to sparse encoding, dense encoding leverages deep neural networks, especially transformers <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib141" title="">2017</a>)</cite>, to capture broader linguistic and semantic information.
Currently, such encodings are widely used in most semantic representation scenarios.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.3.1.1">Algorithm 1</span> </span> <span class="ltx_text" id="alg1.4.2" style="font-size:90%;">Building the retriever.</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg1.5">
<div class="ltx_listingline" id="alg1.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg1.l0.2" style="font-size:90%;">  A natural language corpus </span><math alttext="D=\{d_{1},\ldots,d_{n}\}" class="ltx_Math" display="inline" id="alg1.l0.m1.3"><semantics id="alg1.l0.m1.3a"><mrow id="alg1.l0.m1.3.3" xref="alg1.l0.m1.3.3.cmml"><mi id="alg1.l0.m1.3.3.4" mathsize="90%" xref="alg1.l0.m1.3.3.4.cmml">D</mi><mo id="alg1.l0.m1.3.3.3" mathsize="90%" xref="alg1.l0.m1.3.3.3.cmml">=</mo><mrow id="alg1.l0.m1.3.3.2.2" xref="alg1.l0.m1.3.3.2.3.cmml"><mo id="alg1.l0.m1.3.3.2.2.3" maxsize="90%" minsize="90%" xref="alg1.l0.m1.3.3.2.3.cmml">{</mo><msub id="alg1.l0.m1.2.2.1.1.1" xref="alg1.l0.m1.2.2.1.1.1.cmml"><mi id="alg1.l0.m1.2.2.1.1.1.2" mathsize="90%" xref="alg1.l0.m1.2.2.1.1.1.2.cmml">d</mi><mn id="alg1.l0.m1.2.2.1.1.1.3" mathsize="90%" xref="alg1.l0.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="alg1.l0.m1.3.3.2.2.4" mathsize="90%" xref="alg1.l0.m1.3.3.2.3.cmml">,</mo><mi id="alg1.l0.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg1.l0.m1.1.1.cmml">…</mi><mo id="alg1.l0.m1.3.3.2.2.5" mathsize="90%" xref="alg1.l0.m1.3.3.2.3.cmml">,</mo><msub id="alg1.l0.m1.3.3.2.2.2" xref="alg1.l0.m1.3.3.2.2.2.cmml"><mi id="alg1.l0.m1.3.3.2.2.2.2" mathsize="90%" xref="alg1.l0.m1.3.3.2.2.2.2.cmml">d</mi><mi id="alg1.l0.m1.3.3.2.2.2.3" mathsize="90%" xref="alg1.l0.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo id="alg1.l0.m1.3.3.2.2.6" maxsize="90%" minsize="90%" xref="alg1.l0.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l0.m1.3b"><apply id="alg1.l0.m1.3.3.cmml" xref="alg1.l0.m1.3.3"><eq id="alg1.l0.m1.3.3.3.cmml" xref="alg1.l0.m1.3.3.3"></eq><ci id="alg1.l0.m1.3.3.4.cmml" xref="alg1.l0.m1.3.3.4">𝐷</ci><set id="alg1.l0.m1.3.3.2.3.cmml" xref="alg1.l0.m1.3.3.2.2"><apply id="alg1.l0.m1.2.2.1.1.1.cmml" xref="alg1.l0.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l0.m1.2.2.1.1.1.1.cmml" xref="alg1.l0.m1.2.2.1.1.1">subscript</csymbol><ci id="alg1.l0.m1.2.2.1.1.1.2.cmml" xref="alg1.l0.m1.2.2.1.1.1.2">𝑑</ci><cn id="alg1.l0.m1.2.2.1.1.1.3.cmml" type="integer" xref="alg1.l0.m1.2.2.1.1.1.3">1</cn></apply><ci id="alg1.l0.m1.1.1.cmml" xref="alg1.l0.m1.1.1">…</ci><apply id="alg1.l0.m1.3.3.2.2.2.cmml" xref="alg1.l0.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l0.m1.3.3.2.2.2.1.cmml" xref="alg1.l0.m1.3.3.2.2.2">subscript</csymbol><ci id="alg1.l0.m1.3.3.2.2.2.2.cmml" xref="alg1.l0.m1.3.3.2.2.2.2">𝑑</ci><ci id="alg1.l0.m1.3.3.2.2.2.3.cmml" xref="alg1.l0.m1.3.3.2.2.2.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m1.3c">D=\{d_{1},\ldots,d_{n}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m1.3d">italic_D = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg1.l0.3" style="font-size:90%;"> for building the knowledge database, an encoder </span><math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="alg1.l0.m2.1"><semantics id="alg1.l0.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l0.m2.1.1" mathsize="90%" xref="alg1.l0.m2.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m2.1b"><ci id="alg1.l0.m2.1.1.cmml" xref="alg1.l0.m2.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m2.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m2.1d">caligraphic_E</annotation></semantics></math><span class="ltx_text" id="alg1.l0.4" style="font-size:90%;"> for encoding chunks.</span>
</div>
<div class="ltx_listingline" id="alg1.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0a.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg1.l0a.2" style="font-size:90%;">  The index </span><math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="alg1.l0a.m1.1"><semantics id="alg1.l0a.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l0a.m1.1.1" mathsize="90%" xref="alg1.l0a.m1.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="alg1.l0a.m1.1b"><ci id="alg1.l0a.m1.1.1.cmml" xref="alg1.l0a.m1.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0a.m1.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0a.m1.1d">caligraphic_I</annotation></semantics></math><span class="ltx_text" id="alg1.l0a.3" style="font-size:90%;"> and the key-value store </span><math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="alg1.l0a.m2.1"><semantics id="alg1.l0a.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l0a.m2.1.1" mathsize="90%" xref="alg1.l0a.m2.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="alg1.l0a.m2.1b"><ci id="alg1.l0a.m2.1.1.cmml" xref="alg1.l0a.m2.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0a.m2.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0a.m2.1d">caligraphic_S</annotation></semantics></math><span class="ltx_text" id="alg1.l0a.4" style="font-size:90%;">.
</span>
</div>
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text" id="alg1.l1.2" style="font-size:90%;">  </span><math alttext="\mathcal{K}=\{\},\mathcal{V}=\{\}" class="ltx_Math" display="inline" id="alg1.l1.m1.2"><semantics id="alg1.l1.m1.2a"><mrow id="alg1.l1.m1.2.2.2" xref="alg1.l1.m1.2.2.3.cmml"><mrow id="alg1.l1.m1.1.1.1.1" xref="alg1.l1.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m1.1.1.1.1.2" mathsize="90%" xref="alg1.l1.m1.1.1.1.1.2.cmml">𝒦</mi><mo id="alg1.l1.m1.1.1.1.1.1" mathsize="90%" xref="alg1.l1.m1.1.1.1.1.1.cmml">=</mo><mrow id="alg1.l1.m1.1.1.1.1.3.2" xref="alg1.l1.m1.1.1.1.1.cmml"><mo id="alg1.l1.m1.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="alg1.l1.m1.1.1.1.1.3.1.cmml">{</mo><mo id="alg1.l1.m1.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="alg1.l1.m1.1.1.1.1.3.1.cmml">}</mo></mrow></mrow><mo id="alg1.l1.m1.2.2.2.3" mathsize="90%" xref="alg1.l1.m1.2.2.3a.cmml">,</mo><mrow id="alg1.l1.m1.2.2.2.2" xref="alg1.l1.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m1.2.2.2.2.2" mathsize="90%" xref="alg1.l1.m1.2.2.2.2.2.cmml">𝒱</mi><mo id="alg1.l1.m1.2.2.2.2.1" mathsize="90%" xref="alg1.l1.m1.2.2.2.2.1.cmml">=</mo><mrow id="alg1.l1.m1.2.2.2.2.3.2" xref="alg1.l1.m1.2.2.2.2.cmml"><mo id="alg1.l1.m1.2.2.2.2.3.2.1" maxsize="90%" minsize="90%" xref="alg1.l1.m1.2.2.2.2.3.1.cmml">{</mo><mo id="alg1.l1.m1.2.2.2.2.3.2.2" maxsize="90%" minsize="90%" xref="alg1.l1.m1.2.2.2.2.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.2b"><apply id="alg1.l1.m1.2.2.3.cmml" xref="alg1.l1.m1.2.2.2"><csymbol cd="ambiguous" id="alg1.l1.m1.2.2.3a.cmml" xref="alg1.l1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="alg1.l1.m1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1"><eq id="alg1.l1.m1.1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1.1"></eq><ci id="alg1.l1.m1.1.1.1.1.2.cmml" xref="alg1.l1.m1.1.1.1.1.2">𝒦</ci><list id="alg1.l1.m1.1.1.1.1.3.1.cmml" xref="alg1.l1.m1.1.1.1.1.3.2.1"></list></apply><apply id="alg1.l1.m1.2.2.2.2.cmml" xref="alg1.l1.m1.2.2.2.2"><eq id="alg1.l1.m1.2.2.2.2.1.cmml" xref="alg1.l1.m1.2.2.2.2.1"></eq><ci id="alg1.l1.m1.2.2.2.2.2.cmml" xref="alg1.l1.m1.2.2.2.2.2">𝒱</ci><list id="alg1.l1.m1.2.2.2.2.3.1.cmml" xref="alg1.l1.m1.2.2.2.2.3.2.1"></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.2c">\mathcal{K}=\{\},\mathcal{V}=\{\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.2d">caligraphic_K = { } , caligraphic_V = { }</annotation></semantics></math><span class="ltx_text" id="alg1.l1.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text" id="alg1.l2.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l2.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l2.4" style="font-size:90%;"> </span><math alttext="d_{i}\in D" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><msub id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml"><mi id="alg1.l2.m1.1.1.2.2" mathsize="90%" xref="alg1.l2.m1.1.1.2.2.cmml">d</mi><mi id="alg1.l2.m1.1.1.2.3" mathsize="90%" xref="alg1.l2.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l2.m1.1.1.1" mathsize="90%" xref="alg1.l2.m1.1.1.1.cmml">∈</mo><mi id="alg1.l2.m1.1.1.3" mathsize="90%" xref="alg1.l2.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><in id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1"></in><apply id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.2.1.cmml" xref="alg1.l2.m1.1.1.2">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.2.cmml" xref="alg1.l2.m1.1.1.2.2">𝑑</ci><ci id="alg1.l2.m1.1.1.2.3.cmml" xref="alg1.l2.m1.1.1.2.3">𝑖</ci></apply><ci id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">d_{i}\in D</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_D</annotation></semantics></math><span class="ltx_text" id="alg1.l2.5" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l2.6" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l2.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.2.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text" id="alg1.l3.3" style="font-size:90%;">     </span><math alttext="c^{1}_{i},\ldots,c^{m}_{i}=Chunk(d_{i})" class="ltx_Math" display="inline" id="alg1.l3.m1.4"><semantics id="alg1.l3.m1.4a"><mrow id="alg1.l3.m1.4.4" xref="alg1.l3.m1.4.4.cmml"><mrow id="alg1.l3.m1.3.3.2.2" xref="alg1.l3.m1.3.3.2.3.cmml"><msubsup id="alg1.l3.m1.2.2.1.1.1" xref="alg1.l3.m1.2.2.1.1.1.cmml"><mi id="alg1.l3.m1.2.2.1.1.1.2.2" mathsize="90%" xref="alg1.l3.m1.2.2.1.1.1.2.2.cmml">c</mi><mi id="alg1.l3.m1.2.2.1.1.1.3" mathsize="90%" xref="alg1.l3.m1.2.2.1.1.1.3.cmml">i</mi><mn id="alg1.l3.m1.2.2.1.1.1.2.3" mathsize="90%" xref="alg1.l3.m1.2.2.1.1.1.2.3.cmml">1</mn></msubsup><mo id="alg1.l3.m1.3.3.2.2.3" mathsize="90%" xref="alg1.l3.m1.3.3.2.3.cmml">,</mo><mi id="alg1.l3.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg1.l3.m1.1.1.cmml">…</mi><mo id="alg1.l3.m1.3.3.2.2.4" mathsize="90%" xref="alg1.l3.m1.3.3.2.3.cmml">,</mo><msubsup id="alg1.l3.m1.3.3.2.2.2" xref="alg1.l3.m1.3.3.2.2.2.cmml"><mi id="alg1.l3.m1.3.3.2.2.2.2.2" mathsize="90%" xref="alg1.l3.m1.3.3.2.2.2.2.2.cmml">c</mi><mi id="alg1.l3.m1.3.3.2.2.2.3" mathsize="90%" xref="alg1.l3.m1.3.3.2.2.2.3.cmml">i</mi><mi id="alg1.l3.m1.3.3.2.2.2.2.3" mathsize="90%" xref="alg1.l3.m1.3.3.2.2.2.2.3.cmml">m</mi></msubsup></mrow><mo id="alg1.l3.m1.4.4.4" mathsize="90%" xref="alg1.l3.m1.4.4.4.cmml">=</mo><mrow id="alg1.l3.m1.4.4.3" xref="alg1.l3.m1.4.4.3.cmml"><mi id="alg1.l3.m1.4.4.3.3" mathsize="90%" xref="alg1.l3.m1.4.4.3.3.cmml">C</mi><mo id="alg1.l3.m1.4.4.3.2" xref="alg1.l3.m1.4.4.3.2.cmml">⁢</mo><mi id="alg1.l3.m1.4.4.3.4" mathsize="90%" xref="alg1.l3.m1.4.4.3.4.cmml">h</mi><mo id="alg1.l3.m1.4.4.3.2a" xref="alg1.l3.m1.4.4.3.2.cmml">⁢</mo><mi id="alg1.l3.m1.4.4.3.5" mathsize="90%" xref="alg1.l3.m1.4.4.3.5.cmml">u</mi><mo id="alg1.l3.m1.4.4.3.2b" xref="alg1.l3.m1.4.4.3.2.cmml">⁢</mo><mi id="alg1.l3.m1.4.4.3.6" mathsize="90%" xref="alg1.l3.m1.4.4.3.6.cmml">n</mi><mo id="alg1.l3.m1.4.4.3.2c" xref="alg1.l3.m1.4.4.3.2.cmml">⁢</mo><mi id="alg1.l3.m1.4.4.3.7" mathsize="90%" xref="alg1.l3.m1.4.4.3.7.cmml">k</mi><mo id="alg1.l3.m1.4.4.3.2d" xref="alg1.l3.m1.4.4.3.2.cmml">⁢</mo><mrow id="alg1.l3.m1.4.4.3.1.1" xref="alg1.l3.m1.4.4.3.1.1.1.cmml"><mo id="alg1.l3.m1.4.4.3.1.1.2" maxsize="90%" minsize="90%" xref="alg1.l3.m1.4.4.3.1.1.1.cmml">(</mo><msub id="alg1.l3.m1.4.4.3.1.1.1" xref="alg1.l3.m1.4.4.3.1.1.1.cmml"><mi id="alg1.l3.m1.4.4.3.1.1.1.2" mathsize="90%" xref="alg1.l3.m1.4.4.3.1.1.1.2.cmml">d</mi><mi id="alg1.l3.m1.4.4.3.1.1.1.3" mathsize="90%" xref="alg1.l3.m1.4.4.3.1.1.1.3.cmml">i</mi></msub><mo id="alg1.l3.m1.4.4.3.1.1.3" maxsize="90%" minsize="90%" xref="alg1.l3.m1.4.4.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.4b"><apply id="alg1.l3.m1.4.4.cmml" xref="alg1.l3.m1.4.4"><eq id="alg1.l3.m1.4.4.4.cmml" xref="alg1.l3.m1.4.4.4"></eq><list id="alg1.l3.m1.3.3.2.3.cmml" xref="alg1.l3.m1.3.3.2.2"><apply id="alg1.l3.m1.2.2.1.1.1.cmml" xref="alg1.l3.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.2.2.1.1.1.1.cmml" xref="alg1.l3.m1.2.2.1.1.1">subscript</csymbol><apply id="alg1.l3.m1.2.2.1.1.1.2.cmml" xref="alg1.l3.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.2.2.1.1.1.2.1.cmml" xref="alg1.l3.m1.2.2.1.1.1">superscript</csymbol><ci id="alg1.l3.m1.2.2.1.1.1.2.2.cmml" xref="alg1.l3.m1.2.2.1.1.1.2.2">𝑐</ci><cn id="alg1.l3.m1.2.2.1.1.1.2.3.cmml" type="integer" xref="alg1.l3.m1.2.2.1.1.1.2.3">1</cn></apply><ci id="alg1.l3.m1.2.2.1.1.1.3.cmml" xref="alg1.l3.m1.2.2.1.1.1.3">𝑖</ci></apply><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">…</ci><apply id="alg1.l3.m1.3.3.2.2.2.cmml" xref="alg1.l3.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l3.m1.3.3.2.2.2.1.cmml" xref="alg1.l3.m1.3.3.2.2.2">subscript</csymbol><apply id="alg1.l3.m1.3.3.2.2.2.2.cmml" xref="alg1.l3.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l3.m1.3.3.2.2.2.2.1.cmml" xref="alg1.l3.m1.3.3.2.2.2">superscript</csymbol><ci id="alg1.l3.m1.3.3.2.2.2.2.2.cmml" xref="alg1.l3.m1.3.3.2.2.2.2.2">𝑐</ci><ci id="alg1.l3.m1.3.3.2.2.2.2.3.cmml" xref="alg1.l3.m1.3.3.2.2.2.2.3">𝑚</ci></apply><ci id="alg1.l3.m1.3.3.2.2.2.3.cmml" xref="alg1.l3.m1.3.3.2.2.2.3">𝑖</ci></apply></list><apply id="alg1.l3.m1.4.4.3.cmml" xref="alg1.l3.m1.4.4.3"><times id="alg1.l3.m1.4.4.3.2.cmml" xref="alg1.l3.m1.4.4.3.2"></times><ci id="alg1.l3.m1.4.4.3.3.cmml" xref="alg1.l3.m1.4.4.3.3">𝐶</ci><ci id="alg1.l3.m1.4.4.3.4.cmml" xref="alg1.l3.m1.4.4.3.4">ℎ</ci><ci id="alg1.l3.m1.4.4.3.5.cmml" xref="alg1.l3.m1.4.4.3.5">𝑢</ci><ci id="alg1.l3.m1.4.4.3.6.cmml" xref="alg1.l3.m1.4.4.3.6">𝑛</ci><ci id="alg1.l3.m1.4.4.3.7.cmml" xref="alg1.l3.m1.4.4.3.7">𝑘</ci><apply id="alg1.l3.m1.4.4.3.1.1.1.cmml" xref="alg1.l3.m1.4.4.3.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.4.4.3.1.1.1.1.cmml" xref="alg1.l3.m1.4.4.3.1.1">subscript</csymbol><ci id="alg1.l3.m1.4.4.3.1.1.1.2.cmml" xref="alg1.l3.m1.4.4.3.1.1.1.2">𝑑</ci><ci id="alg1.l3.m1.4.4.3.1.1.1.3.cmml" xref="alg1.l3.m1.4.4.3.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.4c">c^{1}_{i},\ldots,c^{m}_{i}=Chunk(d_{i})</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.4d">italic_c start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , … , italic_c start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_C italic_h italic_u italic_n italic_k ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg1.l3.4" style="font-size:90%;">; </span><span class="ltx_text" id="alg1.l3.1" style="font-size:90%;float:right;">/* Split each data <math alttext="d_{i}" class="ltx_Math" display="inline" id="alg1.l3.1.m1.1"><semantics id="alg1.l3.1.m1.1a"><msub id="alg1.l3.1.m1.1.1" xref="alg1.l3.1.m1.1.1.cmml"><mi id="alg1.l3.1.m1.1.1.2" xref="alg1.l3.1.m1.1.1.2.cmml">d</mi><mi id="alg1.l3.1.m1.1.1.3" xref="alg1.l3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l3.1.m1.1b"><apply id="alg1.l3.1.m1.1.1.cmml" xref="alg1.l3.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l3.1.m1.1.1.1.cmml" xref="alg1.l3.1.m1.1.1">subscript</csymbol><ci id="alg1.l3.1.m1.1.1.2.cmml" xref="alg1.l3.1.m1.1.1.2">𝑑</ci><ci id="alg1.l3.1.m1.1.1.3.cmml" xref="alg1.l3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.1.m1.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.1.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> */
</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text" id="alg1.l4.2" style="font-size:90%;">     </span><span class="ltx_text ltx_font_bold" id="alg1.l4.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l4.4" style="font-size:90%;"> </span><math alttext="j" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mi id="alg1.l4.m1.1.1" mathsize="90%" xref="alg1.l4.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">j</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="alg1.l4.5" style="font-size:90%;"> from </span><math alttext="1" class="ltx_Math" display="inline" id="alg1.l4.m2.1"><semantics id="alg1.l4.m2.1a"><mn id="alg1.l4.m2.1.1" mathsize="90%" xref="alg1.l4.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><cn id="alg1.l4.m2.1.1.cmml" type="integer" xref="alg1.l4.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m2.1d">1</annotation></semantics></math><span class="ltx_text" id="alg1.l4.6" style="font-size:90%;"> to </span><math alttext="m" class="ltx_Math" display="inline" id="alg1.l4.m3.1"><semantics id="alg1.l4.m3.1a"><mi id="alg1.l4.m3.1.1" mathsize="90%" xref="alg1.l4.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m3.1b"><ci id="alg1.l4.m3.1.1.cmml" xref="alg1.l4.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m3.1c">m</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m3.1d">italic_m</annotation></semantics></math><span class="ltx_text" id="alg1.l4.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l4.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l4.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.2.1.1" style="font-size:80%;">5:</span></span><span class="ltx_text" id="alg1.l5.3" style="font-size:90%;">        </span><math alttext="e^{j}_{i}=\mathcal{E}(c^{j}_{i})" class="ltx_Math" display="inline" id="alg1.l5.m1.1"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><msubsup id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml"><mi id="alg1.l5.m1.1.1.3.2.2" mathsize="90%" xref="alg1.l5.m1.1.1.3.2.2.cmml">e</mi><mi id="alg1.l5.m1.1.1.3.3" mathsize="90%" xref="alg1.l5.m1.1.1.3.3.cmml">i</mi><mi id="alg1.l5.m1.1.1.3.2.3" mathsize="90%" xref="alg1.l5.m1.1.1.3.2.3.cmml">j</mi></msubsup><mo id="alg1.l5.m1.1.1.2" mathsize="90%" xref="alg1.l5.m1.1.1.2.cmml">=</mo><mrow id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m1.1.1.1.3" mathsize="90%" xref="alg1.l5.m1.1.1.1.3.cmml">ℰ</mi><mo id="alg1.l5.m1.1.1.1.2" xref="alg1.l5.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l5.m1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.cmml"><mo id="alg1.l5.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg1.l5.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg1.l5.m1.1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l5.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg1.l5.m1.1.1.1.1.1.1.2.2.cmml">c</mi><mi id="alg1.l5.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg1.l5.m1.1.1.1.1.1.1.3.cmml">i</mi><mi id="alg1.l5.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg1.l5.m1.1.1.1.1.1.1.2.3.cmml">j</mi></msubsup><mo id="alg1.l5.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg1.l5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><eq id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2"></eq><apply id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.3">subscript</csymbol><apply id="alg1.l5.m1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.3.2.1.cmml" xref="alg1.l5.m1.1.1.3">superscript</csymbol><ci id="alg1.l5.m1.1.1.3.2.2.cmml" xref="alg1.l5.m1.1.1.3.2.2">𝑒</ci><ci id="alg1.l5.m1.1.1.3.2.3.cmml" xref="alg1.l5.m1.1.1.3.2.3">𝑗</ci></apply><ci id="alg1.l5.m1.1.1.3.3.cmml" xref="alg1.l5.m1.1.1.3.3">𝑖</ci></apply><apply id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"><times id="alg1.l5.m1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.2"></times><ci id="alg1.l5.m1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.3">ℰ</ci><apply id="alg1.l5.m1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1">subscript</csymbol><apply id="alg1.l5.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.1.2.1.cmml" xref="alg1.l5.m1.1.1.1.1.1">superscript</csymbol><ci id="alg1.l5.m1.1.1.1.1.1.1.2.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.2.2">𝑐</ci><ci id="alg1.l5.m1.1.1.1.1.1.1.2.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.2.3">𝑗</ci></apply><ci id="alg1.l5.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">e^{j}_{i}=\mathcal{E}(c^{j}_{i})</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.1d">italic_e start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_E ( italic_c start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg1.l5.4" style="font-size:90%;">; </span><span class="ltx_text" id="alg1.l5.1" style="font-size:90%;float:right;">/* Encode each chunk <math alttext="c^{j}_{i}" class="ltx_Math" display="inline" id="alg1.l5.1.m1.1"><semantics id="alg1.l5.1.m1.1a"><msubsup id="alg1.l5.1.m1.1.1" xref="alg1.l5.1.m1.1.1.cmml"><mi id="alg1.l5.1.m1.1.1.2.2" xref="alg1.l5.1.m1.1.1.2.2.cmml">c</mi><mi id="alg1.l5.1.m1.1.1.3" xref="alg1.l5.1.m1.1.1.3.cmml">i</mi><mi id="alg1.l5.1.m1.1.1.2.3" xref="alg1.l5.1.m1.1.1.2.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l5.1.m1.1b"><apply id="alg1.l5.1.m1.1.1.cmml" xref="alg1.l5.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5.1.m1.1.1.1.cmml" xref="alg1.l5.1.m1.1.1">subscript</csymbol><apply id="alg1.l5.1.m1.1.1.2.cmml" xref="alg1.l5.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5.1.m1.1.1.2.1.cmml" xref="alg1.l5.1.m1.1.1">superscript</csymbol><ci id="alg1.l5.1.m1.1.1.2.2.cmml" xref="alg1.l5.1.m1.1.1.2.2">𝑐</ci><ci id="alg1.l5.1.m1.1.1.2.3.cmml" xref="alg1.l5.1.m1.1.1.2.3">𝑗</ci></apply><ci id="alg1.l5.1.m1.1.1.3.cmml" xref="alg1.l5.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.1.m1.1c">c^{j}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.1.m1.1d">italic_c start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> */
</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span><span class="ltx_text" id="alg1.l6.2" style="font-size:90%;">        Add </span><math alttext="e^{j}_{i}" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><msubsup id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi id="alg1.l6.m1.1.1.2.2" mathsize="90%" xref="alg1.l6.m1.1.1.2.2.cmml">e</mi><mi id="alg1.l6.m1.1.1.3" mathsize="90%" xref="alg1.l6.m1.1.1.3.cmml">i</mi><mi id="alg1.l6.m1.1.1.2.3" mathsize="90%" xref="alg1.l6.m1.1.1.2.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1">subscript</csymbol><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1">superscript</csymbol><ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">𝑒</ci><ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">𝑗</ci></apply><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">e^{j}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">italic_e start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l6.3" style="font-size:90%;"> into </span><math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="alg1.l6.m2.1"><semantics id="alg1.l6.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m2.1.1" mathsize="90%" xref="alg1.l6.m2.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><ci id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m2.1d">caligraphic_K</annotation></semantics></math><span class="ltx_text" id="alg1.l6.4" style="font-size:90%;"> and </span><math alttext="c^{j}_{i}+c^{j+1}_{i}" class="ltx_Math" display="inline" id="alg1.l6.m3.1"><semantics id="alg1.l6.m3.1a"><mrow id="alg1.l6.m3.1.1" xref="alg1.l6.m3.1.1.cmml"><msubsup id="alg1.l6.m3.1.1.2" xref="alg1.l6.m3.1.1.2.cmml"><mi id="alg1.l6.m3.1.1.2.2.2" mathsize="90%" xref="alg1.l6.m3.1.1.2.2.2.cmml">c</mi><mi id="alg1.l6.m3.1.1.2.3" mathsize="90%" xref="alg1.l6.m3.1.1.2.3.cmml">i</mi><mi id="alg1.l6.m3.1.1.2.2.3" mathsize="90%" xref="alg1.l6.m3.1.1.2.2.3.cmml">j</mi></msubsup><mo id="alg1.l6.m3.1.1.1" mathsize="90%" xref="alg1.l6.m3.1.1.1.cmml">+</mo><msubsup id="alg1.l6.m3.1.1.3" xref="alg1.l6.m3.1.1.3.cmml"><mi id="alg1.l6.m3.1.1.3.2.2" mathsize="90%" xref="alg1.l6.m3.1.1.3.2.2.cmml">c</mi><mi id="alg1.l6.m3.1.1.3.3" mathsize="90%" xref="alg1.l6.m3.1.1.3.3.cmml">i</mi><mrow id="alg1.l6.m3.1.1.3.2.3" xref="alg1.l6.m3.1.1.3.2.3.cmml"><mi id="alg1.l6.m3.1.1.3.2.3.2" mathsize="90%" xref="alg1.l6.m3.1.1.3.2.3.2.cmml">j</mi><mo id="alg1.l6.m3.1.1.3.2.3.1" mathsize="90%" xref="alg1.l6.m3.1.1.3.2.3.1.cmml">+</mo><mn id="alg1.l6.m3.1.1.3.2.3.3" mathsize="90%" xref="alg1.l6.m3.1.1.3.2.3.3.cmml">1</mn></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m3.1b"><apply id="alg1.l6.m3.1.1.cmml" xref="alg1.l6.m3.1.1"><plus id="alg1.l6.m3.1.1.1.cmml" xref="alg1.l6.m3.1.1.1"></plus><apply id="alg1.l6.m3.1.1.2.cmml" xref="alg1.l6.m3.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m3.1.1.2.1.cmml" xref="alg1.l6.m3.1.1.2">subscript</csymbol><apply id="alg1.l6.m3.1.1.2.2.cmml" xref="alg1.l6.m3.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m3.1.1.2.2.1.cmml" xref="alg1.l6.m3.1.1.2">superscript</csymbol><ci id="alg1.l6.m3.1.1.2.2.2.cmml" xref="alg1.l6.m3.1.1.2.2.2">𝑐</ci><ci id="alg1.l6.m3.1.1.2.2.3.cmml" xref="alg1.l6.m3.1.1.2.2.3">𝑗</ci></apply><ci id="alg1.l6.m3.1.1.2.3.cmml" xref="alg1.l6.m3.1.1.2.3">𝑖</ci></apply><apply id="alg1.l6.m3.1.1.3.cmml" xref="alg1.l6.m3.1.1.3"><csymbol cd="ambiguous" id="alg1.l6.m3.1.1.3.1.cmml" xref="alg1.l6.m3.1.1.3">subscript</csymbol><apply id="alg1.l6.m3.1.1.3.2.cmml" xref="alg1.l6.m3.1.1.3"><csymbol cd="ambiguous" id="alg1.l6.m3.1.1.3.2.1.cmml" xref="alg1.l6.m3.1.1.3">superscript</csymbol><ci id="alg1.l6.m3.1.1.3.2.2.cmml" xref="alg1.l6.m3.1.1.3.2.2">𝑐</ci><apply id="alg1.l6.m3.1.1.3.2.3.cmml" xref="alg1.l6.m3.1.1.3.2.3"><plus id="alg1.l6.m3.1.1.3.2.3.1.cmml" xref="alg1.l6.m3.1.1.3.2.3.1"></plus><ci id="alg1.l6.m3.1.1.3.2.3.2.cmml" xref="alg1.l6.m3.1.1.3.2.3.2">𝑗</ci><cn id="alg1.l6.m3.1.1.3.2.3.3.cmml" type="integer" xref="alg1.l6.m3.1.1.3.2.3.3">1</cn></apply></apply><ci id="alg1.l6.m3.1.1.3.3.cmml" xref="alg1.l6.m3.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m3.1c">c^{j}_{i}+c^{j+1}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m3.1d">italic_c start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_c start_POSTSUPERSCRIPT italic_j + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l6.5" style="font-size:90%;"> into </span><math alttext="\mathcal{V}" class="ltx_Math" display="inline" id="alg1.l6.m4.1"><semantics id="alg1.l6.m4.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m4.1.1" mathsize="90%" xref="alg1.l6.m4.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m4.1b"><ci id="alg1.l6.m4.1.1.cmml" xref="alg1.l6.m4.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m4.1c">\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m4.1d">caligraphic_V</annotation></semantics></math><span class="ltx_text" id="alg1.l6.6" style="font-size:90%;">; </span><span class="ltx_text" id="alg1.l6.7" style="font-size:90%;float:right;">/* Take next chunk as an exampless */
</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span><span class="ltx_text" id="alg1.l7.2" style="font-size:90%;">        The </span><math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l7.m1.1.1" mathsize="90%" xref="alg1.l7.m1.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">caligraphic_K</annotation></semantics></math><span class="ltx_text" id="alg1.l7.3" style="font-size:90%;"> and </span><math alttext="\mathcal{V}" class="ltx_Math" display="inline" id="alg1.l7.m2.1"><semantics id="alg1.l7.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l7.m2.1.1" mathsize="90%" xref="alg1.l7.m2.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><ci id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m2.1d">caligraphic_V</annotation></semantics></math><span class="ltx_text" id="alg1.l7.4" style="font-size:90%;"> persist in the storage (e.g., SSD) if necessary;
</span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text" id="alg1.l8.2" style="font-size:90%;">     </span><span class="ltx_text ltx_font_bold" id="alg1.l8.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg1.l8.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l8.5" style="font-size:90%;">for</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span><span class="ltx_text" id="alg1.l9.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l9.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg1.l9.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l9.5" style="font-size:90%;">for</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span><span class="ltx_text" id="alg1.l10.2" style="font-size:90%;">  Build the index </span><math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.1.1" mathsize="90%" xref="alg1.l10.m1.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.1d">caligraphic_I</annotation></semantics></math><span class="ltx_text" id="alg1.l10.3" style="font-size:90%;"> with </span><math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="alg1.l10.m2.1"><semantics id="alg1.l10.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m2.1.1" mathsize="90%" xref="alg1.l10.m2.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.1b"><ci id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m2.1d">caligraphic_K</annotation></semantics></math><span class="ltx_text" id="alg1.l10.4" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text" id="alg1.l11.2" style="font-size:90%;">  Store </span><math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="alg1.l11.m1.1"><semantics id="alg1.l11.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.m1.1.1" mathsize="90%" xref="alg1.l11.m1.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.1d">caligraphic_K</annotation></semantics></math><span class="ltx_text" id="alg1.l11.3" style="font-size:90%;"> and </span><math alttext="\mathcal{V}" class="ltx_Math" display="inline" id="alg1.l11.m2.1"><semantics id="alg1.l11.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.m2.1.1" mathsize="90%" xref="alg1.l11.m2.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="alg1.l11.m2.1b"><ci id="alg1.l11.m2.1.1.cmml" xref="alg1.l11.m2.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m2.1c">\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m2.1d">caligraphic_V</annotation></semantics></math><span class="ltx_text" id="alg1.l11.4" style="font-size:90%;"> into the key-value store </span><math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="alg1.l11.m3.1"><semantics id="alg1.l11.m3.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.m3.1.1" mathsize="90%" xref="alg1.l11.m3.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="alg1.l11.m3.1b"><ci id="alg1.l11.m3.1.1.cmml" xref="alg1.l11.m3.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m3.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m3.1d">caligraphic_S</annotation></semantics></math><span class="ltx_text" id="alg1.l11.5" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span><span class="ltx_text" id="alg1.l12.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l12.3" style="font-size:90%;">return</span><span class="ltx_text" id="alg1.l12.4" style="font-size:90%;">  </span><math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="alg1.l12.m1.1"><semantics id="alg1.l12.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l12.m1.1.1" mathsize="90%" xref="alg1.l12.m1.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><ci id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.1d">caligraphic_I</annotation></semantics></math><span class="ltx_text" id="alg1.l12.5" style="font-size:90%;"> and </span><math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="alg1.l12.m2.1"><semantics id="alg1.l12.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l12.m2.1.1" mathsize="90%" xref="alg1.l12.m2.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="alg1.l12.m2.1b"><ci id="alg1.l12.m2.1.1.cmml" xref="alg1.l12.m2.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m2.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m2.1d">caligraphic_S</annotation></semantics></math><span class="ltx_text" id="alg1.l12.6" style="font-size:90%;">;
</span>
</div>
</div>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3. </span>Building the Index</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Indexing in the vector database aims to accelerate the search process for data similar to high-dimensional query embedding.
Unlike common indexing in databases, indexing in the vector database mainly focuses on supporting efficient approximate nearest neighbor (ANN) search <cite class="ltx_cite ltx_citemacro_citep">(Johnson
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib78" title="">2021</a>; Douze et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib33" title="">2024</a>; Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib48" title="">2020</a>)</cite> rather than transaction operations like insertion, deletion, and update.
The key challenge of indexing is making a good trade-off between search quality and search efficiency.
To solve the challenge, there are various specific optimizations in both algorithmic aspects and systematic aspects to be explored, including choices of similarity metrics, dimension reduction (DR) on embeddings, advanced ANN indexing, system-level optimizations, hardware-aware optimization, and so on.
Due to the page limits, this section discusses the optimizations that significantly affect the search quality and efficiency.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<p class="ltx_p" id="S3.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p2.1.1">Choice of Similarity Metrics.</span>
The similarity metrics are the basic components in the retriever, which measures the degree of relevance between query embeddings and chunk embeddings.
The similarity metrics would affect the search quality.
Typical similarity metrics include cosine similarity, Euclidean similarity, Manhattan distance, and Jaccard similarity.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p3">
<p class="ltx_p" id="S3.SS1.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p3.1.1">Dimension Reduction on Embeddings.</span>
Reducing the dimensionality of embeddings can improve search efficiency but at the risk of harming the semantic representations.
The basic but effective dimension reduction (DR) is the principal component analysis (PCA).
The PCA is a simple statistical technique that transforms the original data into a new coordinate system while retaining the most important features.
Another popular and advanced dimension reduction is locality-sensitive hashing (LSH).
LSH significantly reduces the dimensionality by mapping the data into buckets but preserves the similarity of the original input data.
The intuition behind LSH is that the nearest neighbors will be mapped into the same buckets.
Unlike LSH, product quantization (PQ) <cite class="ltx_cite ltx_citemacro_citep">(Jégou
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib69" title="">2011</a>)</cite> is another popular and effective DR technique for ANN search.
The core idea of the PQ is to divide the high-dimensional space into smaller, independently quantized subspaces.
Each subspace creates a codebook of different quantized integers to form the representative and compact vectors.
The above techniques enable efficient storage and fast approximate search but may lose semantic information.
Recent work <cite class="ltx_cite ltx_citemacro_citep">(Chevalier
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib18" title="">2023</a>)</cite> proposed a new technique named AutoCompressor that reduces the dimension of embeddings by compressing the original context into semantically shorter embeddings.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2.3.1.1">Algorithm 2</span> </span> <span class="ltx_text" id="alg2.4.2" style="font-size:90%;">Query the retriever.</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg2.5">
<div class="ltx_listingline" id="alg2.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg2.l0.2" style="font-size:90%;">  A query input </span><math alttext="q" class="ltx_Math" display="inline" id="alg2.l0.m1.1"><semantics id="alg2.l0.m1.1a"><mi id="alg2.l0.m1.1.1" mathsize="90%" xref="alg2.l0.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m1.1b"><ci id="alg2.l0.m1.1.1.cmml" xref="alg2.l0.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m1.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="alg2.l0.3" style="font-size:90%;">, an encoder </span><math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="alg2.l0.m2.1"><semantics id="alg2.l0.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg2.l0.m2.1.1" mathsize="90%" xref="alg2.l0.m2.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m2.1b"><ci id="alg2.l0.m2.1.1.cmml" xref="alg2.l0.m2.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m2.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m2.1d">caligraphic_E</annotation></semantics></math><span class="ltx_text" id="alg2.l0.4" style="font-size:90%;"> for encoding chunks, the index </span><math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="alg2.l0.m3.1"><semantics id="alg2.l0.m3.1a"><mi class="ltx_font_mathcaligraphic" id="alg2.l0.m3.1.1" mathsize="90%" xref="alg2.l0.m3.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m3.1b"><ci id="alg2.l0.m3.1.1.cmml" xref="alg2.l0.m3.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m3.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m3.1d">caligraphic_I</annotation></semantics></math><span class="ltx_text" id="alg2.l0.5" style="font-size:90%;">, the key-value store </span><math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="alg2.l0.m4.1"><semantics id="alg2.l0.m4.1a"><mi class="ltx_font_mathcaligraphic" id="alg2.l0.m4.1.1" mathsize="90%" xref="alg2.l0.m4.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m4.1b"><ci id="alg2.l0.m4.1.1.cmml" xref="alg2.l0.m4.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m4.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m4.1d">caligraphic_S</annotation></semantics></math><span class="ltx_text" id="alg2.l0.6" style="font-size:90%;">, the parameter </span><math alttext="k" class="ltx_Math" display="inline" id="alg2.l0.m5.1"><semantics id="alg2.l0.m5.1a"><mi id="alg2.l0.m5.1.1" mathsize="90%" xref="alg2.l0.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m5.1b"><ci id="alg2.l0.m5.1.1.cmml" xref="alg2.l0.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m5.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="alg2.l0.7" style="font-size:90%;">.</span>
</div>
<div class="ltx_listingline" id="alg2.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0a.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg2.l0a.2" style="font-size:90%;">  Top-</span><math alttext="k" class="ltx_Math" display="inline" id="alg2.l0a.m1.1"><semantics id="alg2.l0a.m1.1a"><mi id="alg2.l0a.m1.1.1" mathsize="90%" xref="alg2.l0a.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l0a.m1.1b"><ci id="alg2.l0a.m1.1.1.cmml" xref="alg2.l0a.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l0a.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="alg2.l0a.3" style="font-size:90%;"> nearest neighbor knowledge.
</span>
</div>
<div class="ltx_listingline" id="alg2.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text" id="alg2.l1.2" style="font-size:90%;">  </span><math alttext="e=\mathcal{E}(q)" class="ltx_Math" display="inline" id="alg2.l1.m1.1"><semantics id="alg2.l1.m1.1a"><mrow id="alg2.l1.m1.1.2" xref="alg2.l1.m1.1.2.cmml"><mi id="alg2.l1.m1.1.2.2" mathsize="90%" xref="alg2.l1.m1.1.2.2.cmml">e</mi><mo id="alg2.l1.m1.1.2.1" mathsize="90%" xref="alg2.l1.m1.1.2.1.cmml">=</mo><mrow id="alg2.l1.m1.1.2.3" xref="alg2.l1.m1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg2.l1.m1.1.2.3.2" mathsize="90%" xref="alg2.l1.m1.1.2.3.2.cmml">ℰ</mi><mo id="alg2.l1.m1.1.2.3.1" xref="alg2.l1.m1.1.2.3.1.cmml">⁢</mo><mrow id="alg2.l1.m1.1.2.3.3.2" xref="alg2.l1.m1.1.2.3.cmml"><mo id="alg2.l1.m1.1.2.3.3.2.1" maxsize="90%" minsize="90%" xref="alg2.l1.m1.1.2.3.cmml">(</mo><mi id="alg2.l1.m1.1.1" mathsize="90%" xref="alg2.l1.m1.1.1.cmml">q</mi><mo id="alg2.l1.m1.1.2.3.3.2.2" maxsize="90%" minsize="90%" xref="alg2.l1.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l1.m1.1b"><apply id="alg2.l1.m1.1.2.cmml" xref="alg2.l1.m1.1.2"><eq id="alg2.l1.m1.1.2.1.cmml" xref="alg2.l1.m1.1.2.1"></eq><ci id="alg2.l1.m1.1.2.2.cmml" xref="alg2.l1.m1.1.2.2">𝑒</ci><apply id="alg2.l1.m1.1.2.3.cmml" xref="alg2.l1.m1.1.2.3"><times id="alg2.l1.m1.1.2.3.1.cmml" xref="alg2.l1.m1.1.2.3.1"></times><ci id="alg2.l1.m1.1.2.3.2.cmml" xref="alg2.l1.m1.1.2.3.2">ℰ</ci><ci id="alg2.l1.m1.1.1.cmml" xref="alg2.l1.m1.1.1">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l1.m1.1c">e=\mathcal{E}(q)</annotation><annotation encoding="application/x-llamapun" id="alg2.l1.m1.1d">italic_e = caligraphic_E ( italic_q )</annotation></semantics></math><span class="ltx_text" id="alg2.l1.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg2.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l2.2.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text" id="alg2.l2.3" style="font-size:90%;">  </span><math alttext="\{idx_{1},\ldots,idx_{k}\}=\mathcal{I}.Search(e,k)" class="ltx_Math" display="inline" id="alg2.l2.m1.5"><semantics id="alg2.l2.m1.5a"><mrow id="alg2.l2.m1.5.5.2" xref="alg2.l2.m1.5.5.3.cmml"><mrow id="alg2.l2.m1.4.4.1.1" xref="alg2.l2.m1.4.4.1.1.cmml"><mrow id="alg2.l2.m1.4.4.1.1.2.2" xref="alg2.l2.m1.4.4.1.1.2.3.cmml"><mo id="alg2.l2.m1.4.4.1.1.2.2.3" maxsize="90%" minsize="90%" xref="alg2.l2.m1.4.4.1.1.2.3.cmml">{</mo><mrow id="alg2.l2.m1.4.4.1.1.1.1.1" xref="alg2.l2.m1.4.4.1.1.1.1.1.cmml"><mi id="alg2.l2.m1.4.4.1.1.1.1.1.2" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.1.1.1.2.cmml">i</mi><mo id="alg2.l2.m1.4.4.1.1.1.1.1.1" xref="alg2.l2.m1.4.4.1.1.1.1.1.1.cmml">⁢</mo><mi id="alg2.l2.m1.4.4.1.1.1.1.1.3" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.1.1.1.3.cmml">d</mi><mo id="alg2.l2.m1.4.4.1.1.1.1.1.1a" xref="alg2.l2.m1.4.4.1.1.1.1.1.1.cmml">⁢</mo><msub id="alg2.l2.m1.4.4.1.1.1.1.1.4" xref="alg2.l2.m1.4.4.1.1.1.1.1.4.cmml"><mi id="alg2.l2.m1.4.4.1.1.1.1.1.4.2" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.1.1.1.4.2.cmml">x</mi><mn id="alg2.l2.m1.4.4.1.1.1.1.1.4.3" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.1.1.1.4.3.cmml">1</mn></msub></mrow><mo id="alg2.l2.m1.4.4.1.1.2.2.4" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.2.3.cmml">,</mo><mi id="alg2.l2.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg2.l2.m1.1.1.cmml">…</mi><mo id="alg2.l2.m1.4.4.1.1.2.2.5" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.2.3.cmml">,</mo><mrow id="alg2.l2.m1.4.4.1.1.2.2.2" xref="alg2.l2.m1.4.4.1.1.2.2.2.cmml"><mi id="alg2.l2.m1.4.4.1.1.2.2.2.2" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.2.2.2.2.cmml">i</mi><mo id="alg2.l2.m1.4.4.1.1.2.2.2.1" xref="alg2.l2.m1.4.4.1.1.2.2.2.1.cmml">⁢</mo><mi id="alg2.l2.m1.4.4.1.1.2.2.2.3" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.2.2.2.3.cmml">d</mi><mo id="alg2.l2.m1.4.4.1.1.2.2.2.1a" xref="alg2.l2.m1.4.4.1.1.2.2.2.1.cmml">⁢</mo><msub id="alg2.l2.m1.4.4.1.1.2.2.2.4" xref="alg2.l2.m1.4.4.1.1.2.2.2.4.cmml"><mi id="alg2.l2.m1.4.4.1.1.2.2.2.4.2" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.2.2.2.4.2.cmml">x</mi><mi id="alg2.l2.m1.4.4.1.1.2.2.2.4.3" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.2.2.2.4.3.cmml">k</mi></msub></mrow><mo id="alg2.l2.m1.4.4.1.1.2.2.6" maxsize="90%" minsize="90%" xref="alg2.l2.m1.4.4.1.1.2.3.cmml">}</mo></mrow><mo id="alg2.l2.m1.4.4.1.1.3" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.3.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="alg2.l2.m1.4.4.1.1.4" mathsize="90%" xref="alg2.l2.m1.4.4.1.1.4.cmml">ℐ</mi></mrow><mo id="alg2.l2.m1.5.5.2.3" lspace="0em" mathsize="90%" rspace="0.167em" xref="alg2.l2.m1.5.5.3a.cmml">.</mo><mrow id="alg2.l2.m1.5.5.2.2" xref="alg2.l2.m1.5.5.2.2.cmml"><mi id="alg2.l2.m1.5.5.2.2.2" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.2.cmml">S</mi><mo id="alg2.l2.m1.5.5.2.2.1" xref="alg2.l2.m1.5.5.2.2.1.cmml">⁢</mo><mi id="alg2.l2.m1.5.5.2.2.3" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.3.cmml">e</mi><mo id="alg2.l2.m1.5.5.2.2.1a" xref="alg2.l2.m1.5.5.2.2.1.cmml">⁢</mo><mi id="alg2.l2.m1.5.5.2.2.4" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.4.cmml">a</mi><mo id="alg2.l2.m1.5.5.2.2.1b" xref="alg2.l2.m1.5.5.2.2.1.cmml">⁢</mo><mi id="alg2.l2.m1.5.5.2.2.5" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.5.cmml">r</mi><mo id="alg2.l2.m1.5.5.2.2.1c" xref="alg2.l2.m1.5.5.2.2.1.cmml">⁢</mo><mi id="alg2.l2.m1.5.5.2.2.6" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.6.cmml">c</mi><mo id="alg2.l2.m1.5.5.2.2.1d" xref="alg2.l2.m1.5.5.2.2.1.cmml">⁢</mo><mi id="alg2.l2.m1.5.5.2.2.7" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.7.cmml">h</mi><mo id="alg2.l2.m1.5.5.2.2.1e" xref="alg2.l2.m1.5.5.2.2.1.cmml">⁢</mo><mrow id="alg2.l2.m1.5.5.2.2.8.2" xref="alg2.l2.m1.5.5.2.2.8.1.cmml"><mo id="alg2.l2.m1.5.5.2.2.8.2.1" maxsize="90%" minsize="90%" xref="alg2.l2.m1.5.5.2.2.8.1.cmml">(</mo><mi id="alg2.l2.m1.2.2" mathsize="90%" xref="alg2.l2.m1.2.2.cmml">e</mi><mo id="alg2.l2.m1.5.5.2.2.8.2.2" mathsize="90%" xref="alg2.l2.m1.5.5.2.2.8.1.cmml">,</mo><mi id="alg2.l2.m1.3.3" mathsize="90%" xref="alg2.l2.m1.3.3.cmml">k</mi><mo id="alg2.l2.m1.5.5.2.2.8.2.3" maxsize="90%" minsize="90%" xref="alg2.l2.m1.5.5.2.2.8.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l2.m1.5b"><apply id="alg2.l2.m1.5.5.3.cmml" xref="alg2.l2.m1.5.5.2"><csymbol cd="ambiguous" id="alg2.l2.m1.5.5.3a.cmml" xref="alg2.l2.m1.5.5.2.3">formulae-sequence</csymbol><apply id="alg2.l2.m1.4.4.1.1.cmml" xref="alg2.l2.m1.4.4.1.1"><eq id="alg2.l2.m1.4.4.1.1.3.cmml" xref="alg2.l2.m1.4.4.1.1.3"></eq><set id="alg2.l2.m1.4.4.1.1.2.3.cmml" xref="alg2.l2.m1.4.4.1.1.2.2"><apply id="alg2.l2.m1.4.4.1.1.1.1.1.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1"><times id="alg2.l2.m1.4.4.1.1.1.1.1.1.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1.1"></times><ci id="alg2.l2.m1.4.4.1.1.1.1.1.2.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1.2">𝑖</ci><ci id="alg2.l2.m1.4.4.1.1.1.1.1.3.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1.3">𝑑</ci><apply id="alg2.l2.m1.4.4.1.1.1.1.1.4.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1.4"><csymbol cd="ambiguous" id="alg2.l2.m1.4.4.1.1.1.1.1.4.1.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1.4">subscript</csymbol><ci id="alg2.l2.m1.4.4.1.1.1.1.1.4.2.cmml" xref="alg2.l2.m1.4.4.1.1.1.1.1.4.2">𝑥</ci><cn id="alg2.l2.m1.4.4.1.1.1.1.1.4.3.cmml" type="integer" xref="alg2.l2.m1.4.4.1.1.1.1.1.4.3">1</cn></apply></apply><ci id="alg2.l2.m1.1.1.cmml" xref="alg2.l2.m1.1.1">…</ci><apply id="alg2.l2.m1.4.4.1.1.2.2.2.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2"><times id="alg2.l2.m1.4.4.1.1.2.2.2.1.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.1"></times><ci id="alg2.l2.m1.4.4.1.1.2.2.2.2.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.2">𝑖</ci><ci id="alg2.l2.m1.4.4.1.1.2.2.2.3.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.3">𝑑</ci><apply id="alg2.l2.m1.4.4.1.1.2.2.2.4.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.4"><csymbol cd="ambiguous" id="alg2.l2.m1.4.4.1.1.2.2.2.4.1.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.4">subscript</csymbol><ci id="alg2.l2.m1.4.4.1.1.2.2.2.4.2.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.4.2">𝑥</ci><ci id="alg2.l2.m1.4.4.1.1.2.2.2.4.3.cmml" xref="alg2.l2.m1.4.4.1.1.2.2.2.4.3">𝑘</ci></apply></apply></set><ci id="alg2.l2.m1.4.4.1.1.4.cmml" xref="alg2.l2.m1.4.4.1.1.4">ℐ</ci></apply><apply id="alg2.l2.m1.5.5.2.2.cmml" xref="alg2.l2.m1.5.5.2.2"><times id="alg2.l2.m1.5.5.2.2.1.cmml" xref="alg2.l2.m1.5.5.2.2.1"></times><ci id="alg2.l2.m1.5.5.2.2.2.cmml" xref="alg2.l2.m1.5.5.2.2.2">𝑆</ci><ci id="alg2.l2.m1.5.5.2.2.3.cmml" xref="alg2.l2.m1.5.5.2.2.3">𝑒</ci><ci id="alg2.l2.m1.5.5.2.2.4.cmml" xref="alg2.l2.m1.5.5.2.2.4">𝑎</ci><ci id="alg2.l2.m1.5.5.2.2.5.cmml" xref="alg2.l2.m1.5.5.2.2.5">𝑟</ci><ci id="alg2.l2.m1.5.5.2.2.6.cmml" xref="alg2.l2.m1.5.5.2.2.6">𝑐</ci><ci id="alg2.l2.m1.5.5.2.2.7.cmml" xref="alg2.l2.m1.5.5.2.2.7">ℎ</ci><interval closure="open" id="alg2.l2.m1.5.5.2.2.8.1.cmml" xref="alg2.l2.m1.5.5.2.2.8.2"><ci id="alg2.l2.m1.2.2.cmml" xref="alg2.l2.m1.2.2">𝑒</ci><ci id="alg2.l2.m1.3.3.cmml" xref="alg2.l2.m1.3.3">𝑘</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2.m1.5c">\{idx_{1},\ldots,idx_{k}\}=\mathcal{I}.Search(e,k)</annotation><annotation encoding="application/x-llamapun" id="alg2.l2.m1.5d">{ italic_i italic_d italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_i italic_d italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } = caligraphic_I . italic_S italic_e italic_a italic_r italic_c italic_h ( italic_e , italic_k )</annotation></semantics></math><span class="ltx_text" id="alg2.l2.4" style="font-size:90%;">; </span><span class="ltx_text" id="alg2.l2.1" style="font-size:90%;float:right;">/* Search the top-<math alttext="k" class="ltx_Math" display="inline" id="alg2.l2.1.m1.1"><semantics id="alg2.l2.1.m1.1a"><mi id="alg2.l2.1.m1.1.1" xref="alg2.l2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l2.1.m1.1b"><ci id="alg2.l2.1.m1.1.1.cmml" xref="alg2.l2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l2.1.m1.1d">italic_k</annotation></semantics></math> nearest neighbors */
</span>
</div>
<div class="ltx_listingline" id="alg2.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l3.1.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text" id="alg2.l3.2" style="font-size:90%;">  </span><math alttext="\{v_{1},\ldots,v_{k}\}=\mathcal{S}.Fetch(\{idx_{1},\ldots,idx_{k}\})" class="ltx_Math" display="inline" id="alg2.l3.m1.4"><semantics id="alg2.l3.m1.4a"><mrow id="alg2.l3.m1.4.4.2" xref="alg2.l3.m1.4.4.3.cmml"><mrow id="alg2.l3.m1.3.3.1.1" xref="alg2.l3.m1.3.3.1.1.cmml"><mrow id="alg2.l3.m1.3.3.1.1.2.2" xref="alg2.l3.m1.3.3.1.1.2.3.cmml"><mo id="alg2.l3.m1.3.3.1.1.2.2.3" maxsize="90%" minsize="90%" xref="alg2.l3.m1.3.3.1.1.2.3.cmml">{</mo><msub id="alg2.l3.m1.3.3.1.1.1.1.1" xref="alg2.l3.m1.3.3.1.1.1.1.1.cmml"><mi id="alg2.l3.m1.3.3.1.1.1.1.1.2" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.1.1.1.2.cmml">v</mi><mn id="alg2.l3.m1.3.3.1.1.1.1.1.3" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.1.1.1.3.cmml">1</mn></msub><mo id="alg2.l3.m1.3.3.1.1.2.2.4" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.2.3.cmml">,</mo><mi id="alg2.l3.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg2.l3.m1.1.1.cmml">…</mi><mo id="alg2.l3.m1.3.3.1.1.2.2.5" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.2.3.cmml">,</mo><msub id="alg2.l3.m1.3.3.1.1.2.2.2" xref="alg2.l3.m1.3.3.1.1.2.2.2.cmml"><mi id="alg2.l3.m1.3.3.1.1.2.2.2.2" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.2.2.2.2.cmml">v</mi><mi id="alg2.l3.m1.3.3.1.1.2.2.2.3" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.2.2.2.3.cmml">k</mi></msub><mo id="alg2.l3.m1.3.3.1.1.2.2.6" maxsize="90%" minsize="90%" xref="alg2.l3.m1.3.3.1.1.2.3.cmml">}</mo></mrow><mo id="alg2.l3.m1.3.3.1.1.3" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.3.cmml">=</mo><mi class="ltx_font_mathcaligraphic" id="alg2.l3.m1.3.3.1.1.4" mathsize="90%" xref="alg2.l3.m1.3.3.1.1.4.cmml">𝒮</mi></mrow><mo id="alg2.l3.m1.4.4.2.3" lspace="0em" mathsize="90%" rspace="0.167em" xref="alg2.l3.m1.4.4.3a.cmml">.</mo><mrow id="alg2.l3.m1.4.4.2.2" xref="alg2.l3.m1.4.4.2.2.cmml"><mi id="alg2.l3.m1.4.4.2.2.3" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.3.cmml">F</mi><mo id="alg2.l3.m1.4.4.2.2.2" xref="alg2.l3.m1.4.4.2.2.2.cmml">⁢</mo><mi id="alg2.l3.m1.4.4.2.2.4" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.4.cmml">e</mi><mo id="alg2.l3.m1.4.4.2.2.2a" xref="alg2.l3.m1.4.4.2.2.2.cmml">⁢</mo><mi id="alg2.l3.m1.4.4.2.2.5" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.5.cmml">t</mi><mo id="alg2.l3.m1.4.4.2.2.2b" xref="alg2.l3.m1.4.4.2.2.2.cmml">⁢</mo><mi id="alg2.l3.m1.4.4.2.2.6" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.6.cmml">c</mi><mo id="alg2.l3.m1.4.4.2.2.2c" xref="alg2.l3.m1.4.4.2.2.2.cmml">⁢</mo><mi id="alg2.l3.m1.4.4.2.2.7" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.7.cmml">h</mi><mo id="alg2.l3.m1.4.4.2.2.2d" xref="alg2.l3.m1.4.4.2.2.2.cmml">⁢</mo><mrow id="alg2.l3.m1.4.4.2.2.1.1" xref="alg2.l3.m1.4.4.2.2.cmml"><mo id="alg2.l3.m1.4.4.2.2.1.1.2" maxsize="90%" minsize="90%" xref="alg2.l3.m1.4.4.2.2.cmml">(</mo><mrow id="alg2.l3.m1.4.4.2.2.1.1.1.2" xref="alg2.l3.m1.4.4.2.2.1.1.1.3.cmml"><mo id="alg2.l3.m1.4.4.2.2.1.1.1.2.3" maxsize="90%" minsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.3.cmml">{</mo><mrow id="alg2.l3.m1.4.4.2.2.1.1.1.1.1" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.cmml"><mi id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.2" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.2.cmml">i</mi><mo id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.1" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.1.cmml">⁢</mo><mi id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.3" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.3.cmml">d</mi><mo id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.1a" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.1.cmml">⁢</mo><msub id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.cmml"><mi id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.2" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.2.cmml">x</mi><mn id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.3" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.3.cmml">1</mn></msub></mrow><mo id="alg2.l3.m1.4.4.2.2.1.1.1.2.4" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.3.cmml">,</mo><mi id="alg2.l3.m1.2.2" mathsize="90%" mathvariant="normal" xref="alg2.l3.m1.2.2.cmml">…</mi><mo id="alg2.l3.m1.4.4.2.2.1.1.1.2.5" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.3.cmml">,</mo><mrow id="alg2.l3.m1.4.4.2.2.1.1.1.2.2" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.cmml"><mi id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.2" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.2.cmml">i</mi><mo id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.1" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.1.cmml">⁢</mo><mi id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.3" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.3.cmml">d</mi><mo id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.1a" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.1.cmml">⁢</mo><msub id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.cmml"><mi id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.2" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.2.cmml">x</mi><mi id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.3" mathsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.3.cmml">k</mi></msub></mrow><mo id="alg2.l3.m1.4.4.2.2.1.1.1.2.6" maxsize="90%" minsize="90%" xref="alg2.l3.m1.4.4.2.2.1.1.1.3.cmml">}</mo></mrow><mo id="alg2.l3.m1.4.4.2.2.1.1.3" maxsize="90%" minsize="90%" xref="alg2.l3.m1.4.4.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l3.m1.4b"><apply id="alg2.l3.m1.4.4.3.cmml" xref="alg2.l3.m1.4.4.2"><csymbol cd="ambiguous" id="alg2.l3.m1.4.4.3a.cmml" xref="alg2.l3.m1.4.4.2.3">formulae-sequence</csymbol><apply id="alg2.l3.m1.3.3.1.1.cmml" xref="alg2.l3.m1.3.3.1.1"><eq id="alg2.l3.m1.3.3.1.1.3.cmml" xref="alg2.l3.m1.3.3.1.1.3"></eq><set id="alg2.l3.m1.3.3.1.1.2.3.cmml" xref="alg2.l3.m1.3.3.1.1.2.2"><apply id="alg2.l3.m1.3.3.1.1.1.1.1.cmml" xref="alg2.l3.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l3.m1.3.3.1.1.1.1.1.1.cmml" xref="alg2.l3.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="alg2.l3.m1.3.3.1.1.1.1.1.2.cmml" xref="alg2.l3.m1.3.3.1.1.1.1.1.2">𝑣</ci><cn id="alg2.l3.m1.3.3.1.1.1.1.1.3.cmml" type="integer" xref="alg2.l3.m1.3.3.1.1.1.1.1.3">1</cn></apply><ci id="alg2.l3.m1.1.1.cmml" xref="alg2.l3.m1.1.1">…</ci><apply id="alg2.l3.m1.3.3.1.1.2.2.2.cmml" xref="alg2.l3.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="alg2.l3.m1.3.3.1.1.2.2.2.1.cmml" xref="alg2.l3.m1.3.3.1.1.2.2.2">subscript</csymbol><ci id="alg2.l3.m1.3.3.1.1.2.2.2.2.cmml" xref="alg2.l3.m1.3.3.1.1.2.2.2.2">𝑣</ci><ci id="alg2.l3.m1.3.3.1.1.2.2.2.3.cmml" xref="alg2.l3.m1.3.3.1.1.2.2.2.3">𝑘</ci></apply></set><ci id="alg2.l3.m1.3.3.1.1.4.cmml" xref="alg2.l3.m1.3.3.1.1.4">𝒮</ci></apply><apply id="alg2.l3.m1.4.4.2.2.cmml" xref="alg2.l3.m1.4.4.2.2"><times id="alg2.l3.m1.4.4.2.2.2.cmml" xref="alg2.l3.m1.4.4.2.2.2"></times><ci id="alg2.l3.m1.4.4.2.2.3.cmml" xref="alg2.l3.m1.4.4.2.2.3">𝐹</ci><ci id="alg2.l3.m1.4.4.2.2.4.cmml" xref="alg2.l3.m1.4.4.2.2.4">𝑒</ci><ci id="alg2.l3.m1.4.4.2.2.5.cmml" xref="alg2.l3.m1.4.4.2.2.5">𝑡</ci><ci id="alg2.l3.m1.4.4.2.2.6.cmml" xref="alg2.l3.m1.4.4.2.2.6">𝑐</ci><ci id="alg2.l3.m1.4.4.2.2.7.cmml" xref="alg2.l3.m1.4.4.2.2.7">ℎ</ci><set id="alg2.l3.m1.4.4.2.2.1.1.1.3.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2"><apply id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1"><times id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.1.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.1"></times><ci id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.2.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.2">𝑖</ci><ci id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.3.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.3">𝑑</ci><apply id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.1.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4">subscript</csymbol><ci id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.2.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.2">𝑥</ci><cn id="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.3.cmml" type="integer" xref="alg2.l3.m1.4.4.2.2.1.1.1.1.1.4.3">1</cn></apply></apply><ci id="alg2.l3.m1.2.2.cmml" xref="alg2.l3.m1.2.2">…</ci><apply id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2"><times id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.1.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.1"></times><ci id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.2.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.2">𝑖</ci><ci id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.3.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.3">𝑑</ci><apply id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4"><csymbol cd="ambiguous" id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.1.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4">subscript</csymbol><ci id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.2.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.2">𝑥</ci><ci id="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.3.cmml" xref="alg2.l3.m1.4.4.2.2.1.1.1.2.2.4.3">𝑘</ci></apply></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3.m1.4c">\{v_{1},\ldots,v_{k}\}=\mathcal{S}.Fetch(\{idx_{1},\ldots,idx_{k}\})</annotation><annotation encoding="application/x-llamapun" id="alg2.l3.m1.4d">{ italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } = caligraphic_S . italic_F italic_e italic_t italic_c italic_h ( { italic_i italic_d italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_i italic_d italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } )</annotation></semantics></math><span class="ltx_text" id="alg2.l3.3" style="font-size:90%;">; </span><span class="ltx_text" id="alg2.l3.4" style="font-size:90%;float:right;">/* Fetch the values of the neighbors */
</span>
</div>
<div class="ltx_listingline" id="alg2.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l4.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text" id="alg2.l4.2" style="font-size:90%;">  </span><math alttext="\{v_{j_{1}},\ldots,v_{j_{k}}\}=PostProcess(\{v_{1},\ldots,v_{k}\})" class="ltx_Math" display="inline" id="alg2.l4.m1.5"><semantics id="alg2.l4.m1.5a"><mrow id="alg2.l4.m1.5.5" xref="alg2.l4.m1.5.5.cmml"><mrow id="alg2.l4.m1.4.4.2.2" xref="alg2.l4.m1.4.4.2.3.cmml"><mo id="alg2.l4.m1.4.4.2.2.3" maxsize="90%" minsize="90%" xref="alg2.l4.m1.4.4.2.3.cmml">{</mo><msub id="alg2.l4.m1.3.3.1.1.1" xref="alg2.l4.m1.3.3.1.1.1.cmml"><mi id="alg2.l4.m1.3.3.1.1.1.2" mathsize="90%" xref="alg2.l4.m1.3.3.1.1.1.2.cmml">v</mi><msub id="alg2.l4.m1.3.3.1.1.1.3" xref="alg2.l4.m1.3.3.1.1.1.3.cmml"><mi id="alg2.l4.m1.3.3.1.1.1.3.2" mathsize="90%" xref="alg2.l4.m1.3.3.1.1.1.3.2.cmml">j</mi><mn id="alg2.l4.m1.3.3.1.1.1.3.3" mathsize="90%" xref="alg2.l4.m1.3.3.1.1.1.3.3.cmml">1</mn></msub></msub><mo id="alg2.l4.m1.4.4.2.2.4" mathsize="90%" xref="alg2.l4.m1.4.4.2.3.cmml">,</mo><mi id="alg2.l4.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg2.l4.m1.1.1.cmml">…</mi><mo id="alg2.l4.m1.4.4.2.2.5" mathsize="90%" xref="alg2.l4.m1.4.4.2.3.cmml">,</mo><msub id="alg2.l4.m1.4.4.2.2.2" xref="alg2.l4.m1.4.4.2.2.2.cmml"><mi id="alg2.l4.m1.4.4.2.2.2.2" mathsize="90%" xref="alg2.l4.m1.4.4.2.2.2.2.cmml">v</mi><msub id="alg2.l4.m1.4.4.2.2.2.3" xref="alg2.l4.m1.4.4.2.2.2.3.cmml"><mi id="alg2.l4.m1.4.4.2.2.2.3.2" mathsize="90%" xref="alg2.l4.m1.4.4.2.2.2.3.2.cmml">j</mi><mi id="alg2.l4.m1.4.4.2.2.2.3.3" mathsize="90%" xref="alg2.l4.m1.4.4.2.2.2.3.3.cmml">k</mi></msub></msub><mo id="alg2.l4.m1.4.4.2.2.6" maxsize="90%" minsize="90%" xref="alg2.l4.m1.4.4.2.3.cmml">}</mo></mrow><mo id="alg2.l4.m1.5.5.4" mathsize="90%" xref="alg2.l4.m1.5.5.4.cmml">=</mo><mrow id="alg2.l4.m1.5.5.3" xref="alg2.l4.m1.5.5.3.cmml"><mi id="alg2.l4.m1.5.5.3.3" mathsize="90%" xref="alg2.l4.m1.5.5.3.3.cmml">P</mi><mo id="alg2.l4.m1.5.5.3.2" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.4" mathsize="90%" xref="alg2.l4.m1.5.5.3.4.cmml">o</mi><mo id="alg2.l4.m1.5.5.3.2a" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.5" mathsize="90%" xref="alg2.l4.m1.5.5.3.5.cmml">s</mi><mo id="alg2.l4.m1.5.5.3.2b" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.6" mathsize="90%" xref="alg2.l4.m1.5.5.3.6.cmml">t</mi><mo id="alg2.l4.m1.5.5.3.2c" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.7" mathsize="90%" xref="alg2.l4.m1.5.5.3.7.cmml">P</mi><mo id="alg2.l4.m1.5.5.3.2d" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.8" mathsize="90%" xref="alg2.l4.m1.5.5.3.8.cmml">r</mi><mo id="alg2.l4.m1.5.5.3.2e" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.9" mathsize="90%" xref="alg2.l4.m1.5.5.3.9.cmml">o</mi><mo id="alg2.l4.m1.5.5.3.2f" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.10" mathsize="90%" xref="alg2.l4.m1.5.5.3.10.cmml">c</mi><mo id="alg2.l4.m1.5.5.3.2g" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.11" mathsize="90%" xref="alg2.l4.m1.5.5.3.11.cmml">e</mi><mo id="alg2.l4.m1.5.5.3.2h" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.12" mathsize="90%" xref="alg2.l4.m1.5.5.3.12.cmml">s</mi><mo id="alg2.l4.m1.5.5.3.2i" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mi id="alg2.l4.m1.5.5.3.13" mathsize="90%" xref="alg2.l4.m1.5.5.3.13.cmml">s</mi><mo id="alg2.l4.m1.5.5.3.2j" xref="alg2.l4.m1.5.5.3.2.cmml">⁢</mo><mrow id="alg2.l4.m1.5.5.3.1.1" xref="alg2.l4.m1.5.5.3.cmml"><mo id="alg2.l4.m1.5.5.3.1.1.2" maxsize="90%" minsize="90%" xref="alg2.l4.m1.5.5.3.cmml">(</mo><mrow id="alg2.l4.m1.5.5.3.1.1.1.2" xref="alg2.l4.m1.5.5.3.1.1.1.3.cmml"><mo id="alg2.l4.m1.5.5.3.1.1.1.2.3" maxsize="90%" minsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.3.cmml">{</mo><msub id="alg2.l4.m1.5.5.3.1.1.1.1.1" xref="alg2.l4.m1.5.5.3.1.1.1.1.1.cmml"><mi id="alg2.l4.m1.5.5.3.1.1.1.1.1.2" mathsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.1.1.2.cmml">v</mi><mn id="alg2.l4.m1.5.5.3.1.1.1.1.1.3" mathsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.1.1.3.cmml">1</mn></msub><mo id="alg2.l4.m1.5.5.3.1.1.1.2.4" mathsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.3.cmml">,</mo><mi id="alg2.l4.m1.2.2" mathsize="90%" mathvariant="normal" xref="alg2.l4.m1.2.2.cmml">…</mi><mo id="alg2.l4.m1.5.5.3.1.1.1.2.5" mathsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.3.cmml">,</mo><msub id="alg2.l4.m1.5.5.3.1.1.1.2.2" xref="alg2.l4.m1.5.5.3.1.1.1.2.2.cmml"><mi id="alg2.l4.m1.5.5.3.1.1.1.2.2.2" mathsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.2.2.2.cmml">v</mi><mi id="alg2.l4.m1.5.5.3.1.1.1.2.2.3" mathsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.2.2.3.cmml">k</mi></msub><mo id="alg2.l4.m1.5.5.3.1.1.1.2.6" maxsize="90%" minsize="90%" xref="alg2.l4.m1.5.5.3.1.1.1.3.cmml">}</mo></mrow><mo id="alg2.l4.m1.5.5.3.1.1.3" maxsize="90%" minsize="90%" xref="alg2.l4.m1.5.5.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l4.m1.5b"><apply id="alg2.l4.m1.5.5.cmml" xref="alg2.l4.m1.5.5"><eq id="alg2.l4.m1.5.5.4.cmml" xref="alg2.l4.m1.5.5.4"></eq><set id="alg2.l4.m1.4.4.2.3.cmml" xref="alg2.l4.m1.4.4.2.2"><apply id="alg2.l4.m1.3.3.1.1.1.cmml" xref="alg2.l4.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="alg2.l4.m1.3.3.1.1.1.1.cmml" xref="alg2.l4.m1.3.3.1.1.1">subscript</csymbol><ci id="alg2.l4.m1.3.3.1.1.1.2.cmml" xref="alg2.l4.m1.3.3.1.1.1.2">𝑣</ci><apply id="alg2.l4.m1.3.3.1.1.1.3.cmml" xref="alg2.l4.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="alg2.l4.m1.3.3.1.1.1.3.1.cmml" xref="alg2.l4.m1.3.3.1.1.1.3">subscript</csymbol><ci id="alg2.l4.m1.3.3.1.1.1.3.2.cmml" xref="alg2.l4.m1.3.3.1.1.1.3.2">𝑗</ci><cn id="alg2.l4.m1.3.3.1.1.1.3.3.cmml" type="integer" xref="alg2.l4.m1.3.3.1.1.1.3.3">1</cn></apply></apply><ci id="alg2.l4.m1.1.1.cmml" xref="alg2.l4.m1.1.1">…</ci><apply id="alg2.l4.m1.4.4.2.2.2.cmml" xref="alg2.l4.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="alg2.l4.m1.4.4.2.2.2.1.cmml" xref="alg2.l4.m1.4.4.2.2.2">subscript</csymbol><ci id="alg2.l4.m1.4.4.2.2.2.2.cmml" xref="alg2.l4.m1.4.4.2.2.2.2">𝑣</ci><apply id="alg2.l4.m1.4.4.2.2.2.3.cmml" xref="alg2.l4.m1.4.4.2.2.2.3"><csymbol cd="ambiguous" id="alg2.l4.m1.4.4.2.2.2.3.1.cmml" xref="alg2.l4.m1.4.4.2.2.2.3">subscript</csymbol><ci id="alg2.l4.m1.4.4.2.2.2.3.2.cmml" xref="alg2.l4.m1.4.4.2.2.2.3.2">𝑗</ci><ci id="alg2.l4.m1.4.4.2.2.2.3.3.cmml" xref="alg2.l4.m1.4.4.2.2.2.3.3">𝑘</ci></apply></apply></set><apply id="alg2.l4.m1.5.5.3.cmml" xref="alg2.l4.m1.5.5.3"><times id="alg2.l4.m1.5.5.3.2.cmml" xref="alg2.l4.m1.5.5.3.2"></times><ci id="alg2.l4.m1.5.5.3.3.cmml" xref="alg2.l4.m1.5.5.3.3">𝑃</ci><ci id="alg2.l4.m1.5.5.3.4.cmml" xref="alg2.l4.m1.5.5.3.4">𝑜</ci><ci id="alg2.l4.m1.5.5.3.5.cmml" xref="alg2.l4.m1.5.5.3.5">𝑠</ci><ci id="alg2.l4.m1.5.5.3.6.cmml" xref="alg2.l4.m1.5.5.3.6">𝑡</ci><ci id="alg2.l4.m1.5.5.3.7.cmml" xref="alg2.l4.m1.5.5.3.7">𝑃</ci><ci id="alg2.l4.m1.5.5.3.8.cmml" xref="alg2.l4.m1.5.5.3.8">𝑟</ci><ci id="alg2.l4.m1.5.5.3.9.cmml" xref="alg2.l4.m1.5.5.3.9">𝑜</ci><ci id="alg2.l4.m1.5.5.3.10.cmml" xref="alg2.l4.m1.5.5.3.10">𝑐</ci><ci id="alg2.l4.m1.5.5.3.11.cmml" xref="alg2.l4.m1.5.5.3.11">𝑒</ci><ci id="alg2.l4.m1.5.5.3.12.cmml" xref="alg2.l4.m1.5.5.3.12">𝑠</ci><ci id="alg2.l4.m1.5.5.3.13.cmml" xref="alg2.l4.m1.5.5.3.13">𝑠</ci><set id="alg2.l4.m1.5.5.3.1.1.1.3.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.2"><apply id="alg2.l4.m1.5.5.3.1.1.1.1.1.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l4.m1.5.5.3.1.1.1.1.1.1.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.1.1">subscript</csymbol><ci id="alg2.l4.m1.5.5.3.1.1.1.1.1.2.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.1.1.2">𝑣</ci><cn id="alg2.l4.m1.5.5.3.1.1.1.1.1.3.cmml" type="integer" xref="alg2.l4.m1.5.5.3.1.1.1.1.1.3">1</cn></apply><ci id="alg2.l4.m1.2.2.cmml" xref="alg2.l4.m1.2.2">…</ci><apply id="alg2.l4.m1.5.5.3.1.1.1.2.2.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.2.2"><csymbol cd="ambiguous" id="alg2.l4.m1.5.5.3.1.1.1.2.2.1.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.2.2">subscript</csymbol><ci id="alg2.l4.m1.5.5.3.1.1.1.2.2.2.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.2.2.2">𝑣</ci><ci id="alg2.l4.m1.5.5.3.1.1.1.2.2.3.cmml" xref="alg2.l4.m1.5.5.3.1.1.1.2.2.3">𝑘</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l4.m1.5c">\{v_{j_{1}},\ldots,v_{j_{k}}\}=PostProcess(\{v_{1},\ldots,v_{k}\})</annotation><annotation encoding="application/x-llamapun" id="alg2.l4.m1.5d">{ italic_v start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT } = italic_P italic_o italic_s italic_t italic_P italic_r italic_o italic_c italic_e italic_s italic_s ( { italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } )</annotation></semantics></math><span class="ltx_text" id="alg2.l4.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg2.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l5.1.1.1" style="font-size:80%;">5:</span></span><span class="ltx_text" id="alg2.l5.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l5.3" style="font-size:90%;">return</span><span class="ltx_text" id="alg2.l5.4" style="font-size:90%;">  </span><math alttext="\{v_{j_{1}},\ldots,v_{j_{k}}\}" class="ltx_Math" display="inline" id="alg2.l5.m1.3"><semantics id="alg2.l5.m1.3a"><mrow id="alg2.l5.m1.3.3.2" xref="alg2.l5.m1.3.3.3.cmml"><mo id="alg2.l5.m1.3.3.2.3" maxsize="90%" minsize="90%" xref="alg2.l5.m1.3.3.3.cmml">{</mo><msub id="alg2.l5.m1.2.2.1.1" xref="alg2.l5.m1.2.2.1.1.cmml"><mi id="alg2.l5.m1.2.2.1.1.2" mathsize="90%" xref="alg2.l5.m1.2.2.1.1.2.cmml">v</mi><msub id="alg2.l5.m1.2.2.1.1.3" xref="alg2.l5.m1.2.2.1.1.3.cmml"><mi id="alg2.l5.m1.2.2.1.1.3.2" mathsize="90%" xref="alg2.l5.m1.2.2.1.1.3.2.cmml">j</mi><mn id="alg2.l5.m1.2.2.1.1.3.3" mathsize="90%" xref="alg2.l5.m1.2.2.1.1.3.3.cmml">1</mn></msub></msub><mo id="alg2.l5.m1.3.3.2.4" mathsize="90%" xref="alg2.l5.m1.3.3.3.cmml">,</mo><mi id="alg2.l5.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg2.l5.m1.1.1.cmml">…</mi><mo id="alg2.l5.m1.3.3.2.5" mathsize="90%" xref="alg2.l5.m1.3.3.3.cmml">,</mo><msub id="alg2.l5.m1.3.3.2.2" xref="alg2.l5.m1.3.3.2.2.cmml"><mi id="alg2.l5.m1.3.3.2.2.2" mathsize="90%" xref="alg2.l5.m1.3.3.2.2.2.cmml">v</mi><msub id="alg2.l5.m1.3.3.2.2.3" xref="alg2.l5.m1.3.3.2.2.3.cmml"><mi id="alg2.l5.m1.3.3.2.2.3.2" mathsize="90%" xref="alg2.l5.m1.3.3.2.2.3.2.cmml">j</mi><mi id="alg2.l5.m1.3.3.2.2.3.3" mathsize="90%" xref="alg2.l5.m1.3.3.2.2.3.3.cmml">k</mi></msub></msub><mo id="alg2.l5.m1.3.3.2.6" maxsize="90%" minsize="90%" xref="alg2.l5.m1.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg2.l5.m1.3b"><set id="alg2.l5.m1.3.3.3.cmml" xref="alg2.l5.m1.3.3.2"><apply id="alg2.l5.m1.2.2.1.1.cmml" xref="alg2.l5.m1.2.2.1.1"><csymbol cd="ambiguous" id="alg2.l5.m1.2.2.1.1.1.cmml" xref="alg2.l5.m1.2.2.1.1">subscript</csymbol><ci id="alg2.l5.m1.2.2.1.1.2.cmml" xref="alg2.l5.m1.2.2.1.1.2">𝑣</ci><apply id="alg2.l5.m1.2.2.1.1.3.cmml" xref="alg2.l5.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="alg2.l5.m1.2.2.1.1.3.1.cmml" xref="alg2.l5.m1.2.2.1.1.3">subscript</csymbol><ci id="alg2.l5.m1.2.2.1.1.3.2.cmml" xref="alg2.l5.m1.2.2.1.1.3.2">𝑗</ci><cn id="alg2.l5.m1.2.2.1.1.3.3.cmml" type="integer" xref="alg2.l5.m1.2.2.1.1.3.3">1</cn></apply></apply><ci id="alg2.l5.m1.1.1.cmml" xref="alg2.l5.m1.1.1">…</ci><apply id="alg2.l5.m1.3.3.2.2.cmml" xref="alg2.l5.m1.3.3.2.2"><csymbol cd="ambiguous" id="alg2.l5.m1.3.3.2.2.1.cmml" xref="alg2.l5.m1.3.3.2.2">subscript</csymbol><ci id="alg2.l5.m1.3.3.2.2.2.cmml" xref="alg2.l5.m1.3.3.2.2.2">𝑣</ci><apply id="alg2.l5.m1.3.3.2.2.3.cmml" xref="alg2.l5.m1.3.3.2.2.3"><csymbol cd="ambiguous" id="alg2.l5.m1.3.3.2.2.3.1.cmml" xref="alg2.l5.m1.3.3.2.2.3">subscript</csymbol><ci id="alg2.l5.m1.3.3.2.2.3.2.cmml" xref="alg2.l5.m1.3.3.2.2.3.2">𝑗</ci><ci id="alg2.l5.m1.3.3.2.2.3.3.cmml" xref="alg2.l5.m1.3.3.2.2.3.3">𝑘</ci></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="alg2.l5.m1.3c">\{v_{j_{1}},\ldots,v_{j_{k}}\}</annotation><annotation encoding="application/x-llamapun" id="alg2.l5.m1.3d">{ italic_v start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg2.l5.5" style="font-size:90%;">;
</span>
</div>
</div>
</figure>
<figure class="ltx_figure" id="S3.F3"><svg class="ltx_picture ltx_centering" height="217.4" id="S3.F3.pic1" overflow="visible" version="1.1" width="679.07"><g fill="#000000" stroke="#000000" transform="translate(0,217.4) matrix(1 0 0 -1 0 0) translate(339.53,0) translate(0,197.44)"><g stroke-width="0.4pt"><g fill="#FFB3B3" stroke="#000000"><path d="M 92.89 19.69 L -92.89 19.69 C -95.95 19.69 -98.43 17.21 -98.43 14.15 L -98.43 -14.15 C -98.43 -17.21 -95.95 -19.69 -92.89 -19.69 L 92.89 -19.69 C 95.95 -19.69 98.43 -17.21 98.43 -14.15 L 98.43 14.15 C 98.43 17.21 95.95 19.69 92.89 19.69 Z M -98.43 -19.69"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -76.06 -4.8)"><foreignobject height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="152.11"><span class="ltx_text" id="S3.F3.pic1.1.1.1.1.1.1">Retrieval fusions in RAG</span></foreignobject></g><g fill="#FFD9B3" stroke="#000000"><path d="M -163.02 -27.56 L -309.43 -27.56 C -312.48 -27.56 -314.96 -30.04 -314.96 -33.09 L -314.96 -61.39 C -314.96 -64.45 -312.48 -66.93 -309.43 -66.93 L -163.02 -66.93 C -159.96 -66.93 -157.48 -64.45 -157.48 -61.39 L -157.48 -33.09 C -157.48 -30.04 -159.96 -27.56 -163.02 -27.56 Z M -314.96 -66.93"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -285.43 -44.01)"><foreignobject height="25.85" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.2.2.2.2.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F3.pic1.2.2.2.2.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.2.2.2.2.1.1.2">Query-based Fusions</span>
</span></foreignobject></g><g fill="#FFD9B3" stroke="#000000"><path d="M 73.21 -27.56 L -73.21 -27.56 C -76.26 -27.56 -78.74 -30.04 -78.74 -33.09 L -78.74 -61.39 C -78.74 -64.45 -76.26 -66.93 -73.21 -66.93 L 73.21 -66.93 C 76.26 -66.93 78.74 -64.45 78.74 -61.39 L 78.74 -33.09 C 78.74 -30.04 76.26 -27.56 73.21 -27.56 Z M -78.74 -66.93"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -49.21 -44.01)"><foreignobject height="25.85" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.3.3.3.3.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F3.pic1.3.3.3.3.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.3.3.3.3.1.1.2">Logits-based Fusions</span>
</span></foreignobject></g><g fill="#FFD9B3" stroke="#000000"><path d="M 309.43 -27.56 L 163.02 -27.56 C 159.96 -27.56 157.48 -30.04 157.48 -33.09 L 157.48 -61.39 C 157.48 -64.45 159.96 -66.93 163.02 -66.93 L 309.43 -66.93 C 312.48 -66.93 314.96 -64.45 314.96 -61.39 L 314.96 -33.09 C 314.96 -30.04 312.48 -27.56 309.43 -27.56 Z M 157.48 -66.93"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 187.01 -52.09)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="98.43">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.4.4.4.4.1.1" style="width:71.1pt;">
<span class="ltx_p" id="S3.F3.pic1.4.4.4.4.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.4.4.4.4.1.1.2">Latent Fusions</span>
</span></foreignobject></g><g fill="#B3FFB3" stroke="#000000"><path d="M -256.83 -82.68 L -333.72 -82.68 C -336.78 -82.68 -339.26 -85.16 -339.26 -88.21 L -339.26 -116.51 C -339.26 -119.57 -336.78 -122.05 -333.72 -122.05 L -256.83 -122.05 C -253.77 -122.05 -251.29 -119.57 -251.29 -116.51 L -251.29 -88.21 C -251.29 -85.16 -253.77 -82.68 -256.83 -82.68 Z M -339.26 -122.05"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -334.65 -107.21)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.5.5.5.5.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.5.5.5.5.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.5.5.5.5.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.F3.pic1.5.5.5.5.1.1.2.1" style="font-size:90%;">Text Concatenation</span></span>
</span></foreignobject></g><g fill="#B3FFB3" stroke="#000000"><path d="M -138.72 -82.68 L -215.61 -82.68 C -218.67 -82.68 -221.15 -85.16 -221.15 -88.21 L -221.15 -116.51 C -221.15 -119.57 -218.67 -122.05 -215.61 -122.05 L -138.72 -122.05 C -135.66 -122.05 -133.18 -119.57 -133.18 -116.51 L -133.18 -88.21 C -133.18 -85.16 -135.66 -82.68 -138.72 -82.68 Z M -221.15 -122.05"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -216.54 -107.21)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.6.6.6.6.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.6.6.6.6.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.6.6.6.6.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.F3.pic1.6.6.6.6.1.1.2.1" style="font-size:90%;">Feature Concatenation</span></span>
</span></foreignobject></g><g fill="#FFFFFF" stroke="#000000"><path d="M -339.26 -197.16 h 87.96 v 71.49 h -87.96 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -334.65 -139.97)"><foreignobject height="62.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.7.7.7.7.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.7.7.7.7.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.7.7.7.7.1.1.2"><span class="ltx_text" id="S3.F3.pic1.7.7.7.7.1.1.2.1" style="font-size:90%;">REALM <cite class="ltx_cite ltx_citemacro_citep">(Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.7.7.7.7.1.1.3"><span class="ltx_text" id="S3.F3.pic1.7.7.7.7.1.1.3.1" style="font-size:90%;">RAG <cite class="ltx_cite ltx_citemacro_citep">(Lewis
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib88" title="">2020</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.7.7.7.7.1.1.4"><span class="ltx_text" id="S3.F3.pic1.7.7.7.7.1.1.4.1" style="font-size:90%;">REINA <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib146" title="">2022</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.7.7.7.7.1.1.5"><span class="ltx_text" id="S3.F3.pic1.7.7.7.7.1.1.5.1" style="font-size:90%;">RALM <cite class="ltx_cite ltx_citemacro_citep">(Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib123" title="">2023b</a>)</cite></span></span>
</span></foreignobject></g><g fill="#FFFFFF" stroke="#000000"><path d="M -221.15 -197.16 h 87.96 v 71.49 h -87.96 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -216.54 -139.97)"><foreignobject height="62.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.8.8.8.8.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.8.8.8.8.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.8.8.8.8.1.1.2"><span class="ltx_text" id="S3.F3.pic1.8.8.8.8.1.1.2.1" style="font-size:90%;">FID <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib67" title="">2021</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.8.8.8.8.1.1.3"><span class="ltx_text" id="S3.F3.pic1.8.8.8.8.1.1.3.1" style="font-size:90%;">RETRO-</span></span>
<span class="ltx_p" id="S3.F3.pic1.8.8.8.8.1.1.4"><span class="ltx_text" id="S3.F3.pic1.8.8.8.8.1.1.4.1" style="font-size:90%;">PROMPT <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib15" title="">2022b</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.8.8.8.8.1.1.5"><span class="ltx_text" id="S3.F3.pic1.8.8.8.8.1.1.5.1" style="font-size:90%;">LUMEN <cite class="ltx_cite ltx_citemacro_citep">(de Jong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib26" title="">2023b</a>)</cite></span></span>
</span></foreignobject></g><g fill="#B3FFB3" stroke="#000000"><path d="M -20.61 -82.68 L -97.5 -82.68 C -100.56 -82.68 -103.04 -85.16 -103.04 -88.21 L -103.04 -116.51 C -103.04 -119.57 -100.56 -122.05 -97.5 -122.05 L -20.61 -122.05 C -17.55 -122.05 -15.07 -119.57 -15.07 -116.51 L -15.07 -88.21 C -15.07 -85.16 -17.55 -82.68 -20.61 -82.68 Z M -103.04 -122.05"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -98.43 -107.21)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.9.9.9.9.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.9.9.9.9.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.9.9.9.9.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.F3.pic1.9.9.9.9.1.1.2.1" style="font-size:90%;">Ensemble</span></span>
</span></foreignobject></g><g fill="#B3FFB3" stroke="#000000"><path d="M 97.5 -82.68 L 20.61 -82.68 C 17.55 -82.68 15.07 -85.16 15.07 -88.21 L 15.07 -116.51 C 15.07 -119.57 17.55 -122.05 20.61 -122.05 L 97.5 -122.05 C 100.56 -122.05 103.04 -119.57 103.04 -116.51 L 103.04 -88.21 C 103.04 -85.16 100.56 -82.68 97.5 -82.68 Z M 15.07 -122.05"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 19.69 -107.21)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.10.10.10.10.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.10.10.10.10.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.10.10.10.10.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.F3.pic1.10.10.10.10.1.1.2.1" style="font-size:90%;">Calibration</span></span>
</span></foreignobject></g><g fill="#FFFFFF" stroke="#000000"><path d="M -103.04 -197.16 h 87.96 v 71.49 h -87.96 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -98.43 -139.97)"><foreignobject height="62.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.11.11.11.11.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.11.11.11.11.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.11.11.11.11.1.1.2"><span class="ltx_text" id="S3.F3.pic1.11.11.11.11.1.1.2.1" style="font-size:90%;">kNN-LM <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib82" title="">2020b</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.11.11.11.11.1.1.3"><span class="ltx_text" id="S3.F3.pic1.11.11.11.11.1.1.3.1" style="font-size:90%;">kNN-MT <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib81" title="">2020a</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.11.11.11.11.1.1.4"><span class="ltx_text" id="S3.F3.pic1.11.11.11.11.1.1.4.1" style="font-size:90%;">kNN-Adapter <cite class="ltx_cite ltx_citemacro_citep">(Huang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib65" title="">2023b</a>)</cite></span></span>
</span></foreignobject></g><g fill="#FFFFFF" stroke="#000000"><path d="M 15.07 -197.16 h 87.96 v 71.49 h -87.96 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 19.69 -139.97)"><foreignobject height="62.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.12.12.12.12.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.12.12.12.12.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.12.12.12.12.1.1.2"><span class="ltx_text" id="S3.F3.pic1.12.12.12.12.1.1.2.1" style="font-size:90%;">Robust-kNN-MT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib73" title="">2022</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.12.12.12.12.1.1.3"><span class="ltx_text" id="S3.F3.pic1.12.12.12.12.1.1.3.1" style="font-size:90%;">Source-Context <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib90" title="">2023a</a>)</cite></span></span>
</span></foreignobject></g><g fill="#B3FFB3" stroke="#000000"><path d="M 215.61 -82.68 L 138.72 -82.68 C 135.66 -82.68 133.18 -85.16 133.18 -88.21 L 133.18 -116.51 C 133.18 -119.57 135.66 -122.05 138.72 -122.05 L 215.61 -122.05 C 218.67 -122.05 221.15 -119.57 221.15 -116.51 L 221.15 -88.21 C 221.15 -85.16 218.67 -82.68 215.61 -82.68 Z M 133.18 -122.05"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 137.8 -107.21)"><foreignobject height="9.69" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.13.13.13.13.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.13.13.13.13.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.13.13.13.13.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.F3.pic1.13.13.13.13.1.1.2.1" style="font-size:90%;">Attention</span></span>
</span></foreignobject></g><g fill="#B3FFB3" stroke="#000000"><path d="M 333.72 -82.68 L 256.83 -82.68 C 253.77 -82.68 251.29 -85.16 251.29 -88.21 L 251.29 -116.51 C 251.29 -119.57 253.77 -122.05 256.83 -122.05 L 333.72 -122.05 C 336.78 -122.05 339.26 -119.57 339.26 -116.51 L 339.26 -88.21 C 339.26 -85.16 336.78 -82.68 333.72 -82.68 Z M 251.29 -122.05"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 255.91 -106.51)"><foreignobject height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.14.14.14.14.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.14.14.14.14.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.14.14.14.14.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.F3.pic1.14.14.14.14.1.1.2.1" style="font-size:90%;">Weighted Addition</span></span>
</span></foreignobject></g><g fill="#FFFFFF" stroke="#000000"><path d="M 133.18 -180.99 h 87.96 v 54.89 h -87.96 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 137.8 -140.4)"><foreignobject height="45.66" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.15.15.15.15.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.15.15.15.15.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.15.15.15.15.1.1.2"><span class="ltx_text" id="S3.F3.pic1.15.15.15.15.1.1.2.1" style="font-size:90%;">RETRO <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.15.15.15.15.1.1.3"><span class="ltx_text" id="S3.F3.pic1.15.15.15.15.1.1.3.1" style="font-size:90%;">Enc-Dec <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib94" title="">2022a</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.15.15.15.15.1.1.4"><span class="ltx_text" id="S3.F3.pic1.15.15.15.15.1.1.4.1" style="font-size:90%;">LONGMEM <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib148" title="">2023b</a>)</cite></span></span>
</span></foreignobject></g><g fill="#FFFFFF" stroke="#000000"><path d="M 251.29 -173.23 h 87.96 v 39.37 h -87.96 Z"></path></g><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 255.91 -148.7)"><foreignobject height="29.06" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="78.74">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.16.16.16.16.1.1" style="width:56.9pt;">
<span class="ltx_p" id="S3.F3.pic1.16.16.16.16.1.1.1"></span>
<span class="ltx_p" id="S3.F3.pic1.16.16.16.16.1.1.2"><span class="ltx_text" id="S3.F3.pic1.16.16.16.16.1.1.2.1" style="font-size:90%;">EAE <cite class="ltx_cite ltx_citemacro_citep">(Févry et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib39" title="">2020</a>)</cite></span></span>
<span class="ltx_p" id="S3.F3.pic1.16.16.16.16.1.1.3"><span class="ltx_text" id="S3.F3.pic1.16.16.16.16.1.1.3.1" style="font-size:90%;">ReFusion <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib154" title="">2024</a>)</cite></span></span>
</span></foreignobject></g></g><g stroke-width="0.8pt"><path d="M -98.7 -19.73 L -153.68 -30.77" style="fill:none"></path><g transform="matrix(-0.98044 -0.19682 0.19682 -0.98044 -153.68 -30.77)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M 0 -19.96 L 0 -23.68" style="fill:none"></path><g transform="matrix(0.0 -1.0 1.0 0.0 0 -23.68)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M 98.7 -19.73 L 153.68 -30.77" style="fill:none"></path><g transform="matrix(0.98044 -0.19682 0.19682 0.98044 153.68 -30.77)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M -257.61 -67.21 L -271.26 -79.95" style="fill:none"></path><g transform="matrix(-0.73116 -0.6822 0.6822 -0.73116 -271.26 -79.95)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M -214.83 -67.21 L -201.18 -79.95" style="fill:none"></path><g transform="matrix(0.73116 -0.6822 0.6822 0.73116 -201.18 -79.95)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M -21.39 -67.21 L -35.04 -79.95" style="fill:none"></path><g transform="matrix(-0.73116 -0.6822 0.6822 -0.73116 -35.04 -79.95)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M 21.39 -67.21 L 35.04 -79.95" style="fill:none"></path><g transform="matrix(0.73116 -0.6822 0.6822 0.73116 35.04 -79.95)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M 214.83 -67.21 L 201.18 -79.95" style="fill:none"></path><g transform="matrix(-0.73116 -0.6822 0.6822 -0.73116 201.18 -79.95)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g><g stroke-width="0.8pt"><path d="M 257.61 -67.21 L 271.26 -79.95" style="fill:none"></path><g transform="matrix(0.73116 -0.6822 0.6822 0.73116 271.26 -79.95)"><path d="M 3.6 0 L -2.16 2.88 L 0 0 L -2.16 -2.88" style="stroke:none"></path></g></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>The categories of fusion methods in RAG.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS3.p4">
<p class="ltx_p" id="S3.SS1.SSS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p4.1.1">Advanced ANN Indexing.</span>
ANN Indexing generally refers to the methods or structures used to organize and manage data so that the approximate-nearest-neighbor search process is optimized for retrieval quality and retrieval efficiency.
This paper will introduce several advanced ANN indexing techniques.</p>
<ol class="ltx_enumerate" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i1.p1.1.1">The InVerted File system with Product Quantization (IVFPQ)</span> <cite class="ltx_cite ltx_citemacro_citep">(Douze et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib33" title="">2024</a>)</cite> is a simple but effective indexing framework that combines two powerful techniques to enable an efficient and scalable ANN search process. The main idea of IVFPQ is first to cluster the data for coarse-grained partition and then to compress the data within each cluster into sub-vectors for fine-grained quantization. The coarse-grained clustering (the IVF component) significantly reduces the search space, while the fine-grained quantization (the PQ component) ensures a high retrieval performance.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">The Hierarchical Navigable Small World (HNSW)</span> <cite class="ltx_cite ltx_citemacro_citep">(Malkov and
Yashunin, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib103" title="">2020</a>)</cite> uses a hierarchical graph structure to perform ANN search in high-dimensional spaces efficiently. Specifically, HNSW treats high-dimensional vectors as nodes and connects them with their nearest neighbors. The multi-layer graph structure is determined probabilistically to ensure fewer nodes at higher layers for efficient search.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I4.i3.p1">
<p class="ltx_p" id="S3.I4.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i3.p1.1.1">Tree-based Indexing</span> aims to organize high-dimensional vectors in tree-liked structures, such as KD-Trees <cite class="ltx_cite ltx_citemacro_citep">(Ram and Sinha, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib124" title="">2019</a>)</cite>, Ball Trees <cite class="ltx_cite ltx_citemacro_citep">(Huang and Tung, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib63" title="">2023</a>)</cite> and VP-Trees <cite class="ltx_cite ltx_citemacro_citep">(Liu and Wei, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib99" title="">2015</a>)</cite>. Typical tree-based indexing is Approximate Nearest Neighbors Oh Yeah (Annoy) <cite class="ltx_cite ltx_citemacro_citep">(Spotify, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib136" title="">2017</a>)</cite>, which uses a forest of trees built based on random projections to separate the vector space into multiple hyperplanes for efficient ANN search.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4. </span>Building the Datastore with Key-Value Pairs</h4>
<div class="ltx_para" id="S3.SS1.SSS4.p1">
<p class="ltx_p" id="S3.SS1.SSS4.p1.1">The datastore used in the vector database is a specialized database that stores and manages data as a collection of key-value pairs, where keys are the unique identifier of high-dimensional embeddings and values are the domain-specific knowledge.
Since the amount of the data stored in the datastore may be quite large, the storage engine, such as LMDB <cite class="ltx_cite ltx_citemacro_citep">(LMDB, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib101" title="">2014</a>)</cite> or RocksDB <cite class="ltx_cite ltx_citemacro_citep">(Facebook, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib36" title="">2013</a>)</cite>, should be capable of efficient retrieval and data persistence.
The key point in the datastore for ANN search is what should be used to store as values.
For example, for question-answer tasks, when adding retrievals to prompts, the naive but effective way is to store the question embedding as the key and question-answer pairs as the value.
This can help the generation process as retrievals are used as demonstrations for models.
Recent works have proposed various state-of-the-art vector databases, including the indexing and the datastore, such as Milvus <cite class="ltx_cite ltx_citemacro_citep">(Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib144" title="">2021b</a>; Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib47" title="">2022</a>)</cite>, FAISS <cite class="ltx_cite ltx_citemacro_citep">(Douze et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib33" title="">2024</a>; Johnson
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib78" title="">2021</a>)</cite>, LlamaIndex <cite class="ltx_cite ltx_citemacro_citep">(Liu, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib96" title="">2022</a>)</cite>, etc.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.5. </span>Code Demonstrations</h4>
<div class="ltx_para" id="S3.SS1.SSS5.p1">
<p class="ltx_p" id="S3.SS1.SSS5.p1.1">Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg1" title="Algorithm 1 ‣ 3.1.2. Encoding Chunks ‣ 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> shows detailed steps to build the retriever.
Lines 2-8 present the chunking and the encoding process for a natural language corpus containing multiple documents.
In line 6, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg1" title="Algorithm 1 ‣ 3.1.2. Encoding Chunks ‣ 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> takes the concatenation of the current chunk and the next chunk as the value.
Notably, the choice of value can vary for different tasks.
Another practical issue is that the memory cost of all keys and values may exceed the memory capacity of the server in the practical scenario.
Thus, it is recommended that the keys and values persist in the storage if necessary.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Querying the Retriever</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">This section will explain how to query the pre-built retriever, which basically includes three steps as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.F2" title="Figure 2 ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>(b): encoding queries, ANN search, and post-processing.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Encoding Queries and ANN Search</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">To align with the pre-built embedding space, the retriever uses the same encoder to encode queries during the querying stage.
The ANN search refers to leveraging the pre-built indexing and datastore to find similar data via approximate nearest neighbor searching algorithms and then retrieve the corresponding values.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p2.1.1">Searching the index</span> refers to searching the pre-built index, finding the top-k nearest neighbors, and returning the unique identifiers of k nearest neighbors.
The nearest neighbor search process depends on indexing algorithms or structures.
Taking IVFPQ as an example, the search process first compares the query embedding with cluster embeddings and selects several candidate clusters for further search.
Then, within each cluster, the search process performs the same product quantization on the query embedding and finds the top-k nearest neighbors based on the distance.
Finally, the search process merges all nearest neighbor candidates and re-orders all candidates for the final top-k nearest neighbors.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p3.1.1">Retrieving values from datastore</span> refers to fetching the corresponding values based on the key identifiers of nearest neighbors.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Post-Processing</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">The post-processing involves a set of techniques after the initial retrieval step.
These techniques aim to refine, enhance, or adapt the retrievals based on the specific task objectives.
This section will list some typical post-processing techniques.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.1.1">Reranking</span> aims to reorder the retrieved knowledge based on task-specific objectives.
The intuition is that the knowledge is retrieved based on task-agnostic metrics, such as Euclidean distance.
Existing reranking methods <cite class="ltx_cite ltx_citemacro_citep">(Chuang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib19" title="">2023</a>; Hossain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib57" title="">2020</a>; Lazaridou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib86" title="">2022</a>; Vu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib142" title="">2023</a>)</cite> mostly design different architectures or strategies to reorder the retrieved knowledge.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Code Demonstrations</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.2">After building the retriever, this section demonstrates the detailed steps of querying the retriever to obtain the top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p1.1.m1.1"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mi id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><ci id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p1.1.m1.1d">italic_k</annotation></semantics></math> nearest neighbor knowledge in algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg2" title="Algorithm 2 ‣ 3.1.3. Building the Index ‣ 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>, including encoding the query (line 1), performing the approximate nearest neighbor search (line 2), and fetching the knowledge for fusion (line 3).
These three steps depend on the specific APIs of encoders, indexing, and datastore.
After obtaining the top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p1.2.m2.1"><semantics id="S3.SS2.SSS3.p1.2.m2.1a"><mi id="S3.SS2.SSS3.p1.2.m2.1.1" xref="S3.SS2.SSS3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.2.m2.1b"><ci id="S3.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p1.2.m2.1d">italic_k</annotation></semantics></math> retrievals, optimizations for post-processing are applied (line 4).</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Retrieval Fusions</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Retrieval fusions refer to how to leverage the retrieved knowledge to improve generators’ performance.
Basically, there are three types of retrieval fusions: query-based fusions, logits-based fusions, and latent fusions.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S3.F3" title="Figure 3 ‣ 3.1.3. Building the Index ‣ 3.1. Building the Retriever ‣ 3. Retriever ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> shows the detailed categorization of fusions and representative works of each retrieval fusion in RAG.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1a">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1a.3.1.1">Algorithm 1</span> </span> <span class="ltx_text" id="alg1a.4.2" style="font-size:90%;">Query-based Fusions.</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg1a.5">
<div class="ltx_listingline" id="alg1.l0b">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0b.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg1.l0b.2" style="font-size:90%;">  A query input </span><math alttext="q" class="ltx_Math" display="inline" id="alg1.l0b.m1.1"><semantics id="alg1.l0b.m1.1a"><mi id="alg1.l0b.m1.1.1" mathsize="90%" xref="alg1.l0b.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg1.l0b.m1.1b"><ci id="alg1.l0b.m1.1.1.cmml" xref="alg1.l0b.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0b.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg1.l0b.m1.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="alg1.l0b.3" style="font-size:90%;">, top-</span><math alttext="k" class="ltx_Math" display="inline" id="alg1.l0b.m2.1"><semantics id="alg1.l0b.m2.1a"><mi id="alg1.l0b.m2.1.1" mathsize="90%" xref="alg1.l0b.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l0b.m2.1b"><ci id="alg1.l0b.m2.1.1.cmml" xref="alg1.l0b.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0b.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg1.l0b.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="alg1.l0b.4" style="font-size:90%;"> nearest neighbor knowledge </span><math alttext="\{v_{1},\ldots,v_{k}\}" class="ltx_Math" display="inline" id="alg1.l0b.m3.3"><semantics id="alg1.l0b.m3.3a"><mrow id="alg1.l0b.m3.3.3.2" xref="alg1.l0b.m3.3.3.3.cmml"><mo id="alg1.l0b.m3.3.3.2.3" maxsize="90%" minsize="90%" xref="alg1.l0b.m3.3.3.3.cmml">{</mo><msub id="alg1.l0b.m3.2.2.1.1" xref="alg1.l0b.m3.2.2.1.1.cmml"><mi id="alg1.l0b.m3.2.2.1.1.2" mathsize="90%" xref="alg1.l0b.m3.2.2.1.1.2.cmml">v</mi><mn id="alg1.l0b.m3.2.2.1.1.3" mathsize="90%" xref="alg1.l0b.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="alg1.l0b.m3.3.3.2.4" mathsize="90%" xref="alg1.l0b.m3.3.3.3.cmml">,</mo><mi id="alg1.l0b.m3.1.1" mathsize="90%" mathvariant="normal" xref="alg1.l0b.m3.1.1.cmml">…</mi><mo id="alg1.l0b.m3.3.3.2.5" mathsize="90%" xref="alg1.l0b.m3.3.3.3.cmml">,</mo><msub id="alg1.l0b.m3.3.3.2.2" xref="alg1.l0b.m3.3.3.2.2.cmml"><mi id="alg1.l0b.m3.3.3.2.2.2" mathsize="90%" xref="alg1.l0b.m3.3.3.2.2.2.cmml">v</mi><mi id="alg1.l0b.m3.3.3.2.2.3" mathsize="90%" xref="alg1.l0b.m3.3.3.2.2.3.cmml">k</mi></msub><mo id="alg1.l0b.m3.3.3.2.6" maxsize="90%" minsize="90%" xref="alg1.l0b.m3.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l0b.m3.3b"><set id="alg1.l0b.m3.3.3.3.cmml" xref="alg1.l0b.m3.3.3.2"><apply id="alg1.l0b.m3.2.2.1.1.cmml" xref="alg1.l0b.m3.2.2.1.1"><csymbol cd="ambiguous" id="alg1.l0b.m3.2.2.1.1.1.cmml" xref="alg1.l0b.m3.2.2.1.1">subscript</csymbol><ci id="alg1.l0b.m3.2.2.1.1.2.cmml" xref="alg1.l0b.m3.2.2.1.1.2">𝑣</ci><cn id="alg1.l0b.m3.2.2.1.1.3.cmml" type="integer" xref="alg1.l0b.m3.2.2.1.1.3">1</cn></apply><ci id="alg1.l0b.m3.1.1.cmml" xref="alg1.l0b.m3.1.1">…</ci><apply id="alg1.l0b.m3.3.3.2.2.cmml" xref="alg1.l0b.m3.3.3.2.2"><csymbol cd="ambiguous" id="alg1.l0b.m3.3.3.2.2.1.cmml" xref="alg1.l0b.m3.3.3.2.2">subscript</csymbol><ci id="alg1.l0b.m3.3.3.2.2.2.cmml" xref="alg1.l0b.m3.3.3.2.2.2">𝑣</ci><ci id="alg1.l0b.m3.3.3.2.2.3.cmml" xref="alg1.l0b.m3.3.3.2.2.3">𝑘</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0b.m3.3c">\{v_{1},\ldots,v_{k}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0b.m3.3d">{ italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg1.l0b.5" style="font-size:90%;">, an encoder </span><math alttext="\mathcal{E}_{f}" class="ltx_Math" display="inline" id="alg1.l0b.m4.1"><semantics id="alg1.l0b.m4.1a"><msub id="alg1.l0b.m4.1.1" xref="alg1.l0b.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l0b.m4.1.1.2" mathsize="90%" xref="alg1.l0b.m4.1.1.2.cmml">ℰ</mi><mi id="alg1.l0b.m4.1.1.3" mathsize="90%" xref="alg1.l0b.m4.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l0b.m4.1b"><apply id="alg1.l0b.m4.1.1.cmml" xref="alg1.l0b.m4.1.1"><csymbol cd="ambiguous" id="alg1.l0b.m4.1.1.1.cmml" xref="alg1.l0b.m4.1.1">subscript</csymbol><ci id="alg1.l0b.m4.1.1.2.cmml" xref="alg1.l0b.m4.1.1.2">ℰ</ci><ci id="alg1.l0b.m4.1.1.3.cmml" xref="alg1.l0b.m4.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0b.m4.1c">\mathcal{E}_{f}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0b.m4.1d">caligraphic_E start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l0b.6" style="font-size:90%;"> and a decoder </span><math alttext="\mathcal{D}_{f}" class="ltx_Math" display="inline" id="alg1.l0b.m5.1"><semantics id="alg1.l0b.m5.1a"><msub id="alg1.l0b.m5.1.1" xref="alg1.l0b.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l0b.m5.1.1.2" mathsize="90%" xref="alg1.l0b.m5.1.1.2.cmml">𝒟</mi><mi id="alg1.l0b.m5.1.1.3" mathsize="90%" xref="alg1.l0b.m5.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l0b.m5.1b"><apply id="alg1.l0b.m5.1.1.cmml" xref="alg1.l0b.m5.1.1"><csymbol cd="ambiguous" id="alg1.l0b.m5.1.1.1.cmml" xref="alg1.l0b.m5.1.1">subscript</csymbol><ci id="alg1.l0b.m5.1.1.2.cmml" xref="alg1.l0b.m5.1.1.2">𝒟</ci><ci id="alg1.l0b.m5.1.1.3.cmml" xref="alg1.l0b.m5.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0b.m5.1c">\mathcal{D}_{f}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0b.m5.1d">caligraphic_D start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l0b.7" style="font-size:90%;"> for feature concatenation, the generator </span><math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg1.l0b.m6.1"><semantics id="alg1.l0b.m6.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l0b.m6.1.1" mathsize="90%" xref="alg1.l0b.m6.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg1.l0b.m6.1b"><ci id="alg1.l0b.m6.1.1.cmml" xref="alg1.l0b.m6.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0b.m6.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0b.m6.1d">caligraphic_G</annotation></semantics></math><span class="ltx_text" id="alg1.l0b.8" style="font-size:90%;"> for text concatenation.</span>
</div>
<div class="ltx_listingline" id="alg1.l0c">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0c.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg1.l0c.2" style="font-size:90%;">  Generated response </span><math alttext="y" class="ltx_Math" display="inline" id="alg1.l0c.m1.1"><semantics id="alg1.l0c.m1.1a"><mi id="alg1.l0c.m1.1.1" mathsize="90%" xref="alg1.l0c.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg1.l0c.m1.1b"><ci id="alg1.l0c.m1.1.1.cmml" xref="alg1.l0c.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0c.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg1.l0c.m1.1d">italic_y</annotation></semantics></math><span class="ltx_text" id="alg1.l0c.3" style="font-size:90%;">.
</span>
</div>
<div class="ltx_listingline" id="alg1.l1a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1a.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text" id="alg1.l1a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l1a.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg1.l1a.4" style="font-size:90%;"> Use the text concatenation </span><span class="ltx_text ltx_font_bold" id="alg1.l1a.5" style="font-size:90%;">then</span><span class="ltx_text" id="alg1.l1a.6" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l2a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2a.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text" id="alg1.l2a.2" style="font-size:90%;">     </span><math alttext="x=v_{1}\oplus\ldots\oplus v_{k}\oplus q" class="ltx_Math" display="inline" id="alg1.l2a.m1.1"><semantics id="alg1.l2a.m1.1a"><mrow id="alg1.l2a.m1.1.1" xref="alg1.l2a.m1.1.1.cmml"><mi id="alg1.l2a.m1.1.1.2" mathsize="90%" xref="alg1.l2a.m1.1.1.2.cmml">x</mi><mo id="alg1.l2a.m1.1.1.1" mathsize="90%" xref="alg1.l2a.m1.1.1.1.cmml">=</mo><mrow id="alg1.l2a.m1.1.1.3" xref="alg1.l2a.m1.1.1.3.cmml"><msub id="alg1.l2a.m1.1.1.3.2" xref="alg1.l2a.m1.1.1.3.2.cmml"><mi id="alg1.l2a.m1.1.1.3.2.2" mathsize="90%" xref="alg1.l2a.m1.1.1.3.2.2.cmml">v</mi><mn id="alg1.l2a.m1.1.1.3.2.3" mathsize="90%" xref="alg1.l2a.m1.1.1.3.2.3.cmml">1</mn></msub><mo id="alg1.l2a.m1.1.1.3.1" mathsize="90%" xref="alg1.l2a.m1.1.1.3.1.cmml">⊕</mo><mi id="alg1.l2a.m1.1.1.3.3" mathsize="90%" mathvariant="normal" xref="alg1.l2a.m1.1.1.3.3.cmml">…</mi><mo id="alg1.l2a.m1.1.1.3.1a" mathsize="90%" xref="alg1.l2a.m1.1.1.3.1.cmml">⊕</mo><msub id="alg1.l2a.m1.1.1.3.4" xref="alg1.l2a.m1.1.1.3.4.cmml"><mi id="alg1.l2a.m1.1.1.3.4.2" mathsize="90%" xref="alg1.l2a.m1.1.1.3.4.2.cmml">v</mi><mi id="alg1.l2a.m1.1.1.3.4.3" mathsize="90%" xref="alg1.l2a.m1.1.1.3.4.3.cmml">k</mi></msub><mo id="alg1.l2a.m1.1.1.3.1b" mathsize="90%" xref="alg1.l2a.m1.1.1.3.1.cmml">⊕</mo><mi id="alg1.l2a.m1.1.1.3.5" mathsize="90%" xref="alg1.l2a.m1.1.1.3.5.cmml">q</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2a.m1.1b"><apply id="alg1.l2a.m1.1.1.cmml" xref="alg1.l2a.m1.1.1"><eq id="alg1.l2a.m1.1.1.1.cmml" xref="alg1.l2a.m1.1.1.1"></eq><ci id="alg1.l2a.m1.1.1.2.cmml" xref="alg1.l2a.m1.1.1.2">𝑥</ci><apply id="alg1.l2a.m1.1.1.3.cmml" xref="alg1.l2a.m1.1.1.3"><csymbol cd="latexml" id="alg1.l2a.m1.1.1.3.1.cmml" xref="alg1.l2a.m1.1.1.3.1">direct-sum</csymbol><apply id="alg1.l2a.m1.1.1.3.2.cmml" xref="alg1.l2a.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l2a.m1.1.1.3.2.1.cmml" xref="alg1.l2a.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l2a.m1.1.1.3.2.2.cmml" xref="alg1.l2a.m1.1.1.3.2.2">𝑣</ci><cn id="alg1.l2a.m1.1.1.3.2.3.cmml" type="integer" xref="alg1.l2a.m1.1.1.3.2.3">1</cn></apply><ci id="alg1.l2a.m1.1.1.3.3.cmml" xref="alg1.l2a.m1.1.1.3.3">…</ci><apply id="alg1.l2a.m1.1.1.3.4.cmml" xref="alg1.l2a.m1.1.1.3.4"><csymbol cd="ambiguous" id="alg1.l2a.m1.1.1.3.4.1.cmml" xref="alg1.l2a.m1.1.1.3.4">subscript</csymbol><ci id="alg1.l2a.m1.1.1.3.4.2.cmml" xref="alg1.l2a.m1.1.1.3.4.2">𝑣</ci><ci id="alg1.l2a.m1.1.1.3.4.3.cmml" xref="alg1.l2a.m1.1.1.3.4.3">𝑘</ci></apply><ci id="alg1.l2a.m1.1.1.3.5.cmml" xref="alg1.l2a.m1.1.1.3.5">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.m1.1c">x=v_{1}\oplus\ldots\oplus v_{k}\oplus q</annotation><annotation encoding="application/x-llamapun" id="alg1.l2a.m1.1d">italic_x = italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊕ … ⊕ italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⊕ italic_q</annotation></semantics></math><span class="ltx_text" id="alg1.l2a.3" style="font-size:90%;">; </span><span class="ltx_text" id="alg1.l2a.4" style="font-size:90%;float:right;">/* Concatenate neighbor texts and query */
</span>
</div>
<div class="ltx_listingline" id="alg1.l3a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3a.1.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text" id="alg1.l3a.2" style="font-size:90%;">     </span><math alttext="y=\mathcal{G}(x)" class="ltx_Math" display="inline" id="alg1.l3a.m1.1"><semantics id="alg1.l3a.m1.1a"><mrow id="alg1.l3a.m1.1.2" xref="alg1.l3a.m1.1.2.cmml"><mi id="alg1.l3a.m1.1.2.2" mathsize="90%" xref="alg1.l3a.m1.1.2.2.cmml">y</mi><mo id="alg1.l3a.m1.1.2.1" mathsize="90%" xref="alg1.l3a.m1.1.2.1.cmml">=</mo><mrow id="alg1.l3a.m1.1.2.3" xref="alg1.l3a.m1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l3a.m1.1.2.3.2" mathsize="90%" xref="alg1.l3a.m1.1.2.3.2.cmml">𝒢</mi><mo id="alg1.l3a.m1.1.2.3.1" xref="alg1.l3a.m1.1.2.3.1.cmml">⁢</mo><mrow id="alg1.l3a.m1.1.2.3.3.2" xref="alg1.l3a.m1.1.2.3.cmml"><mo id="alg1.l3a.m1.1.2.3.3.2.1" maxsize="90%" minsize="90%" xref="alg1.l3a.m1.1.2.3.cmml">(</mo><mi id="alg1.l3a.m1.1.1" mathsize="90%" xref="alg1.l3a.m1.1.1.cmml">x</mi><mo id="alg1.l3a.m1.1.2.3.3.2.2" maxsize="90%" minsize="90%" xref="alg1.l3a.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3a.m1.1b"><apply id="alg1.l3a.m1.1.2.cmml" xref="alg1.l3a.m1.1.2"><eq id="alg1.l3a.m1.1.2.1.cmml" xref="alg1.l3a.m1.1.2.1"></eq><ci id="alg1.l3a.m1.1.2.2.cmml" xref="alg1.l3a.m1.1.2.2">𝑦</ci><apply id="alg1.l3a.m1.1.2.3.cmml" xref="alg1.l3a.m1.1.2.3"><times id="alg1.l3a.m1.1.2.3.1.cmml" xref="alg1.l3a.m1.1.2.3.1"></times><ci id="alg1.l3a.m1.1.2.3.2.cmml" xref="alg1.l3a.m1.1.2.3.2">𝒢</ci><ci id="alg1.l3a.m1.1.1.cmml" xref="alg1.l3a.m1.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3a.m1.1c">y=\mathcal{G}(x)</annotation><annotation encoding="application/x-llamapun" id="alg1.l3a.m1.1d">italic_y = caligraphic_G ( italic_x )</annotation></semantics></math><span class="ltx_text" id="alg1.l3a.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg1.l4a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4a.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text" id="alg1.l4a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l4a.3" style="font-size:90%;">else</span><span class="ltx_text" id="alg1.l4a.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l5a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5a.1.1.1" style="font-size:80%;">5:</span></span><span class="ltx_text" id="alg1.l5a.2" style="font-size:90%;">     </span><math alttext="e_{q}=\mathcal{E}_{f}(q),e_{v_{j}}=\mathcal{E}_{f}(v_{j}),j\in\{1,\ldots,k\}" class="ltx_Math" display="inline" id="alg1.l5a.m1.6"><semantics id="alg1.l5a.m1.6a"><mrow id="alg1.l5a.m1.6.6.2" xref="alg1.l5a.m1.6.6.3.cmml"><mrow id="alg1.l5a.m1.5.5.1.1" xref="alg1.l5a.m1.5.5.1.1.cmml"><msub id="alg1.l5a.m1.5.5.1.1.2" xref="alg1.l5a.m1.5.5.1.1.2.cmml"><mi id="alg1.l5a.m1.5.5.1.1.2.2" mathsize="90%" xref="alg1.l5a.m1.5.5.1.1.2.2.cmml">e</mi><mi id="alg1.l5a.m1.5.5.1.1.2.3" mathsize="90%" xref="alg1.l5a.m1.5.5.1.1.2.3.cmml">q</mi></msub><mo id="alg1.l5a.m1.5.5.1.1.1" mathsize="90%" xref="alg1.l5a.m1.5.5.1.1.1.cmml">=</mo><mrow id="alg1.l5a.m1.5.5.1.1.3" xref="alg1.l5a.m1.5.5.1.1.3.cmml"><msub id="alg1.l5a.m1.5.5.1.1.3.2" xref="alg1.l5a.m1.5.5.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5a.m1.5.5.1.1.3.2.2" mathsize="90%" xref="alg1.l5a.m1.5.5.1.1.3.2.2.cmml">ℰ</mi><mi id="alg1.l5a.m1.5.5.1.1.3.2.3" mathsize="90%" xref="alg1.l5a.m1.5.5.1.1.3.2.3.cmml">f</mi></msub><mo id="alg1.l5a.m1.5.5.1.1.3.1" xref="alg1.l5a.m1.5.5.1.1.3.1.cmml">⁢</mo><mrow id="alg1.l5a.m1.5.5.1.1.3.3.2" xref="alg1.l5a.m1.5.5.1.1.3.cmml"><mo id="alg1.l5a.m1.5.5.1.1.3.3.2.1" maxsize="90%" minsize="90%" xref="alg1.l5a.m1.5.5.1.1.3.cmml">(</mo><mi id="alg1.l5a.m1.1.1" mathsize="90%" xref="alg1.l5a.m1.1.1.cmml">q</mi><mo id="alg1.l5a.m1.5.5.1.1.3.3.2.2" maxsize="90%" minsize="90%" xref="alg1.l5a.m1.5.5.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="alg1.l5a.m1.6.6.2.3" mathsize="90%" xref="alg1.l5a.m1.6.6.3a.cmml">,</mo><mrow id="alg1.l5a.m1.6.6.2.2.2" xref="alg1.l5a.m1.6.6.2.2.3.cmml"><mrow id="alg1.l5a.m1.6.6.2.2.1.1" xref="alg1.l5a.m1.6.6.2.2.1.1.cmml"><msub id="alg1.l5a.m1.6.6.2.2.1.1.3" xref="alg1.l5a.m1.6.6.2.2.1.1.3.cmml"><mi id="alg1.l5a.m1.6.6.2.2.1.1.3.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.3.2.cmml">e</mi><msub id="alg1.l5a.m1.6.6.2.2.1.1.3.3" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3.cmml"><mi id="alg1.l5a.m1.6.6.2.2.1.1.3.3.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3.2.cmml">v</mi><mi id="alg1.l5a.m1.6.6.2.2.1.1.3.3.3" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3.3.cmml">j</mi></msub></msub><mo id="alg1.l5a.m1.6.6.2.2.1.1.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.2.cmml">=</mo><mrow id="alg1.l5a.m1.6.6.2.2.1.1.1" xref="alg1.l5a.m1.6.6.2.2.1.1.1.cmml"><msub id="alg1.l5a.m1.6.6.2.2.1.1.1.3" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5a.m1.6.6.2.2.1.1.1.3.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3.2.cmml">ℰ</mi><mi id="alg1.l5a.m1.6.6.2.2.1.1.1.3.3" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3.3.cmml">f</mi></msub><mo id="alg1.l5a.m1.6.6.2.2.1.1.1.2" xref="alg1.l5a.m1.6.6.2.2.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.cmml"><mo id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.cmml"><mi id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.2.cmml">v</mi><mi id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.3" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="alg1.l5a.m1.6.6.2.2.2.3" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.3a.cmml">,</mo><mrow id="alg1.l5a.m1.6.6.2.2.2.2" xref="alg1.l5a.m1.6.6.2.2.2.2.cmml"><mi id="alg1.l5a.m1.6.6.2.2.2.2.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.2.2.2.cmml">j</mi><mo id="alg1.l5a.m1.6.6.2.2.2.2.1" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.2.2.1.cmml">∈</mo><mrow id="alg1.l5a.m1.6.6.2.2.2.2.3.2" xref="alg1.l5a.m1.6.6.2.2.2.2.3.1.cmml"><mo id="alg1.l5a.m1.6.6.2.2.2.2.3.2.1" maxsize="90%" minsize="90%" xref="alg1.l5a.m1.6.6.2.2.2.2.3.1.cmml">{</mo><mn id="alg1.l5a.m1.2.2" mathsize="90%" xref="alg1.l5a.m1.2.2.cmml">1</mn><mo id="alg1.l5a.m1.6.6.2.2.2.2.3.2.2" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.2.2.3.1.cmml">,</mo><mi id="alg1.l5a.m1.3.3" mathsize="90%" mathvariant="normal" xref="alg1.l5a.m1.3.3.cmml">…</mi><mo id="alg1.l5a.m1.6.6.2.2.2.2.3.2.3" mathsize="90%" xref="alg1.l5a.m1.6.6.2.2.2.2.3.1.cmml">,</mo><mi id="alg1.l5a.m1.4.4" mathsize="90%" xref="alg1.l5a.m1.4.4.cmml">k</mi><mo id="alg1.l5a.m1.6.6.2.2.2.2.3.2.4" maxsize="90%" minsize="90%" xref="alg1.l5a.m1.6.6.2.2.2.2.3.1.cmml">}</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5a.m1.6b"><apply id="alg1.l5a.m1.6.6.3.cmml" xref="alg1.l5a.m1.6.6.2"><csymbol cd="ambiguous" id="alg1.l5a.m1.6.6.3a.cmml" xref="alg1.l5a.m1.6.6.2.3">formulae-sequence</csymbol><apply id="alg1.l5a.m1.5.5.1.1.cmml" xref="alg1.l5a.m1.5.5.1.1"><eq id="alg1.l5a.m1.5.5.1.1.1.cmml" xref="alg1.l5a.m1.5.5.1.1.1"></eq><apply id="alg1.l5a.m1.5.5.1.1.2.cmml" xref="alg1.l5a.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="alg1.l5a.m1.5.5.1.1.2.1.cmml" xref="alg1.l5a.m1.5.5.1.1.2">subscript</csymbol><ci id="alg1.l5a.m1.5.5.1.1.2.2.cmml" xref="alg1.l5a.m1.5.5.1.1.2.2">𝑒</ci><ci id="alg1.l5a.m1.5.5.1.1.2.3.cmml" xref="alg1.l5a.m1.5.5.1.1.2.3">𝑞</ci></apply><apply id="alg1.l5a.m1.5.5.1.1.3.cmml" xref="alg1.l5a.m1.5.5.1.1.3"><times id="alg1.l5a.m1.5.5.1.1.3.1.cmml" xref="alg1.l5a.m1.5.5.1.1.3.1"></times><apply id="alg1.l5a.m1.5.5.1.1.3.2.cmml" xref="alg1.l5a.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l5a.m1.5.5.1.1.3.2.1.cmml" xref="alg1.l5a.m1.5.5.1.1.3.2">subscript</csymbol><ci id="alg1.l5a.m1.5.5.1.1.3.2.2.cmml" xref="alg1.l5a.m1.5.5.1.1.3.2.2">ℰ</ci><ci id="alg1.l5a.m1.5.5.1.1.3.2.3.cmml" xref="alg1.l5a.m1.5.5.1.1.3.2.3">𝑓</ci></apply><ci id="alg1.l5a.m1.1.1.cmml" xref="alg1.l5a.m1.1.1">𝑞</ci></apply></apply><apply id="alg1.l5a.m1.6.6.2.2.3.cmml" xref="alg1.l5a.m1.6.6.2.2.2"><csymbol cd="ambiguous" id="alg1.l5a.m1.6.6.2.2.3a.cmml" xref="alg1.l5a.m1.6.6.2.2.2.3">formulae-sequence</csymbol><apply id="alg1.l5a.m1.6.6.2.2.1.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1"><eq id="alg1.l5a.m1.6.6.2.2.1.1.2.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.2"></eq><apply id="alg1.l5a.m1.6.6.2.2.1.1.3.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3"><csymbol cd="ambiguous" id="alg1.l5a.m1.6.6.2.2.1.1.3.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3">subscript</csymbol><ci id="alg1.l5a.m1.6.6.2.2.1.1.3.2.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3.2">𝑒</ci><apply id="alg1.l5a.m1.6.6.2.2.1.1.3.3.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l5a.m1.6.6.2.2.1.1.3.3.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3">subscript</csymbol><ci id="alg1.l5a.m1.6.6.2.2.1.1.3.3.2.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3.2">𝑣</ci><ci id="alg1.l5a.m1.6.6.2.2.1.1.3.3.3.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.3.3.3">𝑗</ci></apply></apply><apply id="alg1.l5a.m1.6.6.2.2.1.1.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1"><times id="alg1.l5a.m1.6.6.2.2.1.1.1.2.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.2"></times><apply id="alg1.l5a.m1.6.6.2.2.1.1.1.3.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5a.m1.6.6.2.2.1.1.1.3.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3">subscript</csymbol><ci id="alg1.l5a.m1.6.6.2.2.1.1.1.3.2.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3.2">ℰ</ci><ci id="alg1.l5a.m1.6.6.2.2.1.1.1.3.3.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.3.3">𝑓</ci></apply><apply id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.1.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1">subscript</csymbol><ci id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.2.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.2">𝑣</ci><ci id="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.3.cmml" xref="alg1.l5a.m1.6.6.2.2.1.1.1.1.1.1.3">𝑗</ci></apply></apply></apply><apply id="alg1.l5a.m1.6.6.2.2.2.2.cmml" xref="alg1.l5a.m1.6.6.2.2.2.2"><in id="alg1.l5a.m1.6.6.2.2.2.2.1.cmml" xref="alg1.l5a.m1.6.6.2.2.2.2.1"></in><ci id="alg1.l5a.m1.6.6.2.2.2.2.2.cmml" xref="alg1.l5a.m1.6.6.2.2.2.2.2">𝑗</ci><set id="alg1.l5a.m1.6.6.2.2.2.2.3.1.cmml" xref="alg1.l5a.m1.6.6.2.2.2.2.3.2"><cn id="alg1.l5a.m1.2.2.cmml" type="integer" xref="alg1.l5a.m1.2.2">1</cn><ci id="alg1.l5a.m1.3.3.cmml" xref="alg1.l5a.m1.3.3">…</ci><ci id="alg1.l5a.m1.4.4.cmml" xref="alg1.l5a.m1.4.4">𝑘</ci></set></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5a.m1.6c">e_{q}=\mathcal{E}_{f}(q),e_{v_{j}}=\mathcal{E}_{f}(v_{j}),j\in\{1,\ldots,k\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5a.m1.6d">italic_e start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = caligraphic_E start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ( italic_q ) , italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT = caligraphic_E start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) , italic_j ∈ { 1 , … , italic_k }</annotation></semantics></math><span class="ltx_text" id="alg1.l5a.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg1.l6a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6a.1.1.1" style="font-size:80%;">6:</span></span><span class="ltx_text" id="alg1.l6a.2" style="font-size:90%;">     </span><math alttext="e_{x}=e_{q}\oplus e_{v_{1}}\oplus\ldots\oplus e_{v_{k}}" class="ltx_Math" display="inline" id="alg1.l6a.m1.1"><semantics id="alg1.l6a.m1.1a"><mrow id="alg1.l6a.m1.1.1" xref="alg1.l6a.m1.1.1.cmml"><msub id="alg1.l6a.m1.1.1.2" xref="alg1.l6a.m1.1.1.2.cmml"><mi id="alg1.l6a.m1.1.1.2.2" mathsize="90%" xref="alg1.l6a.m1.1.1.2.2.cmml">e</mi><mi id="alg1.l6a.m1.1.1.2.3" mathsize="90%" xref="alg1.l6a.m1.1.1.2.3.cmml">x</mi></msub><mo id="alg1.l6a.m1.1.1.1" mathsize="90%" xref="alg1.l6a.m1.1.1.1.cmml">=</mo><mrow id="alg1.l6a.m1.1.1.3" xref="alg1.l6a.m1.1.1.3.cmml"><msub id="alg1.l6a.m1.1.1.3.2" xref="alg1.l6a.m1.1.1.3.2.cmml"><mi id="alg1.l6a.m1.1.1.3.2.2" mathsize="90%" xref="alg1.l6a.m1.1.1.3.2.2.cmml">e</mi><mi id="alg1.l6a.m1.1.1.3.2.3" mathsize="90%" xref="alg1.l6a.m1.1.1.3.2.3.cmml">q</mi></msub><mo id="alg1.l6a.m1.1.1.3.1" mathsize="90%" xref="alg1.l6a.m1.1.1.3.1.cmml">⊕</mo><msub id="alg1.l6a.m1.1.1.3.3" xref="alg1.l6a.m1.1.1.3.3.cmml"><mi id="alg1.l6a.m1.1.1.3.3.2" mathsize="90%" xref="alg1.l6a.m1.1.1.3.3.2.cmml">e</mi><msub id="alg1.l6a.m1.1.1.3.3.3" xref="alg1.l6a.m1.1.1.3.3.3.cmml"><mi id="alg1.l6a.m1.1.1.3.3.3.2" mathsize="90%" xref="alg1.l6a.m1.1.1.3.3.3.2.cmml">v</mi><mn id="alg1.l6a.m1.1.1.3.3.3.3" mathsize="90%" xref="alg1.l6a.m1.1.1.3.3.3.3.cmml">1</mn></msub></msub><mo id="alg1.l6a.m1.1.1.3.1a" mathsize="90%" xref="alg1.l6a.m1.1.1.3.1.cmml">⊕</mo><mi id="alg1.l6a.m1.1.1.3.4" mathsize="90%" mathvariant="normal" xref="alg1.l6a.m1.1.1.3.4.cmml">…</mi><mo id="alg1.l6a.m1.1.1.3.1b" mathsize="90%" xref="alg1.l6a.m1.1.1.3.1.cmml">⊕</mo><msub id="alg1.l6a.m1.1.1.3.5" xref="alg1.l6a.m1.1.1.3.5.cmml"><mi id="alg1.l6a.m1.1.1.3.5.2" mathsize="90%" xref="alg1.l6a.m1.1.1.3.5.2.cmml">e</mi><msub id="alg1.l6a.m1.1.1.3.5.3" xref="alg1.l6a.m1.1.1.3.5.3.cmml"><mi id="alg1.l6a.m1.1.1.3.5.3.2" mathsize="90%" xref="alg1.l6a.m1.1.1.3.5.3.2.cmml">v</mi><mi id="alg1.l6a.m1.1.1.3.5.3.3" mathsize="90%" xref="alg1.l6a.m1.1.1.3.5.3.3.cmml">k</mi></msub></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6a.m1.1b"><apply id="alg1.l6a.m1.1.1.cmml" xref="alg1.l6a.m1.1.1"><eq id="alg1.l6a.m1.1.1.1.cmml" xref="alg1.l6a.m1.1.1.1"></eq><apply id="alg1.l6a.m1.1.1.2.cmml" xref="alg1.l6a.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.2.1.cmml" xref="alg1.l6a.m1.1.1.2">subscript</csymbol><ci id="alg1.l6a.m1.1.1.2.2.cmml" xref="alg1.l6a.m1.1.1.2.2">𝑒</ci><ci id="alg1.l6a.m1.1.1.2.3.cmml" xref="alg1.l6a.m1.1.1.2.3">𝑥</ci></apply><apply id="alg1.l6a.m1.1.1.3.cmml" xref="alg1.l6a.m1.1.1.3"><csymbol cd="latexml" id="alg1.l6a.m1.1.1.3.1.cmml" xref="alg1.l6a.m1.1.1.3.1">direct-sum</csymbol><apply id="alg1.l6a.m1.1.1.3.2.cmml" xref="alg1.l6a.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.2.1.cmml" xref="alg1.l6a.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.2.2.cmml" xref="alg1.l6a.m1.1.1.3.2.2">𝑒</ci><ci id="alg1.l6a.m1.1.1.3.2.3.cmml" xref="alg1.l6a.m1.1.1.3.2.3">𝑞</ci></apply><apply id="alg1.l6a.m1.1.1.3.3.cmml" xref="alg1.l6a.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.3.1.cmml" xref="alg1.l6a.m1.1.1.3.3">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.3.2.cmml" xref="alg1.l6a.m1.1.1.3.3.2">𝑒</ci><apply id="alg1.l6a.m1.1.1.3.3.3.cmml" xref="alg1.l6a.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.3.3.1.cmml" xref="alg1.l6a.m1.1.1.3.3.3">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.3.3.2.cmml" xref="alg1.l6a.m1.1.1.3.3.3.2">𝑣</ci><cn id="alg1.l6a.m1.1.1.3.3.3.3.cmml" type="integer" xref="alg1.l6a.m1.1.1.3.3.3.3">1</cn></apply></apply><ci id="alg1.l6a.m1.1.1.3.4.cmml" xref="alg1.l6a.m1.1.1.3.4">…</ci><apply id="alg1.l6a.m1.1.1.3.5.cmml" xref="alg1.l6a.m1.1.1.3.5"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.5.1.cmml" xref="alg1.l6a.m1.1.1.3.5">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.5.2.cmml" xref="alg1.l6a.m1.1.1.3.5.2">𝑒</ci><apply id="alg1.l6a.m1.1.1.3.5.3.cmml" xref="alg1.l6a.m1.1.1.3.5.3"><csymbol cd="ambiguous" id="alg1.l6a.m1.1.1.3.5.3.1.cmml" xref="alg1.l6a.m1.1.1.3.5.3">subscript</csymbol><ci id="alg1.l6a.m1.1.1.3.5.3.2.cmml" xref="alg1.l6a.m1.1.1.3.5.3.2">𝑣</ci><ci id="alg1.l6a.m1.1.1.3.5.3.3.cmml" xref="alg1.l6a.m1.1.1.3.5.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6a.m1.1c">e_{x}=e_{q}\oplus e_{v_{1}}\oplus\ldots\oplus e_{v_{k}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6a.m1.1d">italic_e start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = italic_e start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ⊕ italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ⊕ … ⊕ italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l6a.3" style="font-size:90%;">; </span><span class="ltx_text" id="alg1.l6a.4" style="font-size:90%;float:right;">/* Concatenate embeddings of neighbors and query */
</span>
</div>
<div class="ltx_listingline" id="alg1.l7a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7a.1.1.1" style="font-size:80%;">7:</span></span><span class="ltx_text" id="alg1.l7a.2" style="font-size:90%;">     </span><math alttext="y=\mathcal{D}_{f}(e_{x})" class="ltx_Math" display="inline" id="alg1.l7a.m1.1"><semantics id="alg1.l7a.m1.1a"><mrow id="alg1.l7a.m1.1.1" xref="alg1.l7a.m1.1.1.cmml"><mi id="alg1.l7a.m1.1.1.3" mathsize="90%" xref="alg1.l7a.m1.1.1.3.cmml">y</mi><mo id="alg1.l7a.m1.1.1.2" mathsize="90%" xref="alg1.l7a.m1.1.1.2.cmml">=</mo><mrow id="alg1.l7a.m1.1.1.1" xref="alg1.l7a.m1.1.1.1.cmml"><msub id="alg1.l7a.m1.1.1.1.3" xref="alg1.l7a.m1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l7a.m1.1.1.1.3.2" mathsize="90%" xref="alg1.l7a.m1.1.1.1.3.2.cmml">𝒟</mi><mi id="alg1.l7a.m1.1.1.1.3.3" mathsize="90%" xref="alg1.l7a.m1.1.1.1.3.3.cmml">f</mi></msub><mo id="alg1.l7a.m1.1.1.1.2" xref="alg1.l7a.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l7a.m1.1.1.1.1.1" xref="alg1.l7a.m1.1.1.1.1.1.1.cmml"><mo id="alg1.l7a.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg1.l7a.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l7a.m1.1.1.1.1.1.1" xref="alg1.l7a.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l7a.m1.1.1.1.1.1.1.2" mathsize="90%" xref="alg1.l7a.m1.1.1.1.1.1.1.2.cmml">e</mi><mi id="alg1.l7a.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg1.l7a.m1.1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="alg1.l7a.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg1.l7a.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7a.m1.1b"><apply id="alg1.l7a.m1.1.1.cmml" xref="alg1.l7a.m1.1.1"><eq id="alg1.l7a.m1.1.1.2.cmml" xref="alg1.l7a.m1.1.1.2"></eq><ci id="alg1.l7a.m1.1.1.3.cmml" xref="alg1.l7a.m1.1.1.3">𝑦</ci><apply id="alg1.l7a.m1.1.1.1.cmml" xref="alg1.l7a.m1.1.1.1"><times id="alg1.l7a.m1.1.1.1.2.cmml" xref="alg1.l7a.m1.1.1.1.2"></times><apply id="alg1.l7a.m1.1.1.1.3.cmml" xref="alg1.l7a.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l7a.m1.1.1.1.3.1.cmml" xref="alg1.l7a.m1.1.1.1.3">subscript</csymbol><ci id="alg1.l7a.m1.1.1.1.3.2.cmml" xref="alg1.l7a.m1.1.1.1.3.2">𝒟</ci><ci id="alg1.l7a.m1.1.1.1.3.3.cmml" xref="alg1.l7a.m1.1.1.1.3.3">𝑓</ci></apply><apply id="alg1.l7a.m1.1.1.1.1.1.1.cmml" xref="alg1.l7a.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l7a.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l7a.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l7a.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l7a.m1.1.1.1.1.1.1.2">𝑒</ci><ci id="alg1.l7a.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l7a.m1.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7a.m1.1c">y=\mathcal{D}_{f}(e_{x})</annotation><annotation encoding="application/x-llamapun" id="alg1.l7a.m1.1d">italic_y = caligraphic_D start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT ( italic_e start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg1.l7a.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l8a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8a.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text" id="alg1.l8a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l8a.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg1.l8a.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l8a.5" style="font-size:90%;">if</span>
</div>
<div class="ltx_listingline" id="alg1.l9a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9a.1.1.1" style="font-size:80%;">9:</span></span><span class="ltx_text" id="alg1.l9a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg1.l9a.3" style="font-size:90%;">return</span><span class="ltx_text" id="alg1.l9a.4" style="font-size:90%;">  </span><math alttext="y" class="ltx_Math" display="inline" id="alg1.l9a.m1.1"><semantics id="alg1.l9a.m1.1a"><mi id="alg1.l9a.m1.1.1" mathsize="90%" xref="alg1.l9a.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg1.l9a.m1.1b"><ci id="alg1.l9a.m1.1.1.cmml" xref="alg1.l9a.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9a.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg1.l9a.m1.1d">italic_y</annotation></semantics></math><span class="ltx_text" id="alg1.l9a.5" style="font-size:90%;">;
</span>
</div>
</div>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Query-based Fusion</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The simplest and most direct fusion technique is query-based fusion, which integrates the retrieved information with input queries to generate responses.
The query-based fusion can be further categorized into two sub-classes according to the type of concatenated information, i.e., text concatenation and feature concatenation.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Text concatenation involves performing query-based fusion with raw texts, making it particularly suitable for contemporary LLMs like GPT-4.
These models function as black-box systems with limited interaction capabilities, typically offering only API access to users.
Existing works <cite class="ltx_cite ltx_citemacro_citep">(Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>; Lewis
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib88" title="">2020</a>; Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib123" title="">2023b</a>)</cite> directly concatenate the input with the top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_k</annotation></semantics></math> retrieved sentences/documents to form the query for generators.
To better use the in-context learning capability of LLMs, some works <cite class="ltx_cite ltx_citemacro_citep">(Fabbri
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib35" title="">2020</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib146" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib91" title="">2023b</a>; Vu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib142" title="">2023</a>)</cite> design effective prompt templates to integrate retrieved information and inputs.
To address the issue of lengthy inputs after concatenating retrievals, recent studies <cite class="ltx_cite ltx_citemacro_citep">(Lyu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib102" title="">2023</a>; Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib160" title="">2023b</a>; Arefeen
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib6" title="">2023</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib151" title="">2023a</a>; Liu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib97" title="">2023b</a>)</cite> have introduced methods for assigning importance weights to elements within the retrieved knowledge base and filtering out less relevant contexts based on these weights.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">The feature concatenation involves merging the encoded retrievals with the input features.
A simple yet effective approach is FID <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib67" title="">2021</a>)</cite>, which first encodes the retrieved passages into sparse or dense representations and then takes the concatenated features as the input for a generator.
The state-of-the-art performance of the FID demonstrates the efficacy of feature concatenation.
The follow-up works <cite class="ltx_cite ltx_citemacro_citep">(Sachan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib128" title="">2021</a>; Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib49" title="">2023</a>; de Jong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib26" title="">2023b</a>; Izacard
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib68" title="">2023</a>; Liu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib98" title="">2023a</a>)</cite> further improve the FID by jointly tuning the retriever and the encoder, which can enhance the retrieved knowledge’s representations.
Besides, Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib15" title="">2022b</a>)</cite> concatenate the representations of related knowledge as demonstrations for prompt learning, yielding better generalization.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg1a" title="Algorithm 1 ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> presents how to leverage query-based fusions to fuse retrieved knowledge.
For those using text concatenation <cite class="ltx_cite ltx_citemacro_citep">(Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>; Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib123" title="">2023b</a>)</cite>, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg1a" title="Algorithm 1 ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> first concatenates the retrieved texts and inputs (line 2), then feeds the concatenated input into the generator.
Notably, since there is a limit to the maximum input length of existing language models, concatenating too many retrievals would result in a truncation of the concatenated input, which may cut the given input.
Therefore, designing the prompt template is the key step for this branch of work.
For those using feature concatenation <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib67" title="">2021</a>; Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib49" title="">2023</a>)</cite>, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg1a" title="Algorithm 1 ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> first leverages an encoder to obtain the feature (line 5), then concatenates the feature of input and retrievals (line 6), finally passes the concatenated feature into a decoder model (line 7).
This branch of work generally incurs high memory costs due to the long sequence length.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Logits-based Fusion</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The logits-based fusion refers to incorporating the retrieved knowledge into the output layers.
Basically, retrieved knowledge would be fed into the same model to obtain the logits for enhancing or calibrating the predictions.
Therefore, logits-based fusion can be categorized into two branches, i.e., ensemble-based fusion and calibration-based fusion.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Ensemble-based fusion treats the logits from the retrieved knowledge as part of an ensemble of predictions.
Such ensemble-based fusion can significantly improve the generalization and robustness of the model <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib159" title="">2023</a>; Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib82" title="">2020b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib81" title="">a</a>)</cite>.
One notable work of ensemble-based fusion is kNN-LM <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib82" title="">2020b</a>)</cite>, which aggregates the logits of the top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_k</annotation></semantics></math> nearest neighbors’ targets and then interpolates the final predictions.
Similar to kNN-LM, Khandelwal et al. <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib81" title="">2020a</a>)</cite> propose kNN-MT to enhance the machine translation using retrievals’ logits, which is also followed by a branch of works <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib173" title="">2021</a>; Huang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib65" title="">2023b</a>)</cite>.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2a">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2a.3.1.1">Algorithm 2</span> </span> <span class="ltx_text" id="alg2a.4.2" style="font-size:90%;">Logits-based Fusions.</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg2a.5">
<div class="ltx_listingline" id="alg2.l0b">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0b.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg2.l0b.2" style="font-size:90%;">  A query input </span><math alttext="q" class="ltx_Math" display="inline" id="alg2.l0b.m1.1"><semantics id="alg2.l0b.m1.1a"><mi id="alg2.l0b.m1.1.1" mathsize="90%" xref="alg2.l0b.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg2.l0b.m1.1b"><ci id="alg2.l0b.m1.1.1.cmml" xref="alg2.l0b.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0b.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg2.l0b.m1.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="alg2.l0b.3" style="font-size:90%;">, top-</span><math alttext="k" class="ltx_Math" display="inline" id="alg2.l0b.m2.1"><semantics id="alg2.l0b.m2.1a"><mi id="alg2.l0b.m2.1.1" mathsize="90%" xref="alg2.l0b.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l0b.m2.1b"><ci id="alg2.l0b.m2.1.1.cmml" xref="alg2.l0b.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0b.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l0b.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="alg2.l0b.4" style="font-size:90%;"> nearest neighbor knowledge </span><math alttext="\{v_{1},\ldots,v_{k}\}" class="ltx_Math" display="inline" id="alg2.l0b.m3.3"><semantics id="alg2.l0b.m3.3a"><mrow id="alg2.l0b.m3.3.3.2" xref="alg2.l0b.m3.3.3.3.cmml"><mo id="alg2.l0b.m3.3.3.2.3" maxsize="90%" minsize="90%" xref="alg2.l0b.m3.3.3.3.cmml">{</mo><msub id="alg2.l0b.m3.2.2.1.1" xref="alg2.l0b.m3.2.2.1.1.cmml"><mi id="alg2.l0b.m3.2.2.1.1.2" mathsize="90%" xref="alg2.l0b.m3.2.2.1.1.2.cmml">v</mi><mn id="alg2.l0b.m3.2.2.1.1.3" mathsize="90%" xref="alg2.l0b.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="alg2.l0b.m3.3.3.2.4" mathsize="90%" xref="alg2.l0b.m3.3.3.3.cmml">,</mo><mi id="alg2.l0b.m3.1.1" mathsize="90%" mathvariant="normal" xref="alg2.l0b.m3.1.1.cmml">…</mi><mo id="alg2.l0b.m3.3.3.2.5" mathsize="90%" xref="alg2.l0b.m3.3.3.3.cmml">,</mo><msub id="alg2.l0b.m3.3.3.2.2" xref="alg2.l0b.m3.3.3.2.2.cmml"><mi id="alg2.l0b.m3.3.3.2.2.2" mathsize="90%" xref="alg2.l0b.m3.3.3.2.2.2.cmml">v</mi><mi id="alg2.l0b.m3.3.3.2.2.3" mathsize="90%" xref="alg2.l0b.m3.3.3.2.2.3.cmml">k</mi></msub><mo id="alg2.l0b.m3.3.3.2.6" maxsize="90%" minsize="90%" xref="alg2.l0b.m3.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg2.l0b.m3.3b"><set id="alg2.l0b.m3.3.3.3.cmml" xref="alg2.l0b.m3.3.3.2"><apply id="alg2.l0b.m3.2.2.1.1.cmml" xref="alg2.l0b.m3.2.2.1.1"><csymbol cd="ambiguous" id="alg2.l0b.m3.2.2.1.1.1.cmml" xref="alg2.l0b.m3.2.2.1.1">subscript</csymbol><ci id="alg2.l0b.m3.2.2.1.1.2.cmml" xref="alg2.l0b.m3.2.2.1.1.2">𝑣</ci><cn id="alg2.l0b.m3.2.2.1.1.3.cmml" type="integer" xref="alg2.l0b.m3.2.2.1.1.3">1</cn></apply><ci id="alg2.l0b.m3.1.1.cmml" xref="alg2.l0b.m3.1.1">…</ci><apply id="alg2.l0b.m3.3.3.2.2.cmml" xref="alg2.l0b.m3.3.3.2.2"><csymbol cd="ambiguous" id="alg2.l0b.m3.3.3.2.2.1.cmml" xref="alg2.l0b.m3.3.3.2.2">subscript</csymbol><ci id="alg2.l0b.m3.3.3.2.2.2.cmml" xref="alg2.l0b.m3.3.3.2.2.2">𝑣</ci><ci id="alg2.l0b.m3.3.3.2.2.3.cmml" xref="alg2.l0b.m3.3.3.2.2.3">𝑘</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0b.m3.3c">\{v_{1},\ldots,v_{k}\}</annotation><annotation encoding="application/x-llamapun" id="alg2.l0b.m3.3d">{ italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg2.l0b.5" style="font-size:90%;">, the generator </span><math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg2.l0b.m4.1"><semantics id="alg2.l0b.m4.1a"><mi class="ltx_font_mathcaligraphic" id="alg2.l0b.m4.1.1" mathsize="90%" xref="alg2.l0b.m4.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg2.l0b.m4.1b"><ci id="alg2.l0b.m4.1.1.cmml" xref="alg2.l0b.m4.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0b.m4.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg2.l0b.m4.1d">caligraphic_G</annotation></semantics></math><span class="ltx_text" id="alg2.l0b.6" style="font-size:90%;">.</span>
</div>
<div class="ltx_listingline" id="alg2.l0c">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0c.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg2.l0c.2" style="font-size:90%;">  Generated response </span><math alttext="y" class="ltx_Math" display="inline" id="alg2.l0c.m1.1"><semantics id="alg2.l0c.m1.1a"><mi id="alg2.l0c.m1.1.1" mathsize="90%" xref="alg2.l0c.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg2.l0c.m1.1b"><ci id="alg2.l0c.m1.1.1.cmml" xref="alg2.l0c.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0c.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg2.l0c.m1.1d">italic_y</annotation></semantics></math><span class="ltx_text" id="alg2.l0c.3" style="font-size:90%;">.
</span>
</div>
<div class="ltx_listingline" id="alg2.l1a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l1a.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text" id="alg2.l1a.2" style="font-size:90%;">  </span><math alttext="y_{q}=\mathcal{G}(q)" class="ltx_Math" display="inline" id="alg2.l1a.m1.1"><semantics id="alg2.l1a.m1.1a"><mrow id="alg2.l1a.m1.1.2" xref="alg2.l1a.m1.1.2.cmml"><msub id="alg2.l1a.m1.1.2.2" xref="alg2.l1a.m1.1.2.2.cmml"><mi id="alg2.l1a.m1.1.2.2.2" mathsize="90%" xref="alg2.l1a.m1.1.2.2.2.cmml">y</mi><mi id="alg2.l1a.m1.1.2.2.3" mathsize="90%" xref="alg2.l1a.m1.1.2.2.3.cmml">q</mi></msub><mo id="alg2.l1a.m1.1.2.1" mathsize="90%" xref="alg2.l1a.m1.1.2.1.cmml">=</mo><mrow id="alg2.l1a.m1.1.2.3" xref="alg2.l1a.m1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg2.l1a.m1.1.2.3.2" mathsize="90%" xref="alg2.l1a.m1.1.2.3.2.cmml">𝒢</mi><mo id="alg2.l1a.m1.1.2.3.1" xref="alg2.l1a.m1.1.2.3.1.cmml">⁢</mo><mrow id="alg2.l1a.m1.1.2.3.3.2" xref="alg2.l1a.m1.1.2.3.cmml"><mo id="alg2.l1a.m1.1.2.3.3.2.1" maxsize="90%" minsize="90%" xref="alg2.l1a.m1.1.2.3.cmml">(</mo><mi id="alg2.l1a.m1.1.1" mathsize="90%" xref="alg2.l1a.m1.1.1.cmml">q</mi><mo id="alg2.l1a.m1.1.2.3.3.2.2" maxsize="90%" minsize="90%" xref="alg2.l1a.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l1a.m1.1b"><apply id="alg2.l1a.m1.1.2.cmml" xref="alg2.l1a.m1.1.2"><eq id="alg2.l1a.m1.1.2.1.cmml" xref="alg2.l1a.m1.1.2.1"></eq><apply id="alg2.l1a.m1.1.2.2.cmml" xref="alg2.l1a.m1.1.2.2"><csymbol cd="ambiguous" id="alg2.l1a.m1.1.2.2.1.cmml" xref="alg2.l1a.m1.1.2.2">subscript</csymbol><ci id="alg2.l1a.m1.1.2.2.2.cmml" xref="alg2.l1a.m1.1.2.2.2">𝑦</ci><ci id="alg2.l1a.m1.1.2.2.3.cmml" xref="alg2.l1a.m1.1.2.2.3">𝑞</ci></apply><apply id="alg2.l1a.m1.1.2.3.cmml" xref="alg2.l1a.m1.1.2.3"><times id="alg2.l1a.m1.1.2.3.1.cmml" xref="alg2.l1a.m1.1.2.3.1"></times><ci id="alg2.l1a.m1.1.2.3.2.cmml" xref="alg2.l1a.m1.1.2.3.2">𝒢</ci><ci id="alg2.l1a.m1.1.1.cmml" xref="alg2.l1a.m1.1.1">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l1a.m1.1c">y_{q}=\mathcal{G}(q)</annotation><annotation encoding="application/x-llamapun" id="alg2.l1a.m1.1d">italic_y start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = caligraphic_G ( italic_q )</annotation></semantics></math><span class="ltx_text" id="alg2.l1a.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg2.l2a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l2a.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text" id="alg2.l2a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l2a.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg2.l2a.4" style="font-size:90%;"> </span><math alttext="j" class="ltx_Math" display="inline" id="alg2.l2a.m1.1"><semantics id="alg2.l2a.m1.1a"><mi id="alg2.l2a.m1.1.1" mathsize="90%" xref="alg2.l2a.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg2.l2a.m1.1b"><ci id="alg2.l2a.m1.1.1.cmml" xref="alg2.l2a.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2a.m1.1c">j</annotation><annotation encoding="application/x-llamapun" id="alg2.l2a.m1.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="alg2.l2a.5" style="font-size:90%;"> from </span><math alttext="1" class="ltx_Math" display="inline" id="alg2.l2a.m2.1"><semantics id="alg2.l2a.m2.1a"><mn id="alg2.l2a.m2.1.1" mathsize="90%" xref="alg2.l2a.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="alg2.l2a.m2.1b"><cn id="alg2.l2a.m2.1.1.cmml" type="integer" xref="alg2.l2a.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2a.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="alg2.l2a.m2.1d">1</annotation></semantics></math><span class="ltx_text" id="alg2.l2a.6" style="font-size:90%;"> to </span><math alttext="k" class="ltx_Math" display="inline" id="alg2.l2a.m3.1"><semantics id="alg2.l2a.m3.1a"><mi id="alg2.l2a.m3.1.1" mathsize="90%" xref="alg2.l2a.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l2a.m3.1b"><ci id="alg2.l2a.m3.1.1.cmml" xref="alg2.l2a.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2a.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l2a.m3.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="alg2.l2a.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg2.l2a.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg2.l2a.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg2.l3a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l3a.1.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text" id="alg2.l3a.2" style="font-size:90%;">     </span><math alttext="y_{v_{j}}=\mathcal{G}(v_{j})" class="ltx_Math" display="inline" id="alg2.l3a.m1.1"><semantics id="alg2.l3a.m1.1a"><mrow id="alg2.l3a.m1.1.1" xref="alg2.l3a.m1.1.1.cmml"><msub id="alg2.l3a.m1.1.1.3" xref="alg2.l3a.m1.1.1.3.cmml"><mi id="alg2.l3a.m1.1.1.3.2" mathsize="90%" xref="alg2.l3a.m1.1.1.3.2.cmml">y</mi><msub id="alg2.l3a.m1.1.1.3.3" xref="alg2.l3a.m1.1.1.3.3.cmml"><mi id="alg2.l3a.m1.1.1.3.3.2" mathsize="90%" xref="alg2.l3a.m1.1.1.3.3.2.cmml">v</mi><mi id="alg2.l3a.m1.1.1.3.3.3" mathsize="90%" xref="alg2.l3a.m1.1.1.3.3.3.cmml">j</mi></msub></msub><mo id="alg2.l3a.m1.1.1.2" mathsize="90%" xref="alg2.l3a.m1.1.1.2.cmml">=</mo><mrow id="alg2.l3a.m1.1.1.1" xref="alg2.l3a.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg2.l3a.m1.1.1.1.3" mathsize="90%" xref="alg2.l3a.m1.1.1.1.3.cmml">𝒢</mi><mo id="alg2.l3a.m1.1.1.1.2" xref="alg2.l3a.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg2.l3a.m1.1.1.1.1.1" xref="alg2.l3a.m1.1.1.1.1.1.1.cmml"><mo id="alg2.l3a.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg2.l3a.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg2.l3a.m1.1.1.1.1.1.1" xref="alg2.l3a.m1.1.1.1.1.1.1.cmml"><mi id="alg2.l3a.m1.1.1.1.1.1.1.2" mathsize="90%" xref="alg2.l3a.m1.1.1.1.1.1.1.2.cmml">v</mi><mi id="alg2.l3a.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg2.l3a.m1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="alg2.l3a.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg2.l3a.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l3a.m1.1b"><apply id="alg2.l3a.m1.1.1.cmml" xref="alg2.l3a.m1.1.1"><eq id="alg2.l3a.m1.1.1.2.cmml" xref="alg2.l3a.m1.1.1.2"></eq><apply id="alg2.l3a.m1.1.1.3.cmml" xref="alg2.l3a.m1.1.1.3"><csymbol cd="ambiguous" id="alg2.l3a.m1.1.1.3.1.cmml" xref="alg2.l3a.m1.1.1.3">subscript</csymbol><ci id="alg2.l3a.m1.1.1.3.2.cmml" xref="alg2.l3a.m1.1.1.3.2">𝑦</ci><apply id="alg2.l3a.m1.1.1.3.3.cmml" xref="alg2.l3a.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg2.l3a.m1.1.1.3.3.1.cmml" xref="alg2.l3a.m1.1.1.3.3">subscript</csymbol><ci id="alg2.l3a.m1.1.1.3.3.2.cmml" xref="alg2.l3a.m1.1.1.3.3.2">𝑣</ci><ci id="alg2.l3a.m1.1.1.3.3.3.cmml" xref="alg2.l3a.m1.1.1.3.3.3">𝑗</ci></apply></apply><apply id="alg2.l3a.m1.1.1.1.cmml" xref="alg2.l3a.m1.1.1.1"><times id="alg2.l3a.m1.1.1.1.2.cmml" xref="alg2.l3a.m1.1.1.1.2"></times><ci id="alg2.l3a.m1.1.1.1.3.cmml" xref="alg2.l3a.m1.1.1.1.3">𝒢</ci><apply id="alg2.l3a.m1.1.1.1.1.1.1.cmml" xref="alg2.l3a.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l3a.m1.1.1.1.1.1.1.1.cmml" xref="alg2.l3a.m1.1.1.1.1.1">subscript</csymbol><ci id="alg2.l3a.m1.1.1.1.1.1.1.2.cmml" xref="alg2.l3a.m1.1.1.1.1.1.1.2">𝑣</ci><ci id="alg2.l3a.m1.1.1.1.1.1.1.3.cmml" xref="alg2.l3a.m1.1.1.1.1.1.1.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3a.m1.1c">y_{v_{j}}=\mathcal{G}(v_{j})</annotation><annotation encoding="application/x-llamapun" id="alg2.l3a.m1.1d">italic_y start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT = caligraphic_G ( italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg2.l3a.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg2.l4a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l4a.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text" id="alg2.l4a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l4a.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg2.l4a.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg2.l4a.5" style="font-size:90%;">for</span>
</div>
<div class="ltx_listingline" id="alg2.l5a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l5a.1.1.1" style="font-size:80%;">5:</span></span><span class="ltx_text" id="alg2.l5a.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l5a.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg2.l5a.4" style="font-size:90%;"> Use ensemble </span><span class="ltx_text ltx_font_bold" id="alg2.l5a.5" style="font-size:90%;">then</span><span class="ltx_text" id="alg2.l5a.6" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg2.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l6.1.1.1" style="font-size:80%;">6:</span></span><span class="ltx_text" id="alg2.l6.2" style="font-size:90%;">     </span><math alttext="y=\lambda\sum_{j}y_{v_{j}}+(1-\lambda)y_{q}" class="ltx_Math" display="inline" id="alg2.l6.m1.1"><semantics id="alg2.l6.m1.1a"><mrow id="alg2.l6.m1.1.1" xref="alg2.l6.m1.1.1.cmml"><mi id="alg2.l6.m1.1.1.3" mathsize="90%" xref="alg2.l6.m1.1.1.3.cmml">y</mi><mo id="alg2.l6.m1.1.1.2" mathsize="90%" xref="alg2.l6.m1.1.1.2.cmml">=</mo><mrow id="alg2.l6.m1.1.1.1" xref="alg2.l6.m1.1.1.1.cmml"><mrow id="alg2.l6.m1.1.1.1.3" xref="alg2.l6.m1.1.1.1.3.cmml"><mi id="alg2.l6.m1.1.1.1.3.2" mathsize="90%" xref="alg2.l6.m1.1.1.1.3.2.cmml">λ</mi><mo id="alg2.l6.m1.1.1.1.3.1" xref="alg2.l6.m1.1.1.1.3.1.cmml">⁢</mo><mrow id="alg2.l6.m1.1.1.1.3.3" xref="alg2.l6.m1.1.1.1.3.3.cmml"><msub id="alg2.l6.m1.1.1.1.3.3.1" xref="alg2.l6.m1.1.1.1.3.3.1.cmml"><mo id="alg2.l6.m1.1.1.1.3.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="alg2.l6.m1.1.1.1.3.3.1.2.cmml">∑</mo><mi id="alg2.l6.m1.1.1.1.3.3.1.3" mathsize="90%" xref="alg2.l6.m1.1.1.1.3.3.1.3.cmml">j</mi></msub><msub id="alg2.l6.m1.1.1.1.3.3.2" xref="alg2.l6.m1.1.1.1.3.3.2.cmml"><mi id="alg2.l6.m1.1.1.1.3.3.2.2" mathsize="90%" xref="alg2.l6.m1.1.1.1.3.3.2.2.cmml">y</mi><msub id="alg2.l6.m1.1.1.1.3.3.2.3" xref="alg2.l6.m1.1.1.1.3.3.2.3.cmml"><mi id="alg2.l6.m1.1.1.1.3.3.2.3.2" mathsize="90%" xref="alg2.l6.m1.1.1.1.3.3.2.3.2.cmml">v</mi><mi id="alg2.l6.m1.1.1.1.3.3.2.3.3" mathsize="90%" xref="alg2.l6.m1.1.1.1.3.3.2.3.3.cmml">j</mi></msub></msub></mrow></mrow><mo id="alg2.l6.m1.1.1.1.2" mathsize="90%" xref="alg2.l6.m1.1.1.1.2.cmml">+</mo><mrow id="alg2.l6.m1.1.1.1.1" xref="alg2.l6.m1.1.1.1.1.cmml"><mrow id="alg2.l6.m1.1.1.1.1.1.1" xref="alg2.l6.m1.1.1.1.1.1.1.1.cmml"><mo id="alg2.l6.m1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg2.l6.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg2.l6.m1.1.1.1.1.1.1.1" xref="alg2.l6.m1.1.1.1.1.1.1.1.cmml"><mn id="alg2.l6.m1.1.1.1.1.1.1.1.2" mathsize="90%" xref="alg2.l6.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="alg2.l6.m1.1.1.1.1.1.1.1.1" mathsize="90%" xref="alg2.l6.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="alg2.l6.m1.1.1.1.1.1.1.1.3" mathsize="90%" xref="alg2.l6.m1.1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo id="alg2.l6.m1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg2.l6.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="alg2.l6.m1.1.1.1.1.2" xref="alg2.l6.m1.1.1.1.1.2.cmml">⁢</mo><msub id="alg2.l6.m1.1.1.1.1.3" xref="alg2.l6.m1.1.1.1.1.3.cmml"><mi id="alg2.l6.m1.1.1.1.1.3.2" mathsize="90%" xref="alg2.l6.m1.1.1.1.1.3.2.cmml">y</mi><mi id="alg2.l6.m1.1.1.1.1.3.3" mathsize="90%" xref="alg2.l6.m1.1.1.1.1.3.3.cmml">q</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l6.m1.1b"><apply id="alg2.l6.m1.1.1.cmml" xref="alg2.l6.m1.1.1"><eq id="alg2.l6.m1.1.1.2.cmml" xref="alg2.l6.m1.1.1.2"></eq><ci id="alg2.l6.m1.1.1.3.cmml" xref="alg2.l6.m1.1.1.3">𝑦</ci><apply id="alg2.l6.m1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1"><plus id="alg2.l6.m1.1.1.1.2.cmml" xref="alg2.l6.m1.1.1.1.2"></plus><apply id="alg2.l6.m1.1.1.1.3.cmml" xref="alg2.l6.m1.1.1.1.3"><times id="alg2.l6.m1.1.1.1.3.1.cmml" xref="alg2.l6.m1.1.1.1.3.1"></times><ci id="alg2.l6.m1.1.1.1.3.2.cmml" xref="alg2.l6.m1.1.1.1.3.2">𝜆</ci><apply id="alg2.l6.m1.1.1.1.3.3.cmml" xref="alg2.l6.m1.1.1.1.3.3"><apply id="alg2.l6.m1.1.1.1.3.3.1.cmml" xref="alg2.l6.m1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg2.l6.m1.1.1.1.3.3.1.1.cmml" xref="alg2.l6.m1.1.1.1.3.3.1">subscript</csymbol><sum id="alg2.l6.m1.1.1.1.3.3.1.2.cmml" xref="alg2.l6.m1.1.1.1.3.3.1.2"></sum><ci id="alg2.l6.m1.1.1.1.3.3.1.3.cmml" xref="alg2.l6.m1.1.1.1.3.3.1.3">𝑗</ci></apply><apply id="alg2.l6.m1.1.1.1.3.3.2.cmml" xref="alg2.l6.m1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="alg2.l6.m1.1.1.1.3.3.2.1.cmml" xref="alg2.l6.m1.1.1.1.3.3.2">subscript</csymbol><ci id="alg2.l6.m1.1.1.1.3.3.2.2.cmml" xref="alg2.l6.m1.1.1.1.3.3.2.2">𝑦</ci><apply id="alg2.l6.m1.1.1.1.3.3.2.3.cmml" xref="alg2.l6.m1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg2.l6.m1.1.1.1.3.3.2.3.1.cmml" xref="alg2.l6.m1.1.1.1.3.3.2.3">subscript</csymbol><ci id="alg2.l6.m1.1.1.1.3.3.2.3.2.cmml" xref="alg2.l6.m1.1.1.1.3.3.2.3.2">𝑣</ci><ci id="alg2.l6.m1.1.1.1.3.3.2.3.3.cmml" xref="alg2.l6.m1.1.1.1.3.3.2.3.3">𝑗</ci></apply></apply></apply></apply><apply id="alg2.l6.m1.1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1.1"><times id="alg2.l6.m1.1.1.1.1.2.cmml" xref="alg2.l6.m1.1.1.1.1.2"></times><apply id="alg2.l6.m1.1.1.1.1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1.1.1.1"><minus id="alg2.l6.m1.1.1.1.1.1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1.1.1.1.1.1"></minus><cn id="alg2.l6.m1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="alg2.l6.m1.1.1.1.1.1.1.1.2">1</cn><ci id="alg2.l6.m1.1.1.1.1.1.1.1.3.cmml" xref="alg2.l6.m1.1.1.1.1.1.1.1.3">𝜆</ci></apply><apply id="alg2.l6.m1.1.1.1.1.3.cmml" xref="alg2.l6.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg2.l6.m1.1.1.1.1.3.1.cmml" xref="alg2.l6.m1.1.1.1.1.3">subscript</csymbol><ci id="alg2.l6.m1.1.1.1.1.3.2.cmml" xref="alg2.l6.m1.1.1.1.1.3.2">𝑦</ci><ci id="alg2.l6.m1.1.1.1.1.3.3.cmml" xref="alg2.l6.m1.1.1.1.1.3.3">𝑞</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l6.m1.1c">y=\lambda\sum_{j}y_{v_{j}}+(1-\lambda)y_{q}</annotation><annotation encoding="application/x-llamapun" id="alg2.l6.m1.1d">italic_y = italic_λ ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT + ( 1 - italic_λ ) italic_y start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg2.l6.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg2.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l7.1.1.1" style="font-size:80%;">7:</span></span><span class="ltx_text" id="alg2.l7.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l7.3" style="font-size:90%;">else</span><span class="ltx_text" id="alg2.l7.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg2.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l8.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text" id="alg2.l8.2" style="font-size:90%;">     </span><math alttext="\lambda_{t}=Calibrate(y_{q},y_{v_{1}},\ldots,y_{v_{k}})" class="ltx_Math" display="inline" id="alg2.l8.m1.4"><semantics id="alg2.l8.m1.4a"><mrow id="alg2.l8.m1.4.4" xref="alg2.l8.m1.4.4.cmml"><msub id="alg2.l8.m1.4.4.5" xref="alg2.l8.m1.4.4.5.cmml"><mi id="alg2.l8.m1.4.4.5.2" mathsize="90%" xref="alg2.l8.m1.4.4.5.2.cmml">λ</mi><mi id="alg2.l8.m1.4.4.5.3" mathsize="90%" xref="alg2.l8.m1.4.4.5.3.cmml">t</mi></msub><mo id="alg2.l8.m1.4.4.4" mathsize="90%" xref="alg2.l8.m1.4.4.4.cmml">=</mo><mrow id="alg2.l8.m1.4.4.3" xref="alg2.l8.m1.4.4.3.cmml"><mi id="alg2.l8.m1.4.4.3.5" mathsize="90%" xref="alg2.l8.m1.4.4.3.5.cmml">C</mi><mo id="alg2.l8.m1.4.4.3.4" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.6" mathsize="90%" xref="alg2.l8.m1.4.4.3.6.cmml">a</mi><mo id="alg2.l8.m1.4.4.3.4a" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.7" mathsize="90%" xref="alg2.l8.m1.4.4.3.7.cmml">l</mi><mo id="alg2.l8.m1.4.4.3.4b" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.8" mathsize="90%" xref="alg2.l8.m1.4.4.3.8.cmml">i</mi><mo id="alg2.l8.m1.4.4.3.4c" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.9" mathsize="90%" xref="alg2.l8.m1.4.4.3.9.cmml">b</mi><mo id="alg2.l8.m1.4.4.3.4d" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.10" mathsize="90%" xref="alg2.l8.m1.4.4.3.10.cmml">r</mi><mo id="alg2.l8.m1.4.4.3.4e" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.11" mathsize="90%" xref="alg2.l8.m1.4.4.3.11.cmml">a</mi><mo id="alg2.l8.m1.4.4.3.4f" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.12" mathsize="90%" xref="alg2.l8.m1.4.4.3.12.cmml">t</mi><mo id="alg2.l8.m1.4.4.3.4g" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mi id="alg2.l8.m1.4.4.3.13" mathsize="90%" xref="alg2.l8.m1.4.4.3.13.cmml">e</mi><mo id="alg2.l8.m1.4.4.3.4h" xref="alg2.l8.m1.4.4.3.4.cmml">⁢</mo><mrow id="alg2.l8.m1.4.4.3.3.3" xref="alg2.l8.m1.4.4.3.3.4.cmml"><mo id="alg2.l8.m1.4.4.3.3.3.4" maxsize="90%" minsize="90%" xref="alg2.l8.m1.4.4.3.3.4.cmml">(</mo><msub id="alg2.l8.m1.2.2.1.1.1.1" xref="alg2.l8.m1.2.2.1.1.1.1.cmml"><mi id="alg2.l8.m1.2.2.1.1.1.1.2" mathsize="90%" xref="alg2.l8.m1.2.2.1.1.1.1.2.cmml">y</mi><mi id="alg2.l8.m1.2.2.1.1.1.1.3" mathsize="90%" xref="alg2.l8.m1.2.2.1.1.1.1.3.cmml">q</mi></msub><mo id="alg2.l8.m1.4.4.3.3.3.5" mathsize="90%" xref="alg2.l8.m1.4.4.3.3.4.cmml">,</mo><msub id="alg2.l8.m1.3.3.2.2.2.2" xref="alg2.l8.m1.3.3.2.2.2.2.cmml"><mi id="alg2.l8.m1.3.3.2.2.2.2.2" mathsize="90%" xref="alg2.l8.m1.3.3.2.2.2.2.2.cmml">y</mi><msub id="alg2.l8.m1.3.3.2.2.2.2.3" xref="alg2.l8.m1.3.3.2.2.2.2.3.cmml"><mi id="alg2.l8.m1.3.3.2.2.2.2.3.2" mathsize="90%" xref="alg2.l8.m1.3.3.2.2.2.2.3.2.cmml">v</mi><mn id="alg2.l8.m1.3.3.2.2.2.2.3.3" mathsize="90%" xref="alg2.l8.m1.3.3.2.2.2.2.3.3.cmml">1</mn></msub></msub><mo id="alg2.l8.m1.4.4.3.3.3.6" mathsize="90%" xref="alg2.l8.m1.4.4.3.3.4.cmml">,</mo><mi id="alg2.l8.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg2.l8.m1.1.1.cmml">…</mi><mo id="alg2.l8.m1.4.4.3.3.3.7" mathsize="90%" xref="alg2.l8.m1.4.4.3.3.4.cmml">,</mo><msub id="alg2.l8.m1.4.4.3.3.3.3" xref="alg2.l8.m1.4.4.3.3.3.3.cmml"><mi id="alg2.l8.m1.4.4.3.3.3.3.2" mathsize="90%" xref="alg2.l8.m1.4.4.3.3.3.3.2.cmml">y</mi><msub id="alg2.l8.m1.4.4.3.3.3.3.3" xref="alg2.l8.m1.4.4.3.3.3.3.3.cmml"><mi id="alg2.l8.m1.4.4.3.3.3.3.3.2" mathsize="90%" xref="alg2.l8.m1.4.4.3.3.3.3.3.2.cmml">v</mi><mi id="alg2.l8.m1.4.4.3.3.3.3.3.3" mathsize="90%" xref="alg2.l8.m1.4.4.3.3.3.3.3.3.cmml">k</mi></msub></msub><mo id="alg2.l8.m1.4.4.3.3.3.8" maxsize="90%" minsize="90%" xref="alg2.l8.m1.4.4.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l8.m1.4b"><apply id="alg2.l8.m1.4.4.cmml" xref="alg2.l8.m1.4.4"><eq id="alg2.l8.m1.4.4.4.cmml" xref="alg2.l8.m1.4.4.4"></eq><apply id="alg2.l8.m1.4.4.5.cmml" xref="alg2.l8.m1.4.4.5"><csymbol cd="ambiguous" id="alg2.l8.m1.4.4.5.1.cmml" xref="alg2.l8.m1.4.4.5">subscript</csymbol><ci id="alg2.l8.m1.4.4.5.2.cmml" xref="alg2.l8.m1.4.4.5.2">𝜆</ci><ci id="alg2.l8.m1.4.4.5.3.cmml" xref="alg2.l8.m1.4.4.5.3">𝑡</ci></apply><apply id="alg2.l8.m1.4.4.3.cmml" xref="alg2.l8.m1.4.4.3"><times id="alg2.l8.m1.4.4.3.4.cmml" xref="alg2.l8.m1.4.4.3.4"></times><ci id="alg2.l8.m1.4.4.3.5.cmml" xref="alg2.l8.m1.4.4.3.5">𝐶</ci><ci id="alg2.l8.m1.4.4.3.6.cmml" xref="alg2.l8.m1.4.4.3.6">𝑎</ci><ci id="alg2.l8.m1.4.4.3.7.cmml" xref="alg2.l8.m1.4.4.3.7">𝑙</ci><ci id="alg2.l8.m1.4.4.3.8.cmml" xref="alg2.l8.m1.4.4.3.8">𝑖</ci><ci id="alg2.l8.m1.4.4.3.9.cmml" xref="alg2.l8.m1.4.4.3.9">𝑏</ci><ci id="alg2.l8.m1.4.4.3.10.cmml" xref="alg2.l8.m1.4.4.3.10">𝑟</ci><ci id="alg2.l8.m1.4.4.3.11.cmml" xref="alg2.l8.m1.4.4.3.11">𝑎</ci><ci id="alg2.l8.m1.4.4.3.12.cmml" xref="alg2.l8.m1.4.4.3.12">𝑡</ci><ci id="alg2.l8.m1.4.4.3.13.cmml" xref="alg2.l8.m1.4.4.3.13">𝑒</ci><vector id="alg2.l8.m1.4.4.3.3.4.cmml" xref="alg2.l8.m1.4.4.3.3.3"><apply id="alg2.l8.m1.2.2.1.1.1.1.cmml" xref="alg2.l8.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l8.m1.2.2.1.1.1.1.1.cmml" xref="alg2.l8.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg2.l8.m1.2.2.1.1.1.1.2.cmml" xref="alg2.l8.m1.2.2.1.1.1.1.2">𝑦</ci><ci id="alg2.l8.m1.2.2.1.1.1.1.3.cmml" xref="alg2.l8.m1.2.2.1.1.1.1.3">𝑞</ci></apply><apply id="alg2.l8.m1.3.3.2.2.2.2.cmml" xref="alg2.l8.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg2.l8.m1.3.3.2.2.2.2.1.cmml" xref="alg2.l8.m1.3.3.2.2.2.2">subscript</csymbol><ci id="alg2.l8.m1.3.3.2.2.2.2.2.cmml" xref="alg2.l8.m1.3.3.2.2.2.2.2">𝑦</ci><apply id="alg2.l8.m1.3.3.2.2.2.2.3.cmml" xref="alg2.l8.m1.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="alg2.l8.m1.3.3.2.2.2.2.3.1.cmml" xref="alg2.l8.m1.3.3.2.2.2.2.3">subscript</csymbol><ci id="alg2.l8.m1.3.3.2.2.2.2.3.2.cmml" xref="alg2.l8.m1.3.3.2.2.2.2.3.2">𝑣</ci><cn id="alg2.l8.m1.3.3.2.2.2.2.3.3.cmml" type="integer" xref="alg2.l8.m1.3.3.2.2.2.2.3.3">1</cn></apply></apply><ci id="alg2.l8.m1.1.1.cmml" xref="alg2.l8.m1.1.1">…</ci><apply id="alg2.l8.m1.4.4.3.3.3.3.cmml" xref="alg2.l8.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="alg2.l8.m1.4.4.3.3.3.3.1.cmml" xref="alg2.l8.m1.4.4.3.3.3.3">subscript</csymbol><ci id="alg2.l8.m1.4.4.3.3.3.3.2.cmml" xref="alg2.l8.m1.4.4.3.3.3.3.2">𝑦</ci><apply id="alg2.l8.m1.4.4.3.3.3.3.3.cmml" xref="alg2.l8.m1.4.4.3.3.3.3.3"><csymbol cd="ambiguous" id="alg2.l8.m1.4.4.3.3.3.3.3.1.cmml" xref="alg2.l8.m1.4.4.3.3.3.3.3">subscript</csymbol><ci id="alg2.l8.m1.4.4.3.3.3.3.3.2.cmml" xref="alg2.l8.m1.4.4.3.3.3.3.3.2">𝑣</ci><ci id="alg2.l8.m1.4.4.3.3.3.3.3.3.cmml" xref="alg2.l8.m1.4.4.3.3.3.3.3.3">𝑘</ci></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l8.m1.4c">\lambda_{t}=Calibrate(y_{q},y_{v_{1}},\ldots,y_{v_{k}})</annotation><annotation encoding="application/x-llamapun" id="alg2.l8.m1.4d">italic_λ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_C italic_a italic_l italic_i italic_b italic_r italic_a italic_t italic_e ( italic_y start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg2.l8.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg2.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l9.1.1.1" style="font-size:80%;">9:</span></span><span class="ltx_text" id="alg2.l9.2" style="font-size:90%;">     </span><math alttext="y=\lambda_{t}\sum_{j}y_{v_{j}}+(1-\lambda_{t})y_{q}" class="ltx_Math" display="inline" id="alg2.l9.m1.1"><semantics id="alg2.l9.m1.1a"><mrow id="alg2.l9.m1.1.1" xref="alg2.l9.m1.1.1.cmml"><mi id="alg2.l9.m1.1.1.3" mathsize="90%" xref="alg2.l9.m1.1.1.3.cmml">y</mi><mo id="alg2.l9.m1.1.1.2" mathsize="90%" xref="alg2.l9.m1.1.1.2.cmml">=</mo><mrow id="alg2.l9.m1.1.1.1" xref="alg2.l9.m1.1.1.1.cmml"><mrow id="alg2.l9.m1.1.1.1.3" xref="alg2.l9.m1.1.1.1.3.cmml"><msub id="alg2.l9.m1.1.1.1.3.2" xref="alg2.l9.m1.1.1.1.3.2.cmml"><mi id="alg2.l9.m1.1.1.1.3.2.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.3.2.2.cmml">λ</mi><mi id="alg2.l9.m1.1.1.1.3.2.3" mathsize="90%" xref="alg2.l9.m1.1.1.1.3.2.3.cmml">t</mi></msub><mo id="alg2.l9.m1.1.1.1.3.1" xref="alg2.l9.m1.1.1.1.3.1.cmml">⁢</mo><mrow id="alg2.l9.m1.1.1.1.3.3" xref="alg2.l9.m1.1.1.1.3.3.cmml"><msub id="alg2.l9.m1.1.1.1.3.3.1" xref="alg2.l9.m1.1.1.1.3.3.1.cmml"><mo id="alg2.l9.m1.1.1.1.3.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="alg2.l9.m1.1.1.1.3.3.1.2.cmml">∑</mo><mi id="alg2.l9.m1.1.1.1.3.3.1.3" mathsize="90%" xref="alg2.l9.m1.1.1.1.3.3.1.3.cmml">j</mi></msub><msub id="alg2.l9.m1.1.1.1.3.3.2" xref="alg2.l9.m1.1.1.1.3.3.2.cmml"><mi id="alg2.l9.m1.1.1.1.3.3.2.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.3.3.2.2.cmml">y</mi><msub id="alg2.l9.m1.1.1.1.3.3.2.3" xref="alg2.l9.m1.1.1.1.3.3.2.3.cmml"><mi id="alg2.l9.m1.1.1.1.3.3.2.3.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.3.3.2.3.2.cmml">v</mi><mi id="alg2.l9.m1.1.1.1.3.3.2.3.3" mathsize="90%" xref="alg2.l9.m1.1.1.1.3.3.2.3.3.cmml">j</mi></msub></msub></mrow></mrow><mo id="alg2.l9.m1.1.1.1.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.2.cmml">+</mo><mrow id="alg2.l9.m1.1.1.1.1" xref="alg2.l9.m1.1.1.1.1.cmml"><mrow id="alg2.l9.m1.1.1.1.1.1.1" xref="alg2.l9.m1.1.1.1.1.1.1.1.cmml"><mo id="alg2.l9.m1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg2.l9.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg2.l9.m1.1.1.1.1.1.1.1" xref="alg2.l9.m1.1.1.1.1.1.1.1.cmml"><mn id="alg2.l9.m1.1.1.1.1.1.1.1.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="alg2.l9.m1.1.1.1.1.1.1.1.1" mathsize="90%" xref="alg2.l9.m1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="alg2.l9.m1.1.1.1.1.1.1.1.3" xref="alg2.l9.m1.1.1.1.1.1.1.1.3.cmml"><mi id="alg2.l9.m1.1.1.1.1.1.1.1.3.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.1.1.1.1.3.2.cmml">λ</mi><mi id="alg2.l9.m1.1.1.1.1.1.1.1.3.3" mathsize="90%" xref="alg2.l9.m1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="alg2.l9.m1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg2.l9.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="alg2.l9.m1.1.1.1.1.2" xref="alg2.l9.m1.1.1.1.1.2.cmml">⁢</mo><msub id="alg2.l9.m1.1.1.1.1.3" xref="alg2.l9.m1.1.1.1.1.3.cmml"><mi id="alg2.l9.m1.1.1.1.1.3.2" mathsize="90%" xref="alg2.l9.m1.1.1.1.1.3.2.cmml">y</mi><mi id="alg2.l9.m1.1.1.1.1.3.3" mathsize="90%" xref="alg2.l9.m1.1.1.1.1.3.3.cmml">q</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l9.m1.1b"><apply id="alg2.l9.m1.1.1.cmml" xref="alg2.l9.m1.1.1"><eq id="alg2.l9.m1.1.1.2.cmml" xref="alg2.l9.m1.1.1.2"></eq><ci id="alg2.l9.m1.1.1.3.cmml" xref="alg2.l9.m1.1.1.3">𝑦</ci><apply id="alg2.l9.m1.1.1.1.cmml" xref="alg2.l9.m1.1.1.1"><plus id="alg2.l9.m1.1.1.1.2.cmml" xref="alg2.l9.m1.1.1.1.2"></plus><apply id="alg2.l9.m1.1.1.1.3.cmml" xref="alg2.l9.m1.1.1.1.3"><times id="alg2.l9.m1.1.1.1.3.1.cmml" xref="alg2.l9.m1.1.1.1.3.1"></times><apply id="alg2.l9.m1.1.1.1.3.2.cmml" xref="alg2.l9.m1.1.1.1.3.2"><csymbol cd="ambiguous" id="alg2.l9.m1.1.1.1.3.2.1.cmml" xref="alg2.l9.m1.1.1.1.3.2">subscript</csymbol><ci id="alg2.l9.m1.1.1.1.3.2.2.cmml" xref="alg2.l9.m1.1.1.1.3.2.2">𝜆</ci><ci id="alg2.l9.m1.1.1.1.3.2.3.cmml" xref="alg2.l9.m1.1.1.1.3.2.3">𝑡</ci></apply><apply id="alg2.l9.m1.1.1.1.3.3.cmml" xref="alg2.l9.m1.1.1.1.3.3"><apply id="alg2.l9.m1.1.1.1.3.3.1.cmml" xref="alg2.l9.m1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg2.l9.m1.1.1.1.3.3.1.1.cmml" xref="alg2.l9.m1.1.1.1.3.3.1">subscript</csymbol><sum id="alg2.l9.m1.1.1.1.3.3.1.2.cmml" xref="alg2.l9.m1.1.1.1.3.3.1.2"></sum><ci id="alg2.l9.m1.1.1.1.3.3.1.3.cmml" xref="alg2.l9.m1.1.1.1.3.3.1.3">𝑗</ci></apply><apply id="alg2.l9.m1.1.1.1.3.3.2.cmml" xref="alg2.l9.m1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="alg2.l9.m1.1.1.1.3.3.2.1.cmml" xref="alg2.l9.m1.1.1.1.3.3.2">subscript</csymbol><ci id="alg2.l9.m1.1.1.1.3.3.2.2.cmml" xref="alg2.l9.m1.1.1.1.3.3.2.2">𝑦</ci><apply id="alg2.l9.m1.1.1.1.3.3.2.3.cmml" xref="alg2.l9.m1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="alg2.l9.m1.1.1.1.3.3.2.3.1.cmml" xref="alg2.l9.m1.1.1.1.3.3.2.3">subscript</csymbol><ci id="alg2.l9.m1.1.1.1.3.3.2.3.2.cmml" xref="alg2.l9.m1.1.1.1.3.3.2.3.2">𝑣</ci><ci id="alg2.l9.m1.1.1.1.3.3.2.3.3.cmml" xref="alg2.l9.m1.1.1.1.3.3.2.3.3">𝑗</ci></apply></apply></apply></apply><apply id="alg2.l9.m1.1.1.1.1.cmml" xref="alg2.l9.m1.1.1.1.1"><times id="alg2.l9.m1.1.1.1.1.2.cmml" xref="alg2.l9.m1.1.1.1.1.2"></times><apply id="alg2.l9.m1.1.1.1.1.1.1.1.cmml" xref="alg2.l9.m1.1.1.1.1.1.1"><minus id="alg2.l9.m1.1.1.1.1.1.1.1.1.cmml" xref="alg2.l9.m1.1.1.1.1.1.1.1.1"></minus><cn id="alg2.l9.m1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="alg2.l9.m1.1.1.1.1.1.1.1.2">1</cn><apply id="alg2.l9.m1.1.1.1.1.1.1.1.3.cmml" xref="alg2.l9.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg2.l9.m1.1.1.1.1.1.1.1.3.1.cmml" xref="alg2.l9.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="alg2.l9.m1.1.1.1.1.1.1.1.3.2.cmml" xref="alg2.l9.m1.1.1.1.1.1.1.1.3.2">𝜆</ci><ci id="alg2.l9.m1.1.1.1.1.1.1.1.3.3.cmml" xref="alg2.l9.m1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply><apply id="alg2.l9.m1.1.1.1.1.3.cmml" xref="alg2.l9.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg2.l9.m1.1.1.1.1.3.1.cmml" xref="alg2.l9.m1.1.1.1.1.3">subscript</csymbol><ci id="alg2.l9.m1.1.1.1.1.3.2.cmml" xref="alg2.l9.m1.1.1.1.1.3.2">𝑦</ci><ci id="alg2.l9.m1.1.1.1.1.3.3.cmml" xref="alg2.l9.m1.1.1.1.1.3.3">𝑞</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l9.m1.1c">y=\lambda_{t}\sum_{j}y_{v_{j}}+(1-\lambda_{t})y_{q}</annotation><annotation encoding="application/x-llamapun" id="alg2.l9.m1.1d">italic_y = italic_λ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT + ( 1 - italic_λ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) italic_y start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg2.l9.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg2.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l10.1.1.1" style="font-size:80%;">10:</span></span><span class="ltx_text" id="alg2.l10.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l10.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg2.l10.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg2.l10.5" style="font-size:90%;">if</span>
</div>
<div class="ltx_listingline" id="alg2.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l11.1.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text" id="alg2.l11.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg2.l11.3" style="font-size:90%;">return</span><span class="ltx_text" id="alg2.l11.4" style="font-size:90%;">  </span><math alttext="y" class="ltx_Math" display="inline" id="alg2.l11.m1.1"><semantics id="alg2.l11.m1.1a"><mi id="alg2.l11.m1.1.1" mathsize="90%" xref="alg2.l11.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg2.l11.m1.1b"><ci id="alg2.l11.m1.1.1.cmml" xref="alg2.l11.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l11.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg2.l11.m1.1d">italic_y</annotation></semantics></math><span class="ltx_text" id="alg2.l11.5" style="font-size:90%;">;
</span>
</div>
</div>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Different from ensemble-based fusion, calibration-based fusion uses the logits from the retrieved knowledge as a form of calibration for the model’s predictions.
Specifically, Jiang et al. <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib73" title="">2022</a>)</cite> propose a confidence-enhanced kNN-MT that refines the kNN distribution and interpolation weights with the neural machine translation confidence.
Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib90" title="">2023a</a>)</cite> propose to leverage the source context to calibrate the retrieval-augmented neural machine translation.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg2a" title="Algorithm 2 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates the detailed steps of using the logits-based fusion to integrate the retrieved knowledge.
This branch of work first treats retrievals as similar data to augment the model (lines 2-4).
For ensemble, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg2a" title="Algorithm 2 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> leverages a hyperparameter to fuse the retrieval logits and the output logits (line 6).
For calibration, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg2a" title="Algorithm 2 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> dynamically determines the parameter based on the retrieval logits and the output logits (line 8).
Then, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg2a" title="Algorithm 2 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> performs the same fusion with the computed parameter (line 9).</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg3.3.1.1">Algorithm 3</span> </span> <span class="ltx_text" id="alg3.4.2" style="font-size:90%;">Latent Fusions.</span></figcaption>
<div class="ltx_listing ltx_listing" id="alg3.5">
<div class="ltx_listingline" id="alg3.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l0.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg3.l0.2" style="font-size:90%;">  A query input </span><math alttext="q" class="ltx_Math" display="inline" id="alg3.l0.m1.1"><semantics id="alg3.l0.m1.1a"><mi id="alg3.l0.m1.1.1" mathsize="90%" xref="alg3.l0.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg3.l0.m1.1b"><ci id="alg3.l0.m1.1.1.cmml" xref="alg3.l0.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m1.1d">italic_q</annotation></semantics></math><span class="ltx_text" id="alg3.l0.3" style="font-size:90%;">, top-</span><math alttext="k" class="ltx_Math" display="inline" id="alg3.l0.m2.1"><semantics id="alg3.l0.m2.1a"><mi id="alg3.l0.m2.1.1" mathsize="90%" xref="alg3.l0.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg3.l0.m2.1b"><ci id="alg3.l0.m2.1.1.cmml" xref="alg3.l0.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m2.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="alg3.l0.4" style="font-size:90%;"> nearest neighbors </span><math alttext="\{v_{1},\ldots,v_{k}\}" class="ltx_Math" display="inline" id="alg3.l0.m3.3"><semantics id="alg3.l0.m3.3a"><mrow id="alg3.l0.m3.3.3.2" xref="alg3.l0.m3.3.3.3.cmml"><mo id="alg3.l0.m3.3.3.2.3" maxsize="90%" minsize="90%" xref="alg3.l0.m3.3.3.3.cmml">{</mo><msub id="alg3.l0.m3.2.2.1.1" xref="alg3.l0.m3.2.2.1.1.cmml"><mi id="alg3.l0.m3.2.2.1.1.2" mathsize="90%" xref="alg3.l0.m3.2.2.1.1.2.cmml">v</mi><mn id="alg3.l0.m3.2.2.1.1.3" mathsize="90%" xref="alg3.l0.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="alg3.l0.m3.3.3.2.4" mathsize="90%" xref="alg3.l0.m3.3.3.3.cmml">,</mo><mi id="alg3.l0.m3.1.1" mathsize="90%" mathvariant="normal" xref="alg3.l0.m3.1.1.cmml">…</mi><mo id="alg3.l0.m3.3.3.2.5" mathsize="90%" xref="alg3.l0.m3.3.3.3.cmml">,</mo><msub id="alg3.l0.m3.3.3.2.2" xref="alg3.l0.m3.3.3.2.2.cmml"><mi id="alg3.l0.m3.3.3.2.2.2" mathsize="90%" xref="alg3.l0.m3.3.3.2.2.2.cmml">v</mi><mi id="alg3.l0.m3.3.3.2.2.3" mathsize="90%" xref="alg3.l0.m3.3.3.2.2.3.cmml">k</mi></msub><mo id="alg3.l0.m3.3.3.2.6" maxsize="90%" minsize="90%" xref="alg3.l0.m3.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg3.l0.m3.3b"><set id="alg3.l0.m3.3.3.3.cmml" xref="alg3.l0.m3.3.3.2"><apply id="alg3.l0.m3.2.2.1.1.cmml" xref="alg3.l0.m3.2.2.1.1"><csymbol cd="ambiguous" id="alg3.l0.m3.2.2.1.1.1.cmml" xref="alg3.l0.m3.2.2.1.1">subscript</csymbol><ci id="alg3.l0.m3.2.2.1.1.2.cmml" xref="alg3.l0.m3.2.2.1.1.2">𝑣</ci><cn id="alg3.l0.m3.2.2.1.1.3.cmml" type="integer" xref="alg3.l0.m3.2.2.1.1.3">1</cn></apply><ci id="alg3.l0.m3.1.1.cmml" xref="alg3.l0.m3.1.1">…</ci><apply id="alg3.l0.m3.3.3.2.2.cmml" xref="alg3.l0.m3.3.3.2.2"><csymbol cd="ambiguous" id="alg3.l0.m3.3.3.2.2.1.cmml" xref="alg3.l0.m3.3.3.2.2">subscript</csymbol><ci id="alg3.l0.m3.3.3.2.2.2.cmml" xref="alg3.l0.m3.3.3.2.2.2">𝑣</ci><ci id="alg3.l0.m3.3.3.2.2.3.cmml" xref="alg3.l0.m3.3.3.2.2.3">𝑘</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m3.3c">\{v_{1},\ldots,v_{k}\}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m3.3d">{ italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg3.l0.5" style="font-size:90%;">, the encoder </span><math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="alg3.l0.m4.1"><semantics id="alg3.l0.m4.1a"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m4.1.1" mathsize="90%" xref="alg3.l0.m4.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="alg3.l0.m4.1b"><ci id="alg3.l0.m4.1.1.cmml" xref="alg3.l0.m4.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m4.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m4.1d">caligraphic_E</annotation></semantics></math><span class="ltx_text" id="alg3.l0.6" style="font-size:90%;">, the generator </span><math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="alg3.l0.m5.1"><semantics id="alg3.l0.m5.1a"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m5.1.1" mathsize="90%" xref="alg3.l0.m5.1.1.cmml">𝒢</mi><annotation-xml encoding="MathML-Content" id="alg3.l0.m5.1b"><ci id="alg3.l0.m5.1.1.cmml" xref="alg3.l0.m5.1.1">𝒢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m5.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m5.1d">caligraphic_G</annotation></semantics></math><span class="ltx_text" id="alg3.l0.7" style="font-size:90%;"> containing </span><math alttext="l" class="ltx_Math" display="inline" id="alg3.l0.m6.1"><semantics id="alg3.l0.m6.1a"><mi id="alg3.l0.m6.1.1" mathsize="90%" xref="alg3.l0.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg3.l0.m6.1b"><ci id="alg3.l0.m6.1.1.cmml" xref="alg3.l0.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m6.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m6.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg3.l0.8" style="font-size:90%;"> pairs of modules </span><math alttext="\{(\mathcal{M}^{A}_{1},\mathcal{M}^{F}_{1}),\ldots\}" class="ltx_Math" display="inline" id="alg3.l0.m7.2"><semantics id="alg3.l0.m7.2a"><mrow id="alg3.l0.m7.2.2.1" xref="alg3.l0.m7.2.2.2.cmml"><mo id="alg3.l0.m7.2.2.1.2" maxsize="90%" minsize="90%" xref="alg3.l0.m7.2.2.2.cmml">{</mo><mrow id="alg3.l0.m7.2.2.1.1.2" xref="alg3.l0.m7.2.2.1.1.3.cmml"><mo id="alg3.l0.m7.2.2.1.1.2.3" maxsize="90%" minsize="90%" xref="alg3.l0.m7.2.2.1.1.3.cmml">(</mo><msubsup id="alg3.l0.m7.2.2.1.1.1.1" xref="alg3.l0.m7.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m7.2.2.1.1.1.1.2.2" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.1.1.2.2.cmml">ℳ</mi><mn id="alg3.l0.m7.2.2.1.1.1.1.3" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.1.1.3.cmml">1</mn><mi id="alg3.l0.m7.2.2.1.1.1.1.2.3" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.1.1.2.3.cmml">A</mi></msubsup><mo id="alg3.l0.m7.2.2.1.1.2.4" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.3.cmml">,</mo><msubsup id="alg3.l0.m7.2.2.1.1.2.2" xref="alg3.l0.m7.2.2.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m7.2.2.1.1.2.2.2.2" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.2.2.2.2.cmml">ℳ</mi><mn id="alg3.l0.m7.2.2.1.1.2.2.3" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.2.2.3.cmml">1</mn><mi id="alg3.l0.m7.2.2.1.1.2.2.2.3" mathsize="90%" xref="alg3.l0.m7.2.2.1.1.2.2.2.3.cmml">F</mi></msubsup><mo id="alg3.l0.m7.2.2.1.1.2.5" maxsize="90%" minsize="90%" xref="alg3.l0.m7.2.2.1.1.3.cmml">)</mo></mrow><mo id="alg3.l0.m7.2.2.1.3" mathsize="90%" xref="alg3.l0.m7.2.2.2.cmml">,</mo><mi id="alg3.l0.m7.1.1" mathsize="90%" mathvariant="normal" xref="alg3.l0.m7.1.1.cmml">…</mi><mo id="alg3.l0.m7.2.2.1.4" maxsize="90%" minsize="90%" xref="alg3.l0.m7.2.2.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg3.l0.m7.2b"><set id="alg3.l0.m7.2.2.2.cmml" xref="alg3.l0.m7.2.2.1"><interval closure="open" id="alg3.l0.m7.2.2.1.1.3.cmml" xref="alg3.l0.m7.2.2.1.1.2"><apply id="alg3.l0.m7.2.2.1.1.1.1.cmml" xref="alg3.l0.m7.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l0.m7.2.2.1.1.1.1.1.cmml" xref="alg3.l0.m7.2.2.1.1.1.1">subscript</csymbol><apply id="alg3.l0.m7.2.2.1.1.1.1.2.cmml" xref="alg3.l0.m7.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l0.m7.2.2.1.1.1.1.2.1.cmml" xref="alg3.l0.m7.2.2.1.1.1.1">superscript</csymbol><ci id="alg3.l0.m7.2.2.1.1.1.1.2.2.cmml" xref="alg3.l0.m7.2.2.1.1.1.1.2.2">ℳ</ci><ci id="alg3.l0.m7.2.2.1.1.1.1.2.3.cmml" xref="alg3.l0.m7.2.2.1.1.1.1.2.3">𝐴</ci></apply><cn id="alg3.l0.m7.2.2.1.1.1.1.3.cmml" type="integer" xref="alg3.l0.m7.2.2.1.1.1.1.3">1</cn></apply><apply id="alg3.l0.m7.2.2.1.1.2.2.cmml" xref="alg3.l0.m7.2.2.1.1.2.2"><csymbol cd="ambiguous" id="alg3.l0.m7.2.2.1.1.2.2.1.cmml" xref="alg3.l0.m7.2.2.1.1.2.2">subscript</csymbol><apply id="alg3.l0.m7.2.2.1.1.2.2.2.cmml" xref="alg3.l0.m7.2.2.1.1.2.2"><csymbol cd="ambiguous" id="alg3.l0.m7.2.2.1.1.2.2.2.1.cmml" xref="alg3.l0.m7.2.2.1.1.2.2">superscript</csymbol><ci id="alg3.l0.m7.2.2.1.1.2.2.2.2.cmml" xref="alg3.l0.m7.2.2.1.1.2.2.2.2">ℳ</ci><ci id="alg3.l0.m7.2.2.1.1.2.2.2.3.cmml" xref="alg3.l0.m7.2.2.1.1.2.2.2.3">𝐹</ci></apply><cn id="alg3.l0.m7.2.2.1.1.2.2.3.cmml" type="integer" xref="alg3.l0.m7.2.2.1.1.2.2.3">1</cn></apply></interval><ci id="alg3.l0.m7.1.1.cmml" xref="alg3.l0.m7.1.1">…</ci></set></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m7.2c">\{(\mathcal{M}^{A}_{1},\mathcal{M}^{F}_{1}),\ldots\}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m7.2d">{ ( caligraphic_M start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_M start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , … }</annotation></semantics></math><span class="ltx_text" id="alg3.l0.9" style="font-size:90%;">, where </span><math alttext="\mathcal{M}^{A}_{i}" class="ltx_Math" display="inline" id="alg3.l0.m8.1"><semantics id="alg3.l0.m8.1a"><msubsup id="alg3.l0.m8.1.1" xref="alg3.l0.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m8.1.1.2.2" mathsize="90%" xref="alg3.l0.m8.1.1.2.2.cmml">ℳ</mi><mi id="alg3.l0.m8.1.1.3" mathsize="90%" xref="alg3.l0.m8.1.1.3.cmml">i</mi><mi id="alg3.l0.m8.1.1.2.3" mathsize="90%" xref="alg3.l0.m8.1.1.2.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg3.l0.m8.1b"><apply id="alg3.l0.m8.1.1.cmml" xref="alg3.l0.m8.1.1"><csymbol cd="ambiguous" id="alg3.l0.m8.1.1.1.cmml" xref="alg3.l0.m8.1.1">subscript</csymbol><apply id="alg3.l0.m8.1.1.2.cmml" xref="alg3.l0.m8.1.1"><csymbol cd="ambiguous" id="alg3.l0.m8.1.1.2.1.cmml" xref="alg3.l0.m8.1.1">superscript</csymbol><ci id="alg3.l0.m8.1.1.2.2.cmml" xref="alg3.l0.m8.1.1.2.2">ℳ</ci><ci id="alg3.l0.m8.1.1.2.3.cmml" xref="alg3.l0.m8.1.1.2.3">𝐴</ci></apply><ci id="alg3.l0.m8.1.1.3.cmml" xref="alg3.l0.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m8.1c">\mathcal{M}^{A}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m8.1d">caligraphic_M start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg3.l0.10" style="font-size:90%;"> and </span><math alttext="\mathcal{M}^{F}_{i}" class="ltx_Math" display="inline" id="alg3.l0.m9.1"><semantics id="alg3.l0.m9.1a"><msubsup id="alg3.l0.m9.1.1" xref="alg3.l0.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m9.1.1.2.2" mathsize="90%" xref="alg3.l0.m9.1.1.2.2.cmml">ℳ</mi><mi id="alg3.l0.m9.1.1.3" mathsize="90%" xref="alg3.l0.m9.1.1.3.cmml">i</mi><mi id="alg3.l0.m9.1.1.2.3" mathsize="90%" xref="alg3.l0.m9.1.1.2.3.cmml">F</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg3.l0.m9.1b"><apply id="alg3.l0.m9.1.1.cmml" xref="alg3.l0.m9.1.1"><csymbol cd="ambiguous" id="alg3.l0.m9.1.1.1.cmml" xref="alg3.l0.m9.1.1">subscript</csymbol><apply id="alg3.l0.m9.1.1.2.cmml" xref="alg3.l0.m9.1.1"><csymbol cd="ambiguous" id="alg3.l0.m9.1.1.2.1.cmml" xref="alg3.l0.m9.1.1">superscript</csymbol><ci id="alg3.l0.m9.1.1.2.2.cmml" xref="alg3.l0.m9.1.1.2.2">ℳ</ci><ci id="alg3.l0.m9.1.1.2.3.cmml" xref="alg3.l0.m9.1.1.2.3">𝐹</ci></apply><ci id="alg3.l0.m9.1.1.3.cmml" xref="alg3.l0.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m9.1c">\mathcal{M}^{F}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m9.1d">caligraphic_M start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg3.l0.11" style="font-size:90%;"> are the attention module and the FFN module at layer </span><math alttext="i" class="ltx_Math" display="inline" id="alg3.l0.m10.1"><semantics id="alg3.l0.m10.1a"><mi id="alg3.l0.m10.1.1" mathsize="90%" xref="alg3.l0.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg3.l0.m10.1b"><ci id="alg3.l0.m10.1.1.cmml" xref="alg3.l0.m10.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m10.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m10.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="alg3.l0.12" style="font-size:90%;">, </span><math alttext="\mathcal{M}^{C}_{i}" class="ltx_Math" display="inline" id="alg3.l0.m11.1"><semantics id="alg3.l0.m11.1a"><msubsup id="alg3.l0.m11.1.1" xref="alg3.l0.m11.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l0.m11.1.1.2.2" mathsize="90%" xref="alg3.l0.m11.1.1.2.2.cmml">ℳ</mi><mi id="alg3.l0.m11.1.1.3" mathsize="90%" xref="alg3.l0.m11.1.1.3.cmml">i</mi><mi id="alg3.l0.m11.1.1.2.3" mathsize="90%" xref="alg3.l0.m11.1.1.2.3.cmml">C</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg3.l0.m11.1b"><apply id="alg3.l0.m11.1.1.cmml" xref="alg3.l0.m11.1.1"><csymbol cd="ambiguous" id="alg3.l0.m11.1.1.1.cmml" xref="alg3.l0.m11.1.1">subscript</csymbol><apply id="alg3.l0.m11.1.1.2.cmml" xref="alg3.l0.m11.1.1"><csymbol cd="ambiguous" id="alg3.l0.m11.1.1.2.1.cmml" xref="alg3.l0.m11.1.1">superscript</csymbol><ci id="alg3.l0.m11.1.1.2.2.cmml" xref="alg3.l0.m11.1.1.2.2">ℳ</ci><ci id="alg3.l0.m11.1.1.2.3.cmml" xref="alg3.l0.m11.1.1.2.3">𝐶</ci></apply><ci id="alg3.l0.m11.1.1.3.cmml" xref="alg3.l0.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0.m11.1c">\mathcal{M}^{C}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg3.l0.m11.1d">caligraphic_M start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg3.l0.13" style="font-size:90%;"> is the cross-attention module used in attention-based latent fusions.</span>
</div>
<div class="ltx_listingline" id="alg3.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l0a.1.1.1" style="font-size:80%;">0:</span></span><span class="ltx_text" id="alg3.l0a.2" style="font-size:90%;">  Generated response </span><math alttext="y" class="ltx_Math" display="inline" id="alg3.l0a.m1.1"><semantics id="alg3.l0a.m1.1a"><mi id="alg3.l0a.m1.1.1" mathsize="90%" xref="alg3.l0a.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg3.l0a.m1.1b"><ci id="alg3.l0a.m1.1.1.cmml" xref="alg3.l0a.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l0a.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg3.l0a.m1.1d">italic_y</annotation></semantics></math><span class="ltx_text" id="alg3.l0a.3" style="font-size:90%;">.
</span>
</div>
<div class="ltx_listingline" id="alg3.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text" id="alg3.l1.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg3.l1.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg3.l1.4" style="font-size:90%;"> Use the attention </span><span class="ltx_text ltx_font_bold" id="alg3.l1.5" style="font-size:90%;">then</span><span class="ltx_text" id="alg3.l1.6" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text" id="alg3.l2.2" style="font-size:90%;">     </span><math alttext="h^{F}_{0}=q" class="ltx_Math" display="inline" id="alg3.l2.m1.1"><semantics id="alg3.l2.m1.1a"><mrow id="alg3.l2.m1.1.1" xref="alg3.l2.m1.1.1.cmml"><msubsup id="alg3.l2.m1.1.1.2" xref="alg3.l2.m1.1.1.2.cmml"><mi id="alg3.l2.m1.1.1.2.2.2" mathsize="90%" xref="alg3.l2.m1.1.1.2.2.2.cmml">h</mi><mn id="alg3.l2.m1.1.1.2.3" mathsize="90%" xref="alg3.l2.m1.1.1.2.3.cmml">0</mn><mi id="alg3.l2.m1.1.1.2.2.3" mathsize="90%" xref="alg3.l2.m1.1.1.2.2.3.cmml">F</mi></msubsup><mo id="alg3.l2.m1.1.1.1" mathsize="90%" xref="alg3.l2.m1.1.1.1.cmml">=</mo><mi id="alg3.l2.m1.1.1.3" mathsize="90%" xref="alg3.l2.m1.1.1.3.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="alg3.l2.m1.1b"><apply id="alg3.l2.m1.1.1.cmml" xref="alg3.l2.m1.1.1"><eq id="alg3.l2.m1.1.1.1.cmml" xref="alg3.l2.m1.1.1.1"></eq><apply id="alg3.l2.m1.1.1.2.cmml" xref="alg3.l2.m1.1.1.2"><csymbol cd="ambiguous" id="alg3.l2.m1.1.1.2.1.cmml" xref="alg3.l2.m1.1.1.2">subscript</csymbol><apply id="alg3.l2.m1.1.1.2.2.cmml" xref="alg3.l2.m1.1.1.2"><csymbol cd="ambiguous" id="alg3.l2.m1.1.1.2.2.1.cmml" xref="alg3.l2.m1.1.1.2">superscript</csymbol><ci id="alg3.l2.m1.1.1.2.2.2.cmml" xref="alg3.l2.m1.1.1.2.2.2">ℎ</ci><ci id="alg3.l2.m1.1.1.2.2.3.cmml" xref="alg3.l2.m1.1.1.2.2.3">𝐹</ci></apply><cn id="alg3.l2.m1.1.1.2.3.cmml" type="integer" xref="alg3.l2.m1.1.1.2.3">0</cn></apply><ci id="alg3.l2.m1.1.1.3.cmml" xref="alg3.l2.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l2.m1.1c">h^{F}_{0}=q</annotation><annotation encoding="application/x-llamapun" id="alg3.l2.m1.1d">italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_q</annotation></semantics></math><span class="ltx_text" id="alg3.l2.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg3.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l3.1.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text" id="alg3.l3.2" style="font-size:90%;">     </span><span class="ltx_text ltx_font_bold" id="alg3.l3.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg3.l3.4" style="font-size:90%;"> </span><math alttext="i" class="ltx_Math" display="inline" id="alg3.l3.m1.1"><semantics id="alg3.l3.m1.1a"><mi id="alg3.l3.m1.1.1" mathsize="90%" xref="alg3.l3.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg3.l3.m1.1b"><ci id="alg3.l3.m1.1.1.cmml" xref="alg3.l3.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l3.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg3.l3.m1.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="alg3.l3.5" style="font-size:90%;"> from </span><math alttext="1" class="ltx_Math" display="inline" id="alg3.l3.m2.1"><semantics id="alg3.l3.m2.1a"><mn id="alg3.l3.m2.1.1" mathsize="90%" xref="alg3.l3.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="alg3.l3.m2.1b"><cn id="alg3.l3.m2.1.1.cmml" type="integer" xref="alg3.l3.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="alg3.l3.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="alg3.l3.m2.1d">1</annotation></semantics></math><span class="ltx_text" id="alg3.l3.6" style="font-size:90%;"> to </span><math alttext="l" class="ltx_Math" display="inline" id="alg3.l3.m3.1"><semantics id="alg3.l3.m3.1a"><mi id="alg3.l3.m3.1.1" mathsize="90%" xref="alg3.l3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg3.l3.m3.1b"><ci id="alg3.l3.m3.1.1.cmml" xref="alg3.l3.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l3.m3.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg3.l3.m3.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg3.l3.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg3.l3.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg3.l3.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l4.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text" id="alg3.l4.2" style="font-size:90%;">        </span><math alttext="h^{A}_{i}=\mathcal{M}^{A}_{i}(h^{F}_{i-1})" class="ltx_Math" display="inline" id="alg3.l4.m1.1"><semantics id="alg3.l4.m1.1a"><mrow id="alg3.l4.m1.1.1" xref="alg3.l4.m1.1.1.cmml"><msubsup id="alg3.l4.m1.1.1.3" xref="alg3.l4.m1.1.1.3.cmml"><mi id="alg3.l4.m1.1.1.3.2.2" mathsize="90%" xref="alg3.l4.m1.1.1.3.2.2.cmml">h</mi><mi id="alg3.l4.m1.1.1.3.3" mathsize="90%" xref="alg3.l4.m1.1.1.3.3.cmml">i</mi><mi id="alg3.l4.m1.1.1.3.2.3" mathsize="90%" xref="alg3.l4.m1.1.1.3.2.3.cmml">A</mi></msubsup><mo id="alg3.l4.m1.1.1.2" mathsize="90%" xref="alg3.l4.m1.1.1.2.cmml">=</mo><mrow id="alg3.l4.m1.1.1.1" xref="alg3.l4.m1.1.1.1.cmml"><msubsup id="alg3.l4.m1.1.1.1.3" xref="alg3.l4.m1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l4.m1.1.1.1.3.2.2" mathsize="90%" xref="alg3.l4.m1.1.1.1.3.2.2.cmml">ℳ</mi><mi id="alg3.l4.m1.1.1.1.3.3" mathsize="90%" xref="alg3.l4.m1.1.1.1.3.3.cmml">i</mi><mi id="alg3.l4.m1.1.1.1.3.2.3" mathsize="90%" xref="alg3.l4.m1.1.1.1.3.2.3.cmml">A</mi></msubsup><mo id="alg3.l4.m1.1.1.1.2" xref="alg3.l4.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg3.l4.m1.1.1.1.1.1" xref="alg3.l4.m1.1.1.1.1.1.1.cmml"><mo id="alg3.l4.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg3.l4.m1.1.1.1.1.1.1" xref="alg3.l4.m1.1.1.1.1.1.1.cmml"><mi id="alg3.l4.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.2.2.cmml">h</mi><mrow id="alg3.l4.m1.1.1.1.1.1.1.3" xref="alg3.l4.m1.1.1.1.1.1.1.3.cmml"><mi id="alg3.l4.m1.1.1.1.1.1.1.3.2" mathsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="alg3.l4.m1.1.1.1.1.1.1.3.1" mathsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="alg3.l4.m1.1.1.1.1.1.1.3.3" mathsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="alg3.l4.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.2.3.cmml">F</mi></msubsup><mo id="alg3.l4.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg3.l4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l4.m1.1b"><apply id="alg3.l4.m1.1.1.cmml" xref="alg3.l4.m1.1.1"><eq id="alg3.l4.m1.1.1.2.cmml" xref="alg3.l4.m1.1.1.2"></eq><apply id="alg3.l4.m1.1.1.3.cmml" xref="alg3.l4.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.3.1.cmml" xref="alg3.l4.m1.1.1.3">subscript</csymbol><apply id="alg3.l4.m1.1.1.3.2.cmml" xref="alg3.l4.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.3.2.1.cmml" xref="alg3.l4.m1.1.1.3">superscript</csymbol><ci id="alg3.l4.m1.1.1.3.2.2.cmml" xref="alg3.l4.m1.1.1.3.2.2">ℎ</ci><ci id="alg3.l4.m1.1.1.3.2.3.cmml" xref="alg3.l4.m1.1.1.3.2.3">𝐴</ci></apply><ci id="alg3.l4.m1.1.1.3.3.cmml" xref="alg3.l4.m1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l4.m1.1.1.1.cmml" xref="alg3.l4.m1.1.1.1"><times id="alg3.l4.m1.1.1.1.2.cmml" xref="alg3.l4.m1.1.1.1.2"></times><apply id="alg3.l4.m1.1.1.1.3.cmml" xref="alg3.l4.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.1.3.1.cmml" xref="alg3.l4.m1.1.1.1.3">subscript</csymbol><apply id="alg3.l4.m1.1.1.1.3.2.cmml" xref="alg3.l4.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.1.3.2.1.cmml" xref="alg3.l4.m1.1.1.1.3">superscript</csymbol><ci id="alg3.l4.m1.1.1.1.3.2.2.cmml" xref="alg3.l4.m1.1.1.1.3.2.2">ℳ</ci><ci id="alg3.l4.m1.1.1.1.3.2.3.cmml" xref="alg3.l4.m1.1.1.1.3.2.3">𝐴</ci></apply><ci id="alg3.l4.m1.1.1.1.3.3.cmml" xref="alg3.l4.m1.1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l4.m1.1.1.1.1.1.1.cmml" xref="alg3.l4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l4.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l4.m1.1.1.1.1.1.1.2.cmml" xref="alg3.l4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l4.m1.1.1.1.1.1">superscript</csymbol><ci id="alg3.l4.m1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l4.m1.1.1.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l4.m1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l4.m1.1.1.1.1.1.1.2.3">𝐹</ci></apply><apply id="alg3.l4.m1.1.1.1.1.1.1.3.cmml" xref="alg3.l4.m1.1.1.1.1.1.1.3"><minus id="alg3.l4.m1.1.1.1.1.1.1.3.1.cmml" xref="alg3.l4.m1.1.1.1.1.1.1.3.1"></minus><ci id="alg3.l4.m1.1.1.1.1.1.1.3.2.cmml" xref="alg3.l4.m1.1.1.1.1.1.1.3.2">𝑖</ci><cn id="alg3.l4.m1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="alg3.l4.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l4.m1.1c">h^{A}_{i}=\mathcal{M}^{A}_{i}(h^{F}_{i-1})</annotation><annotation encoding="application/x-llamapun" id="alg3.l4.m1.1d">italic_h start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_M start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l4.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg3.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l5.1.1.1" style="font-size:80%;">5:</span></span><span class="ltx_text" id="alg3.l5.2" style="font-size:90%;">        </span><math alttext="e_{v_{1}},\ldots,e_{v_{k}}=\mathcal{E}(v_{1},\ldots,v_{k},h^{A}_{i})" class="ltx_Math" display="inline" id="alg3.l5.m1.7"><semantics id="alg3.l5.m1.7a"><mrow id="alg3.l5.m1.7.7" xref="alg3.l5.m1.7.7.cmml"><mrow id="alg3.l5.m1.4.4.2.2" xref="alg3.l5.m1.4.4.2.3.cmml"><msub id="alg3.l5.m1.3.3.1.1.1" xref="alg3.l5.m1.3.3.1.1.1.cmml"><mi id="alg3.l5.m1.3.3.1.1.1.2" mathsize="90%" xref="alg3.l5.m1.3.3.1.1.1.2.cmml">e</mi><msub id="alg3.l5.m1.3.3.1.1.1.3" xref="alg3.l5.m1.3.3.1.1.1.3.cmml"><mi id="alg3.l5.m1.3.3.1.1.1.3.2" mathsize="90%" xref="alg3.l5.m1.3.3.1.1.1.3.2.cmml">v</mi><mn id="alg3.l5.m1.3.3.1.1.1.3.3" mathsize="90%" xref="alg3.l5.m1.3.3.1.1.1.3.3.cmml">1</mn></msub></msub><mo id="alg3.l5.m1.4.4.2.2.3" mathsize="90%" xref="alg3.l5.m1.4.4.2.3.cmml">,</mo><mi id="alg3.l5.m1.2.2" mathsize="90%" mathvariant="normal" xref="alg3.l5.m1.2.2.cmml">…</mi><mo id="alg3.l5.m1.4.4.2.2.4" mathsize="90%" xref="alg3.l5.m1.4.4.2.3.cmml">,</mo><msub id="alg3.l5.m1.4.4.2.2.2" xref="alg3.l5.m1.4.4.2.2.2.cmml"><mi id="alg3.l5.m1.4.4.2.2.2.2" mathsize="90%" xref="alg3.l5.m1.4.4.2.2.2.2.cmml">e</mi><msub id="alg3.l5.m1.4.4.2.2.2.3" xref="alg3.l5.m1.4.4.2.2.2.3.cmml"><mi id="alg3.l5.m1.4.4.2.2.2.3.2" mathsize="90%" xref="alg3.l5.m1.4.4.2.2.2.3.2.cmml">v</mi><mi id="alg3.l5.m1.4.4.2.2.2.3.3" mathsize="90%" xref="alg3.l5.m1.4.4.2.2.2.3.3.cmml">k</mi></msub></msub></mrow><mo id="alg3.l5.m1.7.7.6" mathsize="90%" xref="alg3.l5.m1.7.7.6.cmml">=</mo><mrow id="alg3.l5.m1.7.7.5" xref="alg3.l5.m1.7.7.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l5.m1.7.7.5.5" mathsize="90%" xref="alg3.l5.m1.7.7.5.5.cmml">ℰ</mi><mo id="alg3.l5.m1.7.7.5.4" xref="alg3.l5.m1.7.7.5.4.cmml">⁢</mo><mrow id="alg3.l5.m1.7.7.5.3.3" xref="alg3.l5.m1.7.7.5.3.4.cmml"><mo id="alg3.l5.m1.7.7.5.3.3.4" maxsize="90%" minsize="90%" xref="alg3.l5.m1.7.7.5.3.4.cmml">(</mo><msub id="alg3.l5.m1.5.5.3.1.1.1" xref="alg3.l5.m1.5.5.3.1.1.1.cmml"><mi id="alg3.l5.m1.5.5.3.1.1.1.2" mathsize="90%" xref="alg3.l5.m1.5.5.3.1.1.1.2.cmml">v</mi><mn id="alg3.l5.m1.5.5.3.1.1.1.3" mathsize="90%" xref="alg3.l5.m1.5.5.3.1.1.1.3.cmml">1</mn></msub><mo id="alg3.l5.m1.7.7.5.3.3.5" mathsize="90%" xref="alg3.l5.m1.7.7.5.3.4.cmml">,</mo><mi id="alg3.l5.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg3.l5.m1.1.1.cmml">…</mi><mo id="alg3.l5.m1.7.7.5.3.3.6" mathsize="90%" xref="alg3.l5.m1.7.7.5.3.4.cmml">,</mo><msub id="alg3.l5.m1.6.6.4.2.2.2" xref="alg3.l5.m1.6.6.4.2.2.2.cmml"><mi id="alg3.l5.m1.6.6.4.2.2.2.2" mathsize="90%" xref="alg3.l5.m1.6.6.4.2.2.2.2.cmml">v</mi><mi id="alg3.l5.m1.6.6.4.2.2.2.3" mathsize="90%" xref="alg3.l5.m1.6.6.4.2.2.2.3.cmml">k</mi></msub><mo id="alg3.l5.m1.7.7.5.3.3.7" mathsize="90%" xref="alg3.l5.m1.7.7.5.3.4.cmml">,</mo><msubsup id="alg3.l5.m1.7.7.5.3.3.3" xref="alg3.l5.m1.7.7.5.3.3.3.cmml"><mi id="alg3.l5.m1.7.7.5.3.3.3.2.2" mathsize="90%" xref="alg3.l5.m1.7.7.5.3.3.3.2.2.cmml">h</mi><mi id="alg3.l5.m1.7.7.5.3.3.3.3" mathsize="90%" xref="alg3.l5.m1.7.7.5.3.3.3.3.cmml">i</mi><mi id="alg3.l5.m1.7.7.5.3.3.3.2.3" mathsize="90%" xref="alg3.l5.m1.7.7.5.3.3.3.2.3.cmml">A</mi></msubsup><mo id="alg3.l5.m1.7.7.5.3.3.8" maxsize="90%" minsize="90%" xref="alg3.l5.m1.7.7.5.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l5.m1.7b"><apply id="alg3.l5.m1.7.7.cmml" xref="alg3.l5.m1.7.7"><eq id="alg3.l5.m1.7.7.6.cmml" xref="alg3.l5.m1.7.7.6"></eq><list id="alg3.l5.m1.4.4.2.3.cmml" xref="alg3.l5.m1.4.4.2.2"><apply id="alg3.l5.m1.3.3.1.1.1.cmml" xref="alg3.l5.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="alg3.l5.m1.3.3.1.1.1.1.cmml" xref="alg3.l5.m1.3.3.1.1.1">subscript</csymbol><ci id="alg3.l5.m1.3.3.1.1.1.2.cmml" xref="alg3.l5.m1.3.3.1.1.1.2">𝑒</ci><apply id="alg3.l5.m1.3.3.1.1.1.3.cmml" xref="alg3.l5.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l5.m1.3.3.1.1.1.3.1.cmml" xref="alg3.l5.m1.3.3.1.1.1.3">subscript</csymbol><ci id="alg3.l5.m1.3.3.1.1.1.3.2.cmml" xref="alg3.l5.m1.3.3.1.1.1.3.2">𝑣</ci><cn id="alg3.l5.m1.3.3.1.1.1.3.3.cmml" type="integer" xref="alg3.l5.m1.3.3.1.1.1.3.3">1</cn></apply></apply><ci id="alg3.l5.m1.2.2.cmml" xref="alg3.l5.m1.2.2">…</ci><apply id="alg3.l5.m1.4.4.2.2.2.cmml" xref="alg3.l5.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="alg3.l5.m1.4.4.2.2.2.1.cmml" xref="alg3.l5.m1.4.4.2.2.2">subscript</csymbol><ci id="alg3.l5.m1.4.4.2.2.2.2.cmml" xref="alg3.l5.m1.4.4.2.2.2.2">𝑒</ci><apply id="alg3.l5.m1.4.4.2.2.2.3.cmml" xref="alg3.l5.m1.4.4.2.2.2.3"><csymbol cd="ambiguous" id="alg3.l5.m1.4.4.2.2.2.3.1.cmml" xref="alg3.l5.m1.4.4.2.2.2.3">subscript</csymbol><ci id="alg3.l5.m1.4.4.2.2.2.3.2.cmml" xref="alg3.l5.m1.4.4.2.2.2.3.2">𝑣</ci><ci id="alg3.l5.m1.4.4.2.2.2.3.3.cmml" xref="alg3.l5.m1.4.4.2.2.2.3.3">𝑘</ci></apply></apply></list><apply id="alg3.l5.m1.7.7.5.cmml" xref="alg3.l5.m1.7.7.5"><times id="alg3.l5.m1.7.7.5.4.cmml" xref="alg3.l5.m1.7.7.5.4"></times><ci id="alg3.l5.m1.7.7.5.5.cmml" xref="alg3.l5.m1.7.7.5.5">ℰ</ci><vector id="alg3.l5.m1.7.7.5.3.4.cmml" xref="alg3.l5.m1.7.7.5.3.3"><apply id="alg3.l5.m1.5.5.3.1.1.1.cmml" xref="alg3.l5.m1.5.5.3.1.1.1"><csymbol cd="ambiguous" id="alg3.l5.m1.5.5.3.1.1.1.1.cmml" xref="alg3.l5.m1.5.5.3.1.1.1">subscript</csymbol><ci id="alg3.l5.m1.5.5.3.1.1.1.2.cmml" xref="alg3.l5.m1.5.5.3.1.1.1.2">𝑣</ci><cn id="alg3.l5.m1.5.5.3.1.1.1.3.cmml" type="integer" xref="alg3.l5.m1.5.5.3.1.1.1.3">1</cn></apply><ci id="alg3.l5.m1.1.1.cmml" xref="alg3.l5.m1.1.1">…</ci><apply id="alg3.l5.m1.6.6.4.2.2.2.cmml" xref="alg3.l5.m1.6.6.4.2.2.2"><csymbol cd="ambiguous" id="alg3.l5.m1.6.6.4.2.2.2.1.cmml" xref="alg3.l5.m1.6.6.4.2.2.2">subscript</csymbol><ci id="alg3.l5.m1.6.6.4.2.2.2.2.cmml" xref="alg3.l5.m1.6.6.4.2.2.2.2">𝑣</ci><ci id="alg3.l5.m1.6.6.4.2.2.2.3.cmml" xref="alg3.l5.m1.6.6.4.2.2.2.3">𝑘</ci></apply><apply id="alg3.l5.m1.7.7.5.3.3.3.cmml" xref="alg3.l5.m1.7.7.5.3.3.3"><csymbol cd="ambiguous" id="alg3.l5.m1.7.7.5.3.3.3.1.cmml" xref="alg3.l5.m1.7.7.5.3.3.3">subscript</csymbol><apply id="alg3.l5.m1.7.7.5.3.3.3.2.cmml" xref="alg3.l5.m1.7.7.5.3.3.3"><csymbol cd="ambiguous" id="alg3.l5.m1.7.7.5.3.3.3.2.1.cmml" xref="alg3.l5.m1.7.7.5.3.3.3">superscript</csymbol><ci id="alg3.l5.m1.7.7.5.3.3.3.2.2.cmml" xref="alg3.l5.m1.7.7.5.3.3.3.2.2">ℎ</ci><ci id="alg3.l5.m1.7.7.5.3.3.3.2.3.cmml" xref="alg3.l5.m1.7.7.5.3.3.3.2.3">𝐴</ci></apply><ci id="alg3.l5.m1.7.7.5.3.3.3.3.cmml" xref="alg3.l5.m1.7.7.5.3.3.3.3">𝑖</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l5.m1.7c">e_{v_{1}},\ldots,e_{v_{k}}=\mathcal{E}(v_{1},\ldots,v_{k},h^{A}_{i})</annotation><annotation encoding="application/x-llamapun" id="alg3.l5.m1.7d">italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT = caligraphic_E ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_h start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l5.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l6.1.1.1" style="font-size:80%;">6:</span></span><span class="ltx_text" id="alg3.l6.2" style="font-size:90%;">        </span><math alttext="h^{R}_{i}=\mathcal{M}^{C}_{i}(h^{A}_{i},e_{v_{1}},\ldots,e_{v_{k}})" class="ltx_Math" display="inline" id="alg3.l6.m1.4"><semantics id="alg3.l6.m1.4a"><mrow id="alg3.l6.m1.4.4" xref="alg3.l6.m1.4.4.cmml"><msubsup id="alg3.l6.m1.4.4.5" xref="alg3.l6.m1.4.4.5.cmml"><mi id="alg3.l6.m1.4.4.5.2.2" mathsize="90%" xref="alg3.l6.m1.4.4.5.2.2.cmml">h</mi><mi id="alg3.l6.m1.4.4.5.3" mathsize="90%" xref="alg3.l6.m1.4.4.5.3.cmml">i</mi><mi id="alg3.l6.m1.4.4.5.2.3" mathsize="90%" xref="alg3.l6.m1.4.4.5.2.3.cmml">R</mi></msubsup><mo id="alg3.l6.m1.4.4.4" mathsize="90%" xref="alg3.l6.m1.4.4.4.cmml">=</mo><mrow id="alg3.l6.m1.4.4.3" xref="alg3.l6.m1.4.4.3.cmml"><msubsup id="alg3.l6.m1.4.4.3.5" xref="alg3.l6.m1.4.4.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l6.m1.4.4.3.5.2.2" mathsize="90%" xref="alg3.l6.m1.4.4.3.5.2.2.cmml">ℳ</mi><mi id="alg3.l6.m1.4.4.3.5.3" mathsize="90%" xref="alg3.l6.m1.4.4.3.5.3.cmml">i</mi><mi id="alg3.l6.m1.4.4.3.5.2.3" mathsize="90%" xref="alg3.l6.m1.4.4.3.5.2.3.cmml">C</mi></msubsup><mo id="alg3.l6.m1.4.4.3.4" xref="alg3.l6.m1.4.4.3.4.cmml">⁢</mo><mrow id="alg3.l6.m1.4.4.3.3.3" xref="alg3.l6.m1.4.4.3.3.4.cmml"><mo id="alg3.l6.m1.4.4.3.3.3.4" maxsize="90%" minsize="90%" xref="alg3.l6.m1.4.4.3.3.4.cmml">(</mo><msubsup id="alg3.l6.m1.2.2.1.1.1.1" xref="alg3.l6.m1.2.2.1.1.1.1.cmml"><mi id="alg3.l6.m1.2.2.1.1.1.1.2.2" mathsize="90%" xref="alg3.l6.m1.2.2.1.1.1.1.2.2.cmml">h</mi><mi id="alg3.l6.m1.2.2.1.1.1.1.3" mathsize="90%" xref="alg3.l6.m1.2.2.1.1.1.1.3.cmml">i</mi><mi id="alg3.l6.m1.2.2.1.1.1.1.2.3" mathsize="90%" xref="alg3.l6.m1.2.2.1.1.1.1.2.3.cmml">A</mi></msubsup><mo id="alg3.l6.m1.4.4.3.3.3.5" mathsize="90%" xref="alg3.l6.m1.4.4.3.3.4.cmml">,</mo><msub id="alg3.l6.m1.3.3.2.2.2.2" xref="alg3.l6.m1.3.3.2.2.2.2.cmml"><mi id="alg3.l6.m1.3.3.2.2.2.2.2" mathsize="90%" xref="alg3.l6.m1.3.3.2.2.2.2.2.cmml">e</mi><msub id="alg3.l6.m1.3.3.2.2.2.2.3" xref="alg3.l6.m1.3.3.2.2.2.2.3.cmml"><mi id="alg3.l6.m1.3.3.2.2.2.2.3.2" mathsize="90%" xref="alg3.l6.m1.3.3.2.2.2.2.3.2.cmml">v</mi><mn id="alg3.l6.m1.3.3.2.2.2.2.3.3" mathsize="90%" xref="alg3.l6.m1.3.3.2.2.2.2.3.3.cmml">1</mn></msub></msub><mo id="alg3.l6.m1.4.4.3.3.3.6" mathsize="90%" xref="alg3.l6.m1.4.4.3.3.4.cmml">,</mo><mi id="alg3.l6.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg3.l6.m1.1.1.cmml">…</mi><mo id="alg3.l6.m1.4.4.3.3.3.7" mathsize="90%" xref="alg3.l6.m1.4.4.3.3.4.cmml">,</mo><msub id="alg3.l6.m1.4.4.3.3.3.3" xref="alg3.l6.m1.4.4.3.3.3.3.cmml"><mi id="alg3.l6.m1.4.4.3.3.3.3.2" mathsize="90%" xref="alg3.l6.m1.4.4.3.3.3.3.2.cmml">e</mi><msub id="alg3.l6.m1.4.4.3.3.3.3.3" xref="alg3.l6.m1.4.4.3.3.3.3.3.cmml"><mi id="alg3.l6.m1.4.4.3.3.3.3.3.2" mathsize="90%" xref="alg3.l6.m1.4.4.3.3.3.3.3.2.cmml">v</mi><mi id="alg3.l6.m1.4.4.3.3.3.3.3.3" mathsize="90%" xref="alg3.l6.m1.4.4.3.3.3.3.3.3.cmml">k</mi></msub></msub><mo id="alg3.l6.m1.4.4.3.3.3.8" maxsize="90%" minsize="90%" xref="alg3.l6.m1.4.4.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l6.m1.4b"><apply id="alg3.l6.m1.4.4.cmml" xref="alg3.l6.m1.4.4"><eq id="alg3.l6.m1.4.4.4.cmml" xref="alg3.l6.m1.4.4.4"></eq><apply id="alg3.l6.m1.4.4.5.cmml" xref="alg3.l6.m1.4.4.5"><csymbol cd="ambiguous" id="alg3.l6.m1.4.4.5.1.cmml" xref="alg3.l6.m1.4.4.5">subscript</csymbol><apply id="alg3.l6.m1.4.4.5.2.cmml" xref="alg3.l6.m1.4.4.5"><csymbol cd="ambiguous" id="alg3.l6.m1.4.4.5.2.1.cmml" xref="alg3.l6.m1.4.4.5">superscript</csymbol><ci id="alg3.l6.m1.4.4.5.2.2.cmml" xref="alg3.l6.m1.4.4.5.2.2">ℎ</ci><ci id="alg3.l6.m1.4.4.5.2.3.cmml" xref="alg3.l6.m1.4.4.5.2.3">𝑅</ci></apply><ci id="alg3.l6.m1.4.4.5.3.cmml" xref="alg3.l6.m1.4.4.5.3">𝑖</ci></apply><apply id="alg3.l6.m1.4.4.3.cmml" xref="alg3.l6.m1.4.4.3"><times id="alg3.l6.m1.4.4.3.4.cmml" xref="alg3.l6.m1.4.4.3.4"></times><apply id="alg3.l6.m1.4.4.3.5.cmml" xref="alg3.l6.m1.4.4.3.5"><csymbol cd="ambiguous" id="alg3.l6.m1.4.4.3.5.1.cmml" xref="alg3.l6.m1.4.4.3.5">subscript</csymbol><apply id="alg3.l6.m1.4.4.3.5.2.cmml" xref="alg3.l6.m1.4.4.3.5"><csymbol cd="ambiguous" id="alg3.l6.m1.4.4.3.5.2.1.cmml" xref="alg3.l6.m1.4.4.3.5">superscript</csymbol><ci id="alg3.l6.m1.4.4.3.5.2.2.cmml" xref="alg3.l6.m1.4.4.3.5.2.2">ℳ</ci><ci id="alg3.l6.m1.4.4.3.5.2.3.cmml" xref="alg3.l6.m1.4.4.3.5.2.3">𝐶</ci></apply><ci id="alg3.l6.m1.4.4.3.5.3.cmml" xref="alg3.l6.m1.4.4.3.5.3">𝑖</ci></apply><vector id="alg3.l6.m1.4.4.3.3.4.cmml" xref="alg3.l6.m1.4.4.3.3.3"><apply id="alg3.l6.m1.2.2.1.1.1.1.cmml" xref="alg3.l6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l6.m1.2.2.1.1.1.1.1.cmml" xref="alg3.l6.m1.2.2.1.1.1.1">subscript</csymbol><apply id="alg3.l6.m1.2.2.1.1.1.1.2.cmml" xref="alg3.l6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l6.m1.2.2.1.1.1.1.2.1.cmml" xref="alg3.l6.m1.2.2.1.1.1.1">superscript</csymbol><ci id="alg3.l6.m1.2.2.1.1.1.1.2.2.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l6.m1.2.2.1.1.1.1.2.3.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.2.3">𝐴</ci></apply><ci id="alg3.l6.m1.2.2.1.1.1.1.3.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.3">𝑖</ci></apply><apply id="alg3.l6.m1.3.3.2.2.2.2.cmml" xref="alg3.l6.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg3.l6.m1.3.3.2.2.2.2.1.cmml" xref="alg3.l6.m1.3.3.2.2.2.2">subscript</csymbol><ci id="alg3.l6.m1.3.3.2.2.2.2.2.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.2">𝑒</ci><apply id="alg3.l6.m1.3.3.2.2.2.2.3.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="alg3.l6.m1.3.3.2.2.2.2.3.1.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.3">subscript</csymbol><ci id="alg3.l6.m1.3.3.2.2.2.2.3.2.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.3.2">𝑣</ci><cn id="alg3.l6.m1.3.3.2.2.2.2.3.3.cmml" type="integer" xref="alg3.l6.m1.3.3.2.2.2.2.3.3">1</cn></apply></apply><ci id="alg3.l6.m1.1.1.cmml" xref="alg3.l6.m1.1.1">…</ci><apply id="alg3.l6.m1.4.4.3.3.3.3.cmml" xref="alg3.l6.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="alg3.l6.m1.4.4.3.3.3.3.1.cmml" xref="alg3.l6.m1.4.4.3.3.3.3">subscript</csymbol><ci id="alg3.l6.m1.4.4.3.3.3.3.2.cmml" xref="alg3.l6.m1.4.4.3.3.3.3.2">𝑒</ci><apply id="alg3.l6.m1.4.4.3.3.3.3.3.cmml" xref="alg3.l6.m1.4.4.3.3.3.3.3"><csymbol cd="ambiguous" id="alg3.l6.m1.4.4.3.3.3.3.3.1.cmml" xref="alg3.l6.m1.4.4.3.3.3.3.3">subscript</csymbol><ci id="alg3.l6.m1.4.4.3.3.3.3.3.2.cmml" xref="alg3.l6.m1.4.4.3.3.3.3.3.2">𝑣</ci><ci id="alg3.l6.m1.4.4.3.3.3.3.3.3.cmml" xref="alg3.l6.m1.4.4.3.3.3.3.3.3">𝑘</ci></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l6.m1.4c">h^{R}_{i}=\mathcal{M}^{C}_{i}(h^{A}_{i},e_{v_{1}},\ldots,e_{v_{k}})</annotation><annotation encoding="application/x-llamapun" id="alg3.l6.m1.4d">italic_h start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_M start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_h start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l6.3" style="font-size:90%;">; </span><span class="ltx_text" id="alg3.l6.4" style="font-size:90%;float:right;">/* Use a cross-attention module to incorporate external knowledge */
</span>
</div>
<div class="ltx_listingline" id="alg3.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l7.1.1.1" style="font-size:80%;">7:</span></span><span class="ltx_text" id="alg3.l7.2" style="font-size:90%;">        </span><math alttext="h^{F}_{i}=\mathcal{M}^{F}_{i}(h^{R}_{i})" class="ltx_Math" display="inline" id="alg3.l7.m1.1"><semantics id="alg3.l7.m1.1a"><mrow id="alg3.l7.m1.1.1" xref="alg3.l7.m1.1.1.cmml"><msubsup id="alg3.l7.m1.1.1.3" xref="alg3.l7.m1.1.1.3.cmml"><mi id="alg3.l7.m1.1.1.3.2.2" mathsize="90%" xref="alg3.l7.m1.1.1.3.2.2.cmml">h</mi><mi id="alg3.l7.m1.1.1.3.3" mathsize="90%" xref="alg3.l7.m1.1.1.3.3.cmml">i</mi><mi id="alg3.l7.m1.1.1.3.2.3" mathsize="90%" xref="alg3.l7.m1.1.1.3.2.3.cmml">F</mi></msubsup><mo id="alg3.l7.m1.1.1.2" mathsize="90%" xref="alg3.l7.m1.1.1.2.cmml">=</mo><mrow id="alg3.l7.m1.1.1.1" xref="alg3.l7.m1.1.1.1.cmml"><msubsup id="alg3.l7.m1.1.1.1.3" xref="alg3.l7.m1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l7.m1.1.1.1.3.2.2" mathsize="90%" xref="alg3.l7.m1.1.1.1.3.2.2.cmml">ℳ</mi><mi id="alg3.l7.m1.1.1.1.3.3" mathsize="90%" xref="alg3.l7.m1.1.1.1.3.3.cmml">i</mi><mi id="alg3.l7.m1.1.1.1.3.2.3" mathsize="90%" xref="alg3.l7.m1.1.1.1.3.2.3.cmml">F</mi></msubsup><mo id="alg3.l7.m1.1.1.1.2" xref="alg3.l7.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg3.l7.m1.1.1.1.1.1" xref="alg3.l7.m1.1.1.1.1.1.1.cmml"><mo id="alg3.l7.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg3.l7.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg3.l7.m1.1.1.1.1.1.1" xref="alg3.l7.m1.1.1.1.1.1.1.cmml"><mi id="alg3.l7.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg3.l7.m1.1.1.1.1.1.1.2.2.cmml">h</mi><mi id="alg3.l7.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg3.l7.m1.1.1.1.1.1.1.3.cmml">i</mi><mi id="alg3.l7.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg3.l7.m1.1.1.1.1.1.1.2.3.cmml">R</mi></msubsup><mo id="alg3.l7.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg3.l7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l7.m1.1b"><apply id="alg3.l7.m1.1.1.cmml" xref="alg3.l7.m1.1.1"><eq id="alg3.l7.m1.1.1.2.cmml" xref="alg3.l7.m1.1.1.2"></eq><apply id="alg3.l7.m1.1.1.3.cmml" xref="alg3.l7.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.3.1.cmml" xref="alg3.l7.m1.1.1.3">subscript</csymbol><apply id="alg3.l7.m1.1.1.3.2.cmml" xref="alg3.l7.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.3.2.1.cmml" xref="alg3.l7.m1.1.1.3">superscript</csymbol><ci id="alg3.l7.m1.1.1.3.2.2.cmml" xref="alg3.l7.m1.1.1.3.2.2">ℎ</ci><ci id="alg3.l7.m1.1.1.3.2.3.cmml" xref="alg3.l7.m1.1.1.3.2.3">𝐹</ci></apply><ci id="alg3.l7.m1.1.1.3.3.cmml" xref="alg3.l7.m1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l7.m1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1"><times id="alg3.l7.m1.1.1.1.2.cmml" xref="alg3.l7.m1.1.1.1.2"></times><apply id="alg3.l7.m1.1.1.1.3.cmml" xref="alg3.l7.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.3.1.cmml" xref="alg3.l7.m1.1.1.1.3">subscript</csymbol><apply id="alg3.l7.m1.1.1.1.3.2.cmml" xref="alg3.l7.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.3.2.1.cmml" xref="alg3.l7.m1.1.1.1.3">superscript</csymbol><ci id="alg3.l7.m1.1.1.1.3.2.2.cmml" xref="alg3.l7.m1.1.1.1.3.2.2">ℳ</ci><ci id="alg3.l7.m1.1.1.1.3.2.3.cmml" xref="alg3.l7.m1.1.1.1.3.2.3">𝐹</ci></apply><ci id="alg3.l7.m1.1.1.1.3.3.cmml" xref="alg3.l7.m1.1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l7.m1.1.1.1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l7.m1.1.1.1.1.1.1.2.cmml" xref="alg3.l7.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l7.m1.1.1.1.1.1">superscript</csymbol><ci id="alg3.l7.m1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l7.m1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.2.3">𝑅</ci></apply><ci id="alg3.l7.m1.1.1.1.1.1.1.3.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l7.m1.1c">h^{F}_{i}=\mathcal{M}^{F}_{i}(h^{R}_{i})</annotation><annotation encoding="application/x-llamapun" id="alg3.l7.m1.1d">italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_M start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_h start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l7.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l8.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text" id="alg3.l8.2" style="font-size:90%;">     </span><span class="ltx_text ltx_font_bold" id="alg3.l8.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg3.l8.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg3.l8.5" style="font-size:90%;">for</span>
</div>
<div class="ltx_listingline" id="alg3.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l9.1.1.1" style="font-size:80%;">9:</span></span><span class="ltx_text" id="alg3.l9.2" style="font-size:90%;">     </span><math alttext="y=LM\_HEAD(h^{F}_{l})" class="ltx_Math" display="inline" id="alg3.l9.m1.1"><semantics id="alg3.l9.m1.1a"><mrow id="alg3.l9.m1.1.1" xref="alg3.l9.m1.1.1.cmml"><mi id="alg3.l9.m1.1.1.3" mathsize="90%" xref="alg3.l9.m1.1.1.3.cmml">y</mi><mo id="alg3.l9.m1.1.1.2" mathsize="90%" xref="alg3.l9.m1.1.1.2.cmml">=</mo><mrow id="alg3.l9.m1.1.1.1" xref="alg3.l9.m1.1.1.1.cmml"><mi id="alg3.l9.m1.1.1.1.3" mathsize="90%" xref="alg3.l9.m1.1.1.1.3.cmml">L</mi><mo id="alg3.l9.m1.1.1.1.2" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l9.m1.1.1.1.4" mathsize="90%" xref="alg3.l9.m1.1.1.1.4.cmml">M</mi><mo id="alg3.l9.m1.1.1.1.2a" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l9.m1.1.1.1.5" mathsize="90%" mathvariant="normal" xref="alg3.l9.m1.1.1.1.5.cmml">_</mi><mo id="alg3.l9.m1.1.1.1.2b" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l9.m1.1.1.1.6" mathsize="90%" xref="alg3.l9.m1.1.1.1.6.cmml">H</mi><mo id="alg3.l9.m1.1.1.1.2c" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l9.m1.1.1.1.7" mathsize="90%" xref="alg3.l9.m1.1.1.1.7.cmml">E</mi><mo id="alg3.l9.m1.1.1.1.2d" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l9.m1.1.1.1.8" mathsize="90%" xref="alg3.l9.m1.1.1.1.8.cmml">A</mi><mo id="alg3.l9.m1.1.1.1.2e" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l9.m1.1.1.1.9" mathsize="90%" xref="alg3.l9.m1.1.1.1.9.cmml">D</mi><mo id="alg3.l9.m1.1.1.1.2f" xref="alg3.l9.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg3.l9.m1.1.1.1.1.1" xref="alg3.l9.m1.1.1.1.1.1.1.cmml"><mo id="alg3.l9.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg3.l9.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg3.l9.m1.1.1.1.1.1.1" xref="alg3.l9.m1.1.1.1.1.1.1.cmml"><mi id="alg3.l9.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg3.l9.m1.1.1.1.1.1.1.2.2.cmml">h</mi><mi id="alg3.l9.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg3.l9.m1.1.1.1.1.1.1.3.cmml">l</mi><mi id="alg3.l9.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg3.l9.m1.1.1.1.1.1.1.2.3.cmml">F</mi></msubsup><mo id="alg3.l9.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg3.l9.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l9.m1.1b"><apply id="alg3.l9.m1.1.1.cmml" xref="alg3.l9.m1.1.1"><eq id="alg3.l9.m1.1.1.2.cmml" xref="alg3.l9.m1.1.1.2"></eq><ci id="alg3.l9.m1.1.1.3.cmml" xref="alg3.l9.m1.1.1.3">𝑦</ci><apply id="alg3.l9.m1.1.1.1.cmml" xref="alg3.l9.m1.1.1.1"><times id="alg3.l9.m1.1.1.1.2.cmml" xref="alg3.l9.m1.1.1.1.2"></times><ci id="alg3.l9.m1.1.1.1.3.cmml" xref="alg3.l9.m1.1.1.1.3">𝐿</ci><ci id="alg3.l9.m1.1.1.1.4.cmml" xref="alg3.l9.m1.1.1.1.4">𝑀</ci><ci id="alg3.l9.m1.1.1.1.5.cmml" xref="alg3.l9.m1.1.1.1.5">_</ci><ci id="alg3.l9.m1.1.1.1.6.cmml" xref="alg3.l9.m1.1.1.1.6">𝐻</ci><ci id="alg3.l9.m1.1.1.1.7.cmml" xref="alg3.l9.m1.1.1.1.7">𝐸</ci><ci id="alg3.l9.m1.1.1.1.8.cmml" xref="alg3.l9.m1.1.1.1.8">𝐴</ci><ci id="alg3.l9.m1.1.1.1.9.cmml" xref="alg3.l9.m1.1.1.1.9">𝐷</ci><apply id="alg3.l9.m1.1.1.1.1.1.1.cmml" xref="alg3.l9.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l9.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l9.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l9.m1.1.1.1.1.1.1.2.cmml" xref="alg3.l9.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l9.m1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l9.m1.1.1.1.1.1">superscript</csymbol><ci id="alg3.l9.m1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l9.m1.1.1.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l9.m1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l9.m1.1.1.1.1.1.1.2.3">𝐹</ci></apply><ci id="alg3.l9.m1.1.1.1.1.1.1.3.cmml" xref="alg3.l9.m1.1.1.1.1.1.1.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l9.m1.1c">y=LM\_HEAD(h^{F}_{l})</annotation><annotation encoding="application/x-llamapun" id="alg3.l9.m1.1d">italic_y = italic_L italic_M _ italic_H italic_E italic_A italic_D ( italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l9.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l10.1.1.1" style="font-size:80%;">10:</span></span><span class="ltx_text" id="alg3.l10.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg3.l10.3" style="font-size:90%;">else</span><span class="ltx_text" id="alg3.l10.4" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l11.1.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text" id="alg3.l11.2" style="font-size:90%;">     </span><math alttext="e_{v_{1}},\ldots,e_{v_{k}}=\mathcal{E}(v_{1},\ldots,v_{k})" class="ltx_Math" display="inline" id="alg3.l11.m1.6"><semantics id="alg3.l11.m1.6a"><mrow id="alg3.l11.m1.6.6" xref="alg3.l11.m1.6.6.cmml"><mrow id="alg3.l11.m1.4.4.2.2" xref="alg3.l11.m1.4.4.2.3.cmml"><msub id="alg3.l11.m1.3.3.1.1.1" xref="alg3.l11.m1.3.3.1.1.1.cmml"><mi id="alg3.l11.m1.3.3.1.1.1.2" mathsize="90%" xref="alg3.l11.m1.3.3.1.1.1.2.cmml">e</mi><msub id="alg3.l11.m1.3.3.1.1.1.3" xref="alg3.l11.m1.3.3.1.1.1.3.cmml"><mi id="alg3.l11.m1.3.3.1.1.1.3.2" mathsize="90%" xref="alg3.l11.m1.3.3.1.1.1.3.2.cmml">v</mi><mn id="alg3.l11.m1.3.3.1.1.1.3.3" mathsize="90%" xref="alg3.l11.m1.3.3.1.1.1.3.3.cmml">1</mn></msub></msub><mo id="alg3.l11.m1.4.4.2.2.3" mathsize="90%" xref="alg3.l11.m1.4.4.2.3.cmml">,</mo><mi id="alg3.l11.m1.2.2" mathsize="90%" mathvariant="normal" xref="alg3.l11.m1.2.2.cmml">…</mi><mo id="alg3.l11.m1.4.4.2.2.4" mathsize="90%" xref="alg3.l11.m1.4.4.2.3.cmml">,</mo><msub id="alg3.l11.m1.4.4.2.2.2" xref="alg3.l11.m1.4.4.2.2.2.cmml"><mi id="alg3.l11.m1.4.4.2.2.2.2" mathsize="90%" xref="alg3.l11.m1.4.4.2.2.2.2.cmml">e</mi><msub id="alg3.l11.m1.4.4.2.2.2.3" xref="alg3.l11.m1.4.4.2.2.2.3.cmml"><mi id="alg3.l11.m1.4.4.2.2.2.3.2" mathsize="90%" xref="alg3.l11.m1.4.4.2.2.2.3.2.cmml">v</mi><mi id="alg3.l11.m1.4.4.2.2.2.3.3" mathsize="90%" xref="alg3.l11.m1.4.4.2.2.2.3.3.cmml">k</mi></msub></msub></mrow><mo id="alg3.l11.m1.6.6.5" mathsize="90%" xref="alg3.l11.m1.6.6.5.cmml">=</mo><mrow id="alg3.l11.m1.6.6.4" xref="alg3.l11.m1.6.6.4.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l11.m1.6.6.4.4" mathsize="90%" xref="alg3.l11.m1.6.6.4.4.cmml">ℰ</mi><mo id="alg3.l11.m1.6.6.4.3" xref="alg3.l11.m1.6.6.4.3.cmml">⁢</mo><mrow id="alg3.l11.m1.6.6.4.2.2" xref="alg3.l11.m1.6.6.4.2.3.cmml"><mo id="alg3.l11.m1.6.6.4.2.2.3" maxsize="90%" minsize="90%" xref="alg3.l11.m1.6.6.4.2.3.cmml">(</mo><msub id="alg3.l11.m1.5.5.3.1.1.1" xref="alg3.l11.m1.5.5.3.1.1.1.cmml"><mi id="alg3.l11.m1.5.5.3.1.1.1.2" mathsize="90%" xref="alg3.l11.m1.5.5.3.1.1.1.2.cmml">v</mi><mn id="alg3.l11.m1.5.5.3.1.1.1.3" mathsize="90%" xref="alg3.l11.m1.5.5.3.1.1.1.3.cmml">1</mn></msub><mo id="alg3.l11.m1.6.6.4.2.2.4" mathsize="90%" xref="alg3.l11.m1.6.6.4.2.3.cmml">,</mo><mi id="alg3.l11.m1.1.1" mathsize="90%" mathvariant="normal" xref="alg3.l11.m1.1.1.cmml">…</mi><mo id="alg3.l11.m1.6.6.4.2.2.5" mathsize="90%" xref="alg3.l11.m1.6.6.4.2.3.cmml">,</mo><msub id="alg3.l11.m1.6.6.4.2.2.2" xref="alg3.l11.m1.6.6.4.2.2.2.cmml"><mi id="alg3.l11.m1.6.6.4.2.2.2.2" mathsize="90%" xref="alg3.l11.m1.6.6.4.2.2.2.2.cmml">v</mi><mi id="alg3.l11.m1.6.6.4.2.2.2.3" mathsize="90%" xref="alg3.l11.m1.6.6.4.2.2.2.3.cmml">k</mi></msub><mo id="alg3.l11.m1.6.6.4.2.2.6" maxsize="90%" minsize="90%" xref="alg3.l11.m1.6.6.4.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l11.m1.6b"><apply id="alg3.l11.m1.6.6.cmml" xref="alg3.l11.m1.6.6"><eq id="alg3.l11.m1.6.6.5.cmml" xref="alg3.l11.m1.6.6.5"></eq><list id="alg3.l11.m1.4.4.2.3.cmml" xref="alg3.l11.m1.4.4.2.2"><apply id="alg3.l11.m1.3.3.1.1.1.cmml" xref="alg3.l11.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="alg3.l11.m1.3.3.1.1.1.1.cmml" xref="alg3.l11.m1.3.3.1.1.1">subscript</csymbol><ci id="alg3.l11.m1.3.3.1.1.1.2.cmml" xref="alg3.l11.m1.3.3.1.1.1.2">𝑒</ci><apply id="alg3.l11.m1.3.3.1.1.1.3.cmml" xref="alg3.l11.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l11.m1.3.3.1.1.1.3.1.cmml" xref="alg3.l11.m1.3.3.1.1.1.3">subscript</csymbol><ci id="alg3.l11.m1.3.3.1.1.1.3.2.cmml" xref="alg3.l11.m1.3.3.1.1.1.3.2">𝑣</ci><cn id="alg3.l11.m1.3.3.1.1.1.3.3.cmml" type="integer" xref="alg3.l11.m1.3.3.1.1.1.3.3">1</cn></apply></apply><ci id="alg3.l11.m1.2.2.cmml" xref="alg3.l11.m1.2.2">…</ci><apply id="alg3.l11.m1.4.4.2.2.2.cmml" xref="alg3.l11.m1.4.4.2.2.2"><csymbol cd="ambiguous" id="alg3.l11.m1.4.4.2.2.2.1.cmml" xref="alg3.l11.m1.4.4.2.2.2">subscript</csymbol><ci id="alg3.l11.m1.4.4.2.2.2.2.cmml" xref="alg3.l11.m1.4.4.2.2.2.2">𝑒</ci><apply id="alg3.l11.m1.4.4.2.2.2.3.cmml" xref="alg3.l11.m1.4.4.2.2.2.3"><csymbol cd="ambiguous" id="alg3.l11.m1.4.4.2.2.2.3.1.cmml" xref="alg3.l11.m1.4.4.2.2.2.3">subscript</csymbol><ci id="alg3.l11.m1.4.4.2.2.2.3.2.cmml" xref="alg3.l11.m1.4.4.2.2.2.3.2">𝑣</ci><ci id="alg3.l11.m1.4.4.2.2.2.3.3.cmml" xref="alg3.l11.m1.4.4.2.2.2.3.3">𝑘</ci></apply></apply></list><apply id="alg3.l11.m1.6.6.4.cmml" xref="alg3.l11.m1.6.6.4"><times id="alg3.l11.m1.6.6.4.3.cmml" xref="alg3.l11.m1.6.6.4.3"></times><ci id="alg3.l11.m1.6.6.4.4.cmml" xref="alg3.l11.m1.6.6.4.4">ℰ</ci><vector id="alg3.l11.m1.6.6.4.2.3.cmml" xref="alg3.l11.m1.6.6.4.2.2"><apply id="alg3.l11.m1.5.5.3.1.1.1.cmml" xref="alg3.l11.m1.5.5.3.1.1.1"><csymbol cd="ambiguous" id="alg3.l11.m1.5.5.3.1.1.1.1.cmml" xref="alg3.l11.m1.5.5.3.1.1.1">subscript</csymbol><ci id="alg3.l11.m1.5.5.3.1.1.1.2.cmml" xref="alg3.l11.m1.5.5.3.1.1.1.2">𝑣</ci><cn id="alg3.l11.m1.5.5.3.1.1.1.3.cmml" type="integer" xref="alg3.l11.m1.5.5.3.1.1.1.3">1</cn></apply><ci id="alg3.l11.m1.1.1.cmml" xref="alg3.l11.m1.1.1">…</ci><apply id="alg3.l11.m1.6.6.4.2.2.2.cmml" xref="alg3.l11.m1.6.6.4.2.2.2"><csymbol cd="ambiguous" id="alg3.l11.m1.6.6.4.2.2.2.1.cmml" xref="alg3.l11.m1.6.6.4.2.2.2">subscript</csymbol><ci id="alg3.l11.m1.6.6.4.2.2.2.2.cmml" xref="alg3.l11.m1.6.6.4.2.2.2.2">𝑣</ci><ci id="alg3.l11.m1.6.6.4.2.2.2.3.cmml" xref="alg3.l11.m1.6.6.4.2.2.2.3">𝑘</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l11.m1.6c">e_{v_{1}},\ldots,e_{v_{k}}=\mathcal{E}(v_{1},\ldots,v_{k})</annotation><annotation encoding="application/x-llamapun" id="alg3.l11.m1.6d">italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT = caligraphic_E ( italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l11.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l12.1.1.1" style="font-size:80%;">12:</span></span><span class="ltx_text" id="alg3.l12.2" style="font-size:90%;">     </span><math alttext="h^{F}_{0}=q" class="ltx_Math" display="inline" id="alg3.l12.m1.1"><semantics id="alg3.l12.m1.1a"><mrow id="alg3.l12.m1.1.1" xref="alg3.l12.m1.1.1.cmml"><msubsup id="alg3.l12.m1.1.1.2" xref="alg3.l12.m1.1.1.2.cmml"><mi id="alg3.l12.m1.1.1.2.2.2" mathsize="90%" xref="alg3.l12.m1.1.1.2.2.2.cmml">h</mi><mn id="alg3.l12.m1.1.1.2.3" mathsize="90%" xref="alg3.l12.m1.1.1.2.3.cmml">0</mn><mi id="alg3.l12.m1.1.1.2.2.3" mathsize="90%" xref="alg3.l12.m1.1.1.2.2.3.cmml">F</mi></msubsup><mo id="alg3.l12.m1.1.1.1" mathsize="90%" xref="alg3.l12.m1.1.1.1.cmml">=</mo><mi id="alg3.l12.m1.1.1.3" mathsize="90%" xref="alg3.l12.m1.1.1.3.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="alg3.l12.m1.1b"><apply id="alg3.l12.m1.1.1.cmml" xref="alg3.l12.m1.1.1"><eq id="alg3.l12.m1.1.1.1.cmml" xref="alg3.l12.m1.1.1.1"></eq><apply id="alg3.l12.m1.1.1.2.cmml" xref="alg3.l12.m1.1.1.2"><csymbol cd="ambiguous" id="alg3.l12.m1.1.1.2.1.cmml" xref="alg3.l12.m1.1.1.2">subscript</csymbol><apply id="alg3.l12.m1.1.1.2.2.cmml" xref="alg3.l12.m1.1.1.2"><csymbol cd="ambiguous" id="alg3.l12.m1.1.1.2.2.1.cmml" xref="alg3.l12.m1.1.1.2">superscript</csymbol><ci id="alg3.l12.m1.1.1.2.2.2.cmml" xref="alg3.l12.m1.1.1.2.2.2">ℎ</ci><ci id="alg3.l12.m1.1.1.2.2.3.cmml" xref="alg3.l12.m1.1.1.2.2.3">𝐹</ci></apply><cn id="alg3.l12.m1.1.1.2.3.cmml" type="integer" xref="alg3.l12.m1.1.1.2.3">0</cn></apply><ci id="alg3.l12.m1.1.1.3.cmml" xref="alg3.l12.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l12.m1.1c">h^{F}_{0}=q</annotation><annotation encoding="application/x-llamapun" id="alg3.l12.m1.1d">italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_q</annotation></semantics></math><span class="ltx_text" id="alg3.l12.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg3.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l13.1.1.1" style="font-size:80%;">13:</span></span><span class="ltx_text" id="alg3.l13.2" style="font-size:90%;">     </span><span class="ltx_text ltx_font_bold" id="alg3.l13.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg3.l13.4" style="font-size:90%;"> </span><math alttext="i" class="ltx_Math" display="inline" id="alg3.l13.m1.1"><semantics id="alg3.l13.m1.1a"><mi id="alg3.l13.m1.1.1" mathsize="90%" xref="alg3.l13.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg3.l13.m1.1b"><ci id="alg3.l13.m1.1.1.cmml" xref="alg3.l13.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l13.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg3.l13.m1.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="alg3.l13.5" style="font-size:90%;"> from </span><math alttext="1" class="ltx_Math" display="inline" id="alg3.l13.m2.1"><semantics id="alg3.l13.m2.1a"><mn id="alg3.l13.m2.1.1" mathsize="90%" xref="alg3.l13.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="alg3.l13.m2.1b"><cn id="alg3.l13.m2.1.1.cmml" type="integer" xref="alg3.l13.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="alg3.l13.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="alg3.l13.m2.1d">1</annotation></semantics></math><span class="ltx_text" id="alg3.l13.6" style="font-size:90%;"> to </span><math alttext="l" class="ltx_Math" display="inline" id="alg3.l13.m3.1"><semantics id="alg3.l13.m3.1a"><mi id="alg3.l13.m3.1.1" mathsize="90%" xref="alg3.l13.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg3.l13.m3.1b"><ci id="alg3.l13.m3.1.1.cmml" xref="alg3.l13.m3.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l13.m3.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg3.l13.m3.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg3.l13.7" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg3.l13.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg3.l13.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l14.1.1.1" style="font-size:80%;">14:</span></span><span class="ltx_text" id="alg3.l14.2" style="font-size:90%;">        </span><math alttext="h^{A}_{i}=\mathcal{M}^{A}_{i}(h^{F}_{i-1})" class="ltx_Math" display="inline" id="alg3.l14.m1.1"><semantics id="alg3.l14.m1.1a"><mrow id="alg3.l14.m1.1.1" xref="alg3.l14.m1.1.1.cmml"><msubsup id="alg3.l14.m1.1.1.3" xref="alg3.l14.m1.1.1.3.cmml"><mi id="alg3.l14.m1.1.1.3.2.2" mathsize="90%" xref="alg3.l14.m1.1.1.3.2.2.cmml">h</mi><mi id="alg3.l14.m1.1.1.3.3" mathsize="90%" xref="alg3.l14.m1.1.1.3.3.cmml">i</mi><mi id="alg3.l14.m1.1.1.3.2.3" mathsize="90%" xref="alg3.l14.m1.1.1.3.2.3.cmml">A</mi></msubsup><mo id="alg3.l14.m1.1.1.2" mathsize="90%" xref="alg3.l14.m1.1.1.2.cmml">=</mo><mrow id="alg3.l14.m1.1.1.1" xref="alg3.l14.m1.1.1.1.cmml"><msubsup id="alg3.l14.m1.1.1.1.3" xref="alg3.l14.m1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l14.m1.1.1.1.3.2.2" mathsize="90%" xref="alg3.l14.m1.1.1.1.3.2.2.cmml">ℳ</mi><mi id="alg3.l14.m1.1.1.1.3.3" mathsize="90%" xref="alg3.l14.m1.1.1.1.3.3.cmml">i</mi><mi id="alg3.l14.m1.1.1.1.3.2.3" mathsize="90%" xref="alg3.l14.m1.1.1.1.3.2.3.cmml">A</mi></msubsup><mo id="alg3.l14.m1.1.1.1.2" xref="alg3.l14.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg3.l14.m1.1.1.1.1.1" xref="alg3.l14.m1.1.1.1.1.1.1.cmml"><mo id="alg3.l14.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg3.l14.m1.1.1.1.1.1.1" xref="alg3.l14.m1.1.1.1.1.1.1.cmml"><mi id="alg3.l14.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.2.2.cmml">h</mi><mrow id="alg3.l14.m1.1.1.1.1.1.1.3" xref="alg3.l14.m1.1.1.1.1.1.1.3.cmml"><mi id="alg3.l14.m1.1.1.1.1.1.1.3.2" mathsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="alg3.l14.m1.1.1.1.1.1.1.3.1" mathsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="alg3.l14.m1.1.1.1.1.1.1.3.3" mathsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="alg3.l14.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.2.3.cmml">F</mi></msubsup><mo id="alg3.l14.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg3.l14.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l14.m1.1b"><apply id="alg3.l14.m1.1.1.cmml" xref="alg3.l14.m1.1.1"><eq id="alg3.l14.m1.1.1.2.cmml" xref="alg3.l14.m1.1.1.2"></eq><apply id="alg3.l14.m1.1.1.3.cmml" xref="alg3.l14.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l14.m1.1.1.3.1.cmml" xref="alg3.l14.m1.1.1.3">subscript</csymbol><apply id="alg3.l14.m1.1.1.3.2.cmml" xref="alg3.l14.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l14.m1.1.1.3.2.1.cmml" xref="alg3.l14.m1.1.1.3">superscript</csymbol><ci id="alg3.l14.m1.1.1.3.2.2.cmml" xref="alg3.l14.m1.1.1.3.2.2">ℎ</ci><ci id="alg3.l14.m1.1.1.3.2.3.cmml" xref="alg3.l14.m1.1.1.3.2.3">𝐴</ci></apply><ci id="alg3.l14.m1.1.1.3.3.cmml" xref="alg3.l14.m1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l14.m1.1.1.1.cmml" xref="alg3.l14.m1.1.1.1"><times id="alg3.l14.m1.1.1.1.2.cmml" xref="alg3.l14.m1.1.1.1.2"></times><apply id="alg3.l14.m1.1.1.1.3.cmml" xref="alg3.l14.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l14.m1.1.1.1.3.1.cmml" xref="alg3.l14.m1.1.1.1.3">subscript</csymbol><apply id="alg3.l14.m1.1.1.1.3.2.cmml" xref="alg3.l14.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l14.m1.1.1.1.3.2.1.cmml" xref="alg3.l14.m1.1.1.1.3">superscript</csymbol><ci id="alg3.l14.m1.1.1.1.3.2.2.cmml" xref="alg3.l14.m1.1.1.1.3.2.2">ℳ</ci><ci id="alg3.l14.m1.1.1.1.3.2.3.cmml" xref="alg3.l14.m1.1.1.1.3.2.3">𝐴</ci></apply><ci id="alg3.l14.m1.1.1.1.3.3.cmml" xref="alg3.l14.m1.1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l14.m1.1.1.1.1.1.1.cmml" xref="alg3.l14.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l14.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l14.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l14.m1.1.1.1.1.1.1.2.cmml" xref="alg3.l14.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l14.m1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l14.m1.1.1.1.1.1">superscript</csymbol><ci id="alg3.l14.m1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l14.m1.1.1.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l14.m1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l14.m1.1.1.1.1.1.1.2.3">𝐹</ci></apply><apply id="alg3.l14.m1.1.1.1.1.1.1.3.cmml" xref="alg3.l14.m1.1.1.1.1.1.1.3"><minus id="alg3.l14.m1.1.1.1.1.1.1.3.1.cmml" xref="alg3.l14.m1.1.1.1.1.1.1.3.1"></minus><ci id="alg3.l14.m1.1.1.1.1.1.1.3.2.cmml" xref="alg3.l14.m1.1.1.1.1.1.1.3.2">𝑖</ci><cn id="alg3.l14.m1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="alg3.l14.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l14.m1.1c">h^{A}_{i}=\mathcal{M}^{A}_{i}(h^{F}_{i-1})</annotation><annotation encoding="application/x-llamapun" id="alg3.l14.m1.1d">italic_h start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_M start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l14.3" style="font-size:90%;">;
</span>
</div>
<div class="ltx_listingline" id="alg3.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l15.1.1.1" style="font-size:80%;">15:</span></span><span class="ltx_text" id="alg3.l15.2" style="font-size:90%;">        </span><math alttext="h^{R}_{i}=h^{A}_{i}+\frac{1}{k}\sum_{j}w_{j}e_{v_{j}}" class="ltx_Math" display="inline" id="alg3.l15.m1.1"><semantics id="alg3.l15.m1.1a"><mrow id="alg3.l15.m1.1.1" xref="alg3.l15.m1.1.1.cmml"><msubsup id="alg3.l15.m1.1.1.2" xref="alg3.l15.m1.1.1.2.cmml"><mi id="alg3.l15.m1.1.1.2.2.2" mathsize="90%" xref="alg3.l15.m1.1.1.2.2.2.cmml">h</mi><mi id="alg3.l15.m1.1.1.2.3" mathsize="90%" xref="alg3.l15.m1.1.1.2.3.cmml">i</mi><mi id="alg3.l15.m1.1.1.2.2.3" mathsize="90%" xref="alg3.l15.m1.1.1.2.2.3.cmml">R</mi></msubsup><mo id="alg3.l15.m1.1.1.1" mathsize="90%" xref="alg3.l15.m1.1.1.1.cmml">=</mo><mrow id="alg3.l15.m1.1.1.3" xref="alg3.l15.m1.1.1.3.cmml"><msubsup id="alg3.l15.m1.1.1.3.2" xref="alg3.l15.m1.1.1.3.2.cmml"><mi id="alg3.l15.m1.1.1.3.2.2.2" mathsize="90%" xref="alg3.l15.m1.1.1.3.2.2.2.cmml">h</mi><mi id="alg3.l15.m1.1.1.3.2.3" mathsize="90%" xref="alg3.l15.m1.1.1.3.2.3.cmml">i</mi><mi id="alg3.l15.m1.1.1.3.2.2.3" mathsize="90%" xref="alg3.l15.m1.1.1.3.2.2.3.cmml">A</mi></msubsup><mo id="alg3.l15.m1.1.1.3.1" mathsize="90%" xref="alg3.l15.m1.1.1.3.1.cmml">+</mo><mrow id="alg3.l15.m1.1.1.3.3" xref="alg3.l15.m1.1.1.3.3.cmml"><mfrac id="alg3.l15.m1.1.1.3.3.2" xref="alg3.l15.m1.1.1.3.3.2.cmml"><mn id="alg3.l15.m1.1.1.3.3.2.2" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.2.2.cmml">1</mn><mi id="alg3.l15.m1.1.1.3.3.2.3" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.2.3.cmml">k</mi></mfrac><mo id="alg3.l15.m1.1.1.3.3.1" xref="alg3.l15.m1.1.1.3.3.1.cmml">⁢</mo><mrow id="alg3.l15.m1.1.1.3.3.3" xref="alg3.l15.m1.1.1.3.3.3.cmml"><msub id="alg3.l15.m1.1.1.3.3.3.1" xref="alg3.l15.m1.1.1.3.3.3.1.cmml"><mo id="alg3.l15.m1.1.1.3.3.3.1.2" maxsize="90%" minsize="90%" stretchy="true" xref="alg3.l15.m1.1.1.3.3.3.1.2.cmml">∑</mo><mi id="alg3.l15.m1.1.1.3.3.3.1.3" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.3.1.3.cmml">j</mi></msub><mrow id="alg3.l15.m1.1.1.3.3.3.2" xref="alg3.l15.m1.1.1.3.3.3.2.cmml"><msub id="alg3.l15.m1.1.1.3.3.3.2.2" xref="alg3.l15.m1.1.1.3.3.3.2.2.cmml"><mi id="alg3.l15.m1.1.1.3.3.3.2.2.2" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.3.2.2.2.cmml">w</mi><mi id="alg3.l15.m1.1.1.3.3.3.2.2.3" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.3.2.2.3.cmml">j</mi></msub><mo id="alg3.l15.m1.1.1.3.3.3.2.1" xref="alg3.l15.m1.1.1.3.3.3.2.1.cmml">⁢</mo><msub id="alg3.l15.m1.1.1.3.3.3.2.3" xref="alg3.l15.m1.1.1.3.3.3.2.3.cmml"><mi id="alg3.l15.m1.1.1.3.3.3.2.3.2" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.3.2.3.2.cmml">e</mi><msub id="alg3.l15.m1.1.1.3.3.3.2.3.3" xref="alg3.l15.m1.1.1.3.3.3.2.3.3.cmml"><mi id="alg3.l15.m1.1.1.3.3.3.2.3.3.2" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.3.2.3.3.2.cmml">v</mi><mi id="alg3.l15.m1.1.1.3.3.3.2.3.3.3" mathsize="90%" xref="alg3.l15.m1.1.1.3.3.3.2.3.3.3.cmml">j</mi></msub></msub></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l15.m1.1b"><apply id="alg3.l15.m1.1.1.cmml" xref="alg3.l15.m1.1.1"><eq id="alg3.l15.m1.1.1.1.cmml" xref="alg3.l15.m1.1.1.1"></eq><apply id="alg3.l15.m1.1.1.2.cmml" xref="alg3.l15.m1.1.1.2"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.2.1.cmml" xref="alg3.l15.m1.1.1.2">subscript</csymbol><apply id="alg3.l15.m1.1.1.2.2.cmml" xref="alg3.l15.m1.1.1.2"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.2.2.1.cmml" xref="alg3.l15.m1.1.1.2">superscript</csymbol><ci id="alg3.l15.m1.1.1.2.2.2.cmml" xref="alg3.l15.m1.1.1.2.2.2">ℎ</ci><ci id="alg3.l15.m1.1.1.2.2.3.cmml" xref="alg3.l15.m1.1.1.2.2.3">𝑅</ci></apply><ci id="alg3.l15.m1.1.1.2.3.cmml" xref="alg3.l15.m1.1.1.2.3">𝑖</ci></apply><apply id="alg3.l15.m1.1.1.3.cmml" xref="alg3.l15.m1.1.1.3"><plus id="alg3.l15.m1.1.1.3.1.cmml" xref="alg3.l15.m1.1.1.3.1"></plus><apply id="alg3.l15.m1.1.1.3.2.cmml" xref="alg3.l15.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.3.2.1.cmml" xref="alg3.l15.m1.1.1.3.2">subscript</csymbol><apply id="alg3.l15.m1.1.1.3.2.2.cmml" xref="alg3.l15.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.3.2.2.1.cmml" xref="alg3.l15.m1.1.1.3.2">superscript</csymbol><ci id="alg3.l15.m1.1.1.3.2.2.2.cmml" xref="alg3.l15.m1.1.1.3.2.2.2">ℎ</ci><ci id="alg3.l15.m1.1.1.3.2.2.3.cmml" xref="alg3.l15.m1.1.1.3.2.2.3">𝐴</ci></apply><ci id="alg3.l15.m1.1.1.3.2.3.cmml" xref="alg3.l15.m1.1.1.3.2.3">𝑖</ci></apply><apply id="alg3.l15.m1.1.1.3.3.cmml" xref="alg3.l15.m1.1.1.3.3"><times id="alg3.l15.m1.1.1.3.3.1.cmml" xref="alg3.l15.m1.1.1.3.3.1"></times><apply id="alg3.l15.m1.1.1.3.3.2.cmml" xref="alg3.l15.m1.1.1.3.3.2"><divide id="alg3.l15.m1.1.1.3.3.2.1.cmml" xref="alg3.l15.m1.1.1.3.3.2"></divide><cn id="alg3.l15.m1.1.1.3.3.2.2.cmml" type="integer" xref="alg3.l15.m1.1.1.3.3.2.2">1</cn><ci id="alg3.l15.m1.1.1.3.3.2.3.cmml" xref="alg3.l15.m1.1.1.3.3.2.3">𝑘</ci></apply><apply id="alg3.l15.m1.1.1.3.3.3.cmml" xref="alg3.l15.m1.1.1.3.3.3"><apply id="alg3.l15.m1.1.1.3.3.3.1.cmml" xref="alg3.l15.m1.1.1.3.3.3.1"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.3.3.3.1.1.cmml" xref="alg3.l15.m1.1.1.3.3.3.1">subscript</csymbol><sum id="alg3.l15.m1.1.1.3.3.3.1.2.cmml" xref="alg3.l15.m1.1.1.3.3.3.1.2"></sum><ci id="alg3.l15.m1.1.1.3.3.3.1.3.cmml" xref="alg3.l15.m1.1.1.3.3.3.1.3">𝑗</ci></apply><apply id="alg3.l15.m1.1.1.3.3.3.2.cmml" xref="alg3.l15.m1.1.1.3.3.3.2"><times id="alg3.l15.m1.1.1.3.3.3.2.1.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.1"></times><apply id="alg3.l15.m1.1.1.3.3.3.2.2.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.2"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.3.3.3.2.2.1.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.2">subscript</csymbol><ci id="alg3.l15.m1.1.1.3.3.3.2.2.2.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.2.2">𝑤</ci><ci id="alg3.l15.m1.1.1.3.3.3.2.2.3.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.2.3">𝑗</ci></apply><apply id="alg3.l15.m1.1.1.3.3.3.2.3.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.3.3.3.2.3.1.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3">subscript</csymbol><ci id="alg3.l15.m1.1.1.3.3.3.2.3.2.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3.2">𝑒</ci><apply id="alg3.l15.m1.1.1.3.3.3.2.3.3.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3.3"><csymbol cd="ambiguous" id="alg3.l15.m1.1.1.3.3.3.2.3.3.1.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3.3">subscript</csymbol><ci id="alg3.l15.m1.1.1.3.3.3.2.3.3.2.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3.3.2">𝑣</ci><ci id="alg3.l15.m1.1.1.3.3.3.2.3.3.3.cmml" xref="alg3.l15.m1.1.1.3.3.3.2.3.3.3">𝑗</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l15.m1.1c">h^{R}_{i}=h^{A}_{i}+\frac{1}{k}\sum_{j}w_{j}e_{v_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg3.l15.m1.1d">italic_h start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_h start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + divide start_ARG 1 end_ARG start_ARG italic_k end_ARG ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_e start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg3.l15.3" style="font-size:90%;"> </span><span class="ltx_text" id="alg3.l15.4" style="font-size:90%;float:right;">/* Use a weighted sum mechanism to fuse the retrieved knowledge */
</span>
</div>
<div class="ltx_listingline" id="alg3.l16">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l16.1.1.1" style="font-size:80%;">16:</span></span><span class="ltx_text" id="alg3.l16.2" style="font-size:90%;">        </span><math alttext="h^{F}_{i}=\mathcal{M}^{F}_{i}(h^{R}_{i})" class="ltx_Math" display="inline" id="alg3.l16.m1.1"><semantics id="alg3.l16.m1.1a"><mrow id="alg3.l16.m1.1.1" xref="alg3.l16.m1.1.1.cmml"><msubsup id="alg3.l16.m1.1.1.3" xref="alg3.l16.m1.1.1.3.cmml"><mi id="alg3.l16.m1.1.1.3.2.2" mathsize="90%" xref="alg3.l16.m1.1.1.3.2.2.cmml">h</mi><mi id="alg3.l16.m1.1.1.3.3" mathsize="90%" xref="alg3.l16.m1.1.1.3.3.cmml">i</mi><mi id="alg3.l16.m1.1.1.3.2.3" mathsize="90%" xref="alg3.l16.m1.1.1.3.2.3.cmml">F</mi></msubsup><mo id="alg3.l16.m1.1.1.2" mathsize="90%" xref="alg3.l16.m1.1.1.2.cmml">=</mo><mrow id="alg3.l16.m1.1.1.1" xref="alg3.l16.m1.1.1.1.cmml"><msubsup id="alg3.l16.m1.1.1.1.3" xref="alg3.l16.m1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l16.m1.1.1.1.3.2.2" mathsize="90%" xref="alg3.l16.m1.1.1.1.3.2.2.cmml">ℳ</mi><mi id="alg3.l16.m1.1.1.1.3.3" mathsize="90%" xref="alg3.l16.m1.1.1.1.3.3.cmml">i</mi><mi id="alg3.l16.m1.1.1.1.3.2.3" mathsize="90%" xref="alg3.l16.m1.1.1.1.3.2.3.cmml">F</mi></msubsup><mo id="alg3.l16.m1.1.1.1.2" xref="alg3.l16.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg3.l16.m1.1.1.1.1.1" xref="alg3.l16.m1.1.1.1.1.1.1.cmml"><mo id="alg3.l16.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg3.l16.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg3.l16.m1.1.1.1.1.1.1" xref="alg3.l16.m1.1.1.1.1.1.1.cmml"><mi id="alg3.l16.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg3.l16.m1.1.1.1.1.1.1.2.2.cmml">h</mi><mi id="alg3.l16.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg3.l16.m1.1.1.1.1.1.1.3.cmml">i</mi><mi id="alg3.l16.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg3.l16.m1.1.1.1.1.1.1.2.3.cmml">R</mi></msubsup><mo id="alg3.l16.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg3.l16.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l16.m1.1b"><apply id="alg3.l16.m1.1.1.cmml" xref="alg3.l16.m1.1.1"><eq id="alg3.l16.m1.1.1.2.cmml" xref="alg3.l16.m1.1.1.2"></eq><apply id="alg3.l16.m1.1.1.3.cmml" xref="alg3.l16.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l16.m1.1.1.3.1.cmml" xref="alg3.l16.m1.1.1.3">subscript</csymbol><apply id="alg3.l16.m1.1.1.3.2.cmml" xref="alg3.l16.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l16.m1.1.1.3.2.1.cmml" xref="alg3.l16.m1.1.1.3">superscript</csymbol><ci id="alg3.l16.m1.1.1.3.2.2.cmml" xref="alg3.l16.m1.1.1.3.2.2">ℎ</ci><ci id="alg3.l16.m1.1.1.3.2.3.cmml" xref="alg3.l16.m1.1.1.3.2.3">𝐹</ci></apply><ci id="alg3.l16.m1.1.1.3.3.cmml" xref="alg3.l16.m1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l16.m1.1.1.1.cmml" xref="alg3.l16.m1.1.1.1"><times id="alg3.l16.m1.1.1.1.2.cmml" xref="alg3.l16.m1.1.1.1.2"></times><apply id="alg3.l16.m1.1.1.1.3.cmml" xref="alg3.l16.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l16.m1.1.1.1.3.1.cmml" xref="alg3.l16.m1.1.1.1.3">subscript</csymbol><apply id="alg3.l16.m1.1.1.1.3.2.cmml" xref="alg3.l16.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l16.m1.1.1.1.3.2.1.cmml" xref="alg3.l16.m1.1.1.1.3">superscript</csymbol><ci id="alg3.l16.m1.1.1.1.3.2.2.cmml" xref="alg3.l16.m1.1.1.1.3.2.2">ℳ</ci><ci id="alg3.l16.m1.1.1.1.3.2.3.cmml" xref="alg3.l16.m1.1.1.1.3.2.3">𝐹</ci></apply><ci id="alg3.l16.m1.1.1.1.3.3.cmml" xref="alg3.l16.m1.1.1.1.3.3">𝑖</ci></apply><apply id="alg3.l16.m1.1.1.1.1.1.1.cmml" xref="alg3.l16.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l16.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l16.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l16.m1.1.1.1.1.1.1.2.cmml" xref="alg3.l16.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l16.m1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l16.m1.1.1.1.1.1">superscript</csymbol><ci id="alg3.l16.m1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l16.m1.1.1.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l16.m1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l16.m1.1.1.1.1.1.1.2.3">𝑅</ci></apply><ci id="alg3.l16.m1.1.1.1.1.1.1.3.cmml" xref="alg3.l16.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l16.m1.1c">h^{F}_{i}=\mathcal{M}^{F}_{i}(h^{R}_{i})</annotation><annotation encoding="application/x-llamapun" id="alg3.l16.m1.1d">italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = caligraphic_M start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_h start_POSTSUPERSCRIPT italic_R end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l16.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l17.1.1.1" style="font-size:80%;">17:</span></span><span class="ltx_text" id="alg3.l17.2" style="font-size:90%;">     </span><span class="ltx_text ltx_font_bold" id="alg3.l17.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg3.l17.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg3.l17.5" style="font-size:90%;">for</span>
</div>
<div class="ltx_listingline" id="alg3.l18">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l18.1.1.1" style="font-size:80%;">18:</span></span><span class="ltx_text" id="alg3.l18.2" style="font-size:90%;">     </span><math alttext="y=LM\_HEAD(h^{F}_{l})" class="ltx_Math" display="inline" id="alg3.l18.m1.1"><semantics id="alg3.l18.m1.1a"><mrow id="alg3.l18.m1.1.1" xref="alg3.l18.m1.1.1.cmml"><mi id="alg3.l18.m1.1.1.3" mathsize="90%" xref="alg3.l18.m1.1.1.3.cmml">y</mi><mo id="alg3.l18.m1.1.1.2" mathsize="90%" xref="alg3.l18.m1.1.1.2.cmml">=</mo><mrow id="alg3.l18.m1.1.1.1" xref="alg3.l18.m1.1.1.1.cmml"><mi id="alg3.l18.m1.1.1.1.3" mathsize="90%" xref="alg3.l18.m1.1.1.1.3.cmml">L</mi><mo id="alg3.l18.m1.1.1.1.2" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l18.m1.1.1.1.4" mathsize="90%" xref="alg3.l18.m1.1.1.1.4.cmml">M</mi><mo id="alg3.l18.m1.1.1.1.2a" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l18.m1.1.1.1.5" mathsize="90%" mathvariant="normal" xref="alg3.l18.m1.1.1.1.5.cmml">_</mi><mo id="alg3.l18.m1.1.1.1.2b" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l18.m1.1.1.1.6" mathsize="90%" xref="alg3.l18.m1.1.1.1.6.cmml">H</mi><mo id="alg3.l18.m1.1.1.1.2c" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l18.m1.1.1.1.7" mathsize="90%" xref="alg3.l18.m1.1.1.1.7.cmml">E</mi><mo id="alg3.l18.m1.1.1.1.2d" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l18.m1.1.1.1.8" mathsize="90%" xref="alg3.l18.m1.1.1.1.8.cmml">A</mi><mo id="alg3.l18.m1.1.1.1.2e" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mi id="alg3.l18.m1.1.1.1.9" mathsize="90%" xref="alg3.l18.m1.1.1.1.9.cmml">D</mi><mo id="alg3.l18.m1.1.1.1.2f" xref="alg3.l18.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg3.l18.m1.1.1.1.1.1" xref="alg3.l18.m1.1.1.1.1.1.1.cmml"><mo id="alg3.l18.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="alg3.l18.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg3.l18.m1.1.1.1.1.1.1" xref="alg3.l18.m1.1.1.1.1.1.1.cmml"><mi id="alg3.l18.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="alg3.l18.m1.1.1.1.1.1.1.2.2.cmml">h</mi><mi id="alg3.l18.m1.1.1.1.1.1.1.3" mathsize="90%" xref="alg3.l18.m1.1.1.1.1.1.1.3.cmml">l</mi><mi id="alg3.l18.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="alg3.l18.m1.1.1.1.1.1.1.2.3.cmml">F</mi></msubsup><mo id="alg3.l18.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="alg3.l18.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l18.m1.1b"><apply id="alg3.l18.m1.1.1.cmml" xref="alg3.l18.m1.1.1"><eq id="alg3.l18.m1.1.1.2.cmml" xref="alg3.l18.m1.1.1.2"></eq><ci id="alg3.l18.m1.1.1.3.cmml" xref="alg3.l18.m1.1.1.3">𝑦</ci><apply id="alg3.l18.m1.1.1.1.cmml" xref="alg3.l18.m1.1.1.1"><times id="alg3.l18.m1.1.1.1.2.cmml" xref="alg3.l18.m1.1.1.1.2"></times><ci id="alg3.l18.m1.1.1.1.3.cmml" xref="alg3.l18.m1.1.1.1.3">𝐿</ci><ci id="alg3.l18.m1.1.1.1.4.cmml" xref="alg3.l18.m1.1.1.1.4">𝑀</ci><ci id="alg3.l18.m1.1.1.1.5.cmml" xref="alg3.l18.m1.1.1.1.5">_</ci><ci id="alg3.l18.m1.1.1.1.6.cmml" xref="alg3.l18.m1.1.1.1.6">𝐻</ci><ci id="alg3.l18.m1.1.1.1.7.cmml" xref="alg3.l18.m1.1.1.1.7">𝐸</ci><ci id="alg3.l18.m1.1.1.1.8.cmml" xref="alg3.l18.m1.1.1.1.8">𝐴</ci><ci id="alg3.l18.m1.1.1.1.9.cmml" xref="alg3.l18.m1.1.1.1.9">𝐷</ci><apply id="alg3.l18.m1.1.1.1.1.1.1.cmml" xref="alg3.l18.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l18.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l18.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l18.m1.1.1.1.1.1.1.2.cmml" xref="alg3.l18.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l18.m1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l18.m1.1.1.1.1.1">superscript</csymbol><ci id="alg3.l18.m1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l18.m1.1.1.1.1.1.1.2.2">ℎ</ci><ci id="alg3.l18.m1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l18.m1.1.1.1.1.1.1.2.3">𝐹</ci></apply><ci id="alg3.l18.m1.1.1.1.1.1.1.3.cmml" xref="alg3.l18.m1.1.1.1.1.1.1.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l18.m1.1c">y=LM\_HEAD(h^{F}_{l})</annotation><annotation encoding="application/x-llamapun" id="alg3.l18.m1.1d">italic_y = italic_L italic_M _ italic_H italic_E italic_A italic_D ( italic_h start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="alg3.l18.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg3.l19">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l19.1.1.1" style="font-size:80%;">19:</span></span><span class="ltx_text" id="alg3.l19.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg3.l19.3" style="font-size:90%;">end</span><span class="ltx_text" id="alg3.l19.4" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg3.l19.5" style="font-size:90%;">if</span>
</div>
<div class="ltx_listingline" id="alg3.l20">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l20.1.1.1" style="font-size:80%;">20:</span></span><span class="ltx_text" id="alg3.l20.2" style="font-size:90%;">  </span><span class="ltx_text ltx_font_bold" id="alg3.l20.3" style="font-size:90%;">return</span><span class="ltx_text" id="alg3.l20.4" style="font-size:90%;">  </span><math alttext="y" class="ltx_Math" display="inline" id="alg3.l20.m1.1"><semantics id="alg3.l20.m1.1a"><mi id="alg3.l20.m1.1.1" mathsize="90%" xref="alg3.l20.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="alg3.l20.m1.1b"><ci id="alg3.l20.m1.1.1.cmml" xref="alg3.l20.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l20.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="alg3.l20.m1.1d">italic_y</annotation></semantics></math><span class="ltx_text" id="alg3.l20.5" style="font-size:90%;">;
</span>
</div>
</div>
<br class="ltx_break ltx_break"/>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Latent Fusion</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The latent fusion investigates merging the retrieved knowledge into the hidden states of generators for a better generation.
Based on the introduction method, latent fusion can be further classified into two categories: attention-based and weighted-addition.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">One notable contribution of attention-based fusion is the Retrieval-Enhanced Transformer (RETRO) <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>)</cite>.
RETRO represents a pioneering effort in pre-training retrieval-based LLMs, introducing a new cross-attention module to integrate retrieved knowledge directly into the model’s hidden states.
A significant finding from this work is demonstrating a scaling law for the retrieval database, where RETRO, with a 2 trillion token database, attains performance comparable to that of major models like GPT-3 and Jurassic-1, albeit with 25 times fewer parameters.
Customizing the transformer model in RETRO highlights the potential of pre-trained, retrieval-enhanced architectures in improving the efficiency and scalability of LLMs.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">In addition to RETRO, other studies <cite class="ltx_cite ltx_citemacro_citep">(Cai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib13" title="">2021</a>; Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib155" title="">2022</a>; de Jong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib27" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib94" title="">2022a</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib152" title="">2023d</a>)</cite> have contributed to the field by leveraging new attention modules to introduce external knowledge.
Typically, Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib94" title="">2022a</a>)</cite> have extended the RETRO model by decoupling the context encoding from the model inference.
Wu et al. <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib155" title="">2022</a>)</cite>, Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib148" title="">2023b</a>)</cite> store the hidden attention keys and values into external memory and retrieve the knowledge from the memory using an attention mechanism.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Due to the high complexity of the attention mechanism, another branch of work adopts lightweight (weighted) additions to introduce retrieved knowledge.
Fevry et al. <cite class="ltx_cite ltx_citemacro_citep">(Févry et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib39" title="">2020</a>)</cite> propose the EAE model that retrieves top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS3.p4.1.m1.1"><semantics id="S4.SS3.p4.1.m1.1a"><mi id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><ci id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.m1.1d">italic_k</annotation></semantics></math> related entities’ embeddings from a learnable external memory and adds entities’ embeddings to the hidden states of the model.
Wu et al. <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib154" title="">2024</a>)</cite> propose ReFusion, which explores various learnable reranking schemes to first re-weight the retrieved knowledge’s embeddings, then use weighted addition to incorporate them into the hidden states of the model.
Those approaches signify a growing trend towards models that dynamically select and integrate relevant knowledge, paving the way for more sophisticated and nuanced language generation and understanding.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg3" title="Algorithm 3 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> shows the steps of using latent fusion to introduce the retrieved knowledge into the hidden states of the generator.
For attention-based latent fusion, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg3" title="Algorithm 3 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> first encodes the retrievals with the output states of the attention module (line 5), then uses a cross-attention module to fuse the retrieval features into the hidden state (line 6).
Different from attention-based latent fusion, weighted-addition-based latent fusion adopts a more lightweight way to incorporate retrieved knowledge (lines 10-19).
Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg3" title="Algorithm 3 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> first encodes the retrievals before feeding them into the generator (line 11), which can be done offline and directly stored as values in the datastore.
Then, algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#alg3" title="Algorithm 3 ‣ 4.2. Logits-based Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> learns a set of weights to add the retrieval features on the hidden states of generators (line 15).</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="390" id="S4.F4.g1" src="x3.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Different RAG training strategies with/without datastore update.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Generators</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This section introduces representative generators and retrieval-augmented generators, which are generally pre-trained on large datasets.
Existing generators are mostly large language models that adopt or modify the transformer-based architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib141" title="">2017</a>)</cite>.
For example, Llama-series models <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib139" title="">2023a</a>; Touvron
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib140" title="">2023b</a>)</cite>, GPT-series models <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib119" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib120" title="">2019</a>; Brown
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib12" title="">2020</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib115" title="">2023</a>)</cite>, and Gemini-series models <cite class="ltx_cite ltx_citemacro_citep">(Anil et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib5" title="">2023</a>; Reid
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib125" title="">2024</a>; Mesnard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib109" title="">2024</a>)</cite> remove all encoder modules, retaining only the decoder module, which includes an attention module and a feed-forward network module.
Other advanced techniques, such as root mean square layer normalization <cite class="ltx_cite ltx_citemacro_citep">(Zhang and
Sennrich, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib166" title="">2019</a>)</cite>, rotary position embedding <cite class="ltx_cite ltx_citemacro_citep">(Su
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib137" title="">2024</a>)</cite>, and group query attention mechanisms <cite class="ltx_cite ltx_citemacro_citep">(Ainslie et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib3" title="">2023</a>)</cite>, have been incorporated into the design of existing large language models to enhance their performance.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Retrieval-augmented generators typically incorporate new modules into the architecture of existing large language models. They are also pre-trained on a large dataset and an external knowledge database constructed from a vast natural language corpus.
These generators mostly leverage latent fusions to incorporate the knowledge into the hidden states of large language models <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>; Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib155" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib94" title="">2022a</a>)</cite>, which has been discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4.SS3" title="4.3. Latent Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>RAG Training</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This section introduces RAG training, which can be categorized into two main classes: <span class="ltx_text ltx_font_bold" id="S6.p1.1.1">RAG without datastore update</span> and <span class="ltx_text ltx_font_bold" id="S6.p1.1.2">RAG with datastore update</span>.
The former refers to the case where only trainable parameters in each module of RAG would be updated, and the knowledge in the datastore would remain the same during the training stage.
The latter refers to the case where the knowledge in the datastore would be updated, then each module’s parameters in RAG would be updated in a similar way as the former case.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>RAG without Datastore Update</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">The goal of training RAG without datastore update is to update the knowledge stored in the short-term memory of generators based on the existing knowledge datastore.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4.F4" title="Figure 4 ‣ 4.3. Latent Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a> (a)-(c), there are three training cases, i.e., training the retriever, training the generator, and jointly training the retriever and generator.</p>
</div>
<section class="ltx_subsubsection" id="S6.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.1. </span>Training retriever.</h4>
<div class="ltx_para" id="S6.SS1.SSS1.p1">
<p class="ltx_p" id="S6.SS1.SSS1.p1.1">Considering the case of no datastore update, training the retriever generally refers to training the retriever encoder and rebuilding the indexing.
Since sparse encodings typically rely on statistical methods without parameters, training the encoder pertains only to dense encoding methods.
Different training methods may have different goals, such as improving the semantic representations, accelerating the encoding process, or learning the domain-specific representations.
The first two goals are often achieved by replacing the original encoder with a more powerful or tiny encoder, such as DistilBERT <cite class="ltx_cite ltx_citemacro_citep">(Sanh
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib129" title="">2019</a>)</cite> or TinyBERT <cite class="ltx_cite ltx_citemacro_citep">(Jiao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib76" title="">2020</a>)</cite>.
The last requires training the original encoder on the domain-specific corpus using contrastive learning.
After training the retriever encoder, the embeddings that serve as keys in the vector database will also change.
Thus, all indexes should be rebuilt with new embeddings.
Besides, if the encoder remains unchanged, the indexing can be updated using new ANN searching algorithms or re-tuning the hyperparameters.
After the retriever is trained, it can be directly incorporated into the RAG without updating the generator.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.2. </span>Training generator.</h4>
<div class="ltx_para" id="S6.SS1.SSS2.p1">
<p class="ltx_p" id="S6.SS1.SSS2.p1.1">Training the generator involves updating its parameters or those in the retrieval fusion modules.
Since the generator is generally an LLM, training the LLM is a resource- and time-consuming process.
Fortunately, several parameter-efficient fine-tuning techniques, such as LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib58" title="">2022</a>)</cite>, are proposed to address the fine-tuning problem of LLMs.
Although the parameters in the retrieval fusion modules are less than those in the generator, only fine-tuning those parameters may encounter some training problems, such as low convergence and overfitting.
Jointly tuning the parameters in the generator and the retrieval fusion modules is a better way to train the generator and the retrieval fusion modules if there are sufficient and powerful resources.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.3. </span>Jointly training the retriever and generator.</h4>
<div class="ltx_para" id="S6.SS1.SSS3.p1">
<p class="ltx_p" id="S6.SS1.SSS3.p1.1">Apart from independently training the retriever and the generator, jointly training the retriever and the generator can be another good choice for better performance on downstream tasks.
The key to this case is to ensure the differentiability from the input to the output during the forward process.
Typically, complex indexes, such as FAISS <cite class="ltx_cite ltx_citemacro_citep">(Douze et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib33" title="">2024</a>)</cite>, are not a suitable choice during the fine-tuning stage.
Existing works generally leverage the complex indexes to pre-select a small subset of nearest neighbors as candidates, then choose the final top-<math alttext="k" class="ltx_Math" display="inline" id="S6.SS1.SSS3.p1.1.m1.1"><semantics id="S6.SS1.SSS3.p1.1.m1.1a"><mi id="S6.SS1.SSS3.p1.1.m1.1.1" xref="S6.SS1.SSS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS3.p1.1.m1.1b"><ci id="S6.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS3.p1.1.m1.1d">italic_k</annotation></semantics></math> nearest neighbors by performing the matrix-multiplication operations.
Joint training is an end-to-end optimization that can lead to better coordination between the retriever and the generator and improve the contextual understanding of the generator.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>RAG with Datastore Update</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S4.F4" title="Figure 4 ‣ 4.3. Latent Fusion ‣ 4. Retrieval Fusions ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a> (d), this scenario involves two stages: updating the knowledge database, then training the retriever and the generator.
There are three cases for updating the knowledge database, i.e., updating with trainable embeddings, updating with new values, and updating with new corpus.
In the first case, values generally are trainable embeddings and are simultaneously/asynchronously updated with parameters in the RAG <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib15" title="">2022b</a>)</cite>.
The last two cases usually refer to updating the knowledge database with up-to-date information.
Taking question-answer corpus as an example, updating with new values refers to updating the answer to existing questions, while updating with new corpus refers to adding new question-answer pairs.
To update the value of existing keys requires first querying the existing key-value pairs and then performing in-place updates.
For a new corpus, the datastore first needs to perform insertion operations, then rebuilds or updates the indexes for new keys.
After updating the datastore, training the retriever and the generator is similar to RAG without datastore update.
However, this training step is not always a necessary step, benefiting to the in-context learning capability of LLMs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Tasks</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This section lists several classical tasks in the NLP domain and introduces advanced RAG techniques used to solve these tasks.</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Language Modeling</h3>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">Language modeling is the task that requires the prediction of the probability distribution of the next word or character given a sequence of words or characters, which is also named the next-token prediction task.
Language modeling has become the fundamental task for pre-training large language models, which can measure the models’ generation capability using the perplexity metric.
The formal definition is as follows:
given such a sequence of tokens <math alttext="x_{1},\ldots,x_{n}" class="ltx_Math" display="inline" id="S7.SS1.p1.1.m1.3"><semantics id="S7.SS1.p1.1.m1.3a"><mrow id="S7.SS1.p1.1.m1.3.3.2" xref="S7.SS1.p1.1.m1.3.3.3.cmml"><msub id="S7.SS1.p1.1.m1.2.2.1.1" xref="S7.SS1.p1.1.m1.2.2.1.1.cmml"><mi id="S7.SS1.p1.1.m1.2.2.1.1.2" xref="S7.SS1.p1.1.m1.2.2.1.1.2.cmml">x</mi><mn id="S7.SS1.p1.1.m1.2.2.1.1.3" xref="S7.SS1.p1.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S7.SS1.p1.1.m1.3.3.2.3" xref="S7.SS1.p1.1.m1.3.3.3.cmml">,</mo><mi id="S7.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S7.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S7.SS1.p1.1.m1.3.3.2.4" xref="S7.SS1.p1.1.m1.3.3.3.cmml">,</mo><msub id="S7.SS1.p1.1.m1.3.3.2.2" xref="S7.SS1.p1.1.m1.3.3.2.2.cmml"><mi id="S7.SS1.p1.1.m1.3.3.2.2.2" xref="S7.SS1.p1.1.m1.3.3.2.2.2.cmml">x</mi><mi id="S7.SS1.p1.1.m1.3.3.2.2.3" xref="S7.SS1.p1.1.m1.3.3.2.2.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.1.m1.3b"><list id="S7.SS1.p1.1.m1.3.3.3.cmml" xref="S7.SS1.p1.1.m1.3.3.2"><apply id="S7.SS1.p1.1.m1.2.2.1.1.cmml" xref="S7.SS1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S7.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S7.SS1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S7.SS1.p1.1.m1.2.2.1.1.2.cmml" xref="S7.SS1.p1.1.m1.2.2.1.1.2">𝑥</ci><cn id="S7.SS1.p1.1.m1.2.2.1.1.3.cmml" type="integer" xref="S7.SS1.p1.1.m1.2.2.1.1.3">1</cn></apply><ci id="S7.SS1.p1.1.m1.1.1.cmml" xref="S7.SS1.p1.1.m1.1.1">…</ci><apply id="S7.SS1.p1.1.m1.3.3.2.2.cmml" xref="S7.SS1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S7.SS1.p1.1.m1.3.3.2.2.1.cmml" xref="S7.SS1.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S7.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S7.SS1.p1.1.m1.3.3.2.2.2">𝑥</ci><ci id="S7.SS1.p1.1.m1.3.3.2.2.3.cmml" xref="S7.SS1.p1.1.m1.3.3.2.2.3">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.1.m1.3c">x_{1},\ldots,x_{n}</annotation><annotation encoding="application/x-llamapun" id="S7.SS1.p1.1.m1.3d">italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> called <span class="ltx_text ltx_font_italic" id="S7.SS1.p1.1.1">Prefix</span>, the language modeling task aims to model its probability via next-token prediction,</p>
<table class="ltx_equation ltx_eqn_table" id="S7.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p(x_{1},\ldots,x_{n})=p(x_{1})\cdot\prod^{n}_{i=2}p(x_{i}|x_{1},\ldots,x_{i-1})," class="ltx_Math" display="block" id="S7.E1.m1.3"><semantics id="S7.E1.m1.3a"><mrow id="S7.E1.m1.3.3.1" xref="S7.E1.m1.3.3.1.1.cmml"><mrow id="S7.E1.m1.3.3.1.1" xref="S7.E1.m1.3.3.1.1.cmml"><mrow id="S7.E1.m1.3.3.1.1.2" xref="S7.E1.m1.3.3.1.1.2.cmml"><mi id="S7.E1.m1.3.3.1.1.2.4" xref="S7.E1.m1.3.3.1.1.2.4.cmml">p</mi><mo id="S7.E1.m1.3.3.1.1.2.3" xref="S7.E1.m1.3.3.1.1.2.3.cmml">⁢</mo><mrow id="S7.E1.m1.3.3.1.1.2.2.2" xref="S7.E1.m1.3.3.1.1.2.2.3.cmml"><mo id="S7.E1.m1.3.3.1.1.2.2.2.3" stretchy="false" xref="S7.E1.m1.3.3.1.1.2.2.3.cmml">(</mo><msub id="S7.E1.m1.3.3.1.1.1.1.1.1" xref="S7.E1.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S7.E1.m1.3.3.1.1.1.1.1.1.2" xref="S7.E1.m1.3.3.1.1.1.1.1.1.2.cmml">x</mi><mn id="S7.E1.m1.3.3.1.1.1.1.1.1.3" xref="S7.E1.m1.3.3.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S7.E1.m1.3.3.1.1.2.2.2.4" xref="S7.E1.m1.3.3.1.1.2.2.3.cmml">,</mo><mi id="S7.E1.m1.1.1" mathvariant="normal" xref="S7.E1.m1.1.1.cmml">…</mi><mo id="S7.E1.m1.3.3.1.1.2.2.2.5" xref="S7.E1.m1.3.3.1.1.2.2.3.cmml">,</mo><msub id="S7.E1.m1.3.3.1.1.2.2.2.2" xref="S7.E1.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S7.E1.m1.3.3.1.1.2.2.2.2.2" xref="S7.E1.m1.3.3.1.1.2.2.2.2.2.cmml">x</mi><mi id="S7.E1.m1.3.3.1.1.2.2.2.2.3" xref="S7.E1.m1.3.3.1.1.2.2.2.2.3.cmml">n</mi></msub><mo id="S7.E1.m1.3.3.1.1.2.2.2.6" stretchy="false" xref="S7.E1.m1.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S7.E1.m1.3.3.1.1.5" xref="S7.E1.m1.3.3.1.1.5.cmml">=</mo><mrow id="S7.E1.m1.3.3.1.1.4" xref="S7.E1.m1.3.3.1.1.4.cmml"><mrow id="S7.E1.m1.3.3.1.1.3.1" xref="S7.E1.m1.3.3.1.1.3.1.cmml"><mi id="S7.E1.m1.3.3.1.1.3.1.3" xref="S7.E1.m1.3.3.1.1.3.1.3.cmml">p</mi><mo id="S7.E1.m1.3.3.1.1.3.1.2" xref="S7.E1.m1.3.3.1.1.3.1.2.cmml">⁢</mo><mrow id="S7.E1.m1.3.3.1.1.3.1.1.1" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.cmml"><mo id="S7.E1.m1.3.3.1.1.3.1.1.1.2" stretchy="false" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.cmml">(</mo><msub id="S7.E1.m1.3.3.1.1.3.1.1.1.1" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.cmml"><mi id="S7.E1.m1.3.3.1.1.3.1.1.1.1.2" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.2.cmml">x</mi><mn id="S7.E1.m1.3.3.1.1.3.1.1.1.1.3" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.3.cmml">1</mn></msub><mo id="S7.E1.m1.3.3.1.1.3.1.1.1.3" rspace="0.055em" stretchy="false" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S7.E1.m1.3.3.1.1.4.3" rspace="0.055em" xref="S7.E1.m1.3.3.1.1.4.3.cmml">⋅</mo><mrow id="S7.E1.m1.3.3.1.1.4.2" xref="S7.E1.m1.3.3.1.1.4.2.cmml"><munderover id="S7.E1.m1.3.3.1.1.4.2.2" xref="S7.E1.m1.3.3.1.1.4.2.2.cmml"><mo id="S7.E1.m1.3.3.1.1.4.2.2.2.2" movablelimits="false" xref="S7.E1.m1.3.3.1.1.4.2.2.2.2.cmml">∏</mo><mrow id="S7.E1.m1.3.3.1.1.4.2.2.3" xref="S7.E1.m1.3.3.1.1.4.2.2.3.cmml"><mi id="S7.E1.m1.3.3.1.1.4.2.2.3.2" xref="S7.E1.m1.3.3.1.1.4.2.2.3.2.cmml">i</mi><mo id="S7.E1.m1.3.3.1.1.4.2.2.3.1" xref="S7.E1.m1.3.3.1.1.4.2.2.3.1.cmml">=</mo><mn id="S7.E1.m1.3.3.1.1.4.2.2.3.3" xref="S7.E1.m1.3.3.1.1.4.2.2.3.3.cmml">2</mn></mrow><mi id="S7.E1.m1.3.3.1.1.4.2.2.2.3" xref="S7.E1.m1.3.3.1.1.4.2.2.2.3.cmml">n</mi></munderover><mrow id="S7.E1.m1.3.3.1.1.4.2.1" xref="S7.E1.m1.3.3.1.1.4.2.1.cmml"><mi id="S7.E1.m1.3.3.1.1.4.2.1.3" xref="S7.E1.m1.3.3.1.1.4.2.1.3.cmml">p</mi><mo id="S7.E1.m1.3.3.1.1.4.2.1.2" xref="S7.E1.m1.3.3.1.1.4.2.1.2.cmml">⁢</mo><mrow id="S7.E1.m1.3.3.1.1.4.2.1.1.1" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.cmml"><mo id="S7.E1.m1.3.3.1.1.4.2.1.1.1.2" stretchy="false" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.cmml">(</mo><mrow id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.cmml"><msub id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.cmml"><mi id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.2" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.2.cmml">x</mi><mi id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.3" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.3.cmml">i</mi></msub><mo fence="false" id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.3" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.3.cmml">|</mo><mrow id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.3.cmml"><msub id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.cmml"><mi id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.2" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.3" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.3" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.3.cmml">,</mo><mi id="S7.E1.m1.2.2" mathvariant="normal" xref="S7.E1.m1.2.2.cmml">…</mi><mo id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.4" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.3.cmml">,</mo><msub id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.cmml"><mi id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.2" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.2.cmml">x</mi><mrow id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.cmml"><mi id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.2" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.2.cmml">i</mi><mo id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.1" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.3" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo id="S7.E1.m1.3.3.1.1.4.2.1.1.1.3" stretchy="false" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S7.E1.m1.3.3.1.2" xref="S7.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.E1.m1.3b"><apply id="S7.E1.m1.3.3.1.1.cmml" xref="S7.E1.m1.3.3.1"><eq id="S7.E1.m1.3.3.1.1.5.cmml" xref="S7.E1.m1.3.3.1.1.5"></eq><apply id="S7.E1.m1.3.3.1.1.2.cmml" xref="S7.E1.m1.3.3.1.1.2"><times id="S7.E1.m1.3.3.1.1.2.3.cmml" xref="S7.E1.m1.3.3.1.1.2.3"></times><ci id="S7.E1.m1.3.3.1.1.2.4.cmml" xref="S7.E1.m1.3.3.1.1.2.4">𝑝</ci><vector id="S7.E1.m1.3.3.1.1.2.2.3.cmml" xref="S7.E1.m1.3.3.1.1.2.2.2"><apply id="S7.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S7.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S7.E1.m1.3.3.1.1.1.1.1.1.2">𝑥</ci><cn id="S7.E1.m1.3.3.1.1.1.1.1.1.3.cmml" type="integer" xref="S7.E1.m1.3.3.1.1.1.1.1.1.3">1</cn></apply><ci id="S7.E1.m1.1.1.cmml" xref="S7.E1.m1.1.1">…</ci><apply id="S7.E1.m1.3.3.1.1.2.2.2.2.cmml" xref="S7.E1.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S7.E1.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="S7.E1.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S7.E1.m1.3.3.1.1.2.2.2.2.2">𝑥</ci><ci id="S7.E1.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S7.E1.m1.3.3.1.1.2.2.2.2.3">𝑛</ci></apply></vector></apply><apply id="S7.E1.m1.3.3.1.1.4.cmml" xref="S7.E1.m1.3.3.1.1.4"><ci id="S7.E1.m1.3.3.1.1.4.3.cmml" xref="S7.E1.m1.3.3.1.1.4.3">⋅</ci><apply id="S7.E1.m1.3.3.1.1.3.1.cmml" xref="S7.E1.m1.3.3.1.1.3.1"><times id="S7.E1.m1.3.3.1.1.3.1.2.cmml" xref="S7.E1.m1.3.3.1.1.3.1.2"></times><ci id="S7.E1.m1.3.3.1.1.3.1.3.cmml" xref="S7.E1.m1.3.3.1.1.3.1.3">𝑝</ci><apply id="S7.E1.m1.3.3.1.1.3.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.3.1.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.3.1.1.1">subscript</csymbol><ci id="S7.E1.m1.3.3.1.1.3.1.1.1.1.2.cmml" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.2">𝑥</ci><cn id="S7.E1.m1.3.3.1.1.3.1.1.1.1.3.cmml" type="integer" xref="S7.E1.m1.3.3.1.1.3.1.1.1.1.3">1</cn></apply></apply><apply id="S7.E1.m1.3.3.1.1.4.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2"><apply id="S7.E1.m1.3.3.1.1.4.2.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.4.2.2.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2">subscript</csymbol><apply id="S7.E1.m1.3.3.1.1.4.2.2.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.4.2.2.2.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2">superscript</csymbol><csymbol cd="latexml" id="S7.E1.m1.3.3.1.1.4.2.2.2.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2.2.2">product</csymbol><ci id="S7.E1.m1.3.3.1.1.4.2.2.2.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2.2.3">𝑛</ci></apply><apply id="S7.E1.m1.3.3.1.1.4.2.2.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2.3"><eq id="S7.E1.m1.3.3.1.1.4.2.2.3.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2.3.1"></eq><ci id="S7.E1.m1.3.3.1.1.4.2.2.3.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.2.3.2">𝑖</ci><cn id="S7.E1.m1.3.3.1.1.4.2.2.3.3.cmml" type="integer" xref="S7.E1.m1.3.3.1.1.4.2.2.3.3">2</cn></apply></apply><apply id="S7.E1.m1.3.3.1.1.4.2.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1"><times id="S7.E1.m1.3.3.1.1.4.2.1.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.2"></times><ci id="S7.E1.m1.3.3.1.1.4.2.1.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.3">𝑝</ci><apply id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1"><csymbol cd="latexml" id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.3">conditional</csymbol><apply id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4">subscript</csymbol><ci id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.2">𝑥</ci><ci id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.4.3">𝑖</ci></apply><list id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2"><apply id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.2">𝑥</ci><cn id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S7.E1.m1.2.2.cmml" xref="S7.E1.m1.2.2">…</ci><apply id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.2">𝑥</ci><apply id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3"><minus id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.1.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.1"></minus><ci id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.2.cmml" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.2">𝑖</ci><cn id="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.3.cmml" type="integer" xref="S7.E1.m1.3.3.1.1.4.2.1.1.1.1.2.2.2.3.3">1</cn></apply></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E1.m1.3c">p(x_{1},\ldots,x_{n})=p(x_{1})\cdot\prod^{n}_{i=2}p(x_{i}|x_{1},\ldots,x_{i-1}),</annotation><annotation encoding="application/x-llamapun" id="S7.E1.m1.3d">italic_p ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = italic_p ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ⋅ ∏ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 2 end_POSTSUBSCRIPT italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S7.SS1.p1.2">where the conditional probabilities <math alttext="p(x_{i}|x_{1},\ldots,x_{i-1})" class="ltx_Math" display="inline" id="S7.SS1.p1.2.m1.2"><semantics id="S7.SS1.p1.2.m1.2a"><mrow id="S7.SS1.p1.2.m1.2.2" xref="S7.SS1.p1.2.m1.2.2.cmml"><mi id="S7.SS1.p1.2.m1.2.2.3" xref="S7.SS1.p1.2.m1.2.2.3.cmml">p</mi><mo id="S7.SS1.p1.2.m1.2.2.2" xref="S7.SS1.p1.2.m1.2.2.2.cmml">⁢</mo><mrow id="S7.SS1.p1.2.m1.2.2.1.1" xref="S7.SS1.p1.2.m1.2.2.1.1.1.cmml"><mo id="S7.SS1.p1.2.m1.2.2.1.1.2" stretchy="false" xref="S7.SS1.p1.2.m1.2.2.1.1.1.cmml">(</mo><mrow id="S7.SS1.p1.2.m1.2.2.1.1.1" xref="S7.SS1.p1.2.m1.2.2.1.1.1.cmml"><msub id="S7.SS1.p1.2.m1.2.2.1.1.1.4" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4.cmml"><mi id="S7.SS1.p1.2.m1.2.2.1.1.1.4.2" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4.2.cmml">x</mi><mi id="S7.SS1.p1.2.m1.2.2.1.1.1.4.3" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4.3.cmml">i</mi></msub><mo fence="false" id="S7.SS1.p1.2.m1.2.2.1.1.1.3" xref="S7.SS1.p1.2.m1.2.2.1.1.1.3.cmml">|</mo><mrow id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.3.cmml"><msub id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.2" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.2.cmml">x</mi><mn id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.3" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.3" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.3.cmml">,</mo><mi id="S7.SS1.p1.2.m1.1.1" mathvariant="normal" xref="S7.SS1.p1.2.m1.1.1.cmml">…</mi><mo id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.4" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.3.cmml">,</mo><msub id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.cmml"><mi id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.2" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.2.cmml">x</mi><mrow id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.cmml"><mi id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.2" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.2.cmml">i</mi><mo id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.1" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.3" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo id="S7.SS1.p1.2.m1.2.2.1.1.3" stretchy="false" xref="S7.SS1.p1.2.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.2.m1.2b"><apply id="S7.SS1.p1.2.m1.2.2.cmml" xref="S7.SS1.p1.2.m1.2.2"><times id="S7.SS1.p1.2.m1.2.2.2.cmml" xref="S7.SS1.p1.2.m1.2.2.2"></times><ci id="S7.SS1.p1.2.m1.2.2.3.cmml" xref="S7.SS1.p1.2.m1.2.2.3">𝑝</ci><apply id="S7.SS1.p1.2.m1.2.2.1.1.1.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1"><csymbol cd="latexml" id="S7.SS1.p1.2.m1.2.2.1.1.1.3.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.3">conditional</csymbol><apply id="S7.SS1.p1.2.m1.2.2.1.1.1.4.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4"><csymbol cd="ambiguous" id="S7.SS1.p1.2.m1.2.2.1.1.1.4.1.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4">subscript</csymbol><ci id="S7.SS1.p1.2.m1.2.2.1.1.1.4.2.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4.2">𝑥</ci><ci id="S7.SS1.p1.2.m1.2.2.1.1.1.4.3.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.4.3">𝑖</ci></apply><list id="S7.SS1.p1.2.m1.2.2.1.1.1.2.3.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2"><apply id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.2">𝑥</ci><cn id="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.3.cmml" type="integer" xref="S7.SS1.p1.2.m1.2.2.1.1.1.1.1.1.3">1</cn></apply><ci id="S7.SS1.p1.2.m1.1.1.cmml" xref="S7.SS1.p1.2.m1.1.1">…</ci><apply id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.1.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2">subscript</csymbol><ci id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.2.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.2">𝑥</ci><apply id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3"><minus id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.1.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.1"></minus><ci id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.2.cmml" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.2">𝑖</ci><cn id="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.3.cmml" type="integer" xref="S7.SS1.p1.2.m1.2.2.1.1.1.2.2.2.3.3">1</cn></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.2.m1.2c">p(x_{i}|x_{1},\ldots,x_{i-1})</annotation><annotation encoding="application/x-llamapun" id="S7.SS1.p1.2.m1.2d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math> are modeled by a parameterized language model.</p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1">Recent works mainly leverage RAG further to improve language modeling capability in the pre-training stage.
A branch of works <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib94" title="">2022a</a>; Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib155" title="">2022</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib148" title="">2023b</a>)</cite> modifies the architecture of generators by adding a new cross-attention module in each transformer block for introducing retrieval knowledge.
The intuition of those works is that given the similar <span class="ltx_text ltx_font_italic" id="S7.SS1.p2.1.1">Prefix</span>es and their next tokens (retrieving stage), the pre-trained model can calibrate the model’s prediction using the cross-attention module to capture the pattern between the next token and prefix (model forwarding stage).
Zhong et al. <cite class="ltx_cite ltx_citemacro_citep">(Zhong
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib174" title="">2022</a>)</cite> propose to augment the language model with three types of retrieval memories/databases (local memory, long-term memory, and external memory) and optimize the next-token probability distribution with nearest neighbors retrieved from the memories/databases.
Another branch of works <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib82" title="">2020b</a>; Huang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib65" title="">2023b</a>; Xu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib161" title="">2023a</a>; Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib123" title="">2023b</a>; Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>)</cite> focuses on augmenting the inputs or outputs of generators with retrievals.
Guu et al. <cite class="ltx_cite ltx_citemacro_citep">(Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>)</cite> and Ram et al. <cite class="ltx_cite ltx_citemacro_citep">(Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib123" title="">2023b</a>)</cite> concatenate the retrieved knowledge with inputs and feed the retrieval-augmented inputs into the generators.
Other works <cite class="ltx_cite ltx_citemacro_citep">(Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib82" title="">2020b</a>; Huang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib65" title="">2023b</a>; Xu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib161" title="">2023a</a>)</cite> fuse the logits of inputs as well as retrievals at the final output layer and generate the final probability distribution based on the interpolated results.
Those works believe that the concatenated/fused retrievals can provide useful context information on inputs/outputs to improve models’ robustness during the pre-training stage.
Besides, Doostmohammadi et al. <cite class="ltx_cite ltx_citemacro_citep">(Doostmohammadi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib32" title="">2023</a>)</cite> focus on pre-training models with a semantic retriever (BM25) and achieve a better language modeling performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Machine Translation</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">Machine translation (MT) leverages computational linguistics algorithms to translate text or speech from one language to another automatically.
The goal of MT is to produce an accurate and fluent translation, preserving the meaning of the original text while adhering to the grammatical and stylistic norms of the target language.
MT systems have evolved from rule-based machine translation (RBMT) to statistical machine translation (SMT) and, more recently, to neural machine translation (NMT).
In particular, NMT methods have significantly improved translation quality by leveraging deep learning techniques, which thus will be the focus of this section.</p>
</div>
<div class="ltx_para" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1">RAG techniques can further enhance MT by incorporating external knowledge into the translation process.
The simplest way is to concatenate the similar translation examples into the inputs or fuse the logits of similar translation examples at the output layer.
For example, some works <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib146" title="">2022</a>; Cheng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib17" title="">2023b</a>)</cite> retrieve similar translations according to the source text and concatenate corresponding target texts or pairs of source and target texts as examples into inputs.
Other works <cite class="ltx_cite ltx_citemacro_citep">(Hossain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib57" title="">2020</a>; Khandelwal et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib81" title="">2020a</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib173" title="">2021</a>)</cite> feed the retrieved source text into the models and obtain the logits of the next target tokens, then aggregate all logits to generate the final predictions.
Moreover, Jiang et al. <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib73" title="">2022</a>)</cite> and Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib90" title="">2023a</a>)</cite> use the logits of retrieved examples to calibrate the aggregated logits, improving the robustness of the generation.
Another branch of works <cite class="ltx_cite ltx_citemacro_citep">(Zhu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib175" title="">2023</a>; Zhong
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib174" title="">2022</a>)</cite> injects external knowledge into the objective function during the training stage, refining the representation space with similar translations.
Besides, Cai et al. <cite class="ltx_cite ltx_citemacro_citep">(Cai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib13" title="">2021</a>)</cite> encode similar translations and store them as the translation memory, then introduce the knowledge from memory with a cross-attention module.
Instead of improving the performance, a branch of work focuses on accelerating the generation efficiency on MT tasks, such as searching from a pre-built subset <cite class="ltx_cite ltx_citemacro_citep">(Meng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib108" title="">2022b</a>; Deguchi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib28" title="">2023</a>)</cite> or a dynamic datastore <cite class="ltx_cite ltx_citemacro_citep">(Dai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib23" title="">2023</a>)</cite>, searching by chunks <cite class="ltx_cite ltx_citemacro_citep">(Martins
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib105" title="">2022</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3. </span>Text Summarization</h3>
<div class="ltx_para" id="S7.SS3.p1">
<p class="ltx_p" id="S7.SS3.p1.1">Text summarization is the process of condensing a larger text document into a shorter version, preserving key information and the overall message.
This task can be broadly categorized into two types: extractive summarization, which involves selecting and compiling parts of the original text, and abstractive summarization, which entails rewriting the essence of the text in a new, concise form.
The goal is to produce a coherent and fluent summary that encapsulates the most critical information from the source material.</p>
</div>
<div class="ltx_para" id="S7.SS3.p2">
<p class="ltx_p" id="S7.SS3.p2.1">RAG techniques can significantly enhance text summarization tasks by leveraging external knowledge and similar documents to inform the summarization process.
<cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib146" title="">2022</a>; Fan and Gardent, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib37" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib91" title="">2023b</a>; Cheng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib17" title="">2023b</a>)</cite> simply concatenates the retrieved similar summaries into inputs to generate summarizations.
Instead of concatenating texts, other works fuse features at the intermediate layers by cross-attention <cite class="ltx_cite ltx_citemacro_citep">(Bertsch
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib10" title="">2023</a>)</cite>, or at the output layers by logits ensemble <cite class="ltx_cite ltx_citemacro_citep">(Hossain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib57" title="">2020</a>)</cite>.
Besides, Jiang et al. <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib75" title="">2023b</a>)</cite> argue that retrieving for every generation may not always be the best choice and propose to retrieve external knowledge during the generation process adaptively.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4. </span>Question Answering</h3>
<div class="ltx_para" id="S7.SS4.p1">
<p class="ltx_p" id="S7.SS4.p1.1">Question Answering (QA) is a fundamental task in NLP that involves building systems capable of automatically answering human questions in natural language.
QA systems can be broadly classified into two categories: open-domain, where the system answers questions about virtually anything, and closed-domain, focusing on a specific area of knowledge.
The primary challenge in QA is understanding the question’s intent and retrieving accurate, relevant information from a vast collection of data to provide a concise answer.
Due to the page limits, this paper only discusses the works of open-domain QA systems.</p>
</div>
<div class="ltx_para" id="S7.SS4.p2">
<p class="ltx_p" id="S7.SS4.p2.1">RAG techniques combine information retrieval with model-based generation, which is highly suitable for QA systems.
In particular, open-domain QA systems usually first require searching for knowledge from the Internet or large-scale databases, then generate the corresponding answers according to the retrieved knowledge.
Naturally, given similar questions and corresponding answers as demonstrations which are concatenated into inputs <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib146" title="">2022</a>; Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib91" title="">2023b</a>; Huang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib61" title="">2023c</a>)</cite>, generators in RAG can learn the pattern between questions and answers and infer what answers should be.
For some specific QA tasks where a set of reference documents is given, retrievers in RAG would retrieve the relevant documents for concatenation, and then generators in RAG would read the context then generate the final answers via the self-attention mechanism <cite class="ltx_cite ltx_citemacro_citep">(Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>; Lee
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib87" title="">2023</a>; Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib123" title="">2023b</a>; Asai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib7" title="">2023</a>)</cite>, which is similar to solving a reading comprehension problem.
Besides, Fabbri et al. <cite class="ltx_cite ltx_citemacro_citep">(Fabbri
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib35" title="">2020</a>)</cite> focus on designing effective templates for re-organizing the concatenated contexts.
Baek et al. <cite class="ltx_cite ltx_citemacro_citep">(Baek
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib8" title="">2023</a>)</cite> leverage the knowledge graph to retrieve the related facts for the input questions, then feed their concatenation and inputs into the generators.
Instead of directly concatenating texts, another branch of works focuses on joining the retrieval embeddings with input embeddings for the encoder-decoder models <cite class="ltx_cite ltx_citemacro_citep">(Izacard and Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib67" title="">2021</a>; Sachan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib128" title="">2021</a>; de Jong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib26" title="">2023b</a>; Izacard
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib68" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S7.SS4.p3">
<p class="ltx_p" id="S7.SS4.p3.1">Some works incorporate the external knowledge in the hidden states or the final logits of generators.
For the fusion in the hidden states, the key is what kind of knowledge should be injected, such as entities <cite class="ltx_cite ltx_citemacro_citep">(Févry et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib39" title="">2020</a>; de Jong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib27" title="">2022</a>)</cite>, chunks <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib11" title="">2022</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib143" title="">2023e</a>)</cite>, documents <cite class="ltx_cite ltx_citemacro_citep">(Cheng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib16" title="">2023a</a>)</cite>.
For the fusion in the logits, most works combine the logits of retrievals and inputs by ensemble techniques <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib132" title="">2023</a>; Guu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib50" title="">2020</a>; Lewis
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib88" title="">2020</a>; Mueller et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib111" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S7.SS4.p4">
<p class="ltx_p" id="S7.SS4.p4.1">Instead of designing different knowledge fusions for QA systems, existing works also improve QA systems with RAG from other aspects.
Some works <cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib46" title="">2019</a>; Paranjape
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib117" title="">2022</a>; Lin
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib95" title="">2022</a>)</cite> use retrieved question-answering pairs as extra training data.
Some works optimize the retriever module, e.g., improving the keys’ representation when building the retriever database <cite class="ltx_cite ltx_citemacro_citep">(Ram et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib122" title="">2023a</a>)</cite>, replacing the indexing with a pre-trained ranking model <cite class="ltx_cite ltx_citemacro_citep">(Yu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib164" title="">2023b</a>)</cite>, or enabling retrieving phrases with two queries <cite class="ltx_cite ltx_citemacro_citep">(Min et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib110" title="">2023</a>)</cite>.
Other works focus on accelerating the generation efficiency of RAG.
Jong et al. <cite class="ltx_cite ltx_citemacro_citep">(de Jong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib25" title="">2023a</a>)</cite> propose the layer-sparse cross-attention to speed up the decoding.
Some works <cite class="ltx_cite ltx_citemacro_citep">(Asai
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib7" title="">2023</a>; Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib75" title="">2023b</a>; Wang
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib150" title="">2023c</a>)</cite> observe that the retrievals may not always provide useful information during the generation process and learn to determine when to retrieve.
Moreover, Sun et al. <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib138" title="">2023</a>)</cite> combine the RAG with agents to iteratively reason the final results.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.5. </span>Information Extraction</h3>
<div class="ltx_para" id="S7.SS5.p1">
<p class="ltx_p" id="S7.SS5.p1.1">Information Extraction (IE) is a critical task in NLP to automatically extract structured information from unstructured and semi-structured text sources.
This task encompasses several sub-tasks, including Named Entity Recognition (NER), Entity Linking (EL), Coreference Resolution (CR), Relation Extraction (RE), etc.
The goal is to identify and classify key elements from text and understand the relationships between them, thereby converting textual data into a structured format amenable to analysis and interpretation.</p>
</div>
<div class="ltx_para" id="S7.SS5.p2">
<p class="ltx_p" id="S7.SS5.p2.1">With RAG techniques, addressing IE tasks can be significantly improved in terms of not only performance but also interpretability.
In NER tasks, Wang et al. <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib149" title="">2021a</a>)</cite> first retrieve similar sentences and then concatenate the ranked retrievals for better semantic representations.
Ren et al. <cite class="ltx_cite ltx_citemacro_citep">(Ren
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib127" title="">2023</a>)</cite> show that naive RAG may not address Event Argument Extraction (EAE) tasks.
Thus, they adopt a sampling-based method to guarantee the same distribution of event labels between retrievals and inputs then concatenate retrieval texts into inputs for better performance in EAE tasks.
Table augmentation is also a challenging task, which requires extracting information from tables.
Glass et al. <cite class="ltx_cite ltx_citemacro_citep">(Glass
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib43" title="">2023</a>)</cite> propose to extract information in a retrieval-augmented manner.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.6. </span>Text Classification</h3>
<div class="ltx_para" id="S7.SS6.p1">
<p class="ltx_p" id="S7.SS6.p1.1">Text classification tasks are common in NLP applications.
Sentiment analysis, a prominent text classification task in NLP, entails identifying and categorizing the emotional tone conveyed in a text.
For example, given a sentence of “I love to watch movies”, the analysis models should determine whether it has a positive attitude or a negative attitude.
The attitude in sentiment analysis can range from positive to negative or can be neutral, nuanced, and even mixed.
The sentiment analysis task is crucial for understanding consumer feedback, monitoring brand reputation, and gaining insights into public opinion on various issues.</p>
</div>
<div class="ltx_para" id="S7.SS6.p2">
<p class="ltx_p" id="S7.SS6.p2.1">RAG techniques can significantly enhance sentiment analysis with different external knowledge fusion strategies.
Li et al. <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib91" title="">2023b</a>)</cite> concatenate the retrieved options and corresponding prompt-based labels with input options.
Other works <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib15" title="">2022b</a>; Guo
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib49" title="">2023</a>)</cite> concatenate the retrieval embeddings with input embeddings before feeding them into the decoder.
Some works fuse the retrieval features into the hidden states of generators via cross-attention <cite class="ltx_cite ltx_citemacro_citep">(Cheng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib16" title="">2023a</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib148" title="">2023b</a>)</cite> or ranking-based addition <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib154" title="">2024</a>)</cite>.
Besides, other works focus on fusing the logits of retrievals with the output logit using ensemble techniques <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib168" title="">2023b</a>; Yu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib162" title="">2023a</a>)</cite>.
Except for knowledge fusions, Min et al. <cite class="ltx_cite ltx_citemacro_citep">(Min et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib110" title="">2023</a>)</cite> enable locating knowledge in phrases more accurately via two queries.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.7. </span>Dialogue Systems</h3>
<div class="ltx_para" id="S7.SS7.p1">
<p class="ltx_p" id="S7.SS7.p1.1">Dialogue systems, also known as conversational agents or chatbots, are designed to simulate conversation with human users, either in text or speech form. These systems can be categorized into two main types: task-oriented systems <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib62" title="">2023a</a>)</cite>, which assist users in completing specific tasks such as booking tickets or ordering food, and open-domain systems, which aim to carry on a general conversation on a wide range of topics <cite class="ltx_cite ltx_citemacro_citep">(Shuster et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib133" title="">2021</a>)</cite>. The core challenge in developing effective dialogue systems lies in understanding user intent, maintaining context, and generating coherent, relevant responses.</p>
</div>
<div class="ltx_para" id="S7.SS7.p2">
<p class="ltx_p" id="S7.SS7.p2.1">Existing works improve the dialogue system with RAG mostly via the concatenation-based methods.
Some works <cite class="ltx_cite ltx_citemacro_citep">(Li
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib93" title="">2021</a>; King and Flanigan, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib84" title="">2023</a>; Cheng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib17" title="">2023b</a>)</cite> concatenate the retrieved history conversations with current inputs.
Other works <cite class="ltx_cite ltx_citemacro_citep">(Fan
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib38" title="">2021</a>; Liu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib98" title="">2023a</a>; Cheng
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib17" title="">2023b</a>)</cite> first leverage an encoder to encode the history responses, then feed the concatenated embeddings into a decoder to generate new responses.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Applications</h2>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1. </span>LLM-based Autonomous Agents</h3>
<div class="ltx_para" id="S8.SS1.p1">
<p class="ltx_p" id="S8.SS1.p1.1">LLM-based autonomous agents are intelligent software systems which leverages the power of LLMs to perform tasks without the need for continuous human intervention <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib92" title="">2024</a>; Xi
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib156" title="">2023</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib145" title="">2024</a>)</cite>.
These agents use LLMs as a brain or controller <cite class="ltx_cite ltx_citemacro_citep">(Huang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib64" title="">2024</a>)</cite>, and extend their abilities through multimodal perception <cite class="ltx_cite ltx_citemacro_citep">(Xie
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib158" title="">2024</a>)</cite>, tool utilization <cite class="ltx_cite ltx_citemacro_citep">(Schick
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib130" title="">2023</a>)</cite> and external memory <cite class="ltx_cite ltx_citemacro_citep">(Packer et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib116" title="">2023</a>)</cite>.
Especially, external long-term memory for agents functions as the knowledge datastore in RAG, which provides agents with the capability to incorporate external knowledge over extended periods.
Therefore, applying RAG would be benefit to access a broader range of information, improving agents’ decision-making and problem-solving abilities <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib170" title="">2024b</a>)</cite>.
This section explores how LLM-based agents can leverage RAG from two perspectives.</p>
</div>
<div class="ltx_para" id="S8.SS1.p2">
<p class="ltx_p" id="S8.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S8.SS1.p2.1.1">Using RAG to Retrieve from External Memory.</span>
LLM-based agents can utilize RAG to access and retrieve information from their own external memory <cite class="ltx_cite ltx_citemacro_citep">(Hatalis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib53" title="">2023</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib171" title="">2024a</a>; Mei
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib106" title="">2024</a>)</cite>.
This external memory serves as a knowledge base that the agent can draw upon to enhance its understanding and decision-making.
When faced with a query or a task, the agent can use RAG to retrieve relevant information from this memory, which is then integrated into the generation process of the LLM.
This allows the agent to produce responses or solutions that are informed by a wider range of knowledge, leading to more accurate and contextually relevant outcomes.</p>
</div>
<div class="ltx_para" id="S8.SS1.p3">
<p class="ltx_p" id="S8.SS1.p3.1">The ability to tap into a vast external memory enables the agent to continuously learn and adapt based on new information, making it more effective over time.
<span class="ltx_text ltx_font_bold" id="S8.SS1.p3.1.1">Using Tools to Search the Web and RAG for Up-to-Date Information.</span>
In addition to retrieving information from its own memory, an LLM-based agent can use tools to search the web for the most current information <cite class="ltx_cite ltx_citemacro_citep">(Schick
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib130" title="">2023</a>)</cite>.
This capability is particularly useful for tasks that require up-to-date knowledge, such as news summarization, market analysis, or responding to rapidly evolving situations.
Once the agent retrieves the latest information from the web, it can use RAG to integrate this data into its generation process.
By combining the LLM’s natural language understanding with real-time data from the web, the agent can generate responses that are not only contextually relevant but also reflect the latest developments.
This approach enhances the agent’s ability to provide accurate and timely information, improving its effectiveness in dynamic environments.</p>
</div>
<div class="ltx_para" id="S8.SS1.p4">
<p class="ltx_p" id="S8.SS1.p4.1">In both cases, RAG plays a crucial role in augmenting the capabilities of LLM-based agents by enabling them to access and leverage a wider range of information, whether it’s from their own external memory or from real-time sources on the web.
This leads to more informed decision-making and enhances the overall performance of the agents.</p>
</div>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2. </span>Frameworks</h3>
<div class="ltx_para" id="S8.SS2.p1">
<p class="ltx_p" id="S8.SS2.p1.1">Frameworks like Langchain <cite class="ltx_cite ltx_citemacro_citep">(LangChain, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib85" title="">2023</a>)</cite> and LLaMAindex <cite class="ltx_cite ltx_citemacro_citep">(Liu, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib96" title="">2022</a>)</cite> pose significant impact on enhancing the practical implementation of RAG.
Langchain and LLaMAindex exemplify the integration of sophisticated retrieval mechanisms with generative models, facilitating the seamless incorporation of external data into the language generation process.
This section will introduce these two representative RAG frameworks in details.</p>
</div>
<div class="ltx_para" id="S8.SS2.p2">
<p class="ltx_p" id="S8.SS2.p2.1">Langchain is a framework designed to augment the capabilities of language models by integrating them with external knowledge sources and databases.
It acts as a middleware that facilitates the interaction between language models and various data retrieval systems, enabling more informed and accurate generation of responses.
The core functionality of Langchain involves orchestrating the flow of information from external databases into the generative process of language models, enhancing their ability to leverage context and specific knowledge in their responses.
This integration plays a crucial role in enabling language models to perform tasks that require access to up-to-date or detailed information that is not contained within the model’s initial training data.</p>
</div>
<div class="ltx_para" id="S8.SS2.p3">
<p class="ltx_p" id="S8.SS2.p3.1">LLaMAindex is a specialized data framework that focuses on organizing and indexing vast amounts of data to improve the retrieval capabilities of language models.
This framework supports efficient querying mechanisms, allowing language models to quickly access relevant information from a structured repository.
LLaMAindex is designed to be highly scalable and can handle diverse data types, from text documents to structured databases.
The indexed data supports a wide range of applications, from simple fact retrieval to complex analytical tasks, making it an indispensable tool for enhancing the information retrieval phase in language models.</p>
</div>
<div class="ltx_para" id="S8.SS2.p4">
<p class="ltx_p" id="S8.SS2.p4.1">Both Langchain and LLaMAindex are deeply connected to the concept of RAG.
Langchain enhances RAG by providing a structured way for language models to interact with external databases and knowledge sources during the generation process.
On the other hand, LLaMAindex serves as a powerful backend for RAG systems by ensuring that the retrieval process is both fast and relevant.
Together, Langchain and LLaMAindex enhance the capabilities of RAG by ensuring that the language models are not only generating text based on their internal knowledge but are also capable of pulling in external data to provide responses that are contextually enriched and informationally robust.

</p>
</div>
</section>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Discussion and Future Direction</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">Despite the success of the RAG for natural language processing, there are some challenges that should be considered.
This paper highlights these challenges to inspire future research and provides possible future research directions in RAG for NLP.</p>
</div>
<section class="ltx_subsection" id="S9.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.1. </span>Retrieval Quality</h3>
<div class="ltx_para" id="S9.SS1.p1">
<p class="ltx_p" id="S9.SS1.p1.1">The retrieval quality refers to improving the relevance of the information retrieved in RAG, which involves the following four key factors to be designed.
The first consideration is <span class="ltx_text ltx_font_bold" id="S9.SS1.p1.1.1">determining the optimal key</span> to use in the vector database.
This process typically involves subjective decision-making and requires human effort to design effectively.
The naive idea is to choose inputs for the given tasks, treating each task as a QA problem.</p>
</div>
<div class="ltx_para" id="S9.SS1.p2">
<p class="ltx_p" id="S9.SS1.p2.1">The second is <span class="ltx_text ltx_font_bold" id="S9.SS1.p2.1.1">the choice of embedding model</span>.
After determining the key, the next step is leveraging embedding models to convert text into vector representations.
Models such as BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib30" title="">2019</a>)</cite>, RoBERTa <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib100" title="">2019</a>)</cite>, or domain-specific embeddings can be crucial to determine how well nuances and contextual meanings are captured.
Adapting the embedding model to better suit specific types of data or queries can significantly enhance retrieval quality.
This requires training the model on domain-specific corpora that include the types of queries and documents the system will encounter.</p>
</div>
<div class="ltx_para" id="S9.SS1.p3">
<p class="ltx_p" id="S9.SS1.p3.1">Thirdly, <span class="ltx_text ltx_font_bold" id="S9.SS1.p3.1.1">designing effective similarity metrics</span> is also crucial to improve retrieval quality.
The goal of similarity metrics is to measure the relevance between the query and the retrieved information.
Some classical similarity metrics, such as cosine similarity or Euclidean distance, used for ranking in the recommender system can also be used in RAG <cite class="ltx_cite ltx_citemacro_citep">(Gunawardana and
Shani, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib45" title="">2009</a>)</cite>.
Apart from these metrics, some works explored more complex similarity metrics, such as optimal transport distance <cite class="ltx_cite ltx_citemacro_citep">(Cui et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib22" title="">2023</a>)</cite>, to obtain a task-specific similarity.</p>
</div>
<div class="ltx_para" id="S9.SS1.p4">
<p class="ltx_p" id="S9.SS1.p4.1">Finally, <span class="ltx_text ltx_font_bold" id="S9.SS1.p4.1.1">approximate nearest neighbor (ANN) searching</span> is also a key step in determining what knowledge should be returned as nearest neighbors.
Advanced ANN searching aims to accelerate the retrieval efficiency at the cost of sacrificing the retrieval quality.
Choosing a suitable ANN algorithm, such as product quantization <cite class="ltx_cite ltx_citemacro_citep">(Jégou
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib69" title="">2011</a>)</cite> or HNSW <cite class="ltx_cite ltx_citemacro_citep">(Malkov and
Yashunin, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib103" title="">2020</a>)</cite>, requires a good trade-off between retrieval efficiency and retrieval quality.
All of these factors collectively contribute to the retrieval quality of the retriever.
</p>
</div>
</section>
<section class="ltx_subsection" id="S9.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.2. </span>RAG Efficiency</h3>
<div class="ltx_para" id="S9.SS2.p1">
<p class="ltx_p" id="S9.SS2.p1.1">RAG efficiency is crucial for downstream NLP applications, which limits the volume of data that can be retrieved.
There are two simple ways to guarantee RAG efficiency without new algorithms, i.e., reducing the volume of data or adding more powerful computing and memory resources.
However, the former may impact the retrieval quality, while the latter requires more resource cost.</p>
</div>
<div class="ltx_para" id="S9.SS2.p2">
<p class="ltx_p" id="S9.SS2.p2.1">RAG efficiency encompasses the efficiency of the retriever and the efficiency of retrieval fusions.
Retriever efficiency refers to the time cost of retrieving relevant information, which can be divided into three parts, i.e., encoding time, ANN searching time, and data fetching time of the datastore.
It is unnecessary to jointly optimize all three components as the bottleneck would vary from different database sizes.
For smaller retrieval databases, such as those with fewer than 1 million entries, the encoding phase is often the primary bottleneck, as the vector database can be all stored in the memory.
Several topics, such as model quantization <cite class="ltx_cite ltx_citemacro_citep">(Kim
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib83" title="">2021</a>; Bai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib9" title="">2021</a>)</cite>, distillation <cite class="ltx_cite ltx_citemacro_citep">(Jiao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib76" title="">2020</a>; Ding
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib31" title="">2023</a>)</cite>, or model pruning <cite class="ltx_cite ltx_citemacro_citep">(Ganesh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib40" title="">2021</a>)</cite>, are used to accelerate the encoding.</p>
</div>
<div class="ltx_para" id="S9.SS2.p3">
<p class="ltx_p" id="S9.SS2.p3.1">In contrast, for larger databases, the time cost of searching in the index and fetching data from the datastore becomes the major bottleneck, as the searching is over a considerable amount of data, and the fetching involves I/O overheads.
In this case, efficient ANN searching algorithms <cite class="ltx_cite ltx_citemacro_citep">(Johnson
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib78" title="">2021</a>; Douze et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib33" title="">2024</a>; Guo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib48" title="">2020</a>)</cite> and system-level optimizations <cite class="ltx_cite ltx_citemacro_citep">(Jin
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib77" title="">2024</a>; Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib74" title="">2024</a>)</cite> are the main focus.</p>
</div>
<div class="ltx_para" id="S9.SS2.p4">
<p class="ltx_p" id="S9.SS2.p4.1">Retrieval fusion efficiency, which aims to enhance the inference efficiency when integrating retrievals, is worth to be optimized for improving the RAG efficiency.
For example, the computational overhead of query-based fusion is often non-negligible due to the long sequence length.
Some works, such as Fid-light <cite class="ltx_cite ltx_citemacro_citep">(Hofstätter et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib56" title="">2023</a>)</cite> and ReFusion <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib154" title="">2024</a>)</cite>, mainly target reducing the computations while integrating the retrieved information.</p>
</div>
</section>
<section class="ltx_subsection" id="S9.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.3. </span>Choices of Fusions</h3>
<div class="ltx_para" id="S9.SS3.p1">
<p class="ltx_p" id="S9.SS3.p1.1">This paper introduces three kinds of retrieval fusions, where each fusion is worth further exploring.
Query-based fusions concatenate the texts or embeddings of retrieved knowledge with inputs.
These methods have better interpretability and are easy to apply even only when the API of LLMs is provided.
However, concatenation leads to a long sequence of inputs, thus resulting in a large computational overhead in the attention and truncation of inputs.
Some works <cite class="ltx_cite ltx_citemacro_citep">(Wu
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib154" title="">2024</a>; Arefeen
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib6" title="">2023</a>)</cite> aim to improve efficiency when integrating retrievals, while others <cite class="ltx_cite ltx_citemacro_citep">(Bertsch
et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib10" title="">2023</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib148" title="">2023b</a>)</cite> focus on improving the efficiency when increasing the model input length.</p>
</div>
<div class="ltx_para" id="S9.SS3.p2">
<p class="ltx_p" id="S9.SS3.p2.1">Conversely, latent-based fusions amalgamate information at a deeper, more abstract level, which may capture more nuanced relationships between the retrieved information and the query.
However, these fusions significantly lack interpretability and often require pre-training or fine-tuning to adjust the retrieval embeddings or reweight the retrievals.
Therefore, enhancing the interpretability of such latent-based fusions is also worth exploring in the future.</p>
</div>
<div class="ltx_para" id="S9.SS3.p3">
<p class="ltx_p" id="S9.SS3.p3.1">Logits-based fusions incorporate information at the decision level, thereby offering a potentially more flexible and robust integration of data from various sources.
Nonetheless, these fusions may oversimplify the fusion process, diminishing the richness of the retrieved information by reducing them to logit values.
Meanwhile, such fusions require performing all inference of retrievals, which is also a time-consuming process.</p>
</div>
<div class="ltx_para" id="S9.SS3.p4">
<p class="ltx_p" id="S9.SS3.p4.1">Apart from applying one kind of fusion in practical applications, combining different fusions is also worth exploring for better performance.
These fusion methods are not mutually exclusive, as they focus on augmenting the different stages of generators, i.e., inputs, hidden states, and outputs.
Besides, during the generation, when to fuse retrieved knowledge is also a significant problem worthy of further exploration <cite class="ltx_cite ltx_citemacro_citep">(Mallen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib104" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S9.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.4. </span>RAG Training</h3>
<div class="ltx_para" id="S9.SS4.p1">
<p class="ltx_p" id="S9.SS4.p1.1">As introduced in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#S6" title="6. RAG Training ‣ Retrieval-Augmented Generation for Natural Language Processing: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a>, RAG training includes two branch of works, RAG with/without datastore update.
For RAG without datastore update, the main challenge is how to jointly optimize all parameters in RAG.
This may involves new loss functions with multiple objectives, new optimizations for efficient tuning parameters in retriever and generator, or other training strategies.</p>
</div>
<div class="ltx_para" id="S9.SS4.p2">
<p class="ltx_p" id="S9.SS4.p2.1">For RAG with datastore update, one challenge is how to align the retrieval representations with the generator’s representations.
Although the time cost of the update operation in datastore cannot be ignored, some works <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib15" title="">2022b</a>)</cite> reduce the update frequency by asychronously updating, thus achieving the alignment of knowledge representation and model’s representation.
Another challenge is when to retrain/fine-tune the generator in RAG when new corpus is added.
Due to the in-context learning capability of exisitng LLM-based generators and high training overhead, retraining/fine-tuning the generator or directly inferring the generator becomes a challenging choice for different scenarios.
Recently, some efficient training strategies <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib58" title="">2022</a>; Dettmers et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib29" title="">2023</a>)</cite> have been proposed to accelerate the fine-tuning process, which can be taken into considerations.</p>
</div>
</section>
<section class="ltx_subsection" id="S9.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.5. </span>Cross-Modality Retrieval</h3>
<div class="ltx_para" id="S9.SS5.p1">
<p class="ltx_p" id="S9.SS5.p1.1">Retrieving cross-modality information in NLP tasks can greatly enhance the quality and richness of the representations, leading to improved performance.
First, cross-modality information, such as combining text with images, videos, or audio, provides a richer context to the content <cite class="ltx_cite ltx_citemacro_citep">(Hu, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib59" title="">2023</a>)</cite>.
For instance, when language is ambiguous, accompanying images can clarify meanings difficult to convey through text alone.
Second, different modalities can contribute various types of information that are not accessible from a single source.
For example, visual data can provide spatial, color, and action cues, while textual data can offer detailed descriptions, emotions, or abstract concepts.
Combining these can lead to a more comprehensive understanding of the data.
Moreover, Models trained on multi-modal data typically exhibit increased robustness and generalizability <cite class="ltx_cite ltx_citemacro_citep">(Wu and Goodman, <a class="ltx_ref" href="https://arxiv.org/html/2407.13193v2#bib.bib153" title="">2018</a>)</cite>.
These models are adept at associating information across diverse inputs, mitigating overfitting to the peculiarities of a single modality.
This attribute is particularly valuable in real-world applications of NLP, such as in autonomous vehicles, where systems must interpret textual information from signs or dialogues and sensory data from the surrounding environment to make informed decisions.
Furthermore, multi-modal data can resolve ambiguities that cannot be resolved within a single modality.
For example, the phrase ”bank” can refer to either a financial institution or the side of a river, and visual context can help disambiguate this.
Last, human communication is inherently multi-modal, incorporating elements such as gestures, facial expressions, and tone of voice.
Systems capable of processing multiple modes of communication can interact with humans in a manner that is both more natural and intuitive.
In conclusion, integrating cross-modality information in RAG for NLP tasks not only enhances the richness and quality of data representations but also significantly improves the systems’ comprehension, interaction capabilities, and adaptability to diverse applications.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10. </span>Conclusion</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">In this survey, we delve into the development of RAG within the field of natural language processing.
First, this paper introduces the components of RAG and their functionalities.
Subsequently, this paper elaborates on each step involved in retriever, discussing the diverse techniques.
Furthermore, this paper categorizes the retrieval fusions, evaluating the strengths and weaknesses inherent of each retrieval fusion techniques.
Besides, this paper discusses the RAG training, including RAG with/without datastore update.
Then, this paper explores how RAG can be adapted for various NLP tasks and provides practical applications of RAG in real-world scenarios.
Conclusively, this paper identifies ongoing challenges and suggests directions for future research to foster advancements in this evolving area.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abnar
et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Samira Abnar, Mostafa
Dehghani, Behnam Neyshabur, and Hanie
Sedghi. 2022.

</span>
<span class="ltx_bibblock">Exploring the Limits of Large Scale Pre-training.
In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">The Tenth International Conference on Learning
Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ainslie et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Joshua Ainslie, James
Lee-Thorp, Michiel de Jong, Yury
Zemlyanskiy, Federico Lebrón, and
Sumit Sanghai. 2023.

</span>
<span class="ltx_bibblock">GQA: Training Generalized Multi-Query Transformer
Models from Multi-Head Checkpoints. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings
of the 2023 Conference on Empirical Methods in Natural Language Processing
(EMNLP)</em>, Houda Bouamor,
Juan Pino, and Kalika Bali (Eds.).
Association for Computational Linguistics,
4895–4901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AlKhamissi et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Badr AlKhamissi, Millicent
Li, Asli Celikyilmaz, Mona T. Diab,
and Marjan Ghazvininejad.
2022.

</span>
<span class="ltx_bibblock">A Review on Language Models as Knowledge Bases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">CoRR</em> abs/2204.06031
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, Sebastian
Borgeaud, Yonghui Wu, Jean-Baptiste
Alayrac, Jiahui Yu, Radu Soricut,
Johan Schalkwyk, Andrew M. Dai,
Anja Hauth, Katie Millican,
David Silver, Slav Petrov,
Melvin Johnson, Ioannis Antonoglou,
Julian Schrittwieser, Amelia Glaese,
Jilin Chen, Emily Pitler,
Timothy P. Lillicrap, Angeliki Lazaridou,
Orhan Firat, James Molloy,
Michael Isard, Paul Ronald Barham,
Tom Hennigan, Benjamin Lee,
Fabio Viola, Malcolm Reynolds,
Yuanzhong Xu, Ryan Doherty,
Eli Collins, Clemens Meyer,
Eliza Rutherford, Erica Moreira,
Kareem Ayoub, Megha Goel,
George Tucker, Enrique Piqueras,
Maxim Krikun, Iain Barr,
Nikolay Savinov, Ivo Danihelka,
Becca Roelofs, Anaïs White,
Anders Andreassen, Tamara von Glehn,
Lakshman Yagati, Mehran Kazemi,
Lucas Gonzalez, Misha Khalman,
Jakub Sygnowski, and et al.
2023.

</span>
<span class="ltx_bibblock">Gemini: A Family of Highly Capable Multimodal
Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">CoRR</em> abs/2312.11805
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arefeen
et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Md. Adnan Arefeen, Biplob
Debnath, and Srimat Chakradhar.
2023.

</span>
<span class="ltx_bibblock">LeanContext: Cost-Efficient Domain-Specific
Question Answering Using LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">CoRR</em> abs/2309.00841
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai
et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu,
Yizhong Wang, Avirup Sil, and
Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock">Self-RAG: Learning to Retrieve, Generate, and
Critique through Self-Reflection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">CoRR</em> abs/2310.11511
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baek
et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinheon Baek, Alham Fikri
Aji, and Amir Saffari. 2023.

</span>
<span class="ltx_bibblock">Knowledge-Augmented Language Model Prompting for
Zero-Shot Knowledge Graph Question Answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">CoRR</em> abs/2306.04136
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Haoli Bai, Wei Zhang,
Lu Hou, Lifeng Shang,
Jin Jin, Xin Jiang, Qun
Liu, Michael R. Lyu, and Irwin King.
2021.

</span>
<span class="ltx_bibblock">BinaryBERT: Pushing the Limit of BERT
Quantization. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the 59th Annual
Meeting of the Association for Computational Linguistics and the 11th
International Joint Conference on Natural Language Processing
(ACL/IJCNLP)</em>. Association for Computational
Linguistics, 4334–4348.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bertsch
et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Amanda Bertsch, Uri Alon,
Graham Neubig, and Matthew R. Gormley.
2023.

</span>
<span class="ltx_bibblock">Unlimiformer: Long-Range Transformers with
Unlimited Length Input. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Advances in Neural
Information Processing Systems 36 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud
et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur
Mensch, Jordan Hoffmann, Trevor Cai,
Eliza Rutherford, Katie Millican,
George van den Driessche, Jean-Baptiste
Lespiau, Bogdan Damoc, Aidan Clark,
Diego de Las Casas, Aurelia Guy,
Jacob Menick, Roman Ring,
Tom Hennigan, Saffron Huang,
Loren Maggiore, Chris Jones,
Albin Cassirer, Andy Brock,
Michela Paganini, Geoffrey Irving,
Oriol Vinyals, Simon Osindero,
Karen Simonyan, Jack W. Rae,
Erich Elsen, and Laurent Sifre.
2022.

</span>
<span class="ltx_bibblock">Improving Language Models by Retrieving from
Trillions of Tokens. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">Proceedings of the 39th
International Conference on Machine Learning (ICML)</em>
<em class="ltx_emph ltx_font_italic" id="bib.bib11.4.2">(Proceedings of Machine Learning Research)</em>,
Vol. 162. 2206–2240.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown
et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin
Mann, Nick Ryder, Melanie Subbiah,
Jared Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh,
Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse,
Mark Chen, Eric Sigler,
Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and
Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners. In
<em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Advances in Neural Information Processing Systems
33 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai
et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Deng Cai, Yan Wang,
Huayang Li, Wai Lam, and
Lemao Liu. 2021.

</span>
<span class="ltx_bibblock">Neural Machine Translation with Monolingual
Translation Memory. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Proceedings of the 59th
Annual Meeting of the Association for Computational Linguistics and the 11th
International Joint Conference on Natural Language Processing
(ACL/IJCNLP)</em>. 7307–7318.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Junying Chen, Qingcai
Chen, Dongfang Li, and Yutao Huang.
2022a.

</span>
<span class="ltx_bibblock">SeDR: Segment Representation Learning for Long
Documents Dense Retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">CoRR</em> abs/2211.10841
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Xiang Chen, Lei Li,
Ningyu Zhang, Xiaozhuan Liang,
Shumin Deng, Chuanqi Tan,
Fei Huang, Luo Si, and
Huajun Chen. 2022b.

</span>
<span class="ltx_bibblock">Decoupling Knowledge from Memorization:
Retrieval-augmented Prompt Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Advances
in Neural Information Processing Systems 35 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng
et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Xin Cheng, Yankai Lin,
Xiuying Chen, Dongyan Zhao, and
Rui Yan. 2023a.

</span>
<span class="ltx_bibblock">Decouple knowledge from paramters for plug-and-play
language modeling. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Findings of the Association
for Computational Linguistics (ACL)</em>. 14288–14308.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng
et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Xin Cheng, Di Luo,
Xiuying Chen, Lemao Liu,
Dongyan Zhao, and Rui Yan.
2023b.

</span>
<span class="ltx_bibblock">Lift Yourself Up: Retrieval-augmented Text
Generation with Self-Memory. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Advances in Neural
Information Processing Systems 36 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chevalier
et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Alexis Chevalier,
Alexander Wettig, Anirudh Ajith, and
Danqi Chen. 2023.

</span>
<span class="ltx_bibblock">Adapting Language Models to Compress Contexts. In
<em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the 2023 Conference on Empirical
Methods in Natural Language Processing (EMNLP)</em>.
3829–3846.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chuang
et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yung-Sung Chuang, Wei
Fang, Shang-Wen Li, Wen-tau Yih,
and James R. Glass. 2023.

</span>
<span class="ltx_bibblock">Expand, Rerank, and Retrieve: Query Reranking for
Open-Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Findings of the
Association for Computational Linguistics (ACL)</em>.
Association for Computational Linguistics,
12131–12147.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark
et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Kevin Clark, Minh-Thang
Luong, Quoc V. Le, and Christopher D.
Manning. 2020.

</span>
<span class="ltx_bibblock">ELECTRA: Pre-training Text Encoders as
Discriminators Rather Than Generators. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">8th
International Conference on Learning Representations (ICLR)</em>.
OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Colombo et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Pierre Colombo,
Telmo Pessoa Pires, Malik Boudiaf,
Dominic Culver, Rui Melo,
Caio Corro, André F. T. Martins,
Fabrizio Esposito, Vera Lúcia
Raposo, Sofia Morgado, and Michael
Desa. 2024.

</span>
<span class="ltx_bibblock">SaulLM-7B: A pioneering Large Language Model for
Law.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">CoRR</em> abs/2403.03883
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yufei Cui, Ziquan Liu,
Yixin Chen, Yuchen Lu,
Xinyue Yu, Xue (Steve) Liu,
Tei-Wei Kuo, Miguel Rodrigues,
Chun Jason Xue, and Antoni B. Chan.
2023.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Multiple Instance Learning. In
<em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Advances in Neural Information Processing Systems
36 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai
et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuhan Dai, Zhirui Zhang,
Qiuzhi Liu, Qu Cui,
Weihua Li, Yichao Du, and
Tong Xu. 2023.

</span>
<span class="ltx_bibblock">Simple and Scalable Nearest Neighbor Machine
Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">The Eleventh International
Conference on Learning Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dale et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
David Dale, Elena Voita,
Loïc Barrault, and Marta R.
Costa-jussà. 2023.

</span>
<span class="ltx_bibblock">Detecting and Mitigating Hallucinations in Machine
Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even
Better. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Proceedings of the 61st Annual Meeting
of the Association for Computational Linguistics (ACL)</em>.
Association for Computational Linguistics,
36–50.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Jong et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Michiel de Jong, Yury
Zemlyanskiy, Joshua Ainslie, Nicholas
FitzGerald, Sumit Sanghai, Fei Sha,
and William W. Cohen. 2023a.

</span>
<span class="ltx_bibblock">FiDO: Fusion-in-Decoder optimized for stronger
performance and faster inference. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Findings of
the Association for Computational Linguistics (ACL)</em>.
11534–11547.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Jong et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Michiel de Jong, Yury
Zemlyanskiy, Nicholas FitzGerald, Joshua
Ainslie, Sumit Sanghai, Fei Sha, and
William W. Cohen. 2023b.

</span>
<span class="ltx_bibblock">Pre-computed memory or on-the-fly encoding? A
hybrid approach to retrieval augmentation makes the most of your compute. In
<em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Proceedings of the 40th International Conference on
Machine Learning (ICML)</em>. 7329–7342.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de Jong et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Michiel de Jong, Yury
Zemlyanskiy, Nicholas FitzGerald, Fei
Sha, and William W. Cohen.
2022.

</span>
<span class="ltx_bibblock">Mention Memory: incorporating textual knowledge
into Transformers through entity mention attention. In
<em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">The Tenth International Conference on Learning
Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deguchi et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hiroyuki Deguchi, Taro
Watanabe, Yusuke Matsui, Masao Utiyama,
Hideki Tanaka, and Eiichiro Sumita.
2023.

</span>
<span class="ltx_bibblock">Subset Retrieval Nearest Neighbor Machine
Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">Proceedings of the 61st Annual
Meeting of the Association for Computational Linguistics (ACL)</em>.
174–189.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro
Pagnoni, Ari Holtzman, and Luke
Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock">QLoRA: Efficient Finetuning of Quantized LLMs. In
<em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Advances in Neural Information Processing Systems
36 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin
et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding. In
<em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT)</em>. 4171–4186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding
et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zixiang Ding, Guoqing
Jiang, Shuai Zhang, Lin Guo, and
Wei Lin. 2023.

</span>
<span class="ltx_bibblock">SKDBERT: Compressing BERT via Stochastic
Knowledge Distillation. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Thirty-Seventh AAAI
Conference on Artificial Intelligence (AAAI)</em>. AAAI
Press, 7414–7422.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doostmohammadi et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ehsan Doostmohammadi,
Tobias Norlund, Marco Kuhlmann, and
Richard Johansson. 2023.

</span>
<span class="ltx_bibblock">Surface-Based Retrieval Reduces Perplexity of
Retrieval-Augmented Language Models. In
<em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
521–529.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Douze et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Matthijs Douze, Alexandr
Guzhva, Chengqi Deng, Jeff Johnson,
Gergely Szilvasy, Pierre-Emmanuel
Mazaré, Maria Lomeli, Lucas
Hosseini, and Hervé Jégou.
2024.

</span>
<span class="ltx_bibblock">The Faiss library.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">CoRR</em> abs/2401.08281
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">explosion (2016)</span>
<span class="ltx_bibblock">
explosion.
2016.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Spacy</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://spacy.io/" title="">https://spacy.io/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fabbri
et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Alexander R. Fabbri,
Patrick Ng, Zhiguo Wang,
Ramesh Nallapati, and Bing Xiang.
2020.

</span>
<span class="ltx_bibblock">Template-Based Question Generation from Retrieved
Sentences for Improved Unsupervised Question Answering. In
<em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
4508–4513.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Facebook (2013)</span>
<span class="ltx_bibblock">
Facebook. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">RocksDB</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebook/rocksdb" title="">https://github.com/facebook/rocksdb</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan and Gardent (2022)</span>
<span class="ltx_bibblock">
Angela Fan and Claire
Gardent. 2022.

</span>
<span class="ltx_bibblock">Generating Full Length Wikipedia Biographies: The
Impact of Gender Bias on the Retrieval-Based Generation of Women
Biographies.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">CoRR</em> abs/2204.05879
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan
et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Angela Fan, Claire
Gardent, Chloé Braud, and Antoine
Bordes. 2021.

</span>
<span class="ltx_bibblock">Augmenting Transformers with KNN-Based Composite
Memory for Dialog.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Trans. Assoc. Comput. Linguistics</em>
9 (2021), 82–99.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Févry et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Thibault Févry,
Livio Baldini Soares, Nicholas
FitzGerald, Eunsol Choi, and Tom
Kwiatkowski. 2020.

</span>
<span class="ltx_bibblock">Entities as Experts: Sparse Memory Access with
Entity Supervision. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.
4937–4951.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganesh et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Prakhar Ganesh, Yao Chen,
Xin Lou, Mohammad Ali Khan,
Yin Yang, Hassan Sajjad,
Preslav Nakov, Deming Chen, and
Marianne Winslett. 2021.

</span>
<span class="ltx_bibblock">Compressing Large-Scale Transformer-Based Models:
A Case Study on BERT.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Trans. Assoc. Comput. Linguistics</em>
9 (2021), 1061–1080.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Tianyu Gao, Xingcheng
Yao, and Danqi Chen. 2021.

</span>
<span class="ltx_bibblock">SimCSE: Simple Contrastive Learning of Sentence
Embeddings. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Processing (EMNLP)</em>.
Association for Computational Linguistics,
6894–6910.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong,
Xinyu Gao, Kangxiang Jia,
Jinliu Pan, Yuxi Bi, Yi
Dai, Jiawei Sun, Qianyu Guo,
Meng Wang, and Haofen Wang.
2023.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for Large Language
Models: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">CoRR</em> abs/2312.10997
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glass
et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Michael R. Glass, Xueqing
Wu, Ankita Rajaram Naik, Gaetano
Rossiello, and Alfio Gliozzo.
2023.

</span>
<span class="ltx_bibblock">Retrieval-Based Transformer for Table
Augmentation. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">Findings of the Association for
Computational Linguistics (ACL)</em>. 5635–5648.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong
et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongyu Gong, Yelong Shen,
Dian Yu, Jianshu Chen, and
Dong Yu. 2020.

</span>
<span class="ltx_bibblock">Recurrent Chunking Mechanisms for Long-Text Machine
Reading Comprehension. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Proceedings of the 58th
Annual Meeting of the Association for Computational Linguistics (ACL)</em>.
Association for Computational Linguistics,
6751–6761.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunawardana and
Shani (2009)</span>
<span class="ltx_bibblock">
Asela Gunawardana and
Guy Shani. 2009.

</span>
<span class="ltx_bibblock">A Survey of Accuracy Evaluation Metrics of
Recommendation Tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">J. Mach. Learn. Res.</em> 10
(2009), 2935–2962.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Daya Guo, Duyu Tang,
Nan Duan, Ming Zhou, and
Jian Yin. 2019.

</span>
<span class="ltx_bibblock">Coupling Retrieval and Meta-Learning for
Context-Dependent Semantic Parsing. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">Proceedings
of the 57th Conference of the Association for Computational Linguistics
(ACL)</em>. 855–866.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Rentong Guo, Xiaofan
Luan, Long Xiang, Xiao Yan,
Xiaomeng Yi, Jigao Luo,
Qianya Cheng, Weizhi Xu,
Jiarui Luo, Frank Liu,
Zhenshan Cao, Yanliang Qiao,
Ting Wang, Bo Tang, and
Charles Xie. 2022.

</span>
<span class="ltx_bibblock">Manu: A Cloud Native Vector Database Management
System.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">Proc. VLDB Endow.</em> 15,
12 (2022), 3548–3561.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Ruiqi Guo, Philip Sun,
Erik Lindgren, Quan Geng,
David Simcha, Felix Chern, and
Sanjiv Kumar. 2020.

</span>
<span class="ltx_bibblock">Accelerating Large-Scale Inference with Anisotropic
Vector Quantization. In <em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">Proceedings of the 37th
International Conference on Machine Learning (ICML)</em>
<em class="ltx_emph ltx_font_italic" id="bib.bib48.4.2">(Proceedings of Machine Learning Research)</em>,
Vol. 119. PMLR,
3887–3896.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhicheng Guo, Sijie
Cheng, Yile Wang, Peng Li, and
Yang Liu. 2023.

</span>
<span class="ltx_bibblock">Prompt-Guided Retrieval Augmentation for
Non-Knowledge-Intensive Tasks. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Findings of the
Association for Computational Linguistics (ACL)</em>.
10896–10912.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu
et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee,
Zora Tung, Panupong Pasupat, and
Ming-Wei Chang. 2020.

</span>
<span class="ltx_bibblock">Retrieval Augmented Language Model Pre-Training.
In <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">Proceedings of the 37th International Conference
on Machine Learning (ICML)</em> <em class="ltx_emph ltx_font_italic" id="bib.bib50.4.2">(Proceedings of Machine
Learning Research)</em>, Vol. 119.
3929–3938.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harris and Harris (2010)</span>
<span class="ltx_bibblock">
David Harris and Sarah
Harris. 2010.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Digital design and computer architecture</em>.

</span>
<span class="ltx_bibblock">Morgan Kaufmann.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harris (1954)</span>
<span class="ltx_bibblock">
Zellig S Harris.
1954.

</span>
<span class="ltx_bibblock">Distributional structure.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Word</em> 10,
2-3 (1954), 146–162.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hatalis et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Kostas Hatalis, Despina
Christou, Joshua Myers, Steven Jones,
Keith Lambert, Adam Amos-Binks,
Zohreh Dannenhauer, and Dustin
Dannenhauer. 2023.

</span>
<span class="ltx_bibblock">Memory Matters: The Need to Improve Long-Term
Memory in LLM-Agents. In <em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">Proceedings of the AAAI
Symposium Series</em>, Vol. 2. 277–280.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Qiyuan He, Yizhong Wang,
and Wenya Wang. 2024.

</span>
<span class="ltx_bibblock">Can Language Models Act as Knowledge Bases at
Scale?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">CoRR</em> abs/2402.14273
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian
Borgeaud, Arthur Mensch, Elena
Buchatskaya, Trevor Cai, Eliza
Rutherford, Diego de Las Casas, Lisa Anne
Hendricks, Johannes Welbl, Aidan Clark,
Tom Hennigan, Eric Noland,
Katie Millican, George van den Driessche,
Bogdan Damoc, Aurelia Guy,
Simon Osindero, Karen Simonyan,
Erich Elsen, Jack W. Rae,
Oriol Vinyals, and Laurent Sifre.
2022.

</span>
<span class="ltx_bibblock">Training Compute-Optimal Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">CoRR</em> abs/2203.15556
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hofstätter et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Sebastian Hofstätter,
Jiecao Chen, Karthik Raman, and
Hamed Zamani. 2023.

</span>
<span class="ltx_bibblock">FiD-Light: Efficient and Effective
Retrieval-Augmented Text Generation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">Proceedings of the 46th International ACM SIGIR
Conference on Research and Development in Information Retrieval (SIGIR)</em>.
ACM, 1437–1447.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hossain et al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Nabil Hossain, Marjan
Ghazvininejad, and Luke Zettlemoyer.
2020.

</span>
<span class="ltx_bibblock">Simple and Effective Retrieve-Edit-Rerank Text
Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">Proceedings of the 58th Annual
Meeting of the Association for Computational Linguistics (ACL)</em>.
2532–2538.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Edward J. Hu, Yelong
Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang,
Lu Wang, and Weizhu Chen.
2022.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language
Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">The Tenth International Conference on
Learning Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu (2023)</span>
<span class="ltx_bibblock">
Xuming Hu.
2023.

</span>
<span class="ltx_bibblock">Multimodal Named Entity Recognition and Relation
Extraction with Retrieval-Augmented Strategy. In
<em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Proceedings of the 46th International ACM SIGIR
Conference on Research and Development in Information Retrieval (SIGIR)</em>.
ACM, 3488.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu and Lu (2024)</span>
<span class="ltx_bibblock">
Yucheng Hu and Yuxing
Lu. 2024.

</span>
<span class="ltx_bibblock">RAG and RAU: A Survey on Retrieval-Augmented
Language Model in Natural Language Processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">CoRR</em> abs/2404.19543
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2023c)</span>
<span class="ltx_bibblock">
Jie Huang, Wei Ping,
Peng Xu, Mohammad Shoeybi,
Kevin Chen-Chuan Chang, and Bryan
Catanzaro. 2023c.

</span>
<span class="ltx_bibblock">RAVEN: In-Context Learning with Retrieval
Augmented Encoder-Decoder Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.3.1">CoRR</em> abs/2308.07922
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Qiushi Huang, Shuai Fu,
Xubo Liu, Wenwu Wang,
Tom Ko, Yu Zhang, and
Lilian H. Y. Tang. 2023a.

</span>
<span class="ltx_bibblock">Learning Retrieval Augmentation for Personalized
Dialogue Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">Proceedings of the 2023
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.
Association for Computational Linguistics,
2523–2540.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang and Tung (2023)</span>
<span class="ltx_bibblock">
Qiang Huang and Anthony
K. H. Tung. 2023.

</span>
<span class="ltx_bibblock">Lightweight-Yet-Efficient: Revitalizing Ball-Tree
for Point-to-Hyperplane Nearest Neighbor Search. In
<em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">39th IEEE International Conference on Data
Engineering (ICDE)</em>. IEEE,
436–449.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span class="ltx_text" id="bib.bib64.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Xu Huang, Weiwen Liu,
Xiaolong Chen, Xingmei Wang,
Hao Wang, Defu Lian,
Yasheng Wang, Ruiming Tang, and
Enhong Chen. 2024.

</span>
<span class="ltx_bibblock">Understanding the planning of LLM agents: A
survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.3.1">CoRR</em> abs/2402.02716
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
et al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Yangsibo Huang, Daogao
Liu, Zexuan Zhong, Weijia Shi, and
Yin Tat Lee. 2023b.

</span>
<span class="ltx_bibblock">kNN-Adapter: Efficient Domain Adaptation for
Black-Box Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.3.1">CoRR</em> abs/2302.10879
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ishiwatari et al<span class="ltx_text" id="bib.bib66.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Shonosuke Ishiwatari,
Jingtao Yao, Shujie Liu,
Mu Li, Ming Zhou, Naoki
Yoshinaga, Masaru Kitsuregawa, and
Weijia Jia. 2017.

</span>
<span class="ltx_bibblock">Chunk-based Decoder for Neural Machine
Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib66.3.1">Proceedings of the 55th Annual
Meeting of the Association for Computational Linguistics (ACL)</em>.
Association for Computational Linguistics,
1901–1912.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard and Grave (2021)</span>
<span class="ltx_bibblock">
Gautier Izacard and
Edouard Grave. 2021.

</span>
<span class="ltx_bibblock">Leveraging Passage Retrieval with Generative Models
for Open Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">Proceedings
of the 16th Conference of the European Chapter of the Association for
Computational Linguistics (EACL)</em>. 874–880.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard
et al<span class="ltx_text" id="bib.bib68.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick
S. H. Lewis, Maria Lomeli, Lucas
Hosseini, Fabio Petroni, Timo Schick,
Jane Dwivedi-Yu, Armand Joulin,
Sebastian Riedel, and Edouard Grave.
2023.

</span>
<span class="ltx_bibblock">Atlas: Few-shot Learning with Retrieval Augmented
Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.3.1">J. Mach. Learn. Res.</em> 24
(2023), 251:1–251:43.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jégou
et al<span class="ltx_text" id="bib.bib69.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Hervé Jégou,
Matthijs Douze, and Cordelia Schmid.
2011.

</span>
<span class="ltx_bibblock">Product Quantization for Nearest Neighbor Search.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.3.1">IEEE Trans. Pattern Anal. Mach. Intell.</em>
33, 1 (2011),
117–128.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al<span class="ltx_text" id="bib.bib70.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee,
Rita Frieske, Tiezheng Yu,
Dan Su, Yan Xu, Etsuko
Ishii, Yejin Bang, Andrea Madotto, and
Pascale Fung. 2023a.

</span>
<span class="ltx_bibblock">Survey of Hallucination in Natural Language
Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.3.1">ACM Comput. Surv.</em> 55,
12 (2023), 248:1–248:38.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji
et al<span class="ltx_text" id="bib.bib71.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Ziwei Ji, Zihan Liu,
Nayeon Lee, Tiezheng Yu,
Bryan Wilie, Min Zeng, and
Pascale Fung. 2023b.

</span>
<span class="ltx_bibblock">RHO: Reducing Hallucination in Open-domain
Dialogues with Knowledge Grounding. In <em class="ltx_emph ltx_font_italic" id="bib.bib71.3.1">Findings of
the Association for Computational Linguistics (ACL)</em>.
Association for Computational Linguistics,
4504–4522.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib72.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre
Sablayrolles, Arthur Mensch, Chris
Bamford, Devendra Singh Chaplot, Diego de
Las Casas, Florian Bressand, Gianna
Lengyel, Guillaume Lample, Lucile
Saulnier, Lélio Renard Lavaud,
Marie-Anne Lachaux, Pierre Stock,
Teven Le Scao, Thibaut Lavril,
Thomas Wang, Timothée Lacroix,
and William El Sayed. 2023a.

</span>
<span class="ltx_bibblock">Mistral 7B.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.3.1">CoRR</em> abs/2310.06825
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib73.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Hui Jiang, Ziyao Lu,
Fandong Meng, Chulun Zhou,
Jie Zhou, Degen Huang, and
Jinsong Su. 2022.

</span>
<span class="ltx_bibblock">Towards Robust k-Nearest-Neighbor Machine
Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib73.3.1">Proceedings of the 2022 Conference
on Empirical Methods in Natural Language Processing (EMNLP)</em>.
5468–5477.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib74.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Wenqi Jiang, Shuai Zhang,
Boran Han, Jie Wang,
Bernie Wang, and Tim Kraska.
2024.

</span>
<span class="ltx_bibblock">PipeRAG: Fast Retrieval-Augmented Generation via
Algorithm-System Co-design.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.3.1">CoRR</em> abs/2403.05676
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib75.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank F.
Xu, Luyu Gao, Zhiqing Sun,
Qian Liu, Jane Dwivedi-Yu,
Yiming Yang, Jamie Callan, and
Graham Neubig. 2023b.

</span>
<span class="ltx_bibblock">Active Retrieval Augmented Generation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib75.3.1">Proceedings of the 2023 Conference on Empirical
Methods in Natural Language Processing (EMNLP)</em>.
7969–7992.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiao et al<span class="ltx_text" id="bib.bib76.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiaoqi Jiao, Yichun Yin,
Lifeng Shang, Xin Jiang,
Xiao Chen, Linlin Li,
Fang Wang, and Qun Liu.
2020.

</span>
<span class="ltx_bibblock">TinyBERT: Distilling BERT for Natural Language
Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib76.3.1">Findings of the Association for
Computational Linguistics (EMNLP)</em> <em class="ltx_emph ltx_font_italic" id="bib.bib76.4.2">(Findings of
ACL)</em>, Vol. EMNLP 2020.
Association for Computational Linguistics,
4163–4174.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin
et al<span class="ltx_text" id="bib.bib77.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Chao Jin, Zili Zhang,
Xuanlin Jiang, Fangyue Liu,
Xin Liu, Xuanzhe Liu, and
Xin Jin. 2024.

</span>
<span class="ltx_bibblock">RAGCache: Efficient Knowledge Caching for
Retrieval-Augmented Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.3.1">CoRR</em> abs/2404.12457
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson
et al<span class="ltx_text" id="bib.bib78.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jeff Johnson, Matthijs
Douze, and Hervé Jégou.
2021.

</span>
<span class="ltx_bibblock">Billion-Scale Similarity Search with GPUs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.3.1">IEEE Trans. Big Data</em> 7,
3 (2021), 535–547.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et al<span class="ltx_text" id="bib.bib79.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam
McCandlish, Tom Henighan, Tom B. Brown,
Benjamin Chess, Rewon Child,
Scott Gray, Alec Radford,
Jeffrey Wu, and Dario Amodei.
2020.

</span>
<span class="ltx_bibblock">Scaling Laws for Neural Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.3.1">CoRR</em> abs/2001.08361
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al<span class="ltx_text" id="bib.bib80.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas
Oguz, Sewon Min, Patrick S. H. Lewis,
Ledell Wu, Sergey Edunov,
Danqi Chen, and Wen-tau Yih.
2020.

</span>
<span class="ltx_bibblock">Dense Passage Retrieval for Open-Domain Question
Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib80.3.1">Proceedings of the 2020 Conference
on Empirical Methods in Natural Language Processing (EMNLP)</em>.
6769–6781.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khandelwal et al<span class="ltx_text" id="bib.bib81.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Urvashi Khandelwal, Angela
Fan, Dan Jurafsky, Luke Zettlemoyer,
and Mike Lewis. 2020a.

</span>
<span class="ltx_bibblock">Nearest Neighbor Machine Translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.3.1">CoRR</em> abs/2010.00710
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khandelwal et al<span class="ltx_text" id="bib.bib82.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Urvashi Khandelwal, Omer
Levy, Dan Jurafsky, Luke Zettlemoyer,
and Mike Lewis. 2020b.

</span>
<span class="ltx_bibblock">Generalization through Memorization: Nearest
Neighbor Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib82.3.1">The 8th International
Conference on Learning Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim
et al<span class="ltx_text" id="bib.bib83.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Sehoon Kim, Amir Gholami,
Zhewei Yao, Michael W. Mahoney, and
Kurt Keutzer. 2021.

</span>
<span class="ltx_bibblock">I-BERT: Integer-only BERT Quantization. In
<em class="ltx_emph ltx_font_italic" id="bib.bib83.3.1">Proceedings of the 38th International Conference on
Machine Learning (ICML)</em> <em class="ltx_emph ltx_font_italic" id="bib.bib83.4.2">(Proceedings of Machine
Learning Research)</em>, Vol. 139.
PMLR, 5506–5518.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">King and Flanigan (2023)</span>
<span class="ltx_bibblock">
Brendan King and Jeffrey
Flanigan. 2023.

</span>
<span class="ltx_bibblock">Diverse Retrieval-Augmented In-Context Learning for
Dialogue State Tracking. In <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">Findings of the
Association for Computational Linguistics (ACL)</em>.
5570–5585.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LangChain (2023)</span>
<span class="ltx_bibblock">
LangChain.
2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">LangChain</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.langchain.com/" title="">https://www.langchain.com/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lazaridou et al<span class="ltx_text" id="bib.bib86.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Angeliki Lazaridou, Elena
Gribovskaya, Wojciech Stokowiec, and
Nikolai Grigorev. 2022.

</span>
<span class="ltx_bibblock">Internet-augmented language models through few-shot
prompting for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.3.1">CoRR</em> abs/2203.05115
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee
et al<span class="ltx_text" id="bib.bib87.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Kyungjae Lee, Sang-eun
Han, Seung-won Hwang, and Moontae
Lee. 2023.

</span>
<span class="ltx_bibblock">When to Read Documents or QA History: On Unified
and Selective Open-domain QA. In <em class="ltx_emph ltx_font_italic" id="bib.bib87.3.1">Findings of the
Association for Computational Linguistics (ACL)</em>.
6420–6432.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis
et al<span class="ltx_text" id="bib.bib88.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Patrick S. H. Lewis, Ethan
Perez, Aleksandra Piktus, Fabio Petroni,
Vladimir Karpukhin, Naman Goyal,
Heinrich Küttler, Mike Lewis,
Wen-tau Yih, Tim Rocktäschel,
Sebastian Riedel, and Douwe Kiela.
2020.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for
Knowledge-Intensive NLP Tasks. In <em class="ltx_emph ltx_font_italic" id="bib.bib88.3.1">Advances in
Neural Information Processing Systems 33 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib89.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Huayang Li, Yixuan Su,
Deng Cai, Yan Wang, and
Lemao Liu. 2022b.

</span>
<span class="ltx_bibblock">A Survey on Retrieval-Augmented Text Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.3.1">CoRR</em> abs/2202.01110
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib90.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Xuanhong Li, Peng Li,
and Po Hu. 2023a.

</span>
<span class="ltx_bibblock">Revisiting Source Context in Nearest Neighbor
Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib90.3.1">Proceedings of the 2023
Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib91.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Xiaonan Li, Kai Lv,
Hang Yan, Tianyang Lin,
Wei Zhu, Yuan Ni,
Guotong Xie, Xiaoling Wang, and
Xipeng Qiu. 2023b.

</span>
<span class="ltx_bibblock">Unified Demonstration Retriever for In-Context
Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib91.3.1">Proceedings of the 61st Annual
Meeting of the Association for Computational Linguistics (ACL)</em>.
4644–4668.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib92.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yuanchun Li, Hao Wen,
Weijun Wang, Xiangyu Li,
Yizhen Yuan, Guohong Liu,
Jiacheng Liu, Wenxing Xu,
Xiang Wang, Yi Sun, Rui
Kong, Yile Wang, Hanfei Geng,
Jian Luan, Xuefeng Jin,
Zilong Ye, Guanjing Xiong,
Fan Zhang, Xiang Li,
Mengwei Xu, Zhijun Li,
Peng Li, Yang Liu,
Ya-Qin Zhang, and Yunxin Liu.
2024.

</span>
<span class="ltx_bibblock">Personal LLM Agents: Insights and Survey about
the Capability, Efficiency and Security.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.3.1">CoRR</em> abs/2401.05459
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
et al<span class="ltx_text" id="bib.bib93.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Yunhao Li, Yunyi Yang,
Xiaojun Quan, and Jianxing Yu.
2021.

</span>
<span class="ltx_bibblock">Retrieve &amp; Memorize: Dialog Policy Learning with
Multi-Action Memory. In <em class="ltx_emph ltx_font_italic" id="bib.bib93.3.1">Findings of the
Association for Computational Linguistics (ACL/IJCNLP)</em>.
447–459.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib94.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Zonglin Li, Ruiqi Guo,
and Sanjiv Kumar. 2022a.

</span>
<span class="ltx_bibblock">Decoupled Context Processing for Context Augmented
Language Modeling. In <em class="ltx_emph ltx_font_italic" id="bib.bib94.3.1">Advances in Neural
Information Processing Systems 35 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin
et al<span class="ltx_text" id="bib.bib95.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Bill Yuchen Lin, Kangmin
Tan, Chris Miller, Beiwen Tian, and
Xiang Ren. 2022.

</span>
<span class="ltx_bibblock">Unsupervised Cross-Task Generalization via
Retrieval Augmentation. In <em class="ltx_emph ltx_font_italic" id="bib.bib95.3.1">Advances in Neural
Information Processing Systems 35 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu (2022)</span>
<span class="ltx_bibblock">
Jerry Liu.
2022.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">LlamaIndex</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.1234" title="">https://doi.org/10.5281/zenodo.1234</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span class="ltx_text" id="bib.bib97.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Junyi Liu, Liangzhi Li,
Tong Xiang, Bowen Wang, and
Yiming Qian. 2023b.

</span>
<span class="ltx_bibblock">TCRA-LLM: Token Compression Retrieval Augmented
Large Language Model for Inference Cost Reduction. In
<em class="ltx_emph ltx_font_italic" id="bib.bib97.3.1">Findings of the Association for Computational
Linguistics (EMNLP)</em>. 9796–9810.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
et al<span class="ltx_text" id="bib.bib98.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Shuai Liu, Hyundong Cho,
Marjorie Freedman, Xuezhe Ma, and
Jonathan May. 2023a.

</span>
<span class="ltx_bibblock">RECAP: Retrieval-Enhanced Context-Aware Prefix
Encoder for Personalized Dialogue Response Generation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib98.3.1">Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
8404–8419.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Wei (2015)</span>
<span class="ltx_bibblock">
Shi-guang Liu and
Yin-wei Wei. 2015.

</span>
<span class="ltx_bibblock">Fast nearest neighbor searching based on improved
VP-tree.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">Pattern Recognit. Lett.</em>
60-61 (2015), 8–15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib100.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott,
Naman Goyal, Jingfei Du,
Mandar Joshi, Danqi Chen,
Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin
Stoyanov. 2019.

</span>
<span class="ltx_bibblock">RoBERTa: A Robustly Optimized BERT Pretraining
Approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.3.1">CoRR</em> abs/1907.11692
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LMDB (2014)</span>
<span class="ltx_bibblock">
LMDB. 2014.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">LMDB</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/LMDB/lmdb" title="">https://github.com/LMDB/lmdb</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span class="ltx_text" id="bib.bib102.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xiaozhong Lyu, Stefan
Grafberger, Samantha Biegel, Shaopeng
Wei, Meng Cao, Sebastian Schelter, and
Ce Zhang. 2023.

</span>
<span class="ltx_bibblock">Improving Retrieval-Augmented Large Language Models
via Data Importance Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.3.1">CoRR</em> abs/2307.03027
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malkov and
Yashunin (2020)</span>
<span class="ltx_bibblock">
Yury A. Malkov and
Dmitry A. Yashunin. 2020.

</span>
<span class="ltx_bibblock">Efficient and Robust Approximate Nearest Neighbor
Search Using Hierarchical Navigable Small World Graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">IEEE Trans. Pattern Anal. Mach. Intell.</em>
42, 4 (2020),
824–836.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallen et al<span class="ltx_text" id="bib.bib104.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Alex Mallen, Akari Asai,
Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh
Hajishirzi. 2023.

</span>
<span class="ltx_bibblock">When Not to Trust Language Models: Investigating
Effectiveness of Parametric and Non-Parametric Memories. In
<em class="ltx_emph ltx_font_italic" id="bib.bib104.3.1">Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
9802–9822.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martins
et al<span class="ltx_text" id="bib.bib105.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Pedro Henrique Martins,
Zita Marinho, and André F. T.
Martins. 2022.

</span>
<span class="ltx_bibblock">Chunk-based Nearest Neighbor Machine Translation.
In <em class="ltx_emph ltx_font_italic" id="bib.bib105.3.1">Proceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing (EMNLP)</em>.
4228–4245.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mei
et al<span class="ltx_text" id="bib.bib106.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Kai Mei, Zelong Li,
Shuyuan Xu, Ruosong Ye,
Yingqiang Ge, and Yongfeng Zhang.
2024.

</span>
<span class="ltx_bibblock">AIOS: LLM Agent Operating System.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib106.3.1">CoRR</em> abs/2403.16971
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng
et al<span class="ltx_text" id="bib.bib107.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Kevin Meng, David Bau,
Alex Andonian, and Yonatan Belinkov.
2022a.

</span>
<span class="ltx_bibblock">Locating and Editing Factual Associations in
GPT. In <em class="ltx_emph ltx_font_italic" id="bib.bib107.3.1">Advances in Neural Information
Processing Systems 35 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng
et al<span class="ltx_text" id="bib.bib108.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Yuxian Meng, Xiaoya Li,
Xiayu Zheng, Fei Wu,
Xiaofei Sun, Tianwei Zhang, and
Jiwei Li. 2022b.

</span>
<span class="ltx_bibblock">Fast Nearest Neighbor Machine Translation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib108.3.1">Findings of the Association for Computational
Linguistics (ACL)</em>. 555–565.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mesnard et al<span class="ltx_text" id="bib.bib109.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Thomas Mesnard, Cassidy
Hardin, Robert Dadashi, Surya
Bhupatiraju, Shreya Pathak, Laurent
Sifre, Morgane Rivière,
Mihir Sanjay Kale, Juliette Love,
Pouya Tafti, Léonard Hussenot,
Aakanksha Chowdhery, Adam Roberts,
Aditya Barua, Alex Botev,
Alex Castro-Ros, Ambrose Slone,
Amélie Héliou, Andrea
Tacchetti, Anna Bulanova, Antonia
Paterson, Beth Tsai, Bobak Shahriari,
Charline Le Lan, Christopher A.
Choquette-Choo, Clément Crepy,
Daniel Cer, Daphne Ippolito,
David Reid, Elena Buchatskaya,
Eric Ni, Eric Noland,
Geng Yan, George Tucker,
George-Cristian Muraru, Grigory
Rozhdestvenskiy, Henryk Michalewski, Ian
Tenney, Ivan Grishchenko, Jacob Austin,
James Keeling, Jane Labanowski,
Jean-Baptiste Lespiau, Jeff Stanway,
Jenny Brennan, Jeremy Chen,
Johan Ferret, Justin Chiu, and
et al. 2024.

</span>
<span class="ltx_bibblock">Gemma: Open Models Based on Gemini Research and
Technology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib109.3.1">CoRR</em> abs/2403.08295
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et al<span class="ltx_text" id="bib.bib110.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Sewon Min, Weijia Shi,
Mike Lewis, Xilun Chen,
Wen-tau Yih, Hannaneh Hajishirzi, and
Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock">Nonparametric Masked Language Modeling. In
<em class="ltx_emph ltx_font_italic" id="bib.bib110.3.1">Findings of the Association for Computational
Linguistics (ACL)</em>. 2097–2118.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mueller et al<span class="ltx_text" id="bib.bib111.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Aaron Mueller, Kanika
Narang, Lambert Mathias, Qifan Wang,
and Hamed Firooz. 2023.

</span>
<span class="ltx_bibblock">Meta-training with Demonstration Retrieval for
Efficient Few-shot Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib111.3.1">Findings of the
Association for Computational Linguistics (ACL)</em>.
6049–6064.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muszynska (2016)</span>
<span class="ltx_bibblock">
Ewa Muszynska.
2016.

</span>
<span class="ltx_bibblock">Graph- and surface-level sentence chunking. In
<em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">Proceedings of the ACL 2016 Student Research
Workshop</em>. Association for Computational Linguistics,
93–99.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NLTK (2001)</span>
<span class="ltx_bibblock">
NLTK. 2001.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">NLTK</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.nltk.org/" title="">https://www.nltk.org/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">Text-Emb-Ada</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/guides/embeddings" title="">https://platform.openai.com/docs/guides/embeddings</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">CoRR</em> abs/2303.08774
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Packer et al<span class="ltx_text" id="bib.bib116.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Charles Packer, Vivian
Fang, Shishir G. Patil, Kevin Lin,
Sarah Wooders, and Joseph E. Gonzalez.
2023.

</span>
<span class="ltx_bibblock">MemGPT: Towards LLMs as Operating Systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib116.3.1">CoRR</em> abs/2310.08560
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paranjape
et al<span class="ltx_text" id="bib.bib117.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Bhargavi Paranjape,
Matthew Lamm, and Ian Tenney.
2022.

</span>
<span class="ltx_bibblock">Retrieval-guided Counterfactual Generation for
QA. In <em class="ltx_emph ltx_font_italic" id="bib.bib117.3.1">Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (ACL)</em>.
1670–1686.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et al<span class="ltx_text" id="bib.bib118.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim
Rocktäschel, Sebastian Riedel,
Patrick S. H. Lewis, Anton Bakhtin,
Yuxiang Wu, and Alexander H. Miller.
2019.

</span>
<span class="ltx_bibblock">Language Models as Knowledge Bases?. In
<em class="ltx_emph ltx_font_italic" id="bib.bib118.3.1">Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP)</em>,
Kentaro Inui, Jing
Jiang, Vincent Ng, and Xiaojun Wan
(Eds.). Association for Computational Linguistics,
2463–2473.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span class="ltx_text" id="bib.bib119.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Alec Radford, Karthik
Narasimhan, Tim Salimans, and Ilya
Sutskever. 2018.

</span>
<span class="ltx_bibblock">Improving language understanding by generative
pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib119.3.1">OpenAI blog</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span class="ltx_text" id="bib.bib120.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu,
Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever.
2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask
learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib120.3.1">OpenAI blog</em> 1,
8 (2019), 9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajaraman and
Ullman (2011)</span>
<span class="ltx_bibblock">
Anand Rajaraman and
Jeffrey David Ullman. 2011.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">Data Mining</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press,
1–17.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram et al<span class="ltx_text" id="bib.bib122.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Ori Ram, Liat Bezalel,
Adi Zicher, Yonatan Belinkov,
Jonathan Berant, and Amir Globerson.
2023a.

</span>
<span class="ltx_bibblock">What Are You Token About? Dense Retrieval as
Distributions Over the Vocabulary. In <em class="ltx_emph ltx_font_italic" id="bib.bib122.3.1">Proceedings
of the 61st Annual Meeting of the Association for Computational Linguistics
(ACL)</em>. 2481–2498.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram et al<span class="ltx_text" id="bib.bib123.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Ori Ram, Yoav Levine,
Itay Dalmedigos, Dor Muhlgay,
Amnon Shashua, Kevin Leyton-Brown,
and Yoav Shoham. 2023b.

</span>
<span class="ltx_bibblock">In-Context Retrieval-Augmented Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib123.3.1">Trans. Assoc. Comput. Linguistics</em>
11 (2023), 1316–1331.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram and Sinha (2019)</span>
<span class="ltx_bibblock">
Parikshit Ram and
Kaushik Sinha. 2019.

</span>
<span class="ltx_bibblock">Revisiting kd-tree for Nearest Neighbor Search. In
<em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery &amp; Data Mining (KDD)</em>,
Ankur Teredesai, Vipin
Kumar, Ying Li, Rómer Rosales,
Evimaria Terzi, and George Karypis
(Eds.). ACM, 1378–1388.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reid
et al<span class="ltx_text" id="bib.bib125.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Machel Reid, Nikolay
Savinov, Denis Teplyashin, Dmitry
Lepikhin, Timothy P. Lillicrap,
Jean-Baptiste Alayrac, Radu Soricut,
Angeliki Lazaridou, Orhan Firat,
Julian Schrittwieser, Ioannis Antonoglou,
Rohan Anil, Sebastian Borgeaud,
Andrew M. Dai, Katie Millican,
Ethan Dyer, Mia Glaese,
Thibault Sottiaux, Benjamin Lee,
Fabio Viola, Malcolm Reynolds,
Yuanzhong Xu, James Molloy,
Jilin Chen, Michael Isard,
Paul Barham, Tom Hennigan,
Ross McIlroy, Melvin Johnson,
Johan Schalkwyk, Eli Collins,
Eliza Rutherford, Erica Moreira,
Kareem Ayoub, Megha Goel,
Clemens Meyer, Gregory Thornton,
Zhen Yang, Henryk Michalewski,
Zaheer Abbas, Nathan Schucher,
Ankesh Anand, Richard Ives,
James Keeling, Karel Lenc,
Salem Haykal, Siamak Shakeri,
Pranav Shyam, Aakanksha Chowdhery,
Roman Ring, Stephen Spencer,
Eren Sezener, and et al.
2024.

</span>
<span class="ltx_bibblock">Gemini 1.5: Unlocking multimodal understanding
across millions of tokens of context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.3.1">CoRR</em> abs/2403.05530
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and
Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna
Gurevych. 2019.

</span>
<span class="ltx_bibblock">Sentence-BERT: Sentence Embeddings using Siamese
BERT-Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">Proceedings of the 2019
Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP)</em>. 3980–3990.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren
et al<span class="ltx_text" id="bib.bib127.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yubing Ren, Yanan Cao,
Ping Guo, Fang Fang, Wei
Ma, and Zheng Lin. 2023.

</span>
<span class="ltx_bibblock">Retrieve-and-Sample: Document-level Event Argument
Extraction via Hybrid Retrieval Augmentation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib127.3.1">Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
293–306.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et al<span class="ltx_text" id="bib.bib128.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Devendra Singh Sachan,
Siva Reddy, William L. Hamilton,
Chris Dyer, and Dani Yogatama.
2021.

</span>
<span class="ltx_bibblock">End-to-End Training of Multi-Document Reader and
Retriever for Open-Domain Question Answering. In
<em class="ltx_emph ltx_font_italic" id="bib.bib128.3.1">Advances in Neural Information Processing Systems
34 (NeurIPS)</em>. 25968–25981.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh
et al<span class="ltx_text" id="bib.bib129.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre
Debut, Julien Chaumond, and Thomas
Wolf. 2019.

</span>
<span class="ltx_bibblock">DistilBERT, a distilled version of BERT: smaller,
faster, cheaper and lighter.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib129.3.1">CoRR</em> abs/1910.01108
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick
et al<span class="ltx_text" id="bib.bib130.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Timo Schick, Jane
Dwivedi-Yu, Roberto Dessì,
Roberta Raileanu, Maria Lomeli,
Eric Hambro, Luke Zettlemoyer,
Nicola Cancedda, and Thomas Scialom.
2023.

</span>
<span class="ltx_bibblock">Toolformer: Language Models Can Teach Themselves to
Use Tools. In <em class="ltx_emph ltx_font_italic" id="bib.bib130.3.1">Advances in Neural Information
Processing Systems 36 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sean Lee (2024)</span>
<span class="ltx_bibblock">
Darius Koenig Julius Lipp Sean Lee,
Aamir Shakir. 2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib131.1.1">Open Source Strikes Bread - New Fluffy
Embeddings Model</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mixedbread.ai/blog/mxbai-embed-large-v1" title="">https://www.mixedbread.ai/blog/mxbai-embed-large-v1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span class="ltx_text" id="bib.bib132.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min,
Michihiro Yasunaga, Minjoon Seo,
Rich James, Mike Lewis,
Luke Zettlemoyer, and Wen-tau Yih.
2023.

</span>
<span class="ltx_bibblock">REPLUG: Retrieval-Augmented Black-Box Language
Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib132.3.1">CoRR</em> abs/2301.12652
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et al<span class="ltx_text" id="bib.bib133.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer
Poff, Moya Chen, Douwe Kiela, and
Jason Weston. 2021.

</span>
<span class="ltx_bibblock">Retrieval Augmentation Reduces Hallucination in
Conversation. In <em class="ltx_emph ltx_font_italic" id="bib.bib133.3.1">Findings of the Association for
Computational Linguistics (EMNLP)</em>. Association for
Computational Linguistics, 3784–3803.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et al<span class="ltx_text" id="bib.bib134.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Karan Singhal, Shekoofeh
Azizi, Tao Tu, S. Sara Mahdavi,
Jason Wei, Hyung Won Chung,
Nathan Scales, Ajay Kumar Tanwani,
Heather Cole-Lewis, Stephen Pfohl,
Perry Payne, Martin Seneviratne,
Paul Gamble, Chris Kelly,
Nathaneal Schärli, Aakanksha
Chowdhery, Philip Andrew Mansfield,
Blaise Agüera y Arcas, Dale R.
Webster, Gregory S. Corrado, Yossi
Matias, Katherine Chou, Juraj Gottweis,
Nenad Tomasev, Yun Liu,
Alvin Rajkomar, Joelle K. Barral,
Christopher Semturs, Alan
Karthikesalingam, and Vivek Natarajan.
2023a.

</span>
<span class="ltx_bibblock">Large Language Models Encode Clinical Knowledge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib134.3.1">Nature</em> 620,
7972 (2023), 172–180.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et al<span class="ltx_text" id="bib.bib135.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Karan Singhal, Tao Tu,
Juraj Gottweis, Rory Sayres,
Ellery Wulczyn, Le Hou,
Kevin Clark, Stephen Pfohl,
Heather Cole-Lewis, Darlene Neal,
Mike Schaekermann, Amy Wang,
Mohamed Amin, Sami Lachgar,
Philip Andrew Mansfield, Sushant Prakash,
Bradley Green, Ewa Dominowska,
Blaise Agüera y Arcas, Nenad
Tomasev, Yun Liu, Renee Wong,
Christopher Semturs, S. Sara Mahdavi,
Joelle K. Barral, Dale R. Webster,
Gregory S. Corrado, Yossi Matias,
Shekoofeh Azizi, Alan Karthikesalingam,
and Vivek Natarajan. 2023b.

</span>
<span class="ltx_bibblock">Towards Expert-Level Medical Question Answering
with Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib135.3.1">CoRR</em> abs/2305.09617
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spotify (2017)</span>
<span class="ltx_bibblock">
Spotify. 2017.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib136.1.1">Annoy</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/spotify/annoy" title="">https://github.com/spotify/annoy</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su
et al<span class="ltx_text" id="bib.bib137.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha H. M.
Ahmed, Yu Lu, Shengfeng Pan,
Wen Bo, and Yunfeng Liu.
2024.

</span>
<span class="ltx_bibblock">RoFormer: Enhanced transformer with Rotary Position
Embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib137.3.1">Neurocomputing</em> 568
(2024), 127063.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib138.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiashuo Sun, Chengjin Xu,
Lumingyuan Tang, Saizhuo Wang,
Chen Lin, Yeyun Gong,
Heung-Yeung Shum, and Jian Guo.
2023.

</span>
<span class="ltx_bibblock">Think-on-Graph: Deep and Responsible Reasoning of
Large Language Model with Knowledge Graph.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib138.3.1">CoRR</em> abs/2307.07697
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib139.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut
Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux,
Timothée Lacroix, Baptiste
Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, Aurélien Rodriguez,
Armand Joulin, Edouard Grave, and
Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock">LLaMA: Open and Efficient Foundation Language
Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib139.3.1">CoRR</em> abs/2302.13971
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron
et al<span class="ltx_text" id="bib.bib140.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis
Martin, Kevin Stone, Peter Albert,
Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra,
Prajjwal Bhargava, Shruti Bhosale,
Dan Bikel, Lukas Blecher,
Cristian Canton-Ferrer, Moya Chen,
Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu,
Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami,
Naman Goyal, Anthony Hartshorn,
Saghar Hosseini, Rui Hou,
Hakan Inan, Marcin Kardas,
Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev,
Punit Singh Koura, Marie-Anne Lachaux,
Thibaut Lavril, Jenya Lee,
Diana Liskovich, Yinghai Lu,
Yuning Mao, Xavier Martinet,
Todor Mihaylov, Pushkar Mishra,
Igor Molybog, Yixin Nie,
Andrew Poulton, Jeremy Reizenstein,
Rashi Rungta, Kalyan Saladi,
Alan Schelten, Ruan Silva,
Eric Michael Smith, Ranjan Subramanian,
Xiaoqing Ellen Tan, Binh Tang,
Ross Taylor, Adina Williams,
Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov,
Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang,
Aurélien Rodriguez, Robert Stojnic,
Sergey Edunov, and Thomas Scialom.
2023b.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat
Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib140.3.1">CoRR</em> abs/2307.09288
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span class="ltx_text" id="bib.bib141.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin.
2017.

</span>
<span class="ltx_bibblock">Attention is All you Need. In
<em class="ltx_emph ltx_font_italic" id="bib.bib141.3.1">Advances in Neural Information Processing Systems
30 (NeurIPS)</em>. 5998–6008.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu et al<span class="ltx_text" id="bib.bib142.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tu Vu, Mohit Iyyer,
Xuezhi Wang, Noah Constant,
Jerry W. Wei, Jason Wei,
Chris Tar, Yun-Hsuan Sung,
Denny Zhou, Quoc V. Le, and
Thang Luong. 2023.

</span>
<span class="ltx_bibblock">FreshLLMs: Refreshing Large Language Models with
Search Engine Augmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib142.3.1">CoRR</em> abs/2310.03214
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib143.2.2.1">.</span> (2023e)</span>
<span class="ltx_bibblock">
Boxin Wang, Wei Ping,
Peng Xu, Lawrence McAfee,
Zihan Liu, Mohammad Shoeybi,
Yi Dong, Oleksii Kuchaiev,
Bo Li, Chaowei Xiao,
Anima Anandkumar, and Bryan Catanzaro.
2023e.

</span>
<span class="ltx_bibblock">Shall We Pretrain Autoregressive Language Models
with Retrieval? A Comprehensive Study. In
<em class="ltx_emph ltx_font_italic" id="bib.bib143.3.1">Proceedings of the 2023 Conference on Empirical
Methods in Natural Language Processing (EMNLP)</em>.
7763–7786.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib144.2.2.1">.</span> (2021b)</span>
<span class="ltx_bibblock">
Jianguo Wang, Xiaomeng
Yi, Rentong Guo, Hai Jin,
Peng Xu, Shengjun Li,
Xiangyu Wang, Xiangzhou Guo,
Chengming Li, Xiaohai Xu,
Kun Yu, Yuxing Yuan,
Yinghao Zou, Jiquan Long,
Yudong Cai, Zhenxiang Li,
Zhifeng Zhang, Yihua Mo,
Jun Gu, Ruiyi Jiang, Yi
Wei, and Charles Xie. 2021b.

</span>
<span class="ltx_bibblock">Milvus: A Purpose-Built Vector Data Management
System. In <em class="ltx_emph ltx_font_italic" id="bib.bib144.3.1">SIGMOD ’21: International Conference
on Management of Data</em>. ACM,
2614–2627.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib145.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Lei Wang, Chen Ma,
Xueyang Feng, Zeyu Zhang,
Hao Yang, Jingsen Zhang,
Zhiyuan Chen, Jiakai Tang,
Xu Chen, Yankai Lin,
Wayne Xin Zhao, Zhewei Wei, and
Jirong Wen. 2024.

</span>
<span class="ltx_bibblock">A survey on large language model based autonomous
agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib145.3.1">Frontiers Comput. Sci.</em>
18, 6 (2024),
186345.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib146.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shuohang Wang, Yichong
Xu, Yuwei Fang, Yang Liu,
Siqi Sun, Ruochen Xu,
Chenguang Zhu, and Michael Zeng.
2022.

</span>
<span class="ltx_bibblock">Training Data is More Valuable than You Think: A
Simple and Effective Method by Retrieving from Training Data. In
<em class="ltx_emph ltx_font_italic" id="bib.bib146.3.1">Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
3170–3179.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib147.2.2.1">.</span> (2023f)</span>
<span class="ltx_bibblock">
Song Wang, Yaochen Zhu,
Haochen Liu, Zaiyi Zheng,
Chen Chen, and Jundong Li.
2023f.

</span>
<span class="ltx_bibblock">Knowledge Editing for Large Language Models: A
Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib147.3.1">CoRR</em> abs/2310.16218
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib148.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Weizhi Wang, Li Dong,
Hao Cheng, Xiaodong Liu,
Xifeng Yan, Jianfeng Gao, and
Furu Wei. 2023b.

</span>
<span class="ltx_bibblock">Augmenting Language Models with Long-Term Memory.
In <em class="ltx_emph ltx_font_italic" id="bib.bib148.3.1">Advances in Neural Information Processing
Systems 36 (NeurIPS)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib149.2.2.1">.</span> (2021a)</span>
<span class="ltx_bibblock">
Xinyu Wang, Yong Jiang,
Nguyen Bach, Tao Wang,
Zhongqiang Huang, Fei Huang, and
Kewei Tu. 2021a.

</span>
<span class="ltx_bibblock">Improving Named Entity Recognition by External
Context Retrieving and Cooperative Learning. In
<em class="ltx_emph ltx_font_italic" id="bib.bib149.3.1">Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing (ACL/IJCNLP)</em>.
1800–1812.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib150.2.2.1">.</span> (2023c)</span>
<span class="ltx_bibblock">
Yile Wang, Peng Li,
Maosong Sun, and Yang Liu.
2023c.

</span>
<span class="ltx_bibblock">Self-Knowledge Guided Retrieval Augmentation for
Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib150.3.1">Findings of the
Association for Computational Linguistics (EMNLP)</em>.
10303–10315.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span class="ltx_text" id="bib.bib151.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Zhiruo Wang, Jun Araki,
Zhengbao Jiang, Md. Rizwan Parvez, and
Graham Neubig. 2023a.

</span>
<span class="ltx_bibblock">Learning to Filter Context for Retrieval-Augmented
Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib151.3.1">CoRR</em> abs/2311.08377
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib152.2.2.1">.</span> (2023d)</span>
<span class="ltx_bibblock">
Zichao Wang, Weili Nie,
Zhuoran Qiao, Chaowei Xiao,
Richard G. Baraniuk, and Anima
Anandkumar. 2023d.

</span>
<span class="ltx_bibblock">Retrieval-based Controllable Molecule Generation.
In <em class="ltx_emph ltx_font_italic" id="bib.bib152.3.1">The Eleventh International Conference on
Learning Representations, (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Goodman (2018)</span>
<span class="ltx_bibblock">
Mike Wu and Noah D.
Goodman. 2018.

</span>
<span class="ltx_bibblock">Multimodal Generative Models for Scalable
Weakly-Supervised Learning. In <em class="ltx_emph ltx_font_italic" id="bib.bib153.1.1">Advances in Neural
Information Processing Systems 31 (NeurIPS)</em>. 5580–5590.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span class="ltx_text" id="bib.bib154.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Shangyu Wu, Ying Xiong,
Yufei Cui, Xue Liu,
Buzhou Tang, Tei-Wei Kuo, and
Chun Jason Xue. 2024.

</span>
<span class="ltx_bibblock">ReFusion: Improving Natural Language
Understanding with Computation-Efficient Retrieval Representation Fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib154.3.1">CoRR</em> abs/2401.02993
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
et al<span class="ltx_text" id="bib.bib155.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yuhuai Wu, Markus Norman
Rabe, DeLesley Hutchins, and Christian
Szegedy. 2022.

</span>
<span class="ltx_bibblock">Memorizing Transformers. In
<em class="ltx_emph ltx_font_italic" id="bib.bib155.3.1">The Tenth International Conference on Learning
Representations (ICLR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xi
et al<span class="ltx_text" id="bib.bib156.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhiheng Xi, Wenxiang
Chen, Xin Guo, Wei He,
Yiwen Ding, Boyang Hong,
Ming Zhang, Junzhe Wang,
Senjie Jin, Enyu Zhou,
Rui Zheng, Xiaoran Fan,
Xiao Wang, Limao Xiong,
Yuhao Zhou, Weiran Wang,
Changhao Jiang, Yicheng Zou,
Xiangyang Liu, Zhangyue Yin,
Shihan Dou, Rongxiang Weng,
Wensen Cheng, Qi Zhang,
Wenjuan Qin, Yongyan Zheng,
Xipeng Qiu, Xuanjing Huang, and
Tao Gui. 2023.

</span>
<span class="ltx_bibblock">The Rise and Potential of Large Language Model
Based Agents: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib156.3.1">CoRR</em> abs/2309.07864
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao
et al<span class="ltx_text" id="bib.bib157.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shitao Xiao, Zheng Liu,
Peitian Zhang, and Niklas Muennighof.
2023.

</span>
<span class="ltx_bibblock">C-Pack: Packaged Resources To Advance General
Chinese Embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib157.3.1">CoRR</em> abs/2309.07597
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie
et al<span class="ltx_text" id="bib.bib158.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Junlin Xie, Zhihong Chen,
Ruifei Zhang, Xiang Wan, and
Guanbin Li. 2024.

</span>
<span class="ltx_bibblock">Large Multimodal Agents: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib158.3.1">CoRR</em> abs/2402.15116
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span class="ltx_text" id="bib.bib159.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ying Xiong, Xin Yang,
Linjing Liu, Ka-Chun Wong,
Qingcai Chen, Yang Xiang, and
Buzhou Tang. 2023.

</span>
<span class="ltx_bibblock">EARA: Improving Biomedical Semantic Textual
Similarity with Entity-Aligned Attention and Retrieval Augmentation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib159.3.1">Findings of the Association for Computational
Linguistics (EMNLP)</em>. Association for Computational
Linguistics, 8760–8771.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib160.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Fangyuan Xu, Weijia Shi,
and Eunsol Choi. 2023b.

</span>
<span class="ltx_bibblock">RECOMP: Improving Retrieval-Augmented LMs with
Compression and Selective Augmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib160.3.1">CoRR</em> abs/2310.04408
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
et al<span class="ltx_text" id="bib.bib161.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Frank F. Xu, Uri Alon,
and Graham Neubig. 2023a.

</span>
<span class="ltx_bibblock">Why do Nearest Neighbor Language Models Work?. In
<em class="ltx_emph ltx_font_italic" id="bib.bib161.3.1">Proceedings of the 40th International Conference on
Machine Learning (ICML)</em> <em class="ltx_emph ltx_font_italic" id="bib.bib161.4.2">(Proceedings of Machine
Learning Research)</em>, Vol. 202.
38325–38341.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu
et al<span class="ltx_text" id="bib.bib162.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Guoxin Yu, Lemao Liu,
Haiyun Jiang, Shuming Shi, and
Xiang Ao. 2023a.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Few-shot Text Classification.
In <em class="ltx_emph ltx_font_italic" id="bib.bib162.3.1">Findings of the Association for Computational
Linguistics (EMNLP)</em>. 6721–6735.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu
et al<span class="ltx_text" id="bib.bib163.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Hao Yu, Aoran Gan,
Kai Zhang, Shiwei Tong,
Qi Liu, and Zhaofeng Liu.
2024.

</span>
<span class="ltx_bibblock">Evaluation of Retrieval-Augmented Generation: A
Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib163.3.1">CoRR</em> abs/2405.07437
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu
et al<span class="ltx_text" id="bib.bib164.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Zichun Yu, Chenyan Xiong,
Shi Yu, and Zhiyuan Liu.
2023b.

</span>
<span class="ltx_bibblock">Augmentation-Adapted Retriever Improves
Generalization of Language Models as Generic Plug-In. In
<em class="ltx_emph ltx_font_italic" id="bib.bib164.3.1">Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (ACL)</em>.
2421–2436.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng
et al<span class="ltx_text" id="bib.bib165.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu,
Zhengxiao Du, Zihan Wang,
Hanyu Lai, Ming Ding,
Zhuoyi Yang, Yifan Xu,
Wendi Zheng, Xiao Xia,
Weng Lam Tam, Zixuan Ma,
Yufei Xue, Jidong Zhai,
Wenguang Chen, Zhiyuan Liu,
Peng Zhang, Yuxiao Dong, and
Jie Tang. 2023.

</span>
<span class="ltx_bibblock">GLM-130B: An Open Bilingual Pre-trained Model.
In <em class="ltx_emph ltx_font_italic" id="bib.bib165.3.1">The Eleventh International Conference on
Learning Representations (ICLR)</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and
Sennrich (2019)</span>
<span class="ltx_bibblock">
Biao Zhang and Rico
Sennrich. 2019.

</span>
<span class="ltx_bibblock">Root Mean Square Layer Normalization. In
<em class="ltx_emph ltx_font_italic" id="bib.bib166.1.1">Advances in Neural Information Processing Systems
32 (NeurIPS)</em>. 12360–12371.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib167.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Hongbo Zhang, Junying
Chen, Feng Jiang, Fei Yu,
Zhihong Chen, Guiming Chen,
Jianquan Li, Xiangbo Wu,
Zhiyi Zhang, Qingying Xiao,
Xiang Wan, Benyou Wang, and
Haizhou Li. 2023a.

</span>
<span class="ltx_bibblock">HuatuoGPT, Towards Taming Language Model to Be a
Doctor. In <em class="ltx_emph ltx_font_italic" id="bib.bib167.3.1">Findings of the Association for
Computational Linguistics (EMNLP)</em>. Association for
Computational Linguistics, 10859–10885.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib168.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Jianyi Zhang, Aashiq
Muhamed, Aditya Anantharaman, Guoyin
Wang, Changyou Chen, Kai Zhong,
Qingjun Cui, Yi Xu,
Belinda Zeng, Trishul Chilimbi, and
Yiran Chen. 2023b.

</span>
<span class="ltx_bibblock">ReAugKD: Retrieval-Augmented Knowledge Distillation
For Pre-trained Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib168.3.1">Proceedings of
the 61st Annual Meeting of the Association for Computational Linguistics
(ACL)</em>. 1128–1136.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib169.2.2.1">.</span> (2024c)</span>
<span class="ltx_bibblock">
Ningyu Zhang, Yunzhi Yao,
Bozhong Tian, Peng Wang,
Shumin Deng, Mengru Wang,
Zekun Xi, Shengyu Mao,
Jintian Zhang, Yuansheng Ni,
Siyuan Cheng, Ziwen Xu,
Xin Xu, Jia-Chen Gu,
Yong Jiang, Pengjun Xie,
Fei Huang, Lei Liang,
Zhiqiang Zhang, Xiaowei Zhu,
Jun Zhou, and Huajun Chen.
2024c.

</span>
<span class="ltx_bibblock">A Comprehensive Study of Knowledge Editing for
Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib169.3.1">CoRR</em> abs/2401.01286
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib170">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib170.2.2.1">.</span> (2024b)</span>
<span class="ltx_bibblock">
Yadong Zhang, Shaoguang
Mao, Tao Ge, Xun Wang,
Adrian de Wynter, Yan Xia,
Wenshan Wu, Ting Song,
Man Lan, and Furu Wei.
2024b.

</span>
<span class="ltx_bibblock">LLM as a Mastermind: A Survey of Strategic
Reasoning with Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib170.3.1">CoRR</em> abs/2404.01230
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib171">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib171.2.2.1">.</span> (2024a)</span>
<span class="ltx_bibblock">
Zeyu Zhang, Xiaohe Bo,
Chen Ma, Rui Li, Xu
Chen, Quanyu Dai, Jieming Zhu,
Zhenhua Dong, and Ji-Rong Wen.
2024a.

</span>
<span class="ltx_bibblock">A Survey on the Memory Mechanism of Large Language
Model based Agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib171.3.1">CoRR</em> abs/2404.13501
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib172">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib172.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Penghao Zhao, Hailin
Zhang, Qinhan Yu, Zhengren Wang,
Yunteng Geng, Fangcheng Fu,
Ling Yang, Wentao Zhang, and
Bin Cui. 2024.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for AI-Generated
Content: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib172.3.1">CoRR</em> abs/2402.19473
(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib173">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib173.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Xin Zheng, Zhirui Zhang,
Junliang Guo, Shujian Huang,
Boxing Chen, Weihua Luo, and
Jiajun Chen. 2021.

</span>
<span class="ltx_bibblock">Adaptive Nearest Neighbor Machine Translation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib173.3.1">Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing (ACL/IJCNLP)</em>.
368–374.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib174">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong
et al<span class="ltx_text" id="bib.bib174.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Zexuan Zhong, Tao Lei,
and Danqi Chen. 2022.

</span>
<span class="ltx_bibblock">Training Language Models with Memory Augmentation.
In <em class="ltx_emph ltx_font_italic" id="bib.bib174.3.1">Proceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing (EMNLP)</em>.
5657–5673.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib175">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu
et al<span class="ltx_text" id="bib.bib175.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenhao Zhu, Jingjing Xu,
Shujian Huang, Lingpeng Kong, and
Jiajun Chen. 2023.

</span>
<span class="ltx_bibblock">INK: Injecting kNN Knowledge in Nearest Neighbor
Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib175.3.1">Proceedings of the 61st
Annual Meeting of the Association for Computational Linguistics (ACL)</em>.
15948–15959.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Jul 19 02:01:55 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
