<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations</title>
<!--Generated on Sat Jul  6 02:18:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.04925v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S1" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S2" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S2.SS1" title="In 2 Related Works ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Course Recommender Systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S2.SS2" title="In 2 Related Works ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Large Language Models in Education</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S2.SS3" title="In 2 Related Works ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Retrieval-Augmented Generation in Education</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.SS1" title="In 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.SS2" title="In 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Recommendation System Design</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.SS2.SSS1" title="In 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Prompt Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.SS2.SSS2" title="In 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Integration of RAG approach</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.SS2.SSS3" title="In 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Comparative Analysis</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.SS1" title="In 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>LLM vs. Non-LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.SS2" title="In 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>LLM vs. LLM with RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S5" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S6" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Acknowledgments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#A1" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>DATASET WE USE</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#A2" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Link of the RAG system code</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#A3" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Link of the Chatbot DEMO</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#A4" title="In RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Link of the Medium Blog inspired us of the demo design</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jiarui Rao
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/>
Jionghao Lin
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Carnegie Mellon University
</span>
<span class="ltx_contact ltx_role_address">5000 Forbes Ave 
</span>
<span class="ltx_contact ltx_role_address">Pittsburgh, PA 15213
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jiaruira@andrew.cmu.edu">jiaruira@andrew.cmu.edu</a>
</span>
<span class="ltx_contact ltx_role_address">Carnegie Mellon University
</span>
<span class="ltx_contact ltx_role_address">5000 Forbes Ave 
</span>
<span class="ltx_contact ltx_role_address">Pittsburgh, PA 15213
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jionghal@andrew.cmu.edu">jionghal@andrew.cmu.edu</a>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Massive Open Online Courses (MOOCs) have significantly enhanced educational accessibility by offering a wide variety of courses and breaking down traditional barriers related to geography, finance, and time. However, students often face difficulties navigating the vast selection of courses, especially when exploring new fields of study. Driven by this challenge, researchers have been exploring course recommender systems to offer tailored guidance that aligns with individual learning preferences and career aspirations. These systems face particular challenges in effectively addressing the “cold start” problem for new users. Recent advancements in recommender systems suggest integrating large language models (LLMs) into the recommendation process to enhance personalized recommendations and address the “cold start” problem. Motivated by these advancements, our study introduces RAMO (Retrieval-Augmented Generation for MOOCs), a system specifically designed to overcome the “cold start” challenges of traditional course recommender systems. The RAMO system leverages the capabilities of LLMs, along with Retrieval-Augmented Generation (RAG)-facilitated contextual understanding, to provide course recommendations through a conversational interface, aiming to enhance the e-learning experience.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Retrieval-Augmented Generation (RAG), Personalized Learning, Recommender Systems, Artificial Intelligence
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_titlenote" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">titlenote: </span>This paper underwent a rigorous review process and was officially accepted on May 31, 2024, for presentation at the Educational Data Mining 2024 Workshop: Leveraging Large Language Models for Next Generation Educational Technologies.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Massive Open Online Courses (MOOCs) gently facilitate access to learning for a diverse global audience <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib3" title="">3</a>]</cite>. By providing an extensive range of courses through an easily accessible online platform, MOOCs not only enhance individual learning and development but also enrich the broader educational community <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib4" title="">4</a>]</cite>. However, the diverse categories of courses across disciplines can often overwhelm students when they step into new fields of study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib17" title="">17</a>]</cite>. Selecting the right courses that align with both personal interests and academic requirements is crucial, as improper choices may lead to wasted time, and resources, and a lack of fulfillment in one’s educational journey.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To resolve this, researchers have developed course recommender systems using advanced algorithms to offer tailored guidance that aligns with individual learning preferences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib30" title="">30</a>]</cite>. Many existing implementations of recommendation systems have demonstrated significant benefits, such as enhancing personalized learning experiences and improving student engagement, as highlighted by a recent study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib11" title="">11</a>]</cite>. However, these systems also face critical limitations, particularly the “<span class="ltx_text ltx_font_italic" id="S1.p2.1.1">cold start</span>” problem, which occurs when trying to make recommendations for new users with limited historical data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib15" title="">15</a>]</cite>. Though previous research proposed a more complex framework—a novel meta-learning heterogeneous information networks approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib25" title="">25</a>]</cite>—to address the “<span class="ltx_text ltx_font_italic" id="S1.p2.1.2">cold start</span>” recommendation issue, the approach faces the challenge of high computational complexity, which is not scalable for large-scale MOOCs platforms.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In response to address the limitations of prior work in recommendation systems, where the recommendations lack sufficient personalization and interaction with users, researchers have proposed integrating large language models (LLMs) into course recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib18" title="">18</a>]</cite>. This approach enhances recommendation accuracy and personalization by leveraging user history and conversational prompts. Recent frameworks like GPT4Rec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib21" title="">21</a>]</cite> and Chat-Rec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib9" title="">9</a>]</cite> demonstrated the potential of LLMs in improving course alignment with learners’ interests and interaction. However, LLMs can sometimes generate misleading or outdated information. To counteract these shortcomings, one possible solution is the integration of Retrieval-Augmented Generation (RAG) with LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib26" title="">26</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S1.F1.2">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S1.F1.1">Demo of the RAG facilitated course recommender system we developed  <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="251" id="S1.F1.1.g1" src="extracted/5713922/interface_ramo.png" width="479"/></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Interface of the Retrieval-Augmented Generation for MOOCs (RAMO) system</figcaption>
</figure>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib10" title="">10</a>]</cite> is a process that optimizes the output of LLMs by extending their robust capabilities to cater specifically to distinct domains or an organization’s internal knowledge base, eliminating the need for retraining the model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib8" title="">8</a>]</cite>. The use of RAG in recommendation systems enhances the adaptability of LLMs, ensuring that recommendations remain current and contextually relevant <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib26" title="">26</a>]</cite>. This advancement paves the way for more precise and targeted course recommendations that adapt to changes in educational content and learner preferences. Despite these improvements, there is a noticeable gap in research specifically focused on using LLMs in course recommender systems, particularly in addressing the “<span class="ltx_text ltx_font_italic" id="S1.p4.1.1">cold start</span>” problem where the system lacks a user’s profile. Thus, our study aims to investigate the potential of LLMs, particularly those enhanced by RAG, in providing course recommendations tailored to individual user needs. We introduce a course recommender system, <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">RAMO</span> (<span class="ltx_text ltx_font_bold" id="S1.p4.1.3">R</span>etrieval-<span class="ltx_text ltx_font_bold" id="S1.p4.1.4">A</span>ugmented <span class="ltx_text ltx_font_bold" id="S1.p4.1.5">G</span>eneration for <span class="ltx_text ltx_font_bold" id="S1.p4.1.6">MO</span>OCs), which employs a RAG-based LLM model (refer to Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>). RAMO leverages RAG’s advantage to improve the quality of course recommendations, addressing and mitigating common issues associated with LLMs especially in “<span class="ltx_text ltx_font_italic" id="S1.p4.1.7">cold start</span>” problem.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Course Recommender Systems</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Course recommender systems are essential in educational technology, helping students choose courses that align with their interests and academic goals. Many prior studies have employed collaborative filtering methods to build course recommender systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib19" title="">19</a>]</cite>. For instance, Schafer et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib31" title="">31</a>]</cite> proposed a recommender system that suggested courses based on the preferences of similar users. A more recent example by Koren et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib19" title="">19</a>]</cite> developed advanced collaborative filtering techniques to enhance course recommendation accuracy. However, a significant issue arises when recommending courses for new users, as there is no historical data available for these individuals—this is known as the “<span class="ltx_text ltx_font_italic" id="S2.SS1.p1.1.1">cold start</span>” problem <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib35" title="">35</a>]</cite>. To address this challenge, a recent study by Wu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib35" title="">35</a>]</cite> leveraged large language models (LLMs), which utilize extensive pre-trained knowledge from web datasets, demonstrating potential in overcoming the cold start problem. Despite the advancements in LLMs, their integration into course recommendation systems remains largely unexplored, presenting an opportunity for future research to innovate and improve student course selection processes.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Large Language Models in Education</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Large language models (LLMs) like ChatGPT, trained on extensive datasets, have the ability to generate human-like text and respond to questions with exceptional precision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib36" title="">36</a>]</cite>. Many studies have highlighted the potential of LLMs in educational applications, leveraging their capabilities to enhance various aspects of teaching and learning. For example, Kabir and Lin <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib16" title="">16</a>]</cite> developed an adaptive practicing system utilizing ChatGPT to generate personalized questions and feedback, demonstrating LLMs’ potential in facilitating tailored educational interactions. Researchers investigated multiple GPT models on their ability to generate tailored learning materials and provide instant feedback on student errors, enhancing personalized learning experiences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib34" title="">34</a>]</cite>. Huber et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib13" title="">13</a>]</cite>
demonstrated the use of LLMs in creating interactive, conversational systems that assist both students and teachers by providing adaptive learning support and resources. Moreover, LLMs are also used in generating automatic feedback for students <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib6" title="">6</a>]</cite>, handling sparse learner performance data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib37" title="">37</a>]</cite> from intelligent tutoring systems, predicting learning performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib38" title="">38</a>]</cite>, and supporting tutor training session <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib23" title="">23</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Retrieval-Augmented Generation in Education</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Retrieval-augmented generationn (RAG) has emerged as a significant technique to enhance the effectiveness of educational tools powered by LLMs. For example, a study <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib20" title="">20</a>]</cite> integrated textbook content into LLM prompts via RAG improved the quality of responses in interactive question-answering (QA) scenarios for middle-school math students, and demonstrated that students generally prefer responses generated by RAGs.
RAG has also been employed in programming education to generate improved feedback for student’s completion of coding tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib14" title="">14</a>]</cite>, by incorporating transcriptions of lecture recordings and using timestamps as meta-information, RAG reduces hallucinations and ensures the use of accurate technical terms. Moreover, RAG has been utilized to assess novice math tutors’ use of social-emotional learning strategies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib22" title="">22</a>]</cite>, they proved that RAG-enhanced prompts demonstrated more accurate and cost-effective performance compared to other prompting strategies by providing relevant external content. This application highlights the potential of RAG in developing personalized tutor training programs and enhancing the overall effectiveness of tutored learning.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">While traditional course recommender systems have laid the groundwork for personalized education, the integration of LLMs and techniques such as RAG offers unprecedented opportunities for enhancing educational experiences. These advanced methods address limitations of earlier approaches and pave the way for more sophisticated and effective educational tools, inspiring us to utilize RAG in developing our course recommender system.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In this study, we utilized the “Coursera Courses Dataset 2021”<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.kaggle.com/datasets/khusheekapoor/coursera-courses-dataset-2021</span></span></span></span> from Kaggle. The dataset, scraped from Coursera’s publicly available information in September 2021, contains a variety of courses that feature comprehensive details such as skill requirements, difficulty levels, and direct course links. It provides a robust knowledge base for our RAMO system, enabling it to suggest courses tailored to students’ specific skills and educational needs. This dataset effectively supports our objective to enhance accessibility and personalized learning through course recommendations. We first cleaned the dataset to remove meaningless symbols and duplicate rows, and it has 3,342 non-duplicate courses in total after data-cleaning, with 6 columns:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Course Name</span>: The title of the course.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">University</span>: The institution offering the course.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Difficulty Level</span>: The level of complexity of the course content.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Rating</span>: The average rating given by learners.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">URL</span>: The web address where the course can be accessed.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i6.p1">
<p class="ltx_p" id="S3.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i6.p1.1.1">Description</span>: A brief overview of what the course covers.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i7.p1">
<p class="ltx_p" id="S3.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i7.p1.1.1">Skills</span>: The specific abilities or knowledge areas that the course aims to develop.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Recommendation System Design</h3>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Prompt Design</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">The “cold start” problem, where systems lack user historical data, is a significant challenge in recommendation systems. Both traditional course recommender algorithums like content-based and collaborative-filtering algorithms and LLM-based system recommendation systems struggle with this issue. However, our RAG-based solution addresses this by using a ‘prompt template’ in the back-end. This template guides RAMO to generate relevant responses even when no user-specific data is available, as detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.T1" title="Table 1 ‣ 3.2.1 Prompt Design ‣ 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>. The RAMO system can provide meaningful recommendations from the outset, unlike non-RAG-based recommender systems, which lack a retrieval process and prompt-based customization. The prompt to our retriever (i.e., to retrieve the relevant docs from the databases) is called the ‘prompt template’, which is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.T1" title="Table 1 ‣ 3.2.1 Prompt Design ‣ 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>. The prompt to our generator is composed with three parts: 1) <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.1">User Question</span>, 2) <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.2">Prompt Template</span>, and 3) <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.3">Search Results</span> (the context of the retrieved relevant documents). We also added the uplifting adverb ‘<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p1.1.4">fantastic</span>’ to the prompt template, to elevate it with Emotional Intelligence since ChatGPT is designed to recognize patterns in language, including those associated with emotions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib33" title="">33</a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overview of interaction prompt structure</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.1.1" style="width:227.6pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1.1.1">Prompt Template</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S3.T1.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.2.1.1">
<span class="ltx_p" id="S3.T1.1.2.2.1.1.1" style="width:227.6pt;"><span class="ltx_text ltx_font_italic" id="S3.T1.1.2.2.1.1.1.1">You are a fantastic Coursera course recommender. Use the following pieces of context to answer the question and recommend relevant courses to the user.
If the user doesn’t specify their requirements, you can just recommend some courses that are most popular in the system based on their ratings and difficulty levels. You only need to provide the course title to the user.
Also, please pay attention to how many courses the user wants you to recommend.
If you don’t know the answer, just say “I don’t know”.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.3.1.1">
<span class="ltx_p" id="S3.T1.1.3.3.1.1.1" style="width:227.6pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.3.1.1.1.1">Context</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" id="S3.T1.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.4.1.1">
<span class="ltx_p" id="S3.T1.1.4.4.1.1.1" style="width:227.6pt;">Retrieved course data</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.5.1.1">
<span class="ltx_p" id="S3.T1.1.5.5.1.1.1" style="width:227.6pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.5.1.1.1.1">User Question</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r" id="S3.T1.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.6.1.1">
<span class="ltx_p" id="S3.T1.1.6.6.1.1.1" style="width:227.6pt;">User’s specific question to the generator</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Integration of RAG approach</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.T2" title="Table 2 ‣ 3.2.2 Integration of RAG approach ‣ 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a> below, we employed several LLMs to build our course recommender system. We provide a list of the LLM models we used, along with details on their associated costs and token limits. The token limit refers to the maximum number of tokens (a token represents about 3/4 of a word or four characters, according to Open AI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib1" title="">1</a>]</cite>) that the model can process in a single input. While some models, like Llama 2 and Llama 3, are free to use on small-scale dataset, due to their open-source nature, others may incur costs based on usage or subscription plans <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib27" title="">27</a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Cost and token limit of models we used</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.2.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.3.1.1" style="padding-top:1pt;padding-bottom:1pt;">LLM Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.3.1.2" style="padding-top:1pt;padding-bottom:1pt;">Output Cost</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S3.T2.2.3.1.3" style="padding-top:1pt;padding-bottom:1pt;">Token Limit</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.1.2.1">GPT-3.5 Turbo</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">
<math alttext="0.50" class="ltx_Math" display="inline" id="S3.T2.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.m1.1a"><mn id="S3.T2.1.1.1.m1.1.1" xref="S3.T2.1.1.1.m1.1.1.cmml">0.50</mn><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><cn id="S3.T2.1.1.1.m1.1.1.cmml" type="float" xref="S3.T2.1.1.1.m1.1.1">0.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">0.50</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.m1.1d">0.50</annotation></semantics></math> per 1M tokens</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.1.3" style="padding-top:1pt;padding-bottom:1pt;">4,096 tokens</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.2">
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_typewriter" id="S3.T2.2.2.2.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.1" style="padding-top:1pt;padding-bottom:1pt;">
<math alttext="30.00" class="ltx_Math" display="inline" id="S3.T2.2.2.1.m1.1"><semantics id="S3.T2.2.2.1.m1.1a"><mn id="S3.T2.2.2.1.m1.1.1" xref="S3.T2.2.2.1.m1.1.1.cmml">30.00</mn><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.1.m1.1b"><cn id="S3.T2.2.2.1.m1.1.1.cmml" type="float" xref="S3.T2.2.2.1.m1.1.1">30.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.1.m1.1c">30.00</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.1.m1.1d">30.00</annotation></semantics></math> per 1M tokens</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.2.3" style="padding-top:1pt;padding-bottom:1pt;">8,192 tokens</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.4.1">
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.1.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_typewriter" id="S3.T2.2.4.1.1.1">Llama-2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.4.1.2" style="padding-top:1pt;padding-bottom:1pt;">Free</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.4.1.3" style="padding-top:1pt;padding-bottom:1pt;">4,096 tokens</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.5.2">
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.2.5.2.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_typewriter" id="S3.T2.2.5.2.1.1">Llama-3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.2.5.2.2" style="padding-top:1pt;padding-bottom:1pt;">Free</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T2.2.5.2.3" style="padding-top:1pt;padding-bottom:1pt;">8,000 tokens</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S3.F2.2">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S3.F2.1">Workflow of the RAG facilitated course recommendation system we proposed
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="683" id="S3.F2.1.g1" src="extracted/5713922/diagram.jpg" width="1196"/></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Workflow for the RAMO System</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">We then leveraged the RAG approach to enhance the system’s understanding of the user context. As shown in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:_diagram_of_RAMO</span>, RAG consists of two primary components: the <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p2.1.1">retriever</span> and the <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p2.1.2">generator</span>. The retriever aims to enhance the prompt templates, which ‘augment’ the retrieval process, tailoring it to specific user queries. The knowledge base used for the retrieval process can contain any format of course data (e.g., csv, pdf, and json), providing a flexible and rich source of information for generating responses and we used the largest MOOC platform—coursera’s course dataset in csv format as the knowledge base. The dataset was transformed into text embeddings and stored in the vector database. These embeddings were then used to find high-quality, relevant information, which was incorporated into the prompt for the generator. Here we use OpenAI embedding model (<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS2.p2.1.3">text-embedding-ada-002</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib29" title="">29</a>]</cite>) to tokenize the course data and store the embeddings in vector store, considering its advantage over BERT (Bidirectional Encoder Representations from Transformers) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib7" title="">7</a>]</cite>, while OpenAI embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib29" title="">29</a>]</cite> offer better generalization and contextual understanding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib28" title="">28</a>]</cite>, making them more suitable for diverse educational content. The generator is powered by LLMs, which generate the textual contents based on the engineered prompts. To facilitate user’s interaction with the system, we make the recommendation process to be completed via conversational manner.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.1">The interface of our recommender system is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">1</span></a>, where we listed 5 default courses based on their ratings in the dataset on the web page to make it more user-friendly. As for the implementation of the system, we use <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS2.p3.1.1">GPT-3.5 Turbo</span>, selected for its robust integration with the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS2.p3.1.2">LangChain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib32" title="">32</a>]</cite> framework—a platform designed to streamline the implementation of language models in application-specific contexts. This setup allows the system to dynamically retrieve relevant documents and generate responses tailored to user inputs, as illustrated in the workflow in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S3.F2" title="Figure 2 ‣ 3.2.2 Integration of RAG approach ‣ 3.2 Recommendation System Design ‣ 3 Method ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Comparative Analysis</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">To evaluate the performance of our system, we conducted a series of tests by providing different prompts representing various user needs to RAMO. This allowed us to explore its ability to deliver course recommendations based on the outputs generated in response to varied user prompts.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p2.1.1">LLM vs. Non-LLM.</span> We explored both the relevance of the recommended courses to the user’s interests and responding time (the time it takes to generate a response) of the LLM-based recommender system compared to non-LLM course recommender systems (e.g., course recommender system using collaborative filtering and content-based approaches), focusing particularly on their ability to address the “<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS3.p2.1.2">cold start</span>” problem. This problem occurs when the user lacks specific requirements on what skills they want to learn, and the system lacks data on the new user.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS3.p3.1.1">LLM vs. LLM with RAG.</span> We further examined the performance of a standard LLM recommender system (without RAG and without using a dataset as a knowledge base) versus an RAG-enhanced LLM recommender system by testing different prompt templates for the retriever and various user queries for the generator to ascertain improvements in system performance and recommendation personalization.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p4">
<p class="ltx_p" id="S3.SS2.SSS3.p4.1">To explore the performance of our course recommender system, we focused on comparing the relevance of the recommended courses to different prompts by varying prompt templates and user-specific requirements.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>LLM vs. Non-LLM</h3>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S4.F3.2">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S4.F3.1">LLM output Vs Rag-Based Output for New User who want to learn something on coursera
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="483" id="S4.F3.1.g1" src="extracted/5713922/cold_start_compare.png" width="1196"/></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Sample output for a cold-start question on LLM vs RAG-LLM system</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We compared RAMO with a traditional course recommendation system built by the content-based and collaborative filtering using the same dataset<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.kaggle.com/code/sagarbapodara/coursera-course-recommendation-system-webapp</span></span></span></span>. During this comparison, we focused on the “<span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">cold start</span>” problem. The “<span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">cold start</span>” problem is especially pertinent in the context of an e-learning platform for tutor training, such as tutor training platform <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib24" title="">24</a>]</cite>. When new tutors join the platform, they are encouraged to complete various training courses to enhance their tutoring skills. Given the wide range of courses available, new tutors may feel overwhelmed when deciding where to begin their learning journey. In such scenarios, they may ask general questions such as, “<span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">What can I learn today since I am a new tutor onboarding to this platform?</span>” They do not have prior course completions or specific learning preferences logged in the system, making it challenging for the recommendation system to personalize suggestions based on historical data. When prompted with “<span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.4">I am a new user</span>”, the traditional recommender system failed to generate a recommendation because its algorithm relies on the cosine similarity of the descriptive texts of the user’s desired learning topic and the database items, and there are no courses with similar title or description as the phrase ‘<span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.5">new user</span>’. In contrast, both our standard LLM and the RAG-enhanced LLM system can provide relevant course suggestions for the new user, with the LLM offering more detailed descriptions based on its internal knowledge base and RAG offering more customized outputs based on its external knowledge base and the prompt template we designed. The comparative results for both the standard and RAG-based recommender systems are displayed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.F3" title="Figure 3 ‣ 4.1 LLM vs. Non-LLM ‣ 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Regarding system performance, the traditional system typically took about 0.02 seconds longer than RAMO to generate responses according to the same user interest—a certain topic the user wants to learn, and this delay increased with the complexity of the user’s input regarding relevant skills.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>LLM vs. LLM with RAG</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To explore how well our LLMs can provide personalized course recommendations, we used prompts that specified a particular skill to be learned. The non-RAG LLM (based on GPT-3.5) delivered detailed suggestions for relevant courses available on Coursera, utilizing its internal database of courses. In contrast, the recommendations from the RAG-enhanced LLM varied according to the specific prompt template used by the retriever. This adaptability allows developers to tailor the quantity and detail of the courses recommended, showcasing the flexibility of the RAG approach. The user interface and the outcomes for a query focused on learning a specific skill are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.F4" title="Figure 4 ‣ 4.2 LLM vs. LLM with RAG ‣ 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S4.F4.2">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S4.F4.1">User Entry and the Output part of the system we developed
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="628" id="S4.F4.1.g1" src="extracted/5713922/specific_q.png" width="598"/></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Output for a specific user question</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We modified the retrieval prompts and generation queries to test the adaptability of our recommendation system. First, we conducted tests on various user queries using the same prompt template to compare the variations in output. The first module in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.F5" title="Figure 5 ‣ 4.2 LLM vs. LLM with RAG ‣ 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the system’s response to a “<span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">cold start</span>” problem, while modules 2 through 6 demonstrate how the output varies based on user questions about the number of courses recommended and the level of detail provided, such as reasons for recommendations, URLs, and other specifics. For example, when user asks question like “<span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">I want to learn python, can you recommend me some courses?</span>”, RAMO can give the output to the user: “<span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.3">Sure! Here are some recommended Python courses for you:
1. Introduction to Python
2. Crash Course on Python
3. First Python Program
4. Python Basics
These courses cover a range of topics from basic syntax to building interactive applications. Happy learning!</span>” When the user changes their mind and decides to learn about another topic, RAMO can give relevant recommendations. The outputs consistently matched the user requirements in relevance, successfully retrieving the pertinent courses from the Coursera dataset, more examples could be found at Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.F5" title="Figure 5 ‣ 4.2 LLM vs. LLM with RAG ‣ 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S4.F5.2">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S4.F5.1">Different User Questions and Responses of the Generator  <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1027" id="S4.F5.1.g1" src="extracted/5713922/question_change.png" width="586"/>
</p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>User questions and related outputs</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_figure_panel undefined" id="S4.F6.2">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S4.F6.1">Different Prompt Templates and Responses of the Generator  <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1083" id="S4.F6.1.g1" src="extracted/5713922/template_change.png" width="586"/></p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Prompt templates and related outputs</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">We also utilized different retrieval prompt templates to explore how the output varies based on different prompts. Specifically, we used the same user question “<span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.1">I want to learn python</span>”, and altered the prompt templates to specify the number of recommended courses and the level of detail provided in the output, ranging from mere course titles to comprehensive descriptions that include titles, URLs, and rationales for each recommendation. The variations in the prompt templates and their corresponding outputs are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.F6" title="Figure 6 ‣ 4.2 LLM vs. LLM with RAG ‣ 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">6</span></a>. Here, red lines highlight changes in the number of courses recommended, blue lines detail the content of the courses—such as the inclusion of reasons for recommendations or just the course titles, ratings, and URLs—while green highlights how we addressed the “<span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.2">cold-start</span>” problem, resulting in recommendations of the three most popular (based on course ratings) and easiest courses (based on its difficulty level), as depicted in the output module labeled 1 in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#S4.F6" title="Figure 6 ‣ 4.2 LLM vs. LLM with RAG ‣ 4 Results ‣ RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations"><span class="ltx_text ltx_ref_tag">6</span></a>. The generated response in response to varied prompts underscores the system’s robustness; for instance, when the template specifies “<span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.3">recommend three courses at a time</span>”, the output consistently includes exactly three courses. Similarly, if the prompt contains ‘course URLs and titles’, the system reliably appends this information to each recommended course, ensuring that the output meticulously adheres to the specified criteria.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we have demonstrated the application of LLMs as course recommender systems, particularly within MOOCs. Our findings confirm the potential of LLMs to deliver personalized course recommendations based on user’s different requirements. We initially compared four LLMs, including GPT-3.5 Turbo and GPT-4. Ultimately, we selected GPT-3.5 as the back-end model for the RAMO system due to its comparable performance to GPT-4 at a lower cost. Although the Llama models are free to access, we found that the GPT models were significantly faster. Specifically, GPT-3.5 had an approximate response time of 3 seconds, whereas Llama 2 and Llama 3 took approximately 5 minutes and 8 minutes, respectively. Furthermore, the integration of RAG has enhanced the quality of recommendation outputs, as evidenced by the generated responses based on various user prompts, which are highly related to user’s needs and all came from the knowledge base. Additionally, our system supports conversational interaction with users, which could be seamlessly integrated into numerous online educational platforms. Our use of open-source LLMs (e.g. Llama 2 and Llama 3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.04925v1#bib.bib27" title="">27</a>]</cite>) has also been validated, proving to be a cost-effective approach for broader deployment.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Limitations
<br class="ltx_break"/></span>As this study is ongoing, we have not yet conducted comprehensive evaluations of our recommender systems, including human evaluations or user studies. This is primarily due to the nascent stage of our research. Moreover, while many research projects on recommendation systems employ benchmarks to evaluate system adaptability, our study currently lacks such benchmarks because we do not possess a test dataset. The Coursera dataset we utilized includes only course data, lacking user profiles which are essential for evaluating the effectiveness of recommender systems across different time periods. If we had access to user data, including users’ past course learning histories and their preferences, we could integrate this information with the course data to enhance our retrieval process. This integration would allow us to personalize recommendations more effectively, tailoring course suggestions to individual learning patterns and preferences. Incorporating detailed user data would enable RAMO to provide more accurate and relevant recommendations, improving user satisfaction and engagement. It would also allow for longitudinal studies to track how users’ interactions with the system evolve over time and how well the recommendations align with their long-term learning goals.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S5.p2.1.2">Future Work
<br class="ltx_break"/></span>We plan to undertake several further steps to advance our research. <span class="ltx_text ltx_font_italic" id="S5.p2.1.3">Firstly</span>, we aim to conduct thorough evaluations and tests to validate the efficacy and reliability of our recommender systems. This will involve integrating user studies and utilizing real user data once our systems are deployed on our e-learning platform. Such measures will enable us to robustly measure performance and refine our approach. <span class="ltx_text ltx_font_italic" id="S5.p2.1.4">Secondly</span>, we will focus on enhancing system performance, considering scalability and the potential to expand our technology to encompass a broader range of educational tools and platforms. These efforts will ensure that our recommender systems not only meet current educational needs but also adapt to future demands and technological advancements. <span class="ltx_text ltx_font_italic" id="S5.p2.1.5">Thirdly</span>, we could deploy RAMO on our own e-learning platform, and then have the opportunity to gather comprehensive user data and utilize our own course dataset rather than Coursera’s. This deployment would allow us to conduct extensive testing and validation, further proving the eligibility and effectiveness of the LLM for recommending courses. With access to real-time user data, we could continuously refine our algorithms, making the system more adaptive and responsive to users’ evolving needs.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">To evaluate the effectiveness of our LLM-based course recommendation system, we plan to conduct a comprehensive experiment that includes quantitative metrics, user studies, and personalization improvements. Our experiment aims to assess both the relevancy of the recommendations and the satisfaction of the users with the recommended courses.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">We will utilize several quantitative metrics to evaluate the performance of the recommendation system. Key metrics include post-test performance, measured by the improvement in students’ scores from pre-test to post-test after tutoring sessions, and course completion rate, which compares the rate of course completion between students who follow the system’s recommendations and those who do not. Additionally, engagement rate will be tracked by monitoring whether students continue engaging with the lesson without dropping out midway. User satisfaction will also be assessed through feedback collected after each lesson via a thumbs-up or thumbs-down system and detailed surveys. To gather qualitative insights into the system’s effectiveness and user experience, we will conduct user studies. These will involve satisfaction surveys completed by students following each lesson to gauge their satisfaction with the course content and the relevance of the recommendations, as well as focus group discussions to explore students’ experiences in more depth and gather suggestions for improvement.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgments</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We extend our sincere gratitude to Chenfei Lou, a current software engineer at X (former twitter), for his invaluable guidance in developing our demo. We also thank Sandy Zhao, a current master’s student in the CMU METALs program, for her excellent assistance in generating the wonderful diagram. Additionally, we appreciate Yuting Wang, an undergraduate student at CMU, for her help in refining the design in this paper.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Maximum length - netdocuments, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-07-05.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Basilico and T. Hofmann.

</span>
<span class="ltx_bibblock">Unifying collaborative and content-based filtering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Proceedings of the twenty-first international conference on Machine learning</span>, page 9, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. H. Baturay.

</span>
<span class="ltx_bibblock">An overview of the world of moocs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Procedia - Social and Behavioral Sciences</span>, 174:427–433, 2015.

</span>
<span class="ltx_bibblock">International Conference on New Horizons in Education, INTE 2014, 25-27 June 2014, Paris, France.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
N. M. Castillo, J. Lee, F. T. Zahra, and D. A. Wagner.

</span>
<span class="ltx_bibblock">Moocs for development: Trends, challenges, and opportunities.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Information Technologies &amp; International Development</span>, 11(2):pp–35, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
W. Dai, J. Lin, H. Jin, T. Li, Y.-S. Tsai, D. Gašević, and G. Chen.

</span>
<span class="ltx_bibblock">Can large language models provide feedback to students? a case study on chatgpt.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">2023 IEEE International Conference on Advanced Learning Technologies (ICALT)</span>, pages 323–325. IEEE, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
W. Dai, Y.-S. Tsai, J. Lin, A. Aldino, F. Jin, T. Li, D. Gasevic, et al.

</span>
<span class="ltx_bibblock">Assessing the proficiency of large language models in automatic feedback generation: An evaluation study.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</span>, pages 4171–4186, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin.

</span>
<span class="ltx_bibblock">Retrieval-generation synergy augmented large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 11661–11665. IEEE, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang.

</span>
<span class="ltx_bibblock">Chat-rec: Towards interactive and explainable llms-augmented recommender system, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2312.10997</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Z. Gulzar, A. A. Leema, and G. Deepak.

</span>
<span class="ltx_bibblock">Pcrs: Personalized course recommender system based on hybrid approach.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Procedia Computer Science</span>, 125:518–524, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Hasan.

</span>
<span class="ltx_bibblock">How does chatgpt generate human-like text?, November 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. E. Huber, K. Kiili, S. Nebel, R. M. Ryan, M. Sailer, and M. Ninaus.

</span>
<span class="ltx_bibblock">Leveraging the potential of large language models in education through playful and game-based learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Educational Psychology Review</span>, 36(1):25, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
S. Jacobs and S. Jaschke.

</span>
<span class="ltx_bibblock">Leveraging lecture content for improved feedback: Explorations with gpt-4 and retrieval augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2405.06681</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Jeevamol and V. Renumol.

</span>
<span class="ltx_bibblock">An ontology-based hybrid e-learning content recommender system for alleviating the cold-start problem.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Education and Information Technologies</span>, 26:4993–5022, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. R. Kabir and F. Lin.

</span>
<span class="ltx_bibblock">An llm-powered adaptive practicing system.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">AIED 2023 workshop on Empowering Education with LLMs-the Next-Gen Interface and Content Generation, AIED</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Knox.

</span>
<span class="ltx_bibblock">Digital culture clash:“massive” education in the e-learning and digital cultures mooc.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Distance Education</span>, 35(2):164–177, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
T. E. Kolb, A. Wagne, M. Sertkan, and J. Neidhardt.

</span>
<span class="ltx_bibblock">Potentials of combining local knowledge and llms for recommender systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1"># PLACEHOLDER_PARENT_METADATA_VALUE#</span>, volume 3560, pages 61–64. CEUR-WS. org, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y. Koren, S. Rendle, and R. Bell.

</span>
<span class="ltx_bibblock">Advances in collaborative filtering.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">Recommender systems handbook</span>, pages 91–142, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Z. Levonian, C. Li, W. Zhu, A. Gade, O. Henkel, M.-E. Postle, and W. Xing.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation to improve math question-answering: Trade-offs between groundedness and human preference.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2310.03184</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Li, W. Zhang, T. Wang, G. Xiong, A. Lu, and G. Medioni.

</span>
<span class="ltx_bibblock">Gpt4rec: A generative framework for personalized recommendation and user interests interpretation, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Lin, A. Gurung, D. R. Thomas, E. Chen, C. Borchers, S. Gupta, K. R. Koedinger, et al.

</span>
<span class="ltx_bibblock">Improving assessment of tutoring practices using retrieval-augmented generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2402.14594</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J. Lin, Z. Han, D. R. Thomas, A. Gurung, S. Gupta, V. Aleven, and K. R. Koedinger.

</span>
<span class="ltx_bibblock">How can i get it right? using gpt to rephrase incorrect trainee responses.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2405.00970</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. Lin, D. R. Thomas, Z. Han, W. Tan, N. D. Nguyen, S. Gupta, E. Gatz, C. Tipper, and K. R. Koedinger.

</span>
<span class="ltx_bibblock">Personalized learning squared (plus): Doubling math learning through ai-assisted tutoring.

</span>
<span class="ltx_bibblock">2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y. Lu, Y. Fang, and C. Shi.

</span>
<span class="ltx_bibblock">Meta-learning on heterogeneous information networks for cold-start recommendation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining</span>, pages 1563–1573, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
H. Lyu, S. Jiang, H. Zeng, Y. Xia, Q. Wang, S. Zhang, R. Chen, C. Leung, J. Tang, and J. Luo.

</span>
<span class="ltx_bibblock">Llm-rec: Personalized recommendation via prompting large language models, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Meta.

</span>
<span class="ltx_bibblock">Llama: Large language model meta ai, July 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
B. Moradiya.

</span>
<span class="ltx_bibblock">The battle of language models: Openai vs. bert, October 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">New and improved embedding model, July 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
C. Romero and S. Ventura.

</span>
<span class="ltx_bibblock">Educational data mining: a review of the state of the art.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">IEEE Transactions on Systems, Man, and Cybernetics, Part C (applications and reviews)</span>, 40(6):601–618, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J. B. Schafer, D. Frankowski, J. Herlocker, and S. Sen.

</span>
<span class="ltx_bibblock">Collaborative filtering recommender systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">The adaptive web: methods and strategies of web personalization</span>, pages 291–324. Springer, 2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
O. Topsakal and T. C. Akinci.

</span>
<span class="ltx_bibblock">Creating large language model applications utilizing langchain: A primer on developing llm apps fast.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">International Conference on Applied Engineering and Natural Sciences</span>, volume 1, pages 1050–1056, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
R. Vinay, G. Spitale, N. Biller-Andorno, and F. Germani.

</span>
<span class="ltx_bibblock">Emotional manipulation through prompt engineering amplifies disinformation generation in ai large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2403.03550</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Wang, T. Xu, H. Li, C. Zhang, J. Liang, J. Tang, P. S. Yu, and Q. Wen.

</span>
<span class="ltx_bibblock">Large language models for education: A survey and outlook.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2403.18105</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
X. Wu, H. Zhou, Y. Shi, W. Yao, X. Huang, and N. Liu.

</span>
<span class="ltx_bibblock">Could small language models serve as recommenders? towards data-centric cold-start recommendation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Proceedings of the ACM on Web Conference 2024</span>, pages 3566–3575, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
ZDNet.

</span>
<span class="ltx_bibblock">What is chatgpt and why does it matter? here’s everything you need to know, July 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
L. Zhang, J. Lin, C. Borchers, M. Cao, and X. Hu.

</span>
<span class="ltx_bibblock">3dg: A framework for using generative ai for handling sparse learner performance data from intelligent tutoring systems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2402.01746</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
L. Zhang, J. Lin, C. Borchers, J. Sabatini, J. Hollander, M. Cao, and X. Hu.

</span>
<span class="ltx_bibblock">Predicting learning performance with large language models: A study in adult literacy.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2403.14668</span>, 2024.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>DATASET WE USE</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">The 2021 coursera dataset we use is available at <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.kaggle.com/datasets/khusheekapoor/coursera-courses-dataset-2021</span>.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Link of the RAG system code</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">The code could be run at:<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://colab.research.google.com/drive/1wLwM5QphDoIctW9_EZt26D6RIpSmfaCD?usp=sharing</span>, including the data preprocessing and the RAG process.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Link of the Chatbot DEMO</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">The demo of the chatbot could be accessed at:<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/spaces/dinosaur-organization/coursera-recommendation#/</span>, you need to first obtain your Openai Api and enter it on the left side.</p>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Link of the Medium Blog inspired us of the demo design</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">We got inspired by a blog published on medium on the designing of a book recommendation chatbot, the article is available at:<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://medium.com/data-and-beyond/data-science-and-machine-learning-books-recommendation-chatbot-83757cbb92f7#/</span></p>
</div>
<div class="ltx_para" id="A4.p2">
<span class="ltx_ERROR undefined" id="A4.p2.1">\balancecolumns</span>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Jul  6 02:18:01 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
