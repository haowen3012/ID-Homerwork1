<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Corrective Retrieval Augmented Generation</title>
<!--Generated on Mon Oct  7 02:17:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2401.15884v3/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S1" title="In Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S2" title="In Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S2.SS0.SSS0.Px1" title="In 2 Related Work â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Hallucinations of LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S2.SS0.SSS0.Px2" title="In 2 Related Work â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Retrieval-Augmented Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S2.SS0.SSS0.Px3" title="In 2 Related Work â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Advanced RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S3" title="In Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Task Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4" title="In Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span><span class="ltx_text ltx_font_smallcaps">CRAG</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS1" title="In 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Overview of Model Inference</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS2" title="In 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Retrieval Evaluator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS3" title="In 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Action Trigger</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS3.SSS0.Px1" title="In 4.3 Action Trigger â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Correct</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS3.SSS0.Px2" title="In 4.3 Action Trigger â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Incorrect</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS3.SSS0.Px3" title="In 4.3 Action Trigger â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Ambiguous</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS3.SSS0.Px4" title="In 4.3 Action Trigger â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">Discussion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS4" title="In 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Knowledge Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS5" title="In 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Web Search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5" title="In Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS1" title="In 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Tasks, Datasets and Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS2" title="In 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Baselines</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS3" title="In 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS4" title="In 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS4.SSS0.Px1" title="In 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">The impact of each triggered action.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS4.SSS0.Px2" title="In 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title">The impact of each knowledge utilization operation.</span></a>
<ol class="ltx_toclist ltx_toclist_paragraph">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS5" title="In The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Accuracy of the Retrieval Evaluator</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS6" title="In 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span>Robustness to Retrieval Performance</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS7" title="In 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.7 </span>Consistent Supplementation of Web Search Knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS8" title="In 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.8 </span>Computational Overhead Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S6" title="In 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion &amp; Limitation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1" title="In 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Task Prompts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2" title="In 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS1" title="In Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Tasks, Datasets and Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS2" title="In Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Experiments compute Resources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS3" title="In Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS4" title="In Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.4 </span>More Detailed Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS5" title="In Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.5 </span>Results on PubHealth and Arc-Challenge</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Corrective Retrieval Augmented Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Shi-Qi Yan<sup class="ltx_sup" id="id8.8.id1">1</sup>, Jia-Chen Gu<sup class="ltx_sup" id="id9.9.id2">2</sup><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>, Yun Zhu<sup class="ltx_sup" id="id10.10.id3">3</sup>, Zhen-Hua Ling<sup class="ltx_sup" id="id11.11.id4">1</sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id12.12.id5">1</sup>National Engineering Research Center of Speech and Language Information Processing, 
<br class="ltx_break"/>University of Science and Technology of China, Hefei, China 
<br class="ltx_break"/><sup class="ltx_sup" id="id13.13.id6">2</sup>Department of Computer Science, University of California, Los Angeles 
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id7">3</sup>Google DeepMind 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id15.15.id8">yansiki@mail.ustc.edu.cn</span>, <span class="ltx_text ltx_font_typewriter" id="id16.16.id9">gujc@ucla.edu</span>, <span class="ltx_text ltx_font_typewriter" id="id17.17.id10">yunzhu@google.com</span>, <span class="ltx_text ltx_font_typewriter" id="id18.18.id11">zhling@ustc.edu.cn</span>
</span><span class="ltx_author_notes">â€†Equal contribution.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id19.id1">Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate.
Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong.
To this end, we propose the <span class="ltx_text ltx_font_bold" id="id19.id1.1">C</span>orrective <span class="ltx_text ltx_font_bold" id="id19.id1.2">R</span>etrieval <span class="ltx_text ltx_font_bold" id="id19.id1.3">A</span>ugmented <span class="ltx_text ltx_font_bold" id="id19.id1.4">G</span>eneration (<span class="ltx_text ltx_font_smallcaps" id="id19.id1.5">CRAG</span>) to improve the robustness of generation.
Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered.
Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results.
Besides, a decompose-then-recompose algorithm is designed for retrieved documents to selectively focus on key information and filter out irrelevant information in them.
<span class="ltx_text ltx_font_smallcaps" id="id19.id1.6">CRAG</span> is plug-and-play and can be seamlessly coupled with various RAG-based approaches.
Experiments on four datasets covering short- and long-form generation tasks show that <span class="ltx_text ltx_font_smallcaps" id="id19.id1.7">CRAG</span> can significantly improve the performance of RAG-based approaches. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The code is available at <a class="ltx_ref ltx_href" href="https://github.com/HuskyInSalt/CRAG" title="">github.com/HuskyInSalt/CRAG</a></span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.7">
<p class="ltx_p" id="p1.7.8"><span class="ltx_text ltx_font_bold" id="p1.7.8.1">Corrective Retrieval Augmented Generation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.7.7" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.7.7.7" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.7.7.7.7">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.4.4.4.4.4">
<span class="ltx_td ltx_align_center" id="p1.4.4.4.4.4.4"><span class="ltx_text ltx_font_bold" id="p1.4.4.4.4.4.4.4">
Shi-Qi Yan<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.1"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.1.1">1</span></sup><span class="ltx_note ltx_role_thanks" id="p1.4.4.4.4.4.4.4.2"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>â€†Equal contribution.</span></span></span>, Jia-Chen Gu<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.3"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.3.1">2</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex2.1.1.1">1</span></span></span></span></span>, Yun Zhu<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.4"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.4.1">3</span></sup>, Zhen-Hua Ling<sup class="ltx_sup" id="p1.4.4.4.4.4.4.4.5"><span class="ltx_text ltx_font_medium" id="p1.4.4.4.4.4.4.4.5.1">1</span></sup></span></span></span>
<span class="ltx_tr" id="p1.5.5.5.5.5">
<span class="ltx_td ltx_align_center" id="p1.5.5.5.5.5.1"><sup class="ltx_sup" id="p1.5.5.5.5.5.1.1">1</sup>National Engineering Research Center of Speech and Language Information Processing,</span></span>
<span class="ltx_tr" id="p1.7.7.7.7.8.1">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.8.1.1">University of Science and Technology of China, Hefei, China</span></span>
<span class="ltx_tr" id="p1.6.6.6.6.6">
<span class="ltx_td ltx_align_center" id="p1.6.6.6.6.6.1"><sup class="ltx_sup" id="p1.6.6.6.6.6.1.1">2</sup>Department of Computer Science, University of California, Los Angeles</span></span>
<span class="ltx_tr" id="p1.7.7.7.7.7">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.7.1"><sup class="ltx_sup" id="p1.7.7.7.7.7.1.1">3</sup>Google DeepMind</span></span>
<span class="ltx_tr" id="p1.7.7.7.7.9.2">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.9.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.7.7.7.7.9.2.1.1">yansiki@mail.ustc.edu.cn</span>, <span class="ltx_text ltx_font_typewriter" id="p1.7.7.7.7.9.2.1.2">gujc@ucla.edu</span>, <span class="ltx_text ltx_font_typewriter" id="p1.7.7.7.7.9.2.1.3">yunzhu@google.com</span>, <span class="ltx_text ltx_font_typewriter" id="p1.7.7.7.7.9.2.1.4">zhling@ustc.edu.cn</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) have attracted increasing attention and exhibited impressive abilities to understand instructions and generate fluent language textsÂ <cite class="ltx_cite ltx_citemacro_citep">(Brown etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib5" title="">2020</a>; Ouyang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib24" title="">2022</a>; Touvron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib34" title="">2023a</a>)</cite>.
Nevertheless, LLMs inevitably manifest hallucinationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ji etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib11" title="">2023</a>)</cite> due to their struggle with factual errorsÂ <cite class="ltx_cite ltx_citemacro_citep">(Mallen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib19" title="">2023</a>; Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib20" title="">2023</a>)</cite> and inability to secure the accuracy of generated texts solely by the parametric knowledge they encapsulateÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib40" title="">2023b</a>; Muhlgay etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib21" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="445" id="S1.F1.g1" src="x1.png" width="398"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
The examples show that a low-quality retriever is prone to introducing a substantial amount of irrelevant information, impeding the generators from acquiring accurate knowledge and potentially misleading them.
</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Prior research has introduced the retrieval techniques to incorporate the knowledge relevant to input and augment generation, as exemplified by retrieval-augmented generation (RAG)Â <cite class="ltx_cite ltx_citemacro_citep">(Lewis etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib15" title="">2020</a>)</cite>.
In this framework, the input to models is augmented by prepending relevant documents that are retrieved from an external knowledge corpusÂ <cite class="ltx_cite ltx_citemacro_citep">(Guu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib9" title="">2020</a>)</cite>.
While RAG serves as a practicable complement to LLMs, its effectiveness is contingent upon the relevance and accuracy of the retrieved documentsÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib16" title="">2022</a>; Tan etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib32" title="">2022</a>)</cite>.
The heavy reliance of generation on the retrieved knowledge raises significant concerns about the modelâ€™s behavior and performance in scenarios where retrieval may fail or return inaccurate resultsÂ <cite class="ltx_cite ltx_citemacro_citep">(Shi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib30" title="">2023</a>)</cite>.
As FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a> shows that a low-quality retriever is prone to introducing a substantial amount of irrelevant information, impeding the models from acquiring accurate knowledge and potentially misleading them, resulting in issues such as hallucinationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib40" title="">2023b</a>)</cite>.
However, most conventional RAG approaches indiscriminately incorporate the retrieved documents, regardless of whether these documents are relevant or notÂ <cite class="ltx_cite ltx_citemacro_citep">(Rony etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib28" title="">2022</a>)</cite>.
Furthermore, current methods mostly treat complete documents as reference knowledge both during retrieval and utilization.
But a considerable portion of the text within these retrieved documents is often non-essential for generation, which should not have been equally referred to and involved in RAG.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">On account of the above issues, this paper particularly studies the scenarios where the retriever returns inaccurate results.
A method named <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">C</span>orrective <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">R</span>etrieval-<span class="ltx_text ltx_font_bold" id="S1.p3.1.3">A</span>ugmented <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">G</span>eneration (<span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.5">CRAG</span>) is proposed to self-correct the results of retriever and improve the utilization of documents for augmenting generation.
A lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query.
This serves as a crucial component in RAG, contributing to informative generation by reviewing and evaluating the relevance and reliability of the retrieved documents.
A confidence degree is quantified based on which different knowledge retrieval actions of {<span class="ltx_text ltx_font_typewriter" id="S1.p3.1.6">Correct</span>, <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.7">Incorrect</span>, <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.8">Ambiguous</span>} can be triggered.
For the latter two actions, large-scale web searchesÂ <cite class="ltx_cite ltx_citemacro_citep">(Piktus etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib25" title="">2021</a>; Komeili etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib14" title="">2022</a>)</cite> are integrated as a strategic extension, since retrieval from static and limited corpora can only return sub-optimal documents in terms of scope and diversity.
This augmentation is implemented to broaden the spectrum of retrieved information, harnessing the expansive and dynamic nature of the web to complement and enrich the initially obtained documents.
Furthermore, to eliminate redundant contexts contained in retrieved documents that are unhelpful for RAG, a decompose-then-recompose algorithm is meticulously crafted throughout the retrieval and utilization process.
This algorithm ensures the refinement of retrieved information, optimizing the extraction of key insights and minimizing the inclusion of non-essential elements, thereby enhancing the utilization of retrieved data.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">CRAG</span> is plug-and-play and experimentally implemented into RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Lewis etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib15" title="">2020</a>)</cite> and Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> for demonstrating its adaptability to RAG-based approaches.
Results on four datasets of PopQAÂ <cite class="ltx_cite ltx_citemacro_citep">(Mallen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib19" title="">2023</a>)</cite>, BiographyÂ <cite class="ltx_cite ltx_citemacro_citep">(Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib20" title="">2023</a>)</cite>, Pub HealthÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib38" title="">2023a</a>)</cite>, and Arc-ChallengeÂ <cite class="ltx_cite ltx_citemacro_citep">(Bhakthavatsalam etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib4" title="">2021</a>)</cite> show that <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">CRAG</span> can significantly improve the performance of standard RAG and state-of-the-art Self-RAG, demonstrating its generalizability across both short- and long-form generation tasks.
To facilitate others to reproduce our results, we will publish all source code later.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In summary, our contributions in this paper are three-fold:
1) This paper studies the scenarios where the retriever returns inaccurate results and, to the best of our knowledge, makes the first attempt to design corrective strategies for RAG to improve its robustness.
2) A plug-and-play method named <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.1">CRAG</span> is proposed to improve the ability of automatic self-correction and efficient utilization of retrieved documents.
3) Experimental results extensively demonstrate <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.2">CRAG</span>â€™s adaptability to RAG-based approaches and its generalizability across short- and long-form generation tasks.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Hallucinations of LLMs</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Although LLMs have exhibited impressive abilities to understand instructions and generate fluent language textsÂ <cite class="ltx_cite ltx_citemacro_citep">(Bang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib3" title="">2023</a>; Qin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib26" title="">2023</a>; Zhong etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib41" title="">2023</a>)</cite>, one of the most severe issues that LLMs have still been struggling with is hallucinations.
As many studies found <cite class="ltx_cite ltx_citemacro_citep">(Tonmoy etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib33" title="">2024</a>; Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib40" title="">2023b</a>; Shuster etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib31" title="">2021</a>)</cite>, either outdated information or incorrect knowledge that is activated would seriously result in hallucinations.
Large-scale unregulated training data collection, low proportion of high-quality sampling data, imperfection of data allocation in the input space, and many other realistic factors could impact the LLMs and exacerbate the problems.
Thus, it is obvious that the lack of accurate and specific knowledge can lead to misleading or even inaccurate generation, which will severely hurt the experience of users in most practical applications.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Retrieval-Augmented Generation</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Lewis etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib15" title="">2020</a>; Guu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib9" title="">2020</a>)</cite> is regarded as a useful method to address the issues above, which enhances the input questions of generative LMs with retrieved documents.
It usually provides an extra knowledge source from a specific corpus, i.e., Wikipedia, which greatly improves the performance of LMs in a variety of tasks, especially in the knowledge-intensive ones.
The proposed methods generally leverage information retrieval to supply documents containing relevant knowledge for generative LLMs.
Earlier studies adopt either sparse or dense retrievers at the front end of a pre-trained language model that specializes in response generation.
Despite this, the methods above usually ignore a question, <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.1">what if the retrieval goes wrong?</em>
Since the purpose of introducing a retrieval is to secure that generative LMs can obtain relevant and accurate knowledge.
If retrieved documents are irrelevant, the retrieval system can even exacerbate the factual error that LMs make.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Advanced RAG</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Many advanced approaches have been developed from the original RAG in recent years Â <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib39" title="">2024</a>; Kim etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib13" title="">2024</a>; Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib36" title="">2024</a>; Liu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib17" title="">2024</a>)</cite>.
Considering that retrieval is sometimes unnecessary for some queries, conversely, responses without retrieval are even more accurate in many situations.
Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> is proposed to selectively retrieve knowledge and introduce a critic model to decide whether to retrieve.
<cite class="ltx_cite ltx_citemacro_citet">Yoran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib37" title="">2024</a>)</cite> designed an NLI model to identify the irrelevant context and improve robustness.
SAIL <cite class="ltx_cite ltx_citemacro_citep">(Luo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib18" title="">2023</a>)</cite> is tuned on instructions to insert retrieved documents before instructions.
While ToolformerÂ <cite class="ltx_cite ltx_citemacro_citep">(Schick etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib29" title="">2023</a>)</cite> is pre-trained for calling APIs such as Wikipedia.
In addition, in some long-text generation tasks, external knowledge is needed more than once, and when to retrieve should be concerned.
<cite class="ltx_cite ltx_citemacro_citet">Jiang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib12" title="">2023</a>)</cite> actively anticipate future content and decide when and what to retrieve in long-form generation.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">Compared with recent studiesÂ <cite class="ltx_cite ltx_citemacro_citep">(Schick etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib29" title="">2023</a>; Luo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib18" title="">2023</a>; Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> that are the most relevant to our work, a main difference should be highlighted.
These approaches target on exploiting retrieval as a useful tool to augment generation or whether retrieval is necessary, while this study particularly studies the scenarios where the retriever returns inaccurate results.
To the best of our knowledge, this paper makes the first attempt to explore and design corrective strategies for RAG to improve its robustness of generation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Task Formulation</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.14">Following previous workÂ <cite class="ltx_cite ltx_citemacro_citep">(Lewis etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib15" title="">2020</a>; Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite>, given input <math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">caligraphic_X</annotation></semantics></math> and an accessible corpus containing a large amount of knowledge documents <math alttext="\mathcal{C}=\{d_{1},...,d_{N}\}" class="ltx_Math" display="inline" id="S3.p1.2.m2.3"><semantics id="S3.p1.2.m2.3a"><mrow id="S3.p1.2.m2.3.3" xref="S3.p1.2.m2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.3.3.4" xref="S3.p1.2.m2.3.3.4.cmml">ğ’</mi><mo id="S3.p1.2.m2.3.3.3" xref="S3.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S3.p1.2.m2.3.3.2.2" xref="S3.p1.2.m2.3.3.2.3.cmml"><mo id="S3.p1.2.m2.3.3.2.2.3" stretchy="false" xref="S3.p1.2.m2.3.3.2.3.cmml">{</mo><msub id="S3.p1.2.m2.2.2.1.1.1" xref="S3.p1.2.m2.2.2.1.1.1.cmml"><mi id="S3.p1.2.m2.2.2.1.1.1.2" xref="S3.p1.2.m2.2.2.1.1.1.2.cmml">d</mi><mn id="S3.p1.2.m2.2.2.1.1.1.3" xref="S3.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p1.2.m2.3.3.2.2.4" xref="S3.p1.2.m2.3.3.2.3.cmml">,</mo><mi id="S3.p1.2.m2.1.1" mathvariant="normal" xref="S3.p1.2.m2.1.1.cmml">â€¦</mi><mo id="S3.p1.2.m2.3.3.2.2.5" xref="S3.p1.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.p1.2.m2.3.3.2.2.2" xref="S3.p1.2.m2.3.3.2.2.2.cmml"><mi id="S3.p1.2.m2.3.3.2.2.2.2" xref="S3.p1.2.m2.3.3.2.2.2.2.cmml">d</mi><mi id="S3.p1.2.m2.3.3.2.2.2.3" xref="S3.p1.2.m2.3.3.2.2.2.3.cmml">N</mi></msub><mo id="S3.p1.2.m2.3.3.2.2.6" stretchy="false" xref="S3.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.3b"><apply id="S3.p1.2.m2.3.3.cmml" xref="S3.p1.2.m2.3.3"><eq id="S3.p1.2.m2.3.3.3.cmml" xref="S3.p1.2.m2.3.3.3"></eq><ci id="S3.p1.2.m2.3.3.4.cmml" xref="S3.p1.2.m2.3.3.4">ğ’</ci><set id="S3.p1.2.m2.3.3.2.3.cmml" xref="S3.p1.2.m2.3.3.2.2"><apply id="S3.p1.2.m2.2.2.1.1.1.cmml" xref="S3.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.p1.2.m2.2.2.1.1.1.2">ğ‘‘</ci><cn id="S3.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.p1.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">â€¦</ci><apply id="S3.p1.2.m2.3.3.2.2.2.cmml" xref="S3.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.p1.2.m2.3.3.2.2.2.2">ğ‘‘</ci><ci id="S3.p1.2.m2.3.3.2.2.2.3.cmml" xref="S3.p1.2.m2.3.3.2.2.2.3">ğ‘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.3c">\mathcal{C}=\{d_{1},...,d_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.3d">caligraphic_C = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math>, the system is expected to generate the output <math alttext="\mathcal{Y}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">ğ’´</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ğ’´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">caligraphic_Y</annotation></semantics></math>.
The entire framework is usually divided into a retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">â„›</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">â„›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">caligraphic_R</annotation></semantics></math> and a generator <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="S3.p1.5.m5.1"><semantics id="S3.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">ğ’¢</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ğ’¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.5.m5.1d">caligraphic_G</annotation></semantics></math>.
The retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S3.p1.6.m6.1"><semantics id="S3.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">â„›</mi><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">â„›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.6.m6.1d">caligraphic_R</annotation></semantics></math> aims to retrieve the top-<math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S3.p1.7.m7.1"><semantics id="S3.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.7.m7.1d">caligraphic_K</annotation></semantics></math> documents <math alttext="\mathcal{D}=\{d_{r_{1}},...,d_{r_{k}}\}" class="ltx_Math" display="inline" id="S3.p1.8.m8.3"><semantics id="S3.p1.8.m8.3a"><mrow id="S3.p1.8.m8.3.3" xref="S3.p1.8.m8.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.3.3.4" xref="S3.p1.8.m8.3.3.4.cmml">ğ’Ÿ</mi><mo id="S3.p1.8.m8.3.3.3" xref="S3.p1.8.m8.3.3.3.cmml">=</mo><mrow id="S3.p1.8.m8.3.3.2.2" xref="S3.p1.8.m8.3.3.2.3.cmml"><mo id="S3.p1.8.m8.3.3.2.2.3" stretchy="false" xref="S3.p1.8.m8.3.3.2.3.cmml">{</mo><msub id="S3.p1.8.m8.2.2.1.1.1" xref="S3.p1.8.m8.2.2.1.1.1.cmml"><mi id="S3.p1.8.m8.2.2.1.1.1.2" xref="S3.p1.8.m8.2.2.1.1.1.2.cmml">d</mi><msub id="S3.p1.8.m8.2.2.1.1.1.3" xref="S3.p1.8.m8.2.2.1.1.1.3.cmml"><mi id="S3.p1.8.m8.2.2.1.1.1.3.2" xref="S3.p1.8.m8.2.2.1.1.1.3.2.cmml">r</mi><mn id="S3.p1.8.m8.2.2.1.1.1.3.3" xref="S3.p1.8.m8.2.2.1.1.1.3.3.cmml">1</mn></msub></msub><mo id="S3.p1.8.m8.3.3.2.2.4" xref="S3.p1.8.m8.3.3.2.3.cmml">,</mo><mi id="S3.p1.8.m8.1.1" mathvariant="normal" xref="S3.p1.8.m8.1.1.cmml">â€¦</mi><mo id="S3.p1.8.m8.3.3.2.2.5" xref="S3.p1.8.m8.3.3.2.3.cmml">,</mo><msub id="S3.p1.8.m8.3.3.2.2.2" xref="S3.p1.8.m8.3.3.2.2.2.cmml"><mi id="S3.p1.8.m8.3.3.2.2.2.2" xref="S3.p1.8.m8.3.3.2.2.2.2.cmml">d</mi><msub id="S3.p1.8.m8.3.3.2.2.2.3" xref="S3.p1.8.m8.3.3.2.2.2.3.cmml"><mi id="S3.p1.8.m8.3.3.2.2.2.3.2" xref="S3.p1.8.m8.3.3.2.2.2.3.2.cmml">r</mi><mi id="S3.p1.8.m8.3.3.2.2.2.3.3" xref="S3.p1.8.m8.3.3.2.2.2.3.3.cmml">k</mi></msub></msub><mo id="S3.p1.8.m8.3.3.2.2.6" stretchy="false" xref="S3.p1.8.m8.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.3b"><apply id="S3.p1.8.m8.3.3.cmml" xref="S3.p1.8.m8.3.3"><eq id="S3.p1.8.m8.3.3.3.cmml" xref="S3.p1.8.m8.3.3.3"></eq><ci id="S3.p1.8.m8.3.3.4.cmml" xref="S3.p1.8.m8.3.3.4">ğ’Ÿ</ci><set id="S3.p1.8.m8.3.3.2.3.cmml" xref="S3.p1.8.m8.3.3.2.2"><apply id="S3.p1.8.m8.2.2.1.1.1.cmml" xref="S3.p1.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.1.1.1.1.cmml" xref="S3.p1.8.m8.2.2.1.1.1">subscript</csymbol><ci id="S3.p1.8.m8.2.2.1.1.1.2.cmml" xref="S3.p1.8.m8.2.2.1.1.1.2">ğ‘‘</ci><apply id="S3.p1.8.m8.2.2.1.1.1.3.cmml" xref="S3.p1.8.m8.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.1.1.1.3.1.cmml" xref="S3.p1.8.m8.2.2.1.1.1.3">subscript</csymbol><ci id="S3.p1.8.m8.2.2.1.1.1.3.2.cmml" xref="S3.p1.8.m8.2.2.1.1.1.3.2">ğ‘Ÿ</ci><cn id="S3.p1.8.m8.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.p1.8.m8.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">â€¦</ci><apply id="S3.p1.8.m8.3.3.2.2.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.8.m8.3.3.2.2.2.1.cmml" xref="S3.p1.8.m8.3.3.2.2.2">subscript</csymbol><ci id="S3.p1.8.m8.3.3.2.2.2.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2.2">ğ‘‘</ci><apply id="S3.p1.8.m8.3.3.2.2.2.3.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.p1.8.m8.3.3.2.2.2.3.1.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3">subscript</csymbol><ci id="S3.p1.8.m8.3.3.2.2.2.3.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.p1.8.m8.3.3.2.2.2.3.3.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3.3">ğ‘˜</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.3c">\mathcal{D}=\{d_{r_{1}},...,d_{r_{k}}\}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.8.m8.3d">caligraphic_D = { italic_d start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , â€¦ , italic_d start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math> that are relevant to the input <math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S3.p1.9.m9.1"><semantics id="S3.p1.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.9.m9.1d">caligraphic_X</annotation></semantics></math> from the corpus <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S3.p1.10.m10.1"><semantics id="S3.p1.10.m10.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.10.m10.1.1" xref="S3.p1.10.m10.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><ci id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.10.m10.1d">caligraphic_C</annotation></semantics></math>.
Based on the input <math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S3.p1.11.m11.1"><semantics id="S3.p1.11.m11.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.11.m11.1.1" xref="S3.p1.11.m11.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.p1.11.m11.1b"><ci id="S3.p1.11.m11.1.1.cmml" xref="S3.p1.11.m11.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.11.m11.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.11.m11.1d">caligraphic_X</annotation></semantics></math> and the retrieved results <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.p1.12.m12.1"><semantics id="S3.p1.12.m12.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.12.m12.1.1" xref="S3.p1.12.m12.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.p1.12.m12.1b"><ci id="S3.p1.12.m12.1.1.cmml" xref="S3.p1.12.m12.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.12.m12.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.12.m12.1d">caligraphic_D</annotation></semantics></math>, the generator <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="S3.p1.13.m13.1"><semantics id="S3.p1.13.m13.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.13.m13.1.1" xref="S3.p1.13.m13.1.1.cmml">ğ’¢</mi><annotation-xml encoding="MathML-Content" id="S3.p1.13.m13.1b"><ci id="S3.p1.13.m13.1.1.cmml" xref="S3.p1.13.m13.1.1">ğ’¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.13.m13.1c">\mathcal{G}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.13.m13.1d">caligraphic_G</annotation></semantics></math> is responsible for generating the output <math alttext="\mathcal{Y}" class="ltx_Math" display="inline" id="S3.p1.14.m14.1"><semantics id="S3.p1.14.m14.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.14.m14.1.1" xref="S3.p1.14.m14.1.1.cmml">ğ’´</mi><annotation-xml encoding="MathML-Content" id="S3.p1.14.m14.1b"><ci id="S3.p1.14.m14.1.1.cmml" xref="S3.p1.14.m14.1.1">ğ’´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.14.m14.1c">\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.14.m14.1d">caligraphic_Y</annotation></semantics></math>.
This framework can be formulated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(\mathcal{Y}|\mathcal{X})=P(\mathcal{D}|\mathcal{X})P(\mathcal{Y},\mathcal{D}%
|\mathcal{X})." class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml">P</mi><mo id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">ğ’´</mi><mo fence="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml">ğ’³</mi></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.4" xref="S3.E1.m1.2.2.1.1.4.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.3.4" xref="S3.E1.m1.2.2.1.1.3.4.cmml">P</mi><mo id="S3.E1.m1.2.2.1.1.3.3" xref="S3.E1.m1.2.2.1.1.3.3.cmml">â¢</mo><mrow id="S3.E1.m1.2.2.1.1.2.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.2.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.2.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.1.2.cmml">ğ’Ÿ</mi><mo fence="false" id="S3.E1.m1.2.2.1.1.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.1.3.cmml">ğ’³</mi></mrow><mo id="S3.E1.m1.2.2.1.1.2.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.2.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m1.2.2.1.1.3.3a" xref="S3.E1.m1.2.2.1.1.3.3.cmml">â¢</mo><mi id="S3.E1.m1.2.2.1.1.3.5" xref="S3.E1.m1.2.2.1.1.3.5.cmml">P</mi><mo id="S3.E1.m1.2.2.1.1.3.3b" xref="S3.E1.m1.2.2.1.1.3.3.cmml">â¢</mo><mrow id="S3.E1.m1.2.2.1.1.3.2.1" xref="S3.E1.m1.2.2.1.1.3.2.2.cmml"><mo id="S3.E1.m1.2.2.1.1.3.2.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.3.2.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ğ’´</mi><mo id="S3.E1.m1.2.2.1.1.3.2.1.3" xref="S3.E1.m1.2.2.1.1.3.2.2.cmml">,</mo><mrow id="S3.E1.m1.2.2.1.1.3.2.1.1" xref="S3.E1.m1.2.2.1.1.3.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.3.2.1.1.2" xref="S3.E1.m1.2.2.1.1.3.2.1.1.2.cmml">ğ’Ÿ</mi><mo fence="false" id="S3.E1.m1.2.2.1.1.3.2.1.1.1" xref="S3.E1.m1.2.2.1.1.3.2.1.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.3.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.2.1.1.3.cmml">ğ’³</mi></mrow><mo id="S3.E1.m1.2.2.1.1.3.2.1.4" stretchy="false" xref="S3.E1.m1.2.2.1.1.3.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" lspace="0em" xref="S3.E1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.4"></eq><apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.2"></times><ci id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3">ğ‘ƒ</ci><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2">ğ’´</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3">ğ’³</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3"><times id="S3.E1.m1.2.2.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.3.3"></times><ci id="S3.E1.m1.2.2.1.1.3.4.cmml" xref="S3.E1.m1.2.2.1.1.3.4">ğ‘ƒ</ci><apply id="S3.E1.m1.2.2.1.1.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.1">conditional</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.2">ğ’Ÿ</ci><ci id="S3.E1.m1.2.2.1.1.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1.3">ğ’³</ci></apply><ci id="S3.E1.m1.2.2.1.1.3.5.cmml" xref="S3.E1.m1.2.2.1.1.3.5">ğ‘ƒ</ci><interval closure="open" id="S3.E1.m1.2.2.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ’´</ci><apply id="S3.E1.m1.2.2.1.1.3.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.3.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.1.1">conditional</csymbol><ci id="S3.E1.m1.2.2.1.1.3.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.1.2">ğ’Ÿ</ci><ci id="S3.E1.m1.2.2.1.1.3.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3.2.1.1.3">ğ’³</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">P(\mathcal{Y}|\mathcal{X})=P(\mathcal{D}|\mathcal{X})P(\mathcal{Y},\mathcal{D}%
|\mathcal{X}).</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">italic_P ( caligraphic_Y | caligraphic_X ) = italic_P ( caligraphic_D | caligraphic_X ) italic_P ( caligraphic_Y , caligraphic_D | caligraphic_X ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.p1.15">It shows that the retriever and generator are seamlessly coupled, exhibiting low risk tolerance.
Any unsuccessful retrieval can result in an unsatisfactory response, regardless of the impressive abilities of the generator.
This is exactly the focus of this paper to improve the robustness of generation.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="599" id="S3.F2.g1" src="x2.png" width="813"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
An overview of the proposed <span class="ltx_text ltx_font_smallcaps" id="S3.F2.5.1">CRAG</span> at inference. A retrieval evaluator is constructed to evaluate the relevance of the retrieved documents to the input, and estimate a confidence degree based on which different knowledge retrieval actions of {<span class="ltx_text ltx_font_typewriter" id="S3.F2.6.2">Correct</span>, <span class="ltx_text ltx_font_typewriter" id="S3.F2.7.3">Incorrect</span>, <span class="ltx_text ltx_font_typewriter" id="S3.F2.8.4">Ambiguous</span>} can be triggered.
</figcaption>
</figure>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">CRAG</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Overview of Model Inference</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S3.F2" title="Figure 2 â€£ 3 Task Formulation â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a> and Algorithm 1 present an overview of <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.1">CRAG</span> at inference, which designs corrective strategies to improve the robustness of generation.
Given an input query and the retrieved documents from any retriever, a lightweight retrieval evaluator is constructed to estimate the relevance score of retrieved documents to the input query (SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS2" title="4.2 Retrieval Evaluator â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.2</span></a>).
The relevance score is quantified into a total of three confidence degrees and then triggered the corresponding actions: {<span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.2">Correct</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.3">Incorrect</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.4">Ambiguous</span>} (SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS3" title="4.3 Action Trigger â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
If the action <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.5">Correct</span> is triggered, the retrieved documents will be refined into more precise knowledge strips. This refinement operation involves knowledge decomposition, filter, and recomposition (SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS4" title="4.4 Knowledge Refinement â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.4</span></a>).
If the action <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.6">Incorrect</span> is triggered, the retrieved documents will be discarded. Instead, web searches are resorted to and regarded as complementary knowledge sources for corrections (SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS5" title="4.5 Web Search â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.5</span></a>).
Eventually, when it cannot confidently make a correct or incorrect judgment, a soft and balanced action <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.7">Ambiguous</span> which combines both of them is triggered.
After optimizing the retrieval results, an arbitrary generative model can be adopted.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Retrieval Evaluator</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">It is natural to wonder whether the retrieved documents are accurate or not before using them, which is significant since irrelevant or misleading messages can be identified in this way.
The accuracy of the retrieval evaluator undeniably plays a pivotal role in shaping the overall system performance, as it influences the outcomes of subsequent processes.
Our objective is to correct the retrieved documents if they are irrelevant.
Specifically, T5-largeÂ <cite class="ltx_cite ltx_citemacro_citep">(Raffel etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib27" title="">2020</a>)</cite> is adopted for initializing the retrieval evaluator and fine-tuned.
Its parameter size is much smaller than the most current LLMsÂ <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib34" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib35" title="">b</a>; Chowdhery etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib6" title="">2023</a>; Anil etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib1" title="">2023</a>; Brown etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib5" title="">2020</a>; Ouyang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib24" title="">2022</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib23" title="">2023</a>)</cite>.
To ensure all experimental results were comparable with Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite>, the same retrieval results through ContrieverÂ <cite class="ltx_cite ltx_citemacro_citep">(Izacard etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib10" title="">2022</a>)</cite> provided by Self-RAG were also adopted in our experiments.
The relevance signals for fine-tuning the evaluator can be collected from the existing datasets.
For example, PopQAÂ <cite class="ltx_cite ltx_citemacro_citep">(Mallen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib19" title="">2023</a>)</cite> provides the golden subject wiki title from wikipedia for each question. We can use that to track a not 100% relevant but rather high-quality passage. We utilized that as the relevance signals for fine-tuning the retrieval evaluator.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://huggingface.co/datasets/akariasai/PopQA</span></span></span>
On the other hand, the negative samples for fine-tuning were all randomly sampled from the retrieval results, which are rather similar to the input query but not relevant.
More details about this fine-tuning step can be referred to in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS3" title="B.3 Implementation Details â€£ Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">B.3</span></a>.
For every question, there are generally 10 documents retrieved.
The question is concatenated with each single document as the input, and the evaluator predicts the relevance score for each question-document pair individually.
We also tried to prompt ChatGPT to identify the retrieval relevance for comparison, but it underperforms as elaborated in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.SS5" title="5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">5.5</span></a>.
Based on these calculated relevance scores, a final judgment is made as to whether the retrieval is correct or not associated with the action trigger.
In our proposed framework, the retrieval quality is evaluated at a relatively low cost without the need to have access to large and expensive LLMs.
Compared with the critic model of Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> that instruction-tuned LLaMA-2 (7B), the evaluator designed in <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p1.1.1">CRAG</span> demonstrates the advantages of being quite lightweight (0.77B).</p>
</div>
<figure class="ltx_float ltx_algorithm" id="algorithm1">
<div class="ltx_listing ltx_lst_numbers_left ltx_listing" id="algorithm1.27">
<div class="ltx_listingline" id="algorithm1.3.3">
<span class="ltx_text ltx_font_bold" id="algorithm1.3.3.1">Require :</span>Â <math alttext="E" class="ltx_Math" display="inline" id="algorithm1.1.1.m1.1"><semantics id="algorithm1.1.1.m1.1a"><mi id="algorithm1.1.1.m1.1.1" xref="algorithm1.1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.1b"><ci id="algorithm1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.m1.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.1c">E</annotation><annotation encoding="application/x-llamapun" id="algorithm1.1.1.m1.1d">italic_E</annotation></semantics></math> (Retrieval Evaluator), <math alttext="W" class="ltx_Math" display="inline" id="algorithm1.2.2.m2.1"><semantics id="algorithm1.2.2.m2.1a"><mi id="algorithm1.2.2.m2.1.1" xref="algorithm1.2.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.m2.1b"><ci id="algorithm1.2.2.m2.1.1.cmml" xref="algorithm1.2.2.m2.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.m2.1c">W</annotation><annotation encoding="application/x-llamapun" id="algorithm1.2.2.m2.1d">italic_W</annotation></semantics></math> (Query Rewriter), <math alttext="G" class="ltx_Math" display="inline" id="algorithm1.3.3.m3.1"><semantics id="algorithm1.3.3.m3.1a"><mi id="algorithm1.3.3.m3.1.1" xref="algorithm1.3.3.m3.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.m3.1b"><ci id="algorithm1.3.3.m3.1.1.cmml" xref="algorithm1.3.3.m3.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.m3.1c">G</annotation><annotation encoding="application/x-llamapun" id="algorithm1.3.3.m3.1d">italic_G</annotation></semantics></math> (Generator)
</div>
<div class="ltx_listingline" id="algorithm1.5.5">
<span class="ltx_text ltx_font_bold" id="algorithm1.5.5.1">Input :</span>Â <math alttext="x" class="ltx_Math" display="inline" id="algorithm1.4.4.m1.1"><semantics id="algorithm1.4.4.m1.1a"><mi id="algorithm1.4.4.m1.1.1" xref="algorithm1.4.4.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.m1.1b"><ci id="algorithm1.4.4.m1.1.1.cmml" xref="algorithm1.4.4.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.4.4.m1.1d">italic_x</annotation></semantics></math> (Input question), <math alttext="D=\{d_{1},d_{2},...,d_{k}\}" class="ltx_Math" display="inline" id="algorithm1.5.5.m2.4"><semantics id="algorithm1.5.5.m2.4a"><mrow id="algorithm1.5.5.m2.4.4" xref="algorithm1.5.5.m2.4.4.cmml"><mi id="algorithm1.5.5.m2.4.4.5" xref="algorithm1.5.5.m2.4.4.5.cmml">D</mi><mo id="algorithm1.5.5.m2.4.4.4" xref="algorithm1.5.5.m2.4.4.4.cmml">=</mo><mrow id="algorithm1.5.5.m2.4.4.3.3" xref="algorithm1.5.5.m2.4.4.3.4.cmml"><mo id="algorithm1.5.5.m2.4.4.3.3.4" stretchy="false" xref="algorithm1.5.5.m2.4.4.3.4.cmml">{</mo><msub id="algorithm1.5.5.m2.2.2.1.1.1" xref="algorithm1.5.5.m2.2.2.1.1.1.cmml"><mi id="algorithm1.5.5.m2.2.2.1.1.1.2" xref="algorithm1.5.5.m2.2.2.1.1.1.2.cmml">d</mi><mn id="algorithm1.5.5.m2.2.2.1.1.1.3" xref="algorithm1.5.5.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="algorithm1.5.5.m2.4.4.3.3.5" xref="algorithm1.5.5.m2.4.4.3.4.cmml">,</mo><msub id="algorithm1.5.5.m2.3.3.2.2.2" xref="algorithm1.5.5.m2.3.3.2.2.2.cmml"><mi id="algorithm1.5.5.m2.3.3.2.2.2.2" xref="algorithm1.5.5.m2.3.3.2.2.2.2.cmml">d</mi><mn id="algorithm1.5.5.m2.3.3.2.2.2.3" xref="algorithm1.5.5.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="algorithm1.5.5.m2.4.4.3.3.6" xref="algorithm1.5.5.m2.4.4.3.4.cmml">,</mo><mi id="algorithm1.5.5.m2.1.1" mathvariant="normal" xref="algorithm1.5.5.m2.1.1.cmml">â€¦</mi><mo id="algorithm1.5.5.m2.4.4.3.3.7" xref="algorithm1.5.5.m2.4.4.3.4.cmml">,</mo><msub id="algorithm1.5.5.m2.4.4.3.3.3" xref="algorithm1.5.5.m2.4.4.3.3.3.cmml"><mi id="algorithm1.5.5.m2.4.4.3.3.3.2" xref="algorithm1.5.5.m2.4.4.3.3.3.2.cmml">d</mi><mi id="algorithm1.5.5.m2.4.4.3.3.3.3" xref="algorithm1.5.5.m2.4.4.3.3.3.3.cmml">k</mi></msub><mo id="algorithm1.5.5.m2.4.4.3.3.8" stretchy="false" xref="algorithm1.5.5.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.m2.4b"><apply id="algorithm1.5.5.m2.4.4.cmml" xref="algorithm1.5.5.m2.4.4"><eq id="algorithm1.5.5.m2.4.4.4.cmml" xref="algorithm1.5.5.m2.4.4.4"></eq><ci id="algorithm1.5.5.m2.4.4.5.cmml" xref="algorithm1.5.5.m2.4.4.5">ğ·</ci><set id="algorithm1.5.5.m2.4.4.3.4.cmml" xref="algorithm1.5.5.m2.4.4.3.3"><apply id="algorithm1.5.5.m2.2.2.1.1.1.cmml" xref="algorithm1.5.5.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="algorithm1.5.5.m2.2.2.1.1.1.1.cmml" xref="algorithm1.5.5.m2.2.2.1.1.1">subscript</csymbol><ci id="algorithm1.5.5.m2.2.2.1.1.1.2.cmml" xref="algorithm1.5.5.m2.2.2.1.1.1.2">ğ‘‘</ci><cn id="algorithm1.5.5.m2.2.2.1.1.1.3.cmml" type="integer" xref="algorithm1.5.5.m2.2.2.1.1.1.3">1</cn></apply><apply id="algorithm1.5.5.m2.3.3.2.2.2.cmml" xref="algorithm1.5.5.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="algorithm1.5.5.m2.3.3.2.2.2.1.cmml" xref="algorithm1.5.5.m2.3.3.2.2.2">subscript</csymbol><ci id="algorithm1.5.5.m2.3.3.2.2.2.2.cmml" xref="algorithm1.5.5.m2.3.3.2.2.2.2">ğ‘‘</ci><cn id="algorithm1.5.5.m2.3.3.2.2.2.3.cmml" type="integer" xref="algorithm1.5.5.m2.3.3.2.2.2.3">2</cn></apply><ci id="algorithm1.5.5.m2.1.1.cmml" xref="algorithm1.5.5.m2.1.1">â€¦</ci><apply id="algorithm1.5.5.m2.4.4.3.3.3.cmml" xref="algorithm1.5.5.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="algorithm1.5.5.m2.4.4.3.3.3.1.cmml" xref="algorithm1.5.5.m2.4.4.3.3.3">subscript</csymbol><ci id="algorithm1.5.5.m2.4.4.3.3.3.2.cmml" xref="algorithm1.5.5.m2.4.4.3.3.3.2">ğ‘‘</ci><ci id="algorithm1.5.5.m2.4.4.3.3.3.3.cmml" xref="algorithm1.5.5.m2.4.4.3.3.3.3">ğ‘˜</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.m2.4c">D=\{d_{1},d_{2},...,d_{k}\}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.5.5.m2.4d">italic_D = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math> (Retrieved documents)
</div>
<div class="ltx_listingline" id="algorithm1.6.6">
<span class="ltx_text ltx_font_bold" id="algorithm1.6.6.1">Output :</span>Â <math alttext="y" class="ltx_Math" display="inline" id="algorithm1.6.6.m1.1"><semantics id="algorithm1.6.6.m1.1a"><mi id="algorithm1.6.6.m1.1.1" xref="algorithm1.6.6.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.m1.1b"><ci id="algorithm1.6.6.m1.1.1.cmml" xref="algorithm1.6.6.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="algorithm1.6.6.m1.1d">italic_y</annotation></semantics></math> (Generated response)
</div>
<div class="ltx_listingline" id="algorithm1.11.11">
<span class="ltx_tag ltx_tag_listingline">1</span>
<math alttext="score_{i}" class="ltx_Math" display="inline" id="algorithm1.7.7.m1.1"><semantics id="algorithm1.7.7.m1.1a"><mrow id="algorithm1.7.7.m1.1.1" xref="algorithm1.7.7.m1.1.1.cmml"><mi id="algorithm1.7.7.m1.1.1.2" xref="algorithm1.7.7.m1.1.1.2.cmml">s</mi><mo id="algorithm1.7.7.m1.1.1.1" xref="algorithm1.7.7.m1.1.1.1.cmml">â¢</mo><mi id="algorithm1.7.7.m1.1.1.3" xref="algorithm1.7.7.m1.1.1.3.cmml">c</mi><mo id="algorithm1.7.7.m1.1.1.1a" xref="algorithm1.7.7.m1.1.1.1.cmml">â¢</mo><mi id="algorithm1.7.7.m1.1.1.4" xref="algorithm1.7.7.m1.1.1.4.cmml">o</mi><mo id="algorithm1.7.7.m1.1.1.1b" xref="algorithm1.7.7.m1.1.1.1.cmml">â¢</mo><mi id="algorithm1.7.7.m1.1.1.5" xref="algorithm1.7.7.m1.1.1.5.cmml">r</mi><mo id="algorithm1.7.7.m1.1.1.1c" xref="algorithm1.7.7.m1.1.1.1.cmml">â¢</mo><msub id="algorithm1.7.7.m1.1.1.6" xref="algorithm1.7.7.m1.1.1.6.cmml"><mi id="algorithm1.7.7.m1.1.1.6.2" xref="algorithm1.7.7.m1.1.1.6.2.cmml">e</mi><mi id="algorithm1.7.7.m1.1.1.6.3" xref="algorithm1.7.7.m1.1.1.6.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m1.1b"><apply id="algorithm1.7.7.m1.1.1.cmml" xref="algorithm1.7.7.m1.1.1"><times id="algorithm1.7.7.m1.1.1.1.cmml" xref="algorithm1.7.7.m1.1.1.1"></times><ci id="algorithm1.7.7.m1.1.1.2.cmml" xref="algorithm1.7.7.m1.1.1.2">ğ‘ </ci><ci id="algorithm1.7.7.m1.1.1.3.cmml" xref="algorithm1.7.7.m1.1.1.3">ğ‘</ci><ci id="algorithm1.7.7.m1.1.1.4.cmml" xref="algorithm1.7.7.m1.1.1.4">ğ‘œ</ci><ci id="algorithm1.7.7.m1.1.1.5.cmml" xref="algorithm1.7.7.m1.1.1.5">ğ‘Ÿ</ci><apply id="algorithm1.7.7.m1.1.1.6.cmml" xref="algorithm1.7.7.m1.1.1.6"><csymbol cd="ambiguous" id="algorithm1.7.7.m1.1.1.6.1.cmml" xref="algorithm1.7.7.m1.1.1.6">subscript</csymbol><ci id="algorithm1.7.7.m1.1.1.6.2.cmml" xref="algorithm1.7.7.m1.1.1.6.2">ğ‘’</ci><ci id="algorithm1.7.7.m1.1.1.6.3.cmml" xref="algorithm1.7.7.m1.1.1.6.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m1.1c">score_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.7.7.m1.1d">italic_s italic_c italic_o italic_r italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> = <math alttext="E" class="ltx_Math" display="inline" id="algorithm1.8.8.m2.1"><semantics id="algorithm1.8.8.m2.1a"><mi id="algorithm1.8.8.m2.1.1" xref="algorithm1.8.8.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m2.1b"><ci id="algorithm1.8.8.m2.1.1.cmml" xref="algorithm1.8.8.m2.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m2.1c">E</annotation><annotation encoding="application/x-llamapun" id="algorithm1.8.8.m2.1d">italic_E</annotation></semantics></math> evaluates the relevance of each pair (<math alttext="x" class="ltx_Math" display="inline" id="algorithm1.9.9.m3.1"><semantics id="algorithm1.9.9.m3.1a"><mi id="algorithm1.9.9.m3.1.1" xref="algorithm1.9.9.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.m3.1b"><ci id="algorithm1.9.9.m3.1.1.cmml" xref="algorithm1.9.9.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.9.9.m3.1d">italic_x</annotation></semantics></math>, <math alttext="d_{i}" class="ltx_Math" display="inline" id="algorithm1.10.10.m4.1"><semantics id="algorithm1.10.10.m4.1a"><msub id="algorithm1.10.10.m4.1.1" xref="algorithm1.10.10.m4.1.1.cmml"><mi id="algorithm1.10.10.m4.1.1.2" xref="algorithm1.10.10.m4.1.1.2.cmml">d</mi><mi id="algorithm1.10.10.m4.1.1.3" xref="algorithm1.10.10.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.m4.1b"><apply id="algorithm1.10.10.m4.1.1.cmml" xref="algorithm1.10.10.m4.1.1"><csymbol cd="ambiguous" id="algorithm1.10.10.m4.1.1.1.cmml" xref="algorithm1.10.10.m4.1.1">subscript</csymbol><ci id="algorithm1.10.10.m4.1.1.2.cmml" xref="algorithm1.10.10.m4.1.1.2">ğ‘‘</ci><ci id="algorithm1.10.10.m4.1.1.3.cmml" xref="algorithm1.10.10.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.m4.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.10.10.m4.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>), <math alttext="d_{i}\in D" class="ltx_Math" display="inline" id="algorithm1.11.11.m5.1"><semantics id="algorithm1.11.11.m5.1a"><mrow id="algorithm1.11.11.m5.1.1" xref="algorithm1.11.11.m5.1.1.cmml"><msub id="algorithm1.11.11.m5.1.1.2" xref="algorithm1.11.11.m5.1.1.2.cmml"><mi id="algorithm1.11.11.m5.1.1.2.2" xref="algorithm1.11.11.m5.1.1.2.2.cmml">d</mi><mi id="algorithm1.11.11.m5.1.1.2.3" xref="algorithm1.11.11.m5.1.1.2.3.cmml">i</mi></msub><mo id="algorithm1.11.11.m5.1.1.1" xref="algorithm1.11.11.m5.1.1.1.cmml">âˆˆ</mo><mi id="algorithm1.11.11.m5.1.1.3" xref="algorithm1.11.11.m5.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.m5.1b"><apply id="algorithm1.11.11.m5.1.1.cmml" xref="algorithm1.11.11.m5.1.1"><in id="algorithm1.11.11.m5.1.1.1.cmml" xref="algorithm1.11.11.m5.1.1.1"></in><apply id="algorithm1.11.11.m5.1.1.2.cmml" xref="algorithm1.11.11.m5.1.1.2"><csymbol cd="ambiguous" id="algorithm1.11.11.m5.1.1.2.1.cmml" xref="algorithm1.11.11.m5.1.1.2">subscript</csymbol><ci id="algorithm1.11.11.m5.1.1.2.2.cmml" xref="algorithm1.11.11.m5.1.1.2.2">ğ‘‘</ci><ci id="algorithm1.11.11.m5.1.1.2.3.cmml" xref="algorithm1.11.11.m5.1.1.2.3">ğ‘–</ci></apply><ci id="algorithm1.11.11.m5.1.1.3.cmml" xref="algorithm1.11.11.m5.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.m5.1c">d_{i}\in D</annotation><annotation encoding="application/x-llamapun" id="algorithm1.11.11.m5.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_D</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="algorithm1.12.12">
<span class="ltx_tag ltx_tag_listingline">2</span>
<span class="ltx_text ltx_font_bold" id="algorithm1.12.12.1">Confidence</span> = Calculate and give a final judgment based on {<math alttext="score_{1},score_{2},...score_{k}" class="ltx_Math" display="inline" id="algorithm1.12.12.m1.3"><semantics id="algorithm1.12.12.m1.3a"><mrow id="algorithm1.12.12.m1.3.3.3" xref="algorithm1.12.12.m1.3.3.4.cmml"><mrow id="algorithm1.12.12.m1.1.1.1.1" xref="algorithm1.12.12.m1.1.1.1.1.cmml"><mi id="algorithm1.12.12.m1.1.1.1.1.2" xref="algorithm1.12.12.m1.1.1.1.1.2.cmml">s</mi><mo id="algorithm1.12.12.m1.1.1.1.1.1" xref="algorithm1.12.12.m1.1.1.1.1.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.1.1.1.1.3" xref="algorithm1.12.12.m1.1.1.1.1.3.cmml">c</mi><mo id="algorithm1.12.12.m1.1.1.1.1.1a" xref="algorithm1.12.12.m1.1.1.1.1.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.1.1.1.1.4" xref="algorithm1.12.12.m1.1.1.1.1.4.cmml">o</mi><mo id="algorithm1.12.12.m1.1.1.1.1.1b" xref="algorithm1.12.12.m1.1.1.1.1.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.1.1.1.1.5" xref="algorithm1.12.12.m1.1.1.1.1.5.cmml">r</mi><mo id="algorithm1.12.12.m1.1.1.1.1.1c" xref="algorithm1.12.12.m1.1.1.1.1.1.cmml">â¢</mo><msub id="algorithm1.12.12.m1.1.1.1.1.6" xref="algorithm1.12.12.m1.1.1.1.1.6.cmml"><mi id="algorithm1.12.12.m1.1.1.1.1.6.2" xref="algorithm1.12.12.m1.1.1.1.1.6.2.cmml">e</mi><mn id="algorithm1.12.12.m1.1.1.1.1.6.3" xref="algorithm1.12.12.m1.1.1.1.1.6.3.cmml">1</mn></msub></mrow><mo id="algorithm1.12.12.m1.3.3.3.4" xref="algorithm1.12.12.m1.3.3.4.cmml">,</mo><mrow id="algorithm1.12.12.m1.2.2.2.2" xref="algorithm1.12.12.m1.2.2.2.2.cmml"><mi id="algorithm1.12.12.m1.2.2.2.2.2" xref="algorithm1.12.12.m1.2.2.2.2.2.cmml">s</mi><mo id="algorithm1.12.12.m1.2.2.2.2.1" xref="algorithm1.12.12.m1.2.2.2.2.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.2.2.2.2.3" xref="algorithm1.12.12.m1.2.2.2.2.3.cmml">c</mi><mo id="algorithm1.12.12.m1.2.2.2.2.1a" xref="algorithm1.12.12.m1.2.2.2.2.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.2.2.2.2.4" xref="algorithm1.12.12.m1.2.2.2.2.4.cmml">o</mi><mo id="algorithm1.12.12.m1.2.2.2.2.1b" xref="algorithm1.12.12.m1.2.2.2.2.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.2.2.2.2.5" xref="algorithm1.12.12.m1.2.2.2.2.5.cmml">r</mi><mo id="algorithm1.12.12.m1.2.2.2.2.1c" xref="algorithm1.12.12.m1.2.2.2.2.1.cmml">â¢</mo><msub id="algorithm1.12.12.m1.2.2.2.2.6" xref="algorithm1.12.12.m1.2.2.2.2.6.cmml"><mi id="algorithm1.12.12.m1.2.2.2.2.6.2" xref="algorithm1.12.12.m1.2.2.2.2.6.2.cmml">e</mi><mn id="algorithm1.12.12.m1.2.2.2.2.6.3" xref="algorithm1.12.12.m1.2.2.2.2.6.3.cmml">2</mn></msub></mrow><mo id="algorithm1.12.12.m1.3.3.3.5" xref="algorithm1.12.12.m1.3.3.4.cmml">,</mo><mrow id="algorithm1.12.12.m1.3.3.3.3" xref="algorithm1.12.12.m1.3.3.3.3.cmml"><mi id="algorithm1.12.12.m1.3.3.3.3.2" mathvariant="normal" xref="algorithm1.12.12.m1.3.3.3.3.2.cmml">â€¦</mi><mo id="algorithm1.12.12.m1.3.3.3.3.1" xref="algorithm1.12.12.m1.3.3.3.3.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.3.3.3.3.3" xref="algorithm1.12.12.m1.3.3.3.3.3.cmml">s</mi><mo id="algorithm1.12.12.m1.3.3.3.3.1a" xref="algorithm1.12.12.m1.3.3.3.3.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.3.3.3.3.4" xref="algorithm1.12.12.m1.3.3.3.3.4.cmml">c</mi><mo id="algorithm1.12.12.m1.3.3.3.3.1b" xref="algorithm1.12.12.m1.3.3.3.3.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.3.3.3.3.5" xref="algorithm1.12.12.m1.3.3.3.3.5.cmml">o</mi><mo id="algorithm1.12.12.m1.3.3.3.3.1c" xref="algorithm1.12.12.m1.3.3.3.3.1.cmml">â¢</mo><mi id="algorithm1.12.12.m1.3.3.3.3.6" xref="algorithm1.12.12.m1.3.3.3.3.6.cmml">r</mi><mo id="algorithm1.12.12.m1.3.3.3.3.1d" xref="algorithm1.12.12.m1.3.3.3.3.1.cmml">â¢</mo><msub id="algorithm1.12.12.m1.3.3.3.3.7" xref="algorithm1.12.12.m1.3.3.3.3.7.cmml"><mi id="algorithm1.12.12.m1.3.3.3.3.7.2" xref="algorithm1.12.12.m1.3.3.3.3.7.2.cmml">e</mi><mi id="algorithm1.12.12.m1.3.3.3.3.7.3" xref="algorithm1.12.12.m1.3.3.3.3.7.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.m1.3b"><list id="algorithm1.12.12.m1.3.3.4.cmml" xref="algorithm1.12.12.m1.3.3.3"><apply id="algorithm1.12.12.m1.1.1.1.1.cmml" xref="algorithm1.12.12.m1.1.1.1.1"><times id="algorithm1.12.12.m1.1.1.1.1.1.cmml" xref="algorithm1.12.12.m1.1.1.1.1.1"></times><ci id="algorithm1.12.12.m1.1.1.1.1.2.cmml" xref="algorithm1.12.12.m1.1.1.1.1.2">ğ‘ </ci><ci id="algorithm1.12.12.m1.1.1.1.1.3.cmml" xref="algorithm1.12.12.m1.1.1.1.1.3">ğ‘</ci><ci id="algorithm1.12.12.m1.1.1.1.1.4.cmml" xref="algorithm1.12.12.m1.1.1.1.1.4">ğ‘œ</ci><ci id="algorithm1.12.12.m1.1.1.1.1.5.cmml" xref="algorithm1.12.12.m1.1.1.1.1.5">ğ‘Ÿ</ci><apply id="algorithm1.12.12.m1.1.1.1.1.6.cmml" xref="algorithm1.12.12.m1.1.1.1.1.6"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.1.1.1.1.6.1.cmml" xref="algorithm1.12.12.m1.1.1.1.1.6">subscript</csymbol><ci id="algorithm1.12.12.m1.1.1.1.1.6.2.cmml" xref="algorithm1.12.12.m1.1.1.1.1.6.2">ğ‘’</ci><cn id="algorithm1.12.12.m1.1.1.1.1.6.3.cmml" type="integer" xref="algorithm1.12.12.m1.1.1.1.1.6.3">1</cn></apply></apply><apply id="algorithm1.12.12.m1.2.2.2.2.cmml" xref="algorithm1.12.12.m1.2.2.2.2"><times id="algorithm1.12.12.m1.2.2.2.2.1.cmml" xref="algorithm1.12.12.m1.2.2.2.2.1"></times><ci id="algorithm1.12.12.m1.2.2.2.2.2.cmml" xref="algorithm1.12.12.m1.2.2.2.2.2">ğ‘ </ci><ci id="algorithm1.12.12.m1.2.2.2.2.3.cmml" xref="algorithm1.12.12.m1.2.2.2.2.3">ğ‘</ci><ci id="algorithm1.12.12.m1.2.2.2.2.4.cmml" xref="algorithm1.12.12.m1.2.2.2.2.4">ğ‘œ</ci><ci id="algorithm1.12.12.m1.2.2.2.2.5.cmml" xref="algorithm1.12.12.m1.2.2.2.2.5">ğ‘Ÿ</ci><apply id="algorithm1.12.12.m1.2.2.2.2.6.cmml" xref="algorithm1.12.12.m1.2.2.2.2.6"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.2.2.2.2.6.1.cmml" xref="algorithm1.12.12.m1.2.2.2.2.6">subscript</csymbol><ci id="algorithm1.12.12.m1.2.2.2.2.6.2.cmml" xref="algorithm1.12.12.m1.2.2.2.2.6.2">ğ‘’</ci><cn id="algorithm1.12.12.m1.2.2.2.2.6.3.cmml" type="integer" xref="algorithm1.12.12.m1.2.2.2.2.6.3">2</cn></apply></apply><apply id="algorithm1.12.12.m1.3.3.3.3.cmml" xref="algorithm1.12.12.m1.3.3.3.3"><times id="algorithm1.12.12.m1.3.3.3.3.1.cmml" xref="algorithm1.12.12.m1.3.3.3.3.1"></times><ci id="algorithm1.12.12.m1.3.3.3.3.2.cmml" xref="algorithm1.12.12.m1.3.3.3.3.2">â€¦</ci><ci id="algorithm1.12.12.m1.3.3.3.3.3.cmml" xref="algorithm1.12.12.m1.3.3.3.3.3">ğ‘ </ci><ci id="algorithm1.12.12.m1.3.3.3.3.4.cmml" xref="algorithm1.12.12.m1.3.3.3.3.4">ğ‘</ci><ci id="algorithm1.12.12.m1.3.3.3.3.5.cmml" xref="algorithm1.12.12.m1.3.3.3.3.5">ğ‘œ</ci><ci id="algorithm1.12.12.m1.3.3.3.3.6.cmml" xref="algorithm1.12.12.m1.3.3.3.3.6">ğ‘Ÿ</ci><apply id="algorithm1.12.12.m1.3.3.3.3.7.cmml" xref="algorithm1.12.12.m1.3.3.3.3.7"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.3.3.3.3.7.1.cmml" xref="algorithm1.12.12.m1.3.3.3.3.7">subscript</csymbol><ci id="algorithm1.12.12.m1.3.3.3.3.7.2.cmml" xref="algorithm1.12.12.m1.3.3.3.3.7.2">ğ‘’</ci><ci id="algorithm1.12.12.m1.3.3.3.3.7.3.cmml" xref="algorithm1.12.12.m1.3.3.3.3.7.3">ğ‘˜</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.m1.3c">score_{1},score_{2},...score_{k}</annotation><annotation encoding="application/x-llamapun" id="algorithm1.12.12.m1.3d">italic_s italic_c italic_o italic_r italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s italic_c italic_o italic_r italic_e start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ italic_s italic_c italic_o italic_r italic_e start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>} 
</div>
<div class="ltx_listingline" id="algorithm1.27.28">
<span class="ltx_text ltx_font_typewriter" id="algorithm1.27.28.1">// </span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="algorithm1.27.28.2">Confidence<span class="ltx_text ltx_font_medium" id="algorithm1.27.28.2.1"> has 3 optional values: [CORRECT], [INCORRECT] or [AMBIGUOUS] </span></span>
</div>
<div class="ltx_listingline" id="algorithm1.27.29">
<span class="ltx_tag ltx_tag_listingline">3</span> <span class="ltx_text ltx_font_bold" id="algorithm1.27.29.1">if</span>Â <em class="ltx_emph ltx_font_italic" id="algorithm1.27.29.2">Confidence == <span class="ltx_text ltx_font_typewriter" id="algorithm1.27.29.2.1">[CORRECT]</span></em>Â <span class="ltx_text ltx_font_bold" id="algorithm1.27.29.3">then</span>
</div>
<div class="ltx_listingline" id="algorithm1.14.14">
<span class="ltx_tag ltx_tag_listingline">4</span>Â Â Â Â Â 
Internal_Knowledge = Knowledge_Refine(<math alttext="x" class="ltx_Math" display="inline" id="algorithm1.13.13.m1.1"><semantics id="algorithm1.13.13.m1.1a"><mi id="algorithm1.13.13.m1.1.1" xref="algorithm1.13.13.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.m1.1b"><ci id="algorithm1.13.13.m1.1.1.cmml" xref="algorithm1.13.13.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.13.13.m1.1d">italic_x</annotation></semantics></math>, <math alttext="D" class="ltx_Math" display="inline" id="algorithm1.14.14.m2.1"><semantics id="algorithm1.14.14.m2.1a"><mi id="algorithm1.14.14.m2.1.1" xref="algorithm1.14.14.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.m2.1b"><ci id="algorithm1.14.14.m2.1.1.cmml" xref="algorithm1.14.14.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="algorithm1.14.14.m2.1d">italic_D</annotation></semantics></math>)
</div>
<div class="ltx_listingline" id="algorithm1.15.15">
<span class="ltx_tag ltx_tag_listingline">5</span>Â Â Â Â Â 
<math alttext="k" class="ltx_Math" display="inline" id="algorithm1.15.15.m1.1"><semantics id="algorithm1.15.15.m1.1a"><mi id="algorithm1.15.15.m1.1.1" xref="algorithm1.15.15.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm1.15.15.m1.1b"><ci id="algorithm1.15.15.m1.1.1.cmml" xref="algorithm1.15.15.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.15.15.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="algorithm1.15.15.m1.1d">italic_k</annotation></semantics></math> = Internal_Knowledge

</div>
<div class="ltx_listingline" id="algorithm1.27.30">
<span class="ltx_tag ltx_tag_listingline">6</span>Â Â Â Â Â  
<span class="ltx_text ltx_font_bold" id="algorithm1.27.30.1">else if</span>Â <em class="ltx_emph ltx_font_italic" id="algorithm1.27.30.2">Confidence == <span class="ltx_text ltx_font_typewriter" id="algorithm1.27.30.2.1">[INCORRECT]</span></em>Â <span class="ltx_text ltx_font_bold" id="algorithm1.27.30.3">then</span>
</div>
<div class="ltx_listingline" id="algorithm1.17.17">
<span class="ltx_tag ltx_tag_listingline">7</span>Â Â Â Â Â Â Â Â Â Â 
External_Knowledge = Web_Search(<math alttext="W" class="ltx_Math" display="inline" id="algorithm1.16.16.m1.1"><semantics id="algorithm1.16.16.m1.1a"><mi id="algorithm1.16.16.m1.1.1" xref="algorithm1.16.16.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="algorithm1.16.16.m1.1b"><ci id="algorithm1.16.16.m1.1.1.cmml" xref="algorithm1.16.16.m1.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.16.16.m1.1c">W</annotation><annotation encoding="application/x-llamapun" id="algorithm1.16.16.m1.1d">italic_W</annotation></semantics></math> Rewrites <math alttext="x" class="ltx_Math" display="inline" id="algorithm1.17.17.m2.1"><semantics id="algorithm1.17.17.m2.1a"><mi id="algorithm1.17.17.m2.1.1" xref="algorithm1.17.17.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.17.17.m2.1b"><ci id="algorithm1.17.17.m2.1.1.cmml" xref="algorithm1.17.17.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.17.17.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.17.17.m2.1d">italic_x</annotation></semantics></math> for searching) 
</div>
<div class="ltx_listingline" id="algorithm1.18.18">
<span class="ltx_tag ltx_tag_listingline">8</span>Â Â Â Â Â Â Â Â Â Â 
<math alttext="k" class="ltx_Math" display="inline" id="algorithm1.18.18.m1.1"><semantics id="algorithm1.18.18.m1.1a"><mi id="algorithm1.18.18.m1.1.1" xref="algorithm1.18.18.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm1.18.18.m1.1b"><ci id="algorithm1.18.18.m1.1.1.cmml" xref="algorithm1.18.18.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.18.18.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="algorithm1.18.18.m1.1d">italic_k</annotation></semantics></math> = External_Knowledge

</div>
<div class="ltx_listingline" id="algorithm1.27.31">
<span class="ltx_tag ltx_tag_listingline">9</span>Â Â Â Â Â Â Â Â Â Â  
<span class="ltx_text ltx_font_bold" id="algorithm1.27.31.1">else if</span>Â <em class="ltx_emph ltx_font_italic" id="algorithm1.27.31.2">Confidence == <span class="ltx_text ltx_font_typewriter" id="algorithm1.27.31.2.1">[AMBIGUOUS]</span></em>Â <span class="ltx_text ltx_font_bold" id="algorithm1.27.31.3">then</span>
</div>
<div class="ltx_listingline" id="algorithm1.20.20">
<span class="ltx_tag ltx_tag_listingline">10</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Internal_Knowledge = Knowledge_Refine(<math alttext="x" class="ltx_Math" display="inline" id="algorithm1.19.19.m1.1"><semantics id="algorithm1.19.19.m1.1a"><mi id="algorithm1.19.19.m1.1.1" xref="algorithm1.19.19.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.19.19.m1.1b"><ci id="algorithm1.19.19.m1.1.1.cmml" xref="algorithm1.19.19.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.19.19.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.19.19.m1.1d">italic_x</annotation></semantics></math>, <math alttext="D" class="ltx_Math" display="inline" id="algorithm1.20.20.m2.1"><semantics id="algorithm1.20.20.m2.1a"><mi id="algorithm1.20.20.m2.1.1" xref="algorithm1.20.20.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="algorithm1.20.20.m2.1b"><ci id="algorithm1.20.20.m2.1.1.cmml" xref="algorithm1.20.20.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.20.20.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="algorithm1.20.20.m2.1d">italic_D</annotation></semantics></math>)
</div>
<div class="ltx_listingline" id="algorithm1.22.22">
<span class="ltx_tag ltx_tag_listingline">11</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
External_Knowledge = Web_Search(<math alttext="W" class="ltx_Math" display="inline" id="algorithm1.21.21.m1.1"><semantics id="algorithm1.21.21.m1.1a"><mi id="algorithm1.21.21.m1.1.1" xref="algorithm1.21.21.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="algorithm1.21.21.m1.1b"><ci id="algorithm1.21.21.m1.1.1.cmml" xref="algorithm1.21.21.m1.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.21.21.m1.1c">W</annotation><annotation encoding="application/x-llamapun" id="algorithm1.21.21.m1.1d">italic_W</annotation></semantics></math> Rewrites <math alttext="x" class="ltx_Math" display="inline" id="algorithm1.22.22.m2.1"><semantics id="algorithm1.22.22.m2.1a"><mi id="algorithm1.22.22.m2.1.1" xref="algorithm1.22.22.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.22.22.m2.1b"><ci id="algorithm1.22.22.m2.1.1.cmml" xref="algorithm1.22.22.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.22.22.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.22.22.m2.1d">italic_x</annotation></semantics></math> for searching) 
</div>
<div class="ltx_listingline" id="algorithm1.23.23">
<span class="ltx_tag ltx_tag_listingline">12</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
<math alttext="k" class="ltx_Math" display="inline" id="algorithm1.23.23.m1.1"><semantics id="algorithm1.23.23.m1.1a"><mi id="algorithm1.23.23.m1.1.1" xref="algorithm1.23.23.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm1.23.23.m1.1b"><ci id="algorithm1.23.23.m1.1.1.cmml" xref="algorithm1.23.23.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.23.23.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="algorithm1.23.23.m1.1d">italic_k</annotation></semantics></math> = Internal_Knowledge + External_Knowledge

</div>
<div class="ltx_listingline" id="algorithm1.27.32">
<span class="ltx_tag ltx_tag_listingline">13</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â   end if
</div>
<div class="ltx_listingline" id="algorithm1.27.27">
<math alttext="G" class="ltx_Math" display="inline" id="algorithm1.24.24.m1.1"><semantics id="algorithm1.24.24.m1.1a"><mi id="algorithm1.24.24.m1.1.1" xref="algorithm1.24.24.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="algorithm1.24.24.m1.1b"><ci id="algorithm1.24.24.m1.1.1.cmml" xref="algorithm1.24.24.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.24.24.m1.1c">G</annotation><annotation encoding="application/x-llamapun" id="algorithm1.24.24.m1.1d">italic_G</annotation></semantics></math> predicts <math alttext="y" class="ltx_Math" display="inline" id="algorithm1.25.25.m2.1"><semantics id="algorithm1.25.25.m2.1a"><mi id="algorithm1.25.25.m2.1.1" xref="algorithm1.25.25.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="algorithm1.25.25.m2.1b"><ci id="algorithm1.25.25.m2.1.1.cmml" xref="algorithm1.25.25.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.25.25.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="algorithm1.25.25.m2.1d">italic_y</annotation></semantics></math> given <math alttext="x" class="ltx_Math" display="inline" id="algorithm1.26.26.m3.1"><semantics id="algorithm1.26.26.m3.1a"><mi id="algorithm1.26.26.m3.1.1" xref="algorithm1.26.26.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="algorithm1.26.26.m3.1b"><ci id="algorithm1.26.26.m3.1.1.cmml" xref="algorithm1.26.26.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.26.26.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="algorithm1.26.26.m3.1d">italic_x</annotation></semantics></math> and <math alttext="k" class="ltx_Math" display="inline" id="algorithm1.27.27.m4.1"><semantics id="algorithm1.27.27.m4.1a"><mi id="algorithm1.27.27.m4.1.1" xref="algorithm1.27.27.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="algorithm1.27.27.m4.1b"><ci id="algorithm1.27.27.m4.1.1.cmml" xref="algorithm1.27.27.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.27.27.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="algorithm1.27.27.m4.1d">italic_k</annotation></semantics></math>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.30.1.1">AlgorithmÂ 1</span> </span><span class="ltx_text ltx_font_smallcaps" id="algorithm1.31.2">CRAG</span> Inference</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Action Trigger</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To correct the irrelevant documents and refine the target documents as needed, actions should be executed discriminately.
Based on the aforementioned confidence score for each retrieved document, three types of actions are designed and triggered accordingly where the upper and lower thresholds are set.
If the confidence score is higher than the upper threshold, the retrieved document is identified as <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.1">Correct</span>, while identified as <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.2">Incorrect</span> if below the lower threshold. Otherwise, a more soft and intermediate action, i.e., <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.3">Ambiguous</span> is executed.
Each retrieved document is conducted individually and integrated eventually.</p>
</div>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Correct</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">Here, a retrieval is assumed <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p1.1.1">Correct</span> when the confidence score of <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px1.p1.1.2">at least one retrieved document</em> is higher than the upper threshold.
If so, it means that there are relevant documents in the retrieved results, and the knowledge from the retrieval results is supposed to be more reliable and accurate.
However, even if a relevant document can be found, there is inevitably some noisy knowledge strips in this document.
To extract the most critical knowledge strips within this document, a knowledge refinement method is further designed which will be elaborated in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS4" title="4.4 Knowledge Refinement â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Incorrect</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">Besides, a retrieval is assumed <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px2.p1.1.1">Incorrect</span> when the confidence scores of <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.1.2">all retrieved documents</em> are below the lower threshold.
This indicates that all retrieved documents are considered irrelevant, which are unhelpful for generation.
Once the knowledge from the retrieval results is judged to be inaccurate, it is unwise to still get stuck in it, which is likely to result in fabricated facts.
Therefore, we need to seek new sources of knowledge for correction.
Here, web search is introduced to search from the Internet as elaborated in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS5" title="4.5 Web Search â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.5</span></a>.
This corrective action helps overcome the embarrassing challenge where no reliable knowledge can be referred to.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Ambiguous</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.1">Except for the above two situations, the remaining will be assigned to an intermediate action of <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px3.p1.1.1">Ambiguous</span>.
This generally occurs when the accuracy of the retrieval is hard to distinguish and the evaluator gives an intermediate score.
Since the retrieval evaluator is not confident in its judgment, both types of processed knowledge in <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px3.p1.1.2">Correct</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px3.p1.1.3">Incorrect</span> are combined to complement each other.
Implementing such a moderating and soft strategy can significantly contribute to strengthening the robustness and resilience of the system, fostering a more adaptable framework for optimal performance.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Discussion</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px4.p1.1">Preliminary experiments of employing only the <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px4.p1.1.1">Correct</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px4.p1.1.2">Incorrect</span> actions show that the efficacy of CRAG was easily affected by the accuracy of the retrieval evaluator.
The reason might be the distinct knowledge switch for all input cases, regardless of the level of confidence in their judgment.
The design of the <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px4.p1.1.3">Ambiguous</span> action significantly helps to mitigate the dependence on the accuracy of the retrieval evaluator.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Knowledge Refinement</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Given a retrieved relevant document, a decompose-then-recompose knowledge refinement method is designed to further extract the most critical knowledge strips in it.
To obtain fine-grained retrieval results, we segmented the retrieved results into internal strips.
If a retrieved result is as short as one or two sentences, it is regarded as an individual strip, otherwise, retrieval documents are required to be split into smaller units which generally consist of a few sentences according to the total length.
The scale is assumed to include an independent piece of information, and the filtering is based on the segments.
Then, the retrieval evaluator fine-tuned in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS2" title="4.2 Retrieval Evaluator â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.2</span></a> is employed to calculate the relevance score of each knowledge strip.
Based on these scores, irrelevant knowledge strips are filtered out, while relevant ones are recomposed via concatenation in order, namely internal knowledge.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Web Search</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">It would be more intelligent if a system itself could determine that its existing knowledge corpus could not solve the problem well and turn to additional external knowledge for help.
On the contrary, even if a system knows that the existing knowledge cannot solve the problem, but still sticks to the limited knowledge corpus, it will only give a fabricated fact in the end, which is called hallucination..
Therefore, it is extremely important to seek complementary external knowledge if the retrieved results are all assumed irrelevant, and we consider a system that knows what it doesnâ€™t know and what it cannot answer to be more intelligent than one that clings to limited knowledge and is incapable of seeking external knowledge.
Since retrieval from static and limited corpora can only return sub-optimal documents in terms of scope and diversity, large-scale web searchesÂ <cite class="ltx_cite ltx_citemacro_citep">(Piktus etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib25" title="">2021</a>; Komeili etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib14" title="">2022</a>)</cite> are integrated as a strategic extension of RAG.
Specifically, the inputs are rewritten into queries composed of keywords by ChatGPT to mimic the daily usage of search engine.
The prompt for rewriting is shown in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1" title="Appendix A Task Prompts â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">A</span></a>.
In <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.p1.1.1">CRAG</span>, a public and accessible commercial web search API is adopted to generate a series of URL links for every query. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>In this study, Google Search API is utilized for searching.</span></span></span>
Considering that knowledge from large-scale web searches could introduce biases or unreliable information, authoritative and regulated web pages like Wikipedia are preferred, which can significantly help mitigate these issues.
Moreover, we utilize the URL links to navigate web pages, transcribe their content, and employ the same knowledge refinement method as SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S4.SS4" title="4.4 Knowledge Refinement â€£ 4 CRAG â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4.4</span></a> to derive the relevant web knowledge, namely external knowledge.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<figure class="ltx_table" id="S5.11">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" id="S5.11.11" style="width:312.2pt;height:498.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.9pt,20.6pt) scale(0.923640048040061,0.923640048040061) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.11.11.11">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.11.11.11.12.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.11.11.11.12.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.11.11.11.12.1.2">PopQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.11.11.11.12.1.3">Bio</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.11.11.11.12.1.4">Pub</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.11.11.11.12.1.5">ARC</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.13.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.13.2.1">Method</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.13.2.2">(Accuracy)</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.13.2.3">(FactScore)</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.13.2.4">(Accuracy)</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.13.2.5">(Accuracy)</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.14.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S5.11.11.11.14.3.1"><em class="ltx_emph ltx_font_italic" id="S5.11.11.11.14.3.1.1">LMs trained with propriety data</em></th>
</tr>
<tr class="ltx_tr" id="S5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.1.1.1.1.1">LLaMA2-c<sub class="ltx_sub" id="S5.1.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.1.1.1.1.1.1.1">13B</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.1.1.1.1.2">20.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.1.1.1.1.3">55.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.1.1.1.1.4">49.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.1.1.1.1.5">38.4</td>
</tr>
<tr class="ltx_tr" id="S5.2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.2.2.2.2.1">Ret-LLaMA2-c<sub class="ltx_sub" id="S5.2.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S5.2.2.2.2.1.1.1">13B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.2.2.2.2.2">51.8</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.2.2.3">79.9</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.2.2.4">52.1</td>
<td class="ltx_td ltx_align_center" id="S5.2.2.2.2.5">37.9</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.15.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.15.4.1">ChatGPT</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.15.4.2">29.3</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.15.4.3">71.8</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.15.4.4">70.1</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.15.4.5"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.15.4.5.1">75.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.16.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.16.5.1">Ret-ChatGPT</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.16.5.2">50.8</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.16.5.3">-</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.16.5.4">54.7</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.16.5.5"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.16.5.5.1">75.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.17.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.17.6.1">Perplexity.ai</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.17.6.2">-</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.17.6.3">71.2</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.17.6.4">-</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.17.6.5">-</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.18.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S5.11.11.11.18.7.1"><em class="ltx_emph ltx_font_italic" id="S5.11.11.11.18.7.1.1">Baselines without retrieval</em></th>
</tr>
<tr class="ltx_tr" id="S5.3.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.3.3.3.3.1">LLaMA2<sub class="ltx_sub" id="S5.3.3.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S5.3.3.3.3.1.1.1">7B</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.3.3.3.3.2">14.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.3.3.3.3.3">44.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.3.3.3.3.4">34.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.3.3.3.3.5">21.8</td>
</tr>
<tr class="ltx_tr" id="S5.4.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.4.4.4.4.1">Alpaca<sub class="ltx_sub" id="S5.4.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S5.4.4.4.4.1.1.1">7B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.4.4.4.4.2">23.6</td>
<td class="ltx_td ltx_align_center" id="S5.4.4.4.4.3">45.8</td>
<td class="ltx_td ltx_align_center" id="S5.4.4.4.4.4">49.8</td>
<td class="ltx_td ltx_align_center" id="S5.4.4.4.4.5">45.0</td>
</tr>
<tr class="ltx_tr" id="S5.5.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.5.5.5.5.1">LLaMA2<sub class="ltx_sub" id="S5.5.5.5.5.1.1"><span class="ltx_text ltx_font_italic" id="S5.5.5.5.5.1.1.1">13B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.5.5.5.5.2">14.7</td>
<td class="ltx_td ltx_align_center" id="S5.5.5.5.5.3">53.4</td>
<td class="ltx_td ltx_align_center" id="S5.5.5.5.5.4">29.4</td>
<td class="ltx_td ltx_align_center" id="S5.5.5.5.5.5">29.4</td>
</tr>
<tr class="ltx_tr" id="S5.6.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.6.6.6.6.1">Alpaca<sub class="ltx_sub" id="S5.6.6.6.6.1.1"><span class="ltx_text ltx_font_italic" id="S5.6.6.6.6.1.1.1">13B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.6.6.6.6.2">24.4</td>
<td class="ltx_td ltx_align_center" id="S5.6.6.6.6.3">50.2</td>
<td class="ltx_td ltx_align_center" id="S5.6.6.6.6.4">55.5</td>
<td class="ltx_td ltx_align_center" id="S5.6.6.6.6.5">54.9</td>
</tr>
<tr class="ltx_tr" id="S5.7.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.7.7.7.7.1">CoVE<sub class="ltx_sub" id="S5.7.7.7.7.1.1"><span class="ltx_text ltx_font_italic" id="S5.7.7.7.7.1.1.1">65B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.7.7.7.7.2">-</td>
<td class="ltx_td ltx_align_center" id="S5.7.7.7.7.3">71.2</td>
<td class="ltx_td ltx_align_center" id="S5.7.7.7.7.4">-</td>
<td class="ltx_td ltx_align_center" id="S5.7.7.7.7.5">-</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.19.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5" id="S5.11.11.11.19.8.1"><em class="ltx_emph ltx_font_italic" id="S5.11.11.11.19.8.1.1">Baselines with retrieval</em></th>
</tr>
<tr class="ltx_tr" id="S5.8.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.8.8.8.8.1">LLaMA2<sub class="ltx_sub" id="S5.8.8.8.8.1.1"><span class="ltx_text ltx_font_italic" id="S5.8.8.8.8.1.1.1">7B</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.8.8.8.8.2">38.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.8.8.8.8.3">78.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.8.8.8.8.4">30.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.8.8.8.8.5">48.0</td>
</tr>
<tr class="ltx_tr" id="S5.9.9.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.9.9.9.9.1">Alpaca<sub class="ltx_sub" id="S5.9.9.9.9.1.1"><span class="ltx_text ltx_font_italic" id="S5.9.9.9.9.1.1.1">7B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.9.9.9.9.2">46.7</td>
<td class="ltx_td ltx_align_center" id="S5.9.9.9.9.3">76.6</td>
<td class="ltx_td ltx_align_center" id="S5.9.9.9.9.4">40.2</td>
<td class="ltx_td ltx_align_center" id="S5.9.9.9.9.5">48.0</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.20.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.20.9.1">SAIL</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.20.9.2">-</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.20.9.3">-</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.20.9.4">69.2</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.20.9.5">48.4</td>
</tr>
<tr class="ltx_tr" id="S5.10.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.10.10.10.10.1">LLaMA2<sub class="ltx_sub" id="S5.10.10.10.10.1.1"><span class="ltx_text ltx_font_italic" id="S5.10.10.10.10.1.1.1">13B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.10.10.10.10.2">45.7</td>
<td class="ltx_td ltx_align_center" id="S5.10.10.10.10.3">77.5</td>
<td class="ltx_td ltx_align_center" id="S5.10.10.10.10.4">30.2</td>
<td class="ltx_td ltx_align_center" id="S5.10.10.10.10.5">26.0</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.11.1">Alpaca<sub class="ltx_sub" id="S5.11.11.11.11.1.1"><span class="ltx_text ltx_font_italic" id="S5.11.11.11.11.1.1.1">13B</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.11.2">46.1</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.11.3">77.7</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.11.4">51.1</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.11.5">57.6</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.21.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="5" id="S5.11.11.11.21.10.1">
<span class="ltx_ERROR undefined" id="S5.11.11.11.21.10.1.1">\hdashline</span> Â Â Â Â  <em class="ltx_emph ltx_font_italic" id="S5.11.11.11.21.10.1.2">LLaMA2-hf-7b</em>
</th>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.22.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.22.11.1">RAG</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.22.11.2">50.5</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.22.11.3">44.9</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.22.11.4">48.9</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.22.11.5">43.4</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.23.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.23.12.1"><span class="ltx_text ltx_font_smallcaps" id="S5.11.11.11.23.12.1.1">CRAG</span></th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.23.12.2"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.23.12.2.1" style="color:#808080;">54.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.23.12.3">47.7</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.23.12.4"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.23.12.4.1" style="color:#808080;">59.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.23.12.5"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.23.12.5.1" style="color:#808080;">53.7</span></td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.24.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.24.13.1">Self-RAG*</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.24.13.2">29.0</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.24.13.3">32.2</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.24.13.4">0.7</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.24.13.5">23.9</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.25.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.25.14.1">Self-CRAG</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.25.14.2">49.0</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.25.14.3"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.25.14.3.1" style="color:#808080;">69.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.25.14.4">0.6</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.25.14.5">27.9</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.26.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="5" id="S5.11.11.11.26.15.1">
<span class="ltx_ERROR undefined" id="S5.11.11.11.26.15.1.1">\hdashline</span> Â Â Â Â  <em class="ltx_emph ltx_font_italic" id="S5.11.11.11.26.15.1.2">SelfRAG-LLaMA2-7b</em>
</th>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.27.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.27.16.1">RAG</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.27.16.2">52.8</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.27.16.3">59.2</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.27.16.4">39.0</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.27.16.5">53.2</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.28.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.28.17.1"><span class="ltx_text ltx_font_smallcaps" id="S5.11.11.11.28.17.1.1">CRAG</span></th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.28.17.2">59.8</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.28.17.3">74.1</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.28.17.4"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.28.17.4.1">75.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.28.17.5">68.6</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.29.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.11.11.11.29.18.1">Self-RAG</th>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.29.18.2">54.9</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.29.18.3">81.2</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.29.18.4">72.4</td>
<td class="ltx_td ltx_align_center" id="S5.11.11.11.29.18.5">67.3</td>
</tr>
<tr class="ltx_tr" id="S5.11.11.11.30.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.11.11.11.30.19.1">Self-CRAG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.11.11.11.30.19.2"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.30.19.2.1">61.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.11.11.11.30.19.3"><span class="ltx_text ltx_font_bold" id="S5.11.11.11.30.19.3.1">86.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.11.11.11.30.19.4">74.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.11.11.11.30.19.5">67.2</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overall evaluation results on the test sets of four datasets.
Results are separated based on the generation LLMs.
<span class="ltx_text ltx_font_bold" id="S5.11.14.1">Bold</span> numbers indicate the best performance among all methods and LLMs.
<span class="ltx_text ltx_font_bold" id="S5.11.15.2" style="color:#808080;">Gray-colored</span> bold scores indicate the best performance using a specific LLM.
* indicates the results reproduced by us, otherwise results except ours are cited from their original papers.
</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="S5.11.16">We conducted experiments to extensively demonstrate <span class="ltx_text ltx_font_smallcaps" id="S5.11.16.1">CRAG</span>â€™s adaptability to RAG-based approaches and its generalizability across both short- and long-form generation tasks.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<section class="ltx_subsection ltx_figure_panel" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Tasks, Datasets and Metrics</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.1.1">CRAG</span> was evaluated on four datasets, including
<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.2">PopQA</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Mallen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib19" title="">2023</a>)</cite> (<em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.3">short</em>-form generation),
<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.4">Biography</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib20" title="">2023</a>)</cite> (<em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.5">long</em>-form generation),
<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.6">PubHealth</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib38" title="">2023a</a>)</cite> (<em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.7">true-or-false</em> question), and
<span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.8">Arc-Challenge</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Bhakthavatsalam etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib4" title="">2021</a>)</cite> (<em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.9">multiple-choice</em> question).
Following previous work, accuracy was adopted as the evaluation metric for PopQA, PubHealth, and Arc-Challenge.
FactScoreÂ <cite class="ltx_cite ltx_citemacro_citep">(Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib20" title="">2023</a>)</cite> was adopted as the evaluation metric for Biography.
Readers can refer to AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS1" title="B.1 Tasks, Datasets and Metrics â€£ Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">B.1</span></a> for more details.
The same metrics are used because our proposed method is comparable to previous studies, since we used the same retrieval results as previous work.
The difference lies in that our motivation is to improve the retrieval quality by correcting the retrieval results that the system judges to be of low quality.
This can be analogous to RAGâ€™s augmentation to standalone parameterized language models and we further augment RAG with corrective strategies.</p>
</div>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Baselines</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We primarily compared <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.1.1">CRAG</span> with both approaches with and without retrieval, where the latter can be further split into standard RAG and latest advanced RAG, including:</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.2"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.2.1">Baselines without retrieval.</span> We evaluated some public LLMs, LLaMA2-7B,13B <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib35" title="">2023b</a>)</cite>, instruction-tuned models, Alpaca-7B,13B <cite class="ltx_cite ltx_citemacro_citep">(Dubois etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib8" title="">2023</a>)</cite>, and CoVE<sub class="ltx_sub" id="S5.SS2.p2.2.2"><span class="ltx_text ltx_font_italic" id="S5.SS2.p2.2.2.1">65B</span></sub> <cite class="ltx_cite ltx_citemacro_citep">(Dhuliawala etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib7" title="">2024</a>)</cite> which introduces iterative engineering to improve the factuality of LLM generations.
Propriety LLMs such as LLaMA2-chat<sub class="ltx_sub" id="S5.SS2.p2.2.3"><span class="ltx_text ltx_font_italic" id="S5.SS2.p2.2.3.1">13B</span></sub> and ChatGPT are also included.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">Standard RAG.</span> We evaluated the standard RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Lewis etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib15" title="">2020</a>)</cite> where an LM generates output given the query prepended with the top retrieved documents using the same retriever as in our system.
Here we adopted several public instruction-tuned LLMs, including LLaMA2-7B, 13B <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib35" title="">2023b</a>)</cite>, Alpaca-7B,13B <cite class="ltx_cite ltx_citemacro_citep">(Dubois etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib8" title="">2023</a>)</cite>, as well as LLaMA2-7B instruction-tuned in Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">Advanced RAG.</span>
(1) SAIL <cite class="ltx_cite ltx_citemacro_citep">(Luo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib18" title="">2023</a>)</cite> that instruction-tuned an LM on the Alpaca instruction-tuning data with top retrieved documents inserted before instructions.
(2) Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> that tuned the LLaMA2 on the instruction-tuning data comtaining several sets of reflection tokens which were labeled by GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib23" title="">2023</a>)</cite>.
(3) FollowingÂ <cite class="ltx_cite ltx_citemacro_citet">Asai etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite>, we also cited the results of retrieval-augmented baselines trained with private data: Ret-ChatGPT and Ret-LLaMA-chat, which deploy the same augmentation technique above, as well as perplexity.ai, an InstructGPT-based production search system.</p>
</div>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5" title="5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a> presents the results on four datasets.
The model coupling the proposed method with standard RAG is named <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p1.1.1">CRAG</span> and that coupling with Self-RAG is named Self-CRAG.
Readers can refer to AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.SS3" title="B.3 Implementation Details â€£ Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">B.3</span></a> for more implementation details of our proposed methods.
From these results, we can conclude the following findings:</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.1">First, the proposed method can significantly improve the performance of RAG and Self-RAG.</em>
Specifically, as shown in tableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5" title="5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p2.1.2">CRAG</span> outperformed RAG by margins of 7.0% accuracy on PopQA, 14.9% FactScore on Biography, 36.6% accuracy on PubHealth, and 15.4% accuracy on Arc-Challenge when based on <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.3">SelfRAG-LLaMA2-7b</em>,
as well as by margins of 4.4% accuracy on PopQA, 2.8% FactScore on Biography, and 10.3% on Arc-Challenge when based on <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.4">LLaMA2-hf-7b</em>.
Compared with the current state-of-the-art Self-RAG, Self-CRAG outperformed it by margins of 20.0% accuracy on PopQA, 36.9% FactScore on Biography, and 4.0% accuracy on Arc-Challenge when based on <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.5">LLaMA2-hf-7b</em>,
as well as by margins of 6.9% accuracy on PopQA, 5.0% FactScore on Biography, and 2.4% accuracy on PubHealth, when based on <em class="ltx_emph ltx_font_italic" id="S5.SS3.p2.1.6">SelfRAG-LLaMA2-7b</em>.
These results demonstrated the adaptability of <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p2.1.7">CRAG</span> which is plug-and-play and can be implemented into RAG-based approaches.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1"><em class="ltx_emph ltx_font_italic" id="S5.SS3.p3.1.1">Second, the proposed method demonstrated great generalizability across a variety of generation tasks.</em>
In particular, these benchmarks reported in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5" title="5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a> respectively represent different practical scenarios including short-form entity generation (PopQA), long-form generation (Biography), and closed-set tasks (PubHealth, Arc-Challenge).
These results verified the consistent effectiveness of <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.1.2">CRAG</span>.
Its versatility across a spectrum of tasks underscores its robust capabilities and generalizability across diverse scenarios.</p>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1"><em class="ltx_emph ltx_font_italic" id="S5.SS3.p4.1.1">Third, the proposed method exhibited greater flexibility in replacing the underlying LLM generator.</em>
It can be seen that <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p4.1.2">CRAG</span> still showed competitive performance when the underlying LLMs was changed from <em class="ltx_emph ltx_font_italic" id="S5.SS3.p4.1.3">SelfRAG-LLaMA2-7b</em> to <em class="ltx_emph ltx_font_italic" id="S5.SS3.p4.1.4">LLaMA2-hf-7b</em>, while the performance of Self-RAG dropped significantly, even underperforming the standard RAG on several benchmarks.
The reason for these results is that Self-RAG needs to be instruction-tuned using human or LLM annotated data to learn to output special critic tokens as needed, while this ability is not learned in common LLMs.
<span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p4.1.5">CRAG</span> does not have any requirements for this ability.
As you can imagine, when more advanced LLMs are available in the future, they can be coupled with <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p4.1.6">CRAG</span> easily, while additional instruction tuning is still necessary for Self-RAG.</p>
</div>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Ablation Study</h3>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:424.9pt;height:267.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(83.8pt,-52.8pt) scale(1.65180813546784,1.65180813546784) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T2.1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">LLaMA2-hf-7b</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">SelfRAG-LLaMA2-7b</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.2.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T2.1.1.2.1.1.1">CRAG</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.2.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.3.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="S5.T2.1.1.3.2.1.1">\hdashline</span>Â  w/o. <span class="ltx_text ltx_font_typewriter" id="S5.T2.1.1.3.2.1.2">Correct</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.3.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">53.2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.3.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">58.3</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.4.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. <span class="ltx_text ltx_font_typewriter" id="S5.T2.1.1.4.3.1.1">Incorrect</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.4</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.4.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.5</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.5.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. <span class="ltx_text ltx_font_typewriter" id="S5.T2.1.1.5.4.1.1">Ambiguous</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.0</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.6.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-CRAG</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.6.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">49.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.6.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">61.8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.7.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="S5.T2.1.1.7.6.1.1">\hdashline</span>Â  w/o. <span class="ltx_text ltx_font_typewriter" id="S5.T2.1.1.7.6.1.2">Correct</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">43.6</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.7.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.6</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.1.1.8.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. <span class="ltx_text ltx_font_typewriter" id="S5.T2.1.1.8.7.1.1">Incorrect</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">47.7</td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.8.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">60.8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.1.1.9.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. <span class="ltx_text ltx_font_typewriter" id="S5.T2.1.1.9.8.1.1">Ambiguous</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.9.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">48.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.1.1.9.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">61.5</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation study for removing each single action on the PopQA dataset in terms of accuracy.
</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">The impact of each triggered action.</h4>
<div class="ltx_para" id="S5.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS4.SSS0.Px1.p1.1">To further verify the effectiveness of triggered actions designed in the retrieval evaluator, ablation tests for removing each single action in the proposed method were conducted as shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.T2" title="Table 2 â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.
Evaluations on the PopQA dataset were conducted to demonstrate the performance change in terms of accuracy.
Specifically, when the action <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.1">Correct</span> or <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.2">Incorrect</span> was removed, it was merged with <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.3">Ambiguous</span> so that the proportion that originally triggered <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.4">Correct</span> or <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.5">Incorrect</span> would trigger <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.6">Ambiguous</span>.
On the other hand, when the action <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.7">Ambiguous</span> was removed, there was only one threshold against which all input queries clearly triggered <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.8">Correct</span> or <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px1.p1.1.9">Incorrect</span>.
From these results, it can be seen that there was a performance drop no matter which action was removed, illustrating that each action contributed to improving the robustness of generation.
To further illustrate the study, experiments are also conducted by triggering only one action once, and the results shown in the appendix also prove the consistency.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">The impact of each knowledge utilization operation.</h4>
<figure class="ltx_table" id="S5.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.1" style="width:424.9pt;height:256.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(78.2pt,-47.1pt) scale(1.58196670326969,1.58196670326969) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T3.1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">LLaMA2-hf-7b</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">SelfRAG-LLaMA2-7b</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.2.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S5.T3.1.1.2.1.1.1">CRAG</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.2.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.2.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.8</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.3.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="S5.T3.1.1.3.2.1.1">\hdashline</span>Â  w/o. refinement</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">49.8</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.3.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">54.2</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.4.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. rewriting</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">51.7</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.4.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">56.2</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.5.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. selection</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">50.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.5.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">58.6</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.1.1.6.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-CRAG</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.6.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">49.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.1.6.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">61.8</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.7.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="S5.T3.1.1.7.6.1.1">\hdashline</span>Â  w/o. refinement</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">35.9</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.7.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">52.2</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.1.1.8.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. rewriting</th>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">37.2</td>
<td class="ltx_td ltx_align_center" id="S5.T3.1.1.8.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">58.4</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.1.1.9.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">w/o. selection</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.9.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">24.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.1.1.9.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">57.9</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study for removing each knowledge utilization operation on the PopQA in terms of accuracy.
</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS4.SSS0.Px2.p1.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.T3" title="Table 3 â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a> illustrated how the performance changed if a key knowledge utilization operation was ablated.
Evaluations on the PopQA dataset in terms of accuracy were conducted by individually removing the knowledge utilization operations of document refinement, search query rewriting, and external knowledge selection.
Removing document refinement denoted that the original retrieved documents were directly fed to the following generator, as in most existing works.
Additionally, removing search query rewriting denoted that questions were not rewritten into queries consisting of keywords during knowledge searching.
Eventually, removing knowledge selection denoted that all searched content of web pages was all regarded as the external knowledge without selection.
These results help derive the findings that the performance of the final system degraded no matter which knowledge utilization operation was removed, revealing that each knowledge utilization operation contributed to improving the utilization of knowledge.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.1" style="width:424.9pt;height:167.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(98.3pt,-38.7pt) scale(1.86107304031207,1.86107304031207) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T4.1.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.1.1.1.1.2">Accuracy</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.1.2.2.1">Our Retrieval Evaluator (T5-based)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.2.2.2">84.3</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.3.3.1">
<span class="ltx_ERROR undefined" id="S5.T4.1.1.3.3.1.1">\hdashline</span>ChatGPT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.3.3.2">58.0</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.4.4.1">ChatGPT-CoT</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.4.2">62.4</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T4.1.1.5.5.1">ChatGPT-few-shot</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.5.5.2">64.7</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Evaluation of our retrieval evaluator and ChatGPT for the retrieval results on the PopQA dataset.
</figcaption>
</figure>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Accuracy of the Retrieval Evaluator</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">The quality of the retrieval evaluator significantly determined the performance of the entire system.
Given the document retrieval results, we assessed whether the retrieval evaluator can accurately determine the overall quality of these results.
The assessment accuracy on the PopQA dataset of our retrieval evaluator and the commercial LLM ChatGPT on the document retrieval results was shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.T4" title="Table 4 â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">4</span></a>.
The prompts of <em class="ltx_emph ltx_font_italic" id="S5.SS5.p1.1.1">ChatGPT</em>, <em class="ltx_emph ltx_font_italic" id="S5.SS5.p1.1.2">ChatGPT-CoT</em>, and <em class="ltx_emph ltx_font_italic" id="S5.SS5.p1.1.3">ChatGPT-few-shot</em> used in our experiments can be referred to in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1" title="Appendix A Task Prompts â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">A</span></a>.
Results reveal that the lightweight T5-based retrieval evaluator significantly outperformed the competitive ChatGPT in all settings.</p>
</div>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Robustness to Retrieval Performance</h3>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="228" id="S5.F3.g1" src="x3.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The generation performance of Self-RAG and Self-CRAG given different retrieval performance on the PopQA dataset with SelfRAG-LLaMA-7b.
The lower horizontal line demonstrates the performance of the generator without retrieval.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">To further verify the robustness of the proposed method to retrieval performance, we studied how the generation performance changed given different retrieval performance.
A part of accurate retrieval results were deliberately removed at random to imitate a low-quality retriever and evaluate how the performance changed.
FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.F3" title="Figure 3 â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrated the performance change of Self-RAG and Self-CRAG on the PopQA dataset.
It can be seen that the generation performance of Self-RAG and Self-CRAG dropped as the retrieval performance dropped, indicating that the generator relied heavily on the quality of the retriever.
Furthermore, as the retrieval performance dropped, the generation performance of Self-CRAG dropped more slightly than that of Self-RAG.
These results imply the superiority of Self-CRAG over Self-RAG on enhancing the robustness to retrieval performance.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T5.1" style="width:424.9pt;height:235.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(82.4pt,-45.6pt) scale(1.63320426662006,1.63320426662006) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T5.1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">LLaMA2-hf-7b</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">SelfRAG-LLaMA2-7b</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.1.1.2.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">PopQA</th>
<td class="ltx_td ltx_border_t" id="S5.T5.1.1.2.1.2" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T5.1.1.2.1.3" style="padding-left:2.0pt;padding-right:2.0pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.3.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="S5.T5.1.1.3.2.1.1">\hdashline</span>Â  <span class="ltx_text ltx_font_smallcaps" id="S5.T5.1.1.3.2.1.2">CRAG</span>
</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.9</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.8</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.4.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">RAG</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.4.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">50.5</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.4.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">52.8</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.5.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">RAG w. web</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.5.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">52.2</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.5.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">53.8</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.6.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="S5.T5.1.1.6.5.1.1">\hdashline</span>Â  Self-CRAG</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.6.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">49.0</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.6.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">61.8</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.7.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-RAG</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.7.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">29.0</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.7.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">54.9</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T5.1.1.8.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-RAG w. web</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.8.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">24.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.8.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">57.9</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Comparison results between <span class="ltx_text ltx_font_smallcaps" id="S5.T5.3.1">CRAG</span>, Self-CRAG and RAG, Self-RAG with the same input in terms of accuracy.
</figcaption>
</figure>
<section class="ltx_subsection" id="S5.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7 </span>Consistent Supplementation of Web Search Knowledge</h3>
<div class="ltx_para" id="S5.SS7.p1">
<p class="ltx_p" id="S5.SS7.p1.1">This paper highlights the necessity of enhancing the retrieved context by incorporating additional information when the initial retrieval results are irrelevant and unreliable.
Meanwhile, it is also crucial to confirm that the primary improvements in our method stem from the self-correction mechanism, rather than solely from the supplementary information obtained through web searches.
To further demonstrate the effectiveness of the proposed self-correction mechanism, both RAG and Self-RAG were consistently supplemented with web search knowledge to ensure they had access to the same scope of the retrieved knowledge.
The results in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.T5" title="Table 5 â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">5</span></a> show that consistently supplementing RAG or Self-RAG with web search knowledge can improve the performance in most cases (except Self-RAG w. web using the original LLaMA2 model), though the improvement remains limited.
Furthermore, augmenting RAG or Self-RAG with the proposed self-correction mechanism significantly outperformed the models consistently supplemented with web search knowledge in all cases.
This finding confirms that the observed advancements are primarily attributable to the proposed self-correction mechanism.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.2" style="width:390.3pt;height:140pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(69.7pt,-25.0pt) scale(1.55523016132129,1.55523016132129) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T6.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.2.2.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T6.2.2.3.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.2.2.3.1.2">TFLOPs per token</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.2.2.3.1.3">executing time(s)</td>
</tr>
<tr class="ltx_tr" id="S5.T6.2.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T6.2.2.4.2.1">RAG</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.2.2.4.2.2">26.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.2.2.4.2.3">0.363</td>
</tr>
<tr class="ltx_tr" id="S5.T6.2.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T6.2.2.5.3.1"><span class="ltx_text ltx_font_smallcaps" id="S5.T6.2.2.5.3.1.1">CRAG</span></th>
<td class="ltx_td ltx_align_center" id="S5.T6.2.2.5.3.2">27.2</td>
<td class="ltx_td ltx_align_center" id="S5.T6.2.2.5.3.3">0.512</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T6.1.1.1.2">
<span class="ltx_ERROR undefined" id="S5.T6.1.1.1.2.1">\hdashline</span>Self-RAG</th>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.1.1">26.5<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.1.1.1.1.m1.1"><semantics id="S5.T6.1.1.1.1.m1.1a"><mo id="S5.T6.1.1.1.1.m1.1.1" xref="S5.T6.1.1.1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T6.1.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.1.1.1.1.m1.1d">âˆ¼</annotation></semantics></math>132.4</td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.1.3">0.741</td>
</tr>
<tr class="ltx_tr" id="S5.T6.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T6.2.2.2.2">Self-CRAG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.2.2.2.1">27.2<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.2.2.2.1.m1.1"><semantics id="S5.T6.2.2.2.1.m1.1a"><mo id="S5.T6.2.2.2.1.m1.1.1" xref="S5.T6.2.2.2.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S5.T6.2.2.2.1.m1.1.1.cmml" xref="S5.T6.2.2.2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.2.2.2.1.m1.1d">âˆ¼</annotation></semantics></math>80.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.2.2.2.3">0.908</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>computational overhead assessment of RAG, <span class="ltx_text ltx_font_smallcaps" id="S5.T6.4.1">CRAG</span>, Self-CRAG, and Self-RAG about FLOPs per token on GPUs and executing time per instance. The upper bound of Self-CRAG is lower because only three passages are provided as input (correct, incorrect and ambiguous content). All the data in the table only represents a rough estimate of the generation phase, the retrieval and data-processing stages are not included.
</figcaption>
</figure>
<section class="ltx_subsection" id="S5.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.8 </span>Computational Overhead Analysis</h3>
<div class="ltx_para" id="S5.SS8.p1">
<p class="ltx_p" id="S5.SS8.p1.1">To illustrate that our self-correction mechanism serves as a lightweight, plug-and-play solution for various RAG-based frameworks, we measured the computational overhead.
FLOPs prediction formulas in <cite class="ltx_cite ltx_citemacro_citet">Narayanan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib22" title="">2021</a>)</cite> were employed, with the results presented in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.T6" title="Table 6 â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a> which shows the predicted FLOPs per token on GPUs.
Due to the adaptive nature of Self-RAG, which varies its generation strategies based on input, the computational overhead cannot be precisely determined.
Therefore, we present an estimated range instead.
Additionally, we conducted the experiments on PopQA to assess the average execution time per instance in practice, as detailed in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#S5.T6" title="Table 6 â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">6</span></a>.
The findings indicate that the self-correction mechanism incurs only modest computational overhead while significantly enhancing performance, thereby validating its lightweight nature.</p>
</div>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion &amp; Limitation</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper studies the problem where RAG-based approaches are challenged if retrieval goes wrong, thereby exposing inaccurate and misleading knowledge to generative LMs.
Corrective Retrieval Augmented Generation is proposed to improve the robustness of generation.
Essentially, a lightweight retrieval evaluator is to estimate and trigger three knowledge retrieval actions discriminately.
With the further leverage of web search and optimized knowledge utilization, <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.1">CRAG</span> has significantly improved the ability of automatic self-correction and efficient utilization of retrieved documents.
Experiments extensively demonstrate its adaptability to RAG-based approaches as well as generalizability across short- and long-form generation tasks.
While we primarily proposed to improve the RAG framework from a corrective perspective and <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2">CRAG</span> can be seamlessly coupled with various RAG-based approaches, fine-tuning an external retrieval evaluator is inevitable.
How to eliminate this external evaluator and equip LLMs with better retrieval evaluation capabilities will be our future work.</p>
</div>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil etÂ al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, AndrewÂ M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, JonathanÂ H. Clark, LaurentÂ El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, etÂ al. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.10403" title="">PaLM 2 technical report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">CoRR</em>, abs/2305.10403.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai etÂ al. (2024)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=hSyW5go0v8" title="">Self-rag: Learning to retrieve, generate, and critique through self-reflection</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024</em>. OpenReview.net.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, QuyetÂ V. Do, Yan Xu, and Pascale Fung. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2023.IJCNLP-MAIN.45" title="">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity</a>.

</span>
<span class="ltx_bibblock">pages 675â€“718.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhakthavatsalam etÂ al. (2021)</span>
<span class="ltx_bibblock">
Sumithra Bhakthavatsalam, Daniel Khashabi, Tushar Khot, BhavanaÂ Dalvi Mishra, Kyle Richardson, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord, and Peter Clark. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2102.03315" title="">Think you have solved direct-answer question answering? try arc-da, the direct-answer AI2 reasoning challenge</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">CoRR</em>, abs/2102.03315.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
TomÂ B Brown, Benjamin Mann, Nick Ryder, etÂ al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Advances in neural information processing systems</em>, pages 1877â€“1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery etÂ al. (2023)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, HyungÂ Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, YiÂ Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, AndrewÂ M. Dai, ThanumalayanÂ Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v24/22-1144.html" title="">Palm: Scaling language modeling with pathways</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">J. Mach. Learn. Res.</em>, 24:240:1â€“240:113.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhuliawala etÂ al. (2024)</span>
<span class="ltx_bibblock">
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2024.FINDINGS-ACL.212" title="">Chain-of-verification reduces hallucination in large language models</a>.

</span>
<span class="ltx_bibblock">pages 3563â€“3578.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubois etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and TatsunoriÂ B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2305.14387" title="">Alpacafarm: A simulation framework for methods that learn from human feedback</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">CoRR</em>, abs/2305.14387.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://proceedings.mlr.press/v119/guu20a.html" title="">Retrieval augmented language model pre-training</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event</em>, volume 119 of <em class="ltx_emph ltx_font_italic" id="bib.bib9.2.2">Proceedings of Machine Learning Research</em>, pages 3929â€“3938. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=jKN1pXi7b0" title="">Unsupervised dense information retrieval with contrastive learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Trans. Mach. Learn. Res.</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji etÂ al. (2023)</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3571730" title="">Survey of hallucination in natural language generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">ACM Comput. Surv.</em>, 55(12):248:1â€“248:38.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, FrankÂ F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.emnlp-main.495" title="">Active retrieval augmented generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 7969â€“7992. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha, and Jinwoo Shin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=w4DW6qkRmt" title="">Sure: Summarizing retrievals using answer candidates for open-domain QA of llms</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024</em>. OpenReview.net.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Komeili etÂ al. (2022)</span>
<span class="ltx_bibblock">
Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2022.ACL-LONG.579" title="">Internet-augmented dialogue generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 8460â€“8478. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020)</span>
<span class="ltx_bibblock">
Patrick S.Â H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="">Retrieval-augmented generation for knowledge-intensive NLP tasks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022)</span>
<span class="ltx_bibblock">
Huayang Li, Yixuan Su, Deng Cai, Yan Wang, and Lemao Liu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2202.01110" title="">A survey on retrieval-augmented text generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">CoRR</em>, abs/2202.01110.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Yanming Liu, Xinyue Peng, Xuhong Zhang, Weihao Liu, Jianwei Yin, Jiannan Cao, and Tianyu Du. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2024.FINDINGS-ACL.281" title="">RA-ISF: learning to answer and understand from retrieval augmentation via iterative self-feedback</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024</em>, pages 4730â€“4749. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2023)</span>
<span class="ltx_bibblock">
Hongyin Luo, Tianhua Zhang, Yung-Sung Chuang, Yuan Gong, Yoon Kim, Xixin Wu, Helen Meng, and JamesÂ R. Glass. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.findings-emnlp.242" title="">Search augmented instruction learning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 3717â€“3729. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2023.ACL-LONG.546" title="">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 9802â€“9822. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min etÂ al. (2023)</span>
<span class="ltx_bibblock">
Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, PangÂ Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2023.emnlp-main.741" title="">Factscore: Fine-grained atomic evaluation of factual precision in long form text generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 12076â€“12100. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muhlgay etÂ al. (2023)</span>
<span class="ltx_bibblock">
Dor Muhlgay, Ori Ram, Inbal Magar, Yoav Levine, Nir Ratner, Yonatan Belinkov, Omri Abend, Kevin Leyton-Brown, Amnon Shashua, and Yoav Shoham. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2307.06908" title="">Generating benchmarks for factuality evaluation of language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">CoRR</em>, abs/2307.06908.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narayanan etÂ al. (2021)</span>
<span class="ltx_bibblock">
Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa Patwary, Vijay Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, Amar Phanishayee, and Matei Zaharia. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3458817.3476209" title="">Efficient large-scale language model training on GPU clusters using megatron-lm</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2021, St. Louis, Missouri, USA, November 14-19, 2021</em>, pageÂ 58. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2303.08774" title="">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CoRR</em>, abs/2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, XuÂ Jiang, Diogo Almeida, CarrollÂ L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, PaulÂ F. Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html" title="">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Piktus etÂ al. (2021)</span>
<span class="ltx_bibblock">
Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Dmytro Okhonko, Samuel Broscheit, Gautier Izacard, Patrick S.Â H. Lewis, Barlas Oguz, Edouard Grave, Wen-tau Yih, and Sebastian Riedel. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2112.09924" title="">The web is your oyster - knowledge-intensive NLP against a very large web corpus</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">CoRR</em>, abs/2112.09924.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2023.EMNLP-MAIN.85" title="">Is chatgpt a general-purpose natural language processing task solver?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 1339â€“1384. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and PeterÂ J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v21/20-074.html" title="">Exploring the limits of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">J. Mach. Learn. Res.</em>, 21:140:1â€“140:67.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rony etÂ al. (2022)</span>
<span class="ltx_bibblock">
Md. Rashad AlÂ Hasan Rony, Ricardo Usbeck, and Jens Lehmann. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2022.FINDINGS-NAACL.195" title="">Dialokg: Knowledge-structure aware task-oriented dialogue generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Findings of the Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15, 2022</em>, pages 2557â€“2571. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick etÂ al. (2023)</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto DessÃ¬, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://papers.nips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html" title="">Toolformer: Language models can teach themselves to use tools</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi etÂ al. (2023)</span>
<span class="ltx_bibblock">
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, EdÂ H. Chi, Nathanael SchÃ¤rli, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v202/shi23a.html" title="">Large language models can be easily distracted by irrelevant context</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib30.2.2">Proceedings of Machine Learning Research</em>, pages 31210â€“31227. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster etÂ al. (2021)</span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2021.FINDINGS-EMNLP.320" title="">Retrieval augmentation reduces hallucination in conversation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021</em>, pages 3784â€“3803. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan etÂ al. (2022)</span>
<span class="ltx_bibblock">
Chao-Hong Tan, Jia-Chen Gu, Chongyang Tao, Zhen-Hua Ling, Can Xu, Huang Hu, Xiubo Geng, and Daxin Jiang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/V1/2022.FINDINGS-ACL.125" title="">Tegtok: Augmenting text generation via task-specific and open-world knowledge</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 1597â€“1609. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tonmoy etÂ al. (2024)</span>
<span class="ltx_bibblock">
S.Â M. TowhidulÂ Islam Tonmoy, S.Â M.Â Mehedi Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, and Amitava Das. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2401.01313" title="">A comprehensive survey of hallucination mitigation techniques in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">CoRR</em>, abs/2401.01313.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, AurÃ©lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2302.13971" title="">Llama: Open and efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">CoRR</em>, abs/2302.13971.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, etÂ al. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">CoRR</em>, abs/2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2024)</span>
<span class="ltx_bibblock">
Zihao Wang, Anji Liu, Haowei Lin, Jiaqi Li, Xiaojian Ma, and Yitao Liang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2403.05313" title="">RAT: retrieval augmented thoughts elicit context-aware reasoning in long-horizon generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">CoRR</em>, abs/2403.05313.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoran etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Berant. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=ZS4m74kZpH" title="">Making retrieval-augmented language models robust to irrelevant context</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Tianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei Fang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu, Danny Fox, Helen Meng, and JamesÂ R. Glass. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2304.03728" title="">Interpretable unified language checking</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">CoRR</em>, abs/2304.03728.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2024)</span>
<span class="ltx_bibblock">
Tianjun Zhang, ShishirÂ G. Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, and JosephÂ E. Gonzalez. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2403.10131" title="">RAFT: adapting language model to domain specific RAG</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">CoRR</em>, abs/2403.10131.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, YuÂ Zhang, Yulong Chen, Longyue Wang, AnhÂ Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2309.01219" title="">Sirenâ€™s song in the AI ocean: A survey on hallucination in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">CoRR</em>, abs/2309.01219.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong etÂ al. (2023)</span>
<span class="ltx_bibblock">
Qihuang Zhong, Liang Ding, Juhua Liu, BoÂ Du, and Dacheng Tao. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2302.10198" title="">Can chatgpt understand too? A comparative study on chatgpt and fine-tuned BERT</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">CoRR</em>, abs/2302.10198.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Task Prompts</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">The prompts for generating knowledge keywords as web search queries were illustrated in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1.T7" title="Table 7 â€£ Appendix A Task Prompts â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_table" id="A1.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>The few-shot prompt to GPT-3.5 Turbo for generating knowledge keywords as web search queries.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T7.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T7.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T7.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.1.1.1.1">
<span class="ltx_p" id="A1.T7.1.1.1.1.1.1" style="width:411.9pt;">Extract at most three keywords separated by comma from the following dialogues and questions as queries for the web search, including topic background within dialogues and main intent within questions.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.2.2.1.1">
<span class="ltx_p" id="A1.T7.1.2.2.1.1.1" style="width:411.9pt;">question: What is Henry Feildenâ€™s occupation?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.3.3.1.1">
<span class="ltx_p" id="A1.T7.1.3.3.1.1.1" style="width:411.9pt;">query: Henry Feilden, occupation</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.4.4.1.1">
<span class="ltx_p" id="A1.T7.1.4.4.1.1.1" style="width:411.9pt;">question: In what city was Billy Carlson born?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.5.5.1.1">
<span class="ltx_p" id="A1.T7.1.5.5.1.1.1" style="width:411.9pt;">query: city, Billy Carlson, born</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.6.6.1.1">
<span class="ltx_p" id="A1.T7.1.6.6.1.1.1" style="width:411.9pt;">question: What is the religion of John Gwynn?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.7.7.1.1">
<span class="ltx_p" id="A1.T7.1.7.7.1.1.1" style="width:411.9pt;">query: religion of John Gwynn</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.8.8.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.8.8.1.1">
<span class="ltx_p" id="A1.T7.1.8.8.1.1.1" style="width:411.9pt;">question: What sport does Kiribati menâ€™s national basketball team play?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.9.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.9.9.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.9.9.1.1">
<span class="ltx_p" id="A1.T7.1.9.9.1.1.1" style="width:411.9pt;">query: sport, Kiribati menâ€™s national basketball team play</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.10.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T7.1.10.10.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.10.10.1.1">
<span class="ltx_p" id="A1.T7.1.10.10.1.1.1" style="width:411.9pt;">question: [question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.11.11">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T7.1.11.11.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T7.1.11.11.1.1">
<span class="ltx_p" id="A1.T7.1.11.11.1.1.1" style="width:411.9pt;">query:</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">The prompts to instruct ChatGPT as the evaluator were illustrated in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1.T8" title="Table 8 â€£ Appendix A Task Prompts â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">8</span></a>, TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1.T9" title="Table 9 â€£ Appendix A Task Prompts â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">9</span></a>, and TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A1.T10" title="Table 10 â€£ Appendix A Task Prompts â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">10</span></a> respectively.</p>
</div>
<figure class="ltx_table" id="A1.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>The direct prompt to GPT-3.5 Turbo as the evaluator.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T8.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T8.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T8.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T8.1.1.1.1.1">
<span class="ltx_p" id="A1.T8.1.1.1.1.1.1" style="width:411.9pt;">Given a question, does the following document have exact information to answer the question? Answer yes or no only.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T8.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T8.1.2.2.1.1">
<span class="ltx_p" id="A1.T8.1.2.2.1.1.1" style="width:411.9pt;">Question: [question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T8.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T8.1.3.3.1.1">
<span class="ltx_p" id="A1.T8.1.3.3.1.1.1" style="width:411.9pt;">Document: [document]</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A1.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>The prompt to GPT-3.5 Turbo with Chain-of-Thought as the evaluator.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T9.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T9.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T9.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.1.1.1.1">
<span class="ltx_p" id="A1.T9.1.1.1.1.1.1" style="width:411.9pt;">Given a question, does the following document have exact information to answer the question?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T9.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.2.2.1.1">
<span class="ltx_p" id="A1.T9.1.2.2.1.1.1" style="width:411.9pt;">Question: [question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T9.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.3.3.1.1">
<span class="ltx_p" id="A1.T9.1.3.3.1.1.1" style="width:411.9pt;">Document: [document]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T9.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.4.4.1.1">
<span class="ltx_p" id="A1.T9.1.4.4.1.1.1" style="width:411.9pt;">Think Step by step, and answer with yes or no only.</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A1.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>The few-shot prompt to GPT-3.5 Turbo as the evaluator.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T10.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T10.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T10.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.1.1.1.1">
<span class="ltx_p" id="A1.T10.1.1.1.1.1.1" style="width:411.9pt;">Given a question, does the following document have exact information to answer the question? Answer yes or no only.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.2.2.1.1">
<span class="ltx_p" id="A1.T10.1.2.2.1.1.1" style="width:411.9pt;">Question: In what city was Abraham Raimbach born?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.3.3.1.1">
<span class="ltx_p" id="A1.T10.1.3.3.1.1.1" style="width:411.9pt;">Document: Bancroft was born on November 25, 1839 in New Ipswich, New Hampshire to James Bancroft and Sarah Kimball. At an early age he was cared for by Mr. and Mrs. Patch of Ashby, Massachusetts, the neighboring town. While not legally adopted, they named him Cecil Franklin Patch Bancroft, adding Franklin Patch after the son Mr. and Mrs. Patch had who recently died. He attended public schools in Ashby as well as the Appleton Academy in New Ipswich. He entered Dartmouth College in 1856 at the age of sixteen and graduated in 1860 near the top of his class. Bancroft continued his education as he began his career in teaching. He took classes at the Union Theological Seminary in New York City during the 1864-65 academic year. While there he was a member of the United States Christian Commission, traveling to support soldiers during the Civil War. He then transferred to the Andover Theological Seminary where he would graduate in 1867.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.4.4.1.1">
<span class="ltx_p" id="A1.T10.1.4.4.1.1.1" style="width:411.9pt;">Answer: No.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.5.5.1.1">
<span class="ltx_p" id="A1.T10.1.5.5.1.1.1" style="width:411.9pt;">Question: In what country is Wilcza Jama, SokÃ³Å‚ka County?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.6.6.1.1">
<span class="ltx_p" id="A1.T10.1.6.6.1.1.1" style="width:411.9pt;">Document: Wilcza Jama is a village in the administrative district of Gmina SokÃ³Å‚ka, within SokÃ³Å‚ka County, Podlaskie Voivodeship, in north-eastern Poland, close to the border with Belarus.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.7.7.1.1">
<span class="ltx_p" id="A1.T10.1.7.7.1.1.1" style="width:411.9pt;">Answer: Yes.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.8.8.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.8.8.1.1">
<span class="ltx_p" id="A1.T10.1.8.8.1.1.1" style="width:411.9pt;">Question: What sport does 2004 Legg Mason Tennis Classic play?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.9.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.9.9.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.9.9.1.1">
<span class="ltx_p" id="A1.T10.1.9.9.1.1.1" style="width:411.9pt;">Document: The 2004 Legg Mason Tenis Classic was the 36th edition of this tennis tournament and was played on outdoor hard courts. The tournament was part of the International Series of the 2004 ATP Tour. It was held at the William H.G. FitzGerald Tennis Center in Washington, D.C. from August 16 through August 22, 2004.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.10.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.10.10.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.10.10.1.1">
<span class="ltx_p" id="A1.T10.1.10.10.1.1.1" style="width:411.9pt;">Answer: Yes.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.11.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.11.11.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.11.11.1.1">
<span class="ltx_p" id="A1.T10.1.11.11.1.1.1" style="width:411.9pt;">Question: Who is the author of Skin?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.12.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.12.12.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.12.12.1.1">
<span class="ltx_p" id="A1.T10.1.12.12.1.1.1" style="width:411.9pt;">Document: The Skin Weâ€™re In: A Year of Black Resistance and Power is a book by Desmond Cole published by Doubleday Canada in 2020. The Skin Weâ€™re In describes the struggle against racism in Canada during the year 2017, chronicling Coleâ€™s role as an anti-racist activist and the impact of systemic racism in Canadian society. Among the events it discusses are the aftermath of the assault of Dafonte Miller in late 2016 and Canada 150. The work argues that Canada is not immune to the anti-Black racism that characterizes American society. Due to an error by the publisher, the initial printing of the bookâ€™s cover did not include word BÌˆlackÃ¯n the subtitle. The mistake was later corrected. The book won the Toronto Book Award for 2020. In 2021, the book was nominated for the Shaughnessy Cohen Prize for Political Writing.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.13.13">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.13.13.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.13.13.1.1">
<span class="ltx_p" id="A1.T10.1.13.13.1.1.1" style="width:411.9pt;">Answer: No.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.14.14">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.14.14.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.14.14.1.1">
<span class="ltx_p" id="A1.T10.1.14.14.1.1.1" style="width:411.9pt;">Question: [question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.15.15">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A1.T10.1.15.15.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.15.15.1.1">
<span class="ltx_p" id="A1.T10.1.15.15.1.1.1" style="width:411.9pt;">Document: [document]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.16.16">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A1.T10.1.16.16.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T10.1.16.16.1.1">
<span class="ltx_p" id="A1.T10.1.16.16.1.1.1" style="width:411.9pt;">Answer:</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experiments</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Tasks, Datasets and Metrics</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1"><span class="ltx_text ltx_font_smallcaps" id="A2.SS1.p1.1.1">CRAG</span> was evaluated on four datasets, which are in public domain and licensed for research purposes, including:</p>
</div>
<div class="ltx_para" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1">PopQA</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Mallen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib19" title="">2023</a>)</cite> is a <em class="ltx_emph ltx_font_italic" id="A2.SS1.p2.1.2">short</em>-form generation task.
Generally, only one entity of factual knowledge is expected to be answered for each single question.
In our experiments, we exactly followed the setting in Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> which evaluated methods on a long-tail subset consisting of 1,399 rare entity queries whose monthly Wikipedia page views are less than 100.
Accuracy was adopted as the evaluation metric.</p>
</div>
<div class="ltx_para" id="A2.SS1.p3">
<p class="ltx_p" id="A2.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p3.1.1">Biography</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib20" title="">2023</a>)</cite> is a <em class="ltx_emph ltx_font_italic" id="A2.SS1.p3.1.2">long</em>-form generation task that is tasked to generate a detailed biography about a certain entity.
Following previous work, FactScoreÂ <cite class="ltx_cite ltx_citemacro_citep">(Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib20" title="">2023</a>)</cite> was adopted to evaluate the generated biographies.</p>
</div>
<div class="ltx_para" id="A2.SS1.p4">
<p class="ltx_p" id="A2.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p4.1.1">PubHealth</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib38" title="">2023a</a>)</cite> is a task in health care domain consisting of true-or-false questions.
Claims are represented about health with factual information, and the model is tasked to verify the authenticity and give the judgment.
Accuracy was adopted as the evaluation metric.</p>
</div>
<div class="ltx_para" id="A2.SS1.p5">
<p class="ltx_p" id="A2.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p5.1.1">Arc-Challenge</span>Â <cite class="ltx_cite ltx_citemacro_citep">(Bhakthavatsalam etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib4" title="">2021</a>)</cite> is a multiple-choice question task about some daily commonsense science phenomena.
Given a scientific event that occurs in daily life, the model is required to select the correct description among 3 or 4 optional choices.
Accuracy was adopted as the evaluation metric as well.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Experiments compute Resources</h3>
<div class="ltx_para" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">We used NVIDIA A800 80GB GPU for experiments. For LLaMA-2 (7B) generation, it occupies over 40GB memory during inference. For T5-large (0.77B) fine-tuning, it takes much less compared with LLaMA-2.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Implementation Details</h3>
<div class="ltx_para" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.SS3.p1.1.1">Retrieval Evaluator:</span> We fine-tuned the retrieval evaluator based on the lightweight T5-largeÂ <cite class="ltx_cite ltx_citemacro_citep">(Raffel etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib27" title="">2020</a>)</cite> pre-trained model.
The dataset we used is the version provided by Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite>.
Specifically, the original PopQA dataset consists of 14k samples, 1,399 of which were used for testing following Self-RAGÂ <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite>, and the remaining were used for fine-tuning to avoid information leakage.
Besides, the fine-tuned evaluator was transferred and also utilized on the Bio, Pub and ARC datasets during inference.
The label of positive samples was 1, while that of negative ones was -1.
At inference, the evaluator scored the relevance from -1 to 1 for each document.
The two confidence thresholds for triggering one of the three actions were set empirically.
Specifically, they were set as (0.59, -0.99) in PopQA, (0.5, -0.91) in PubQA and Arc-Challenge, as well as (0.95, -0.91) in Biography.</p>
</div>
<div class="ltx_para" id="A2.SS3.p2">
<p class="ltx_p" id="A2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="A2.SS3.p2.1.1">Internal Knowledge:</span>
To obtain fine-grained retrieval results, we segmented the retrieved results into internal strips.
If a retrieved result is as short as one or two sentences, it is regarded as an individual strip, otherwise, retrieval documents are required to be split into smaller units which generally consist of a few sentences according to the total length.
The scale is assumed to include an independent piece of information, and the filtering is based on the segments.
We directly adopted the evaluator again for knowledge strips filtering, and the top-k is set to 5, filter threshold as -0.5.</p>
</div>
<div class="ltx_para" id="A2.SS3.p3">
<p class="ltx_p" id="A2.SS3.p3.4"><span class="ltx_text ltx_font_bold" id="A2.SS3.p3.4.1">External Knowledge:</span> Google Search API was adopted to search for the relevant URLs, top-k is set to 5, and pages from Wikipedia will be added preferentially.
The searched web pages are generally in the form of HTML files, where content is split with special tokens like <math alttext="&lt;" class="ltx_Math" display="inline" id="A2.SS3.p3.1.m1.1"><semantics id="A2.SS3.p3.1.m1.1a"><mo id="A2.SS3.p3.1.m1.1.1" xref="A2.SS3.p3.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.1.m1.1b"><lt id="A2.SS3.p3.1.m1.1.1.cmml" xref="A2.SS3.p3.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.1.m1.1d">&lt;</annotation></semantics></math>p<math alttext="&gt;" class="ltx_Math" display="inline" id="A2.SS3.p3.2.m2.1"><semantics id="A2.SS3.p3.2.m2.1a"><mo id="A2.SS3.p3.2.m2.1.1" xref="A2.SS3.p3.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.2.m2.1b"><gt id="A2.SS3.p3.2.m2.1.1.cmml" xref="A2.SS3.p3.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.2.m2.1d">&gt;</annotation></semantics></math> and <math alttext="&lt;" class="ltx_Math" display="inline" id="A2.SS3.p3.3.m3.1"><semantics id="A2.SS3.p3.3.m3.1a"><mo id="A2.SS3.p3.3.m3.1.1" xref="A2.SS3.p3.3.m3.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.3.m3.1b"><lt id="A2.SS3.p3.3.m3.1.1.cmml" xref="A2.SS3.p3.3.m3.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.3.m3.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.3.m3.1d">&lt;</annotation></semantics></math>/p<math alttext="&gt;" class="ltx_Math" display="inline" id="A2.SS3.p3.4.m4.1"><semantics id="A2.SS3.p3.4.m4.1a"><mo id="A2.SS3.p3.4.m4.1.1" xref="A2.SS3.p3.4.m4.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.4.m4.1b"><gt id="A2.SS3.p3.4.m4.1.1.cmml" xref="A2.SS3.p3.4.m4.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.4.m4.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.4.m4.1d">&gt;</annotation></semantics></math>.
Thus an extra segmentation like the knowledge refinement is not required, related knowledge paragraphs can be directly selected with the evaluator similar to internal knowledge.
In this way, the accuracy of the search outcomes can be ensured without compromising the quality and relevance of the information used for generation.</p>
</div>
<div class="ltx_para" id="A2.SS3.p4">
<p class="ltx_p" id="A2.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="A2.SS3.p4.1.1">Generator:</span> As <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p4.1.2">CRAG</span> is a plug-and-play method, all generation models that can be utilized in RAG fit our approach as well.
To be consistent with baselines for comparison, we adopted LLaMA2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib35" title="">2023b</a>)</cite> for the generation.
We first introduced the <em class="ltx_emph ltx_font_italic" id="A2.SS3.p4.1.3">LLaMA2-hf-7b</em> from huggingface to generate responses.
Since Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> fine-tuned LLaMA2 and reached a new state-of-the-art performance on several tasks, we further utilized the launched model, <em class="ltx_emph ltx_font_italic" id="A2.SS3.p4.1.4">SelfRAG-LLaMA2-7b</em>, as a new generator to be consistent with their work and study the specific improvement of our method.</p>
</div>
<div class="ltx_para" id="A2.SS3.p5">
<p class="ltx_p" id="A2.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="A2.SS3.p5.1.1">Self-CRAG:</span>
To demonstrate that our plug-and-play approach can be utilized in other concurrent studies, we specifically designed to insert our <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p5.1.2">CRAG</span> into the Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Asai etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#bib.bib2" title="">2024</a>)</cite> framework and named it Self-CRAG.
Self-RAG is an advanced RAG approach that introduces a critic model to decide whether to retrieve and which retrieved document to be referred for generation.
It meets our demand for deciding which action to be triggered, thus we replaced the retrieved items in Self-RAG with our processed internal knowledge for <span class="ltx_text ltx_font_typewriter" id="A2.SS3.p5.1.3">Correct</span>, external knowledge for <span class="ltx_text ltx_font_typewriter" id="A2.SS3.p5.1.4">Incorrect</span>, and combined knowledge for <span class="ltx_text ltx_font_typewriter" id="A2.SS3.p5.1.5">Ambiguous</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>More Detailed Results</h3>
<div class="ltx_para" id="A2.SS4.p1">
<p class="ltx_p" id="A2.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="A2.SS4.p1.1.1">Ablation Study:</span> The following results in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2401.15884v3#A2.T11" title="Table 11 â€£ B.4 More Detailed Results â€£ Appendix B Experiments â€£ 6 Conclusion &amp; Limitation â€£ 5.8 Computational Overhead Analysis â€£ 5.7 Consistent Supplementation of Web Search Knowledge â€£ 5.6 Robustness to Retrieval Performance â€£ 5.5 Accuracy of the Retrieval Evaluator â€£ The impact of each knowledge utilization operation. â€£ 5.4 Ablation Study â€£ 5.3 Results â€£ 5.2 Baselines â€£ 5.1 Tasks, Datasets and Metrics â€£ 5 Experiments â€£ Corrective Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">11</span></a> demonstrate the ablation study by triggering one action only for all instances.</p>
</div>
<figure class="ltx_table" id="A2.T11">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Ablation study for removing only a single action on the PopQA dataset in terms of accuracy.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T11.1" style="width:424.9pt;height:269pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(84.5pt,-53.5pt) scale(1.66077412781199,1.66077412781199) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T11.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T11.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A2.T11.1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T11.1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">LLaMA2-hf-7b</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T11.1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">SelfRAG-LLaMA2-7b</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T11.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T11.1.1.2.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_smallcaps" id="A2.T11.1.1.2.1.1.1">CRAG</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.1.2.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.1.2.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.8</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T11.1.1.3.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="A2.T11.1.1.3.2.1.1">\hdashline</span>Â  only <span class="ltx_text ltx_font_typewriter" id="A2.T11.1.1.3.2.1.2">Correct</span>
</th>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.3.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">52.4</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.3.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">56.7</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T11.1.1.4.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">only <span class="ltx_text ltx_font_typewriter" id="A2.T11.1.1.4.3.1.1">Incorrect</span>
</th>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.4.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">47.0</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.4.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">48.5</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T11.1.1.5.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">only <span class="ltx_text ltx_font_typewriter" id="A2.T11.1.1.5.4.1.1">Ambiguous</span>
</th>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.5.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">52.7</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.5.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">58.0</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T11.1.1.6.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-CRAG</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.1.6.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">49.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T11.1.1.6.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">61.8</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T11.1.1.7.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_ERROR undefined" id="A2.T11.1.1.7.6.1.1">\hdashline</span>Â  only <span class="ltx_text ltx_font_typewriter" id="A2.T11.1.1.7.6.1.2">Correct</span>
</th>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.7.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">48.6</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.7.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">57.2</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T11.1.1.8.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">only <span class="ltx_text ltx_font_typewriter" id="A2.T11.1.1.8.7.1.1">Incorrect</span>
</th>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.8.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">40.8</td>
<td class="ltx_td ltx_align_center" id="A2.T11.1.1.8.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">53.3</td>
</tr>
<tr class="ltx_tr" id="A2.T11.1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A2.T11.1.1.9.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">only <span class="ltx_text ltx_font_typewriter" id="A2.T11.1.1.9.8.1.1">Ambiguous</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T11.1.1.9.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">44.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T11.1.1.9.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">59.8</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.5 </span>Results on PubHealth and Arc-Challenge</h3>
<div class="ltx_para" id="A2.SS5.p1">
<p class="ltx_p" id="A2.SS5.p1.1">It is worth mentioning that the performance on PubHealth based on <em class="ltx_emph ltx_font_italic" id="A2.SS5.p1.1.1">LLaMA2-hf-7b</em> was much worse than others.
We studied these cases and found that <em class="ltx_emph ltx_font_italic" id="A2.SS5.p1.1.2">LLaMA2-hf-7b</em> is relatively weak in instruction comprehension.
Most of the cases fail to generate <span class="ltx_text ltx_font_typewriter" id="A2.SS5.p1.1.3">True</span> or <span class="ltx_text ltx_font_typewriter" id="A2.SS5.p1.1.4">False</span> in such a binary-question task, resulting in a low accuracy during the evaluation.
This situation somewhat happens in Arc-Challenge as well, when the model is tasked to generate the index of a candidate.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Oct  7 02:17:00 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
