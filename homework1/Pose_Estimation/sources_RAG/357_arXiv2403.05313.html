<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation</title>
<!--Generated on Fri Mar  8 13:45:12 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.05313v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S1" title="1 Introduction ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S2" title="2 Retrieval Augmented Thoughts ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Retrieval Augmented Thoughts</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S2.SS1" title="2.1 Preliminary ‣ 2 Retrieval Augmented Thoughts ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Preliminary</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S2.SS2" title="2.2 Our Approach ‣ 2 Retrieval Augmented Thoughts ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Our Approach</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3" title="3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS1" title="3.1 Experimental Setups ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setups</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS1.SSS0.Px1" title="Evaluation Metrics ‣ 3.1 Experimental Setups ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS1.SSS0.Px2" title="Baselines ‣ 3.1 Experimental Setups ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS1.SSS0.Px3" title="RAG Settings ‣ 3.1 Experimental Setups ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">RAG Settings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS2" title="3.2 Results ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS3" title="3.3 Case Analysis ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Case Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS4" title="3.4 Ablation Study ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS4.SSS0.Px1" title="Ablation on retrieval in ‣ 3.4 Ablation Study ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Ablation on retrieval in <abbr class="ltx_glossaryref" title=""></abbr></span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS4.SSS0.Px2" title="Ablation on causal reasoning in ‣ 3.4 Ablation Study ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Ablation on causal reasoning in <abbr class="ltx_glossaryref" title=""></abbr></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.SS5" title="3.5 Robustness of ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Robustness of <abbr class="ltx_glossaryref" title=""></abbr></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S4" title="4 Related Works ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S4.SS0.SSS0.Px1" title="Retrieval-augmented Generation (RAG) ‣ 4 Related Works ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Retrieval-augmented Generation (RAG)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S4.SS0.SSS0.Px2" title="Reasoning-enhanced RAG ‣ 4 Related Works ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Reasoning-enhanced RAG</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S4.SS0.SSS0.Px3" title="Language Model for Reasoning ‣ 4 Related Works ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Language Model for Reasoning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S5" title="5 Conclusion ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1" title="Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Task Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS1" title="A.1 Code Generation ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Code Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS1.SSS0.Px1" title="Benchmarks ‣ A.1 Code Generation ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS1.SSS0.Px2" title="Metrics ‣ A.1 Code Generation ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS1.SSS0.Px3" title="Baselines ‣ A.1 Code Generation ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS1.SSS0.Px4" title="RAG Settings ‣ A.1 Code Generation ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">RAG Settings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS2" title="A.2 Mathematical Reasoning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Mathematical Reasoning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS2.SSS0.Px1" title="Benchmarks ‣ A.2 Mathematical Reasoning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS2.SSS0.Px2" title="Metrics and Baselines ‣ A.2 Mathematical Reasoning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Metrics and Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS3" title="A.3 Embodied Planning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Embodied Planning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS3.SSS0.Px1" title="Benchmarks ‣ A.3 Embodied Planning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS3.SSS0.Px2" title="RAG Settings ‣ A.3 Embodied Planning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">RAG Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS3.SSS0.Px3" title="Evaluation Metrics ‣ A.3 Embodied Planning ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Evaluation Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS4" title="A.4 Creative Writing ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Creative Writing</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS4.SSS0.Px1" title="Benchmarks ‣ A.4 Creative Writing ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS4.SSS0.Px2" title="RAG Settings ‣ A.4 Creative Writing ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">RAG Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A1.SS4.SSS0.Px3" title="Baselines and Evaluations ‣ A.4 Creative Writing ‣ Appendix A Task Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title">Baselines and Evaluations</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A2" title="Appendix B Prompt Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Prompt Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A3" title="Appendix C TrueSkill Evaluation Framework ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>TrueSkill Evaluation Framework</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A4" title="Appendix D Disscussions on Benchmark Contamination ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Disscussions on Benchmark Contamination</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A5" title="Appendix E More Results ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>More Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A5.SS1" title="E.1 Emboddied Planning ‣ Appendix E More Results ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Emboddied Planning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A5.SS2" title="E.2 Creative Writing ‣ Appendix E More Results ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Creative Writing</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: etoc</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2403.05313v1 [cs.CL] 08 Mar 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line"><span class="ltx_ERROR undefined" id="id1">\pdftrailerid</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">redacted











 




























































<span class="ltx_ERROR undefined" id="p1.1.1">\reportnumber</span>
<span class="ltx_ERROR undefined" id="p1.1.2">\correspondingauthor</span>
Yitao Liang <span class="ltx_text ltx_font_typewriter" id="p1.1.3">yitaol@pku.edu.cn
<br class="ltx_break"/></span>&lt;Zihao Wang&gt; <span class="ltx_text ltx_font_typewriter" id="p1.1.4">zhwang@stu.pku.edu.cn</span> &lt;Anji Liu&gt; <span class="ltx_text ltx_font_typewriter" id="p1.1.5">liuanji@cs.ucla.edu</span>
&lt;Haowei Lin&gt; <span class="ltx_text ltx_font_typewriter" id="p1.1.6">linhaowei@pku.edu.cn</span> 
<br class="ltx_break"/>&lt;Jiaqi Li&gt; <span class="ltx_text ltx_font_typewriter" id="p1.1.7">ljqjane@gmail.com</span> &lt;Xiaojian Ma&gt; <span class="ltx_text ltx_font_typewriter" id="p1.1.8">xiaojian.ma@ucla.edu</span>
</p>
</div>
<h1 class="ltx_title ltx_title_document">
<img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="23" id="id1.g1" src="x1.png" width="30"/> RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zihao Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Peking University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anji Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of California, Los Angeles
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haowei Lin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Peking University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiaqi Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beijing Institute for General Artificial Intelligence
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaojian Ma
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beijing Institute for General Artificial Intelligence
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yitao Liang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Peking University
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">We explore how iterative revising a chain of thoughts with the help of information retrieval significantly improves large language models’ reasoning and generation ability in long-horizon generation tasks, while hugely mitigating hallucination.
In particular, the proposed method — <em class="ltx_emph ltx_font_italic" id="id2.id1.1">retrieval-augmented thoughts</em> (RAT)
— revises each thought step one by one with retrieved information relevant to the task query, the current and the past thought steps, after the initial zero-shot CoT is generated.
Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA-7b substantially improves their performances on various long-horizon generation tasks; on average of relatively increasing rating scores by 13.63% on code generation, 16.96% on mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task planning.</p>
<p class="ltx_p" id="id3.id2">The demo page can be found in <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://craftjarvis.github.io/RAT" title="">https://craftjarvis.github.io/RAT</a>.</p>
</div>
<figure class="ltx_figure" id="S0.F1" lang="en"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="505" id="S0.F1.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
<span class="ltx_text ltx_font_bold" id="S0.F1.12.1">Pipeline of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>.</span> Given a task prompt (denoted as <math alttext="\mathit{I}" class="ltx_Math" display="inline" id="S0.F1.5.m1.1"><semantics id="S0.F1.5.m1.1b"><mi id="S0.F1.5.m1.1.1" xref="S0.F1.5.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S0.F1.5.m1.1c"><ci id="S0.F1.5.m1.1.1.cmml" xref="S0.F1.5.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.5.m1.1d">\mathit{I}</annotation><annotation encoding="application/x-llamapun" id="S0.F1.5.m1.1e">italic_I</annotation></semantics></math> in the figure), <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> starts from initial step-by-step thoughts (<math alttext="T_{1},T_{2},\cdots,T_{n}" class="ltx_Math" display="inline" id="S0.F1.6.m2.4"><semantics id="S0.F1.6.m2.4b"><mrow id="S0.F1.6.m2.4.4.3" xref="S0.F1.6.m2.4.4.4.cmml"><msub id="S0.F1.6.m2.2.2.1.1" xref="S0.F1.6.m2.2.2.1.1.cmml"><mi id="S0.F1.6.m2.2.2.1.1.2" xref="S0.F1.6.m2.2.2.1.1.2.cmml">T</mi><mn id="S0.F1.6.m2.2.2.1.1.3" xref="S0.F1.6.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S0.F1.6.m2.4.4.3.4" xref="S0.F1.6.m2.4.4.4.cmml">,</mo><msub id="S0.F1.6.m2.3.3.2.2" xref="S0.F1.6.m2.3.3.2.2.cmml"><mi id="S0.F1.6.m2.3.3.2.2.2" xref="S0.F1.6.m2.3.3.2.2.2.cmml">T</mi><mn id="S0.F1.6.m2.3.3.2.2.3" xref="S0.F1.6.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S0.F1.6.m2.4.4.3.5" xref="S0.F1.6.m2.4.4.4.cmml">,</mo><mi id="S0.F1.6.m2.1.1" mathvariant="normal" xref="S0.F1.6.m2.1.1.cmml">⋯</mi><mo id="S0.F1.6.m2.4.4.3.6" xref="S0.F1.6.m2.4.4.4.cmml">,</mo><msub id="S0.F1.6.m2.4.4.3.3" xref="S0.F1.6.m2.4.4.3.3.cmml"><mi id="S0.F1.6.m2.4.4.3.3.2" xref="S0.F1.6.m2.4.4.3.3.2.cmml">T</mi><mi id="S0.F1.6.m2.4.4.3.3.3" xref="S0.F1.6.m2.4.4.3.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S0.F1.6.m2.4c"><list id="S0.F1.6.m2.4.4.4.cmml" xref="S0.F1.6.m2.4.4.3"><apply id="S0.F1.6.m2.2.2.1.1.cmml" xref="S0.F1.6.m2.2.2.1.1"><csymbol cd="ambiguous" id="S0.F1.6.m2.2.2.1.1.1.cmml" xref="S0.F1.6.m2.2.2.1.1">subscript</csymbol><ci id="S0.F1.6.m2.2.2.1.1.2.cmml" xref="S0.F1.6.m2.2.2.1.1.2">𝑇</ci><cn id="S0.F1.6.m2.2.2.1.1.3.cmml" type="integer" xref="S0.F1.6.m2.2.2.1.1.3">1</cn></apply><apply id="S0.F1.6.m2.3.3.2.2.cmml" xref="S0.F1.6.m2.3.3.2.2"><csymbol cd="ambiguous" id="S0.F1.6.m2.3.3.2.2.1.cmml" xref="S0.F1.6.m2.3.3.2.2">subscript</csymbol><ci id="S0.F1.6.m2.3.3.2.2.2.cmml" xref="S0.F1.6.m2.3.3.2.2.2">𝑇</ci><cn id="S0.F1.6.m2.3.3.2.2.3.cmml" type="integer" xref="S0.F1.6.m2.3.3.2.2.3">2</cn></apply><ci id="S0.F1.6.m2.1.1.cmml" xref="S0.F1.6.m2.1.1">⋯</ci><apply id="S0.F1.6.m2.4.4.3.3.cmml" xref="S0.F1.6.m2.4.4.3.3"><csymbol cd="ambiguous" id="S0.F1.6.m2.4.4.3.3.1.cmml" xref="S0.F1.6.m2.4.4.3.3">subscript</csymbol><ci id="S0.F1.6.m2.4.4.3.3.2.cmml" xref="S0.F1.6.m2.4.4.3.3.2">𝑇</ci><ci id="S0.F1.6.m2.4.4.3.3.3.cmml" xref="S0.F1.6.m2.4.4.3.3.3">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.6.m2.4d">T_{1},T_{2},\cdots,T_{n}</annotation><annotation encoding="application/x-llamapun" id="S0.F1.6.m2.4e">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>) produced by an LLM in zero-shot (“let’s think step by step”). Some thought steps (such as <math alttext="T_{1}" class="ltx_Math" display="inline" id="S0.F1.7.m3.1"><semantics id="S0.F1.7.m3.1b"><msub id="S0.F1.7.m3.1.1" xref="S0.F1.7.m3.1.1.cmml"><mi id="S0.F1.7.m3.1.1.2" xref="S0.F1.7.m3.1.1.2.cmml">T</mi><mn id="S0.F1.7.m3.1.1.3" xref="S0.F1.7.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S0.F1.7.m3.1c"><apply id="S0.F1.7.m3.1.1.cmml" xref="S0.F1.7.m3.1.1"><csymbol cd="ambiguous" id="S0.F1.7.m3.1.1.1.cmml" xref="S0.F1.7.m3.1.1">subscript</csymbol><ci id="S0.F1.7.m3.1.1.2.cmml" xref="S0.F1.7.m3.1.1.2">𝑇</ci><cn id="S0.F1.7.m3.1.1.3.cmml" type="integer" xref="S0.F1.7.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.7.m3.1d">T_{1}</annotation><annotation encoding="application/x-llamapun" id="S0.F1.7.m3.1e">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> in the figure) may be <span class="ltx_text" id="S0.F1.13.2" style="color:#FF0000;">flawed</span> due to hallucination. <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> iteratively revises each thought step <math alttext="(T^{\star}_{1},T^{\star}_{2},\cdots,T^{\star}_{i-1},T_{i})" class="ltx_Math" display="inline" id="S0.F1.8.m4.5"><semantics id="S0.F1.8.m4.5b"><mrow id="S0.F1.8.m4.5.5.4" xref="S0.F1.8.m4.5.5.5.cmml"><mo id="S0.F1.8.m4.5.5.4.5" stretchy="false" xref="S0.F1.8.m4.5.5.5.cmml">(</mo><msubsup id="S0.F1.8.m4.2.2.1.1" xref="S0.F1.8.m4.2.2.1.1.cmml"><mi id="S0.F1.8.m4.2.2.1.1.2.2" xref="S0.F1.8.m4.2.2.1.1.2.2.cmml">T</mi><mn id="S0.F1.8.m4.2.2.1.1.3" xref="S0.F1.8.m4.2.2.1.1.3.cmml">1</mn><mo id="S0.F1.8.m4.2.2.1.1.2.3" xref="S0.F1.8.m4.2.2.1.1.2.3.cmml">⋆</mo></msubsup><mo id="S0.F1.8.m4.5.5.4.6" xref="S0.F1.8.m4.5.5.5.cmml">,</mo><msubsup id="S0.F1.8.m4.3.3.2.2" xref="S0.F1.8.m4.3.3.2.2.cmml"><mi id="S0.F1.8.m4.3.3.2.2.2.2" xref="S0.F1.8.m4.3.3.2.2.2.2.cmml">T</mi><mn id="S0.F1.8.m4.3.3.2.2.3" xref="S0.F1.8.m4.3.3.2.2.3.cmml">2</mn><mo id="S0.F1.8.m4.3.3.2.2.2.3" xref="S0.F1.8.m4.3.3.2.2.2.3.cmml">⋆</mo></msubsup><mo id="S0.F1.8.m4.5.5.4.7" xref="S0.F1.8.m4.5.5.5.cmml">,</mo><mi id="S0.F1.8.m4.1.1" mathvariant="normal" xref="S0.F1.8.m4.1.1.cmml">⋯</mi><mo id="S0.F1.8.m4.5.5.4.8" xref="S0.F1.8.m4.5.5.5.cmml">,</mo><msubsup id="S0.F1.8.m4.4.4.3.3" xref="S0.F1.8.m4.4.4.3.3.cmml"><mi id="S0.F1.8.m4.4.4.3.3.2.2" xref="S0.F1.8.m4.4.4.3.3.2.2.cmml">T</mi><mrow id="S0.F1.8.m4.4.4.3.3.3" xref="S0.F1.8.m4.4.4.3.3.3.cmml"><mi id="S0.F1.8.m4.4.4.3.3.3.2" xref="S0.F1.8.m4.4.4.3.3.3.2.cmml">i</mi><mo id="S0.F1.8.m4.4.4.3.3.3.1" xref="S0.F1.8.m4.4.4.3.3.3.1.cmml">−</mo><mn id="S0.F1.8.m4.4.4.3.3.3.3" xref="S0.F1.8.m4.4.4.3.3.3.3.cmml">1</mn></mrow><mo id="S0.F1.8.m4.4.4.3.3.2.3" xref="S0.F1.8.m4.4.4.3.3.2.3.cmml">⋆</mo></msubsup><mo id="S0.F1.8.m4.5.5.4.9" xref="S0.F1.8.m4.5.5.5.cmml">,</mo><msub id="S0.F1.8.m4.5.5.4.4" xref="S0.F1.8.m4.5.5.4.4.cmml"><mi id="S0.F1.8.m4.5.5.4.4.2" xref="S0.F1.8.m4.5.5.4.4.2.cmml">T</mi><mi id="S0.F1.8.m4.5.5.4.4.3" xref="S0.F1.8.m4.5.5.4.4.3.cmml">i</mi></msub><mo id="S0.F1.8.m4.5.5.4.10" stretchy="false" xref="S0.F1.8.m4.5.5.5.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S0.F1.8.m4.5c"><vector id="S0.F1.8.m4.5.5.5.cmml" xref="S0.F1.8.m4.5.5.4"><apply id="S0.F1.8.m4.2.2.1.1.cmml" xref="S0.F1.8.m4.2.2.1.1"><csymbol cd="ambiguous" id="S0.F1.8.m4.2.2.1.1.1.cmml" xref="S0.F1.8.m4.2.2.1.1">subscript</csymbol><apply id="S0.F1.8.m4.2.2.1.1.2.cmml" xref="S0.F1.8.m4.2.2.1.1"><csymbol cd="ambiguous" id="S0.F1.8.m4.2.2.1.1.2.1.cmml" xref="S0.F1.8.m4.2.2.1.1">superscript</csymbol><ci id="S0.F1.8.m4.2.2.1.1.2.2.cmml" xref="S0.F1.8.m4.2.2.1.1.2.2">𝑇</ci><ci id="S0.F1.8.m4.2.2.1.1.2.3.cmml" xref="S0.F1.8.m4.2.2.1.1.2.3">⋆</ci></apply><cn id="S0.F1.8.m4.2.2.1.1.3.cmml" type="integer" xref="S0.F1.8.m4.2.2.1.1.3">1</cn></apply><apply id="S0.F1.8.m4.3.3.2.2.cmml" xref="S0.F1.8.m4.3.3.2.2"><csymbol cd="ambiguous" id="S0.F1.8.m4.3.3.2.2.1.cmml" xref="S0.F1.8.m4.3.3.2.2">subscript</csymbol><apply id="S0.F1.8.m4.3.3.2.2.2.cmml" xref="S0.F1.8.m4.3.3.2.2"><csymbol cd="ambiguous" id="S0.F1.8.m4.3.3.2.2.2.1.cmml" xref="S0.F1.8.m4.3.3.2.2">superscript</csymbol><ci id="S0.F1.8.m4.3.3.2.2.2.2.cmml" xref="S0.F1.8.m4.3.3.2.2.2.2">𝑇</ci><ci id="S0.F1.8.m4.3.3.2.2.2.3.cmml" xref="S0.F1.8.m4.3.3.2.2.2.3">⋆</ci></apply><cn id="S0.F1.8.m4.3.3.2.2.3.cmml" type="integer" xref="S0.F1.8.m4.3.3.2.2.3">2</cn></apply><ci id="S0.F1.8.m4.1.1.cmml" xref="S0.F1.8.m4.1.1">⋯</ci><apply id="S0.F1.8.m4.4.4.3.3.cmml" xref="S0.F1.8.m4.4.4.3.3"><csymbol cd="ambiguous" id="S0.F1.8.m4.4.4.3.3.1.cmml" xref="S0.F1.8.m4.4.4.3.3">subscript</csymbol><apply id="S0.F1.8.m4.4.4.3.3.2.cmml" xref="S0.F1.8.m4.4.4.3.3"><csymbol cd="ambiguous" id="S0.F1.8.m4.4.4.3.3.2.1.cmml" xref="S0.F1.8.m4.4.4.3.3">superscript</csymbol><ci id="S0.F1.8.m4.4.4.3.3.2.2.cmml" xref="S0.F1.8.m4.4.4.3.3.2.2">𝑇</ci><ci id="S0.F1.8.m4.4.4.3.3.2.3.cmml" xref="S0.F1.8.m4.4.4.3.3.2.3">⋆</ci></apply><apply id="S0.F1.8.m4.4.4.3.3.3.cmml" xref="S0.F1.8.m4.4.4.3.3.3"><minus id="S0.F1.8.m4.4.4.3.3.3.1.cmml" xref="S0.F1.8.m4.4.4.3.3.3.1"></minus><ci id="S0.F1.8.m4.4.4.3.3.3.2.cmml" xref="S0.F1.8.m4.4.4.3.3.3.2">𝑖</ci><cn id="S0.F1.8.m4.4.4.3.3.3.3.cmml" type="integer" xref="S0.F1.8.m4.4.4.3.3.3.3">1</cn></apply></apply><apply id="S0.F1.8.m4.5.5.4.4.cmml" xref="S0.F1.8.m4.5.5.4.4"><csymbol cd="ambiguous" id="S0.F1.8.m4.5.5.4.4.1.cmml" xref="S0.F1.8.m4.5.5.4.4">subscript</csymbol><ci id="S0.F1.8.m4.5.5.4.4.2.cmml" xref="S0.F1.8.m4.5.5.4.4.2">𝑇</ci><ci id="S0.F1.8.m4.5.5.4.4.3.cmml" xref="S0.F1.8.m4.5.5.4.4.3">𝑖</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.8.m4.5d">(T^{\star}_{1},T^{\star}_{2},\cdots,T^{\star}_{i-1},T_{i})</annotation><annotation encoding="application/x-llamapun" id="S0.F1.8.m4.5e">( italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> using RAG from an external knowledge base (denoted as <span class="ltx_text ltx_font_typewriter" id="S0.F1.14.3">Library</span>). Detailed prompting strategy can be found in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#S2.SS2" title="2.2 Our Approach ‣ 2 Retrieval Augmented Thoughts ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Section 2.2</span></a>.
</figcaption>
</figure>
<figure class="ltx_figure" id="S0.F2" lang="en"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="490" id="S0.F2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
<span class="ltx_text ltx_font_bold" id="S0.F2.5.1">Top</span>: An example of different LLM reasoning methods on creative generation tasks.
<span class="ltx_text" id="S0.F2.6.2" style="color:#FF0000;">Red</span> text indicates errors or illusions in the text generated by LLM, while <span class="ltx_text" id="S0.F2.7.3" style="color:#008000;">green</span> text represents correct generation. Methods without RAG often generate incorrect information with hallucination, classical RAG is highly related to retrieved content with a loose structure, and RAT-generated texts perform best in terms of accuracy and completeness.
<span class="ltx_text ltx_font_bold" id="S0.F2.8.4">Bottom</span>: The quantitative performance comparison for different LLM reasoning methods on complex embodied planning, mathematical reasoning, code generation, and creative generation tasks. Our <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> outperforms all the baselines on all tasks.
</figcaption>
</figure>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><span class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_long">Large Language Models</span></span> (<abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr>) have achieved fruitful progress on various natural language reasoning tasks <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib56" title="">2022</a>; Yao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib58" title="">2022</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib53" title="">2023a</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib66" title="">2023</a>; Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib6" title="">2020</a>)</cite>, especially when combining large-scale models  <cite class="ltx_cite ltx_citemacro_citep">(Team, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib47" title="">2022</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib39" title="">2023</a>)</cite> with sophisticated prompting strategies, notably  <span class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_long">chain-of-thought</span></span> (<abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr>) prompting <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib56" title="">2022</a>; Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib26" title="">2022</a>)</cite>. However, there have been increasing concerns about the factual correctness of <abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr> reasoning, citing the possible hallucinations in model responses <cite class="ltx_cite ltx_citemacro_citep">(Rawte et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib41" title="">2023</a>)</cite> or the intermediate reasoning paths, <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">i.e</em>.<span class="ltx_text" id="S1.p1.1.2"></span> <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr>s <cite class="ltx_cite ltx_citemacro_citep">(Dhuliawala et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib13" title="">2023</a>)</cite>. This issue becomes more significant when it comes to zero-shot <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> prompting, aka. “let’s think step-by-step” <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib26" title="">2022</a>)</cite> and long-horizon generation tasks that require multi-step and context-aware reasoning, including code generation, task planning, mathematical reasoning, <em class="ltx_emph ltx_font_italic" id="S1.p1.1.3">etc</em>. Factually valid intermediate thoughts could be critical to the successful completion of these tasks.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Several prompting techniques have been proposed to mitigate this issue, one promising direction,  <span class="ltx_glossaryref" title="Retrieval Augmented Generation"><span class="ltx_text ltx_glossary_long">Retrieval Augmented Generation</span></span> (<abbr class="ltx_glossaryref" title="Retrieval Augmented Generation"><span class="ltx_text ltx_glossary_short">RAG</span></abbr>) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib28" title="">2020b</a>)</cite> seeks insights from human reasoning <cite class="ltx_cite ltx_citemacro_citep">(Holyoak and Morrison, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib21" title="">2012</a>)</cite>, and utilizes retrieved information to facilitate more factually grounded reasoning.
In this paper, we explore how to synergize <abbr class="ltx_glossaryref" title="Retrieval Augmented Generation"><span class="ltx_text ltx_glossary_short">RAG</span></abbr> with sophisticated long-horizon reasoning. Our intuition is that the hallucination within the intermediate reasoning process could be alleviated through the help of outside knowledge. The resulting prompting strategy, <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">retrieval-augmented thoughts</span> (RAT), is illustrated in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#S0.F1" title="Figure 1 ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>. Our strategy comprises two key ideas. Firstly, the initial zero-shot <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> produced by <abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr> along with the original task prompt will be used as queries to retrieve the information that could help revise the possibly flawed <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr>. Secondly, instead of retrieving and revising with the full <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> and producing the final response at once, we devise a progressive approach, where <abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr> produce the response step-by-step following the <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> (a series of subtasks), and only the current thought step will be revised based on the information retrieved with task prompt, the current and the past CoTs. This strategy can be an analogy to the human reasoning process: we utilize outside knowledge to adjust our step-by-step thinking during complex long-horizon problem-solving <cite class="ltx_cite ltx_citemacro_citep">(Holyoak and Morrison, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib21" title="">2012</a>)</cite>. A comparison of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> and counterparts can be found in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#S0.F2" title="Figure 2 ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We evaluate <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> on a wide collection of challenging long-horizon tasks, including code generation, mathematical reasoning, embodied task planning, and creative writing. We employ several <abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr> of varied scales: GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib6" title="">2020</a>)</cite>, GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib39" title="">2023</a>)</cite>, CodeLLaMA-7b <cite class="ltx_cite ltx_citemacro_citep">(Rozière et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib44" title="">2023</a>)</cite>. The results indicate that combing <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> with these <abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr> elicits strong advantages over vanilla <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> prompting and <abbr class="ltx_glossaryref" title="Retrieval Augmented Generation"><span class="ltx_text ltx_glossary_short">RAG</span></abbr> approaches. In particular, we observe new state-of-the-art level of performances across our selection of tasks: 1) code generation: HumanEval (+20.94%), HumanEval+ (+18.89%), MBPP (+14.83%), MBPP+ (+1.86%); 2) mathematical reasoning problems: GSM8K (+8.36%), and GSMHard (+31.37%); 3) Minecraft task planning (2.96 times on executability and +51.94% on plausibility); 4) creative writing (+19.19% on human score). Our additional ablation studies further confirm the crucial roles played by the two key ingredients of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>: revising <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> using <abbr class="ltx_glossaryref" title="Retrieval Augmented Generation"><span class="ltx_text ltx_glossary_short">RAG</span></abbr> and progressive revision &amp; generation. This work reveals how can <abbr class="ltx_glossaryref" title="Large Language Models"><span class="ltx_text ltx_glossary_short">LLMs</span></abbr> revise their reasoning process in a zero-shot fashion with the help of outside knowledge, just as what humans do.</p>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Retrieval Augmented Thoughts</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our goal is to support long-horizon reasoning and generation while mitigating hallucination when using LLMs. To have satisfying performance on long-horizon tasks, two ingredients are indispensable. Firstly, access to factual information can be facilitated by retrieval. Secondly, appropriate intermediate steps that outline a scratchpad to finish complex tasks, can be facilitated by CoT. Yet, a naive combination of the two would not necessarily yield improvements. Two questions still persist: (1) what is relevant information to retrieve; (2) how to effectively correct reasoning steps with relevant factual information. To better appreciate our method and why our method can address these two questions, we first provide a brief preliminary introduction of RAG and CoT.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Retrieval augmented thoughts (RAT)</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="algx1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l1.1.1.1" style="font-size:80%;">1:</span></span>Task Prompt <math alttext="I" class="ltx_Math" display="inline" id="algx1.l1.m1.1"><semantics id="algx1.l1.m1.1a"><mi id="algx1.l1.m1.1.1" xref="algx1.l1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="algx1.l1.m1.1b"><ci id="algx1.l1.m1.1.1.cmml" xref="algx1.l1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l1.m1.1c">I</annotation><annotation encoding="application/x-llamapun" id="algx1.l1.m1.1d">italic_I</annotation></semantics></math>, Autoregressive Large Language Model <math alttext="p_{\theta}" class="ltx_Math" display="inline" id="algx1.l1.m2.1"><semantics id="algx1.l1.m2.1a"><msub id="algx1.l1.m2.1.1" xref="algx1.l1.m2.1.1.cmml"><mi id="algx1.l1.m2.1.1.2" xref="algx1.l1.m2.1.1.2.cmml">p</mi><mi id="algx1.l1.m2.1.1.3" xref="algx1.l1.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="algx1.l1.m2.1b"><apply id="algx1.l1.m2.1.1.cmml" xref="algx1.l1.m2.1.1"><csymbol cd="ambiguous" id="algx1.l1.m2.1.1.1.cmml" xref="algx1.l1.m2.1.1">subscript</csymbol><ci id="algx1.l1.m2.1.1.2.cmml" xref="algx1.l1.m2.1.1.2">𝑝</ci><ci id="algx1.l1.m2.1.1.3.cmml" xref="algx1.l1.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l1.m2.1c">p_{\theta}</annotation><annotation encoding="application/x-llamapun" id="algx1.l1.m2.1d">italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="algx1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l2.3.1.1" style="font-size:80%;">2:</span></span><math alttext="T=\{T_{1},T_{2},\ldots,T_{n}\}\leftarrow p_{\theta}(\cdot|I)" class="ltx_math_unparsed" display="inline" id="algx1.l2.m1.1"><semantics id="algx1.l2.m1.1a"><mrow id="algx1.l2.m1.1b"><mi id="algx1.l2.m1.1.2">T</mi><mo id="algx1.l2.m1.1.3">=</mo><mrow id="algx1.l2.m1.1.4"><mo id="algx1.l2.m1.1.4.1" stretchy="false">{</mo><msub id="algx1.l2.m1.1.4.2"><mi id="algx1.l2.m1.1.4.2.2">T</mi><mn id="algx1.l2.m1.1.4.2.3">1</mn></msub><mo id="algx1.l2.m1.1.4.3">,</mo><msub id="algx1.l2.m1.1.4.4"><mi id="algx1.l2.m1.1.4.4.2">T</mi><mn id="algx1.l2.m1.1.4.4.3">2</mn></msub><mo id="algx1.l2.m1.1.4.5">,</mo><mi id="algx1.l2.m1.1.1" mathvariant="normal">…</mi><mo id="algx1.l2.m1.1.4.6">,</mo><msub id="algx1.l2.m1.1.4.7"><mi id="algx1.l2.m1.1.4.7.2">T</mi><mi id="algx1.l2.m1.1.4.7.3">n</mi></msub><mo id="algx1.l2.m1.1.4.8" stretchy="false">}</mo></mrow><mo id="algx1.l2.m1.1.5" stretchy="false">←</mo><msub id="algx1.l2.m1.1.6"><mi id="algx1.l2.m1.1.6.2">p</mi><mi id="algx1.l2.m1.1.6.3">θ</mi></msub><mrow id="algx1.l2.m1.1.7"><mo id="algx1.l2.m1.1.7.1" stretchy="false">(</mo><mo id="algx1.l2.m1.1.7.2" lspace="0em" rspace="0em">⋅</mo><mo fence="false" id="algx1.l2.m1.1.7.3" rspace="0.167em" stretchy="false">|</mo><mi id="algx1.l2.m1.1.7.4">I</mi><mo id="algx1.l2.m1.1.7.5" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="algx1.l2.m1.1c">T=\{T_{1},T_{2},\ldots,T_{n}\}\leftarrow p_{\theta}(\cdot|I)</annotation><annotation encoding="application/x-llamapun" id="algx1.l2.m1.1d">italic_T = { italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } ← italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( ⋅ | italic_I )</annotation></semantics></math> <span class="ltx_text" id="algx1.l2.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l2.1.m1.1"><semantics id="algx1.l2.1.m1.1a"><mo id="algx1.l2.1.m1.1.1" xref="algx1.l2.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l2.1.m1.1b"><ci id="algx1.l2.1.m1.1.1.cmml" xref="algx1.l2.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l2.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l2.1.m1.1d">▷</annotation></semantics></math> Generate zero-shot initial step-by-step thoughts <math alttext="T" class="ltx_Math" display="inline" id="algx1.l2.2.m2.1"><semantics id="algx1.l2.2.m2.1a"><mi id="algx1.l2.2.m2.1.1" xref="algx1.l2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="algx1.l2.2.m2.1b"><ci id="algx1.l2.2.m2.1.1.cmml" xref="algx1.l2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="algx1.l2.2.m2.1d">italic_T</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="algx1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l3.4.1.1" style="font-size:80%;">3:</span></span><math alttext="T^{\star}\leftarrow T_{1},i\leftarrow 1" class="ltx_Math" display="inline" id="algx1.l3.m1.2"><semantics id="algx1.l3.m1.2a"><mrow id="algx1.l3.m1.2.2.2" xref="algx1.l3.m1.2.2.3.cmml"><mrow id="algx1.l3.m1.1.1.1.1" xref="algx1.l3.m1.1.1.1.1.cmml"><msup id="algx1.l3.m1.1.1.1.1.2" xref="algx1.l3.m1.1.1.1.1.2.cmml"><mi id="algx1.l3.m1.1.1.1.1.2.2" xref="algx1.l3.m1.1.1.1.1.2.2.cmml">T</mi><mo id="algx1.l3.m1.1.1.1.1.2.3" xref="algx1.l3.m1.1.1.1.1.2.3.cmml">⋆</mo></msup><mo id="algx1.l3.m1.1.1.1.1.1" stretchy="false" xref="algx1.l3.m1.1.1.1.1.1.cmml">←</mo><msub id="algx1.l3.m1.1.1.1.1.3" xref="algx1.l3.m1.1.1.1.1.3.cmml"><mi id="algx1.l3.m1.1.1.1.1.3.2" xref="algx1.l3.m1.1.1.1.1.3.2.cmml">T</mi><mn id="algx1.l3.m1.1.1.1.1.3.3" xref="algx1.l3.m1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="algx1.l3.m1.2.2.2.3" xref="algx1.l3.m1.2.2.3a.cmml">,</mo><mrow id="algx1.l3.m1.2.2.2.2" xref="algx1.l3.m1.2.2.2.2.cmml"><mi id="algx1.l3.m1.2.2.2.2.2" xref="algx1.l3.m1.2.2.2.2.2.cmml">i</mi><mo id="algx1.l3.m1.2.2.2.2.1" stretchy="false" xref="algx1.l3.m1.2.2.2.2.1.cmml">←</mo><mn id="algx1.l3.m1.2.2.2.2.3" xref="algx1.l3.m1.2.2.2.2.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l3.m1.2b"><apply id="algx1.l3.m1.2.2.3.cmml" xref="algx1.l3.m1.2.2.2"><csymbol cd="ambiguous" id="algx1.l3.m1.2.2.3a.cmml" xref="algx1.l3.m1.2.2.2.3">formulae-sequence</csymbol><apply id="algx1.l3.m1.1.1.1.1.cmml" xref="algx1.l3.m1.1.1.1.1"><ci id="algx1.l3.m1.1.1.1.1.1.cmml" xref="algx1.l3.m1.1.1.1.1.1">←</ci><apply id="algx1.l3.m1.1.1.1.1.2.cmml" xref="algx1.l3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="algx1.l3.m1.1.1.1.1.2.1.cmml" xref="algx1.l3.m1.1.1.1.1.2">superscript</csymbol><ci id="algx1.l3.m1.1.1.1.1.2.2.cmml" xref="algx1.l3.m1.1.1.1.1.2.2">𝑇</ci><ci id="algx1.l3.m1.1.1.1.1.2.3.cmml" xref="algx1.l3.m1.1.1.1.1.2.3">⋆</ci></apply><apply id="algx1.l3.m1.1.1.1.1.3.cmml" xref="algx1.l3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="algx1.l3.m1.1.1.1.1.3.1.cmml" xref="algx1.l3.m1.1.1.1.1.3">subscript</csymbol><ci id="algx1.l3.m1.1.1.1.1.3.2.cmml" xref="algx1.l3.m1.1.1.1.1.3.2">𝑇</ci><cn id="algx1.l3.m1.1.1.1.1.3.3.cmml" type="integer" xref="algx1.l3.m1.1.1.1.1.3.3">1</cn></apply></apply><apply id="algx1.l3.m1.2.2.2.2.cmml" xref="algx1.l3.m1.2.2.2.2"><ci id="algx1.l3.m1.2.2.2.2.1.cmml" xref="algx1.l3.m1.2.2.2.2.1">←</ci><ci id="algx1.l3.m1.2.2.2.2.2.cmml" xref="algx1.l3.m1.2.2.2.2.2">𝑖</ci><cn id="algx1.l3.m1.2.2.2.2.3.cmml" type="integer" xref="algx1.l3.m1.2.2.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l3.m1.2c">T^{\star}\leftarrow T_{1},i\leftarrow 1</annotation><annotation encoding="application/x-llamapun" id="algx1.l3.m1.2d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ← italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_i ← 1</annotation></semantics></math> <span class="ltx_text" id="algx1.l3.3" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l3.1.m1.1"><semantics id="algx1.l3.1.m1.1a"><mo id="algx1.l3.1.m1.1.1" xref="algx1.l3.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l3.1.m1.1b"><ci id="algx1.l3.1.m1.1.1.cmml" xref="algx1.l3.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l3.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l3.1.m1.1d">▷</annotation></semantics></math> Draft answer <math alttext="T^{\star}" class="ltx_Math" display="inline" id="algx1.l3.2.m2.1"><semantics id="algx1.l3.2.m2.1a"><msup id="algx1.l3.2.m2.1.1" xref="algx1.l3.2.m2.1.1.cmml"><mi id="algx1.l3.2.m2.1.1.2" xref="algx1.l3.2.m2.1.1.2.cmml">T</mi><mo id="algx1.l3.2.m2.1.1.3" xref="algx1.l3.2.m2.1.1.3.cmml">⋆</mo></msup><annotation-xml encoding="MathML-Content" id="algx1.l3.2.m2.1b"><apply id="algx1.l3.2.m2.1.1.cmml" xref="algx1.l3.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l3.2.m2.1.1.1.cmml" xref="algx1.l3.2.m2.1.1">superscript</csymbol><ci id="algx1.l3.2.m2.1.1.2.cmml" xref="algx1.l3.2.m2.1.1.2">𝑇</ci><ci id="algx1.l3.2.m2.1.1.3.cmml" xref="algx1.l3.2.m2.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l3.2.m2.1c">T^{\star}</annotation><annotation encoding="application/x-llamapun" id="algx1.l3.2.m2.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math> initialized with the first thought step <math alttext="T_{1}" class="ltx_Math" display="inline" id="algx1.l3.3.m3.1"><semantics id="algx1.l3.3.m3.1a"><msub id="algx1.l3.3.m3.1.1" xref="algx1.l3.3.m3.1.1.cmml"><mi id="algx1.l3.3.m3.1.1.2" xref="algx1.l3.3.m3.1.1.2.cmml">T</mi><mn id="algx1.l3.3.m3.1.1.3" xref="algx1.l3.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="algx1.l3.3.m3.1b"><apply id="algx1.l3.3.m3.1.1.cmml" xref="algx1.l3.3.m3.1.1"><csymbol cd="ambiguous" id="algx1.l3.3.m3.1.1.1.cmml" xref="algx1.l3.3.m3.1.1">subscript</csymbol><ci id="algx1.l3.3.m3.1.1.2.cmml" xref="algx1.l3.3.m3.1.1.2">𝑇</ci><cn id="algx1.l3.3.m3.1.1.3.cmml" type="integer" xref="algx1.l3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l3.3.m3.1c">T_{1}</annotation><annotation encoding="application/x-llamapun" id="algx1.l3.3.m3.1d">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="algx1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l4.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text ltx_font_bold" id="algx1.l4.2">repeat</span>
</div>
<div class="ltx_listingline" id="algx1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l5.4.1.1" style="font-size:80%;">5:</span></span>     <math alttext="Q_{i}\leftarrow\text{ToQuery}(I,T^{\star})" class="ltx_Math" display="inline" id="algx1.l5.m1.2"><semantics id="algx1.l5.m1.2a"><mrow id="algx1.l5.m1.2.2" xref="algx1.l5.m1.2.2.cmml"><msub id="algx1.l5.m1.2.2.3" xref="algx1.l5.m1.2.2.3.cmml"><mi id="algx1.l5.m1.2.2.3.2" xref="algx1.l5.m1.2.2.3.2.cmml">Q</mi><mi id="algx1.l5.m1.2.2.3.3" xref="algx1.l5.m1.2.2.3.3.cmml">i</mi></msub><mo id="algx1.l5.m1.2.2.2" stretchy="false" xref="algx1.l5.m1.2.2.2.cmml">←</mo><mrow id="algx1.l5.m1.2.2.1" xref="algx1.l5.m1.2.2.1.cmml"><mtext id="algx1.l5.m1.2.2.1.3" xref="algx1.l5.m1.2.2.1.3a.cmml">ToQuery</mtext><mo id="algx1.l5.m1.2.2.1.2" xref="algx1.l5.m1.2.2.1.2.cmml">⁢</mo><mrow id="algx1.l5.m1.2.2.1.1.1" xref="algx1.l5.m1.2.2.1.1.2.cmml"><mo id="algx1.l5.m1.2.2.1.1.1.2" stretchy="false" xref="algx1.l5.m1.2.2.1.1.2.cmml">(</mo><mi id="algx1.l5.m1.1.1" xref="algx1.l5.m1.1.1.cmml">I</mi><mo id="algx1.l5.m1.2.2.1.1.1.3" xref="algx1.l5.m1.2.2.1.1.2.cmml">,</mo><msup id="algx1.l5.m1.2.2.1.1.1.1" xref="algx1.l5.m1.2.2.1.1.1.1.cmml"><mi id="algx1.l5.m1.2.2.1.1.1.1.2" xref="algx1.l5.m1.2.2.1.1.1.1.2.cmml">T</mi><mo id="algx1.l5.m1.2.2.1.1.1.1.3" xref="algx1.l5.m1.2.2.1.1.1.1.3.cmml">⋆</mo></msup><mo id="algx1.l5.m1.2.2.1.1.1.4" stretchy="false" xref="algx1.l5.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l5.m1.2b"><apply id="algx1.l5.m1.2.2.cmml" xref="algx1.l5.m1.2.2"><ci id="algx1.l5.m1.2.2.2.cmml" xref="algx1.l5.m1.2.2.2">←</ci><apply id="algx1.l5.m1.2.2.3.cmml" xref="algx1.l5.m1.2.2.3"><csymbol cd="ambiguous" id="algx1.l5.m1.2.2.3.1.cmml" xref="algx1.l5.m1.2.2.3">subscript</csymbol><ci id="algx1.l5.m1.2.2.3.2.cmml" xref="algx1.l5.m1.2.2.3.2">𝑄</ci><ci id="algx1.l5.m1.2.2.3.3.cmml" xref="algx1.l5.m1.2.2.3.3">𝑖</ci></apply><apply id="algx1.l5.m1.2.2.1.cmml" xref="algx1.l5.m1.2.2.1"><times id="algx1.l5.m1.2.2.1.2.cmml" xref="algx1.l5.m1.2.2.1.2"></times><ci id="algx1.l5.m1.2.2.1.3a.cmml" xref="algx1.l5.m1.2.2.1.3"><mtext id="algx1.l5.m1.2.2.1.3.cmml" xref="algx1.l5.m1.2.2.1.3">ToQuery</mtext></ci><interval closure="open" id="algx1.l5.m1.2.2.1.1.2.cmml" xref="algx1.l5.m1.2.2.1.1.1"><ci id="algx1.l5.m1.1.1.cmml" xref="algx1.l5.m1.1.1">𝐼</ci><apply id="algx1.l5.m1.2.2.1.1.1.1.cmml" xref="algx1.l5.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="algx1.l5.m1.2.2.1.1.1.1.1.cmml" xref="algx1.l5.m1.2.2.1.1.1.1">superscript</csymbol><ci id="algx1.l5.m1.2.2.1.1.1.1.2.cmml" xref="algx1.l5.m1.2.2.1.1.1.1.2">𝑇</ci><ci id="algx1.l5.m1.2.2.1.1.1.1.3.cmml" xref="algx1.l5.m1.2.2.1.1.1.1.3">⋆</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.m1.2c">Q_{i}\leftarrow\text{ToQuery}(I,T^{\star})</annotation><annotation encoding="application/x-llamapun" id="algx1.l5.m1.2d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ← ToQuery ( italic_I , italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT )</annotation></semantics></math> <span class="ltx_text" id="algx1.l5.3" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l5.1.m1.1"><semantics id="algx1.l5.1.m1.1a"><mo id="algx1.l5.1.m1.1.1" xref="algx1.l5.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l5.1.m1.1b"><ci id="algx1.l5.1.m1.1.1.cmml" xref="algx1.l5.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l5.1.m1.1d">▷</annotation></semantics></math> Generate query <math alttext="Q_{i}" class="ltx_Math" display="inline" id="algx1.l5.2.m2.1"><semantics id="algx1.l5.2.m2.1a"><msub id="algx1.l5.2.m2.1.1" xref="algx1.l5.2.m2.1.1.cmml"><mi id="algx1.l5.2.m2.1.1.2" xref="algx1.l5.2.m2.1.1.2.cmml">Q</mi><mi id="algx1.l5.2.m2.1.1.3" xref="algx1.l5.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algx1.l5.2.m2.1b"><apply id="algx1.l5.2.m2.1.1.cmml" xref="algx1.l5.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l5.2.m2.1.1.1.cmml" xref="algx1.l5.2.m2.1.1">subscript</csymbol><ci id="algx1.l5.2.m2.1.1.2.cmml" xref="algx1.l5.2.m2.1.1.2">𝑄</ci><ci id="algx1.l5.2.m2.1.1.3.cmml" xref="algx1.l5.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.2.m2.1c">Q_{i}</annotation><annotation encoding="application/x-llamapun" id="algx1.l5.2.m2.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> based on current draft answer <math alttext="T^{\star}" class="ltx_Math" display="inline" id="algx1.l5.3.m3.1"><semantics id="algx1.l5.3.m3.1a"><msup id="algx1.l5.3.m3.1.1" xref="algx1.l5.3.m3.1.1.cmml"><mi id="algx1.l5.3.m3.1.1.2" xref="algx1.l5.3.m3.1.1.2.cmml">T</mi><mo id="algx1.l5.3.m3.1.1.3" xref="algx1.l5.3.m3.1.1.3.cmml">⋆</mo></msup><annotation-xml encoding="MathML-Content" id="algx1.l5.3.m3.1b"><apply id="algx1.l5.3.m3.1.1.cmml" xref="algx1.l5.3.m3.1.1"><csymbol cd="ambiguous" id="algx1.l5.3.m3.1.1.1.cmml" xref="algx1.l5.3.m3.1.1">superscript</csymbol><ci id="algx1.l5.3.m3.1.1.2.cmml" xref="algx1.l5.3.m3.1.1.2">𝑇</ci><ci id="algx1.l5.3.m3.1.1.3.cmml" xref="algx1.l5.3.m3.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l5.3.m3.1c">T^{\star}</annotation><annotation encoding="application/x-llamapun" id="algx1.l5.3.m3.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="algx1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l6.3.1.1" style="font-size:80%;">6:</span></span>     <math alttext="R_{i}\leftarrow\text{RetrieveFromCorpus}(Q_{i})" class="ltx_Math" display="inline" id="algx1.l6.m1.1"><semantics id="algx1.l6.m1.1a"><mrow id="algx1.l6.m1.1.1" xref="algx1.l6.m1.1.1.cmml"><msub id="algx1.l6.m1.1.1.3" xref="algx1.l6.m1.1.1.3.cmml"><mi id="algx1.l6.m1.1.1.3.2" xref="algx1.l6.m1.1.1.3.2.cmml">R</mi><mi id="algx1.l6.m1.1.1.3.3" xref="algx1.l6.m1.1.1.3.3.cmml">i</mi></msub><mo id="algx1.l6.m1.1.1.2" stretchy="false" xref="algx1.l6.m1.1.1.2.cmml">←</mo><mrow id="algx1.l6.m1.1.1.1" xref="algx1.l6.m1.1.1.1.cmml"><mtext id="algx1.l6.m1.1.1.1.3" xref="algx1.l6.m1.1.1.1.3a.cmml">RetrieveFromCorpus</mtext><mo id="algx1.l6.m1.1.1.1.2" xref="algx1.l6.m1.1.1.1.2.cmml">⁢</mo><mrow id="algx1.l6.m1.1.1.1.1.1" xref="algx1.l6.m1.1.1.1.1.1.1.cmml"><mo id="algx1.l6.m1.1.1.1.1.1.2" stretchy="false" xref="algx1.l6.m1.1.1.1.1.1.1.cmml">(</mo><msub id="algx1.l6.m1.1.1.1.1.1.1" xref="algx1.l6.m1.1.1.1.1.1.1.cmml"><mi id="algx1.l6.m1.1.1.1.1.1.1.2" xref="algx1.l6.m1.1.1.1.1.1.1.2.cmml">Q</mi><mi id="algx1.l6.m1.1.1.1.1.1.1.3" xref="algx1.l6.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="algx1.l6.m1.1.1.1.1.1.3" stretchy="false" xref="algx1.l6.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l6.m1.1b"><apply id="algx1.l6.m1.1.1.cmml" xref="algx1.l6.m1.1.1"><ci id="algx1.l6.m1.1.1.2.cmml" xref="algx1.l6.m1.1.1.2">←</ci><apply id="algx1.l6.m1.1.1.3.cmml" xref="algx1.l6.m1.1.1.3"><csymbol cd="ambiguous" id="algx1.l6.m1.1.1.3.1.cmml" xref="algx1.l6.m1.1.1.3">subscript</csymbol><ci id="algx1.l6.m1.1.1.3.2.cmml" xref="algx1.l6.m1.1.1.3.2">𝑅</ci><ci id="algx1.l6.m1.1.1.3.3.cmml" xref="algx1.l6.m1.1.1.3.3">𝑖</ci></apply><apply id="algx1.l6.m1.1.1.1.cmml" xref="algx1.l6.m1.1.1.1"><times id="algx1.l6.m1.1.1.1.2.cmml" xref="algx1.l6.m1.1.1.1.2"></times><ci id="algx1.l6.m1.1.1.1.3a.cmml" xref="algx1.l6.m1.1.1.1.3"><mtext id="algx1.l6.m1.1.1.1.3.cmml" xref="algx1.l6.m1.1.1.1.3">RetrieveFromCorpus</mtext></ci><apply id="algx1.l6.m1.1.1.1.1.1.1.cmml" xref="algx1.l6.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algx1.l6.m1.1.1.1.1.1.1.1.cmml" xref="algx1.l6.m1.1.1.1.1.1">subscript</csymbol><ci id="algx1.l6.m1.1.1.1.1.1.1.2.cmml" xref="algx1.l6.m1.1.1.1.1.1.1.2">𝑄</ci><ci id="algx1.l6.m1.1.1.1.1.1.1.3.cmml" xref="algx1.l6.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l6.m1.1c">R_{i}\leftarrow\text{RetrieveFromCorpus}(Q_{i})</annotation><annotation encoding="application/x-llamapun" id="algx1.l6.m1.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ← RetrieveFromCorpus ( italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> <span class="ltx_text" id="algx1.l6.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l6.1.m1.1"><semantics id="algx1.l6.1.m1.1a"><mo id="algx1.l6.1.m1.1.1" xref="algx1.l6.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l6.1.m1.1b"><ci id="algx1.l6.1.m1.1.1.cmml" xref="algx1.l6.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l6.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l6.1.m1.1d">▷</annotation></semantics></math> Retrieve information <math alttext="R_{i}" class="ltx_Math" display="inline" id="algx1.l6.2.m2.1"><semantics id="algx1.l6.2.m2.1a"><msub id="algx1.l6.2.m2.1.1" xref="algx1.l6.2.m2.1.1.cmml"><mi id="algx1.l6.2.m2.1.1.2" xref="algx1.l6.2.m2.1.1.2.cmml">R</mi><mi id="algx1.l6.2.m2.1.1.3" xref="algx1.l6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algx1.l6.2.m2.1b"><apply id="algx1.l6.2.m2.1.1.cmml" xref="algx1.l6.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l6.2.m2.1.1.1.cmml" xref="algx1.l6.2.m2.1.1">subscript</csymbol><ci id="algx1.l6.2.m2.1.1.2.cmml" xref="algx1.l6.2.m2.1.1.2">𝑅</ci><ci id="algx1.l6.2.m2.1.1.3.cmml" xref="algx1.l6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l6.2.m2.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="algx1.l6.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> from corpus or Internet
</span>
</div>
<div class="ltx_listingline" id="algx1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l7.4.1.1" style="font-size:80%;">7:</span></span>     <math alttext="T^{\star}\leftarrow p_{\theta}(\cdot|I,T^{\star},R_{i})" class="ltx_math_unparsed" display="inline" id="algx1.l7.m1.1"><semantics id="algx1.l7.m1.1a"><mrow id="algx1.l7.m1.1b"><msup id="algx1.l7.m1.1.1"><mi id="algx1.l7.m1.1.1.2">T</mi><mo id="algx1.l7.m1.1.1.3">⋆</mo></msup><mo id="algx1.l7.m1.1.2" stretchy="false">←</mo><msub id="algx1.l7.m1.1.3"><mi id="algx1.l7.m1.1.3.2">p</mi><mi id="algx1.l7.m1.1.3.3">θ</mi></msub><mrow id="algx1.l7.m1.1.4"><mo id="algx1.l7.m1.1.4.1" stretchy="false">(</mo><mo id="algx1.l7.m1.1.4.2" lspace="0em" rspace="0em">⋅</mo><mo fence="false" id="algx1.l7.m1.1.4.3" rspace="0.167em" stretchy="false">|</mo><mi id="algx1.l7.m1.1.4.4">I</mi><mo id="algx1.l7.m1.1.4.5">,</mo><msup id="algx1.l7.m1.1.4.6"><mi id="algx1.l7.m1.1.4.6.2">T</mi><mo id="algx1.l7.m1.1.4.6.3">⋆</mo></msup><mo id="algx1.l7.m1.1.4.7">,</mo><msub id="algx1.l7.m1.1.4.8"><mi id="algx1.l7.m1.1.4.8.2">R</mi><mi id="algx1.l7.m1.1.4.8.3">i</mi></msub><mo id="algx1.l7.m1.1.4.9" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="algx1.l7.m1.1c">T^{\star}\leftarrow p_{\theta}(\cdot|I,T^{\star},R_{i})</annotation><annotation encoding="application/x-llamapun" id="algx1.l7.m1.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ← italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( ⋅ | italic_I , italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> <span class="ltx_text" id="algx1.l7.3" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l7.1.m1.1"><semantics id="algx1.l7.1.m1.1a"><mo id="algx1.l7.1.m1.1.1" xref="algx1.l7.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l7.1.m1.1b"><ci id="algx1.l7.1.m1.1.1.cmml" xref="algx1.l7.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l7.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l7.1.m1.1d">▷</annotation></semantics></math> Revise draft answer <math alttext="T^{\star}" class="ltx_Math" display="inline" id="algx1.l7.2.m2.1"><semantics id="algx1.l7.2.m2.1a"><msup id="algx1.l7.2.m2.1.1" xref="algx1.l7.2.m2.1.1.cmml"><mi id="algx1.l7.2.m2.1.1.2" xref="algx1.l7.2.m2.1.1.2.cmml">T</mi><mo id="algx1.l7.2.m2.1.1.3" xref="algx1.l7.2.m2.1.1.3.cmml">⋆</mo></msup><annotation-xml encoding="MathML-Content" id="algx1.l7.2.m2.1b"><apply id="algx1.l7.2.m2.1.1.cmml" xref="algx1.l7.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l7.2.m2.1.1.1.cmml" xref="algx1.l7.2.m2.1.1">superscript</csymbol><ci id="algx1.l7.2.m2.1.1.2.cmml" xref="algx1.l7.2.m2.1.1.2">𝑇</ci><ci id="algx1.l7.2.m2.1.1.3.cmml" xref="algx1.l7.2.m2.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l7.2.m2.1c">T^{\star}</annotation><annotation encoding="application/x-llamapun" id="algx1.l7.2.m2.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math> based on retrieved text <math alttext="R_{i}" class="ltx_Math" display="inline" id="algx1.l7.3.m3.1"><semantics id="algx1.l7.3.m3.1a"><msub id="algx1.l7.3.m3.1.1" xref="algx1.l7.3.m3.1.1.cmml"><mi id="algx1.l7.3.m3.1.1.2" xref="algx1.l7.3.m3.1.1.2.cmml">R</mi><mi id="algx1.l7.3.m3.1.1.3" xref="algx1.l7.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="algx1.l7.3.m3.1b"><apply id="algx1.l7.3.m3.1.1.cmml" xref="algx1.l7.3.m3.1.1"><csymbol cd="ambiguous" id="algx1.l7.3.m3.1.1.1.cmml" xref="algx1.l7.3.m3.1.1">subscript</csymbol><ci id="algx1.l7.3.m3.1.1.2.cmml" xref="algx1.l7.3.m3.1.1.2">𝑅</ci><ci id="algx1.l7.3.m3.1.1.3.cmml" xref="algx1.l7.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l7.3.m3.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="algx1.l7.3.m3.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="algx1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l8.3.1.1" style="font-size:80%;">8:</span></span>     <math alttext="T^{\star}\leftarrow\text{CONCAT}(T^{\star},T_{i+1})" class="ltx_Math" display="inline" id="algx1.l8.m1.2"><semantics id="algx1.l8.m1.2a"><mrow id="algx1.l8.m1.2.2" xref="algx1.l8.m1.2.2.cmml"><msup id="algx1.l8.m1.2.2.4" xref="algx1.l8.m1.2.2.4.cmml"><mi id="algx1.l8.m1.2.2.4.2" xref="algx1.l8.m1.2.2.4.2.cmml">T</mi><mo id="algx1.l8.m1.2.2.4.3" xref="algx1.l8.m1.2.2.4.3.cmml">⋆</mo></msup><mo id="algx1.l8.m1.2.2.3" stretchy="false" xref="algx1.l8.m1.2.2.3.cmml">←</mo><mrow id="algx1.l8.m1.2.2.2" xref="algx1.l8.m1.2.2.2.cmml"><mtext id="algx1.l8.m1.2.2.2.4" xref="algx1.l8.m1.2.2.2.4a.cmml">CONCAT</mtext><mo id="algx1.l8.m1.2.2.2.3" xref="algx1.l8.m1.2.2.2.3.cmml">⁢</mo><mrow id="algx1.l8.m1.2.2.2.2.2" xref="algx1.l8.m1.2.2.2.2.3.cmml"><mo id="algx1.l8.m1.2.2.2.2.2.3" stretchy="false" xref="algx1.l8.m1.2.2.2.2.3.cmml">(</mo><msup id="algx1.l8.m1.1.1.1.1.1.1" xref="algx1.l8.m1.1.1.1.1.1.1.cmml"><mi id="algx1.l8.m1.1.1.1.1.1.1.2" xref="algx1.l8.m1.1.1.1.1.1.1.2.cmml">T</mi><mo id="algx1.l8.m1.1.1.1.1.1.1.3" xref="algx1.l8.m1.1.1.1.1.1.1.3.cmml">⋆</mo></msup><mo id="algx1.l8.m1.2.2.2.2.2.4" xref="algx1.l8.m1.2.2.2.2.3.cmml">,</mo><msub id="algx1.l8.m1.2.2.2.2.2.2" xref="algx1.l8.m1.2.2.2.2.2.2.cmml"><mi id="algx1.l8.m1.2.2.2.2.2.2.2" xref="algx1.l8.m1.2.2.2.2.2.2.2.cmml">T</mi><mrow id="algx1.l8.m1.2.2.2.2.2.2.3" xref="algx1.l8.m1.2.2.2.2.2.2.3.cmml"><mi id="algx1.l8.m1.2.2.2.2.2.2.3.2" xref="algx1.l8.m1.2.2.2.2.2.2.3.2.cmml">i</mi><mo id="algx1.l8.m1.2.2.2.2.2.2.3.1" xref="algx1.l8.m1.2.2.2.2.2.2.3.1.cmml">+</mo><mn id="algx1.l8.m1.2.2.2.2.2.2.3.3" xref="algx1.l8.m1.2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msub><mo id="algx1.l8.m1.2.2.2.2.2.5" stretchy="false" xref="algx1.l8.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l8.m1.2b"><apply id="algx1.l8.m1.2.2.cmml" xref="algx1.l8.m1.2.2"><ci id="algx1.l8.m1.2.2.3.cmml" xref="algx1.l8.m1.2.2.3">←</ci><apply id="algx1.l8.m1.2.2.4.cmml" xref="algx1.l8.m1.2.2.4"><csymbol cd="ambiguous" id="algx1.l8.m1.2.2.4.1.cmml" xref="algx1.l8.m1.2.2.4">superscript</csymbol><ci id="algx1.l8.m1.2.2.4.2.cmml" xref="algx1.l8.m1.2.2.4.2">𝑇</ci><ci id="algx1.l8.m1.2.2.4.3.cmml" xref="algx1.l8.m1.2.2.4.3">⋆</ci></apply><apply id="algx1.l8.m1.2.2.2.cmml" xref="algx1.l8.m1.2.2.2"><times id="algx1.l8.m1.2.2.2.3.cmml" xref="algx1.l8.m1.2.2.2.3"></times><ci id="algx1.l8.m1.2.2.2.4a.cmml" xref="algx1.l8.m1.2.2.2.4"><mtext id="algx1.l8.m1.2.2.2.4.cmml" xref="algx1.l8.m1.2.2.2.4">CONCAT</mtext></ci><interval closure="open" id="algx1.l8.m1.2.2.2.2.3.cmml" xref="algx1.l8.m1.2.2.2.2.2"><apply id="algx1.l8.m1.1.1.1.1.1.1.cmml" xref="algx1.l8.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algx1.l8.m1.1.1.1.1.1.1.1.cmml" xref="algx1.l8.m1.1.1.1.1.1.1">superscript</csymbol><ci id="algx1.l8.m1.1.1.1.1.1.1.2.cmml" xref="algx1.l8.m1.1.1.1.1.1.1.2">𝑇</ci><ci id="algx1.l8.m1.1.1.1.1.1.1.3.cmml" xref="algx1.l8.m1.1.1.1.1.1.1.3">⋆</ci></apply><apply id="algx1.l8.m1.2.2.2.2.2.2.cmml" xref="algx1.l8.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="algx1.l8.m1.2.2.2.2.2.2.1.cmml" xref="algx1.l8.m1.2.2.2.2.2.2">subscript</csymbol><ci id="algx1.l8.m1.2.2.2.2.2.2.2.cmml" xref="algx1.l8.m1.2.2.2.2.2.2.2">𝑇</ci><apply id="algx1.l8.m1.2.2.2.2.2.2.3.cmml" xref="algx1.l8.m1.2.2.2.2.2.2.3"><plus id="algx1.l8.m1.2.2.2.2.2.2.3.1.cmml" xref="algx1.l8.m1.2.2.2.2.2.2.3.1"></plus><ci id="algx1.l8.m1.2.2.2.2.2.2.3.2.cmml" xref="algx1.l8.m1.2.2.2.2.2.2.3.2">𝑖</ci><cn id="algx1.l8.m1.2.2.2.2.2.2.3.3.cmml" type="integer" xref="algx1.l8.m1.2.2.2.2.2.2.3.3">1</cn></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l8.m1.2c">T^{\star}\leftarrow\text{CONCAT}(T^{\star},T_{i+1})</annotation><annotation encoding="application/x-llamapun" id="algx1.l8.m1.2d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ← CONCAT ( italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_T start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT )</annotation></semantics></math> <span class="ltx_text" id="algx1.l8.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l8.1.m1.1"><semantics id="algx1.l8.1.m1.1a"><mo id="algx1.l8.1.m1.1.1" xref="algx1.l8.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l8.1.m1.1b"><ci id="algx1.l8.1.m1.1.1.cmml" xref="algx1.l8.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l8.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l8.1.m1.1d">▷</annotation></semantics></math> Append the next thought step <math alttext="T_{i+1}" class="ltx_Math" display="inline" id="algx1.l8.2.m2.1"><semantics id="algx1.l8.2.m2.1a"><msub id="algx1.l8.2.m2.1.1" xref="algx1.l8.2.m2.1.1.cmml"><mi id="algx1.l8.2.m2.1.1.2" xref="algx1.l8.2.m2.1.1.2.cmml">T</mi><mrow id="algx1.l8.2.m2.1.1.3" xref="algx1.l8.2.m2.1.1.3.cmml"><mi id="algx1.l8.2.m2.1.1.3.2" xref="algx1.l8.2.m2.1.1.3.2.cmml">i</mi><mo id="algx1.l8.2.m2.1.1.3.1" xref="algx1.l8.2.m2.1.1.3.1.cmml">+</mo><mn id="algx1.l8.2.m2.1.1.3.3" xref="algx1.l8.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="algx1.l8.2.m2.1b"><apply id="algx1.l8.2.m2.1.1.cmml" xref="algx1.l8.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l8.2.m2.1.1.1.cmml" xref="algx1.l8.2.m2.1.1">subscript</csymbol><ci id="algx1.l8.2.m2.1.1.2.cmml" xref="algx1.l8.2.m2.1.1.2">𝑇</ci><apply id="algx1.l8.2.m2.1.1.3.cmml" xref="algx1.l8.2.m2.1.1.3"><plus id="algx1.l8.2.m2.1.1.3.1.cmml" xref="algx1.l8.2.m2.1.1.3.1"></plus><ci id="algx1.l8.2.m2.1.1.3.2.cmml" xref="algx1.l8.2.m2.1.1.3.2">𝑖</ci><cn id="algx1.l8.2.m2.1.1.3.3.cmml" type="integer" xref="algx1.l8.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l8.2.m2.1c">T_{i+1}</annotation><annotation encoding="application/x-llamapun" id="algx1.l8.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="algx1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l9.2.1.1" style="font-size:80%;">9:</span></span>     <math alttext="i\leftarrow i+1" class="ltx_Math" display="inline" id="algx1.l9.m1.1"><semantics id="algx1.l9.m1.1a"><mrow id="algx1.l9.m1.1.1" xref="algx1.l9.m1.1.1.cmml"><mi id="algx1.l9.m1.1.1.2" xref="algx1.l9.m1.1.1.2.cmml">i</mi><mo id="algx1.l9.m1.1.1.1" stretchy="false" xref="algx1.l9.m1.1.1.1.cmml">←</mo><mrow id="algx1.l9.m1.1.1.3" xref="algx1.l9.m1.1.1.3.cmml"><mi id="algx1.l9.m1.1.1.3.2" xref="algx1.l9.m1.1.1.3.2.cmml">i</mi><mo id="algx1.l9.m1.1.1.3.1" xref="algx1.l9.m1.1.1.3.1.cmml">+</mo><mn id="algx1.l9.m1.1.1.3.3" xref="algx1.l9.m1.1.1.3.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="algx1.l9.m1.1b"><apply id="algx1.l9.m1.1.1.cmml" xref="algx1.l9.m1.1.1"><ci id="algx1.l9.m1.1.1.1.cmml" xref="algx1.l9.m1.1.1.1">←</ci><ci id="algx1.l9.m1.1.1.2.cmml" xref="algx1.l9.m1.1.1.2">𝑖</ci><apply id="algx1.l9.m1.1.1.3.cmml" xref="algx1.l9.m1.1.1.3"><plus id="algx1.l9.m1.1.1.3.1.cmml" xref="algx1.l9.m1.1.1.3.1"></plus><ci id="algx1.l9.m1.1.1.3.2.cmml" xref="algx1.l9.m1.1.1.3.2">𝑖</ci><cn id="algx1.l9.m1.1.1.3.3.cmml" type="integer" xref="algx1.l9.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l9.m1.1c">i\leftarrow i+1</annotation><annotation encoding="application/x-llamapun" id="algx1.l9.m1.1d">italic_i ← italic_i + 1</annotation></semantics></math> <span class="ltx_text" id="algx1.l9.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l9.1.m1.1"><semantics id="algx1.l9.1.m1.1a"><mo id="algx1.l9.1.m1.1.1" xref="algx1.l9.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l9.1.m1.1b"><ci id="algx1.l9.1.m1.1.1.cmml" xref="algx1.l9.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l9.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l9.1.m1.1d">▷</annotation></semantics></math> Begin the next revision round
</span>
</div>
<div class="ltx_listingline" id="algx1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l10.3.1.1" style="font-size:80%;">10:</span></span><span class="ltx_text ltx_font_bold" id="algx1.l10.4">until</span> <math alttext="i&gt;n" class="ltx_Math" display="inline" id="algx1.l10.m1.1"><semantics id="algx1.l10.m1.1a"><mrow id="algx1.l10.m1.1.1" xref="algx1.l10.m1.1.1.cmml"><mi id="algx1.l10.m1.1.1.2" xref="algx1.l10.m1.1.1.2.cmml">i</mi><mo id="algx1.l10.m1.1.1.1" xref="algx1.l10.m1.1.1.1.cmml">&gt;</mo><mi id="algx1.l10.m1.1.1.3" xref="algx1.l10.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="algx1.l10.m1.1b"><apply id="algx1.l10.m1.1.1.cmml" xref="algx1.l10.m1.1.1"><gt id="algx1.l10.m1.1.1.1.cmml" xref="algx1.l10.m1.1.1.1"></gt><ci id="algx1.l10.m1.1.1.2.cmml" xref="algx1.l10.m1.1.1.2">𝑖</ci><ci id="algx1.l10.m1.1.1.3.cmml" xref="algx1.l10.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l10.m1.1c">i&gt;n</annotation><annotation encoding="application/x-llamapun" id="algx1.l10.m1.1d">italic_i &gt; italic_n</annotation></semantics></math> <span class="ltx_text" id="algx1.l10.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l10.1.m1.1"><semantics id="algx1.l10.1.m1.1a"><mo id="algx1.l10.1.m1.1.1" xref="algx1.l10.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l10.1.m1.1b"><ci id="algx1.l10.1.m1.1.1.cmml" xref="algx1.l10.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l10.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l10.1.m1.1d">▷</annotation></semantics></math> Repeat until all the revised thoughts <math alttext="T_{1:n}^{\star}" class="ltx_Math" display="inline" id="algx1.l10.2.m2.1"><semantics id="algx1.l10.2.m2.1a"><msubsup id="algx1.l10.2.m2.1.1" xref="algx1.l10.2.m2.1.1.cmml"><mi id="algx1.l10.2.m2.1.1.2.2" xref="algx1.l10.2.m2.1.1.2.2.cmml">T</mi><mrow id="algx1.l10.2.m2.1.1.2.3" xref="algx1.l10.2.m2.1.1.2.3.cmml"><mn id="algx1.l10.2.m2.1.1.2.3.2" xref="algx1.l10.2.m2.1.1.2.3.2.cmml">1</mn><mo id="algx1.l10.2.m2.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="algx1.l10.2.m2.1.1.2.3.1.cmml">:</mo><mi id="algx1.l10.2.m2.1.1.2.3.3" xref="algx1.l10.2.m2.1.1.2.3.3.cmml">n</mi></mrow><mo id="algx1.l10.2.m2.1.1.3" xref="algx1.l10.2.m2.1.1.3.cmml">⋆</mo></msubsup><annotation-xml encoding="MathML-Content" id="algx1.l10.2.m2.1b"><apply id="algx1.l10.2.m2.1.1.cmml" xref="algx1.l10.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l10.2.m2.1.1.1.cmml" xref="algx1.l10.2.m2.1.1">superscript</csymbol><apply id="algx1.l10.2.m2.1.1.2.cmml" xref="algx1.l10.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l10.2.m2.1.1.2.1.cmml" xref="algx1.l10.2.m2.1.1">subscript</csymbol><ci id="algx1.l10.2.m2.1.1.2.2.cmml" xref="algx1.l10.2.m2.1.1.2.2">𝑇</ci><apply id="algx1.l10.2.m2.1.1.2.3.cmml" xref="algx1.l10.2.m2.1.1.2.3"><ci id="algx1.l10.2.m2.1.1.2.3.1.cmml" xref="algx1.l10.2.m2.1.1.2.3.1">:</ci><cn id="algx1.l10.2.m2.1.1.2.3.2.cmml" type="integer" xref="algx1.l10.2.m2.1.1.2.3.2">1</cn><ci id="algx1.l10.2.m2.1.1.2.3.3.cmml" xref="algx1.l10.2.m2.1.1.2.3.3">𝑛</ci></apply></apply><ci id="algx1.l10.2.m2.1.1.3.cmml" xref="algx1.l10.2.m2.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l10.2.m2.1c">T_{1:n}^{\star}</annotation><annotation encoding="application/x-llamapun" id="algx1.l10.2.m2.1d">italic_T start_POSTSUBSCRIPT 1 : italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math> are obtained
</span>
</div>
<div class="ltx_listingline" id="algx1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="algx1.l11.3.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text ltx_font_bold" id="algx1.l11.4">return</span> <math alttext="T^{\star}" class="ltx_Math" display="inline" id="algx1.l11.m1.1"><semantics id="algx1.l11.m1.1a"><msup id="algx1.l11.m1.1.1" xref="algx1.l11.m1.1.1.cmml"><mi id="algx1.l11.m1.1.1.2" xref="algx1.l11.m1.1.1.2.cmml">T</mi><mo id="algx1.l11.m1.1.1.3" xref="algx1.l11.m1.1.1.3.cmml">⋆</mo></msup><annotation-xml encoding="MathML-Content" id="algx1.l11.m1.1b"><apply id="algx1.l11.m1.1.1.cmml" xref="algx1.l11.m1.1.1"><csymbol cd="ambiguous" id="algx1.l11.m1.1.1.1.cmml" xref="algx1.l11.m1.1.1">superscript</csymbol><ci id="algx1.l11.m1.1.1.2.cmml" xref="algx1.l11.m1.1.1.2">𝑇</ci><ci id="algx1.l11.m1.1.1.3.cmml" xref="algx1.l11.m1.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l11.m1.1c">T^{\star}</annotation><annotation encoding="application/x-llamapun" id="algx1.l11.m1.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math> <span class="ltx_text" id="algx1.l11.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="algx1.l11.1.m1.1"><semantics id="algx1.l11.1.m1.1a"><mo id="algx1.l11.1.m1.1.1" xref="algx1.l11.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="algx1.l11.1.m1.1b"><ci id="algx1.l11.1.m1.1.1.cmml" xref="algx1.l11.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="algx1.l11.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="algx1.l11.1.m1.1d">▷</annotation></semantics></math> Output <math alttext="T^{\star}" class="ltx_Math" display="inline" id="algx1.l11.2.m2.1"><semantics id="algx1.l11.2.m2.1a"><msup id="algx1.l11.2.m2.1.1" xref="algx1.l11.2.m2.1.1.cmml"><mi id="algx1.l11.2.m2.1.1.2" xref="algx1.l11.2.m2.1.1.2.cmml">T</mi><mo id="algx1.l11.2.m2.1.1.3" xref="algx1.l11.2.m2.1.1.3.cmml">⋆</mo></msup><annotation-xml encoding="MathML-Content" id="algx1.l11.2.m2.1b"><apply id="algx1.l11.2.m2.1.1.cmml" xref="algx1.l11.2.m2.1.1"><csymbol cd="ambiguous" id="algx1.l11.2.m2.1.1.1.cmml" xref="algx1.l11.2.m2.1.1">superscript</csymbol><ci id="algx1.l11.2.m2.1.1.2.cmml" xref="algx1.l11.2.m2.1.1.2">𝑇</ci><ci id="algx1.l11.2.m2.1.1.3.cmml" xref="algx1.l11.2.m2.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algx1.l11.2.m2.1c">T^{\star}</annotation><annotation encoding="application/x-llamapun" id="algx1.l11.2.m2.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math> as the final generation
</span>
</div>
</div>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Preliminary</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.7"><span class="ltx_text ltx_font_bold" id="S2.SS1.p1.7.1">Retrieval-Augmented Generation</span> (RAG) targets the problem of generating fictitious facts by providing LLMs with relevant text extracted from trusted sources. It is primarily used in question-answering (QA) tasks <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib28" title="">2020b</a>)</cite>. Specifically, given a set of <math alttext="n" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_n</annotation></semantics></math> candidate documents <math alttext="R:=\{R_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mrow id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml">R</mi><mo id="S2.SS1.p1.2.m2.1.1.2" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p1.2.m2.1.1.2.cmml">:=</mo><msubsup id="S2.SS1.p1.2.m2.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.cmml"><mrow id="S2.SS1.p1.2.m2.1.1.1.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.1.1.2.cmml"><mo id="S2.SS1.p1.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.2" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.2.cmml">R</mi><mi id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.3" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS1.p1.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS1.p1.2.m2.1.1.1.1.3" xref="S2.SS1.p1.2.m2.1.1.1.1.3.cmml"><mi id="S2.SS1.p1.2.m2.1.1.1.1.3.2" xref="S2.SS1.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S2.SS1.p1.2.m2.1.1.1.1.3.1" xref="S2.SS1.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S2.SS1.p1.2.m2.1.1.1.1.3.3" xref="S2.SS1.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS1.p1.2.m2.1.1.1.3" xref="S2.SS1.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">assign</csymbol><ci id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">𝑅</ci><apply id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.1">superscript</csymbol><apply id="S2.SS1.p1.2.m2.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.1">subscript</csymbol><set id="S2.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1"><apply id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.2">𝑅</ci><ci id="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S2.SS1.p1.2.m2.1.1.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.3"><eq id="S2.SS1.p1.2.m2.1.1.1.1.3.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S2.SS1.p1.2.m2.1.1.1.1.3.2.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.3.2">𝑖</ci><cn id="S2.SS1.p1.2.m2.1.1.1.1.3.3.cmml" type="integer" xref="S2.SS1.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS1.p1.2.m2.1.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">R:=\{R_{i}\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_R := { italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, RAG aims to retrieve the most relevant ones w.r.t. a query <math alttext="Q" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_Q</annotation></semantics></math>, which can be the question/task prompt itself or relevant information generated by LLMs. To achieve this, RAG first extracts semantic-aware embeddings of the documents <math alttext="r_{i}:=\text{emb}(R_{i})\in\mathbb{R}^{K}" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><msub id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml"><mi id="S2.SS1.p1.4.m4.1.1.3.2" xref="S2.SS1.p1.4.m4.1.1.3.2.cmml">r</mi><mi id="S2.SS1.p1.4.m4.1.1.3.3" xref="S2.SS1.p1.4.m4.1.1.3.3.cmml">i</mi></msub><mo id="S2.SS1.p1.4.m4.1.1.4" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p1.4.m4.1.1.4.cmml">:=</mo><mrow id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml"><mtext id="S2.SS1.p1.4.m4.1.1.1.3" xref="S2.SS1.p1.4.m4.1.1.1.3a.cmml">emb</mtext><mo id="S2.SS1.p1.4.m4.1.1.1.2" xref="S2.SS1.p1.4.m4.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS1.p1.4.m4.1.1.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.cmml"><mo id="S2.SS1.p1.4.m4.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS1.p1.4.m4.1.1.1.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.4.m4.1.1.1.1.1.1.2" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.2.cmml">R</mi><mi id="S2.SS1.p1.4.m4.1.1.1.1.1.1.3" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS1.p1.4.m4.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p1.4.m4.1.1.5" xref="S2.SS1.p1.4.m4.1.1.5.cmml">∈</mo><msup id="S2.SS1.p1.4.m4.1.1.6" xref="S2.SS1.p1.4.m4.1.1.6.cmml"><mi id="S2.SS1.p1.4.m4.1.1.6.2" xref="S2.SS1.p1.4.m4.1.1.6.2.cmml">ℝ</mi><mi id="S2.SS1.p1.4.m4.1.1.6.3" xref="S2.SS1.p1.4.m4.1.1.6.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><and id="S2.SS1.p1.4.m4.1.1a.cmml" xref="S2.SS1.p1.4.m4.1.1"></and><apply id="S2.SS1.p1.4.m4.1.1b.cmml" xref="S2.SS1.p1.4.m4.1.1"><csymbol cd="latexml" id="S2.SS1.p1.4.m4.1.1.4.cmml" xref="S2.SS1.p1.4.m4.1.1.4">assign</csymbol><apply id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.3.1.cmml" xref="S2.SS1.p1.4.m4.1.1.3">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.3.2.cmml" xref="S2.SS1.p1.4.m4.1.1.3.2">𝑟</ci><ci id="S2.SS1.p1.4.m4.1.1.3.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"><times id="S2.SS1.p1.4.m4.1.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.1.2"></times><ci id="S2.SS1.p1.4.m4.1.1.1.3a.cmml" xref="S2.SS1.p1.4.m4.1.1.1.3"><mtext id="S2.SS1.p1.4.m4.1.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.1.3">emb</mtext></ci><apply id="S2.SS1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.2">𝑅</ci><ci id="S2.SS1.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="S2.SS1.p1.4.m4.1.1c.cmml" xref="S2.SS1.p1.4.m4.1.1"><in id="S2.SS1.p1.4.m4.1.1.5.cmml" xref="S2.SS1.p1.4.m4.1.1.5"></in><share href="#S2.SS1.p1.4.m4.1.1.1.cmml" id="S2.SS1.p1.4.m4.1.1d.cmml" xref="S2.SS1.p1.4.m4.1.1"></share><apply id="S2.SS1.p1.4.m4.1.1.6.cmml" xref="S2.SS1.p1.4.m4.1.1.6"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.6.1.cmml" xref="S2.SS1.p1.4.m4.1.1.6">superscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.6.2.cmml" xref="S2.SS1.p1.4.m4.1.1.6.2">ℝ</ci><ci id="S2.SS1.p1.4.m4.1.1.6.3.cmml" xref="S2.SS1.p1.4.m4.1.1.6.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">r_{i}:=\text{emb}(R_{i})\in\mathbb{R}^{K}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT := emb ( italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math> (<math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">italic_K</annotation></semantics></math> is the size of the embedding) as well as the query <math alttext="q:=\text{emb}(Q)\in\mathbb{R}^{K}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.1"><semantics id="S2.SS1.p1.6.m6.1a"><mrow id="S2.SS1.p1.6.m6.1.2" xref="S2.SS1.p1.6.m6.1.2.cmml"><mi id="S2.SS1.p1.6.m6.1.2.2" xref="S2.SS1.p1.6.m6.1.2.2.cmml">q</mi><mo id="S2.SS1.p1.6.m6.1.2.3" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p1.6.m6.1.2.3.cmml">:=</mo><mrow id="S2.SS1.p1.6.m6.1.2.4" xref="S2.SS1.p1.6.m6.1.2.4.cmml"><mtext id="S2.SS1.p1.6.m6.1.2.4.2" xref="S2.SS1.p1.6.m6.1.2.4.2a.cmml">emb</mtext><mo id="S2.SS1.p1.6.m6.1.2.4.1" xref="S2.SS1.p1.6.m6.1.2.4.1.cmml">⁢</mo><mrow id="S2.SS1.p1.6.m6.1.2.4.3.2" xref="S2.SS1.p1.6.m6.1.2.4.cmml"><mo id="S2.SS1.p1.6.m6.1.2.4.3.2.1" stretchy="false" xref="S2.SS1.p1.6.m6.1.2.4.cmml">(</mo><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">Q</mi><mo id="S2.SS1.p1.6.m6.1.2.4.3.2.2" stretchy="false" xref="S2.SS1.p1.6.m6.1.2.4.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p1.6.m6.1.2.5" xref="S2.SS1.p1.6.m6.1.2.5.cmml">∈</mo><msup id="S2.SS1.p1.6.m6.1.2.6" xref="S2.SS1.p1.6.m6.1.2.6.cmml"><mi id="S2.SS1.p1.6.m6.1.2.6.2" xref="S2.SS1.p1.6.m6.1.2.6.2.cmml">ℝ</mi><mi id="S2.SS1.p1.6.m6.1.2.6.3" xref="S2.SS1.p1.6.m6.1.2.6.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><apply id="S2.SS1.p1.6.m6.1.2.cmml" xref="S2.SS1.p1.6.m6.1.2"><and id="S2.SS1.p1.6.m6.1.2a.cmml" xref="S2.SS1.p1.6.m6.1.2"></and><apply id="S2.SS1.p1.6.m6.1.2b.cmml" xref="S2.SS1.p1.6.m6.1.2"><csymbol cd="latexml" id="S2.SS1.p1.6.m6.1.2.3.cmml" xref="S2.SS1.p1.6.m6.1.2.3">assign</csymbol><ci id="S2.SS1.p1.6.m6.1.2.2.cmml" xref="S2.SS1.p1.6.m6.1.2.2">𝑞</ci><apply id="S2.SS1.p1.6.m6.1.2.4.cmml" xref="S2.SS1.p1.6.m6.1.2.4"><times id="S2.SS1.p1.6.m6.1.2.4.1.cmml" xref="S2.SS1.p1.6.m6.1.2.4.1"></times><ci id="S2.SS1.p1.6.m6.1.2.4.2a.cmml" xref="S2.SS1.p1.6.m6.1.2.4.2"><mtext id="S2.SS1.p1.6.m6.1.2.4.2.cmml" xref="S2.SS1.p1.6.m6.1.2.4.2">emb</mtext></ci><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">𝑄</ci></apply></apply><apply id="S2.SS1.p1.6.m6.1.2c.cmml" xref="S2.SS1.p1.6.m6.1.2"><in id="S2.SS1.p1.6.m6.1.2.5.cmml" xref="S2.SS1.p1.6.m6.1.2.5"></in><share href="#S2.SS1.p1.6.m6.1.2.4.cmml" id="S2.SS1.p1.6.m6.1.2d.cmml" xref="S2.SS1.p1.6.m6.1.2"></share><apply id="S2.SS1.p1.6.m6.1.2.6.cmml" xref="S2.SS1.p1.6.m6.1.2.6"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.1.2.6.1.cmml" xref="S2.SS1.p1.6.m6.1.2.6">superscript</csymbol><ci id="S2.SS1.p1.6.m6.1.2.6.2.cmml" xref="S2.SS1.p1.6.m6.1.2.6.2">ℝ</ci><ci id="S2.SS1.p1.6.m6.1.2.6.3.cmml" xref="S2.SS1.p1.6.m6.1.2.6.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">q:=\text{emb}(Q)\in\mathbb{R}^{K}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.1d">italic_q := emb ( italic_Q ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>. <math alttext="\text{emb}(\cdot)" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m7.1"><semantics id="S2.SS1.p1.7.m7.1a"><mrow id="S2.SS1.p1.7.m7.1.2" xref="S2.SS1.p1.7.m7.1.2.cmml"><mtext id="S2.SS1.p1.7.m7.1.2.2" xref="S2.SS1.p1.7.m7.1.2.2a.cmml">emb</mtext><mo id="S2.SS1.p1.7.m7.1.2.1" xref="S2.SS1.p1.7.m7.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.p1.7.m7.1.2.3.2" xref="S2.SS1.p1.7.m7.1.2.cmml"><mo id="S2.SS1.p1.7.m7.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.7.m7.1.2.cmml">(</mo><mo id="S2.SS1.p1.7.m7.1.1" lspace="0em" rspace="0em" xref="S2.SS1.p1.7.m7.1.1.cmml">⋅</mo><mo id="S2.SS1.p1.7.m7.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.7.m7.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><apply id="S2.SS1.p1.7.m7.1.2.cmml" xref="S2.SS1.p1.7.m7.1.2"><times id="S2.SS1.p1.7.m7.1.2.1.cmml" xref="S2.SS1.p1.7.m7.1.2.1"></times><ci id="S2.SS1.p1.7.m7.1.2.2a.cmml" xref="S2.SS1.p1.7.m7.1.2.2"><mtext id="S2.SS1.p1.7.m7.1.2.2.cmml" xref="S2.SS1.p1.7.m7.1.2.2">emb</mtext></ci><ci id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">\text{emb}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m7.1d">emb ( ⋅ )</annotation></semantics></math> can be implemented with various text embedding models, such as Sentence-BERT <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib42" title="">2019</a>)</cite>. The relevance between the query and a document is measured by their cosine similarity:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx1">
<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{sim}(Q,R_{i})=\frac{q\cdot r_{i}}{\|q\|\|r_{i}\|}." class="ltx_Math" display="inline" id="S2.Ex1.m1.4"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4.4.1" xref="S2.Ex1.m1.4.4.1.1.cmml"><mrow id="S2.Ex1.m1.4.4.1.1" xref="S2.Ex1.m1.4.4.1.1.cmml"><mrow id="S2.Ex1.m1.4.4.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.cmml"><mtext id="S2.Ex1.m1.4.4.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.3a.cmml">sim</mtext><mo id="S2.Ex1.m1.4.4.1.1.1.2" xref="S2.Ex1.m1.4.4.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.4.4.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.2.cmml"><mo id="S2.Ex1.m1.4.4.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.4.4.1.1.1.1.2.cmml">(</mo><mi id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml">Q</mi><mo id="S2.Ex1.m1.4.4.1.1.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.1.2.cmml">,</mo><msub id="S2.Ex1.m1.4.4.1.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.4.4.1.1.1.1.1.1.2" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml">R</mi><mi id="S2.Ex1.m1.4.4.1.1.1.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.Ex1.m1.4.4.1.1.1.1.1.4" stretchy="false" xref="S2.Ex1.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.4.4.1.1.2" xref="S2.Ex1.m1.4.4.1.1.2.cmml">=</mo><mstyle displaystyle="true" id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml"><mfrac id="S2.Ex1.m1.2.2a" xref="S2.Ex1.m1.2.2.cmml"><mrow id="S2.Ex1.m1.2.2.4" xref="S2.Ex1.m1.2.2.4.cmml"><mi id="S2.Ex1.m1.2.2.4.2" xref="S2.Ex1.m1.2.2.4.2.cmml">q</mi><mo id="S2.Ex1.m1.2.2.4.1" lspace="0.222em" rspace="0.222em" xref="S2.Ex1.m1.2.2.4.1.cmml">⋅</mo><msub id="S2.Ex1.m1.2.2.4.3" xref="S2.Ex1.m1.2.2.4.3.cmml"><mi id="S2.Ex1.m1.2.2.4.3.2" xref="S2.Ex1.m1.2.2.4.3.2.cmml">r</mi><mi id="S2.Ex1.m1.2.2.4.3.3" xref="S2.Ex1.m1.2.2.4.3.3.cmml">i</mi></msub></mrow><mrow id="S2.Ex1.m1.2.2.2" xref="S2.Ex1.m1.2.2.2.cmml"><mrow id="S2.Ex1.m1.2.2.2.4.2" xref="S2.Ex1.m1.2.2.2.4.1.cmml"><mo id="S2.Ex1.m1.2.2.2.4.2.1" stretchy="false" xref="S2.Ex1.m1.2.2.2.4.1.1.cmml">‖</mo><mi id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml">q</mi><mo id="S2.Ex1.m1.2.2.2.4.2.2" stretchy="false" xref="S2.Ex1.m1.2.2.2.4.1.1.cmml">‖</mo></mrow><mo id="S2.Ex1.m1.2.2.2.3" xref="S2.Ex1.m1.2.2.2.3.cmml">⁢</mo><mrow id="S2.Ex1.m1.2.2.2.2.1" xref="S2.Ex1.m1.2.2.2.2.2.cmml"><mo id="S2.Ex1.m1.2.2.2.2.1.2" stretchy="false" xref="S2.Ex1.m1.2.2.2.2.2.1.cmml">‖</mo><msub id="S2.Ex1.m1.2.2.2.2.1.1" xref="S2.Ex1.m1.2.2.2.2.1.1.cmml"><mi id="S2.Ex1.m1.2.2.2.2.1.1.2" xref="S2.Ex1.m1.2.2.2.2.1.1.2.cmml">r</mi><mi id="S2.Ex1.m1.2.2.2.2.1.1.3" xref="S2.Ex1.m1.2.2.2.2.1.1.3.cmml">i</mi></msub><mo id="S2.Ex1.m1.2.2.2.2.1.3" stretchy="false" xref="S2.Ex1.m1.2.2.2.2.2.1.cmml">‖</mo></mrow></mrow></mfrac></mstyle></mrow><mo id="S2.Ex1.m1.4.4.1.2" lspace="0em" xref="S2.Ex1.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.4b"><apply id="S2.Ex1.m1.4.4.1.1.cmml" xref="S2.Ex1.m1.4.4.1"><eq id="S2.Ex1.m1.4.4.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.2"></eq><apply id="S2.Ex1.m1.4.4.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1"><times id="S2.Ex1.m1.4.4.1.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.2"></times><ci id="S2.Ex1.m1.4.4.1.1.1.3a.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3"><mtext id="S2.Ex1.m1.4.4.1.1.1.3.cmml" xref="S2.Ex1.m1.4.4.1.1.1.3">sim</mtext></ci><interval closure="open" id="S2.Ex1.m1.4.4.1.1.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1"><ci id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3">𝑄</ci><apply id="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.2">𝑅</ci><ci id="S2.Ex1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.3">𝑖</ci></apply></interval></apply><apply id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.2.2"><divide id="S2.Ex1.m1.2.2.3.cmml" xref="S2.Ex1.m1.2.2"></divide><apply id="S2.Ex1.m1.2.2.4.cmml" xref="S2.Ex1.m1.2.2.4"><ci id="S2.Ex1.m1.2.2.4.1.cmml" xref="S2.Ex1.m1.2.2.4.1">⋅</ci><ci id="S2.Ex1.m1.2.2.4.2.cmml" xref="S2.Ex1.m1.2.2.4.2">𝑞</ci><apply id="S2.Ex1.m1.2.2.4.3.cmml" xref="S2.Ex1.m1.2.2.4.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.2.2.4.3.1.cmml" xref="S2.Ex1.m1.2.2.4.3">subscript</csymbol><ci id="S2.Ex1.m1.2.2.4.3.2.cmml" xref="S2.Ex1.m1.2.2.4.3.2">𝑟</ci><ci id="S2.Ex1.m1.2.2.4.3.3.cmml" xref="S2.Ex1.m1.2.2.4.3.3">𝑖</ci></apply></apply><apply id="S2.Ex1.m1.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2"><times id="S2.Ex1.m1.2.2.2.3.cmml" xref="S2.Ex1.m1.2.2.2.3"></times><apply id="S2.Ex1.m1.2.2.2.4.1.cmml" xref="S2.Ex1.m1.2.2.2.4.2"><csymbol cd="latexml" id="S2.Ex1.m1.2.2.2.4.1.1.cmml" xref="S2.Ex1.m1.2.2.2.4.2.1">norm</csymbol><ci id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1">𝑞</ci></apply><apply id="S2.Ex1.m1.2.2.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2.2.1"><csymbol cd="latexml" id="S2.Ex1.m1.2.2.2.2.2.1.cmml" xref="S2.Ex1.m1.2.2.2.2.1.2">norm</csymbol><apply id="S2.Ex1.m1.2.2.2.2.1.1.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.2.2.2.2.1.1.1.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S2.Ex1.m1.2.2.2.2.1.1.2.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.2">𝑟</ci><ci id="S2.Ex1.m1.2.2.2.2.1.1.3.cmml" xref="S2.Ex1.m1.2.2.2.2.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\displaystyle\text{sim}(Q,R_{i})=\frac{q\cdot r_{i}}{\|q\|\|r_{i}\|}.</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.4d">sim ( italic_Q , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = divide start_ARG italic_q ⋅ italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_q ∥ ∥ italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.8">Based on their relevance, the top-ranked <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m1.1"><semantics id="S2.SS1.p1.8.m1.1a"><mi id="S2.SS1.p1.8.m1.1.1" xref="S2.SS1.p1.8.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m1.1b"><ci id="S2.SS1.p1.8.m1.1.1.cmml" xref="S2.SS1.p1.8.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m1.1d">italic_k</annotation></semantics></math> documents are then fed into the prompt for LLMs to generate the final answer. With such rich and factual contexts, RAG mitigates the hallucination of LLMs. However, complex reasoning tasks (e.g., those requiring multi-step reasoning) can be difficult to translate into effective search queries, leading to challenges in finding relevant documents and making RAG less applicable. Traditionally, RAG retrieves all relevant information at once. Yet, it overlooks the fact that it is difficult to predict what “facts" or information is required in the subsequent reasoning and generation steps. The task prompt itself is hardly sufficient to provide enough clues for this.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">Chain of Thoughts (CoT) prompting</span> is designed to enhance the performance of LLMs under tasks that require complex reasoning steps <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib56" title="">2022</a>)</cite>, such as multi-step math word problems. Specifically, instead of tasking LLMs to generate the correct answer directly, CoT prompting incentivizes LLMs to first output intermediate reasoning steps, termed thoughts, that serve as a scratch space for the task, before summarizing the thoughts into a final answer. Such behavior of LLMs can either be stimulated in <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.2">zero-shot</span> by prompting terms that encourage CoT reasoning (e.g., “let’s think step by step”) <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib26" title="">2022</a>)</cite>, or triggered by few-shot examples that perform CoT in similar tasks. However, since no direct supervision is posed to the intermediate thoughts, LLMs could make errors due to the lack of relevant domain knowledge <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib48" title="">2023</a>)</cite> or biased by hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Rawte et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib41" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Our Approach</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.5">Our intuition to mitigate the issues of CoT prompting and RAG mentioned above is to apply RAG to revise every thought step generated by CoT prompting. An overview can be found in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#S0.F1" title="Figure 1 ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Figure 1</span></a> and Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#alg1" title="Algorithm 1 ‣ 2 Retrieval Augmented Thoughts ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, given a task prompt <math alttext="\mathit{I}" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\mathit{I}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_I</annotation></semantics></math>, we first prompt LLM to generate step-by-step thoughts in <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.5.1">zero shot</span> (“let’s think step-by-step”) <math alttext="T:=\{T_{i}\}_{i=1}^{n}" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mrow id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">T</mi><mo id="S2.SS2.p1.2.m2.1.1.2" lspace="0.278em" rspace="0.278em" xref="S2.SS2.p1.2.m2.1.1.2.cmml">:=</mo><msubsup id="S2.SS2.p1.2.m2.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.cmml"><mrow id="S2.SS2.p1.2.m2.1.1.1.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.1.1.2.cmml"><mo id="S2.SS2.p1.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.2" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.3" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS2.p1.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS2.p1.2.m2.1.1.1.1.3" xref="S2.SS2.p1.2.m2.1.1.1.1.3.cmml"><mi id="S2.SS2.p1.2.m2.1.1.1.1.3.2" xref="S2.SS2.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S2.SS2.p1.2.m2.1.1.1.1.3.1" xref="S2.SS2.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S2.SS2.p1.2.m2.1.1.1.1.3.3" xref="S2.SS2.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p1.2.m2.1.1.1.3" xref="S2.SS2.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">assign</csymbol><ci id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">𝑇</ci><apply id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.1">superscript</csymbol><apply id="S2.SS2.p1.2.m2.1.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.1">subscript</csymbol><set id="S2.SS2.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1"><apply id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.2">𝑇</ci><ci id="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S2.SS2.p1.2.m2.1.1.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.3"><eq id="S2.SS2.p1.2.m2.1.1.1.1.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S2.SS2.p1.2.m2.1.1.1.1.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.1.1.3.2">𝑖</ci><cn id="S2.SS2.p1.2.m2.1.1.1.1.3.3.cmml" type="integer" xref="S2.SS2.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS2.p1.2.m2.1.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">T:=\{T_{i}\}_{i=1}^{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">italic_T := { italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="T_{i}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.1"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">T</mi><mi id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">𝑇</ci><ci id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">T_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p1.4.m4.1"><semantics id="S2.SS2.p1.4.m4.1a"><mi id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><ci id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.4.m4.1d">italic_i</annotation></semantics></math>th thought step. In long-horizon generation tasks, <math alttext="T" class="ltx_Math" display="inline" id="S2.SS2.p1.5.m5.1"><semantics id="S2.SS2.p1.5.m5.1a"><mi id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><ci id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.5.m5.1d">italic_T</annotation></semantics></math> can either be the intermediate reasoning steps, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.5.2">e.g</em>.<span class="ltx_text" id="S2.SS2.p1.5.3"></span> the pseudo code with comments in code generation, article outline in creative writing, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.5.4">etc</em>.<span class="ltx_text" id="S2.SS2.p1.5.5"></span>, or the draft response itself, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.5.6">e.g</em>.<span class="ltx_text" id="S2.SS2.p1.5.7"></span> a list of sub-goals in embodied task planning as shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#S0.F1" title="Figure 1 ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.4">Since <math alttext="T" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">italic_T</annotation></semantics></math> could be flawed (<em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.4.1">e.g</em>.<span class="ltx_text" id="S2.SS2.p2.4.2"></span>, contains hallucination), we proceed to use RAG to revise every generated thought step before generating the final response from these thoughts. Specifically, assuming we have fixed the previous thought steps and now are about to revise <math alttext="T_{1:i}" class="ltx_Math" display="inline" id="S2.SS2.p2.2.m2.1"><semantics id="S2.SS2.p2.2.m2.1a"><msub id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml"><mi id="S2.SS2.p2.2.m2.1.1.2" xref="S2.SS2.p2.2.m2.1.1.2.cmml">T</mi><mrow id="S2.SS2.p2.2.m2.1.1.3" xref="S2.SS2.p2.2.m2.1.1.3.cmml"><mn id="S2.SS2.p2.2.m2.1.1.3.2" xref="S2.SS2.p2.2.m2.1.1.3.2.cmml">1</mn><mo id="S2.SS2.p2.2.m2.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS2.p2.2.m2.1.1.3.1.cmml">:</mo><mi id="S2.SS2.p2.2.m2.1.1.3.3" xref="S2.SS2.p2.2.m2.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><apply id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.2">𝑇</ci><apply id="S2.SS2.p2.2.m2.1.1.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3"><ci id="S2.SS2.p2.2.m2.1.1.3.1.cmml" xref="S2.SS2.p2.2.m2.1.1.3.1">:</ci><cn id="S2.SS2.p2.2.m2.1.1.3.2.cmml" type="integer" xref="S2.SS2.p2.2.m2.1.1.3.2">1</cn><ci id="S2.SS2.p2.2.m2.1.1.3.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">T_{1:i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.2.m2.1d">italic_T start_POSTSUBSCRIPT 1 : italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, we begin by converting the text <math alttext="\{\mathit{I},T_{1},\dots,T_{i}\}" class="ltx_Math" display="inline" id="S2.SS2.p2.3.m3.4"><semantics id="S2.SS2.p2.3.m3.4a"><mrow id="S2.SS2.p2.3.m3.4.4.2" xref="S2.SS2.p2.3.m3.4.4.3.cmml"><mo id="S2.SS2.p2.3.m3.4.4.2.3" stretchy="false" xref="S2.SS2.p2.3.m3.4.4.3.cmml">{</mo><mi id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml">I</mi><mo id="S2.SS2.p2.3.m3.4.4.2.4" xref="S2.SS2.p2.3.m3.4.4.3.cmml">,</mo><msub id="S2.SS2.p2.3.m3.3.3.1.1" xref="S2.SS2.p2.3.m3.3.3.1.1.cmml"><mi id="S2.SS2.p2.3.m3.3.3.1.1.2" xref="S2.SS2.p2.3.m3.3.3.1.1.2.cmml">T</mi><mn id="S2.SS2.p2.3.m3.3.3.1.1.3" xref="S2.SS2.p2.3.m3.3.3.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p2.3.m3.4.4.2.5" xref="S2.SS2.p2.3.m3.4.4.3.cmml">,</mo><mi id="S2.SS2.p2.3.m3.2.2" mathvariant="normal" xref="S2.SS2.p2.3.m3.2.2.cmml">…</mi><mo id="S2.SS2.p2.3.m3.4.4.2.6" xref="S2.SS2.p2.3.m3.4.4.3.cmml">,</mo><msub id="S2.SS2.p2.3.m3.4.4.2.2" xref="S2.SS2.p2.3.m3.4.4.2.2.cmml"><mi id="S2.SS2.p2.3.m3.4.4.2.2.2" xref="S2.SS2.p2.3.m3.4.4.2.2.2.cmml">T</mi><mi id="S2.SS2.p2.3.m3.4.4.2.2.3" xref="S2.SS2.p2.3.m3.4.4.2.2.3.cmml">i</mi></msub><mo id="S2.SS2.p2.3.m3.4.4.2.7" stretchy="false" xref="S2.SS2.p2.3.m3.4.4.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.4b"><set id="S2.SS2.p2.3.m3.4.4.3.cmml" xref="S2.SS2.p2.3.m3.4.4.2"><ci id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">𝐼</ci><apply id="S2.SS2.p2.3.m3.3.3.1.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.3.m3.3.3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1">subscript</csymbol><ci id="S2.SS2.p2.3.m3.3.3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.2">𝑇</ci><cn id="S2.SS2.p2.3.m3.3.3.1.1.3.cmml" type="integer" xref="S2.SS2.p2.3.m3.3.3.1.1.3">1</cn></apply><ci id="S2.SS2.p2.3.m3.2.2.cmml" xref="S2.SS2.p2.3.m3.2.2">…</ci><apply id="S2.SS2.p2.3.m3.4.4.2.2.cmml" xref="S2.SS2.p2.3.m3.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.3.m3.4.4.2.2.1.cmml" xref="S2.SS2.p2.3.m3.4.4.2.2">subscript</csymbol><ci id="S2.SS2.p2.3.m3.4.4.2.2.2.cmml" xref="S2.SS2.p2.3.m3.4.4.2.2.2">𝑇</ci><ci id="S2.SS2.p2.3.m3.4.4.2.2.3.cmml" xref="S2.SS2.p2.3.m3.4.4.2.2.3">𝑖</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.4c">\{\mathit{I},T_{1},\dots,T_{i}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.3.m3.4d">{ italic_I , italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }</annotation></semantics></math> into a query <math alttext="Q_{i}" class="ltx_Math" display="inline" id="S2.SS2.p2.4.m4.1"><semantics id="S2.SS2.p2.4.m4.1a"><msub id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml"><mi id="S2.SS2.p2.4.m4.1.1.2" xref="S2.SS2.p2.4.m4.1.1.2.cmml">Q</mi><mi id="S2.SS2.p2.4.m4.1.1.3" xref="S2.SS2.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><apply id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.4.m4.1.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p2.4.m4.1.1.2.cmml" xref="S2.SS2.p2.4.m4.1.1.2">𝑄</ci><ci id="S2.SS2.p2.4.m4.1.1.3.cmml" xref="S2.SS2.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">Q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.4.m4.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx2">
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Q_{i}=\text{ToQuery}(\mathit{I},T_{1},\dots,T_{i})," class="ltx_Math" display="inline" id="S2.Ex2.m1.3"><semantics id="S2.Ex2.m1.3a"><mrow id="S2.Ex2.m1.3.3.1" xref="S2.Ex2.m1.3.3.1.1.cmml"><mrow id="S2.Ex2.m1.3.3.1.1" xref="S2.Ex2.m1.3.3.1.1.cmml"><msub id="S2.Ex2.m1.3.3.1.1.4" xref="S2.Ex2.m1.3.3.1.1.4.cmml"><mi id="S2.Ex2.m1.3.3.1.1.4.2" xref="S2.Ex2.m1.3.3.1.1.4.2.cmml">Q</mi><mi id="S2.Ex2.m1.3.3.1.1.4.3" xref="S2.Ex2.m1.3.3.1.1.4.3.cmml">i</mi></msub><mo id="S2.Ex2.m1.3.3.1.1.3" xref="S2.Ex2.m1.3.3.1.1.3.cmml">=</mo><mrow id="S2.Ex2.m1.3.3.1.1.2" xref="S2.Ex2.m1.3.3.1.1.2.cmml"><mtext id="S2.Ex2.m1.3.3.1.1.2.4" xref="S2.Ex2.m1.3.3.1.1.2.4a.cmml">ToQuery</mtext><mo id="S2.Ex2.m1.3.3.1.1.2.3" xref="S2.Ex2.m1.3.3.1.1.2.3.cmml">⁢</mo><mrow id="S2.Ex2.m1.3.3.1.1.2.2.2" xref="S2.Ex2.m1.3.3.1.1.2.2.3.cmml"><mo id="S2.Ex2.m1.3.3.1.1.2.2.2.3" stretchy="false" xref="S2.Ex2.m1.3.3.1.1.2.2.3.cmml">(</mo><mi id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml">I</mi><mo id="S2.Ex2.m1.3.3.1.1.2.2.2.4" xref="S2.Ex2.m1.3.3.1.1.2.2.3.cmml">,</mo><msub id="S2.Ex2.m1.3.3.1.1.1.1.1.1" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.3.3.1.1.1.1.1.1.2" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml">T</mi><mn id="S2.Ex2.m1.3.3.1.1.1.1.1.1.3" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.Ex2.m1.3.3.1.1.2.2.2.5" xref="S2.Ex2.m1.3.3.1.1.2.2.3.cmml">,</mo><mi id="S2.Ex2.m1.2.2" mathvariant="normal" xref="S2.Ex2.m1.2.2.cmml">…</mi><mo id="S2.Ex2.m1.3.3.1.1.2.2.2.6" xref="S2.Ex2.m1.3.3.1.1.2.2.3.cmml">,</mo><msub id="S2.Ex2.m1.3.3.1.1.2.2.2.2" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S2.Ex2.m1.3.3.1.1.2.2.2.2.2" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2.2.cmml">T</mi><mi id="S2.Ex2.m1.3.3.1.1.2.2.2.2.3" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.Ex2.m1.3.3.1.1.2.2.2.7" stretchy="false" xref="S2.Ex2.m1.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.Ex2.m1.3.3.1.2" xref="S2.Ex2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.3b"><apply id="S2.Ex2.m1.3.3.1.1.cmml" xref="S2.Ex2.m1.3.3.1"><eq id="S2.Ex2.m1.3.3.1.1.3.cmml" xref="S2.Ex2.m1.3.3.1.1.3"></eq><apply id="S2.Ex2.m1.3.3.1.1.4.cmml" xref="S2.Ex2.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.1.1.4.1.cmml" xref="S2.Ex2.m1.3.3.1.1.4">subscript</csymbol><ci id="S2.Ex2.m1.3.3.1.1.4.2.cmml" xref="S2.Ex2.m1.3.3.1.1.4.2">𝑄</ci><ci id="S2.Ex2.m1.3.3.1.1.4.3.cmml" xref="S2.Ex2.m1.3.3.1.1.4.3">𝑖</ci></apply><apply id="S2.Ex2.m1.3.3.1.1.2.cmml" xref="S2.Ex2.m1.3.3.1.1.2"><times id="S2.Ex2.m1.3.3.1.1.2.3.cmml" xref="S2.Ex2.m1.3.3.1.1.2.3"></times><ci id="S2.Ex2.m1.3.3.1.1.2.4a.cmml" xref="S2.Ex2.m1.3.3.1.1.2.4"><mtext id="S2.Ex2.m1.3.3.1.1.2.4.cmml" xref="S2.Ex2.m1.3.3.1.1.2.4">ToQuery</mtext></ci><vector id="S2.Ex2.m1.3.3.1.1.2.2.3.cmml" xref="S2.Ex2.m1.3.3.1.1.2.2.2"><ci id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1">𝐼</ci><apply id="S2.Ex2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1.2">𝑇</ci><cn id="S2.Ex2.m1.3.3.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.Ex2.m1.3.3.1.1.1.1.1.1.3">1</cn></apply><ci id="S2.Ex2.m1.2.2.cmml" xref="S2.Ex2.m1.2.2">…</ci><apply id="S2.Ex2.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="S2.Ex2.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2.2">𝑇</ci><ci id="S2.Ex2.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S2.Ex2.m1.3.3.1.1.2.2.2.2.3">𝑖</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.3c">\displaystyle Q_{i}=\text{ToQuery}(\mathit{I},T_{1},\dots,T_{i}),</annotation><annotation encoding="application/x-llamapun" id="S2.Ex2.m1.3d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ToQuery ( italic_I , italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p2.11">where <math alttext="\text{ToQuery}(\cdot)" class="ltx_Math" display="inline" id="S2.SS2.p2.5.m1.1"><semantics id="S2.SS2.p2.5.m1.1a"><mrow id="S2.SS2.p2.5.m1.1.2" xref="S2.SS2.p2.5.m1.1.2.cmml"><mtext id="S2.SS2.p2.5.m1.1.2.2" xref="S2.SS2.p2.5.m1.1.2.2a.cmml">ToQuery</mtext><mo id="S2.SS2.p2.5.m1.1.2.1" xref="S2.SS2.p2.5.m1.1.2.1.cmml">⁢</mo><mrow id="S2.SS2.p2.5.m1.1.2.3.2" xref="S2.SS2.p2.5.m1.1.2.cmml"><mo id="S2.SS2.p2.5.m1.1.2.3.2.1" stretchy="false" xref="S2.SS2.p2.5.m1.1.2.cmml">(</mo><mo id="S2.SS2.p2.5.m1.1.1" lspace="0em" rspace="0em" xref="S2.SS2.p2.5.m1.1.1.cmml">⋅</mo><mo id="S2.SS2.p2.5.m1.1.2.3.2.2" stretchy="false" xref="S2.SS2.p2.5.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m1.1b"><apply id="S2.SS2.p2.5.m1.1.2.cmml" xref="S2.SS2.p2.5.m1.1.2"><times id="S2.SS2.p2.5.m1.1.2.1.cmml" xref="S2.SS2.p2.5.m1.1.2.1"></times><ci id="S2.SS2.p2.5.m1.1.2.2a.cmml" xref="S2.SS2.p2.5.m1.1.2.2"><mtext id="S2.SS2.p2.5.m1.1.2.2.cmml" xref="S2.SS2.p2.5.m1.1.2.2">ToQuery</mtext></ci><ci id="S2.SS2.p2.5.m1.1.1.cmml" xref="S2.SS2.p2.5.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m1.1c">\text{ToQuery}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.5.m1.1d">ToQuery ( ⋅ )</annotation></semantics></math> can either be a text encoder or an LLM that translates the task prompt <math alttext="\mathit{I}" class="ltx_Math" display="inline" id="S2.SS2.p2.6.m2.1"><semantics id="S2.SS2.p2.6.m2.1a"><mi id="S2.SS2.p2.6.m2.1.1" xref="S2.SS2.p2.6.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.6.m2.1b"><ci id="S2.SS2.p2.6.m2.1.1.cmml" xref="S2.SS2.p2.6.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.6.m2.1c">\mathit{I}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.6.m2.1d">italic_I</annotation></semantics></math>, the current and the past thought steps <math alttext="T_{1},\dots,T_{i}" class="ltx_Math" display="inline" id="S2.SS2.p2.7.m3.3"><semantics id="S2.SS2.p2.7.m3.3a"><mrow id="S2.SS2.p2.7.m3.3.3.2" xref="S2.SS2.p2.7.m3.3.3.3.cmml"><msub id="S2.SS2.p2.7.m3.2.2.1.1" xref="S2.SS2.p2.7.m3.2.2.1.1.cmml"><mi id="S2.SS2.p2.7.m3.2.2.1.1.2" xref="S2.SS2.p2.7.m3.2.2.1.1.2.cmml">T</mi><mn id="S2.SS2.p2.7.m3.2.2.1.1.3" xref="S2.SS2.p2.7.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p2.7.m3.3.3.2.3" xref="S2.SS2.p2.7.m3.3.3.3.cmml">,</mo><mi id="S2.SS2.p2.7.m3.1.1" mathvariant="normal" xref="S2.SS2.p2.7.m3.1.1.cmml">…</mi><mo id="S2.SS2.p2.7.m3.3.3.2.4" xref="S2.SS2.p2.7.m3.3.3.3.cmml">,</mo><msub id="S2.SS2.p2.7.m3.3.3.2.2" xref="S2.SS2.p2.7.m3.3.3.2.2.cmml"><mi id="S2.SS2.p2.7.m3.3.3.2.2.2" xref="S2.SS2.p2.7.m3.3.3.2.2.2.cmml">T</mi><mi id="S2.SS2.p2.7.m3.3.3.2.2.3" xref="S2.SS2.p2.7.m3.3.3.2.2.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.7.m3.3b"><list id="S2.SS2.p2.7.m3.3.3.3.cmml" xref="S2.SS2.p2.7.m3.3.3.2"><apply id="S2.SS2.p2.7.m3.2.2.1.1.cmml" xref="S2.SS2.p2.7.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.7.m3.2.2.1.1.1.cmml" xref="S2.SS2.p2.7.m3.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p2.7.m3.2.2.1.1.2.cmml" xref="S2.SS2.p2.7.m3.2.2.1.1.2">𝑇</ci><cn id="S2.SS2.p2.7.m3.2.2.1.1.3.cmml" type="integer" xref="S2.SS2.p2.7.m3.2.2.1.1.3">1</cn></apply><ci id="S2.SS2.p2.7.m3.1.1.cmml" xref="S2.SS2.p2.7.m3.1.1">…</ci><apply id="S2.SS2.p2.7.m3.3.3.2.2.cmml" xref="S2.SS2.p2.7.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.7.m3.3.3.2.2.1.cmml" xref="S2.SS2.p2.7.m3.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p2.7.m3.3.3.2.2.2.cmml" xref="S2.SS2.p2.7.m3.3.3.2.2.2">𝑇</ci><ci id="S2.SS2.p2.7.m3.3.3.2.2.3.cmml" xref="S2.SS2.p2.7.m3.3.3.2.2.3">𝑖</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.7.m3.3c">T_{1},\dots,T_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.7.m3.3d">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> into a query <math alttext="Q_{i}" class="ltx_Math" display="inline" id="S2.SS2.p2.8.m4.1"><semantics id="S2.SS2.p2.8.m4.1a"><msub id="S2.SS2.p2.8.m4.1.1" xref="S2.SS2.p2.8.m4.1.1.cmml"><mi id="S2.SS2.p2.8.m4.1.1.2" xref="S2.SS2.p2.8.m4.1.1.2.cmml">Q</mi><mi id="S2.SS2.p2.8.m4.1.1.3" xref="S2.SS2.p2.8.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.8.m4.1b"><apply id="S2.SS2.p2.8.m4.1.1.cmml" xref="S2.SS2.p2.8.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m4.1.1.1.cmml" xref="S2.SS2.p2.8.m4.1.1">subscript</csymbol><ci id="S2.SS2.p2.8.m4.1.1.2.cmml" xref="S2.SS2.p2.8.m4.1.1.2">𝑄</ci><ci id="S2.SS2.p2.8.m4.1.1.3.cmml" xref="S2.SS2.p2.8.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.8.m4.1c">Q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.8.m4.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> that can be processed by the retrieval system. We adopt RAG to retrieve relevant documents <math alttext="R_{i}" class="ltx_Math" display="inline" id="S2.SS2.p2.9.m5.1"><semantics id="S2.SS2.p2.9.m5.1a"><msub id="S2.SS2.p2.9.m5.1.1" xref="S2.SS2.p2.9.m5.1.1.cmml"><mi id="S2.SS2.p2.9.m5.1.1.2" xref="S2.SS2.p2.9.m5.1.1.2.cmml">R</mi><mi id="S2.SS2.p2.9.m5.1.1.3" xref="S2.SS2.p2.9.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.9.m5.1b"><apply id="S2.SS2.p2.9.m5.1.1.cmml" xref="S2.SS2.p2.9.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.9.m5.1.1.1.cmml" xref="S2.SS2.p2.9.m5.1.1">subscript</csymbol><ci id="S2.SS2.p2.9.m5.1.1.2.cmml" xref="S2.SS2.p2.9.m5.1.1.2">𝑅</ci><ci id="S2.SS2.p2.9.m5.1.1.3.cmml" xref="S2.SS2.p2.9.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.9.m5.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.9.m5.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> using <math alttext="Q_{i}" class="ltx_Math" display="inline" id="S2.SS2.p2.10.m6.1"><semantics id="S2.SS2.p2.10.m6.1a"><msub id="S2.SS2.p2.10.m6.1.1" xref="S2.SS2.p2.10.m6.1.1.cmml"><mi id="S2.SS2.p2.10.m6.1.1.2" xref="S2.SS2.p2.10.m6.1.1.2.cmml">Q</mi><mi id="S2.SS2.p2.10.m6.1.1.3" xref="S2.SS2.p2.10.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.10.m6.1b"><apply id="S2.SS2.p2.10.m6.1.1.cmml" xref="S2.SS2.p2.10.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.10.m6.1.1.1.cmml" xref="S2.SS2.p2.10.m6.1.1">subscript</csymbol><ci id="S2.SS2.p2.10.m6.1.1.2.cmml" xref="S2.SS2.p2.10.m6.1.1.2">𝑄</ci><ci id="S2.SS2.p2.10.m6.1.1.3.cmml" xref="S2.SS2.p2.10.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.10.m6.1c">Q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.10.m6.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, which are then prepended to the prompt to generate a revised thought step <math alttext="T^{\star}_{i}" class="ltx_Math" display="inline" id="S2.SS2.p2.11.m7.1"><semantics id="S2.SS2.p2.11.m7.1a"><msubsup id="S2.SS2.p2.11.m7.1.1" xref="S2.SS2.p2.11.m7.1.1.cmml"><mi id="S2.SS2.p2.11.m7.1.1.2.2" xref="S2.SS2.p2.11.m7.1.1.2.2.cmml">T</mi><mi id="S2.SS2.p2.11.m7.1.1.3" xref="S2.SS2.p2.11.m7.1.1.3.cmml">i</mi><mo id="S2.SS2.p2.11.m7.1.1.2.3" xref="S2.SS2.p2.11.m7.1.1.2.3.cmml">⋆</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.11.m7.1b"><apply id="S2.SS2.p2.11.m7.1.1.cmml" xref="S2.SS2.p2.11.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.11.m7.1.1.1.cmml" xref="S2.SS2.p2.11.m7.1.1">subscript</csymbol><apply id="S2.SS2.p2.11.m7.1.1.2.cmml" xref="S2.SS2.p2.11.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.11.m7.1.1.2.1.cmml" xref="S2.SS2.p2.11.m7.1.1">superscript</csymbol><ci id="S2.SS2.p2.11.m7.1.1.2.2.cmml" xref="S2.SS2.p2.11.m7.1.1.2.2">𝑇</ci><ci id="S2.SS2.p2.11.m7.1.1.2.3.cmml" xref="S2.SS2.p2.11.m7.1.1.2.3">⋆</ci></apply><ci id="S2.SS2.p2.11.m7.1.1.3.cmml" xref="S2.SS2.p2.11.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.11.m7.1c">T^{\star}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.11.m7.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx3">
<tbody id="S2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle T^{\star}_{1:i}=p_{\theta}(\cdot|\mathit{I},T_{1},\dots,T_{i},R_%
{i})." class="ltx_math_unparsed" display="inline" id="S2.Ex3.m1.1"><semantics id="S2.Ex3.m1.1a"><mrow id="S2.Ex3.m1.1b"><msubsup id="S2.Ex3.m1.1.1"><mi id="S2.Ex3.m1.1.1.2.2">T</mi><mrow id="S2.Ex3.m1.1.1.3"><mn id="S2.Ex3.m1.1.1.3.2">1</mn><mo id="S2.Ex3.m1.1.1.3.1" lspace="0.278em" rspace="0.278em">:</mo><mi id="S2.Ex3.m1.1.1.3.3">i</mi></mrow><mo id="S2.Ex3.m1.1.1.2.3">⋆</mo></msubsup><mo id="S2.Ex3.m1.1.2">=</mo><msub id="S2.Ex3.m1.1.3"><mi id="S2.Ex3.m1.1.3.2">p</mi><mi id="S2.Ex3.m1.1.3.3">θ</mi></msub><mrow id="S2.Ex3.m1.1.4"><mo id="S2.Ex3.m1.1.4.1" stretchy="false">(</mo><mo id="S2.Ex3.m1.1.4.2" lspace="0em" rspace="0em">⋅</mo><mo fence="false" id="S2.Ex3.m1.1.4.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.Ex3.m1.1.4.4">I</mi><mo id="S2.Ex3.m1.1.4.5">,</mo><msub id="S2.Ex3.m1.1.4.6"><mi id="S2.Ex3.m1.1.4.6.2">T</mi><mn id="S2.Ex3.m1.1.4.6.3">1</mn></msub><mo id="S2.Ex3.m1.1.4.7">,</mo><mi id="S2.Ex3.m1.1.4.8" mathvariant="normal">…</mi><mo id="S2.Ex3.m1.1.4.9">,</mo><msub id="S2.Ex3.m1.1.4.10"><mi id="S2.Ex3.m1.1.4.10.2">T</mi><mi id="S2.Ex3.m1.1.4.10.3">i</mi></msub><mo id="S2.Ex3.m1.1.4.11">,</mo><msub id="S2.Ex3.m1.1.4.12"><mi id="S2.Ex3.m1.1.4.12.2">R</mi><mi id="S2.Ex3.m1.1.4.12.3">i</mi></msub><mo id="S2.Ex3.m1.1.4.13" stretchy="false">)</mo></mrow><mo id="S2.Ex3.m1.1.5" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S2.Ex3.m1.1c">\displaystyle T^{\star}_{1:i}=p_{\theta}(\cdot|\mathit{I},T_{1},\dots,T_{i},R_%
{i}).</annotation><annotation encoding="application/x-llamapun" id="S2.Ex3.m1.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_i end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( ⋅ | italic_I , italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p2.12">Finally, depending on the actual task, the revised thought steps <math alttext="T^{\star}_{1:n}" class="ltx_Math" display="inline" id="S2.SS2.p2.12.m1.1"><semantics id="S2.SS2.p2.12.m1.1a"><msubsup id="S2.SS2.p2.12.m1.1.1" xref="S2.SS2.p2.12.m1.1.1.cmml"><mi id="S2.SS2.p2.12.m1.1.1.2.2" xref="S2.SS2.p2.12.m1.1.1.2.2.cmml">T</mi><mrow id="S2.SS2.p2.12.m1.1.1.3" xref="S2.SS2.p2.12.m1.1.1.3.cmml"><mn id="S2.SS2.p2.12.m1.1.1.3.2" xref="S2.SS2.p2.12.m1.1.1.3.2.cmml">1</mn><mo id="S2.SS2.p2.12.m1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS2.p2.12.m1.1.1.3.1.cmml">:</mo><mi id="S2.SS2.p2.12.m1.1.1.3.3" xref="S2.SS2.p2.12.m1.1.1.3.3.cmml">n</mi></mrow><mo id="S2.SS2.p2.12.m1.1.1.2.3" xref="S2.SS2.p2.12.m1.1.1.2.3.cmml">⋆</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.12.m1.1b"><apply id="S2.SS2.p2.12.m1.1.1.cmml" xref="S2.SS2.p2.12.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.12.m1.1.1.1.cmml" xref="S2.SS2.p2.12.m1.1.1">subscript</csymbol><apply id="S2.SS2.p2.12.m1.1.1.2.cmml" xref="S2.SS2.p2.12.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.12.m1.1.1.2.1.cmml" xref="S2.SS2.p2.12.m1.1.1">superscript</csymbol><ci id="S2.SS2.p2.12.m1.1.1.2.2.cmml" xref="S2.SS2.p2.12.m1.1.1.2.2">𝑇</ci><ci id="S2.SS2.p2.12.m1.1.1.2.3.cmml" xref="S2.SS2.p2.12.m1.1.1.2.3">⋆</ci></apply><apply id="S2.SS2.p2.12.m1.1.1.3.cmml" xref="S2.SS2.p2.12.m1.1.1.3"><ci id="S2.SS2.p2.12.m1.1.1.3.1.cmml" xref="S2.SS2.p2.12.m1.1.1.3.1">:</ci><cn id="S2.SS2.p2.12.m1.1.1.3.2.cmml" type="integer" xref="S2.SS2.p2.12.m1.1.1.3.2">1</cn><ci id="S2.SS2.p2.12.m1.1.1.3.3.cmml" xref="S2.SS2.p2.12.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.12.m1.1c">T^{\star}_{1:n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.12.m1.1d">italic_T start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_n end_POSTSUBSCRIPT</annotation></semantics></math> can simply be used as the final model response, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.12.1">e.g</em>.<span class="ltx_text" id="S2.SS2.p2.12.2"></span>, embodied task planning. For tasks like code generation, or creative writing, the LLM will be further prompted to produce the complete response (code, passage) from each revised thought step in a step-by-step fashion.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.7">Note that, when revising the <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mi id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">italic_i</annotation></semantics></math>-th thought step <math alttext="T_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><msub id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml"><mi id="S2.SS2.p3.2.m2.1.1.2" xref="S2.SS2.p3.2.m2.1.1.2.cmml">T</mi><mi id="S2.SS2.p3.2.m2.1.1.3" xref="S2.SS2.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><apply id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.1.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p3.2.m2.1.1.2.cmml" xref="S2.SS2.p3.2.m2.1.1.2">𝑇</ci><ci id="S2.SS2.p3.2.m2.1.1.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">T_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, instead of using the current step <math alttext="T_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m3.1"><semantics id="S2.SS2.p3.3.m3.1a"><msub id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml"><mi id="S2.SS2.p3.3.m3.1.1.2" xref="S2.SS2.p3.3.m3.1.1.2.cmml">T</mi><mi id="S2.SS2.p3.3.m3.1.1.3" xref="S2.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><apply id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2">𝑇</ci><ci id="S2.SS2.p3.3.m3.1.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">T_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m3.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> only, or the complete chain of thoughts <math alttext="T_{1},\dots,T_{n}" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m4.3"><semantics id="S2.SS2.p3.4.m4.3a"><mrow id="S2.SS2.p3.4.m4.3.3.2" xref="S2.SS2.p3.4.m4.3.3.3.cmml"><msub id="S2.SS2.p3.4.m4.2.2.1.1" xref="S2.SS2.p3.4.m4.2.2.1.1.cmml"><mi id="S2.SS2.p3.4.m4.2.2.1.1.2" xref="S2.SS2.p3.4.m4.2.2.1.1.2.cmml">T</mi><mn id="S2.SS2.p3.4.m4.2.2.1.1.3" xref="S2.SS2.p3.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p3.4.m4.3.3.2.3" xref="S2.SS2.p3.4.m4.3.3.3.cmml">,</mo><mi id="S2.SS2.p3.4.m4.1.1" mathvariant="normal" xref="S2.SS2.p3.4.m4.1.1.cmml">…</mi><mo id="S2.SS2.p3.4.m4.3.3.2.4" xref="S2.SS2.p3.4.m4.3.3.3.cmml">,</mo><msub id="S2.SS2.p3.4.m4.3.3.2.2" xref="S2.SS2.p3.4.m4.3.3.2.2.cmml"><mi id="S2.SS2.p3.4.m4.3.3.2.2.2" xref="S2.SS2.p3.4.m4.3.3.2.2.2.cmml">T</mi><mi id="S2.SS2.p3.4.m4.3.3.2.2.3" xref="S2.SS2.p3.4.m4.3.3.2.2.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.3b"><list id="S2.SS2.p3.4.m4.3.3.3.cmml" xref="S2.SS2.p3.4.m4.3.3.2"><apply id="S2.SS2.p3.4.m4.2.2.1.1.cmml" xref="S2.SS2.p3.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.2.2.1.1.1.cmml" xref="S2.SS2.p3.4.m4.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p3.4.m4.2.2.1.1.2.cmml" xref="S2.SS2.p3.4.m4.2.2.1.1.2">𝑇</ci><cn id="S2.SS2.p3.4.m4.2.2.1.1.3.cmml" type="integer" xref="S2.SS2.p3.4.m4.2.2.1.1.3">1</cn></apply><ci id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1">…</ci><apply id="S2.SS2.p3.4.m4.3.3.2.2.cmml" xref="S2.SS2.p3.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.3.3.2.2.1.cmml" xref="S2.SS2.p3.4.m4.3.3.2.2">subscript</csymbol><ci id="S2.SS2.p3.4.m4.3.3.2.2.2.cmml" xref="S2.SS2.p3.4.m4.3.3.2.2.2">𝑇</ci><ci id="S2.SS2.p3.4.m4.3.3.2.2.3.cmml" xref="S2.SS2.p3.4.m4.3.3.2.2.3">𝑛</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.3c">T_{1},\dots,T_{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m4.3d">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> to produce the query for RAG, we ensure the query <math alttext="Q_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.5.m5.1"><semantics id="S2.SS2.p3.5.m5.1a"><msub id="S2.SS2.p3.5.m5.1.1" xref="S2.SS2.p3.5.m5.1.1.cmml"><mi id="S2.SS2.p3.5.m5.1.1.2" xref="S2.SS2.p3.5.m5.1.1.2.cmml">Q</mi><mi id="S2.SS2.p3.5.m5.1.1.3" xref="S2.SS2.p3.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m5.1b"><apply id="S2.SS2.p3.5.m5.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.5.m5.1.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p3.5.m5.1.1.2.cmml" xref="S2.SS2.p3.5.m5.1.1.2">𝑄</ci><ci id="S2.SS2.p3.5.m5.1.1.3.cmml" xref="S2.SS2.p3.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m5.1c">Q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.5.m5.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is produced from the current thought step <math alttext="T_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.6.m6.1"><semantics id="S2.SS2.p3.6.m6.1a"><msub id="S2.SS2.p3.6.m6.1.1" xref="S2.SS2.p3.6.m6.1.1.cmml"><mi id="S2.SS2.p3.6.m6.1.1.2" xref="S2.SS2.p3.6.m6.1.1.2.cmml">T</mi><mi id="S2.SS2.p3.6.m6.1.1.3" xref="S2.SS2.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m6.1b"><apply id="S2.SS2.p3.6.m6.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.6.m6.1.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p3.6.m6.1.1.2.cmml" xref="S2.SS2.p3.6.m6.1.1.2">𝑇</ci><ci id="S2.SS2.p3.6.m6.1.1.3.cmml" xref="S2.SS2.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m6.1c">T_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.6.m6.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and previous revised thought steps <math alttext="T_{1:i-1}^{\star}" class="ltx_Math" display="inline" id="S2.SS2.p3.7.m7.1"><semantics id="S2.SS2.p3.7.m7.1a"><msubsup id="S2.SS2.p3.7.m7.1.1" xref="S2.SS2.p3.7.m7.1.1.cmml"><mi id="S2.SS2.p3.7.m7.1.1.2.2" xref="S2.SS2.p3.7.m7.1.1.2.2.cmml">T</mi><mrow id="S2.SS2.p3.7.m7.1.1.2.3" xref="S2.SS2.p3.7.m7.1.1.2.3.cmml"><mn id="S2.SS2.p3.7.m7.1.1.2.3.2" xref="S2.SS2.p3.7.m7.1.1.2.3.2.cmml">1</mn><mo id="S2.SS2.p3.7.m7.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS2.p3.7.m7.1.1.2.3.1.cmml">:</mo><mrow id="S2.SS2.p3.7.m7.1.1.2.3.3" xref="S2.SS2.p3.7.m7.1.1.2.3.3.cmml"><mi id="S2.SS2.p3.7.m7.1.1.2.3.3.2" xref="S2.SS2.p3.7.m7.1.1.2.3.3.2.cmml">i</mi><mo id="S2.SS2.p3.7.m7.1.1.2.3.3.1" xref="S2.SS2.p3.7.m7.1.1.2.3.3.1.cmml">−</mo><mn id="S2.SS2.p3.7.m7.1.1.2.3.3.3" xref="S2.SS2.p3.7.m7.1.1.2.3.3.3.cmml">1</mn></mrow></mrow><mo id="S2.SS2.p3.7.m7.1.1.3" xref="S2.SS2.p3.7.m7.1.1.3.cmml">⋆</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m7.1b"><apply id="S2.SS2.p3.7.m7.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1">superscript</csymbol><apply id="S2.SS2.p3.7.m7.1.1.2.cmml" xref="S2.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.2.1.cmml" xref="S2.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.2.2.cmml" xref="S2.SS2.p3.7.m7.1.1.2.2">𝑇</ci><apply id="S2.SS2.p3.7.m7.1.1.2.3.cmml" xref="S2.SS2.p3.7.m7.1.1.2.3"><ci id="S2.SS2.p3.7.m7.1.1.2.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.2.3.1">:</ci><cn id="S2.SS2.p3.7.m7.1.1.2.3.2.cmml" type="integer" xref="S2.SS2.p3.7.m7.1.1.2.3.2">1</cn><apply id="S2.SS2.p3.7.m7.1.1.2.3.3.cmml" xref="S2.SS2.p3.7.m7.1.1.2.3.3"><minus id="S2.SS2.p3.7.m7.1.1.2.3.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.2.3.3.1"></minus><ci id="S2.SS2.p3.7.m7.1.1.2.3.3.2.cmml" xref="S2.SS2.p3.7.m7.1.1.2.3.3.2">𝑖</ci><cn id="S2.SS2.p3.7.m7.1.1.2.3.3.3.cmml" type="integer" xref="S2.SS2.p3.7.m7.1.1.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.SS2.p3.7.m7.1.1.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m7.1c">T_{1:i-1}^{\star}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.7.m7.1d">italic_T start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math>, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.7.1">i.e</em>.<span class="ltx_text" id="S2.SS2.p3.7.2"></span>, we adopt a <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.7.3">casual reasoning</span> to revise the thoughts using RAG:</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx4">
<tbody id="S2.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Q_{i}" class="ltx_Math" display="inline" id="S2.Ex4.m1.1"><semantics id="S2.Ex4.m1.1a"><msub id="S2.Ex4.m1.1.1" xref="S2.Ex4.m1.1.1.cmml"><mi id="S2.Ex4.m1.1.1.2" xref="S2.Ex4.m1.1.1.2.cmml">Q</mi><mi id="S2.Ex4.m1.1.1.3" xref="S2.Ex4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.Ex4.m1.1b"><apply id="S2.Ex4.m1.1.1.cmml" xref="S2.Ex4.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.1.cmml" xref="S2.Ex4.m1.1.1">subscript</csymbol><ci id="S2.Ex4.m1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.2">𝑄</ci><ci id="S2.Ex4.m1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m1.1c">\displaystyle Q_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex4.m1.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{ToQuery}(I,T_{1:i-1}^{\star},T_{i})" class="ltx_Math" display="inline" id="S2.Ex4.m2.3"><semantics id="S2.Ex4.m2.3a"><mrow id="S2.Ex4.m2.3.3" xref="S2.Ex4.m2.3.3.cmml"><mi id="S2.Ex4.m2.3.3.4" xref="S2.Ex4.m2.3.3.4.cmml"></mi><mo id="S2.Ex4.m2.3.3.3" xref="S2.Ex4.m2.3.3.3.cmml">=</mo><mrow id="S2.Ex4.m2.3.3.2" xref="S2.Ex4.m2.3.3.2.cmml"><mtext id="S2.Ex4.m2.3.3.2.4" xref="S2.Ex4.m2.3.3.2.4a.cmml">ToQuery</mtext><mo id="S2.Ex4.m2.3.3.2.3" xref="S2.Ex4.m2.3.3.2.3.cmml">⁢</mo><mrow id="S2.Ex4.m2.3.3.2.2.2" xref="S2.Ex4.m2.3.3.2.2.3.cmml"><mo id="S2.Ex4.m2.3.3.2.2.2.3" stretchy="false" xref="S2.Ex4.m2.3.3.2.2.3.cmml">(</mo><mi id="S2.Ex4.m2.1.1" xref="S2.Ex4.m2.1.1.cmml">I</mi><mo id="S2.Ex4.m2.3.3.2.2.2.4" xref="S2.Ex4.m2.3.3.2.2.3.cmml">,</mo><msubsup id="S2.Ex4.m2.2.2.1.1.1.1" xref="S2.Ex4.m2.2.2.1.1.1.1.cmml"><mi id="S2.Ex4.m2.2.2.1.1.1.1.2.2" xref="S2.Ex4.m2.2.2.1.1.1.1.2.2.cmml">T</mi><mrow id="S2.Ex4.m2.2.2.1.1.1.1.2.3" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.cmml"><mn id="S2.Ex4.m2.2.2.1.1.1.1.2.3.2" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.2.cmml">1</mn><mo id="S2.Ex4.m2.2.2.1.1.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.1.cmml">:</mo><mrow id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.cmml"><mi id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.2" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.2.cmml">i</mi><mo id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.1" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.3" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></mrow><mo id="S2.Ex4.m2.2.2.1.1.1.1.3" xref="S2.Ex4.m2.2.2.1.1.1.1.3.cmml">⋆</mo></msubsup><mo id="S2.Ex4.m2.3.3.2.2.2.5" xref="S2.Ex4.m2.3.3.2.2.3.cmml">,</mo><msub id="S2.Ex4.m2.3.3.2.2.2.2" xref="S2.Ex4.m2.3.3.2.2.2.2.cmml"><mi id="S2.Ex4.m2.3.3.2.2.2.2.2" xref="S2.Ex4.m2.3.3.2.2.2.2.2.cmml">T</mi><mi id="S2.Ex4.m2.3.3.2.2.2.2.3" xref="S2.Ex4.m2.3.3.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.Ex4.m2.3.3.2.2.2.6" stretchy="false" xref="S2.Ex4.m2.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex4.m2.3b"><apply id="S2.Ex4.m2.3.3.cmml" xref="S2.Ex4.m2.3.3"><eq id="S2.Ex4.m2.3.3.3.cmml" xref="S2.Ex4.m2.3.3.3"></eq><csymbol cd="latexml" id="S2.Ex4.m2.3.3.4.cmml" xref="S2.Ex4.m2.3.3.4">absent</csymbol><apply id="S2.Ex4.m2.3.3.2.cmml" xref="S2.Ex4.m2.3.3.2"><times id="S2.Ex4.m2.3.3.2.3.cmml" xref="S2.Ex4.m2.3.3.2.3"></times><ci id="S2.Ex4.m2.3.3.2.4a.cmml" xref="S2.Ex4.m2.3.3.2.4"><mtext id="S2.Ex4.m2.3.3.2.4.cmml" xref="S2.Ex4.m2.3.3.2.4">ToQuery</mtext></ci><vector id="S2.Ex4.m2.3.3.2.2.3.cmml" xref="S2.Ex4.m2.3.3.2.2.2"><ci id="S2.Ex4.m2.1.1.cmml" xref="S2.Ex4.m2.1.1">𝐼</ci><apply id="S2.Ex4.m2.2.2.1.1.1.1.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m2.2.2.1.1.1.1.1.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1">superscript</csymbol><apply id="S2.Ex4.m2.2.2.1.1.1.1.2.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m2.2.2.1.1.1.1.2.1.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1">subscript</csymbol><ci id="S2.Ex4.m2.2.2.1.1.1.1.2.2.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.2.2">𝑇</ci><apply id="S2.Ex4.m2.2.2.1.1.1.1.2.3.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3"><ci id="S2.Ex4.m2.2.2.1.1.1.1.2.3.1.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.1">:</ci><cn id="S2.Ex4.m2.2.2.1.1.1.1.2.3.2.cmml" type="integer" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.2">1</cn><apply id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3"><minus id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.1.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.1"></minus><ci id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.2.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.2">𝑖</ci><cn id="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.3.cmml" type="integer" xref="S2.Ex4.m2.2.2.1.1.1.1.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.Ex4.m2.2.2.1.1.1.1.3.cmml" xref="S2.Ex4.m2.2.2.1.1.1.1.3">⋆</ci></apply><apply id="S2.Ex4.m2.3.3.2.2.2.2.cmml" xref="S2.Ex4.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.Ex4.m2.3.3.2.2.2.2.1.cmml" xref="S2.Ex4.m2.3.3.2.2.2.2">subscript</csymbol><ci id="S2.Ex4.m2.3.3.2.2.2.2.2.cmml" xref="S2.Ex4.m2.3.3.2.2.2.2.2">𝑇</ci><ci id="S2.Ex4.m2.3.3.2.2.2.2.3.cmml" xref="S2.Ex4.m2.3.3.2.2.2.2.3">𝑖</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m2.3c">\displaystyle=\text{ToQuery}(I,T_{1:i-1}^{\star},T_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.Ex4.m2.3d">= ToQuery ( italic_I , italic_T start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle T_{1:i}^{\star}" class="ltx_Math" display="inline" id="S2.Ex5.m1.1"><semantics id="S2.Ex5.m1.1a"><msubsup id="S2.Ex5.m1.1.1" xref="S2.Ex5.m1.1.1.cmml"><mi id="S2.Ex5.m1.1.1.2.2" xref="S2.Ex5.m1.1.1.2.2.cmml">T</mi><mrow id="S2.Ex5.m1.1.1.2.3" xref="S2.Ex5.m1.1.1.2.3.cmml"><mn id="S2.Ex5.m1.1.1.2.3.2" xref="S2.Ex5.m1.1.1.2.3.2.cmml">1</mn><mo id="S2.Ex5.m1.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.Ex5.m1.1.1.2.3.1.cmml">:</mo><mi id="S2.Ex5.m1.1.1.2.3.3" xref="S2.Ex5.m1.1.1.2.3.3.cmml">i</mi></mrow><mo id="S2.Ex5.m1.1.1.3" xref="S2.Ex5.m1.1.1.3.cmml">⋆</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.Ex5.m1.1b"><apply id="S2.Ex5.m1.1.1.cmml" xref="S2.Ex5.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex5.m1.1.1.1.cmml" xref="S2.Ex5.m1.1.1">superscript</csymbol><apply id="S2.Ex5.m1.1.1.2.cmml" xref="S2.Ex5.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex5.m1.1.1.2.1.cmml" xref="S2.Ex5.m1.1.1">subscript</csymbol><ci id="S2.Ex5.m1.1.1.2.2.cmml" xref="S2.Ex5.m1.1.1.2.2">𝑇</ci><apply id="S2.Ex5.m1.1.1.2.3.cmml" xref="S2.Ex5.m1.1.1.2.3"><ci id="S2.Ex5.m1.1.1.2.3.1.cmml" xref="S2.Ex5.m1.1.1.2.3.1">:</ci><cn id="S2.Ex5.m1.1.1.2.3.2.cmml" type="integer" xref="S2.Ex5.m1.1.1.2.3.2">1</cn><ci id="S2.Ex5.m1.1.1.2.3.3.cmml" xref="S2.Ex5.m1.1.1.2.3.3">𝑖</ci></apply></apply><ci id="S2.Ex5.m1.1.1.3.cmml" xref="S2.Ex5.m1.1.1.3">⋆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex5.m1.1c">\displaystyle T_{1:i}^{\star}</annotation><annotation encoding="application/x-llamapun" id="S2.Ex5.m1.1d">italic_T start_POSTSUBSCRIPT 1 : italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=p_{\theta}(\cdot|I,T_{1:i-1}^{\star},T_{i},R_{i})." class="ltx_math_unparsed" display="inline" id="S2.Ex5.m2.1"><semantics id="S2.Ex5.m2.1a"><mrow id="S2.Ex5.m2.1b"><mo id="S2.Ex5.m2.1.1">=</mo><msub id="S2.Ex5.m2.1.2"><mi id="S2.Ex5.m2.1.2.2">p</mi><mi id="S2.Ex5.m2.1.2.3">θ</mi></msub><mrow id="S2.Ex5.m2.1.3"><mo id="S2.Ex5.m2.1.3.1" stretchy="false">(</mo><mo id="S2.Ex5.m2.1.3.2" lspace="0em" rspace="0em">⋅</mo><mo fence="false" id="S2.Ex5.m2.1.3.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.Ex5.m2.1.3.4">I</mi><mo id="S2.Ex5.m2.1.3.5">,</mo><msubsup id="S2.Ex5.m2.1.3.6"><mi id="S2.Ex5.m2.1.3.6.2.2">T</mi><mrow id="S2.Ex5.m2.1.3.6.2.3"><mn id="S2.Ex5.m2.1.3.6.2.3.2">1</mn><mo id="S2.Ex5.m2.1.3.6.2.3.1" lspace="0.278em" rspace="0.278em">:</mo><mrow id="S2.Ex5.m2.1.3.6.2.3.3"><mi id="S2.Ex5.m2.1.3.6.2.3.3.2">i</mi><mo id="S2.Ex5.m2.1.3.6.2.3.3.1">−</mo><mn id="S2.Ex5.m2.1.3.6.2.3.3.3">1</mn></mrow></mrow><mo id="S2.Ex5.m2.1.3.6.3">⋆</mo></msubsup><mo id="S2.Ex5.m2.1.3.7">,</mo><msub id="S2.Ex5.m2.1.3.8"><mi id="S2.Ex5.m2.1.3.8.2">T</mi><mi id="S2.Ex5.m2.1.3.8.3">i</mi></msub><mo id="S2.Ex5.m2.1.3.9">,</mo><msub id="S2.Ex5.m2.1.3.10"><mi id="S2.Ex5.m2.1.3.10.2">R</mi><mi id="S2.Ex5.m2.1.3.10.3">i</mi></msub><mo id="S2.Ex5.m2.1.3.11" stretchy="false">)</mo></mrow><mo id="S2.Ex5.m2.1.4" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S2.Ex5.m2.1c">\displaystyle=p_{\theta}(\cdot|I,T_{1:i-1}^{\star},T_{i},R_{i}).</annotation><annotation encoding="application/x-llamapun" id="S2.Ex5.m2.1d">= italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( ⋅ | italic_I , italic_T start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">This allows for the correction of errors in the original thoughts <math alttext="T" class="ltx_Math" display="inline" id="S2.SS2.p5.1.m1.1"><semantics id="S2.SS2.p5.1.m1.1a"><mi id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><ci id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.1.m1.1d">italic_T</annotation></semantics></math> by continually consulting different reference texts and ensures that each step of reasoning is informed by the most accurate and relevant information, significantly improving the quality and reliability of the generated output.</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1">Our hypothesis why our method can address the two problems mentioned at the beginning of this section is as follows. Firstly, the most straightforward way to know what information will be used in complex reasoning is to “see” the reasoning steps. Our approach leverages all the generated thoughts along with the task prompt to provide more clues for more effective retrieval. Secondly, some information cannot be directly retrieved, especially information related to the final answer to a hard complex question. Instead, retrieval of information relevant to intermediate questions, which are assumed to be easier, is more accessible. Thanks to the compositional nature of many reasoning tasks, an iterative retrieval process could also be more effective. Thirdly, correcting potential hallucinations needs to be targeted. Revising a complete CoT with RAG could introduce errors at otherwise already-correct steps. Revising every step one by one could be more reliable. The first two points address question (1) and the last point addresses question (2). Quantitative evidence can be found in our ablation studies in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#S3.SS4" title="3.4 Ablation Study ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Section 3.4</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We test our proposed method <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> on a diverse set of benchmarks that highlight long-horizon generation and reasoning. Existing methods traditionally struggle in those benchmarks; “hallucinated" steps are obvious in LLMs’ outputs. Those steps either fail to stick to the original query or are plainly invalid. We kindly refer readers to subsection 3.3 (case analysis) for a more detailed discussion. Due to space constraints, we do not introduce each benchmark setting, nor do we discuss our results in each benchmark in full length. Rather, this section provides a comprehensive demonstration of our method’s performance and provides a spotlight to provide preliminary empirical analysis about why and when our method works and when it fails.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setups</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We adopt four groups of benchmarks.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Code generation results on different benchmarks.<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S3.T1.2.m1.1"><semantics id="S3.T1.2.m1.1b"><msup id="S3.T1.2.m1.1.1" xref="S3.T1.2.m1.1.1.cmml"><mi id="S3.T1.2.m1.1.1b" xref="S3.T1.2.m1.1.1.cmml"></mi><mo id="S3.T1.2.m1.1.1.1" xref="S3.T1.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.2.m1.1c"><apply id="S3.T1.2.m1.1.1.cmml" xref="S3.T1.2.m1.1.1"><times id="S3.T1.2.m1.1.1.1.cmml" xref="S3.T1.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.m1.1d">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.m1.1e">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>All tests are evaluated under zero-shot (0-demonstration) settings. We also report the <span class="ltx_text" id="S3.T1.5.1" style="color:#FF0000;">relative improvements</span> between RAT and DIRECT methods.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.3" style="width:429.3pt;height:317.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-29.0pt,21.4pt) scale(0.88108685456853,0.88108685456853) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.3.1">
<tr class="ltx_tr" id="S3.T1.3.1.1">
<td class="ltx_td ltx_border_t" id="S3.T1.3.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T1.3.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">HumanEval</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">HumanEval+</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">MBPP</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">MBPP+</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Average <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.3.1.1.1.m1.1"><semantics id="S3.T1.3.1.1.1.m1.1a"><mo id="S3.T1.3.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.1.1.1.m1.1b"><ci id="S3.T1.3.1.1.1.m1.1.1.cmml" xref="S3.T1.3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.1.1.1.m1.1d">↑</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.2">
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.2.1" rowspan="-2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.2.1.1">Base Models</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.2.2" rowspan="-2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.2.2.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.2.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.3">
<td class="ltx_td ltx_border_t" id="S3.T1.3.1.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">DIRECT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.78%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.85%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">30.85%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.59%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.27%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.27%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.22%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.17%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.28%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.3.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">44.97%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.4">
<td class="ltx_td" id="S3.T1.3.1.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">CoT</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.86%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.58%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.12%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.83%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.99%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.91%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.4.9.1">42.19%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.51%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.79%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.4.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.21%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.5">
<td class="ltx_td" id="S3.T1.3.1.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG_1 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.50%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.65%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.66%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.83%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.41%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.63%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">43.66%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">50.09%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.56%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.80%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.6">
<td class="ltx_td" id="S3.T1.3.1.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG_5 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.90%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.90%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.37%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.75%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">34.06%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">53.90%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">43.35%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.10" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.6.10.1">51.08%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.92%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.91%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.7">
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.1" rowspan="-5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.7.1.1">CodeLlama-7b</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.3.1">39.57%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.4.1">51.34%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.5.1">36.22%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.6.1">46.50%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.7.1">40.86%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.8.1">60.63%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">39.14%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.04%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.11" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.11.1">38.95%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.12" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.7.12.1">51.63%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.8">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Relative Improvement</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.2.1" style="color:#FF0000;">17.14%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.3.1" style="color:#FF0000;">25.68%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.4.1" style="color:#FF0000;">17.41%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.5.1" style="color:#FF0000;">27.08%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.6.1" style="color:#FF0000;">4.05%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.7.1" style="color:#FF0000;">11.72%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.8.1" style="color:#FF0000;">-5.05%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.9.1" style="color:#FF0000;">-0.27%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.10" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.10.1" style="color:#FF0000;">7.35%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.8.11" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.8.11.1" style="color:#FF0000;">14.80%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.9">
<td class="ltx_td ltx_border_t" id="S3.T1.3.1.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">DIRECT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">50.49%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">72.56%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.09%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.55%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.9.7.1">60.84%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">72.95%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.92%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">64.09%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">53.59%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.04%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.10">
<td class="ltx_td" id="S3.T1.3.1.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">CoT</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.31%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">75.88%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.72%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">74.85%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.19%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">65.49%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.69%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">62.94%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.98%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">69.79%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.11">
<td class="ltx_td" id="S3.T1.3.1.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG_1 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">50.61%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">76.22%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.22%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.55%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.23%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.54%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">53.62%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">68.09%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.92%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.11.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">71.35%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.12">
<td class="ltx_td" id="S3.T1.3.1.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG_5 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">45.49%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">74.39%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.58%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.55%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.39%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">69.73%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.98%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">70.10%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">49.61%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.12.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">71.19%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.13">
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.1" rowspan="-5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.13.1.1">GPT-3.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.3.1">59.27%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.4.1">80.49%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.5.1">56.31%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.6.1">76.07%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.13.7.1" style="color:#000000;">59.31%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.13.8.1" style="color:#000000;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.8.1.1" style="color:#000000;">74.74%</span></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.13.9.1" style="color:#000000;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.9.1.1" style="color:#000000;">59.10%</span></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.10" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.13.10.1" style="color:#000000;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.10.1.1" style="color:#000000;">72.61%</span></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.11" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.11.1">58.50%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.13.12" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.13.12.1">75.98%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.14">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S3.T1.3.1.14.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Relative Improvement</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.2.1" style="color:#FF0000;">17.39%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.3.1" style="color:#FF0000;">10.93%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.4.1" style="color:#FF0000;">17.09%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.5.1" style="color:#FF0000;">7.82%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.6.1" style="color:#FF0000;">-2.51%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.7.1" style="color:#FF0000;">2.45%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.8.1" style="color:#FF0000;">7.61%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.9.1" style="color:#FF0000;">13.29%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.10" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.10.1" style="color:#FF0000;">9.17%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.14.11" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.14.11.1" style="color:#FF0000;">8.48%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.15">
<td class="ltx_td ltx_border_t" id="S3.T1.3.1.15.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">DIRECT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.32%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">78.66%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.36%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">76.69%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.00%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">76.07%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">66.13%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">78.53%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.45%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.15.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.49%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.16">
<td class="ltx_td" id="S3.T1.3.1.16.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">CoT</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.87%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">72.56%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.90%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">66.25%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">61.22%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">74.23%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">64.42%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.75%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.10%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.16.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">73.20%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.17">
<td class="ltx_td" id="S3.T1.3.1.17.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG_1 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">61.10%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.27%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.04%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.30%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.53%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">69.94%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">65.77%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">77.30%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.86%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.17.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">75.95%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.18">
<td class="ltx_td" id="S3.T1.3.1.18.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG_5 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">62.80%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">82.93%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.51%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">79.75%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">60.12%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">74.23%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">63.56%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">78.53%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">61.50%</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.18.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">78.86%</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.19">
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.1" rowspan="-5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.19.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.3.1">69.33%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.4.1">88.40%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.5.1">64.63%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.6.1">82.21%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.7.1">68.90%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.8.1">79.85%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.9.1">67.36%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.10" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.10.1">82.14%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.11" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.11.1">67.55%</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.19.12" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.19.12.1">83.15%</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.20">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" colspan="2" id="S3.T1.3.1.20.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Relative Improvement</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.2.1" style="color:#FF0000;">20.94%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.3.1" style="color:#FF0000;">12.38%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.4.1" style="color:#FF0000;">18.89%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.5.1" style="color:#FF0000;">7.20%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.6.1" style="color:#FF0000;">14.83%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.7.1" style="color:#FF0000;">4.97%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.8.1" style="color:#FF0000;">1.86%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.9.1" style="color:#FF0000;">4.60%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.10" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.10.1" style="color:#FF0000;">13.63%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.3.1.20.11" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T1.3.1.20.11.1" style="color:#FF0000;">7.31%</span></td>
</tr>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold" id="S3.T2.13.1">Evaluation results on mathematical reasoning, creative writing, and embodied planning tasks.</span> Among them, mathematical reasoning and creative writing use <span class="ltx_text ltx_font_typewriter" id="S3.T2.14.2">gpt-3.5</span> as base models, while embodied planning uses <span class="ltx_text ltx_font_typewriter" id="S3.T2.15.3">gpt-4</span> as base models. <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.2.m1.1"><semantics id="S3.T2.2.m1.1b"><mi id="S3.T2.2.m1.1.1" mathvariant="normal" xref="S3.T2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.2.m1.1c"><ci id="S3.T2.2.m1.1.1.cmml" xref="S3.T2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.m1.1e">roman_Δ</annotation></semantics></math> represents the relative improvements than DIRECT.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.9" style="width:429.3pt;height:93.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-75.0pt,16.3pt) scale(0.741016390192119,0.741016390192119) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.9.7">
<tr class="ltx_tr" id="S3.T2.6.4.4">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.6.4.4.5" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S3.T2.6.4.4.5.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T2.4.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.3.1.1.1.1">Math Reasoning Accuracy <math alttext="{}^{*}" class="ltx_Math" display="inline" id="S3.T2.3.1.1.1.1.m1.1"><semantics id="S3.T2.3.1.1.1.1.m1.1a"><msup id="S3.T2.3.1.1.1.1.m1.1.1" xref="S3.T2.3.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.3.1.1.1.1.m1.1.1a" xref="S3.T2.3.1.1.1.1.m1.1.1.cmml"></mi><mo id="S3.T2.3.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="S3.T2.3.1.1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T2.3.1.1.1.1.m1.1b"><apply id="S3.T2.3.1.1.1.1.m1.1.1.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1"><times id="S3.T2.3.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.1.1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.4.2.2.2.m1.1"><semantics id="S3.T2.4.2.2.2.m1.1a"><mo id="S3.T2.4.2.2.2.m1.1.1" stretchy="false" xref="S3.T2.4.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.2.2.2.m1.1b"><ci id="S3.T2.4.2.2.2.m1.1.1.cmml" xref="S3.T2.4.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.2.2.2.m1.1d">↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T2.5.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.5.3.3.3.1">Creative Writing</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.5.3.3.3.m1.1"><semantics id="S3.T2.5.3.3.3.m1.1a"><mo id="S3.T2.5.3.3.3.m1.1.1" stretchy="false" xref="S3.T2.5.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.3.3.3.m1.1b"><ci id="S3.T2.5.3.3.3.m1.1.1.cmml" xref="S3.T2.5.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.3.3.3.m1.1d">↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T2.6.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_text ltx_font_bold" id="S3.T2.6.4.4.4.1">Embodied Planning</span> <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.6.4.4.4.m1.1"><semantics id="S3.T2.6.4.4.4.m1.1a"><mo id="S3.T2.6.4.4.4.m1.1.1" stretchy="false" xref="S3.T2.6.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.4.4.4.m1.1b"><ci id="S3.T2.6.4.4.4.m1.1.1.cmml" xref="S3.T2.6.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.6.4.4.4.m1.1d">↑</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.7">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">GSM8K</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">GSMHard</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.7.5.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Average (<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.7.5.5.1.m1.1"><semantics id="S3.T2.7.5.5.1.m1.1a"><mi id="S3.T2.7.5.5.1.m1.1.1" mathvariant="normal" xref="S3.T2.7.5.5.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.7.5.5.1.m1.1b"><ci id="S3.T2.7.5.5.1.m1.1.1.cmml" xref="S3.T2.7.5.5.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.5.5.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.7.5.5.1.m1.1d">roman_Δ</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">Win Rate</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.8.6.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">TrueSkill Rating (<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.8.6.6.2.m1.1"><semantics id="S3.T2.8.6.6.2.m1.1a"><mi id="S3.T2.8.6.6.2.m1.1.1" mathvariant="normal" xref="S3.T2.8.6.6.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.8.6.6.2.m1.1b"><ci id="S3.T2.8.6.6.2.m1.1.1.cmml" xref="S3.T2.8.6.6.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.6.6.2.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.8.6.6.2.m1.1d">roman_Δ</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">Uncertainty</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">Executablity</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Plausibitlity (<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.9.7.7.3.m1.1"><semantics id="S3.T2.9.7.7.3.m1.1a"><mi id="S3.T2.9.7.7.3.m1.1.1" mathvariant="normal" xref="S3.T2.9.7.7.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.9.7.7.3.m1.1b"><ci id="S3.T2.9.7.7.3.m1.1.1.cmml" xref="S3.T2.9.7.7.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.7.7.3.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.9.7.7.3.m1.1d">roman_Δ</annotation></semantics></math>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.7.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">Uncertainty</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.9.7.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DIRECT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">65.85%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.26%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">58.56%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">46.67%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">19.33±2.08%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">20.57</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.9.7.8.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.05</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.9">
<td class="ltx_td ltx_align_left" id="S3.T2.9.7.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">CoT</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">63.82%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">44.72%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.27(-7.32)%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.67%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.31(-0.0%)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.09</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">49.33±3.05%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.75(+25.2%)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.9.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.33</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.10">
<td class="ltx_td ltx_align_left" id="S3.T2.9.7.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG-1 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">61.81%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.26%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">56.54(+4.17)%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">38.71%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.99(-1.6%)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.11</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.00±5.29%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">24.97(+21.4%)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.10.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.11</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.11">
<td class="ltx_td ltx_align_left" id="S3.T2.9.7.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAG-5 shot</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">61.81%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">56.78%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.30(+4.88)%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">31.67%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.88(-2.1%)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.22</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.00±3.61%</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.02(+21.6%)</td>
<td class="ltx_td ltx_align_center" id="S3.T2.9.7.11.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.11</td>
</tr>
<tr class="ltx_tr" id="S3.T2.9.7.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.9.7.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAT</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.2.1">71.36%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.3.1">67.34%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.4.1">69.35(+16.96)%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.5.1">81.01%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.6.1">29.07(+19.2%)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.08</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.8.1">76.67±8.02%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.9.7.12.9.1">29.37(+42.78%)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.9.7.12.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">3.37</td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Code Generation</span> includess HumanEval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib9" title="">2021</a>)</cite>, HumanEval+ <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>, MBPP <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib2" title="">2021</a>)</cite>, and MBPP+ <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>. These benchmarks encompass a wide range of programming problems, from simple function implementations to more complex algorithmic challenges, providing a robust testbed for assessing generative capabilities.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Mathematical Reasoning</span> evaluation is conducted on GSM8K and GSM-HARD dataset, which comprises thousands of multi-step mathematical problems <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib10" title="">2021</a>; Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib16" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Creative Writing</span> tasks are conducted to evaluate the versatility of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>, including survey, summarization <em class="ltx_emph ltx_font_italic" id="S3.SS1.p4.1.2">etc</em>., highlighting different aspects of open-ended text generation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Embodied Planning</span> tasks are evaluated on open-ended environments Minecraft. A set of 100 tasks ranging from simple objectives to challenging diamond objectives are evaluated through MC-TextWorld <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib32" title="">2023</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Evaluation Metrics</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">For code generation, the classical pass rate pass@k is selected as the evaluation metrics <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib9" title="">2021</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>, <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.1.m1.1d">italic_k</annotation></semantics></math> denotes the sampling number. We compute accuracy to evaluate every question in mathematical reasoning tasks, aligning with the established metric for the GSM8K <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib10" title="">2021</a>)</cite>. For embodied planning tasks, we compute the plan execution success rate in MC-TextWorld as executability <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib32" title="">2023</a>)</cite>. We also conduct human elo rating evaluation to compute the trueskill rating score <cite class="ltx_cite ltx_citemacro_citep">(Herbrich et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib20" title="">2006</a>)</cite> for embodied planning (as plausibility) and creative writing tasks. These indicators are better the higher they are.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Baselines</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">To establish a comprehensive and equitable comparison landscape, we incorporate a suite of baseline methods. Our baselines include the original language models, referred to as DIRECT, and the Retrieval-Augmented Generation (RAG) methodology with <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.1.m1.1d">italic_n</annotation></semantics></math> retrieved examples, instantiated in both single-shot (1 shot) and multi-shot (5 shots) configurations, as documented by <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib28" title="">2020b</a>)</cite>. Additionally, we examine the zero-shot <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> (CoT) approach, as conceptualized by <cite class="ltx_cite ltx_citemacro_citet">Kojima et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib26" title="">2022</a>)</cite>, which simulates a step-by-step reasoning process to facilitate complex problem-solving tasks under zero demonstration.
For different methods, the same language model is used as base models.
To ensure a fair comparison, none of the methods used examples from the benchmark as demonstrations for in-context learning.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">RAG Settings</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.1"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> leverages the capabilities of Retrieval-Augmented Generation methods, which enhance the performance of language models by integrating external knowledge sources. Specifically, we employed the <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px3.p1.1.1">codeparrot/github-jupyter</span> dataset as our primary search vector library for code generation and mathematical reasoning tasks.
For embodied planning tasks in Minecraft, we utilized the Minecraft Wiki<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://minecraft.wiki/" title="">https://minecraft.wiki/</a></span></span></span> and DigMinecraft<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.digminecraft.com/" title="">https://www.digminecraft.com/</a></span></span></span> websites as the information sources accessible to the LLMs.
For open-ended creative writing tasks, we use Google to search the query on the Internet.
We utilized OpenAI’s <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px3.p1.1.2">text-embedding-ada-002</span> API service for all embedding calculations across different methods and base models.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p2.1">Acknowledging the risk of benchmark contamination (an issue where the code library may contain solutions to the exact problems being evaluated), we adopted a rigorous pre-processing methodology as described by <cite class="ltx_cite ltx_citemacro_citet">Guo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib19" title="">2024</a>)</cite>.
The potential implications of benchmark contamination, along with the effectiveness of our pre-processing strategy, are discussed in detail in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A4" title="Appendix D Disscussions on Benchmark Contamination ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Results</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The code generation results presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.T1" title="Table 1 ‣ 3.1 Experimental Setups ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">1</span></a> and results on other benchmarks presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.T2" title="Table 2 ‣ 3.1 Experimental Setups ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrate the comprehensive evaluation of the <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> across multiple benchmarks.
<abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> consistently outperforms the other methods across the majority of the benchmarks and metrics, showcasing its superior ability to generate long-horizon context. Notably, in the HumanEval and HumanEval+ benchmarks of code generation, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> achieves remarkable improvements in pass@1 and pass@5 rates, indicating a significant enhancement in first-attempt accuracy and within the top five attempts. For example, on the HumanEval benchmark, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> improves pass@1 by up to 20.94% and pass@5 by up to 25.68% relative to the base models’ performances. This trend is observed across different underlying base models, highlighting <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s effectiveness regardless of the initial model’s capabilities.
For mathematical reasoning tasks, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> demonstrates a significant relative improvement, with an 8.37% increase in accuracy on GSM8K and a remarkable 31.37% increase on GSMHard, culminating in an overall average improvement of 18.44% when deployed on the GPT-3.5 model.
<abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> significantly outperforms all other methods on open-ended embodied planning tasks in Minecraft, achieving the highest scores with 76.67±8.02% for executability and 29.37 human rating score for plausibility, demonstrating its superior ability to generate feasible and contextually appropriate plans in the complex open-world environment.
<abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s superior performance also keeps across a broad spectrum of creative writing tasks. Its ability to generate high-quality content in diverse scenarios was demonstrated, highlighting its potential as a powerful tool for enhancing the general creative writing capabilities of LLMs in open-ended scenarios.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The tasks are extremely diverse, while <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> can have consistent improvements over all baselines.
These results underline the advantages of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s approach, which leverages iterative refinement of retrieval queries based on evolving reasoning thoughts. This strategy not only enhances the relevance and quality of the information retrieved but also significantly improves the accuracy and efficiency of the generated context.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Case Analysis</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Here we take the embodied planning task and creative writing task to do case analysis.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">In a manner analogous to multi-document question-answering tasks <cite class="ltx_cite ltx_citemacro_citep">(Trivedi et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib49" title="">2022a</a>)</cite>, the task of long-horizon planning in Minecraft is knowledge-dense, requiring consideration of various items for the completion of each task.
However, open-world Minecraft knowledge on the internet is fragmented, making task completion often dependent on information from multiple sources. We observed that while language models like ChatGPT can identify necessary items through zero-shot CoT reasoning, inaccuracies in procedural steps are common. For example, ChatGPT inaccurately identified the materials for a crafting table as 4 wood blocks (the right answer is 4 planks), indicating lower executability reliability in CoT plans. Classical RAG algorithms, retrieving the knowledge with the question as a query and focusing on the final target item, inadequately retrieve intermediary items, offering minimal task improvement. Contrastingly, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> improves upon CoT’s initial answers by continuously refining thoughts with targeted retrieval, aligning closely with task progression and relevant item knowledge. This methodology significantly enhances planning effectiveness by ensuring a comprehensive understanding and retrieval of all items involved in a plan, highlighting the synergy between structured reasoning and dynamic knowledge retrieval in addressing long-horizon planning challenges in Minecraft.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">In addressing open-ended creative writing tasks, assessments of LM’s generations typically focus on completeness and accuracy. When tasked with “summarizing the American Civil War according to a timeline”, LMs under DIRECT and CoT prompts often produce significant hallucinations. For example, the statement “The Civil War officially began on April 12, 1860, when Confederate troops attacked Fort Sumter in South Carolina, a Union-held fort” contains incorrect information, where the year 1860 is erroneously mentioned instead of the correct year, 1861.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">Direct queries to the internet for this task tend to retrieve limited events, frequently overlooking the accurate start date of the war, April 12, 1861. Moreover, the RAG approach, which tends to summarize content retrieved from searches, often misses this event in its responses, whether it’s RAG-1 or RAG-5. On the other hand, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> bases its search on a language model’s draft answer, finding that hallucinations usually occur in details, such as specific dates, which do not hinder the search engine from identifying relevant information like “American Civil War starting date”. RAT utilizes the content retrieved to identify and correct errors in the draft answer rather than merely summarizing the retrieved content. Therefore, RAT can achieve a complete generation through reasoning and enhance the accuracy and credibility of the answer by leveraging retrieved knowledge. Experimental results validate the effectiveness of RAT.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Ablation Study</h3>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparative Impact of Retrieval Strategies on <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> Performance.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.8" style="width:429.3pt;height:120.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(54.9pt,-15.5pt) scale(1.34373372943033,1.34373372943033) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.8.8">
<tr class="ltx_tr" id="S3.T3.8.8.9">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T3.8.8.9.1" rowspan="2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S3.T3.8.8.9.1.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T3.8.8.9.2" style="padding-top:1pt;padding-bottom:1pt;">HumanEval</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T3.8.8.9.3" style="padding-top:1pt;padding-bottom:1pt;">HumanEval+</td>
</tr>
<tr class="ltx_tr" id="S3.T3.8.8.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">pass@1(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T3.1.1.1.1.m1.1"><semantics id="S3.T3.1.1.1.1.m1.1a"><mi id="S3.T3.1.1.1.1.m1.1.1" mathvariant="normal" xref="S3.T3.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.m1.1b"><ci id="S3.T3.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T3.1.1.1.1.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T3.2.2.2.2.m2.1"><semantics id="S3.T3.2.2.2.2.m2.1a"><mo id="S3.T3.2.2.2.2.m2.1.1" stretchy="false" xref="S3.T3.2.2.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.2.m2.1b"><ci id="S3.T3.2.2.2.2.m2.1.1.cmml" xref="S3.T3.2.2.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.2.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.2.2.2.2.m2.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.4.4.4.4" style="padding-top:1pt;padding-bottom:1pt;">pass@5(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T3.3.3.3.3.m1.1"><semantics id="S3.T3.3.3.3.3.m1.1a"><mi id="S3.T3.3.3.3.3.m1.1.1" mathvariant="normal" xref="S3.T3.3.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.3.m1.1b"><ci id="S3.T3.3.3.3.3.m1.1.1.cmml" xref="S3.T3.3.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.3.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T3.3.3.3.3.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T3.4.4.4.4.m2.1"><semantics id="S3.T3.4.4.4.4.m2.1a"><mo id="S3.T3.4.4.4.4.m2.1.1" stretchy="false" xref="S3.T3.4.4.4.4.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.4.4.m2.1b"><ci id="S3.T3.4.4.4.4.m2.1.1.cmml" xref="S3.T3.4.4.4.4.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.4.4.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.4.4.4.4.m2.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.6.6.6.6" style="padding-top:1pt;padding-bottom:1pt;">pass@1(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T3.5.5.5.5.m1.1"><semantics id="S3.T3.5.5.5.5.m1.1a"><mi id="S3.T3.5.5.5.5.m1.1.1" mathvariant="normal" xref="S3.T3.5.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.5.5.m1.1b"><ci id="S3.T3.5.5.5.5.m1.1.1.cmml" xref="S3.T3.5.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.5.5.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T3.5.5.5.5.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T3.6.6.6.6.m2.1"><semantics id="S3.T3.6.6.6.6.m2.1a"><mo id="S3.T3.6.6.6.6.m2.1.1" stretchy="false" xref="S3.T3.6.6.6.6.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.6.6.m2.1b"><ci id="S3.T3.6.6.6.6.m2.1.1.cmml" xref="S3.T3.6.6.6.6.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.6.6.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.6.6.6.6.m2.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.8.8.8.8" style="padding-top:1pt;padding-bottom:1pt;">pass@5(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T3.7.7.7.7.m1.1"><semantics id="S3.T3.7.7.7.7.m1.1a"><mi id="S3.T3.7.7.7.7.m1.1.1" mathvariant="normal" xref="S3.T3.7.7.7.7.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.7.7.m1.1b"><ci id="S3.T3.7.7.7.7.m1.1.1.cmml" xref="S3.T3.7.7.7.7.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.7.7.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T3.7.7.7.7.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T3.8.8.8.8.m2.1"><semantics id="S3.T3.8.8.8.8.m2.1a"><mo id="S3.T3.8.8.8.8.m2.1.1" stretchy="false" xref="S3.T3.8.8.8.8.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.8.8.m2.1b"><ci id="S3.T3.8.8.8.8.m2.1.1.cmml" xref="S3.T3.8.8.8.8.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.8.8.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T3.8.8.8.8.m2.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.8.8.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.8.8.10.1" style="padding-top:1pt;padding-bottom:1pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.8.8.10.2" style="padding-top:1pt;padding-bottom:1pt;">50.6%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.8.8.10.3" style="padding-top:1pt;padding-bottom:1pt;">76.2%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.8.8.10.4" style="padding-top:1pt;padding-bottom:1pt;">48.2%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.8.8.10.5" style="padding-top:1pt;padding-bottom:1pt;">70.5%</td>
</tr>
<tr class="ltx_tr" id="S3.T3.8.8.11">
<td class="ltx_td ltx_align_left" id="S3.T3.8.8.11.1" style="padding-top:1pt;padding-bottom:1pt;">CoT+RAG</td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.11.2" style="padding-top:1pt;padding-bottom:1pt;">53.9(<span class="ltx_text" id="S3.T3.8.8.11.2.1" style="color:#FF0000;">+3.3</span>)%</td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.11.3" style="padding-top:1pt;padding-bottom:1pt;">76.8(<span class="ltx_text" id="S3.T3.8.8.11.3.1" style="color:#FF0000;">+0.6</span>)%</td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.11.4" style="padding-top:1pt;padding-bottom:1pt;">51.3(<span class="ltx_text" id="S3.T3.8.8.11.4.1" style="color:#FF0000;">+3.1</span>)%</td>
<td class="ltx_td ltx_align_center" id="S3.T3.8.8.11.5" style="padding-top:1pt;padding-bottom:1pt;">69.3(<span class="ltx_text" id="S3.T3.8.8.11.5.1" style="color:#FF0000;">-1.2</span>)%</td>
</tr>
<tr class="ltx_tr" id="S3.T3.8.8.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.8.8.12.1" style="padding-top:1pt;padding-bottom:1pt;"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.8.8.12.2" style="padding-top:1pt;padding-bottom:1pt;">59.2(<span class="ltx_text" id="S3.T3.8.8.12.2.1" style="color:#FF0000;">+8.7</span>)%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.8.8.12.3" style="padding-top:1pt;padding-bottom:1pt;">80.4(<span class="ltx_text" id="S3.T3.8.8.12.3.1" style="color:#FF0000;">+7.9</span>)%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.8.8.12.4" style="padding-top:1pt;padding-bottom:1pt;">56.3(<span class="ltx_text" id="S3.T3.8.8.12.4.1" style="color:#FF0000;">+8.2</span>)%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.8.8.12.5" style="padding-top:1pt;padding-bottom:1pt;">76.0(<span class="ltx_text" id="S3.T3.8.8.12.5.1" style="color:#FF0000;">+5.5</span>)%</td>
</tr>
</table>
</span></div>
</figure>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Ablation on retrieval in <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> </h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.1">In this ablation study, we investigate the influence of various retrieval strategies on the efficacy of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>, focusing on the optimization of content retrieval for improving generative outputs. The experimental results, detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.T3" title="Table 3 ‣ 3.4 Ablation Study ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">3</span></a>, highlight the significant advancements achieved through the iterative refinement of retrieval queries in <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> compared to baseline methods. The baseline denoted as RAG-1, employs a direct approach by using the question itself as the retrieval query. In contrast, CoT+RAG enhances this process by utilizing the entirety of the reasoning thoughts output by the language model as the query, aiming for a broader contextual understanding. However, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> introduces a more dynamic method by employing continuously modified parts of reasoning thoughts as queries, which allows for a more focused and relevant information retrieval process.
The comparative analysis shows that <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> surpasses both the baseline and the CoT+RAG method in terms of pass@1 and pass@5 metrics across the HumanEval and HumanEval+ benchmarks. Specifically, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> demonstrates an 8.7 percentage point increase in pass@1 and a 7.9 percentage point increase in pass@5 over the baseline in the HumanEval benchmark, and similarly impressive gains in the HumanEval+ benchmark. These improvements underscore the effectiveness of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s retrieval strategy, which by iteratively refining next queries based on evolving reasoning thoughts and previous queries, ensures the retrieval of highly pertinent information. This process not only enhances the relevance of the information retrieved but also significantly improves the quality and accuracy of the final generated outputs. The results firmly establish the superiority of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s dynamic retrieval method in leveraging contextual nuances to drive more precise and effective generative processes.</p>
</div>
<figure class="ltx_table" id="S3.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation Study on Causal vs. Non-Causal Reasoning in <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T4.8" style="width:429.3pt;height:129.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(65.6pt,-19.8pt) scale(1.44055589853655,1.44055589853655) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T4.8.8">
<tr class="ltx_tr" id="S3.T4.8.8.9">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T4.8.8.9.1" rowspan="2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S3.T4.8.8.9.1.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T4.8.8.9.2" style="padding-top:1pt;padding-bottom:1pt;">HumanEval</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S3.T4.8.8.9.3" style="padding-top:1pt;padding-bottom:1pt;">HumanEval+</td>
</tr>
<tr class="ltx_tr" id="S3.T4.8.8.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">pass@1(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T4.1.1.1.1.m1.1"><semantics id="S3.T4.1.1.1.1.m1.1a"><mi id="S3.T4.1.1.1.1.m1.1.1" mathvariant="normal" xref="S3.T4.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.1.m1.1b"><ci id="S3.T4.1.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T4.1.1.1.1.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T4.2.2.2.2.m2.1"><semantics id="S3.T4.2.2.2.2.m2.1a"><mo id="S3.T4.2.2.2.2.m2.1.1" stretchy="false" xref="S3.T4.2.2.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.2.m2.1b"><ci id="S3.T4.2.2.2.2.m2.1.1.cmml" xref="S3.T4.2.2.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.2.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T4.2.2.2.2.m2.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.4.4.4.4" style="padding-top:1pt;padding-bottom:1pt;">pass@5(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T4.3.3.3.3.m1.1"><semantics id="S3.T4.3.3.3.3.m1.1a"><mi id="S3.T4.3.3.3.3.m1.1.1" mathvariant="normal" xref="S3.T4.3.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T4.3.3.3.3.m1.1b"><ci id="S3.T4.3.3.3.3.m1.1.1.cmml" xref="S3.T4.3.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.3.3.3.3.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T4.3.3.3.3.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T4.4.4.4.4.m2.1"><semantics id="S3.T4.4.4.4.4.m2.1a"><mo id="S3.T4.4.4.4.4.m2.1.1" stretchy="false" xref="S3.T4.4.4.4.4.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.4.4.4.4.m2.1b"><ci id="S3.T4.4.4.4.4.m2.1.1.cmml" xref="S3.T4.4.4.4.4.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.4.4.4.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T4.4.4.4.4.m2.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.6.6.6.6" style="padding-top:1pt;padding-bottom:1pt;">pass@1(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T4.5.5.5.5.m1.1"><semantics id="S3.T4.5.5.5.5.m1.1a"><mi id="S3.T4.5.5.5.5.m1.1.1" mathvariant="normal" xref="S3.T4.5.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T4.5.5.5.5.m1.1b"><ci id="S3.T4.5.5.5.5.m1.1.1.cmml" xref="S3.T4.5.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.5.5.5.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T4.5.5.5.5.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T4.6.6.6.6.m2.1"><semantics id="S3.T4.6.6.6.6.m2.1a"><mo id="S3.T4.6.6.6.6.m2.1.1" stretchy="false" xref="S3.T4.6.6.6.6.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.6.6.6.6.m2.1b"><ci id="S3.T4.6.6.6.6.m2.1.1.cmml" xref="S3.T4.6.6.6.6.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.6.6.6.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T4.6.6.6.6.m2.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.8.8.8.8" style="padding-top:1pt;padding-bottom:1pt;">pass@5(<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T4.7.7.7.7.m1.1"><semantics id="S3.T4.7.7.7.7.m1.1a"><mi id="S3.T4.7.7.7.7.m1.1.1" mathvariant="normal" xref="S3.T4.7.7.7.7.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T4.7.7.7.7.m1.1b"><ci id="S3.T4.7.7.7.7.m1.1.1.cmml" xref="S3.T4.7.7.7.7.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.7.7.7.7.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T4.7.7.7.7.m1.1d">roman_Δ</annotation></semantics></math>)<math alttext="\leavevmode\nobreak\ \uparrow" class="ltx_Math" display="inline" id="S3.T4.8.8.8.8.m2.1"><semantics id="S3.T4.8.8.8.8.m2.1a"><mo id="S3.T4.8.8.8.8.m2.1.1" stretchy="false" xref="S3.T4.8.8.8.8.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.8.8.8.8.m2.1b"><ci id="S3.T4.8.8.8.8.m2.1.1.cmml" xref="S3.T4.8.8.8.8.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.8.8.8.8.m2.1c">\leavevmode\nobreak\ \uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T4.8.8.8.8.m2.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T4.8.8.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T4.8.8.10.1" style="padding-top:1pt;padding-bottom:1pt;">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.8.8.10.2" style="padding-top:1pt;padding-bottom:1pt;">47.3%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.8.8.10.3" style="padding-top:1pt;padding-bottom:1pt;">75.8%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.8.8.10.4" style="padding-top:1pt;padding-bottom:1pt;">41.7%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T4.8.8.10.5" style="padding-top:1pt;padding-bottom:1pt;">74.8%</td>
</tr>
<tr class="ltx_tr" id="S3.T4.8.8.11">
<td class="ltx_td ltx_align_left" id="S3.T4.8.8.11.1" style="padding-top:1pt;padding-bottom:1pt;">Non-Causal</td>
<td class="ltx_td ltx_align_center" id="S3.T4.8.8.11.2" style="padding-top:1pt;padding-bottom:1pt;">57.3(<span class="ltx_text" id="S3.T4.8.8.11.2.1" style="color:#FF0000;">+10.0</span>)%</td>
<td class="ltx_td ltx_align_center" id="S3.T4.8.8.11.3" style="padding-top:1pt;padding-bottom:1pt;">78.0(<span class="ltx_text" id="S3.T4.8.8.11.3.1" style="color:#FF0000;">+2.1</span>)%</td>
<td class="ltx_td ltx_align_center" id="S3.T4.8.8.11.4" style="padding-top:1pt;padding-bottom:1pt;">54.9(<span class="ltx_text" id="S3.T4.8.8.11.4.1" style="color:#FF0000;">+13.2</span>)%</td>
<td class="ltx_td ltx_align_center" id="S3.T4.8.8.11.5" style="padding-top:1pt;padding-bottom:1pt;">74.8(<span class="ltx_text" id="S3.T4.8.8.11.5.1" style="color:#FF0000;">+0.0</span>)%</td>
</tr>
<tr class="ltx_tr" id="S3.T4.8.8.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T4.8.8.12.1" style="padding-top:1pt;padding-bottom:1pt;">Causal</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.8.8.12.2" style="padding-top:1pt;padding-bottom:1pt;">59.2(<span class="ltx_text" id="S3.T4.8.8.12.2.1" style="color:#FF0000;">+11.9</span>)%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.8.8.12.3" style="padding-top:1pt;padding-bottom:1pt;">80.4(<span class="ltx_text" id="S3.T4.8.8.12.3.1" style="color:#FF0000;">+4.6</span>)%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.8.8.12.4" style="padding-top:1pt;padding-bottom:1pt;">56.3(<span class="ltx_text" id="S3.T4.8.8.12.4.1" style="color:#FF0000;">+14.6</span>)%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T4.8.8.12.5" style="padding-top:1pt;padding-bottom:1pt;">76.0(<span class="ltx_text" id="S3.T4.8.8.12.5.1" style="color:#FF0000;">+1.2</span>)%</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Ablation on causal reasoning in <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> </h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p1.1">In this ablation study, we systematically examine the impact of causal and non-causal reasoning approaches on the performance of the <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> system, with the Chain of Thought (CoT) serving as our baseline. Our findings, as summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S3.T4" title="Table 4 ‣ Ablation on retrieval in ‣ 3.4 Ablation Study ‣ 3 Experiments ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">4</span></a>, reveal significant enhancements in generation capabilities when incorporating causal reasoning techniques. Specifically, the causal approach, which iteratively performs reasoning and retrieval, leads to notable improvements in both pass@1 and pass@5 metrics across HumanEval and HumanEval+ benchmarks. For instance, the causal method outperforms the baseline (CoT) by 11.9 percentage points in pass@1 and by 4.6 percentage points in pass@5 on the HumanEval dataset. This approach contrasts with the non-causal method, which, although also surpassing the baseline, leverages the initial reasoning thought to directly retrieve all necessary steps and generate the final answer. The causal method’s superior performance underscores the value of sequential reasoning and information retrieval in enhancing the accuracy and reliability of generated outputs. This iterative process likely aids in refining the search and reasoning steps based on continuously updated context, allowing for more precise and relevant information retrieval, which in turn supports more accurate final answers. These results firmly establish the efficacy of causal reasoning in long-horizon problem-solving tasks.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Robustness of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>
</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> was rigorously validated across a diverse set of tasks, including code generation, mathematical reasoning, creative writing, and embodied planning. This variety of tasks underscores the generalization capability of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>, demonstrating its robust performance across highly diverse challenges. Furthermore, all our experimental settings were conducted in a zero-shot manner; we did not design task-specific prompts for <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>, but rather used the simplest possible prompts (which can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#A2" title="Appendix B Prompt Details ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">B</span></a>) to articulate questions or instructions for all methods. This approach ensures <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s generalization ability in open-ended scenarios.</p>
</div>
<div class="ltx_para" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.1">The diversity of our evaluation was further enhanced by testing <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> across various language models of differing capacities. This included CodeLlama-7b <cite class="ltx_cite ltx_citemacro_citep">(Rozière et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib44" title="">2023</a>)</cite>, ChatGPT (gpt-3.5-turbo) <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib40" title="">2022</a>)</cite>, and the more advanced GPT-4 (gpt-4) model <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib39" title="">2023</a>)</cite>. Remarkably, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> maintained its generalization capability across different scales of language models, showing improvements in benchmarks such as the HumanEval for code generation tasks. Notably, the largest improvement was observed with GPT-4, attributed to its superior ability for in-context learning from retrieved text. On MBPP+, CodeLlama-7b based <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> has demonstrated performance degradation. This decline could be due to the limited in-context learning ability of smaller language models.</p>
</div>
<div class="ltx_para" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.1">For mathematical reasoning tasks, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> demonstrated a significant relative improvement, with an overall average improvement of 18.44% when applied to the GPT-3.5 model. This trend of improvement persisted with GPT-4, which achieved a remarkable 10.26% relative improvement from DIRECT to <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>. These findings highlight <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s robustness and its effective enhancement of language models’ performance across a spectrum of computational and creative tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Works</h2>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Retrieval-augmented Generation (RAG)</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Recently, RAG has gained popularity for boosting the performance of LLMs by guiding their generation process using the retrieved knowledge <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib64" title="">2023</a>)</cite>. Without updating model parameters that may be expensive <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib27" title="">2020a</a>)</cite> or unstable <cite class="ltx_cite ltx_citemacro_citep">(Ke et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib24" title="">2022b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib23" title="">a</a>)</cite>, RAG is a cost-effective way for LLMs to interact with the external world <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib18" title="">2018</a>; Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib27" title="">2020a</a>)</cite>. RAG is widely applied to downstream tasks, such as code generation <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib67" title="">2022b</a>; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib36" title="">2022</a>; Nashid et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib37" title="">2023</a>)</cite>, question answering <cite class="ltx_cite ltx_citemacro_citep">(Baek et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib3" title="">2023</a>; Siriwardhana et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib46" title="">2023</a>)</cite>, and creative writing <cite class="ltx_cite ltx_citemacro_citep">(Wen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib57" title="">2023</a>; Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib1" title="">2023</a>)</cite>. </p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Reasoning-enhanced RAG</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">Some recent works also leverage reasoning to enhance the performance of RAG <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib30" title="">2023b</a>)</cite>. For example, IRCoT <cite class="ltx_cite ltx_citemacro_citep">(Trivedi et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib50" title="">2022b</a>)</cite> exploits CoT to generate better queries for retrieval, IRGR <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib43" title="">2022</a>)</cite>
performs iteratively retrieval to search for suitable
premises for multi-hop QA, GEEK <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib34" title="">2023a</a>)</cite> can choose to query external knowledge or perform
a single logical reasoning step in long-horizon generation tasks, and ITRG <cite class="ltx_cite ltx_citemacro_citep">(Feng et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib14" title="">2023a</a>)</cite> performs retrieval based on the last-step generation. However, these previous RAG methods simply adopt a single query to retrieve the knowledge for question-answering tasks <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib17" title="">2023</a>; Feng et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib15" title="">2023b</a>)</cite>, while our proposed <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> performs retrieval using reasoning and draft answers in an autoregressive way, which significantly improves the performance of RAG in various tasks as demonstrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#S0.F2" title="Figure 2 ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Language Model for Reasoning</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">The advancement of reasoning in language models has seen notable methodologies emerge since <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> was proposed by <cite class="ltx_cite ltx_citemacro_citet">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib56" title="">2022</a>)</cite>, which showcased LMs’ ability to generate self-derived problem-solving strategies. This foundational work spurred further innovations such as the least-to-most prompting <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib65" title="">2022a</a>)</cite>, zero-shot CoT <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib26" title="">2022</a>)</cite>, self-consistency <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib52" title="">2022</a>)</cite>, zero-shot CoT without prompting <cite class="ltx_cite ltx_citemacro_citep">(Wang and Zhou, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib51" title="">2024</a>)</cite>.
Moving beyond basic prompting, <cite class="ltx_cite ltx_citemacro_citet">Creswell et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib12" title="">2022</a>)</cite> introduced the Selection-Inference framework, while <cite class="ltx_cite ltx_citemacro_citet">Zelikman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib62" title="">2022</a>)</cite> developed STaR to refine reasoning through model finetuning. <cite class="ltx_cite ltx_citemacro_citet">Creswell and Shanahan (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib11" title="">2022</a>)</cite> proposed a faithful reasoning model, segmenting reasoning into dedicated steps, similar to Scratchpad’s approach by <cite class="ltx_cite ltx_citemacro_citet">Nye et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib38" title="">2021</a>)</cite> for enhancing multi-step computation. Tree-of-Thought <cite class="ltx_cite ltx_citemacro_citep">(Yao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib59" title="">2023</a>)</cite> and Graph-of-Thought <cite class="ltx_cite ltx_citemacro_citep">(Besta et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib5" title="">2023</a>)</cite> also expand the reasoning paths into a complex structure instead of linear CoT.
These methods usually aim to improve the reasoning ability of LLM by designing prompts or providing feedback from the environment to assist in better planning and decision-making <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib55" title="">2023c</a>; Yao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib58" title="">2022</a>; Shinn et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib45" title="">2023</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib29" title="">2023a</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib63" title="">2023</a>)</cite>.
However, <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> takes a different approach by using RAG to access external knowledge that can help LLM with its reasoning process.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We have presented Retrieval Augmented Thoughts (RAT), a simple yet effective prompting strategy that synergies chain of thought (CoT) prompting and retrieval augmented generation (RAG) to address the challenging long-horizon reasoning and generation tasks. Our key ideas involve revising the zero-shot chain of thoughts produced by LLMs through RAG with the thoughts as queries, and causally revising the thoughts &amp; generating the response progressively. <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>, a <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">zero-shot</span> prompting approach, has demonstrated significant advantages over vanilla CoT prompting, RAG, and other baselines on challenging code generation, mathematics reasoning, embodied task planning, and creative writing tasks.
</p>
</div>
</section>
<section class="ltx_section" id="Sx1" lang="en">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank a grant from CCF-Tencent Rhino-Bird Open Research Fund. One author is funded in part by NSF grants #IIS-1943641, #IIS-1956441, #CCF-1837129, an SRA from Meta and a research gift from Amazon Alexa AI, and a gift from RelationalAI.</p>
</div>
</section>
<section class="ltx_section" id="Sx2" lang="en">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">In this seciton, we discuss three limitations of our <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> as follows.</p>
</div>
<div class="ltx_para" id="Sx2.p2">
<p class="ltx_p" id="Sx2.p2.1">One limitation of this work is that the performance of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> relies on the chain-of-thought reasoning and in-context learning (or RAG) capability of the base LLM. Since this work does not involve any model training, the capability of base LLM will not change when applying <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>. Despite <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> achieves significant improvement on powerful LLMs such as GPT-3.5 and GPT-4, the effect on smaller and weaker LLMs such as GPT-2 is questionable. On top of that, it is interesting to further explore how to improve <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> via fine-tuning weaker LLMs <cite class="ltx_cite ltx_citemacro_citep">(Ke et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib25" title="">2023</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib33" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="Sx2.p3">
<p class="ltx_p" id="Sx2.p3.1">Another limitation of this work is that the performance of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> also relies on the quality of the retrieved knowledge. When we have an inferior external knowledge base which is irrelevant to the user query, the retrieved knowledge may be unhelpful for LLMs to generate useful information. Also, even if we select a relatively large knowledge base that entails the relevant information, it will be expensive to maintain and retrieve from such a huge knowledge base and also hurts the retrieval precision. An interesting and crucial direction is to study how to build and evaluate the quality of a knowledge base used for efficient and effective retrieval.
</p>
</div>
<div class="ltx_para" id="Sx2.p4">
<p class="ltx_p" id="Sx2.p4.1">It is noteworthy that the above two limitations also apply to the traditional studies on retrieval-augmented generation (RAG). The last limitation of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> is that we follow CoT to solve the problems in a explicit step-by-step fashion. Sometimes step-by-step thinking may be redundant for straightforward questions, while some questions require more complex reasoning structures (e.g., tree-of-thoughts <cite class="ltx_cite ltx_citemacro_citep">(Yao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib59" title="">2023</a>)</cite>). It is also interesting to explore the better reasoning methods for LLMs in our future work.</p>
</div>
</section>
<section class="ltx_section" id="Sx3" lang="en">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>
<div class="ltx_para" id="Sx3.p1">
<p class="ltx_p" id="Sx3.p1.1">All datasets and models are publicly accessible except for OpenAI’s GPT series and the text embedding APIs. We have not identified any significant ethical considerations associated with this work. We believe our newly proposed <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> can improve the generation of LLMs in various fields and reduce LLMs’ hallucinations.</p>
</div>
<span class="ltx_ERROR undefined" id="Sx3.1">\nobibliography</span>
<div class="ltx_para" id="Sx3.p2">
<p class="ltx_p" id="Sx3.p2.1">*</p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. (2023)</span>
<span class="ltx_bibblock">
A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi.

</span>
<span class="ltx_bibblock">Self-rag: Learning to retrieve, generate, and critique through self-reflection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2310.11511</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Austin et al. (2021)</span>
<span class="ltx_bibblock">
J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, et al.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2108.07732</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baek et al. (2023)</span>
<span class="ltx_bibblock">
J. Baek, A. F. Aji, and A. Saffari.

</span>
<span class="ltx_bibblock">Knowledge-augmented language model prompting for zero-shot knowledge graph question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2306.04136</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baker et al. (2022)</span>
<span class="ltx_bibblock">
B. Baker, I. Akkaya, P. Zhokhov, J. Huizinga, J. Tang, A. Ecoffet, B. Houghton, R. Sampedro, and J. Clune.

</span>
<span class="ltx_bibblock">Video pretraining (vpt): Learning to act by watching unlabeled online videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2206.11795</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besta et al. (2023)</span>
<span class="ltx_bibblock">
M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, L. Gianinazzi, J. Gajda, T. Lehmann, M. Podstawski, H. Niewiadomski, P. Nyczyk, et al.

</span>
<span class="ltx_bibblock">Graph of thoughts: Solving elaborate problems with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2308.09687</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Advances in neural information processing systems</em>, 33:1877–1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2023a)</span>
<span class="ltx_bibblock">
S. Cai, Z. Wang, X. Ma, A. Liu, and Y. Liang.

</span>
<span class="ltx_bibblock">Open-world multi-task control through goal-aware representation learning and adaptive horizon prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 13734–13744, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2023b)</span>
<span class="ltx_bibblock">
S. Cai, B. Zhang, Z. Wang, X. Ma, A. Liu, and Y. Liang.

</span>
<span class="ltx_bibblock">Groot: Learning to follow instructions by watching gameplay videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2310.08235</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2107.03374</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al. (2021)</span>
<span class="ltx_bibblock">
K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2110.14168</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Creswell and Shanahan (2022)</span>
<span class="ltx_bibblock">
A. Creswell and M. Shanahan.

</span>
<span class="ltx_bibblock">Faithful reasoning using large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2208.14271</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Creswell et al. (2022)</span>
<span class="ltx_bibblock">
A. Creswell, M. Shanahan, and I. Higgins.

</span>
<span class="ltx_bibblock">Selection-inference: Exploiting large language models for interpretable logical reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2205.09712</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhuliawala et al. (2023)</span>
<span class="ltx_bibblock">
S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz, and J. Weston.

</span>
<span class="ltx_bibblock">Chain-of-verification reduces hallucination in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv: 2309.11495</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2023a)</span>
<span class="ltx_bibblock">
Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin.

</span>
<span class="ltx_bibblock">Retrieval-generation synergy augmented large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">ArXiv</em>, abs/2310.05149, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2023b)</span>
<span class="ltx_bibblock">
Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin.

</span>
<span class="ltx_bibblock">Retrieval-generation synergy augmented large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2310.05149</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2022)</span>
<span class="ltx_bibblock">
L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig.

</span>
<span class="ltx_bibblock">Pal: Program-aided language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2211.10435</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2312.10997</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2018)</span>
<span class="ltx_bibblock">
J. Gu, Y. Wang, K. Cho, and V. O. Li.

</span>
<span class="ltx_bibblock">Search engine guided neural machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2024)</span>
<span class="ltx_bibblock">
D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. K. Li, F. Luo, Y. Xiong, and W. Liang.

</span>
<span class="ltx_bibblock">Deepseek-coder: When the large language model meets programming – the rise of code intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2401.14196</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herbrich et al. (2006)</span>
<span class="ltx_bibblock">
R. Herbrich, T. Minka, and T. Graepel.

</span>
<span class="ltx_bibblock">Trueskill™: a bayesian skill rating system.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in neural information processing systems</em>, 19, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holyoak and Morrison (2012)</span>
<span class="ltx_bibblock">
K. J. Holyoak and R. G. Morrison.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">The Oxford handbook of thinking and reasoning</em>.

</span>
<span class="ltx_bibblock">Oxford University Press, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2022)</span>
<span class="ltx_bibblock">
W. Huang, P. Abbeel, D. Pathak, and I. Mordatch.

</span>
<span class="ltx_bibblock">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ICML</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et al. (2022a)</span>
<span class="ltx_bibblock">
Z. Ke, H. Lin, Y. Shao, H. Xu, L. Shu, and B. Liu.

</span>
<span class="ltx_bibblock">Continual training of language models for few-shot learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2210.05549</em>, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et al. (2022b)</span>
<span class="ltx_bibblock">
Z. Ke, Y. Shao, H. Lin, H. Xu, L. Shu, and B. Liu.

</span>
<span class="ltx_bibblock">Adapting a language model while preserving its general knowledge.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 10177–10188, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et al. (2023)</span>
<span class="ltx_bibblock">
Z. Ke, Y. Shao, H. Lin, T. Konishi, G. Kim, and B. Liu.

</span>
<span class="ltx_bibblock">Continual pre-training of language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">The Eleventh International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2022)</span>
<span class="ltx_bibblock">
T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in neural information processing systems</em>, 35:22199–22213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020a)</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Advances in Neural Information Processing Systems</em>, 33:9459–9474, 2020a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020b)</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Advances in Neural Information Processing Systems</em>, 33:9459–9474, 2020b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
C. Li, J. Liang, A. Zeng, X. Chen, K. Hausman, D. Sadigh, S. Levine, L. Fei-Fei, F. Xia, and B. Ichter.

</span>
<span class="ltx_bibblock">Chain of code: Reasoning with a language model-augmented code emulator, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
X. Li, R. Zhao, Y. K. Chia, B. Ding, S. Joty, S. Poria, and L. Bing.

</span>
<span class="ltx_bibblock">Chain-of-knowledge: Grounding large language models via dynamic knowledge adapting over heterogeneous sources.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">The Twelfth International Conference on Learning Representations</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lifshitz et al. (2023)</span>
<span class="ltx_bibblock">
S. Lifshitz, K. Paster, H. Chan, J. Ba, and S. McIlraith.

</span>
<span class="ltx_bibblock">Steve-1: A generative model for text-to-behavior in minecraft.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2306.00937</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2023)</span>
<span class="ltx_bibblock">
H. Lin, Z. Wang, J. Ma, and Y. Liang.

</span>
<span class="ltx_bibblock">Mcu: A task-centric framework for open-ended agent evaluation in minecraft.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2310.08367</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
H. Lin, B. Huang, H. Ye, Q. Chen, Z. Wang, S. Li, J. Ma, X. Wan, J. Zou, and Y. Liang.

</span>
<span class="ltx_bibblock">Selecting large language model to fine-tune via rectified scaling law.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2402.02314</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
C. Liu, X. Li, L. Shang, X. Jiang, Q. Liu, E. Y. Lam, and N. Wong.

</span>
<span class="ltx_bibblock">Gradually excavating external knowledge for implicit complex question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Conference on Empirical Methods in Natural Language Processing</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
J. Liu, C. S. Xia, Y. Wang, and L. Zhang.

</span>
<span class="ltx_bibblock">Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2022)</span>
<span class="ltx_bibblock">
S. Lu, N. Duan, H. Han, D. Guo, S.-w. Hwang, and A. Svyatkovskiy.

</span>
<span class="ltx_bibblock">Reacc: A retrieval-augmented code completion framework.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 6227–6240, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nashid et al. (2023)</span>
<span class="ltx_bibblock">
N. Nashid, M. Sintaha, and A. Mesbah.

</span>
<span class="ltx_bibblock">Retrieval-based prompt selection for code-related few-shot learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 45th International Conference on Software Engineering (ICSE’23)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nye et al. (2021)</span>
<span class="ltx_bibblock">
M. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan, A. Lewkowycz, M. Bosma, D. Luan, et al.

</span>
<span class="ltx_bibblock">Show your work: Scratchpads for intermediate computation with language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2112.00114</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2203.02155</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rawte et al. (2023)</span>
<span class="ltx_bibblock">
V. Rawte, A. Sheth, and A. Das.

</span>
<span class="ltx_bibblock">A survey of hallucination in large foundation models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2309.05922</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
N. Reimers and I. Gurevych.

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:1908.10084</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ribeiro et al. (2022)</span>
<span class="ltx_bibblock">
D. Ribeiro, S. Wang, X. Ma, R. Dong, X. Wei, H. Zhu, X. Chen, Z. Huang, P. Xu, A. Arnold, et al.

</span>
<span class="ltx_bibblock">Entailment tree explanations via iterative retrieval-generation reasoner.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2205.09224</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rozière et al. (2023)</span>
<span class="ltx_bibblock">
B. Rozière, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin, A. Kozhevnikov, I. Evtimov, J. Bitton, M. P. Bhatt, C. C. Ferrer, A. Grattafiori, W. Xiong, A. D’efossez, J. Copet, F. Azhar, H. Touvron, L. Martin, N. Usunier, T. Scialom, and G. Synnaeve.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">ArXiv</em>, abs/2308.12950, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn et al. (2023)</span>
<span class="ltx_bibblock">
N. Shinn, B. Labash, and A. Gopinath.

</span>
<span class="ltx_bibblock">Reflexion: an autonomous agent with dynamic memory and self-reflection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2303.11366</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siriwardhana et al. (2023)</span>
<span class="ltx_bibblock">
S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana, and S. Nanayakkara.

</span>
<span class="ltx_bibblock">Improving the domain adaptation of retrieval augmented generation (rag) models for open domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Transactions of the Association for Computational Linguistics</em>, 11:1–17, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2022)</span>
<span class="ltx_bibblock">
G. P. Team.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv: 2204.02311</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trivedi et al. (2022a)</span>
<span class="ltx_bibblock">
H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal.

</span>
<span class="ltx_bibblock">Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">ArXiv</em>, abs/2212.10509, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trivedi et al. (2022b)</span>
<span class="ltx_bibblock">
H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal.

</span>
<span class="ltx_bibblock">Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2212.10509</em>, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Zhou (2024)</span>
<span class="ltx_bibblock">
X. Wang and D. Zhou.

</span>
<span class="ltx_bibblock">Chain-of-thought reasoning without prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2402.10200</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery, and D. Zhou.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2203.11171</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang, A. Chowdhery, and D. Zhou.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">The Eleventh International Conference on Learning Representations, ICLR 2023</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Z. Wang, S. Cai, A. Liu, Y. Jin, J. Hou, B. Zhang, H. Lin, Z. He, Z. Zheng, Y. Yang, X. Ma, and Y. Liang.

</span>
<span class="ltx_bibblock">Jarvis-1: Open-world multi-task agents with memory-augmented multimodal language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">ArXiv</em>, abs/2311.05997, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023c)</span>
<span class="ltx_bibblock">
Z. Wang, S. Cai, A. Liu, X. Ma, and Y. Liang.

</span>
<span class="ltx_bibblock">Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2302.01560</em>, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou.

</span>
<span class="ltx_bibblock">Chain of thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">36th Conference on Neural Information Processing Systems (NeurIPS 2022)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2023)</span>
<span class="ltx_bibblock">
Z. Wen, Z. Tian, W. Wu, Y. Yang, Y. Shi, Z. Huang, and D. Li.

</span>
<span class="ltx_bibblock">Grove: a retrieval-augmented complex story generation framework with a forest of evidence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2310.05388</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2022)</span>
<span class="ltx_bibblock">
S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao.

</span>
<span class="ltx_bibblock">React: Synergizing reasoning and acting in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">arXiv preprint arXiv:2210.03629</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2023)</span>
<span class="ltx_bibblock">
S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan.

</span>
<span class="ltx_bibblock">Tree of thoughts: Deliberate problem solving with large language models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2023)</span>
<span class="ltx_bibblock">
H. Yuan, C. Zhang, H. Wang, F. Xie, P. Cai, H. Dong, and Z. Lu.

</span>
<span class="ltx_bibblock">Plan4mc: Skill reinforcement learning and planning for open-world minecraft tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2303.16563</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2024)</span>
<span class="ltx_bibblock">
H. Yuan, Z. Mu, F. Xie, and Z. Lu.

</span>
<span class="ltx_bibblock">Pre-training goal-based models for sample-efficient reinforcement learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelikman et al. (2022)</span>
<span class="ltx_bibblock">
E. Zelikman, Y. Wu, J. Mu, and N. Goodman.

</span>
<span class="ltx_bibblock">Star: Bootstrapping reasoning with reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Advances in Neural Information Processing Systems</em>, 35:15476–15488, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
C. Zhang, K. Yang, S. Hu, Z. Wang, G. Li, Y. Sun, C. Zhang, Z. Zhang, A. Liu, S.-C. Zhu, et al.

</span>
<span class="ltx_bibblock">Proagent: Building proactive cooperative ai with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2308.11339</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
R. Zhao, H. Chen, W. Wang, F. Jiao, X. L. Do, C. Qin, B. Ding, X. Guo, M. Li, X. Li, and S. R. Joty.

</span>
<span class="ltx_bibblock">Retrieving multimodal information for augmented generation: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">ArXiv</em>, abs/2303.10868, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2022a)</span>
<span class="ltx_bibblock">
D. Zhou, N. Schärli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet, Q. Le, et al.

</span>
<span class="ltx_bibblock">Least-to-most prompting enables complex reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">arXiv preprint arXiv:2205.10625</em>, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023)</span>
<span class="ltx_bibblock">
D. Zhou, N. Schärli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet, Q. V. Le, and E. H. Chi.

</span>
<span class="ltx_bibblock">Least-to-most prompting enables complex reasoning in large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">The Eleventh International Conference on Learning Representations, ICLR 2023</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2022b)</span>
<span class="ltx_bibblock">
S. Zhou, U. Alon, F. F. Xu, Z. Jiang, and G. Neubig.

</span>
<span class="ltx_bibblock">Docprompting: Generating code by retrieving the docs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">The Eleventh International Conference on Learning Representations</em>, 2022b.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Task Details</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Code Generation</h3>
<section class="ltx_paragraph" id="A1.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Benchmarks</h4>
<div class="ltx_para" id="A1.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS1.SSS0.Px1.p1.1">We select HumanEval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib9" title="">2021</a>)</cite>, HumanEval+ <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>, MBPP <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib2" title="">2021</a>)</cite>, and MBPP+ <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite> as the code generation evaluation benchmark.
These benchmarks are commonly used to test the performance of code generation models, which are briefly introduced below:</p>
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">HumanEval</span> consists of 164 Python programming problems, each with a function signature, docstring, body, and multiple unit tests <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib9" title="">2021</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">HumanEval+</span> includes the same programming problems as HumanEval, but with an additional 80 times more unit tests for each of the 164 problems <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i3.p1.1.1">MBPP</span> is a collection of approximately 1,000 Python programming problems that are intended to be solvable by beginner programmers. Each problem includes an English task description, a code solution, and three automated test cases. We assess the sample test set from index 11 to 175 <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib2" title="">2021</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i4.p1.1.1">MBPP+</span> consists of 399 tasks <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>, which are a subset of the original MBPP dataset. Additionally, MBPP+ includes extra unit tests for each of the 399 problems (35 times more than the original MBPP). We utilized the first 164 questions as our test set.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS1.SSS0.Px1.p1.2">These benchmarks encompass a wide range of programming problems, from simple function implementations to more complex algorithmic challenges, providing a robust testbed for assessing the generative capabilities of various models.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Metrics</h4>
<div class="ltx_para" id="A1.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS1.SSS0.Px2.p1.1">We adopt the <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px2.p1.1.1">pass@k</span> metric for evaluating the efficacy of various code generation algorithms, following the methodology proposed by <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib9" title="">2021</a>)</cite> and extended by <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib35" title="">2023b</a>)</cite>. This metric quantifies the rate at which generated code snippets successfully execute and pass all test cases, where <math alttext="k" class="ltx_Math" display="inline" id="A1.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="A1.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="A1.SS1.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="A1.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS0.Px2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS0.Px2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS0.Px2.p1.1.m1.1d">italic_k</annotation></semantics></math> represents the number of attempts or samples generated by the model for each problem.
This approach allows us to rigorously assess the precision and reliability of code generation models in producing functionally correct code across a diverse set of programming challenges.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Baselines</h4>
<div class="ltx_para" id="A1.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS1.SSS0.Px3.p1.1">To establish a comprehensive and equitable comparison landscape, we incorporate a suite of baseline methods and diverse code generation models. Our baselines include the original code generation language models, referred to as DIRECT, and the Retrieval-Augmented Generation (RAG) methodology with <math alttext="n" class="ltx_Math" display="inline" id="A1.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="A1.SS1.SSS0.Px3.p1.1.m1.1a"><mi id="A1.SS1.SSS0.Px3.p1.1.m1.1.1" xref="A1.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS0.Px3.p1.1.m1.1b"><ci id="A1.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS0.Px3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS0.Px3.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.SSS0.Px3.p1.1.m1.1d">italic_n</annotation></semantics></math> retrieved examples, instantiated in both single-shot (1 shot) and multi-shot (5 shots) configurations, as documented by <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib28" title="">2020b</a>)</cite>. Additionally, we examine the zero-shot <abbr class="ltx_glossaryref" title="chain-of-thought"><span class="ltx_text ltx_glossary_short">CoT</span></abbr> (CoT) approach, as conceptualized by <cite class="ltx_cite ltx_citemacro_citet">Kojima et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib26" title="">2022</a>)</cite>, which simulates a step-by-step reasoning process to facilitate complex problem-solving tasks under zero demonstration.
To ensure a fair comparison, none of the methods used examples from the benchmark as demonstrations for in-context learning.
</p>
</div>
<div class="ltx_para" id="A1.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="A1.SS1.SSS0.Px3.p2.1">The diversity of our evaluation is further enriched by testing across various language models with differing capacities, including CodeLlama-7b <cite class="ltx_cite ltx_citemacro_citep">(Rozière et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib44" title="">2023</a>)</cite>, along with ChatGPT(<span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px3.p2.1.1">gpt-3.5-turbo</span>) <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib40" title="">2022</a>)</cite>, and the more advanced GPT-4(<span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px3.p2.1.2">gpt-4</span>) model <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib39" title="">2023</a>)</cite>.
Recognizing the potential format discrepancies in code outputs, especially considering that models like <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px3.p2.1.3">gpt-3.5-turbo</span> and <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px3.p2.1.4">gpt-4</span> may produce code in markdown format which is not immediately executable, we implement post-processing steps to convert the original language model outputs into a form that can be executed within a sandbox environment. This normalization ensures that all models are evaluated under uniform execution conditions, thereby facilitating a fair and direct comparison of their code generation capabilities. Through this methodological framework, we aim to provide a detailed and nuanced understanding of the performance landscape across a spectrum of LLM-driven code generation approaches.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS1.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">RAG Settings</h4>
<div class="ltx_para" id="A1.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="A1.SS1.SSS0.Px4.p1.1"><abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> leverages the capabilities of Retrieval-Augmented Generation methods, which enhance the performance of language models by integrating external knowledge sources.
Specifically, we employed the <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px4.p1.1.1">codeparrot/github-jupyter</span> dataset as our primary search vector library. This dataset is a comprehensive compilation of 452k markdown and code pairs, meticulously extracted from Jupyter notebooks hosted on GitHub BigQuery, representing a rich repository of programming knowledge and examples.
We utilized OpenAI’s <span class="ltx_text ltx_font_typewriter" id="A1.SS1.SSS0.Px4.p1.1.2">text-embedding-ada-002</span> API service for all embedding calculations across different methods and base models.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Mathematical Reasoning</h3>
<section class="ltx_paragraph" id="A1.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Benchmarks</h4>
<div class="ltx_para" id="A1.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS2.SSS0.Px1.p1.1">Our evaluation framework for assessing mathematical reasoning capabilities leverages two primary benchmarks: the GSM8K dataset, which comprises over 8,000 multi-step mathematical problems <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib10" title="">2021</a>)</cite>, and the GSM-HARD dataset, an adaptation of GSM8K where numbers in the questions are replaced with larger values to increase problem complexity <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib16" title="">2022</a>)</cite>. This study employs the PAL methodology to scrutinize the mathematical reasoning results, involving the utilization of Large Language Models (LLMs) to parse natural language problems, generate intermediary programmatic solutions, and subsequently execute these solutions via a Python interpreter. The test set for each benchmark consists of samples ranging from index 1 to 200. Uniquely, our approach does not use any examples for in-context learning, differing from the original PAL methods.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Metrics and Baselines</h4>
<div class="ltx_para" id="A1.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS2.SSS0.Px2.p1.1">Accuracy serves as our principal metric for evaluation, aligning with the established metric for the GSM8K benchmark. Each question undergoes three execution attempts, with the average score recorded as the final result. The baselines, including DIRECT, CoT, RAG (1 shot), and RAG (5 shots), are consistent with those outlined in code generation, facilitating a comprehensive and comparative analysis across different code generation benchmarks. The RAG settings are consistent with the code generation tasks.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Embodied Planning</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">We further conduct experiments on embodied planning benchmarks on open-ended environments Minecraft <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib32" title="">2023</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Benchmarks</h4>
<div class="ltx_para" id="A1.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.1">The complexity and vast item interconnectivity within the open-world Minecraft present an ideal testbed for evaluating the LLM’s capability to generate long-horizon plans <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib60" title="">2023</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib55" title="">2023c</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib54" title="">b</a>)</cite>. With thousands of items and intricate relationships between them, obtaining a specific item in survival mode from scratch may involve dozens of intermediate items and their quantitative relationships, such as crafting 1 crafting table from 4 planks. This setting rigorously tests the planning abilities of LLMs instead of low-level control policies <cite class="ltx_cite ltx_citemacro_citep">(Cai et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib8" title="">2023b</a>; Baker et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib4" title="">2022</a>; Cai et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib7" title="">2023a</a>; Lifshitz et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib31" title="">2023</a>; Yuan et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib61" title="">2024</a>)</cite>. Moreover, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib54" title="">2023b</a>)</cite> have identified instances of hallucinations about Minecraft knowledge in OpenAI’s ChatGPT and a general scarcity of Minecraft-related knowledge in open-source language models, making this task a suitable benchmark for assessing the RAG algorithm’s effectiveness.</p>
</div>
<div class="ltx_para" id="A1.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p2.1">The planning prompts are aligned with those used in DEPS <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib55" title="">2023c</a>)</cite>, structured as Python templates and evaluated using MC-TextWorld as detailed by <cite class="ltx_cite ltx_citemacro_citet">Lin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib32" title="">2023</a>)</cite>.
A set of 100 tasks were randomly selected for the test set, ranging from simple objectives like obtaining a crafting table to more complex goals such as crafting an iron helmet and even challenging making an enchanting table.
The task instruction is formulated as:</p>
<ul class="ltx_itemize" id="A1.I2">
<li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i1.p1">
<p class="ltx_p" id="A1.I2.i1.p1.1">Give you nothing in the inventory, generate a step-by-step plan for the task of obtaining a {placeholder:acacia_boat} in Minecraft survival mode, and describe the object Minecraft item and its number at every step. For every step, start with ’STEP’ as start.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i2.p1">
<p class="ltx_p" id="A1.I2.i2.p1.1">Give you nothing in the inventory, generate a step-by-step plan for the task of obtaining a {placeholder:diamond_pickaxe} boat in Minecraft survival mode, and describe the object Minecraft item and its number at every step. For every step, start with ’STEP’ as start.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p2.2">There are over 100 tasks involving different Minecraft items.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">RAG Settings</h4>
<div class="ltx_para" id="A1.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p1.1">For the retrieval component of the RAG algorithm, we utilized the Minecraft Wiki<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://minecraft.wiki/" title="">https://minecraft.wiki/</a></span></span></span> and DigMinecraft<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.digminecraft.com/" title="">https://www.digminecraft.com/</a></span></span></span> websites as the information sources accessible to the LLMs. Data from these websites was cleaned and formatted into markdown text, then segmented into trunks not exceeding 2000 tokens each, with embedding calculations performed using OpenAI’s <span class="ltx_text ltx_font_typewriter" id="A1.SS3.SSS0.Px2.p1.1.1">text-embedding-ada-002</span> API service.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Evaluation Metrics</h4>
<div class="ltx_para" id="A1.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px3.p1.1">Based on the methodology of <cite class="ltx_cite ltx_citemacro_citet">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib22" title="">2022</a>)</cite>, our evaluation of open-ended, long-horizon planning in Minecraft focuses on both executability and plausibility.
Executability primarily examines whether a plan can be carried out, including the accuracy of each step’s preconditions and effects. The executability is automatically calculated using MC-TextWorld <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib32" title="">2023</a>)</cite>. However, executability only evaluates if an objective-level plan can be executed, without considering the specific details involved in executing individual objectives. For instance, crafting a wooden pickaxe requires placing a crafting table and arranging three planks and two sticks in a particular pattern, which are important details for human execution but not assessed by MC-TextWorld. Therefore, we complement our evaluation with human ratings to assess the plausibility of plans.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Creative Writing</h3>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1">To further understand the potential of Retrieval-Augmented Generation (RAG) models in enhancing the creativity and relevance of generated content, we extend our investigation to open-ended text generation tasks within the realm of creative writing.</p>
</div>
<section class="ltx_paragraph" id="A1.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Benchmarks</h4>
<div class="ltx_para" id="A1.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS4.SSS0.Px1.p1.1">The versatility of <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr> was tested through a series of creative writing tasks, each chosen to highlight different aspects of open-ended text generation. These tasks include:</p>
<ul class="ltx_itemize" id="A1.I3">
<li class="ltx_item" id="A1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i1.p1">
<p class="ltx_p" id="A1.I3.i1.p1.1">Write a survey paper to summarize the <span class="ltx_text ltx_font_typewriter" id="A1.I3.i1.p1.1.1">placeholder:Retrieval-augmented Generation methods for Large Language Models</span>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i2.p1">
<p class="ltx_p" id="A1.I3.i2.p1.1">Describe of <span class="ltx_text ltx_font_typewriter" id="A1.I3.i2.p1.1.1">placeholder:Jin-Yong</span>’s life.</p>
</div>
</li>
<li class="ltx_item" id="A1.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I3.i3.p1">
<p class="ltx_p" id="A1.I3.i3.p1.1">Summarize the <span class="ltx_text ltx_font_typewriter" id="A1.I3.i3.p1.1.1">placeholder:American Civil War</span> according to the timeline.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS4.SSS0.Px1.p1.2">For each task, three variants for <span class="ltx_text ltx_font_typewriter" id="A1.SS4.SSS0.Px1.p1.2.1">placeholder</span> were created to ensure a comprehensive evaluation of the model’s performance across different contexts and requirements.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">RAG Settings</h4>
<div class="ltx_para" id="A1.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS4.SSS0.Px2.p1.1">Differing from previous tasks, creative writing is categorized as an open-ended generation task, demanding a broader scope of information retrieval to aid content generation. To accommodate this, Google was utilized as the search engine, with the top-k web pages converted into markdown text to assist the LLM in generating outputs.
This approach allowed LLM to leverage a wide array of information sources.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Baselines and Evaluations</h4>
<div class="ltx_para" id="A1.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS4.SSS0.Px3.p1.1">To benchmark <abbr class="ltx_glossaryref" title="Retrieval Augmented Thoughts"><span class="ltx_text ltx_glossary_short">RAT</span></abbr>’s performance, we compared it against DIRECT, RAG-1 shot, and RAG-5 shot methods, all based on the <span class="ltx_text ltx_font_typewriter" id="A1.SS4.SSS0.Px3.p1.1.1">gpt-3.5-turbo</span> model. The evaluation was conducted by human experts, employing the TrueSkill rating system <cite class="ltx_cite ltx_citemacro_citep">(Herbrich et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib20" title="">2006</a>)</cite> to calculate scores for each method. This evaluation framework enabled a comprehensive assessment of each model’s creative output quality, accuracy, relevance, and innovativeness.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A2" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Prompt Details</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Our prompts consist of three parts: prompt for generating initial answer, prompt for generating search query, and prompt for revising answers according to retrieved context.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.p2">
<svg class="ltx_picture" height="178.13" id="A2.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,178.13) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 172.81 C 0 175.75 2.38 178.13 5.32 178.13 L 594.68 178.13 C 597.62 178.13 600 175.75 600 172.81 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 149.22 L 598.62 149.22 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 150.61 L 1.38 172.81 C 1.38 174.98 3.15 176.74 5.32 176.74 L 594.68 176.74 C 596.85 176.74 598.62 174.98 598.62 172.81 L 598.62 150.61 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="134" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">user</span>}</span></span>
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">##Question:</span></span>
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3"><span class="ltx_text ltx_font_bold" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3.1" style="font-size:80%;">{question}</span></span>
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4"><span class="ltx_text" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4.1" style="font-size:80%;">##Instruction:</span></span>
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5"><span class="ltx_text" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5.1" style="font-size:80%;">Try to answer this question/instruction with step-by-step thoughts and make the answer more structural.</span></span>
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.6"><span class="ltx_text" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.6.1" style="font-size:80%;">Use /n/n to split the answer into several paragraphs.</span></span>
<span class="ltx_p" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7"><span class="ltx_text" id="A2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7.1" style="font-size:80%;">Just respond to the instruction directly. DO NOT add additional explanations or introducement in the answer unless you are asked to.</span></span>
</span>
<span class="ltx_para" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">assistant</span>}</span></span>
<span class="ltx_p" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">…</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.1">The process of query generation is omitted in code generation tasks. Instead, we use the generated code draft as a query and compute the embedding of it based on OpenAI Embedding services. For embodied planning and creative writing tasks, we will generate an additional query.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.p4">
<svg class="ltx_picture" height="310.96" id="A2.p4.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,310.96) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 305.64 C 0 308.58 2.38 310.96 5.32 310.96 L 594.68 310.96 C 597.62 310.96 600 308.58 600 305.64 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 282.06 L 598.62 282.06 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 283.44 L 1.38 305.64 C 1.38 307.82 3.15 309.58 5.32 309.58 L 594.68 309.58 C 596.85 309.58 598.62 307.82 598.62 305.64 L 598.62 283.44 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="266.84" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1" style="width:421.6pt;">
<span class="ltx_para" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">##Question:</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_bold" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">{question}<span class="ltx_text ltx_font_medium" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1.1"></span></span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3.1" style="font-size:80%;">##Content:</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4"><span class="ltx_text ltx_font_bold" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4.1" style="font-size:80%;">{answer}<span class="ltx_text ltx_font_medium" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4.1.1"></span></span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5.1" style="font-size:80%;">##Instruction:</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.6"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.6.1" style="font-size:80%;">I want to verify the content correctness of the given question, especially the last sentences.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7.1" style="font-size:80%;">Please summarize the content with the corresponding question.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.8"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.8.1" style="font-size:80%;">This summarization will be used as a query to search with Bing search engine.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.9"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.9.1" style="font-size:80%;">The query should be short but need to be specific to promise Bing can find related knowledge or pages.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.10"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.10.1" style="font-size:80%;">You can also use search syntax to make the query short and clear enough for the search engine to find relevant language data.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.11"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.11.1" style="font-size:80%;">Try to make the query as relevant as possible to the last few sentences in the content.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.12"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.12.1" style="font-size:80%;">**IMPORTANT**</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.13"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.13.1" style="font-size:80%;">Just output the query directly. DO NOT add additional explanations or introducement in the answer unless you are asked to.</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.14"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.14.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.14.1.1">assistant</span>}</span></span>
<span class="ltx_p" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.15"><span class="ltx_text" id="A2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.15.1" style="font-size:80%;">…</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A2.p5">
<svg class="ltx_picture" height="337.83" id="A2.p5.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,337.83) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 332.51 C 0 335.45 2.38 337.83 5.32 337.83 L 594.68 337.83 C 597.62 337.83 600 335.45 600 332.51 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 298.66 L 598.62 298.66 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 300.05 L 1.38 332.51 C 1.38 334.68 3.15 336.45 5.32 336.45 L 594.68 336.45 C 596.85 336.45 598.62 334.68 598.62 332.51 L 598.62 300.05 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="283.44" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">user</span>}</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">##Existing Text in Wiki Web:</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3"><span class="ltx_text ltx_font_bold" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3.1" style="font-size:80%;">{content}<span class="ltx_text ltx_font_medium" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.3.1.1"></span></span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.4.1" style="font-size:80%;">##Question:</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5"><span class="ltx_text ltx_font_bold" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5.1" style="font-size:80%;">{question}<span class="ltx_text ltx_font_medium" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.5.1.1"></span></span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.6"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.6.1" style="font-size:80%;">##Answer:</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7"><span class="ltx_text ltx_font_bold" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7.1" style="font-size:80%;">{answer}<span class="ltx_text ltx_font_medium" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.7.1.1"></span></span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.8"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.8.1" style="font-size:80%;">##Instruction:</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.9"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.9.1" style="font-size:80%;">I want to revise the answer according to retrieved related text of the question in WIKI pages.</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.10"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.10.1" style="font-size:80%;">You need to check whether the answer is correct.</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.11"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.11.1" style="font-size:80%;">If you find some errors in the answer, revise the answer to make it better.</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.12"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.12.1" style="font-size:80%;">If you find some necessary details are ignored, add it to make the answer more plausible according to the related text.</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.13"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.13.1" style="font-size:80%;">If you find the answer is right and do not need to add more details, just output the original answer directly.</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.14"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.14.1" style="font-size:80%;">**IMPORTANT**</span></span>
<span class="ltx_p" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.15"><span class="ltx_text" id="A2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.15.1" style="font-size:80%;">Try to keep the structure (multiple paragraphs with its subtitles) in the revised answer and make it more structural for understanding.
Split the paragraphs with /n/n characters.
Just output the revised answer directly. DO NOT add additional explanations or annoucement in the revised answer unless you are asked to.</span></span>
</span>
<span class="ltx_para" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">assistant</span>}</span></span>
<span class="ltx_p" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">…</span></span>
</span></span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_appendix" id="A3" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>TrueSkill Evaluation Framework</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Part of the tasks in “Embodied planning” and “creative writing” involve using humans for labeling. Human labelers have 4 choices: “A is better”, “B is better”, “Tie” or “Both are bad”. In this case, “Tie” and “Both are bad” will be counted as a tie.
For each task group, we have selected more than 10 professional annotators to provide labels.
We use the Python “trueskill” package to calculate the win rate and score. The default score for every method is set as 25.
In order to facilitate user understanding and selection, we also provide prompts when entering the system.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.p2">
<svg class="ltx_picture" height="275.51" id="A3.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,275.51) matrix(1 0 0 -1 0 0)"><g fill="#0000BF" fill-opacity="1.000000"><path d="M 0 5.32 L 0 270.19 C 0 273.13 2.38 275.51 5.32 275.51 L 594.68 275.51 C 597.62 275.51 600 273.13 600 270.19 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#FFF2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 270.19 C 1.38 272.36 3.15 274.13 5.32 274.13 L 594.68 274.13 C 596.85 274.13 598.62 272.36 598.62 270.19 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="258.91" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A3.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" style="width:421.6pt;">
<span class="ltx_para" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;"># Chatbot Arena : Benchmarking LLMs in the Wild</span></span>
<span class="ltx_p" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">##Rules</span></span>
<span class="ltx_p" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3"><span class="ltx_text" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.1" style="font-size:80%;">- Refresh to obtain the question and its corresponding answers from two anonymous models.</span></span>
<span class="ltx_p" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4"><span class="ltx_text" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.1" style="font-size:80%;">- Vote for the better answer. And then click "New Round" to get a new question.</span></span>
<span class="ltx_p" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5"><span class="ltx_text" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.1" style="font-size:80%;">- If both answers are bad, vote for "Both are bad".</span></span>
<span class="ltx_p" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6"><span class="ltx_text" id="A3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.1" style="font-size:80%;">- If you want to skip, click "Skip".</span></span>
</span>
<span class="ltx_para" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">## Principle</span></span>
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">You can evaluate the performance of the model from the following aspects:</span></span>
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">1. **Relevance**: Does it answer the question accurately?</span></span>
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">2. **Accuracy**: Is it accurate? For example, a crafting table is made by combining 4 wooden planks, not 4 logs; a diamond axe requires 3 diamonds and 2 sticks to craft, not 3 sticks and 2 diamonds.</span></span>
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.5"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.5.1" style="font-size:80%;">3. **Completeness**: Is it complete? For example, crafting a wooden pickaxe from logs requires first crafting wooden planks and then crafting sticks before finally being able to craft the pickaxe. The intermediate steps cannot be ignored.</span></span>
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.6"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.6.1" style="font-size:80%;">4. **Readability**: Is it coherent?</span></span>
<span class="ltx_p" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.7"><span class="ltx_text" id="A3.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.7.1" style="font-size:80%;">5. **Executability**: Considering the characteristics of the game, is it executable?</span></span>
</span>
<span class="ltx_para" id="A3.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.p3">
<span class="ltx_p" id="A3.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.p3.1"><span class="ltx_text" id="A3.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.p3.1.1" style="font-size:80%;">## Vote now!</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<figure class="ltx_table" id="A3.1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_centering ltx_flex_size_2 ltx_img_landscape" height="662" id="A3.1.g1" src="x4.png" width="822"/></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="A3.F1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure C.1: </span>
The human evaluation UI.
We will display responses from two different methods for the same instruction on the page simultaneously. The source of the response will be marked as [MASK], and after human labeling, [MASK] will be replaced with the specific method name.
</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section class="ltx_appendix" id="A4" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Disscussions on Benchmark Contamination</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">To avoid the code library containing solutions to the exact problems being evaluated) in code generation benchmarks, we adopted a rigorous pre-processing methodology as described by <cite class="ltx_cite ltx_citemacro_citet">Guo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.05313v1#bib.bib19" title="">2024</a>)</cite>.
This process was meticulously designed to remove any direct matches or overly similar code snippets from our search vector library, thereby ensuring that our evaluation remains fair and uncontaminated by pre-existing solutions.
This examination aims to underscore the importance of maintaining the integrity of the evaluation process while utilizing external knowledge sources to augment the capabilities of language models in code-generation tasks.</p>
</div>
<figure class="ltx_table" id="A4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Benchmark contamination study based on CodeLlama-7b-Python models. We find using the code corpus finetuning the CodeLlama models directly will damage model performance on the code generation benchmark, while using RAT for in-context generation yields better performance.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A4.T5.1" style="width:216.8pt;height:105.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(15.9pt,-7.7pt) scale(1.17176761843657,1.17176761843657) ;">
<table class="ltx_tabular ltx_align_middle" id="A4.T5.1.1">
<tr class="ltx_tr" id="A4.T5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A4.T5.1.1.1.1" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="A4.T5.1.1.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A4.T5.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">HumanEval</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A4.T5.1.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">HumanEval+</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">pass@5</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A4.T5.1.1.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DIRECT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.85%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">53.65%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">37.43%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.T5.1.1.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.78%</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.1.4">
<td class="ltx_td ltx_align_left" id="A4.T5.1.1.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">FINETUNE</td>
<td class="ltx_td ltx_align_center" id="A4.T5.1.1.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.02%</td>
<td class="ltx_td ltx_align_center" id="A4.T5.1.1.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">40.24%</td>
<td class="ltx_td ltx_align_center" id="A4.T5.1.1.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">26.34%</td>
<td class="ltx_td ltx_align_center" id="A4.T5.1.1.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.98%</td>
</tr>
<tr class="ltx_tr" id="A4.T5.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A4.T5.1.1.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">RAT</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T5.1.1.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">45.73%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T5.1.1.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.75%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T5.1.1.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">43.29%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T5.1.1.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">53.66%</td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">To further explore the potential benchmark contamination, we also conducted additional finetuning on CodeLLaMA-7B-Python using the code corpus in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.05313v1#A4.T5" title="Table 5 ‣ Appendix D Disscussions on Benchmark Contamination ‣ RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"><span class="ltx_text ltx_ref_tag">Table 5</span></a>.</p>
</div>
</section>
<section class="ltx_appendix" id="A5" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>More Results</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Emboddied Planning</h3>
<div class="ltx_para" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">Embodied planning involves multiple steps, each of which relies on specific world knowledge and causal knowledge (i.e., preceding steps are usually preconditions for subsequent steps), including recipes for items in Minecraft, tools for performing related actions, and quantity restrictions. Therefore, although the plan generated by ChatGPT may appear complete and correct, there are often errors within the steps that can affect the proper execution of the plan.</p>
</div>
<div class="ltx_para" id="A5.SS1.p2">
<p class="ltx_p" id="A5.SS1.p2.1">We mark the errors found in the generated plan in <span class="ltx_text" id="A5.SS1.p2.1.1" style="color:#FF0000;">red</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p3">
<svg class="ltx_picture" height="446.13" id="A5.SS1.p3.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,446.13) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 440.81 C 0 443.75 2.38 446.13 5.32 446.13 L 594.68 446.13 C 597.62 446.13 600 443.75 600 440.81 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 406.96 L 598.62 406.96 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 408.35 L 1.38 440.81 C 1.38 442.98 3.15 444.74 5.32 444.74 L 594.68 444.74 C 596.85 444.74 598.62 442.98 598.62 440.81 L 598.62 408.35 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="391.74" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Give you nothing in the inventory, generate a step-by-step plan for the task of obtaining a golden apple in Minecraft survival mode, and describe the object Minecraft item and its number at every step. For every step, start with ’STEP’ as start.</span></span>
</span>
<span class="ltx_para" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">response</span> from Original ChatGPT}</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">STEP 1: Start by punching trees to gather at least 4 logs.
- Minecraft item: 4x Logs</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">STEP 2: Craft the logs into a crafting table.
- Minecraft item: 1x Crafting Table</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">STEP 3: Place the crafting table on the ground and right-click on it to open the crafting interface.</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5.1" style="font-size:80%;">STEP 4: Use the crafting interface to turn 4 of the oak planks into a wooden pickaxe.</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6.1" style="font-size:80%;">- Minecraft item: Wooden Pickaxe</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.7"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.7.1" style="font-size:80%;">STEP 5: Find a cave or dig into the ground to gather some stone. Mine at least 8 blocks of stone using your wooden pickaxe.
- Minecraft item: 8x Cobblestone</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.8"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.8.1" style="font-size:80%;">STEP 6: Craft the cobblestone into a furnace using the crafting table.
- Minecraft item: 1x Furnace</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.9"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.9.1" style="font-size:80%;">STEP 7: Place the furnace on the ground and right-click on it to open the furnace interface.</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.10"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.10.1" style="font-size:80%;">STEP 8: Use the furnace interface to smelt some iron ore. Place at least 3 iron ore in the top slot of the furnace and use wooden planks as fuel in the bottom slot.
- Minecraft item: 3x Iron Ingots</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.11"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.11.1" style="font-size:80%;">STEP 9: Craft the iron ingots into a bucket using the crafting table.
- Minecraft item: 1x Bucket</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.12"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.12.1" style="font-size:80%;">STEP 10: Find a water source (such as a lake or a river) and right-click on it while holding the bucket to fill it with water.
- Minecraft item: 1x Water Bucket</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.13"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.13.1" style="font-size:80%;">STEP 11: Look for an apple tree in a forest biome. Break some leaves until you find an apple.
- Minecraft item: 1x Apple</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.14"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.14.1" style="font-size:80%;">STEP 12: Combine the water bucket and the apple in the crafting table to craft a golden apple.
- Minecraft item: 1x Golden Apple</span></span>
<span class="ltx_p" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.15"><span class="ltx_text" id="A5.SS1.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.15.1" style="font-size:80%;">Congratulations! You have successfully obtained a golden apple in Minecraft survival mode.</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A5.SS1.p4">
<p class="ltx_p" id="A5.SS1.p4.1">Although the Zero-shot CoT has generated a step-by-step plan overall, there are many factual errors within it. These include recipe errors in STEP 2, where the crafting table requires planks instead of wood; missing raw materials in STEP 4, as the wooden pickaxe needs 2 sticks but lacks the relevant step in the plan; absence of instructions to use a stone pickaxe to mine iron ore in STEP 8; and an incorrect recipe for golden apple in STEP 12, which should include gold ingots and an apple rather than a water bucket.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p5">
<svg class="ltx_picture" height="620.05" id="A5.SS1.p5.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,620.05) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 614.73 C 0 617.67 2.38 620.05 5.32 620.05 L 594.68 620.05 C 597.62 620.05 600 617.67 600 614.73 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 589.61 L 598.62 589.61 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 590.99 L 1.38 614.73 C 1.38 616.91 3.15 618.67 5.32 618.67 L 594.68 618.67 C 596.85 618.67 598.62 616.91 598.62 614.73 L 598.62 590.99 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="574.39" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Give you nothing in the inventory, generate a step-by-step plan for the task of obtaining a golden apple in Minecraft survival mode, and describe the object Minecraft item and its number at every step. For every step, start with ’STEP’ as start.</span></span>
</span>
<span class="ltx_para" id="A5.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">response</span> from Original ChatGPT}</span></span>
</span>
<span class="ltx_para" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3">
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.1"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.1.1" style="font-size:80%;">STEP 1: Find a tree and chop it down to get wood. You need at least 4 Oak Logs.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.2"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.2.1" style="font-size:80%;">- Minecraft items: 4x Oak Logs</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.3"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.3.1" style="font-size:80%;">STEP 2: Craft the oak log into oak planks.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.4"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.4.1" style="font-size:80%;">- Minecraft items: 16x Oak Planks</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.5"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.5.1" style="font-size:80%;">STEP 3: Convert some oak planks into sticks.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.6"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.6.1" style="font-size:80%;">- Minecraft items: 4x Stick</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.7"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.7.1" style="font-size:80%;">STEP 4: Use the crafting table to create a wooden pickaxe.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.8"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.8.1" style="font-size:80%;">- Minecraft items: 1x Wooden Pickaxe</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.9"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.9.1" style="font-size:80%;">STEP 5: Start digging down to find stone and gather at least three pieces of cobblestone.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.10"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.10.1" style="font-size:80%;">- Minecraft items: 3x Cobblestone</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.11"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.11.1" style="font-size:80%;">STEP 6: Use the crafting table to create a stone pickaxe.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.12"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.12.1" style="font-size:80%;">- Minecraft items: 1x Stone Pickaxe</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.13"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.13.1" style="font-size:80%;">STEP 7: Explore caves and mineshafts to find iron ore. Collect 3 iron ore for crafting an iron pickaxe.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.14"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.14.1" style="font-size:80%;">- Minecraft items: 3x Iron Ore</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.15"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.15.1" style="font-size:80%;">STEP 8: Smelt the iron ore using a furnace to obtain iron ingot.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.16"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.16.1" style="font-size:80%;">- Minecraft items: 3x Iron Ingot</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.17"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.17.1" style="font-size:80%;">STEP 9: Use the crafting table to create an iron pickaxe.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.18"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.18.1" style="font-size:80%;">- Minecraft items: 1x iron pickaxe</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.19"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.19.1" style="font-size:80%;">STEP 10: Explore caves and mineshafts to find gold ore. Use an iron pickaxe or higher to mine the gold ore block. Collect as much gold ore as needed for crafting a golden apple.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.20"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.20.1" style="font-size:80%;">- Minecraft items: 8x Gold Ore</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.21"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.21.1" style="font-size:80%;">STEP 11: Smelt the raw gold using a furnace to obtain a gold ingot.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.22"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.22.1" style="font-size:80%;">- Minecraft items: 8x Gold Ingot</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.23"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.23.1" style="font-size:80%;">STEP 12: Find an oak tree and chop it down until an apple falls.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.24"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.24.1" style="font-size:80%;">- Minecraft items: 1x Apple</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.25"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.25.1" style="font-size:80%;">STEP 13: Open the crafting menu and place the items in the correct pattern to craft a Golden Apple. In the 3x3 crafting grid, place 8 Gold Ingots in the first and third rows, leaving the middle square empty. In the second row, place 1 Gold Ingot in the first and third squares, and place an Apple in the middle square.</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.26"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.26.1" style="font-size:80%;">- Minecraft items: 1x Golden Apple</span></span>
<span class="ltx_p" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.27"><span class="ltx_text" id="A5.SS1.p5.pic1.4.4.4.4.4.4.4.4.4.4.4.4.3.3.3.3.3.3.3.p3.27.1" style="font-size:80%;">Congratulations! You have successfully obtained a golden apple in Minecraft survival mode.
</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A5.SS1.p6">
<p class="ltx_p" id="A5.SS1.p6.1">There are still errors in the plan generated by RAT, such as the lack of tools before "STEP 8: smelt iron ore into iron ingots", which should be “Mine 8 cobblestone to craft 1 furnace”. However, compared to the errors in ChatGPT, the error rate in the plan has been significantly reduced.</p>
</div>
<div class="ltx_para" id="A5.SS1.p7">
<p class="ltx_p" id="A5.SS1.p7.1">We have also listed the links of the retrieved pages involved in different steps.
We can see that the text sources retrieved in each step generated by RAT are usually highly related to the synthesized item of that step. Traditional RAG uses instructions for retrieval and can only find the final step.
While RAT can retrieve all links related to intermediate items, which improves the accuracy and plausibility greatly.</p>
</div>
<figure class="ltx_table" id="A5.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Page link of retrieved text in embodied Minecraft planning tasks.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A5.T6.1" style="width:411.9pt;height:188.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-69.0pt,31.6pt) scale(0.749146217274252,0.749146217274252) ;">
<table class="ltx_tabular ltx_align_middle" id="A5.T6.1.1">
<tr class="ltx_tr" id="A5.T6.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A5.T6.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Step</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A5.T6.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">Item</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A5.T6.1.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Recipe</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A5.T6.1.1.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">Link</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T6.1.1.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T6.1.1.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">4x Oak Log</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T6.1.1.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T6.1.1.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://minecraft.fandom.com/wiki/Log</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.3">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">2</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">16x Oak Planks</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">4x Oak Log</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/basic_recipes/make_oak_wood_plank.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.4">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">3</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">4x Stick</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">2x Oak Planks</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/basic_recipes/make_stick.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.5">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">4</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">1x Wooden Pickaxe</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Oak Planks, 2 Stick</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/tool_recipes/make_wooden_pickaxe.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.6">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">5</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Cobblestone</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Wooden Pickaxe</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://minecraft.fandom.com/wiki/Cobblestone</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.7">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">6</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">1x Stone Pickaxe</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Cobblestone, 2 Stick</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/tool_recipes/make_stone_pickaxe.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.8">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Iron Ore</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Stone Pickaxe</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://minecraft.fandom.com/wiki/Iron_Ore</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.9">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">8</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Iron Ingot</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Iron Ore</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/basic_recipes/make_iron_ingot.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.10">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">9</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">1 Iron Pickaxe</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">3x Iron Ingot, 2x Stick</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/tool_recipes/make_iron_pickaxe.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.11">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">10</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">8x Gold Ore</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Iron Pickaxe</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://minecraft.fandom.com/wiki/Gold_Ore</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.12">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">11</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">8x Gold Ingot</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">8x Gold Ore</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/basic_recipes/make_gold_ingot.php</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.13">
<td class="ltx_td ltx_align_center" id="A5.T6.1.1.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">12</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.13.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">1x Apple</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.13.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">-</td>
<td class="ltx_td ltx_align_left" id="A5.T6.1.1.13.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://minecraft.fandom.com/wiki/Apple</td>
</tr>
<tr class="ltx_tr" id="A5.T6.1.1.14">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T6.1.1.14.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">13</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A5.T6.1.1.14.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">1x Golden Apple</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A5.T6.1.1.14.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">8x Gold Ingot, 1x Apple</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A5.T6.1.1.14.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">https://www.digminecraft.com/food_recipes/make_golden_apple.php</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Creative Writing</h3>
<div class="ltx_para ltx_noindent" id="A5.SS2.p1">
<svg class="ltx_picture" height="286.43" id="A5.SS2.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,286.43) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 281.11 C 0 284.04 2.38 286.43 5.32 286.43 L 594.68 286.43 C 597.62 286.43 600 284.04 600 281.11 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 257.52 L 598.62 257.52 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 258.91 L 1.38 281.11 C 1.38 283.28 3.15 285.04 5.32 285.04 L 594.68 285.04 C 596.85 285.04 598.62 283.28 598.62 281.11 L 598.62 258.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="242.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Describe the history of the United States.
{<span class="ltx_text ltx_font_bold" id="A5.SS2.p1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1.1">response</span> from Original ChatGPT}</span></span>
</span>
<span class="ltx_para" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">The history of the United States dates back thousands of years, with indigenous peoples such as the Native Americans inhabiting the land long before the arrival of European settlers. However, the official history of the United States begins in 1776 when the Founding Fathers declared independence from Great Britain. This marked the start of the American Revolution, a conflict that ultimately led to the creation of the United States as an independent nation.</span></span>
<span class="ltx_p" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">After gaining independence, the United States went through a period of rapid expansion in the 19th century. The country acquired vast amounts of territory, including the Louisiana Purchase and the annexation of Texas. This expansion was accompanied by conflicts, such as the Mexican-American War and the Civil War, which tested the unity of the nation.</span></span>
<span class="ltx_p" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">In the 20th century, the United States emerged as a global superpower. The country played a significant role in both World War I and World War II, eventually becoming the leader of the free world during the Cold War with the Soviet Union. The United States experienced social and cultural shifts during this time, including the Civil Rights Movement and the rise of consumerism.</span></span>
<span class="ltx_p" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A5.SS2.p1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">Today, the United States remains a powerful nation, with a diverse population and a complex history that continues to shape its identity.</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p2">
<svg class="ltx_picture" height="435.87" id="A5.SS2.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,435.87) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 430.54 C 0 433.48 2.38 435.87 5.32 435.87 L 594.68 435.87 C 597.62 435.87 600 433.48 600 430.54 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 406.96 L 598.62 406.96 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 408.35 L 1.38 430.54 C 1.38 432.72 3.15 434.48 5.32 434.48 L 594.68 434.48 C 596.85 434.48 598.62 432.72 598.62 430.54 L 598.62 408.35 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="391.74" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Describe the history of the United States.</span></span>
</span>
<span class="ltx_para" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">response</span> from Zero-shot CoT}</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">**Pre-Columbian Era**</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">The history of the United States begins long before the arrival of European explorers in the 15th century. The land was initially inhabited by diverse Native American tribes, such as the Apache, Sioux, Iroquois, and Cherokee. These societies had rich cultures, with their own languages, traditions, and social structures. They lived off the land, flourishing through hunting, fishing, farming, and trade. However, the indigenous populations faced significant challenges, including conflicts, displacement, and diseases brought by the European settlers.</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">**Colonial Period**</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5.1" style="font-size:80%;">In the 16th century, European powers began to claim territories in what is now the United States. The Spanish were the first to establish colonies, initially focusing on Central and South America. Later, English, French, and Dutch explorers arrived, establishing their own colonies along the Atlantic coast. These colonies varied in purpose and organization, with the English colonies primarily seeking economic opportunities and religious freedom. Over time, thirteen British colonies emerged, forging their own identities, developing local governments, and experiencing an increase in population due to immigration.</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6.1" style="font-size:80%;">**American Revolution and Beyond**</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.7"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.7.1" style="font-size:80%;">Tensions between the British colonies and their colonial masters grew, leading to the American Revolution in 1775. The colonies, unified under the Continental Congress, fought for independence from British rule. The war lasted several years, until the signing of the Treaty of Paris in 1783, which granted the newly formed United States of America independence. After achieving independence, the founding fathers convened to draft the Constitution, establishing the framework for the new nation’s government.</span></span>
<span class="ltx_p" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.8"><span class="ltx_text" id="A5.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.8.1" style="font-size:80%;">This is just a brief overview, and the history of the United States is vast and complex. However, these steps provide a simplified understanding of how the nation evolved from Native American civilizations to a group of British colonies, to an independent country.</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p3">
<svg class="ltx_picture" height="354.38" id="A5.SS2.p3.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,354.38) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 349.06 C 0 352 2.38 354.38 5.32 354.38 L 594.68 354.38 C 597.62 354.38 600 352 600 349.06 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 323.94 L 598.62 323.94 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 325.32 L 1.38 349.06 C 1.38 351.23 3.15 353 5.32 353 L 594.68 353 C 596.85 353 598.62 351.23 598.62 349.06 L 598.62 325.32 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="308.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS2.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Describe the history of the United States.</span></span>
</span>
<span class="ltx_para" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">response</span> from RAG-1}</span></span>
<span class="ltx_p" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">The history of the United States is a complex and rich tapestry that spans over four centuries. The story begins with the arrival of European explorers and settlers in the 16th century. In 1492, Christopher Columbus reached the Americas, which led to subsequent expeditions and colonization by the Spanish, French, Dutch, and English. The first successful English settlement was established at Jamestown, Virginia in 1607.</span></span>
<span class="ltx_p" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">Over the next few centuries, the colonies grew and developed their own unique cultures, economies, and systems of government. Tensions rose between the American colonies and the British Crown, leading to the American Revolutionary War in 1775. The colonies declared their independence in 1776 and formed the United States of America, which became a republic based on democratic ideals and principles.</span></span>
<span class="ltx_p" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">The young nation faced numerous challenges in its early years, including establishing a central government, expanding westward, and dealing with the issue of slavery. The 19th century saw rapid westward expansion, the Industrial Revolution, and the Civil War. The United States emerged from the Civil War as a more unified and powerful nation, with the abolition of slavery and the preservation of the Union. In the 20th century, the United States became a global superpower, playing a crucial role in both World Wars and the Cold War. It witnessed significant social movements for civil rights and equality, as well as advancements in technology and innovation.</span></span>
<span class="ltx_p" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5"><span class="ltx_text" id="A5.SS2.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5.1" style="font-size:80%;">Today, the United States is a diverse and influential country with a strong economy, global military presence, and a complex political landscape. Its history continues to shape its present and future, as the nation grapples with ongoing social, economic, and political challenges.</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p4">
<svg class="ltx_picture" height="370.99" id="A5.SS2.p4.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,370.99) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 365.66 C 0 368.6 2.38 370.99 5.32 370.99 L 594.68 370.99 C 597.62 370.99 600 368.6 600 365.66 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 340.54 L 598.62 340.54 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 341.93 L 1.38 365.66 C 1.38 367.84 3.15 369.6 5.32 369.6 L 594.68 369.6 C 596.85 369.6 598.62 367.84 598.62 365.66 L 598.62 341.93 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="325.32" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Describe the history of the United States.</span></span>
</span>
<span class="ltx_para" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">response</span> from RAG-5}</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">The history of the United States dates back to the colonization of the Americas by European explorers in the 16th century. The first permanent English settlement was established in Jamestown, Virginia in 1607. This marked the beginning of British colonization in North America.</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">Over the next century, more British colonies were established along the eastern seaboard, including Massachusetts, New York, Pennsylvania, and Georgia. These colonies grew and developed their own distinct cultures and economies.</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">Tensions between the colonies and the British government grew in the mid-18th century, leading to the American Revolutionary War in 1775. The colonists, led by figures such as George Washington, Thomas Jefferson, and Benjamin Franklin, fought for their independence from British rule.</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5.1" style="font-size:80%;">In 1776, the Second Continental Congress adopted the Declaration of Independence, which declared the thirteen American colonies to be independent states. This marked the birth of the United States of America.</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6.1" style="font-size:80%;">Following the Revolutionary War, the Founding Fathers drafted the Constitution of the United States, which established a federal government and outlined the rights and freedoms of American citizens. The Constitution was ratified in 1788 and is still the supreme law of the land.</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.7"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.7.1" style="font-size:80%;">Since its founding, the United States has experienced significant growth and development. It expanded westward through the Louisiana Purchase and the annexation of Texas, and it eventually stretched from coast to coast. The country also faced significant challenges, such as the Civil War, the Great Depression, and the Civil Rights Movement.</span></span>
<span class="ltx_p" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.8"><span class="ltx_text" id="A5.SS2.p4.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.8.1" style="font-size:80%;">Today, the United States is a global superpower with a diverse population and a strong economy. It is known for its democratic system of government, individual freedoms, and cultural influence.</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p5">
<svg class="ltx_picture" height="469.07" id="A5.SS2.p5.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,469.07) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.32 L 0 463.75 C 0 466.69 2.38 469.07 5.32 469.07 L 594.68 469.07 C 597.62 469.07 600 466.69 600 463.75 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 440.17 L 598.62 440.17 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.000000"><path d="M 1.38 441.55 L 1.38 463.75 C 1.38 465.93 3.15 467.69 5.32 467.69 L 594.68 467.69 C 596.85 467.69 598.62 465.93 598.62 463.75 L 598.62 441.55 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignobject height="424.95" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="583.4"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2" style="width:421.6pt;">
<span class="ltx_para" id="A5.SS2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.SS2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1"><span class="ltx_text" id="A5.SS2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.1.1.1">instruction</span>}</span></span>
<span class="ltx_p" id="A5.SS2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2"><span class="ltx_text" id="A5.SS2.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.p1.2.1" style="font-size:80%;">Describe the history of the United States.
</span></span>
</span>
<span class="ltx_para" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1"><span class="ltx_text" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1" style="font-size:80%;">{<span class="ltx_text ltx_font_bold" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.1.1.1">response</span> from RAT}</span></span>
<span class="ltx_p" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2"><span class="ltx_text" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.2.1" style="font-size:80%;">The history of the United States is characterized by several significant phases. The pre-colonial period witnessed diverse Native American populations with unique cultures inhabiting the land. This era transitioned into colonialism through European exploration and settlement by powers such as the Spanish, French, Dutch, and British, leading to the establishment of colonies along the East Coast with distinct economic and political frameworks.</span></span>
<span class="ltx_p" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3"><span class="ltx_text" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.3.1" style="font-size:80%;">A pivotal moment in American history was the American Revolution, beginning in 1775, as the colonies sought independence from British rule. The Declaration of Independence in 1776 marked the nation’s founding on principles of liberty and democracy, establishing autonomy from Great Britain. This revolutionary period not only birthed a republic based on the will of the people but also forged American national identity, fostering a collective ethos entrenched in history and culture, inspiring revolutions worldwide and aiding in the establishment of republican governments elsewhere.</span></span>
<span class="ltx_p" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4"><span class="ltx_text" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.4.1" style="font-size:80%;">The United States stands out as the first modern nation to achieve independence through a national war of liberation, articulating its motives and aspirations in a declaration of independence. This event had global reverberations, spreading fundamental values like liberty, equality, natural and civil rights, and civic duty. The formative years were shaped by the drafting of the Constitution in 1787, defining the federal government’s framework. The subsequent ratification of the Bill of Rights further cemented individual freedoms and outlined governance principles that have endured across the nation’s history, ensuring a system of checks and balances that protect citizens’ rights.</span></span>
<span class="ltx_p" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5"><span class="ltx_text" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.5.1" style="font-size:80%;">The 19th century in the United States witnessed significant developments, including westward expansion, industrialization, and conflicts like the Civil War (1861-1865), which decisively addressed issues of slavery and reinforced federal authority over the states. The late 19th and early 20th centuries were marked by rapid industrial growth, extensive immigration, urbanization, and overseas expansion, including involvement in conflicts such as the Spanish-American War and World War I. The 20th century saw the United States emerge as a global superpower after World War II, engaging in the Cold War with the Soviet Union and participating in conflicts like the Korean and Vietnam Wars, significantly impacting the nation’s foreign policy and global standing.</span></span>
<span class="ltx_p" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6"><span class="ltx_text" id="A5.SS2.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.2.2.2.2.2.2.2.p2.6.1" style="font-size:80%;">Recent history includes social movements for civil rights, gender equality, and environmental protection, as well as economic shifts, advancements in technology, and challenges in areas such as healthcare and international relations.</span></span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Mar  8 13:45:12 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
