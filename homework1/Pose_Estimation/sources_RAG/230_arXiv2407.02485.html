<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</title>
<!--Generated on Tue Jul  2 17:55:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.02485v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S1" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S2" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S3" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Preliminaries</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S3.SS1" title="In 3 Preliminaries ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Problem Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S3.SS2" title="In 3 Preliminaries ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Limitation of Current RAG Pipelines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>RankRAG</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4.SS1" title="In 4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Stage-I: Supervised Fine-Tuning (SFT)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4.SS2" title="In 4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Stage-II: Unified Instruction-Tuning for Ranking and Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4.SS3" title="In 4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>RankRAG Inference: Retrieve-Rerank-Generate Pipeline</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS1" title="In 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experiment Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS1.SSS0.Px1" title="In 5.1 Experiment Setup ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title">Tasks and Datasets.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS2" title="In 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Main Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS3" title="In 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Ablation Studies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS4" title="In 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Experiment on Domain-specific RAG Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS5" title="In 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>A Closer Look at the Ranking Module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS6" title="In 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span>Case Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S6" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A1" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Dataset Description</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A1.SS1" title="In Appendix A Dataset Description ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Main Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A1.SS2" title="In Appendix A Dataset Description ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Biomedical Benchmarks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A2" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Data Blending Details for Ranking-enhanced Instruction Finetuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A3" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Prompt Formats of Instruction Tuning</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A3.SS1" title="In Appendix C Prompt Formats of Instruction Tuning ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Stage I: Supervised Fine-tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A3.SS2" title="In Appendix C Prompt Formats of Instruction Tuning ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Stage-II: Unified Instruction-Tuning for Ranking and Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A4" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Prompt Formats of Target Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A4.SS1" title="In Appendix D Prompt Formats of Target Tasks ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>Context Ranking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A4.SS2" title="In Appendix D Prompt Formats of Target Tasks ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>RAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A5" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional Experiment Results</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A5.SS1" title="In Appendix E Additional Experiment Results ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Ranking Performance Using DPR and Contriever as Retrievers <math alttext="\mathcal{R}" class="ltx_Math" display="inline"><semantics><mi class="ltx_font_mathcaligraphic">ℛ</mi><annotation-xml encoding="MathML-Content"><ci>ℛ</ci></annotation-xml><annotation encoding="application/x-tex">\mathcal{R}</annotation><annotation encoding="application/x-llamapun">caligraphic_R</annotation></semantics></math></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A5.SS2" title="In Appendix E Additional Experiment Results ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>RAG Performance with Different <math alttext="k" class="ltx_Math" display="inline"><semantics><mi>k</mi><annotation-xml encoding="MathML-Content"><ci>𝑘</ci></annotation-xml><annotation encoding="application/x-tex">k</annotation><annotation encoding="application/x-llamapun">italic_k</annotation></semantics></math></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A6" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Performance of NQ and Trivia QA on DPR Splits</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A7" title="In RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Additional Case Studies</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yue Yu  
<br class="ltx_break"/>Georgia Tech 
<br class="ltx_break"/>&amp;Wei Ping <sup class="ltx_sup" id="id2.2.id1"><span class="ltx_text ltx_font_italic" id="id2.2.id1.1">∗</span></sup>
<br class="ltx_break"/>NVIDIA 
<br class="ltx_break"/>&amp;Zihan Liu 
<br class="ltx_break"/>NVIDIA 
<br class="ltx_break"/>&amp;Boxin Wang 
<br class="ltx_break"/>NVIDIA 
<br class="ltx_break"/>&amp;Jiaxuan You 
<br class="ltx_break"/>NVIDIA 
<br class="ltx_break"/>Chao Zhang 
<br class="ltx_break"/>Georgia Tech 
<br class="ltx_break"/>&amp;Mohammad Shoeybi 
<br class="ltx_break"/>NVIDIA 
<br class="ltx_break"/>&amp;Bryan Catanzaro
<br class="ltx_break"/>NVIDIA
</span><span class="ltx_author_notes">Yue Yu did this work during an internship at NVIDIA. Correspondence to: Yue Yu &lt;yueyu@gatech.edu&gt;, Wei Ping &lt;wping@nvidia.com&gt;.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Large language models (LLMs) typically utilize the top-<em class="ltx_emph ltx_font_italic" id="id3.id1.1">k</em> contexts from a retriever in retrieval-augmented generation (RAG).
In this work, we propose a novel instruction fine-tuning framework RankRAG, which instruction-tunes a single LLM for the dual purpose of context ranking and answer generation in RAG.
In particular, the instruction-tuned LLMs work surprisingly well by adding a small fraction of ranking data into the training blend, and outperform existing expert ranking models, including the same LLM exclusively fine-tuned on a large amount of ranking data.
For generation, we compare our model with many strong baselines, including GPT-4-0613, GPT-4-turbo-2024-0409, and ChatQA-1.5, an open-sourced model with the state-of-the-art performance on RAG benchmarks.
Specifically, our Llama3-RankRAG significantly outperforms Llama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks.
In addition, it also performs comparably to GPT-4 on five RAG benchmarks in the biomedical domain without instruction fine-tuning on biomedical data, demonstrating its superb capability for generalization to new domains.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib46" title="">2020</a>; Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib25" title="">2021</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">2024</a>)</cite> is a widely used technique for customizing large language models (LLMs) to handle long-tail knowledge <cite class="ltx_cite ltx_citemacro_citep">(Mallen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib55" title="">2023</a>; Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib5" title="">2024b</a>)</cite>, provide up-to-date information <cite class="ltx_cite ltx_citemacro_citep">(Kasai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib36" title="">2023</a>)</cite>, and adapt to specific domains and tasks <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib90" title="">2024</a>)</cite> without modifying the model weights.
In general, a dense embedding based retriever <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib48" title="">2023</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib83" title="">2022</a>)</cite> first retrieves top-<em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">k</em> chunked contexts from a collection documents or external database for a given question.
Then, LLM reads the top-<em class="ltx_emph ltx_font_italic" id="S1.p1.1.2">k</em> contexts to generate the answer.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.2">However, the current RAG pipeline has the following limitations:
<em class="ltx_emph ltx_font_italic" id="S1.p2.2.1">i)</em> LLMs are not good at reading too many chunked contexts (e.g., top-100) even with the long-context window, not only due to efficiency reasons, but also because a shorter list of top-<em class="ltx_emph ltx_font_italic" id="S1.p2.2.2">k</em> (e.g., 5, 10) contexts usually leads to higher accuracy of generation <cite class="ltx_cite ltx_citemacro_citep">(e.g., see Table 5 in Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib92" title="">2024b</a>)</cite>.
<em class="ltx_emph ltx_font_italic" id="S1.p2.2.3">ii)</em> Given a small <math alttext="k" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mi id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">italic_k</annotation></semantics></math>, one needs a mechanism to ensure the <em class="ltx_emph ltx_font_italic" id="S1.p2.2.4">high recall</em> of relevant contents.
Relying solely on a retrieval model may be inadequate due to challenges in learning effective local alignments across the entire embedding space to support accurate matching <cite class="ltx_cite ltx_citemacro_citep">(Luan et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib52" title="">2021</a>)</cite>.
In practice, a separate ranking model <cite class="ltx_cite ltx_citemacro_citep">(Nogueira et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib61" title="">2020</a>; Glass et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib19" title="">2022</a>; Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib54" title="">2023</a>)</cite> that cross-encodes question and candidate context can work better than a dense embedding-based retriever for obtaining the most relevant top-<em class="ltx_emph ltx_font_italic" id="S1.p2.2.5">k</em> contexts from top-<em class="ltx_emph ltx_font_italic" id="S1.p2.2.6">N</em> candidates (<em class="ltx_emph ltx_font_italic" id="S1.p2.2.7">N</em> <math alttext="\gg" class="ltx_Math" display="inline" id="S1.p2.2.m2.1"><semantics id="S1.p2.2.m2.1a"><mo id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">≫</mo><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><csymbol cd="latexml" id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">much-greater-than</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\gg</annotation><annotation encoding="application/x-llamapun" id="S1.p2.2.m2.1d">≫</annotation></semantics></math> <em class="ltx_emph ltx_font_italic" id="S1.p2.2.8">k</em>).
<em class="ltx_emph ltx_font_italic" id="S1.p2.2.9">iii)</em> However, the zero-shot generalization capability of the expert ranking model can be relatively limited compared to the versatile LLM itself.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Based on the above considerations, our goal is to design an RAG instruction tuning pipeline that uses a single language model to achieve both high-recall context extraction and high-quality content generation.
In previous study, instruction-tuned LLMs demonstrate a strong ability to extract answers from relevant context for a given question <cite class="ltx_cite ltx_citemacro_citep">(e.g., OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">2023</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>)</cite>.
This capability can be viewed as the “dual capability” of
determining whether a chunk of context is relevant to the question thus is useful for generating the answer. We hypothesize that these capabilities mutually enhance each other.
Motivated by this insight, we propose RankRAG, which intruction-tunes a single LLM for both context ranking and answer generation in RAG framework.
Furthermore, RankRAG expands upon existing instruction-tuning data by incorporating context-rich QA, retrieval-augmented QA and ranking datasets, enhancing the LLM’s ability to filter out irrelevant contexts during both the retrieval and generation phases of RAG.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Our contribution can be summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose RankRAG, a novel framework that enhances LLM’s RAG capability through simultaneously instructing the LLM on context ranking and answer generation.
During training, we design a specialized task focused on identifying relevant contexts or passages for a given question. This task is structured for ranking and framed as regular question answering with instruction, aligning more effectively with retrieval-augmented generation tasks. At inference, the LLM first reranks the retrieved contexts, then generates answer based on the refined top-<em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.1">k</em> (e.g., 5). This framework is readily applicable to diverse knowledge-intensive NLP tasks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Remarkably, we observe that integrating a small fraction of ranking data into the instruction tuning blend of LLM works surprisingly well on the evaluations of ranking associated with the RAG tasks, even surpassing the LLMs fine-tuned with <math alttext="10\times" class="ltx_math_unparsed" display="inline" id="S1.I1.i2.p1.1.m1.1"><semantics id="S1.I1.i2.p1.1.m1.1a"><mrow id="S1.I1.i2.p1.1.m1.1b"><mn id="S1.I1.i2.p1.1.m1.1.1">10</mn><mo id="S1.I1.i2.p1.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.1c">10\times</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i2.p1.1.m1.1d">10 ×</annotation></semantics></math> more ranking data. We attribute this success to the transferable design of RankRAG training.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We extensively compare the proposed RankRAG method with several strong baselines, including the open-sourced ChatQA-1.5.
On nine general-domain and five biomedical knowledge-intensive benchmarks for RAG, Llama3-RankRAG-8B and Llama3-RankRAG-70B outperforms Llama3-ChatQA-1.5-8B and Llama3-ChatQA-1.5-70B by a margin, respectively.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In the remainder of the paper, we discuss related work in § <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S2" title="2 Related Work ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>.
We introduce problem setup in § <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S3" title="3 Preliminaries ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">3</span></a> and RankRAG method in § <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4" title="4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">4</span></a>.
We present the experimental setup in § <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5" title="5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">5</span></a>, and conclude the paper in § <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S6" title="6 Conclusion ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Retrieval-augumented generation (RAG) has been established for knowledge-intensive NLP tasks <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib46" title="">2020</a>; Borgeaud et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib8" title="">2022</a>; Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib27" title="">2023</a>; Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib25" title="">2021</a>)</cite>.
In the standard process, a standalone dense-embedding-based retriever <cite class="ltx_cite ltx_citemacro_cite">(e.g., Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>)</cite> first retrieves relevant information from an external corpus, which the LLM then utilizes in the generation process.
To improve this pipeline, recent research has focused on aligning retrievers to the needs of LLMs for generation <cite class="ltx_cite ltx_citemacro_citep">(Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib74" title="">2024</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>)</cite>, designing multi-step retrieval processes <cite class="ltx_cite ltx_citemacro_citep">(Trivedi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib80" title="">2023</a>; Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib30" title="">2023</a>; Jeong et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib28" title="">2024</a>; Shao et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib73" title="">2023</a>)</cite>, or filtering irrelevant contexts <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib86" title="">2023c</a>; Yoran et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib94" title="">2024</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib91" title="">2024a</a>)</cite>.
To improve generation, several studies have designed instruction-tuning methods dedicated to enhancing the search <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib54" title="">2023</a>; Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib101" title="">2024</a>; Muennighoff et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib60" title="">2024</a>)</cite> and RAG capability of LLMs <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>; Luo et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib53" title="">2023</a>; Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">2024a</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Although strong retrievers have been introduced <cite class="ltx_cite ltx_citemacro_citep">(e.g., Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib48" title="">2023</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib98" title="">2022</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib83" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib84" title="">2023a</a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib45" title="">2024</a>)</cite>, one potential approach to improve retriever is optimizing it along with LLM in an end-to-end manner <cite class="ltx_cite ltx_citemacro_cite">(e.g., Guu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib20" title="">2020</a>; Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib74" title="">2024</a>; Sachan et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib72" title="">2021</a>; Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib27" title="">2023</a>)</cite>.
However, this requires surrogate loss for optimization and complicates the training pipeline, especially when the embedding database needs to be re-indexed frequently due to the update of the embedding model (i.e., retriever).</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Ranking serves as an intermediate step to improve the quality of information retrieval <cite class="ltx_cite ltx_citemacro_citep">(Mitra et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib59" title="">2018</a>)</cite>, and has been applied to RAG pipeline for improving generation quality <cite class="ltx_cite ltx_citemacro_citep">(Glass et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib19" title="">2022</a>; Ram et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib70" title="">2023</a>)</cite>.
However, these methods still rely on an additional moderate-sized model (e.g. BERT, T5) for ranking, which is often insufficient to capture the relevance between query and contexts and may lack the zero-shot generalization capability.
Although recent studies have demonstrated the strong ability of LLMs at ranking tasks <cite class="ltx_cite ltx_citemacro_citep">(Khalifa et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib37" title="">2023</a>; Qin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib68" title="">2024</a>; Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib75" title="">2023</a>)</cite>, how to harvest this ability for the RAG pipeline remains underexplored.</p>
</div>
<figure class="ltx_figure" id="S2.F4.sf1">
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminaries</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we first introduce the preliminaries of retrieval-augmented generation as well as the problem setup.
Then we present the limitations in the current RAG pipeline, which motivates the proposed RankRAG method.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Setup</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">In retrieval-augmented generation, a collection of documents or contexts (e.g. Wikipedia) is given, providing the grounded knowledge.
Given a question <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_q</annotation></semantics></math>, the retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">caligraphic_R</annotation></semantics></math> (e.g., a parameterized embedding model) first retrieves top-<math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_k</annotation></semantics></math> contexts <math alttext="\mathcal{C}=\{c_{1},\cdots,c_{k}\}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.3"><semantics id="S3.SS1.p1.4.m4.3a"><mrow id="S3.SS1.p1.4.m4.3.3" xref="S3.SS1.p1.4.m4.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.4.m4.3.3.4" xref="S3.SS1.p1.4.m4.3.3.4.cmml">𝒞</mi><mo id="S3.SS1.p1.4.m4.3.3.3" xref="S3.SS1.p1.4.m4.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.4.m4.3.3.2.2" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml"><mo id="S3.SS1.p1.4.m4.3.3.2.2.3" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">{</mo><msub id="S3.SS1.p1.4.m4.2.2.1.1.1" xref="S3.SS1.p1.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.4.m4.2.2.1.1.1.2" xref="S3.SS1.p1.4.m4.2.2.1.1.1.2.cmml">c</mi><mn id="S3.SS1.p1.4.m4.2.2.1.1.1.3" xref="S3.SS1.p1.4.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.4.m4.3.3.2.2.4" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">,</mo><mi id="S3.SS1.p1.4.m4.1.1" mathvariant="normal" xref="S3.SS1.p1.4.m4.1.1.cmml">⋯</mi><mo id="S3.SS1.p1.4.m4.3.3.2.2.5" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.4.m4.3.3.2.2.2" xref="S3.SS1.p1.4.m4.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.4.m4.3.3.2.2.2.2" xref="S3.SS1.p1.4.m4.3.3.2.2.2.2.cmml">c</mi><mi id="S3.SS1.p1.4.m4.3.3.2.2.2.3" xref="S3.SS1.p1.4.m4.3.3.2.2.2.3.cmml">k</mi></msub><mo id="S3.SS1.p1.4.m4.3.3.2.2.6" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.3b"><apply id="S3.SS1.p1.4.m4.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3"><eq id="S3.SS1.p1.4.m4.3.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3.3"></eq><ci id="S3.SS1.p1.4.m4.3.3.4.cmml" xref="S3.SS1.p1.4.m4.3.3.4">𝒞</ci><set id="S3.SS1.p1.4.m4.3.3.2.3.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2"><apply id="S3.SS1.p1.4.m4.2.2.1.1.1.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1.1.2">𝑐</ci><cn id="S3.SS1.p1.4.m4.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.4.m4.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">⋯</ci><apply id="S3.SS1.p1.4.m4.3.3.2.2.2.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2.2">𝑐</ci><ci id="S3.SS1.p1.4.m4.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2.3">𝑘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.3c">\mathcal{C}=\{c_{1},\cdots,c_{k}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.3d">caligraphic_C = { italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_c start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT }</annotation></semantics></math> that are most relevant to the question.
Subsequently, the language model produces the final answer
where the answer can either be a short phrase or a long sentence, depending on the type of the target task. Our focus is on autoregressive language models <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib62" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">2023</a>; Meta-AI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib57" title="">2024</a>)</cite>, which is the most common architectures for LLMs.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Limitation of Current RAG Pipelines</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Before formally introducing RankRAG, we would like to first pinpoint several limitations of the current “retrieve-then-generate” pipeline with large language models.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.3"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.3.1">Limited Capacity of Retriever.</span>
Current RAG systems usually employ sparse retrieval (e.g. BM25 <cite class="ltx_cite ltx_citemacro_citep">(Robertson et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib71" title="">2004</a>)</cite>) or moderate-size (e.g. BERT-based) embedding model <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib48" title="">2023</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib83" title="">2022</a>)</cite> as the retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">caligraphic_R</annotation></semantics></math>, mainly due to efficiency consideration as there are often millions of, if not more, documents need to be indexed.
These models encode questions and documents <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.3.2">independently</em> and calculate the similarity between question and documents using vector similarity metrics.
However, the <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.3.3">limited capacity of embedding model</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.3.4">independent processing of query and documents</em> constrain the ability to estimate textual relevance between question <math alttext="q" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_q</annotation></semantics></math> and documents <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_d</annotation></semantics></math>, reducing their effectiveness in new tasks or domains, verified by both theoretical <cite class="ltx_cite ltx_citemacro_citep">(Menon et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib56" title="">2022</a>)</cite> and empirical <cite class="ltx_cite ltx_citemacro_citep">(Luan et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib52" title="">2021</a>; Thakur et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib76" title="">2021</a>)</cite> studies.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.6"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.6.1">Trade-off of Picking Top-<em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.6.1.1">k</em> Contexts.</span>
Although the state-of-the-art long-context LLM can take many retrieved contexts as input for answer generation, the performance quickly saturates with increased <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_k</annotation></semantics></math> in practice. For example, <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib92" title="">2024b</a>)</cite> finds the optimal number of chunked context <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_k</annotation></semantics></math> is around <math alttext="10" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mn id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><cn id="S3.SS2.p3.3.m3.1.1.cmml" type="integer" xref="S3.SS2.p3.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">10</annotation></semantics></math> for long document QA tasks.
As illurstrated in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:motivation-diff_k</span>, we perform evaluation on ChatQA-1.5 <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite>, one of the strongest RAG model with open weights, and find the saturation of accuracy when <math alttext="k=10" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">k</mi><mo id="S3.SS2.p3.4.m4.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><eq id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1"></eq><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝑘</ci><cn id="S3.SS2.p3.4.m4.1.1.3.cmml" type="integer" xref="S3.SS2.p3.4.m4.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">k=10</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_k = 10</annotation></semantics></math>.
In general, a smaller <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_k</annotation></semantics></math> often fails to capture all relevant information, compromising the <em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.6.2">recall</em>, given the limited expressibility of retriver. In contrast, a larger <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_k</annotation></semantics></math> improves <em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.6.3">recall</em> but at the cost of introducing irrelevant content that hampers the LLM’s ability to generate accurate answers <cite class="ltx_cite ltx_citemacro_citep">(Yoran et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib94" title="">2024</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib96" title="">2023b</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>RankRAG</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To address the limitations mentioned in the previous section, we propose the RankRAG method to enhance the LLM’s ability for retrieval-augmented generation. Specifically, we instruction-tune the LLM to simultaneously <em class="ltx_emph ltx_font_italic" id="S4.p1.1.1">capture the relevance between the question and context</em> and <em class="ltx_emph ltx_font_italic" id="S4.p1.1.2">utilize the retrieved context for answer generation</em>. The details are introduced as follows.</p>
</div>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S2.F4.g1" src="x1.png" width="822"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S2.F4.3.2" style="font-size:90%;">Two-stage instruction tuning framework for RankRAG. </span></figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Stage-I: Supervised Fine-Tuning (SFT)</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">It is observed that general instruction-tuning or supervised fine-tuning (SFT) often significantly improves the ability of LLMs to follow instructions, thus improving zero-shot results on various downstream tasks <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib87" title="">2022</a>; Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib65" title="">2022</a>)</cite>.
As such, we follow existing works <cite class="ltx_cite ltx_citemacro_citep">(Chung et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib11" title="">2024</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">2024</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite> to first leverage SFT on a blend of high quality instruction following datasets, including: <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.1">i)</em>
a <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.2">private crowd-sourced conversational dataset</em> and <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.3">public conversation datasets</em>: OpenAssistant <cite class="ltx_cite ltx_citemacro_citep">(Köpf et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib43" title="">2023</a>)</cite>, Dolly <cite class="ltx_cite ltx_citemacro_citep">(Conover et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib12" title="">2023</a>)</cite>, and SODA <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib39" title="">2023</a>)</cite>, <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.4">ii)</em> <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.5">a long-form QA dataset</em> ELI5 that requires elaborate answers <cite class="ltx_cite ltx_citemacro_citep">(Fan et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib17" title="">2019</a>)</cite>, <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.6">iii)</em> <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.7">LLM-generated instructions</em>: Self-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib85" title="">2023b</a>)</cite> and Unnatural Instructions <cite class="ltx_cite ltx_citemacro_citep">(Honovich et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib23" title="">2023</a>)</cite>, <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.8">iv)</em> <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.9">FLAN and Chain-of-thought datasets</em> <cite class="ltx_cite ltx_citemacro_citep">(Chung et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib11" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">There are overall 128K SFT examples in total. We make sure that there is <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.1.1">no overlap</em> between SFT data and data from evaluation tasks.
For each sample in the instruction-following dataset, we take the multi-turn conversational format, use the previous turns of conversation between the user and the assistant as the context, and compute the loss only at the last response from the assistant.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Stage-II: Unified Instruction-Tuning for Ranking and Generation</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The Stage-I SFT enpowers the LLMs with basic instruction-following capabilities; however, their performance on RAG tasks often remains suboptimal, as the LLMs are not optimized for extracting answers from retrieved context for a given question.
Although recent studies <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib99" title="">2024</a>)</cite> enhance the RAG capability of LLM by instruction tuning it on context-rich generation tasks, these approaches can still be ineffective with poor initial retrieval results.
RankRAG instruction tunes the LLM for both retrieval-augmented generation and context ranking. In particular, the context ranking capability is crucial to obtain more relevant top-<em class="ltx_emph ltx_font_italic" id="S4.SS2.p1.1.1">k</em> context with imperfect retriever.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">To achieve this goal, the instruction tuning blend of Stage-II consists the following five parts:</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">1) <span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">SFT data from Stage-I.</span> This part is included to maintain LLM’s instruction-following capability.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">2) <span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Context-rich QA data.</span>
We first follow <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite> to leverage multiple context-rich QA tasks to enhance the LLM’s capability of using context for generation. The training blend we use consists of:
<em class="ltx_emph ltx_font_italic" id="S4.SS2.p4.1.2">i</em>) standard QA and reading comprehension datasets: DROP <cite class="ltx_cite ltx_citemacro_citep">(Dua et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib16" title="">2019</a>)</cite>, NarrativeQA <cite class="ltx_cite ltx_citemacro_citep">(Kočiskỳ et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib41" title="">2018</a>)</cite>, Quoref <cite class="ltx_cite ltx_citemacro_citep">(Dasigi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib13" title="">2019</a>)</cite>, ROPES <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib47" title="">2019</a>)</cite>, NewsQA <cite class="ltx_cite ltx_citemacro_citep">(Trischler et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib79" title="">2017</a>)</cite>, TAT-QA <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib100" title="">2021</a>)</cite>, which contains a question, <span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.3">a golden context</span> and an answer.
<em class="ltx_emph ltx_font_italic" id="S4.SS2.p4.1.4">ii</em>) conversational QA datasets: HumanAnnotatedConvQA and SyntheticConvQA open-sourced by <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite>, which contains a conversation between user and assistant, as well as one background document. The model needs to generate an answer given the conversation history and document.</p>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">3) <span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.1">Retrieval-augmented QA data.</span>
In addition to the above QA datasets used in <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite>, we add two datasets with not only gold context but also the top-retrieved context using BM25.
Note that, it is crucial to improve LLM’s robustness over irrelevant context at generation.
Being aware of this, we consider two QA tasks, namely SQuAD <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib69" title="">2016</a>)</cite> and WebQuestions <cite class="ltx_cite ltx_citemacro_citep">(Berant et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib7" title="">2013</a>)</cite>. For each question with the answer, we combine the gold context with the top-retrieved contexts using BM25, ensuring a total of five contexts. Note that some retrieved contexts may not contain the answer, and could be the “hard-negative” contexts.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.2">4) <span class="ltx_text ltx_font_bold" id="S4.SS2.p6.2.1">Context ranking data.</span>
To empower LLMs with ranking capabilities, we use the popular MS MARCO passage (context) ranking dataset <cite class="ltx_cite ltx_citemacro_citep">(Bajaj et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib6" title="">2016</a>)</cite>.
We treat the gold query-passage pairs <math alttext="(q,c^{+})" class="ltx_Math" display="inline" id="S4.SS2.p6.1.m1.2"><semantics id="S4.SS2.p6.1.m1.2a"><mrow id="S4.SS2.p6.1.m1.2.2.1" xref="S4.SS2.p6.1.m1.2.2.2.cmml"><mo id="S4.SS2.p6.1.m1.2.2.1.2" stretchy="false" xref="S4.SS2.p6.1.m1.2.2.2.cmml">(</mo><mi id="S4.SS2.p6.1.m1.1.1" xref="S4.SS2.p6.1.m1.1.1.cmml">q</mi><mo id="S4.SS2.p6.1.m1.2.2.1.3" xref="S4.SS2.p6.1.m1.2.2.2.cmml">,</mo><msup id="S4.SS2.p6.1.m1.2.2.1.1" xref="S4.SS2.p6.1.m1.2.2.1.1.cmml"><mi id="S4.SS2.p6.1.m1.2.2.1.1.2" xref="S4.SS2.p6.1.m1.2.2.1.1.2.cmml">c</mi><mo id="S4.SS2.p6.1.m1.2.2.1.1.3" xref="S4.SS2.p6.1.m1.2.2.1.1.3.cmml">+</mo></msup><mo id="S4.SS2.p6.1.m1.2.2.1.4" stretchy="false" xref="S4.SS2.p6.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.m1.2b"><interval closure="open" id="S4.SS2.p6.1.m1.2.2.2.cmml" xref="S4.SS2.p6.1.m1.2.2.1"><ci id="S4.SS2.p6.1.m1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1">𝑞</ci><apply id="S4.SS2.p6.1.m1.2.2.1.1.cmml" xref="S4.SS2.p6.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.1.m1.2.2.1.1.1.cmml" xref="S4.SS2.p6.1.m1.2.2.1.1">superscript</csymbol><ci id="S4.SS2.p6.1.m1.2.2.1.1.2.cmml" xref="S4.SS2.p6.1.m1.2.2.1.1.2">𝑐</ci><plus id="S4.SS2.p6.1.m1.2.2.1.1.3.cmml" xref="S4.SS2.p6.1.m1.2.2.1.1.3"></plus></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.2c">(q,c^{+})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.1.m1.2d">( italic_q , italic_c start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT )</annotation></semantics></math> as relevant while using hard negative passages <math alttext="(q,c^{-})" class="ltx_Math" display="inline" id="S4.SS2.p6.2.m2.2"><semantics id="S4.SS2.p6.2.m2.2a"><mrow id="S4.SS2.p6.2.m2.2.2.1" xref="S4.SS2.p6.2.m2.2.2.2.cmml"><mo id="S4.SS2.p6.2.m2.2.2.1.2" stretchy="false" xref="S4.SS2.p6.2.m2.2.2.2.cmml">(</mo><mi id="S4.SS2.p6.2.m2.1.1" xref="S4.SS2.p6.2.m2.1.1.cmml">q</mi><mo id="S4.SS2.p6.2.m2.2.2.1.3" xref="S4.SS2.p6.2.m2.2.2.2.cmml">,</mo><msup id="S4.SS2.p6.2.m2.2.2.1.1" xref="S4.SS2.p6.2.m2.2.2.1.1.cmml"><mi id="S4.SS2.p6.2.m2.2.2.1.1.2" xref="S4.SS2.p6.2.m2.2.2.1.1.2.cmml">c</mi><mo id="S4.SS2.p6.2.m2.2.2.1.1.3" xref="S4.SS2.p6.2.m2.2.2.1.1.3.cmml">−</mo></msup><mo id="S4.SS2.p6.2.m2.2.2.1.4" stretchy="false" xref="S4.SS2.p6.2.m2.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m2.2b"><interval closure="open" id="S4.SS2.p6.2.m2.2.2.2.cmml" xref="S4.SS2.p6.2.m2.2.2.1"><ci id="S4.SS2.p6.2.m2.1.1.cmml" xref="S4.SS2.p6.2.m2.1.1">𝑞</ci><apply id="S4.SS2.p6.2.m2.2.2.1.1.cmml" xref="S4.SS2.p6.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.2.m2.2.2.1.1.1.cmml" xref="S4.SS2.p6.2.m2.2.2.1.1">superscript</csymbol><ci id="S4.SS2.p6.2.m2.2.2.1.1.2.cmml" xref="S4.SS2.p6.2.m2.2.2.1.1.2">𝑐</ci><minus id="S4.SS2.p6.2.m2.2.2.1.1.3.cmml" xref="S4.SS2.p6.2.m2.2.2.1.1.3"></minus></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m2.2c">(q,c^{-})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.2.m2.2d">( italic_q , italic_c start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT )</annotation></semantics></math> mined via BM25 as irrelevant pairs.
The LLM need to generate “True” or “False” given the corresponding query-passage pair, where the question along with the task-specific instruction is “For the question <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p6.2.2">{question}</span>, access whether the passage is relevant to the question.”.</p>
</div>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.4">We want to handle ranking in conversational senario as well. While MS MARCO spans various topics, the questions are only single-turn short sentences. However, ranking data are only available, if any, at a small amount for conversation QA.
To overcome this limitation, we repurpose the conversational QA pairs to generate pseudo relevance pairs.
As each conversation is only associated with <em class="ltx_emph ltx_font_italic" id="S4.SS2.p7.4.1">one</em> document <math alttext="d" class="ltx_Math" display="inline" id="S4.SS2.p7.1.m1.1"><semantics id="S4.SS2.p7.1.m1.1a"><mi id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><ci id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.1.m1.1d">italic_d</annotation></semantics></math>, we cut each document into 150-word chunks <math alttext="(c_{1},c_{2},\ldots,c_{n})" class="ltx_Math" display="inline" id="S4.SS2.p7.2.m2.4"><semantics id="S4.SS2.p7.2.m2.4a"><mrow id="S4.SS2.p7.2.m2.4.4.3" xref="S4.SS2.p7.2.m2.4.4.4.cmml"><mo id="S4.SS2.p7.2.m2.4.4.3.4" stretchy="false" xref="S4.SS2.p7.2.m2.4.4.4.cmml">(</mo><msub id="S4.SS2.p7.2.m2.2.2.1.1" xref="S4.SS2.p7.2.m2.2.2.1.1.cmml"><mi id="S4.SS2.p7.2.m2.2.2.1.1.2" xref="S4.SS2.p7.2.m2.2.2.1.1.2.cmml">c</mi><mn id="S4.SS2.p7.2.m2.2.2.1.1.3" xref="S4.SS2.p7.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.SS2.p7.2.m2.4.4.3.5" xref="S4.SS2.p7.2.m2.4.4.4.cmml">,</mo><msub id="S4.SS2.p7.2.m2.3.3.2.2" xref="S4.SS2.p7.2.m2.3.3.2.2.cmml"><mi id="S4.SS2.p7.2.m2.3.3.2.2.2" xref="S4.SS2.p7.2.m2.3.3.2.2.2.cmml">c</mi><mn id="S4.SS2.p7.2.m2.3.3.2.2.3" xref="S4.SS2.p7.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S4.SS2.p7.2.m2.4.4.3.6" xref="S4.SS2.p7.2.m2.4.4.4.cmml">,</mo><mi id="S4.SS2.p7.2.m2.1.1" mathvariant="normal" xref="S4.SS2.p7.2.m2.1.1.cmml">…</mi><mo id="S4.SS2.p7.2.m2.4.4.3.7" xref="S4.SS2.p7.2.m2.4.4.4.cmml">,</mo><msub id="S4.SS2.p7.2.m2.4.4.3.3" xref="S4.SS2.p7.2.m2.4.4.3.3.cmml"><mi id="S4.SS2.p7.2.m2.4.4.3.3.2" xref="S4.SS2.p7.2.m2.4.4.3.3.2.cmml">c</mi><mi id="S4.SS2.p7.2.m2.4.4.3.3.3" xref="S4.SS2.p7.2.m2.4.4.3.3.3.cmml">n</mi></msub><mo id="S4.SS2.p7.2.m2.4.4.3.8" stretchy="false" xref="S4.SS2.p7.2.m2.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.4b"><vector id="S4.SS2.p7.2.m2.4.4.4.cmml" xref="S4.SS2.p7.2.m2.4.4.3"><apply id="S4.SS2.p7.2.m2.2.2.1.1.cmml" xref="S4.SS2.p7.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.2.m2.2.2.1.1.1.cmml" xref="S4.SS2.p7.2.m2.2.2.1.1">subscript</csymbol><ci id="S4.SS2.p7.2.m2.2.2.1.1.2.cmml" xref="S4.SS2.p7.2.m2.2.2.1.1.2">𝑐</ci><cn id="S4.SS2.p7.2.m2.2.2.1.1.3.cmml" type="integer" xref="S4.SS2.p7.2.m2.2.2.1.1.3">1</cn></apply><apply id="S4.SS2.p7.2.m2.3.3.2.2.cmml" xref="S4.SS2.p7.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS2.p7.2.m2.3.3.2.2.1.cmml" xref="S4.SS2.p7.2.m2.3.3.2.2">subscript</csymbol><ci id="S4.SS2.p7.2.m2.3.3.2.2.2.cmml" xref="S4.SS2.p7.2.m2.3.3.2.2.2">𝑐</ci><cn id="S4.SS2.p7.2.m2.3.3.2.2.3.cmml" type="integer" xref="S4.SS2.p7.2.m2.3.3.2.2.3">2</cn></apply><ci id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1">…</ci><apply id="S4.SS2.p7.2.m2.4.4.3.3.cmml" xref="S4.SS2.p7.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S4.SS2.p7.2.m2.4.4.3.3.1.cmml" xref="S4.SS2.p7.2.m2.4.4.3.3">subscript</csymbol><ci id="S4.SS2.p7.2.m2.4.4.3.3.2.cmml" xref="S4.SS2.p7.2.m2.4.4.3.3.2">𝑐</ci><ci id="S4.SS2.p7.2.m2.4.4.3.3.3.cmml" xref="S4.SS2.p7.2.m2.4.4.3.3.3">𝑛</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.4c">(c_{1},c_{2},\ldots,c_{n})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.2.m2.4d">( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math>.
We compute the 4-gram recall score between each chunk <math alttext="c_{i}" class="ltx_Math" display="inline" id="S4.SS2.p7.3.m3.1"><semantics id="S4.SS2.p7.3.m3.1a"><msub id="S4.SS2.p7.3.m3.1.1" xref="S4.SS2.p7.3.m3.1.1.cmml"><mi id="S4.SS2.p7.3.m3.1.1.2" xref="S4.SS2.p7.3.m3.1.1.2.cmml">c</mi><mi id="S4.SS2.p7.3.m3.1.1.3" xref="S4.SS2.p7.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.3.m3.1b"><apply id="S4.SS2.p7.3.m3.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.3.m3.1.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p7.3.m3.1.1.2.cmml" xref="S4.SS2.p7.3.m3.1.1.2">𝑐</ci><ci id="S4.SS2.p7.3.m3.1.1.3.cmml" xref="S4.SS2.p7.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.3.m3.1c">c_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.3.m3.1d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and the ground-truth answer <math alttext="a" class="ltx_Math" display="inline" id="S4.SS2.p7.4.m4.1"><semantics id="S4.SS2.p7.4.m4.1a"><mi id="S4.SS2.p7.4.m4.1.1" xref="S4.SS2.p7.4.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.4.m4.1b"><ci id="S4.SS2.p7.4.m4.1.1.cmml" xref="S4.SS2.p7.4.m4.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.4.m4.1c">a</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.4.m4.1d">italic_a</annotation></semantics></math>, considering segments with a recall score above 0.5 as relevant and those below 0.1 as irrelevant for the corresponding conversation. Note that, each sample contains one question-context pair for this ranking dataset. In total, there are around 50k ranking pairs from MS MARCO ranking and synthetic conversations for instruction finetuning.</p>
</div>
<div class="ltx_para" id="S4.SS2.p8">
<p class="ltx_p" id="S4.SS2.p8.1">5) <span class="ltx_text ltx_font_bold" id="S4.SS2.p8.1.1">Retrieval-augmented ranking data.</span>
We aim to train the LLM with the capability of determining the relevance of multiple contexts simultaneously given a question, which is closer to the test-time behavior of RAG with top-<em class="ltx_emph ltx_font_italic" id="S4.SS2.p8.1.2">k</em> contexts.
As before, we utilize two QA datasets, SQuAD <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib69" title="">2016</a>)</cite> and WebQuestions <cite class="ltx_cite ltx_citemacro_citep">(Berant et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib7" title="">2013</a>)</cite>. We combine the gold context with the top-retrieved contexts using BM25, ensuring a total of five contexts.
The contexts containing the answer are considered relevant, and the LLM is trained to <em class="ltx_emph ltx_font_italic" id="S4.SS2.p8.1.3">explicitly</em> identify all relevant contexts for the question.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>The instruction template for Stage-II. It is worth noting that all the tasks can be unified in the <math alttext="(x,c,y)" class="ltx_Math" display="inline" id="S4.T1.2.m1.3"><semantics id="S4.T1.2.m1.3b"><mrow id="S4.T1.2.m1.3.4.2" xref="S4.T1.2.m1.3.4.1.cmml"><mo id="S4.T1.2.m1.3.4.2.1" stretchy="false" xref="S4.T1.2.m1.3.4.1.cmml">(</mo><mi id="S4.T1.2.m1.1.1" xref="S4.T1.2.m1.1.1.cmml">x</mi><mo id="S4.T1.2.m1.3.4.2.2" xref="S4.T1.2.m1.3.4.1.cmml">,</mo><mi id="S4.T1.2.m1.2.2" xref="S4.T1.2.m1.2.2.cmml">c</mi><mo id="S4.T1.2.m1.3.4.2.3" xref="S4.T1.2.m1.3.4.1.cmml">,</mo><mi id="S4.T1.2.m1.3.3" xref="S4.T1.2.m1.3.3.cmml">y</mi><mo id="S4.T1.2.m1.3.4.2.4" stretchy="false" xref="S4.T1.2.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.2.m1.3c"><vector id="S4.T1.2.m1.3.4.1.cmml" xref="S4.T1.2.m1.3.4.2"><ci id="S4.T1.2.m1.1.1.cmml" xref="S4.T1.2.m1.1.1">𝑥</ci><ci id="S4.T1.2.m1.2.2.cmml" xref="S4.T1.2.m1.2.2">𝑐</ci><ci id="S4.T1.2.m1.3.3.cmml" xref="S4.T1.2.m1.3.3">𝑦</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.m1.3d">(x,c,y)</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.m1.3e">( italic_x , italic_c , italic_y )</annotation></semantics></math> format, which is able to facilitate effective knowledge transfer across tasks. 
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.5" style="width:433.6pt;height:121.9pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-70.5pt,19.7pt) scale(0.754737967523585,0.754737967523585) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T1.5.3">
<tr class="ltx_tr" id="S4.T1.5.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="S4.T1.5.3.3.4" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.3.4.1">
<span class="ltx_p" id="S4.T1.5.3.3.4.1.1" style="width:105.3pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.3.3.4.1.1.1" style="font-size:90%;">Task</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T1.3.1.1.1" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.3.1.1.1.1">
<span class="ltx_p" id="S4.T1.3.1.1.1.1.1" style="width:210.6pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.3.1.1.1.1.1.1" style="font-size:90%;">Question <math alttext="x" class="ltx_Math" display="inline" id="S4.T1.3.1.1.1.1.1.1.m1.1"><semantics id="S4.T1.3.1.1.1.1.1.1.m1.1a"><mi id="S4.T1.3.1.1.1.1.1.1.m1.1.1" xref="S4.T1.3.1.1.1.1.1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.3.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.3.1.1.1.1.1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.1.1.1.1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.1.1.1.1.1.1.m1.1d">italic_x</annotation></semantics></math></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T1.4.2.2.2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.4.2.2.2.1">
<span class="ltx_p" id="S4.T1.4.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.4.2.2.2.1.1.1" style="font-size:90%;">Context <math alttext="c" class="ltx_Math" display="inline" id="S4.T1.4.2.2.2.1.1.1.m1.1"><semantics id="S4.T1.4.2.2.2.1.1.1.m1.1a"><mi id="S4.T1.4.2.2.2.1.1.1.m1.1.1" xref="S4.T1.4.2.2.2.1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.2.2.1.1.1.m1.1b"><ci id="S4.T1.4.2.2.2.1.1.1.m1.1.1.cmml" xref="S4.T1.4.2.2.2.1.1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.2.2.1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.2.2.2.1.1.1.m1.1d">italic_c</annotation></semantics></math></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T1.5.3.3.3" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.3.3.1">
<span class="ltx_p" id="S4.T1.5.3.3.3.1.1" style="width:65.4pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.3.3.3.1.1.1" style="font-size:90%;">Answer <math alttext="y" class="ltx_Math" display="inline" id="S4.T1.5.3.3.3.1.1.1.m1.1"><semantics id="S4.T1.5.3.3.3.1.1.1.m1.1a"><mi id="S4.T1.5.3.3.3.1.1.1.m1.1.1" xref="S4.T1.5.3.3.3.1.1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.T1.5.3.3.3.1.1.1.m1.1b"><ci id="S4.T1.5.3.3.3.1.1.1.m1.1.1.cmml" xref="S4.T1.5.3.3.3.1.1.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.3.3.3.1.1.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.3.3.3.1.1.1.m1.1d">italic_y</annotation></semantics></math></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T1.5.3.4.1" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.4.1.1">
<span class="ltx_p" id="S4.T1.5.3.4.1.1.1" style="width:105.3pt;"><span class="ltx_text" id="S4.T1.5.3.4.1.1.1.1" style="font-size:90%;">Context-rich QA</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.4.2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.4.2.1">
<span class="ltx_p" id="S4.T1.5.3.4.2.1.1" style="width:210.6pt;"><span class="ltx_text" id="S4.T1.5.3.4.2.1.1.1" style="font-size:90%;">Answer the following question from context. </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.4.2.1.1.2" style="font-size:90%;">{question}</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.4.3" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.4.3.1">
<span class="ltx_p" id="S4.T1.5.3.4.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S4.T1.5.3.4.3.1.1.1" style="font-size:90%;">Passage: </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.4.3.1.1.2" style="font-size:90%;">{Passage}</span><span class="ltx_text" id="S4.T1.5.3.4.3.1.1.3" style="font-size:90%;"> (1 Psg.)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.4.4" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.4.4.1">
<span class="ltx_p" id="S4.T1.5.3.4.4.1.1" style="width:65.4pt;"><span class="ltx_text" id="S4.T1.5.3.4.4.1.1.1" style="font-size:90%;">A phrase/sentence</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T1.5.3.5.1" rowspan="2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.5.1.1">
<span class="ltx_p" id="S4.T1.5.3.5.1.1.1" style="width:105.3pt;"><span class="ltx_text" id="S4.T1.5.3.5.1.1.1.1" style="font-size:90%;">Retrieval-augmented QA</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.5.2" rowspan="2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.5.2.1">
<span class="ltx_p" id="S4.T1.5.3.5.2.1.1" style="width:210.6pt;"><span class="ltx_text" id="S4.T1.5.3.5.2.1.1.1" style="font-size:90%;">Answer the following question from context. <span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.5.2.1.1.1.1">{question}</span></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.5.3" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.5.3.1">
<span class="ltx_p" id="S4.T1.5.3.5.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S4.T1.5.3.5.3.1.1.1" style="font-size:90%;">Passage 1: </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.5.3.1.1.2" style="font-size:90%;">{Passage 1}</span><span class="ltx_text" id="S4.T1.5.3.5.3.1.1.3" style="font-size:90%;">…</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.5.4" rowspan="2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.5.4.1">
<span class="ltx_p" id="S4.T1.5.3.5.4.1.1" style="width:65.4pt;"><span class="ltx_text" id="S4.T1.5.3.5.4.1.1.1" style="font-size:90%;">A phrase/sentence</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T1.5.3.6.1" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.6.1.1">
<span class="ltx_p" id="S4.T1.5.3.6.1.1.1" style="width:142.3pt;"><span class="ltx_text" id="S4.T1.5.3.6.1.1.1.1" style="font-size:90%;">Passage 5: </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.6.1.1.1.2" style="font-size:90%;">{Passage 5}</span><span class="ltx_text" id="S4.T1.5.3.6.1.1.1.3" style="font-size:90%;"> (5 Psg. total)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S4.T1.5.3.7.1" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.7.1.1">
<span class="ltx_p" id="S4.T1.5.3.7.1.1.1" style="width:105.3pt;"><span class="ltx_text" id="S4.T1.5.3.7.1.1.1.1" style="font-size:90%;">Context ranking</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.7.2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.7.2.1">
<span class="ltx_p" id="S4.T1.5.3.7.2.1.1" style="width:210.6pt;"><span class="ltx_text" id="S4.T1.5.3.7.2.1.1.1" style="font-size:90%;">For the question </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.7.2.1.1.2" style="font-size:90%;">{question}</span><span class="ltx_text" id="S4.T1.5.3.7.2.1.1.3" style="font-size:90%;">, access whether the passage is relevant to the question.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.7.3" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.7.3.1">
<span class="ltx_p" id="S4.T1.5.3.7.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S4.T1.5.3.7.3.1.1.1" style="font-size:90%;">Passage: <span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.7.3.1.1.1.1">{Passage}</span> (1 Psg.)</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.7.4" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.7.4.1">
<span class="ltx_p" id="S4.T1.5.3.7.4.1.1" style="width:65.4pt;"><span class="ltx_text" id="S4.T1.5.3.7.4.1.1.1" style="font-size:90%;">True/False</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="S4.T1.5.3.8.1" rowspan="2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.8.1.1">
<span class="ltx_p" id="S4.T1.5.3.8.1.1.1" style="width:105.3pt;"><span class="ltx_text" id="S4.T1.5.3.8.1.1.1.1" style="font-size:90%;">Retrieval-augmented ranking</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.8.2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.8.2.1">
<span class="ltx_p" id="S4.T1.5.3.8.2.1.1" style="width:210.6pt;"><span class="ltx_text" id="S4.T1.5.3.8.2.1.1.1" style="font-size:90%;">For the question </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.8.2.1.1.2" style="font-size:90%;">{question}</span><span class="ltx_text" id="S4.T1.5.3.8.2.1.1.3" style="font-size:90%;">, find all passages from</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.5.3.8.3" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.8.3.1">
<span class="ltx_p" id="S4.T1.5.3.8.3.1.1" style="width:142.3pt;"><span class="ltx_text" id="S4.T1.5.3.8.3.1.1.1" style="font-size:90%;">Passage 1: </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.8.3.1.1.2" style="font-size:90%;">{Passage 1}</span><span class="ltx_text" id="S4.T1.5.3.8.3.1.1.3" style="font-size:90%;">…</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T1.5.3.8.4" rowspan="2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.8.4.1">
<span class="ltx_p" id="S4.T1.5.3.8.4.1.1" style="width:65.4pt;"><span class="ltx_text" id="S4.T1.5.3.8.4.1.1.1" style="font-size:90%;">Passage Indexes</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.3.9">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T1.5.3.9.1" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.9.1.1">
<span class="ltx_p" id="S4.T1.5.3.9.1.1.1" style="width:210.6pt;"><span class="ltx_text" id="S4.T1.5.3.9.1.1.1.1" style="font-size:90%;">the context that are relevant to the question.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S4.T1.5.3.9.2" style="padding-top:-0.45pt;padding-bottom:-0.45pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.5.3.9.2.1">
<span class="ltx_p" id="S4.T1.5.3.9.2.1.1" style="width:142.3pt;"><span class="ltx_text" id="S4.T1.5.3.9.2.1.1.1" style="font-size:90%;">Passage 5: </span><span class="ltx_text ltx_font_typewriter" id="S4.T1.5.3.9.2.1.1.2" style="font-size:90%;">{Passage 5}</span><span class="ltx_text" id="S4.T1.5.3.9.2.1.1.3" style="font-size:90%;"> (5 Psg. total)</span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS2.p9">
<p class="ltx_p" id="S4.SS2.p9.4"><span class="ltx_text ltx_font_bold" id="S4.SS2.p9.4.1">Unifying RAG and ranking with instruction tuning.</span>
It is worth noting that, despite the variety of datasets and tasks described, they can all be cast into a standardized QA format <math alttext="(x,c,y)" class="ltx_Math" display="inline" id="S4.SS2.p9.1.m1.3"><semantics id="S4.SS2.p9.1.m1.3a"><mrow id="S4.SS2.p9.1.m1.3.4.2" xref="S4.SS2.p9.1.m1.3.4.1.cmml"><mo id="S4.SS2.p9.1.m1.3.4.2.1" stretchy="false" xref="S4.SS2.p9.1.m1.3.4.1.cmml">(</mo><mi id="S4.SS2.p9.1.m1.1.1" xref="S4.SS2.p9.1.m1.1.1.cmml">x</mi><mo id="S4.SS2.p9.1.m1.3.4.2.2" xref="S4.SS2.p9.1.m1.3.4.1.cmml">,</mo><mi id="S4.SS2.p9.1.m1.2.2" xref="S4.SS2.p9.1.m1.2.2.cmml">c</mi><mo id="S4.SS2.p9.1.m1.3.4.2.3" xref="S4.SS2.p9.1.m1.3.4.1.cmml">,</mo><mi id="S4.SS2.p9.1.m1.3.3" xref="S4.SS2.p9.1.m1.3.3.cmml">y</mi><mo id="S4.SS2.p9.1.m1.3.4.2.4" stretchy="false" xref="S4.SS2.p9.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p9.1.m1.3b"><vector id="S4.SS2.p9.1.m1.3.4.1.cmml" xref="S4.SS2.p9.1.m1.3.4.2"><ci id="S4.SS2.p9.1.m1.1.1.cmml" xref="S4.SS2.p9.1.m1.1.1">𝑥</ci><ci id="S4.SS2.p9.1.m1.2.2.cmml" xref="S4.SS2.p9.1.m1.2.2">𝑐</ci><ci id="S4.SS2.p9.1.m1.3.3.cmml" xref="S4.SS2.p9.1.m1.3.3">𝑦</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p9.1.m1.3c">(x,c,y)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p9.1.m1.3d">( italic_x , italic_c , italic_y )</annotation></semantics></math>, where <math alttext="x" class="ltx_Math" display="inline" id="S4.SS2.p9.2.m2.1"><semantics id="S4.SS2.p9.2.m2.1a"><mi id="S4.SS2.p9.2.m2.1.1" xref="S4.SS2.p9.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p9.2.m2.1b"><ci id="S4.SS2.p9.2.m2.1.1.cmml" xref="S4.SS2.p9.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p9.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p9.2.m2.1d">italic_x</annotation></semantics></math> is the question, <math alttext="c" class="ltx_Math" display="inline" id="S4.SS2.p9.3.m3.1"><semantics id="S4.SS2.p9.3.m3.1a"><mi id="S4.SS2.p9.3.m3.1.1" xref="S4.SS2.p9.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p9.3.m3.1b"><ci id="S4.SS2.p9.3.m3.1.1.cmml" xref="S4.SS2.p9.3.m3.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p9.3.m3.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p9.3.m3.1d">italic_c</annotation></semantics></math> is the corresponding context, and <math alttext="y" class="ltx_Math" display="inline" id="S4.SS2.p9.4.m4.1"><semantics id="S4.SS2.p9.4.m4.1a"><mi id="S4.SS2.p9.4.m4.1.1" xref="S4.SS2.p9.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p9.4.m4.1b"><ci id="S4.SS2.p9.4.m4.1.1.cmml" xref="S4.SS2.p9.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p9.4.m4.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p9.4.m4.1d">italic_y</annotation></semantics></math> is the target output answer.
For example, for the retrieval-augmented ranking data, the question is “<em class="ltx_emph ltx_font_italic" id="S4.SS2.p9.4.2">For the question &lt;question&gt;, find all the passages from the context that are relevant to the question</em>.”
Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4.T1" title="Table 1 ‣ 4.2 Stage-II: Unified Instruction-Tuning for Ranking and Generation ‣ 4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">1</span></a> exhibits how to cast different tasks into a unified format.
Despite its simplicity, this approach has the following advantages: <em class="ltx_emph ltx_font_italic" id="S4.SS2.p9.4.3">i</em>) It empowers the LLM with the ranking capability by adding relatively small amount of ranking data. <em class="ltx_emph ltx_font_italic" id="S4.SS2.p9.4.4">ii</em>) By standardizing these tasks into a unified format, they can <em class="ltx_emph ltx_font_italic" id="S4.SS2.p9.4.5">mutually enhance</em> each other. After that, we obtain the final RankRAG model that can be applied to various knowledge-intensive NLP tasks.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>RankRAG Inference: Retrieve-Rerank-Generate Pipeline</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.6">As RankRAG incorporates an additional reranking step, the inference pipeline for each question is modified as a <em class="ltx_emph ltx_font_italic" id="S4.SS3.p1.6.1">retrieve-rerank-generate</em> pipeline, described as follows:
(1) the retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">caligraphic_R</annotation></semantics></math> first retrieves top-<math alttext="N" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">italic_N</annotation></semantics></math> contexts from the corpus. (2) the RankRAG model calculates the relevance score between the question and retrieved <math alttext="N" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">italic_N</annotation></semantics></math> contexts as the probability of generating the answer as <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.6.2">True</span> using the prompt in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4.T1" title="Table 1 ‣ 4.2 Stage-II: Unified Instruction-Tuning for Ranking and Generation ‣ 4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>, then reranks contexts to only retain top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">italic_k</annotation></semantics></math> (<math alttext="k\ll N" class="ltx_Math" display="inline" id="S4.SS3.p1.5.m5.1"><semantics id="S4.SS3.p1.5.m5.1a"><mrow id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">k</mi><mo id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1.cmml">≪</mo><mi id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1">much-less-than</csymbol><ci id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2">𝑘</ci><ci id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">k\ll N</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.5.m5.1d">italic_k ≪ italic_N</annotation></semantics></math>) contexts, which are then used as the input for the generation step. (3) The top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS3.p1.6.m6.1"><semantics id="S4.SS3.p1.6.m6.1a"><mi id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><ci id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.6.m6.1d">italic_k</annotation></semantics></math> contexts, along with the question, are concatenated and fed back into the RankRAG model to generate the final answer.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.4"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.4.1">Efficiency Discussion.</span> We are aware that the addition of a reranking step introduces extra processing time. In practice, for each question, denote the time for indexing and retrieval as <math alttext="t_{1}" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">t</mi><mn id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">𝑡</ci><cn id="S4.SS3.p2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">t_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, the time for using LLM to calculate the relevance score as <math alttext="t_{2}" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><msub id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">t</mi><mn id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">𝑡</ci><cn id="S4.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">t_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> and the time for generation as <math alttext="t_{3}" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><msub id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">t</mi><mn id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">𝑡</ci><cn id="S4.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="S4.SS3.p2.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">t_{3}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math>, then the ratio of added time overhead is <math alttext="\frac{N*t_{2}}{t_{1}+t_{3}}" class="ltx_Math" display="inline" id="S4.SS3.p2.4.m4.1"><semantics id="S4.SS3.p2.4.m4.1a"><mfrac id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mrow id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2.2" xref="S4.SS3.p2.4.m4.1.1.2.2.cmml">N</mi><mo id="S4.SS3.p2.4.m4.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p2.4.m4.1.1.2.1.cmml">∗</mo><msub id="S4.SS3.p2.4.m4.1.1.2.3" xref="S4.SS3.p2.4.m4.1.1.2.3.cmml"><mi id="S4.SS3.p2.4.m4.1.1.2.3.2" xref="S4.SS3.p2.4.m4.1.1.2.3.2.cmml">t</mi><mn id="S4.SS3.p2.4.m4.1.1.2.3.3" xref="S4.SS3.p2.4.m4.1.1.2.3.3.cmml">2</mn></msub></mrow><mrow id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml"><msub id="S4.SS3.p2.4.m4.1.1.3.2" xref="S4.SS3.p2.4.m4.1.1.3.2.cmml"><mi id="S4.SS3.p2.4.m4.1.1.3.2.2" xref="S4.SS3.p2.4.m4.1.1.3.2.2.cmml">t</mi><mn id="S4.SS3.p2.4.m4.1.1.3.2.3" xref="S4.SS3.p2.4.m4.1.1.3.2.3.cmml">1</mn></msub><mo id="S4.SS3.p2.4.m4.1.1.3.1" xref="S4.SS3.p2.4.m4.1.1.3.1.cmml">+</mo><msub id="S4.SS3.p2.4.m4.1.1.3.3" xref="S4.SS3.p2.4.m4.1.1.3.3.cmml"><mi id="S4.SS3.p2.4.m4.1.1.3.3.2" xref="S4.SS3.p2.4.m4.1.1.3.3.2.cmml">t</mi><mn id="S4.SS3.p2.4.m4.1.1.3.3.3" xref="S4.SS3.p2.4.m4.1.1.3.3.3.cmml">3</mn></msub></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><divide id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"></divide><apply id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2"><times id="S4.SS3.p2.4.m4.1.1.2.1.cmml" xref="S4.SS3.p2.4.m4.1.1.2.1"></times><ci id="S4.SS3.p2.4.m4.1.1.2.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2.2">𝑁</ci><apply id="S4.SS3.p2.4.m4.1.1.2.3.cmml" xref="S4.SS3.p2.4.m4.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.2.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.2.3">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.2.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2.3.2">𝑡</ci><cn id="S4.SS3.p2.4.m4.1.1.2.3.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.1.1.2.3.3">2</cn></apply></apply><apply id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3"><plus id="S4.SS3.p2.4.m4.1.1.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3.1"></plus><apply id="S4.SS3.p2.4.m4.1.1.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.3.2.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.3.2.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.2.2">𝑡</ci><cn id="S4.SS3.p2.4.m4.1.1.3.2.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.1.1.3.2.3">1</cn></apply><apply id="S4.SS3.p2.4.m4.1.1.3.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.1.1.3.3.1.cmml" xref="S4.SS3.p2.4.m4.1.1.3.3">subscript</csymbol><ci id="S4.SS3.p2.4.m4.1.1.3.3.2.cmml" xref="S4.SS3.p2.4.m4.1.1.3.3.2">𝑡</ci><cn id="S4.SS3.p2.4.m4.1.1.3.3.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\frac{N*t_{2}}{t_{1}+t_{3}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.1d">divide start_ARG italic_N ∗ italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>. In practice, calculating relevance typically requires generating just one token and involves much shorter inputs compared to the generation step with top-<em class="ltx_emph ltx_font_italic" id="S4.SS3.p2.4.2">k</em> contexts. We provide efficiency study in §<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS5" title="5.5 A Closer Look at the Ranking Module ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">5.5</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we conduct comprehensive experiments on a variety of knowledge-intensive NLP tasks to demonstrate the zero-shot capabilities of RankRAG.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experiment Setup</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Tasks and Datasets.</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">We consider 3 types of tasks in experiments: (1) <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS1.SSS0.Px1.p1.1.1"><em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.1.1.1">Open-domain QA</em> (OpenQA)</span>, which includes NQ <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib42" title="">2019</a>)</cite>, TriviaQA <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib34" title="">2017</a>)</cite>, PopQA <cite class="ltx_cite ltx_citemacro_citep">(Mallen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib55" title="">2023</a>)</cite>, HotpotQA <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib93" title="">2018</a>)</cite> and 2WikimQA <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib22" title="">2020</a>)</cite>. The first three are single-hop QA tasks, while the last two are multi-hop QA datasets.
For NQ, TriviaQA, and HotpotQA, we use the split from KILT benchmark <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib67" title="">2021</a>)</cite>
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The results of NQ and TriviaQA using the split from DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>)</cite> are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A6" title="Appendix F Performance of NQ and Trivia QA on DPR Splits ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">F</span></a>.</span></span></span>.
(2) <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS1.SSS0.Px1.p1.1.2"><em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.1.2.1">Fact verification</em></span>, where we use FEVER <cite class="ltx_cite ltx_citemacro_citep">(Thorne et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib77" title="">2018</a>)</cite> from KILT benchmark.
(3) <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS1.SSS0.Px1.p1.1.3"><em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p1.1.3.1">Conversational QA</em> (ConvQA)</span>, we consider three datasets including Doc2Dial <cite class="ltx_cite ltx_citemacro_citep">(Feng et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib18" title="">2020</a>)</cite>, TopiOCQA <cite class="ltx_cite ltx_citemacro_citep">(Adlakha et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib1" title="">2022</a>)</cite> and INSCIT <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib89" title="">2023</a>)</cite>, which have long documents that cannot be fitted directly into LLMs thus necessitates retrieval and ranking. The detailed dataset information is in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A1.SS1" title="A.1 Main Experiments ‣ Appendix A Dataset Description ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p2.1.1">Baselines.</span> We consider the following baselines: (1) <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS1.SSS0.Px1.p2.1.2"><em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p2.1.2.1">Baseline LLMs without RAG</em></span>, where we consider LLMs trained with proprietary data including InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib65" title="">2022</a>)</cite>, PaLM 2 <cite class="ltx_cite ltx_citemacro_citep">(Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib2" title="">2023</a>)</cite>, FLAN-LaMDA <cite class="ltx_cite ltx_citemacro_citep">(Longpre et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib51" title="">2023</a>)</cite>, GLaM <cite class="ltx_cite ltx_citemacro_citep">(Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib15" title="">2022</a>)</cite>,
Claude 2 <cite class="ltx_cite ltx_citemacro_citep">(Anthropic, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib3" title="">2023</a>)</cite>, Mixtral-8x22B-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Mistral, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib58" title="">2024</a>)</cite>, DeepSeek-V2 Chat <cite class="ltx_cite ltx_citemacro_citep">(DeepSeek, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib14" title="">2024</a>)</cite> and only use the official reported results.
We also consider two ChatGPT-series models, namely GPT-3.5-turbo (<span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS0.Px1.p2.1.3">gpt-3.5-turbo-0613</span>) <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib62" title="">2022</a>)</cite> and GPT-4 (<span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS0.Px1.p2.1.4">gpt-4-0613</span>) <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">2023</a>)</cite>.
(2) <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.SS1.SSS0.Px1.p2.1.5"><em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p2.1.5.1">Baselines with retrieval</em></span>, we evaluate models augmented with retrieval. Specifically, we include Atlas <cite class="ltx_cite ltx_citemacro_citep">(Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib27" title="">2023</a>)</cite> and Raven <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib24" title="">2023</a>)</cite>, two RAG models based on encoder-decoder LMs. For decoder-only models, we consider Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">2024a</a>)</cite>, RECOMP <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib91" title="">2024a</a>)</cite>, InstructRetro <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">2024</a>)</cite>, RePlug <cite class="ltx_cite ltx_citemacro_citep">(Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib74" title="">2024</a>)</cite>, RA-DIT <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>)</cite>, Llama-3-instruct <cite class="ltx_cite ltx_citemacro_citep">(Meta-AI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib57" title="">2024</a>)</cite> and ChatQA-1.5 <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite>.
We also list the result of RAG pipelines using InstructGPT (175B parameters) as the backbone including GenRead <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib95" title="">2023a</a>)</cite>, Retrieve-read <cite class="ltx_cite ltx_citemacro_citep">(Lazaridou et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib44" title="">2022</a>)</cite> and ReFeed <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib97" title="">2024</a>)</cite>, but mainly for reference.
Other reported numbers are directly comparable if they follow the standard zero-shot settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p3.1.1">Evaluation Metrics.</span>
For OpenQA datasets, we use <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p3.1.2">Exact Match (EM)</em> as the main metric but also report Accuracy for TriviaQA and PopQA and F1 score for HotpotQA and 2WikimQA as it is used in several studies <cite class="ltx_cite ltx_citemacro_citep">(Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">2024a</a>; Mallen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib55" title="">2023</a>)</cite>.
For FEVER, we use accuracy as the metric.
For ConvQA datasets, we follow <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">2024</a>)</cite> to use F1 score as the metric.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p4">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p4.8"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p4.8.1">Implementation Details.</span>
We use Llama3 8B and 70B <cite class="ltx_cite ltx_citemacro_citep">(Meta-AI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib57" title="">2024</a>)</cite> as the backbone in our main experiments. For the two-stage instruction tuning, we set the batch size to 128 and train the model for 1000 steps with learning rate 5e-6 in Stage-I. Then, we reduce the learning rate to 3e-7 for 8B and 2e-7 for 70B model, set the batch size to 64, and train the model for 3300 steps (around 1 epoch).
We use the Adam optimizer <cite class="ltx_cite ltx_citemacro_citep">(Kingma &amp; Ba, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib40" title="">2014</a>)</cite> with <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.1.m1.1"><semantics id="S5.SS1.SSS0.Px1.p4.1.m1.1a"><mrow id="S5.SS1.SSS0.Px1.p4.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.cmml"><msub id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.cmml"><mi id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.2" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.2.cmml">β</mi><mn id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.3" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.1" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.3" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.1.m1.1b"><apply id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1"><eq id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.1"></eq><apply id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.2">𝛽</ci><cn id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.3.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.2.3">1</cn></apply><cn id="S5.SS1.SSS0.Px1.p4.1.m1.1.1.3.cmml" type="float" xref="S5.SS1.SSS0.Px1.p4.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.1.m1.1c">\beta_{1}=0.9</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.1.m1.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9</annotation></semantics></math> and <math alttext="\beta_{2}=0.98" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.2.m2.1"><semantics id="S5.SS1.SSS0.Px1.p4.2.m2.1a"><mrow id="S5.SS1.SSS0.Px1.p4.2.m2.1.1" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.cmml"><msub id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.cmml"><mi id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.2" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.2.cmml">β</mi><mn id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.3" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.1" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.3" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.3.cmml">0.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.2.m2.1b"><apply id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1"><eq id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.1"></eq><apply id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.2">𝛽</ci><cn id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.3.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.2.3">2</cn></apply><cn id="S5.SS1.SSS0.Px1.p4.2.m2.1.1.3.cmml" type="float" xref="S5.SS1.SSS0.Px1.p4.2.m2.1.1.3">0.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.2.m2.1c">\beta_{2}=0.98</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.2.m2.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.98</annotation></semantics></math>.
During the inference stage, we use the December 2018 Wikidump as the corpus index for NQ, TQA, HotpotQA, 2WikimQA, and use the December 2020 Wikidump for PopQA, following <cite class="ltx_cite ltx_citemacro_citep">(Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">2024a</a>)</cite>.
By default, we follow <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">2024</a>; Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">2024</a>)</cite> to use the Dragon retriever <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib48" title="">2023</a>)</cite> as default and retrieve top-<math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.3.m3.1"><semantics id="S5.SS1.SSS0.Px1.p4.3.m3.1a"><mi id="S5.SS1.SSS0.Px1.p4.3.m3.1.1" xref="S5.SS1.SSS0.Px1.p4.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.3.m3.1b"><ci id="S5.SS1.SSS0.Px1.p4.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.3.m3.1d">italic_N</annotation></semantics></math> (<math alttext="100" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.4.m4.1"><semantics id="S5.SS1.SSS0.Px1.p4.4.m4.1a"><mn id="S5.SS1.SSS0.Px1.p4.4.m4.1.1" xref="S5.SS1.SSS0.Px1.p4.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.4.m4.1b"><cn id="S5.SS1.SSS0.Px1.p4.4.m4.1.1.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.4.m4.1c">100</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.4.m4.1d">100</annotation></semantics></math> for 8B and <math alttext="30" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.5.m5.1"><semantics id="S5.SS1.SSS0.Px1.p4.5.m5.1a"><mn id="S5.SS1.SSS0.Px1.p4.5.m5.1.1" xref="S5.SS1.SSS0.Px1.p4.5.m5.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.5.m5.1b"><cn id="S5.SS1.SSS0.Px1.p4.5.m5.1.1.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.5.m5.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.5.m5.1c">30</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.5.m5.1d">30</annotation></semantics></math> for 70B) documents for ranking, but RankRAG can be adapted to various retrievers and different <math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.6.m6.1"><semantics id="S5.SS1.SSS0.Px1.p4.6.m6.1a"><mi id="S5.SS1.SSS0.Px1.p4.6.m6.1.1" xref="S5.SS1.SSS0.Px1.p4.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.6.m6.1b"><ci id="S5.SS1.SSS0.Px1.p4.6.m6.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.6.m6.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.6.m6.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.6.m6.1d">italic_N</annotation></semantics></math> (see § <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS3" title="5.3 Ablation Studies ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">5.3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.SS5" title="5.5 A Closer Look at the Ranking Module ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">5.5</span></a>). To ensure a fair comparison, we test the performance of <math alttext="k\in\{5,10,20\}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.7.m7.3"><semantics id="S5.SS1.SSS0.Px1.p4.7.m7.3a"><mrow id="S5.SS1.SSS0.Px1.p4.7.m7.3.4" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.cmml"><mi id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.2" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.2.cmml">k</mi><mo id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.1" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.1.cmml">∈</mo><mrow id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.2" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.1.cmml"><mo id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.2.1" stretchy="false" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.1.cmml">{</mo><mn id="S5.SS1.SSS0.Px1.p4.7.m7.1.1" xref="S5.SS1.SSS0.Px1.p4.7.m7.1.1.cmml">5</mn><mo id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.2.2" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p4.7.m7.2.2" xref="S5.SS1.SSS0.Px1.p4.7.m7.2.2.cmml">10</mn><mo id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.2.3" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p4.7.m7.3.3" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.3.cmml">20</mn><mo id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.2.4" stretchy="false" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.7.m7.3b"><apply id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.cmml" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4"><in id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.1.cmml" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.1"></in><ci id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.2.cmml" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.2">𝑘</ci><set id="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.1.cmml" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.4.3.2"><cn id="S5.SS1.SSS0.Px1.p4.7.m7.1.1.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.7.m7.1.1">5</cn><cn id="S5.SS1.SSS0.Px1.p4.7.m7.2.2.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.7.m7.2.2">10</cn><cn id="S5.SS1.SSS0.Px1.p4.7.m7.3.3.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.7.m7.3.3">20</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.7.m7.3c">k\in\{5,10,20\}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.7.m7.3d">italic_k ∈ { 5 , 10 , 20 }</annotation></semantics></math> and report <em class="ltx_emph ltx_font_italic" id="S5.SS1.SSS0.Px1.p4.8.2">the best performance</em> for baselines.
For generation, we keep temperature <math alttext="T=0" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p4.8.m8.1"><semantics id="S5.SS1.SSS0.Px1.p4.8.m8.1a"><mrow id="S5.SS1.SSS0.Px1.p4.8.m8.1.1" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.2" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.2.cmml">T</mi><mo id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.1" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.3" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p4.8.m8.1b"><apply id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1"><eq id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.1"></eq><ci id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.2">𝑇</ci><cn id="S5.SS1.SSS0.Px1.p4.8.m8.1.1.3.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p4.8.m8.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p4.8.m8.1c">T=0</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p4.8.m8.1d">italic_T = 0</annotation></semantics></math> and set the maximum number of generated token to be 32 for OpenQA, 128 for ConvQA and 8 for others.
Training RankRAG-8B uses 32 NVIDIA A100 GPUs for 10 hours (4 hours for Stage-I and 6 hours for Stage-II finetuning), while training RankRAG-70B uses 128 NVIDIA A100 GPUs for 16 hours (4 hours for Stage-I and 12 hours for Stage-II Finetuning).</p>
</div>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p5">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p5.1.1">Data Contamination Issues.</span>
One possible issue for the zero-shot evaluation is the test set contamination, where some of the task-specific examples overlap with the instruction fine-tuning data <cite class="ltx_cite ltx_citemacro_citep">(Oren et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib64" title="">2024</a>)</cite>. To address this issue, we have performed a string match-based analysis where we do not observe any overlap between the train data and data from target tasks.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of RankRAG and baselines on 9 datasets.
Unless specified, all results are under <em class="ltx_emph ltx_font_bold ltx_font_italic" id="S5.T2.13.1">zero-shot</em> evaluation without additional demonstrations.
Results unavailable in public reports are marked as “–”.
We use NQ, TriviaQA, and HotpotQA from the KILT benchmark for Llama3-Instruct, Llama3-ChatQA-1.5, and Llama3-RankRAG.
Note that<sup class="ltx_sup" id="S5.T2.14.2">†</sup>: GPT-4 and GPT-4-turbo may refuse to answer the question when retrieved passages do not contain relevant information, thus the EM / accuracy drops after including RAG on TriviaQA, HotpotQA and 2WikimQA.

</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.5" style="width:433.6pt;height:368.3pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-165.7pt,140.5pt) scale(0.566787764611348,0.566787764611348) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.5.3">
<tr class="ltx_tr" id="S5.T2.5.3.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T2.5.3.4.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.1.1" style="font-size:90%;">Task (<em class="ltx_emph ltx_font_italic" id="S5.T2.5.3.4.1.1.1" style="color:#0000FF;">Zero-shot</em>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.2.1" style="font-size:90%;">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.3.1" style="font-size:90%;">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.4.1" style="font-size:90%;">PopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.5.1" style="font-size:90%;">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.6.1" style="font-size:90%;">2WikimQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.7.1" style="font-size:90%;">FEVER</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.8.1" style="font-size:90%;">Doc2Dial</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.9.1" style="font-size:90%;">TopiOCQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.10.1" style="font-size:90%;">Inscit</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.3.4.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.4.11.1" style="font-size:90%;">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.5.3.5.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.5.1.1" style="font-size:90%;">Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.2.1" style="font-size:90%;">EM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.3.1" style="font-size:90%;">EM / Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.4.1" style="font-size:90%;">EM / Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.5.1" style="font-size:90%;">EM / F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.6.1" style="font-size:90%;">EM / F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.7.1" style="font-size:90%;">Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.8.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.9.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.10.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.5.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.5.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.6">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" id="S5.T2.5.3.6.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_italic" id="S5.T2.5.3.6.1.1" style="font-size:90%;color:#000000;">Without Retrieval-Augmented Generation</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.6.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.6.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.6.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.6.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.6.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.5.3.7.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.7.1.1" style="font-size:90%;">InstructGPT (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib65" title="">Ouyang et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.7.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.2.1" style="font-size:90%;">29.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.3.1" style="font-size:90%;">65.8 / 73.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.5.1" style="font-size:90%;">26.0 / 38.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.6.1" style="font-size:90%;">27.2 / 34.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.7.1" style="font-size:90%;">77.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.7.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.7.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.8.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.8.1.1" style="font-size:90%;">PaLM2 540B (0 shot, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib2" title="">Anil et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.8.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.2.1" style="font-size:90%;">21.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.3.1" style="font-size:90%;">76.9 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.8.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.8.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.9.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.9.1.1" style="font-size:90%;">PaLM2 540B (</span><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.9.1.2" style="font-size:90%;">5 shot</span><span class="ltx_text" id="S5.T2.5.3.9.1.3" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib2" title="">Anil et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.9.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.2.1" style="font-size:90%;">37.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.3.1" style="font-size:90%;">86.1 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.9.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.9.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.10.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.10.1.1" style="font-size:90%;">GLaM 64B  (</span><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.10.1.2" style="font-size:90%;">0 shot</span><span class="ltx_text" id="S5.T2.5.3.10.1.3" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib15" title="">Du et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.10.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.2.1" style="font-size:90%;">37.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.3.1" style="font-size:90%;">71.3 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.10.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.10.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.11.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.11.1.1" style="font-size:90%;">FLAN-LaMDA 137B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib87" title="">Wei et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.11.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.2.1" style="font-size:90%;">20.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.3.1" style="font-size:90%;">68.1 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.11.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.11.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.12.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.12.1.1" style="font-size:90%;">Claude 2 (</span><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.12.1.2" style="font-size:90%;">5 shot</span><span class="ltx_text" id="S5.T2.5.3.12.1.3" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib3" title="">Anthropic</a></cite><span class="ltx_text" id="S5.T2.5.3.12.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.2.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.5.3.12.3.1" style="font-size:90%;">87.5</span><span class="ltx_text" id="S5.T2.5.3.12.3.2" style="font-size:90%;"> / –</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.12.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.12.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.13.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.13.1.1" style="font-size:90%;">Mixtral-8x22B-Instruct (</span><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.13.1.2" style="font-size:90%;">5 shot</span><span class="ltx_text" id="S5.T2.5.3.13.1.3" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib58" title="">Mistral</a></cite><span class="ltx_text" id="S5.T2.5.3.13.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.2.1" style="font-size:90%;">40.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.3.1" style="font-size:90%;">82.2 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.13.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.13.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.14.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.14.1.1" style="font-size:90%;">DeepSeek-V2 236B (</span><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.14.1.2" style="font-size:90%;">5 shot</span><span class="ltx_text" id="S5.T2.5.3.14.1.3" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib14" title="">DeepSeek</a></cite><span class="ltx_text" id="S5.T2.5.3.14.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.2.1" style="font-size:90%;">53.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.3.1" style="font-size:90%;">86.7 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.14.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.14.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.15.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.15.1.1" style="font-size:90%;">GPT-3.5-turbo-1106 (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib62" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T2.5.3.15.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.2.1" style="font-size:90%;">38.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.3.1" style="font-size:90%;">82.9 / 91.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.4.1" style="font-size:90%;">28.4 / 32.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.5.1" style="font-size:90%;">29.9 / 42.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.6.1" style="font-size:90%;">23.9 / 30.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.7.1" style="font-size:90%;">82.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.8.1" style="font-size:90%;">20.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.9.1" style="font-size:90%;">28.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.10.1" style="font-size:90%;">27.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.15.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.15.11.1" style="font-size:90%;">38.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.16.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.16.1.1" style="font-size:90%;">GPT-4-0613 (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T2.5.3.16.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.2.1" style="font-size:90%;">40.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.16.3.1" style="font-size:90%;">84.8 / </span><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.16.3.2" style="font-size:90%;">94.5</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.4.1" style="font-size:90%;">31.3 / 34.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.5.1" style="font-size:90%;">34.5 / 46.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.6.1" style="font-size:90%;">29.8 / 36.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.7.1" style="font-size:90%;">87.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.8.1" style="font-size:90%;">27.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.9.1" style="font-size:90%;">30.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.10.1" style="font-size:90%;">27.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.16.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.16.11.1" style="font-size:90%;">42.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.17.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.17.1.1" style="font-size:90%;">GPT-4-turbo-2024-0409 (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T2.5.3.17.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.2.1" style="font-size:90%;">41.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.3.1" style="font-size:90%;">80.0 / 94.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.4.1" style="font-size:90%;">25.0 / 33.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.5.1" style="font-size:90%;">26.6 / 43.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.6.1" style="font-size:90%;">24.1 / 35.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.7.1" style="font-size:90%;">87.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.8.1" style="font-size:90%;">27.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.9.1" style="font-size:90%;">26.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.10.1" style="font-size:90%;">24.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.17.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.17.11.1" style="font-size:90%;">38.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.18">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" id="S5.T2.5.3.18.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_italic" id="S5.T2.5.3.18.1.1" style="font-size:90%;color:#000000;">With Retrieval-Augmented Generation</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.18.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.18.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.18.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.18.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.5.3.18.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.19">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.5.3.19.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.19.1.1" style="font-size:90%;">Atlas 11B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib27" title="">Izacard et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.19.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.2.1" style="font-size:90%;">26.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.3.1" style="font-size:90%;">56.9 / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.5.1" style="font-size:90%;">34.7 / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.7.1" style="font-size:90%;">77.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.19.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.19.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.20">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.20.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.20.1.1" style="font-size:90%;">Raven 11B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib24" title="">Huang et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.20.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.2.1" style="font-size:90%;">29.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.3.1" style="font-size:90%;">65.7 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.20.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.20.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.21.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.21.1.1" style="font-size:90%;">Self-RAG 7B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">Asai et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.21.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.2.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.3.1" style="font-size:90%;">– / 66.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.4.1" style="font-size:90%;">– / 54.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.21.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.21.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.22">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.22.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.22.1.1" style="font-size:90%;">Self-RAG 13B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">Asai et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.22.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.2.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.3.1" style="font-size:90%;">– / 69.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.4.1" style="font-size:90%;">– / 55.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.22.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.22.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.23">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.23.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.23.1.1" style="font-size:90%;">RECOMP 20B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib91" title="">Xu et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.23.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.2.1" style="font-size:90%;">37.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.3.1" style="font-size:90%;">59.0 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.5.1" style="font-size:90%;">30.4 / 40.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.23.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.23.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.24">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.24.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.24.1.1" style="font-size:90%;">InstructRetro 43B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib82" title="">Wang et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.24.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.2.1" style="font-size:90%;">38.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.3.1" style="font-size:90%;">78.3 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.4.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.8.1" style="font-size:90%;">36.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.24.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.24.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.25">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.25.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.25.1.1" style="font-size:90%;">RePlug 65B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib74" title="">Shi et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.25.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.2.1" style="font-size:90%;">28.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.3.1" style="font-size:90%;">72.6 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.5.1" style="font-size:90%;">32.0 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.7.1" style="font-size:90%;">73.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.25.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.25.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.26">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.26.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.26.1.1" style="font-size:90%;">RA-DIT 65B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">Lin et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.26.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.2.1" style="font-size:90%;">35.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.3.1" style="font-size:90%;">75.4 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.5.1" style="font-size:90%;">39.7 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.7.1" style="font-size:90%;">80.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.26.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.26.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.27">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.27.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.27.1.1" style="font-size:90%;">Llama3-Instruct 8B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib57" title="">Meta-AI</a></cite><span class="ltx_text" id="S5.T2.5.3.27.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.2.1" style="font-size:90%;">30.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.3.1" style="font-size:90%;">70.7 / 80.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.4.1" style="font-size:90%;">34.9 / 55.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.5.1" style="font-size:90%;">26.0 / 35.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.6.1" style="font-size:90%;">9.6 / 25.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.7.1" style="font-size:90%;">88.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.8.1" style="font-size:90%;">33.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.9.1" style="font-size:90%;">44.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.10.1" style="font-size:90%;">32.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.27.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.27.11.1" style="font-size:90%;">40.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.28">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.28.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.28.1.1" style="font-size:90%;">Llama3-Instruct 70B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib57" title="">Meta-AI</a></cite><span class="ltx_text" id="S5.T2.5.3.28.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.2.1" style="font-size:90%;">42.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.3.1" style="font-size:90%;">82.4 / 89.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.4.1" style="font-size:90%;">45.3 / 56.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.5.1" style="font-size:90%;">35.5 / 43.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.6.1" style="font-size:90%;">13.5 / 27.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.7.1" style="font-size:90%;">91.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.8.1" style="font-size:90%;">37.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.9.1" style="font-size:90%;">49.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.28.10.1" style="font-size:90%;">36.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.28.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.28.11.1" style="font-size:90%;">47.1</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.29">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.29.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.29.1.1" style="font-size:90%;">Llama3-ChatQA-1.5 8B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.29.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.2.1" style="font-size:90%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.3.1" style="font-size:90%;">81.0 / 87.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.4.1" style="font-size:90%;">52.6 / 59.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.5.1" style="font-size:90%;">33.4 / 44.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.6.1" style="font-size:90%;">26.8 / 31.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.7.1" style="font-size:90%;">90.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.8.1" style="font-size:90%;">39.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.9.1" style="font-size:90%;">49.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.10.1" style="font-size:90%;">30.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.29.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.29.11.1" style="font-size:90%;">49.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.30">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.30.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.30.1.1" style="font-size:90%;">Llama3-ChatQA-1.5 70B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.30.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.30.2.1" style="font-size:90%;">47.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.3.1" style="font-size:90%;">85.6</span><span class="ltx_text" id="S5.T2.5.3.30.3.2" style="font-size:90%;"> / </span><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.3.3" style="font-size:90%;">91.4</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.30.4.1" style="font-size:90%;">50.9 / 58.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.5.1" style="font-size:90%;">42.2</span><span class="ltx_text" id="S5.T2.5.3.30.5.2" style="font-size:90%;"> / </span><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.5.3" style="font-size:90%;">54.4</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.6.1" style="font-size:90%;">34.9</span><span class="ltx_text" id="S5.T2.5.3.30.6.2" style="font-size:90%;"> / </span><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.6.3" style="font-size:90%;">37.4</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.7.1" style="font-size:90%;">92.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.8.1" style="font-size:90%;">41.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.30.9.1" style="font-size:90%;">55.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.30.10.1" style="font-size:90%;">32.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.30.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.30.11.1" style="font-size:90%;">53.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.31" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.5.3.31.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.1.1" style="font-size:90%;background-color:#E0F3EB;">Llama3-RankRAG 8B (<span class="ltx_text ltx_font_bold" id="S5.T2.5.3.31.1.1.1">0 shot</span>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.31.2.1" style="font-size:90%;background-color:#E0F3EB;">50.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.3.1" style="font-size:90%;background-color:#E0F3EB;">82.9 / 89.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.31.4.1" style="font-size:90%;background-color:#E0F3EB;">57.6</span><span class="ltx_text" id="S5.T2.5.3.31.4.2" style="font-size:90%;background-color:#E0F3EB;"> / <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.31.4.2.1">64.1</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.5.1" style="font-size:90%;background-color:#E0F3EB;">35.3 / 46.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.6.1" style="font-size:90%;background-color:#E0F3EB;">31.4 / 36.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.7.1" style="font-size:90%;background-color:#E0F3EB;">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.8.1" style="font-size:90%;background-color:#E0F3EB;">40.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.9.1" style="font-size:90%;background-color:#E0F3EB;">50.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.10.1" style="font-size:90%;background-color:#E0F3EB;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.31.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.31.11.1" style="font-size:90%;background-color:#E0F3EB;">52.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.32" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.32.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.32.1.1" style="font-size:90%;background-color:#E0F3EB;">Llama3-RankRAG 70B (<span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.1.1.1">0 shot</span>)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.2.1" style="font-size:90%;background-color:#E0F3EB;">54.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.3.1" style="font-size:90%;background-color:#E0F3EB;">86.5<span class="ltx_text ltx_font_medium" id="S5.T2.5.3.32.3.1.1"> / </span>92.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.4.1" style="font-size:90%;background-color:#E0F3EB;">59.9<span class="ltx_text ltx_font_medium" id="S5.T2.5.3.32.4.1.1"> / </span>65.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.5.1" style="font-size:90%;background-color:#E0F3EB;">42.7<span class="ltx_text ltx_font_medium" id="S5.T2.5.3.32.5.1.1"> / </span>55.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.6.1" style="font-size:90%;background-color:#E0F3EB;">38.2<span class="ltx_text ltx_font_medium" id="S5.T2.5.3.32.6.1.1"> / </span>43.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.7.1" style="font-size:90%;background-color:#E0F3EB;">93.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.8.1" style="font-size:90%;background-color:#E0F3EB;">41.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.32.9.1" style="font-size:90%;background-color:#E0F3EB;">52.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.5.3.32.10.1" style="font-size:90%;background-color:#E0F3EB;">35.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.32.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.5.3.32.11.1" style="font-size:90%;background-color:#E0F3EB;">56.1</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="10" id="S5.T2.3.1.1.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_font_bold" id="S5.T2.3.1.1.1.2" style="font-size:90%;">For reference</span><span class="ltx_text" id="S5.T2.3.1.1.1.3" style="font-size:90%;">: </span><em class="ltx_emph ltx_font_italic" id="S5.T2.3.1.1.1.1" style="font-size:90%;">Using InstructGPT or CodeX (<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T2.3.1.1.1.1.m1.1"><semantics id="S5.T2.3.1.1.1.1.m1.1a"><mo id="S5.T2.3.1.1.1.1.m1.1.1" xref="S5.T2.3.1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T2.3.1.1.1.1.m1.1.1.cmml" xref="S5.T2.3.1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.1.1.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.1.1.1.1.m1.1d">∼</annotation></semantics></math>175B) <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib65" title="">2022</a>)</cite> as the Backbone LLM.</em>
</td>
<td class="ltx_td ltx_border_t" id="S5.T2.3.1.1.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.33">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.5.3.33.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.33.1.1" style="font-size:90%;">GenRead (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib95" title="">Yu et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.33.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.2.1" style="font-size:90%;">32.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.3.1" style="font-size:90%;">66.2 / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.4.1" style="font-size:90%;">46.0 / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.5.1" style="font-size:90%;">36.4 / 39.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.7.1" style="font-size:90%;">80.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.5.3.33.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.33.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.34">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.34.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.34.1.1" style="font-size:90%;">Retrieve-Read (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib44" title="">Lazaridou et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.34.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.2.1" style="font-size:90%;">31.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.3.1" style="font-size:90%;">61.4 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.5.1" style="font-size:90%;">35.2 / 38.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.6.1" style="font-size:90%;">27.7 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.7.1" style="font-size:90%;">82.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.34.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.34.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.35">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.35.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.35.1.1" style="font-size:90%;">ReFeed (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib97" title="">Yu et al.</a></cite><span class="ltx_text" id="S5.T2.5.3.35.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.2.1" style="font-size:90%;">39.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.3.1" style="font-size:90%;">68.9 / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.5.1" style="font-size:90%;">41.5 / 45.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.35.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.35.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.36">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.5.3.36.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.36.1.1" style="font-size:90%;">GPT-3.5-turbo-1106 RAG (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib62" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T2.5.3.36.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.2.1" style="font-size:90%;">46.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.3.1" style="font-size:90%;">79.7 / 88.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.4.1" style="font-size:90%;">49.9 / 57.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.5.1" style="font-size:90%;">31.2 / 41.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.6.1" style="font-size:90%;">27.2 / 32.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.7.1" style="font-size:90%;">90.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.8.1" style="font-size:90%;">34.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.9.1" style="font-size:90%;">44.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.10.1" style="font-size:90%;">35.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.5.3.36.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.36.11.1" style="font-size:90%;">46.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.4.2.2.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.4.2.2.1.1" style="font-size:90%;">GPT-4-0613 RAG</span><sup class="ltx_sup" id="S5.T2.4.2.2.1.2"><span class="ltx_text" id="S5.T2.4.2.2.1.2.1" style="font-size:90%;">†</span></sup><span class="ltx_text" id="S5.T2.4.2.2.1.3" style="font-size:90%;"> (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T2.4.2.2.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.2.1" style="font-size:90%;">40.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.3.1" style="font-size:90%;">75.0 / 88.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.4.1" style="font-size:90%;">44.3 / 61.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.5.1" style="font-size:90%;">27.6 / 38.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.6.1" style="font-size:90%;">14.4 / 17.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.7.1" style="font-size:90%;">92.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.8.1" style="font-size:90%;">34.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.9.1" style="font-size:90%;">45.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.10.1" style="font-size:90%;">36.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.2.2.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.4.2.2.11.1" style="font-size:90%;">43.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.5.3.3">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T2.5.3.3.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T2.5.3.3.1.1" style="font-size:90%;">GPT-4-turbo-2024-0409 RAG</span><sup class="ltx_sup" id="S5.T2.5.3.3.1.2"><span class="ltx_text" id="S5.T2.5.3.3.1.2.1" style="font-size:90%;">†</span></sup><span class="ltx_text" id="S5.T2.5.3.3.1.3" style="font-size:90%;"> (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T2.5.3.3.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.2.1" style="font-size:90%;">40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.3.1" style="font-size:90%;">70.2 / 91.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.4.1" style="font-size:90%;">39.5 / 58.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.5.1" style="font-size:90%;">8.1 / 17.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.6.1" style="font-size:90%;">22.8 / 39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.7.1" style="font-size:90%;">92.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.8.1" style="font-size:90%;">35.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.9.1" style="font-size:90%;">48.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.10.1" style="font-size:90%;">33.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.5.3.3.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T2.5.3.3.11.1" style="font-size:90%;">41.6</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Main Experiments</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.T2" title="Table 2 ‣ Tasks and Datasets. ‣ 5.1 Experiment Setup ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a> presents results of RankRAG and baselines.
The findings are summarized as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.3"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.3.1">RankRAG outperforms existing RAG methods.</span>
With 8B scale, RankRAG consistently outperforms ChatQA-1.5 8B, one of the most recent open-sourced model with state-of-the-art performance on many RAG benchmarks.
RankRAG 8B is also competitive when compared with baseline models with much more parameters. For example, it significantly outperforms InstructRetro (<math alttext="5\times" class="ltx_math_unparsed" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mrow id="S5.SS2.p2.1.m1.1b"><mn id="S5.SS2.p2.1.m1.1.1">5</mn><mo id="S5.SS2.p2.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">5\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">5 ×</annotation></semantics></math> parameters), RA-DIT 65B (<math alttext="8\times" class="ltx_math_unparsed" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1b"><mn id="S5.SS2.p2.2.m2.1.1">8</mn><mo id="S5.SS2.p2.2.m2.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">8\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">8 ×</annotation></semantics></math> paramters), and even outperforms Llama3-instruct 70B (<math alttext="8\times" class="ltx_math_unparsed" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mrow id="S5.SS2.p2.3.m3.1b"><mn id="S5.SS2.p2.3.m3.1.1">8</mn><mo id="S5.SS2.p2.3.m3.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">8\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">8 ×</annotation></semantics></math> parameters) on NQ and TriviaQA tasks.
With more parameters, RankRAG 70B outperforms the strong ChatQA-1.5 70B model, and largely outperforms previous RAG baselines with InstructGPT as the underlying LLM.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">RankRAG demonstrates larger improvement on more challenging datasets.</span> We observe that the performance gains of RankRAG over baselines are more pronounced for more challenging QA datasets. For example, on long-tailed QA (PopQA) and multi-hop QA (2WikimQA) tasks, we achieve more than 10% improvement over ChatQA-1.5.
These findings suggest that in challenging OpenQA datasets where top documents from retrievers are less relevant to the answer, context ranking effectively enhances performance.
In this work we focus on improving single-time retrieval for QA tasks. How to effectively combine multi-round RAG pipelines <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib30" title="">2023</a>; Khattab et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib38" title="">2022</a>; Jeong et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib28" title="">2024</a>)</cite> with RankRAG is an interesting avenue of future work.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Studies</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">Effect of Designed Components.</span> Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.T3" title="Table 3 ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">3</span></a> shows the ablations of RankRAG with Llama3 8B as the backbone on nine general-domain datasets. Overall, we observe all of the proposed components contribute to the final performance.
Removing context ranking hurts performance on all tasks, justifying its efficacy in selecting the most relevant contexts for the target question.
Besides, the retrieval-augmented QA (RQA) and retrieval-augmented ranking (RAR) designed for instruction fine-tuning improve outcomes on most tasks by helping the model explicitly pinpoint relevant contexts. On the contrary, the RAFT method used in <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">2024</a>)</cite> treats each retrieved context separately during instruction finetuning, which yields suboptimal results when compared to RankRAG with the same training data.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation study of RankRAG. We use Llama3-8B as the backbone. Where ‘RQA’ and ‘RAR’ stands for retrieval-augmented QA and retrieval-augmented ranking data, respectively. For ‘w/o reranking’, we do not perform ranking in the inference stage.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.4" style="width:433.6pt;height:96.2pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-110.3pt,24.3pt) scale(0.662858338723669,0.662858338723669) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T3.4.1">
<tr class="ltx_tr" id="S5.T3.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T3.4.1.1.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.1.1" style="font-size:90%;">Task (Zero-Shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.2.1" style="font-size:90%;">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.3.1" style="font-size:90%;">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.4.1" style="font-size:90%;">PopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.5.1" style="font-size:90%;">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.6.1" style="font-size:90%;">2WikimQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.7.1" style="font-size:90%;">FEVER</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.8.1" style="font-size:90%;">Doc2Dial</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.9.1" style="font-size:90%;">TopiOCQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.10.1" style="font-size:90%;">Inscit</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.4.1.1.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.1.11.1" style="font-size:90%;">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.4.1.2.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.2.1.1" style="font-size:90%;">Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.2.1" style="font-size:90%;">EM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.3.1" style="font-size:90%;">EM / Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.4.1" style="font-size:90%;">EM / Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.5.1" style="font-size:90%;">EM / F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.6.1" style="font-size:90%;">EM / F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.7.1" style="font-size:90%;">Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.8.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.9.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.10.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.2.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.2.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.3" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.4.1.3.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.3.1.1" style="font-size:90%;background-color:#E0F3EB;">RankRAG 8B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.2.1" style="font-size:90%;background-color:#E0F3EB;">50.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.3.1" style="font-size:90%;background-color:#E0F3EB;">82.9 / 89.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.4.1" style="font-size:90%;background-color:#E0F3EB;">57.6 / 64.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.3.5.1" style="font-size:90%;background-color:#E0F3EB;">35.3 / <span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.5.1.1">46.7</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.3.6.1" style="font-size:90%;background-color:#E0F3EB;">31.4 / 36.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.3.7.1" style="font-size:90%;background-color:#E0F3EB;">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.8.1" style="font-size:90%;background-color:#E0F3EB;">40.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.9.1" style="font-size:90%;background-color:#E0F3EB;">50.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.3.10.1" style="font-size:90%;background-color:#E0F3EB;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.3.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.3.11.1" style="font-size:90%;background-color:#E0F3EB;">52.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.4.1.4.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.1.1" style="font-size:90%;">w/o reranking</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.2.1" style="font-size:90%;">48.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.3.1" style="font-size:90%;">80.3 / 86.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.4.1" style="font-size:90%;">49.3 / 59.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.5.1" style="font-size:90%;">31.3 / 41.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.6.1" style="font-size:90%;">26.4 / 30.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.7.1" style="font-size:90%;">91.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.8.1" style="font-size:90%;">39.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.9.1" style="font-size:90%;">49.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.10.1" style="font-size:90%;">30.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.4.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.4.11.1" style="font-size:90%;">49.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.4.1.5.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.1.1" style="font-size:90%;">w/o RQA</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.2.1" style="font-size:90%;">49.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.3.1" style="font-size:90%;">82.0 / 88.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.4.1" style="font-size:90%;">55.1 / 62.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_font_bold" id="S5.T3.4.1.5.5.1" style="font-size:90%;">35.6</span><span class="ltx_text" id="S5.T3.4.1.5.5.2" style="font-size:90%;"> / 45.9</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.5.6.1" style="font-size:90%;">31.8 / 37.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.5.7.1" style="font-size:90%;">92.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.8.1" style="font-size:90%;">39.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.9.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.10.1" style="font-size:90%;">32.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.5.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.5.11.1" style="font-size:90%;">51.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.4.1.6.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.1.1" style="font-size:90%;">w/o RAR</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.2.1" style="font-size:90%;">48.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.3.1" style="font-size:90%;">82.2 / 89.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.4.1" style="font-size:90%;">56.0 / 62.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.5.1" style="font-size:90%;">35.1 / 45.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.6.1" style="font-size:90%;">31.2 / 35.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.7.1" style="font-size:90%;">91.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.8.1" style="font-size:90%;">39.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.9.1" style="font-size:90%;">48.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.4.1.6.10.1" style="font-size:90%;">33.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.1.6.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.6.11.1" style="font-size:90%;">51.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.4.1.7.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T3.4.1.7.1.1" style="font-size:90%;">w/ RAFT (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib49" title="">Lin et al.</a></cite><span class="ltx_text" id="S5.T3.4.1.7.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.2.1" style="font-size:90%;">43.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.3.1" style="font-size:90%;">80.8 / 87.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.4.1" style="font-size:90%;">48.9 / 56.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.5.1" style="font-size:90%;">30.5 / 41.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.6.1" style="font-size:90%;">25.2 / 29.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.7.1" style="font-size:90%;">91.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.8.1" style="font-size:90%;">36.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.9.1" style="font-size:90%;">46.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.10.1" style="font-size:90%;">30.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.4.1.7.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.7.11.1" style="font-size:90%;">48.1</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.1.8">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T3.4.1.8.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.1.1" style="font-size:90%;">w/ Stage-I SFT Only</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.2.1" style="font-size:90%;">38.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.3.1" style="font-size:90%;">63.7 / 76.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.4.1" style="font-size:90%;">49.8 / 54.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.5.1" style="font-size:90%;">26.5 / 40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.6.1" style="font-size:90%;">18.0 / 25.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.7.1" style="font-size:90%;">85.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.8.1" style="font-size:90%;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.9.1" style="font-size:90%;">33.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.10.1" style="font-size:90%;">30.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.4.1.8.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T3.4.1.8.11.1" style="font-size:90%;">42.2</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">Performance with Different LLMs.</span></p>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Zero-shot evaluation using Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib78" title="">2023</a>)</cite> model as the backbone.
</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.8" style="width:433.6pt;height:99pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-140.0pt,31.8pt) scale(0.607610290169165,0.607610290169165) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T4.8.1">
<tr class="ltx_tr" id="S5.T4.8.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T4.8.1.1.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.1.1" style="font-size:90%;">Task (Zero-Shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.2.1" style="font-size:90%;">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.3.1" style="font-size:90%;">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.4.1" style="font-size:90%;">PopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.5.1" style="font-size:90%;">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.6.1" style="font-size:90%;">2WikimQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.7.1" style="font-size:90%;">FEVER</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.8.1" style="font-size:90%;">Doc2Dial</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.9.1" style="font-size:90%;">TopiOCQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.10.1" style="font-size:90%;">Inscit</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.8.1.1.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.1.11.1" style="font-size:90%;">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.8.1.2.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.1.2.1.1" style="font-size:90%;">Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.2.1" style="font-size:90%;">EM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.3.1" style="font-size:90%;">EM / Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.4.1" style="font-size:90%;">EM / Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.5.1" style="font-size:90%;">EM / F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.6.1" style="font-size:90%;">EM / F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.7.1" style="font-size:90%;">Acc.</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.8.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.9.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.10.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.2.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.2.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.8.1.3.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T4.8.1.3.1.1" style="font-size:90%;">Llama2-70B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib78" title="">Touvron et al.</a></cite><span class="ltx_text" id="S5.T4.8.1.3.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.2.1" style="font-size:90%;">25.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.3.1" style="font-size:90%;">82.4 / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.4.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.5.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.6.1" style="font-size:90%;">– / –</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.7.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.8.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.9.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.10.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.3.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.3.11.1" style="font-size:90%;">–</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.8.1.4.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T4.8.1.4.1.1" style="font-size:90%;">Llama2-ChatQA-1.0 7B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite><span class="ltx_text" id="S5.T4.8.1.4.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.2.1" style="font-size:90%;">41.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.3.1" style="font-size:90%;">77.8 / 86.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.4.1" style="font-size:90%;">46.7 / 55.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.5.1" style="font-size:90%;">28.9 / 40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.6.1" style="font-size:90%;">24.0 / 27.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.7.1" style="font-size:90%;">85.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.8.1" style="font-size:90%;">37.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.9.1" style="font-size:90%;">45.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.10.1" style="font-size:90%;">31.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.4.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.4.11.1" style="font-size:90%;">46.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.8.1.5.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T4.8.1.5.1.1" style="font-size:90%;">Llama2-ChatQA-1.0 13B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite><span class="ltx_text" id="S5.T4.8.1.5.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.2.1" style="font-size:90%;">47.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.3.1" style="font-size:90%;">80.9 / 87.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.4.1" style="font-size:90%;">51.8 / 56.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.5.1" style="font-size:90%;">32.9 / 43.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.6.1" style="font-size:90%;">27.6 / 31.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.7.1" style="font-size:90%;">87.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.8.1" style="font-size:90%;">38.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.9.1" style="font-size:90%;">48.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.10.1" style="font-size:90%;">30.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.5.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.5.11.1" style="font-size:90%;">49.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.8.1.6.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text" id="S5.T4.8.1.6.1.1" style="font-size:90%;">Llama2-ChatQA-1.0 70B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite><span class="ltx_text" id="S5.T4.8.1.6.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.2.1" style="font-size:90%;">49.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.3.1" style="font-size:90%;">83.2 / 89.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.4.1" style="font-size:90%;">52.1 / 56.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.5.1" style="font-size:90%;">39.0 / 49.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.6.1" style="font-size:90%;">28.9 / 34.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.7.1" style="font-size:90%;">91.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.8.1" style="font-size:90%;">38.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.9.1" style="font-size:90%;">51.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.10.1" style="font-size:90%;">31.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.6.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.6.11.1" style="font-size:90%;">51.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.7" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.8.1.7.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.1.1" style="font-size:90%;background-color:#E0F3EB;">Llama2-RankRAG 7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.2.1" style="font-size:90%;background-color:#E0F3EB;">46.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.3.1" style="font-size:90%;background-color:#E0F3EB;">84.0 / 89.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.4.1" style="font-size:90%;background-color:#E0F3EB;">55.9 / 61.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.5.1" style="font-size:90%;background-color:#E0F3EB;">32.2 / 43.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.6.1" style="font-size:90%;background-color:#E0F3EB;">26.8 / 30.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.7.1" style="font-size:90%;background-color:#E0F3EB;">86.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.8.1" style="font-size:90%;background-color:#E0F3EB;">38.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.9.1" style="font-size:90%;background-color:#E0F3EB;">49.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.10.1" style="font-size:90%;background-color:#E0F3EB;">32.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.1.7.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.7.11.1" style="font-size:90%;background-color:#E0F3EB;">50.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.8" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.8.1.8.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.1.1" style="font-size:90%;background-color:#E0F3EB;">Llama2-RankRAG 13B</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.2.1" style="font-size:90%;background-color:#E0F3EB;">50.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.3.1" style="font-size:90%;background-color:#E0F3EB;">84.5 / 91.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.4.1" style="font-size:90%;background-color:#E0F3EB;">58.0 / 63.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.5.1" style="font-size:90%;background-color:#E0F3EB;">36.4 / 47.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.6.1" style="font-size:90%;background-color:#E0F3EB;">29.5 / 34.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.7.1" style="font-size:90%;background-color:#E0F3EB;">91.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.8.1" style="font-size:90%;background-color:#E0F3EB;">39.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.9.1" style="font-size:90%;background-color:#E0F3EB;">49.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.10.1" style="font-size:90%;background-color:#E0F3EB;">33.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.8.1.8.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.8.11.1" style="font-size:90%;background-color:#E0F3EB;">52.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.1.9" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T4.8.1.9.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.1.1" style="font-size:90%;background-color:#E0F3EB;">Llama2-RankRAG 70B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.2.1" style="font-size:90%;background-color:#E0F3EB;">53.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.3" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.3.1" style="font-size:90%;background-color:#E0F3EB;">85.8 / 92.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.4" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.4.1" style="font-size:90%;background-color:#E0F3EB;">58.7 / 64.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.5.1" style="font-size:90%;background-color:#E0F3EB;">41.8 / 53.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.6" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.6.1" style="font-size:90%;background-color:#E0F3EB;">33.8 / 38.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.7" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.7.1" style="font-size:90%;background-color:#E0F3EB;">91.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.8" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.8.1" style="font-size:90%;background-color:#E0F3EB;">41.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.9" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.9.1" style="font-size:90%;background-color:#E0F3EB;">52.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.10" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.10.1" style="font-size:90%;background-color:#E0F3EB;">35.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.8.1.9.11" style="padding-top:-0.25pt;padding-bottom:-0.25pt;"><span class="ltx_text" id="S5.T4.8.1.9.11.1" style="font-size:90%;background-color:#E0F3EB;">55.0</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.T4" title="Table 4 ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">4</span></a> reports the performance of RankRAG and the most recent baseline ChatQA using Llama2 with backbone having varying amounts of parameters.
Notably, there exist consistent gains in terms of the average performance (7.8%/6.4%/6.3% on 7B/13B/70B variants respectively), justifying the advantage of RankRAG across different LLM types and scales.</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S5.F6.sf1">
</figure>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.1">Performance with Different Retrievers.</span>
Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:dpr_contriever</span> exhibits the performance of RankRAG and ChatQA-1.5 with different dense retrievers on three representative tasks, where we consider DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>)</cite> and Contriever-MS MARCO <cite class="ltx_cite ltx_citemacro_citep">(Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib26" title="">2022</a>)</cite> as two variants.
We note that although the initial retrieved result is not good enough,
RankRAG still surpasses ChatQA-1.5 by more than 10% for both retrievers on average. To summarize, RankRAG is robust to the choice of retrievers.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Experiment on Domain-specific RAG Benchmarks</h3>
<figure class="ltx_table ltx_align_floatright" id="S5.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T5.2.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S5.T5.3.2" style="font-size:90%;">The performance of RankRAG on Mirage, a zero-shot
biomedical RAG benchmark. RankRAG and baselines use retrieval by default. Most of numbers are from <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib90" title="">2024</a>)</cite>.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T5.4" style="width:433.6pt;height:145.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-78.9pt,26.4pt) scale(0.733122549279359,0.733122549279359) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T5.4.1">
<tr class="ltx_tr" id="S5.T5.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T5.4.1.1.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.4.1.1.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.2.1">MMLU-med</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.4.1.1.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.3.1">PubmedQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.4.1.1.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.4.1">BioASQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.4.1.1.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.5.1">MedQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.4.1.1.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.6.1">MedMCQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.4.1.1.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.4.1.1.7.1">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.4.1.2.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">GPT-4-0613 (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">OpenAI</a></cite>)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.2.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">87.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.2.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">70.60</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.2.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">92.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.2.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">82.80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.2.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">66.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.2.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">79.97</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.3">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.3.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">GPT-3.5 (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib62" title="">OpenAI</a></cite>)</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.3.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">75.48</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.3.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">67.40</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.3.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">90.29</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.3.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">66.61</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.3.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">58.04</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.3.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">71.56</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.4">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.4.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">Mixtral 8*7B (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib29" title="">Jiang et al.</a></cite>)</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.4.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">75.85</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.4.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">67.60</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.4.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">87.54</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.4.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">60.02</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.4.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">56.42</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.4.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">69.49</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.5">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.5.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">Llama2 70B (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib78" title="">Touvron et al.</a></cite>)</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.5.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">54.55</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.5.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">50.40</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.5.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">73.95</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.5.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">44.93</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.5.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">43.08</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.5.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">53.38</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.6">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.6.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">Meditron 70B (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib10" title="">Chen et al.</a></cite>)</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.6.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">65.38</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.6.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">56.40</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.6.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">76.86</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.6.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">49.57</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.6.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">52.67</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.6.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">60.18</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.7">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.7.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">PMC-llama 13B (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib88" title="">Wu et al.</a></cite>)</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.7.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">52.53</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.7.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">42.58</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.7.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">48.29</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.7.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">56.00</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.7.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">65.21</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.7.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">52.92</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.8">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.8.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">Llama3-ChatQA-1.5 8B (<cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite>)</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.8.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">61.40</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.8.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">66.40</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.8.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">82.69</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.8.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">42.36</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.8.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">46.97</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.8.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">59.96</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.9">
<td class="ltx_td ltx_align_left" id="S5.T5.4.1.9.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">Llama3-ChatQA-1.5 70B</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.9.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">80.51</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.9.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">74.80</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.9.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">83.17</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.9.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">68.89</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.9.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">62.54</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.1.9.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">73.98</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.10" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.4.1.10.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.1.1" style="background-color:#E0F3EB;">Llama3-RankRAG 8B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.10.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.2.1" style="background-color:#E0F3EB;">64.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.10.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.3.1" style="background-color:#E0F3EB;">65.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.10.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.4.1" style="background-color:#E0F3EB;">84.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.10.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.5.1" style="background-color:#E0F3EB;">48.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.10.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.6.1" style="background-color:#E0F3EB;">56.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.1.10.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.10.7.1" style="background-color:#E0F3EB;">63.95</span></td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.1.11" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T5.4.1.11.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.1.1" style="background-color:#E0F3EB;">Llama3-RankRAG 70B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.1.11.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.2.1" style="background-color:#E0F3EB;">81.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.1.11.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.3.1" style="background-color:#E0F3EB;">79.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.1.11.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.4.1" style="background-color:#E0F3EB;">90.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.1.11.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.5.1" style="background-color:#E0F3EB;">69.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.1.11.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.6.1" style="background-color:#E0F3EB;">69.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.1.11.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T5.4.1.11.7.1" style="background-color:#E0F3EB;">78.06</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.2">To demonstrate that RankRAG can adapt to specialized domains, we conduct experiments on Mirage <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib90" title="">2024</a>)</cite>, a recently introduced RAG benchmark for the biomedical field.
We follow <cite class="ltx_cite ltx_citemacro_citet">Xiong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib90" title="">2024</a>)</cite> to employ MedCPT <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib33" title="">2023</a>)</cite> as the retriever <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><ci id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.1.m1.1d">caligraphic_R</annotation></semantics></math> with MedCorp<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Link: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/MedRAG" title="">https://huggingface.co/MedRAG</a>. Detailed dataset information is in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A1.SS2" title="A.2 Biomedical Benchmarks ‣ Appendix A Dataset Description ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</span></span></span> as the corpus <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S5.SS4.p1.2.m2.1"><semantics id="S5.SS4.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.1b"><ci id="S5.SS4.p1.2.m2.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.m2.1d">caligraphic_D</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">The experiment results of RankRAG and baselines are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.T5" title="Table 5 ‣ 5.4 Experiment on Domain-specific RAG Benchmarks ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">5</span></a>. From the table, we observe that RankRAG, even without fine-tuning on the biomedical domain, excels at medical QA tasks.
Notably, RankRAG 8B surpasses Meditron 70B—a leading open-source LLM for the medical domain—by 6.3%.
Besides, RankRAG 70B attains more than 98% performance of GPT-4. These results justify RankRAG’s capacity to be readily applied to new domains without extra post-training.
</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Ranking performance with different ranking models. Unless specified, all baselines are used to rank the top 100 retrieved passages. RankRAG achieves better performance despite using fewer ranking data.
<sup class="ltx_sup" id="S5.T6.33.1">∗</sup> NQ, TriviaQA and HotpotQA are used for training the BGE-Reranker model.
<sup class="ltx_sup" id="S5.T6.34.2">†</sup>: Our re-implementation.
<sup class="ltx_sup" id="S5.T6.35.3">‡</sup> We only rerank top-30 passages for GPT-4 due to budget constraint.

</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.23" style="width:433.6pt;height:155.1pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-187.1pt,66.7pt) scale(0.536802471272672,0.536802471272672) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T6.23.17">
<tr class="ltx_tr" id="S5.T6.23.17.18">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T6.23.17.18.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.1.1" style="font-size:90%;">Task</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.23.17.18.2" rowspan="2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.2.1" style="font-size:90%;"># Rank Data</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.23.17.18.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.3.1" style="font-size:90%;">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.23.17.18.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.4.1" style="font-size:90%;">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.23.17.18.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.5.1" style="font-size:90%;">PopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.23.17.18.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.6.1" style="font-size:90%;">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.23.17.18.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.18.7.1" style="font-size:90%;">Inscit</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.19">
<td class="ltx_td ltx_align_left" id="S5.T6.23.17.19.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.19.1.1" style="font-size:90%;">Recall</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.2.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.3.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.4.1" style="font-size:90%;">R@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.5.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.6.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.7.1" style="font-size:90%;">R@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.8.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.9.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.10.1" style="font-size:90%;">R@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.11.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.12.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.13.1" style="font-size:90%;">R@20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.14.1" style="font-size:90%;">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.15.1" style="font-size:90%;">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.23.17.19.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.19.16.1" style="font-size:90%;">R@20</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.20">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.23.17.20.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.20.1.1" style="font-size:90%;">Backbone Retriever</span></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.20.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.21">
<td class="ltx_td ltx_align_left" id="S5.T6.23.17.21.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.23.17.21.1.1" style="font-size:90%;">Dragon (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib48" title="">Lin et al.</a></cite><span class="ltx_text" id="S5.T6.23.17.21.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.2.1" style="font-size:90%;">–</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.3.1" style="font-size:90%;">74.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.4.1" style="font-size:90%;">80.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.5.1" style="font-size:90%;">84.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.6.1" style="font-size:90%;">89.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.7.1" style="font-size:90%;">92.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.8.1" style="font-size:90%;">95.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.9.1" style="font-size:90%;">69.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.10.1" style="font-size:90%;">76.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.11.1" style="font-size:90%;">82.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.12.1" style="font-size:90%;">47.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.13.1" style="font-size:90%;">52.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.14.1" style="font-size:90%;">60.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.15.1" style="font-size:90%;">43.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.16.1" style="font-size:90%;">56.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.21.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.21.17.1" style="font-size:90%;">64.9</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.22">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.23.17.22.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.22.1.1" style="font-size:90%;">Finetuned Baseline Ranking Model</span></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.22.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T6.7.1.1">
<td class="ltx_td ltx_align_left" id="S5.T6.7.1.1.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.7.1.1.2.1" style="font-size:90%;">RankBERT 110M (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib19" title="">Glass et al.</a></cite><span class="ltx_text" id="S5.T6.7.1.1.2.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.7.1.1.1.m1.1"><semantics id="S5.T6.7.1.1.1.m1.1a"><mo id="S5.T6.7.1.1.1.m1.1.1" mathsize="90%" xref="S5.T6.7.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.7.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T6.7.1.1.1.m1.1.1.cmml" xref="S5.T6.7.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.7.1.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.7.1.1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S5.T6.7.1.1.1.1" style="font-size:90%;">503k</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.3.1" style="font-size:90%;">73.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.4.1" style="font-size:90%;">79.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.5.1" style="font-size:90%;">84.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.6.1" style="font-size:90%;">88.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.7.1" style="font-size:90%;">92.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.8.1" style="font-size:90%;">95.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.9.1" style="font-size:90%;">78.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.10.1" style="font-size:90%;">82.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.11.1" style="font-size:90%;">85.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.12.1" style="font-size:90%;">54.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.13.1" style="font-size:90%;">59.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.14.1" style="font-size:90%;">63.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.15.1" style="font-size:90%;">45.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.16.1" style="font-size:90%;">57.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.1.1.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.7.1.1.17.1" style="font-size:90%;">66.7</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.8.2.2">
<td class="ltx_td ltx_align_left" id="S5.T6.8.2.2.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.8.2.2.2.1" style="font-size:90%;">monoT5 3B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib61" title="">Nogueira et al.</a></cite><span class="ltx_text" id="S5.T6.8.2.2.2.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.8.2.2.1.m1.1"><semantics id="S5.T6.8.2.2.1.m1.1a"><mo id="S5.T6.8.2.2.1.m1.1.1" mathsize="90%" xref="S5.T6.8.2.2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.8.2.2.1.m1.1b"><csymbol cd="latexml" id="S5.T6.8.2.2.1.m1.1.1.cmml" xref="S5.T6.8.2.2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.8.2.2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.8.2.2.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S5.T6.8.2.2.1.1" style="font-size:90%;">503k</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.3.1" style="font-size:90%;">75.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.4.1" style="font-size:90%;">80.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.5.1" style="font-size:90%;">84.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.6.1" style="font-size:90%;">90.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.7.1" style="font-size:90%;">93.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.8.1" style="font-size:90%;">95.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.9.1" style="font-size:90%;">81.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.10.1" style="font-size:90%;">83.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.11.1" style="font-size:90%;">85.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.12.1" style="font-size:90%;">54.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.13.1" style="font-size:90%;">60.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.14.1" style="font-size:90%;">63.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.15.1" style="font-size:90%;">48.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.16.1" style="font-size:90%;">59.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.2.2.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.8.2.2.17.1" style="font-size:90%;">68.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.18.12.12">
<td class="ltx_td ltx_align_left" id="S5.T6.18.12.12.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.18.12.12.11.1" style="font-size:90%;">BGE-Rerank-v2-m3 568M (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib9" title="">Chen et al.</a></cite><span class="ltx_text" id="S5.T6.18.12.12.11.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.3.3.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.9.3.3.1.m1.1"><semantics id="S5.T6.9.3.3.1.m1.1a"><mo id="S5.T6.9.3.3.1.m1.1.1" mathsize="90%" xref="S5.T6.9.3.3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.9.3.3.1.m1.1b"><csymbol cd="latexml" id="S5.T6.9.3.3.1.m1.1.1.cmml" xref="S5.T6.9.3.3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.9.3.3.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.9.3.3.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S5.T6.9.3.3.1.1" style="font-size:90%;">1.6M</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.10.4.4.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.10.4.4.2.1" style="font-size:90%;">78.0</span><sup class="ltx_sup" id="S5.T6.10.4.4.2.2"><span class="ltx_text" id="S5.T6.10.4.4.2.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.11.5.5.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.11.5.5.3.1" style="font-size:90%;">82.8</span><sup class="ltx_sup" id="S5.T6.11.5.5.3.2"><span class="ltx_text" id="S5.T6.11.5.5.3.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.12.6.6.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.12.6.6.4.1" style="font-size:90%;">85.6</span><sup class="ltx_sup" id="S5.T6.12.6.6.4.2"><span class="ltx_text" id="S5.T6.12.6.6.4.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.13.7.7.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.13.7.7.5.1" style="font-size:90%;">91.6</span><sup class="ltx_sup" id="S5.T6.13.7.7.5.2"><span class="ltx_text" id="S5.T6.13.7.7.5.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.14.8.8.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.14.8.8.6.1" style="font-size:90%;">94.5</span><sup class="ltx_sup" id="S5.T6.14.8.8.6.2"><span class="ltx_text" id="S5.T6.14.8.8.6.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.15.9.9.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.15.9.9.7.1" style="font-size:90%;">97.1</span><sup class="ltx_sup" id="S5.T6.15.9.9.7.2"><span class="ltx_text" id="S5.T6.15.9.9.7.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.18.12.12.12.1" style="font-size:90%;">79.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.18.12.12.13.1" style="font-size:90%;">84.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.18.12.12.14.1" style="font-size:90%;">86.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.16.10.10.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.16.10.10.8.1" style="font-size:90%;">58.5</span><sup class="ltx_sup" id="S5.T6.16.10.10.8.2"><span class="ltx_text" id="S5.T6.16.10.10.8.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.17.11.11.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.17.11.11.9.1" style="font-size:90%;">61.8</span><sup class="ltx_sup" id="S5.T6.17.11.11.9.2"><span class="ltx_text" id="S5.T6.17.11.11.9.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.18.12.12.10.1" style="font-size:90%;">65.0</span><sup class="ltx_sup" id="S5.T6.18.12.12.10.2"><span class="ltx_text" id="S5.T6.18.12.12.10.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.18.12.12.15.1" style="font-size:90%;">51.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.18.12.12.16.1" style="font-size:90%;">59.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.18.12.12.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.18.12.12.17.1" style="font-size:90%;">69.7</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.20.14.14">
<td class="ltx_td ltx_align_left" id="S5.T6.19.13.13.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.19.13.13.1.1" style="font-size:90%;">RankLLaMA 8B</span><sup class="ltx_sup" id="S5.T6.19.13.13.1.2"><span class="ltx_text" id="S5.T6.19.13.13.1.2.1" style="font-size:90%;">†</span></sup><span class="ltx_text" id="S5.T6.19.13.13.1.3" style="font-size:90%;"> (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib54" title="">Ma et al.</a></cite><span class="ltx_text" id="S5.T6.19.13.13.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.20.14.14.2.m1.1"><semantics id="S5.T6.20.14.14.2.m1.1a"><mo id="S5.T6.20.14.14.2.m1.1.1" mathsize="90%" xref="S5.T6.20.14.14.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.20.14.14.2.m1.1b"><csymbol cd="latexml" id="S5.T6.20.14.14.2.m1.1.1.cmml" xref="S5.T6.20.14.14.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.20.14.14.2.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.20.14.14.2.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S5.T6.20.14.14.2.1" style="font-size:90%;">503k</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.3.1" style="font-size:90%;">77.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.4.1" style="font-size:90%;">83.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.5.1" style="font-size:90%;">86.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.6.1" style="font-size:90%;">91.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.7.1" style="font-size:90%;">93.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.8.1" style="font-size:90%;">96.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.9.1" style="font-size:90%;">80.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.10.1" style="font-size:90%;">84.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.11.1" style="font-size:90%;">86.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.12.1" style="font-size:90%;">57.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.20.14.14.13.1" style="font-size:90%;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.14.1" style="font-size:90%;">64.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.15.1" style="font-size:90%;">57.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.16.1" style="font-size:90%;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.20.14.14.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.20.14.14.17.1" style="font-size:90%;">71.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.23">
<td class="ltx_td ltx_align_left" id="S5.T6.23.17.23.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.23.17.23.1.1" style="font-size:90%;">ChatQA-1.5 8B (</span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib50" title="">Liu et al.</a></cite><span class="ltx_text" id="S5.T6.23.17.23.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.2.1" style="font-size:90%;">N/A</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.3.1" style="font-size:90%;">68.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.4.1" style="font-size:90%;">75.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.5.1" style="font-size:90%;">82.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.6.1" style="font-size:90%;">85.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.7.1" style="font-size:90%;">91.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.8.1" style="font-size:90%;">94.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.9.1" style="font-size:90%;">67.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.10.1" style="font-size:90%;">76.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.11.1" style="font-size:90%;">83.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.12.1" style="font-size:90%;">37.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.13.1" style="font-size:90%;">45.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.14.1" style="font-size:90%;">53.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.15.1" style="font-size:90%;">32.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.16.1" style="font-size:90%;">42.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.23.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.23.17.1" style="font-size:90%;">54.9</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.24">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.23.17.24.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.24.1.1" style="font-size:90%;">Off-the-shelf LLM Reranker</span></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.24.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.25">
<td class="ltx_td ltx_align_left" id="S5.T6.23.17.25.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.23.17.25.1.1" style="font-size:90%;">GPT-3.5 (</span><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.25.1.2" style="font-size:90%;">top 100</span><span class="ltx_text" id="S5.T6.23.17.25.1.3" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib62" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T6.23.17.25.1.4" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.2.1" style="font-size:90%;">Unk.</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.3.1" style="font-size:90%;">77.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.4.1" style="font-size:90%;">82.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.5.1" style="font-size:90%;">85.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.6.1" style="font-size:90%;">91.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.7.1" style="font-size:90%;">94.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.8.1" style="font-size:90%;">96.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.9.1" style="font-size:90%;">77.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.10.1" style="font-size:90%;">82.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.11.1" style="font-size:90%;">85.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.12.1" style="font-size:90%;">52.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.13.1" style="font-size:90%;">56.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.14.1" style="font-size:90%;">62.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.15.1" style="font-size:90%;">50.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.16.1" style="font-size:90%;">59.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.23.17.25.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.25.17.1" style="font-size:90%;">68.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.21.15.15">
<td class="ltx_td ltx_align_left" id="S5.T6.21.15.15.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<span class="ltx_text" id="S5.T6.21.15.15.1.1" style="font-size:90%;">GPT-4</span><sup class="ltx_sup" id="S5.T6.21.15.15.1.2"><span class="ltx_text" id="S5.T6.21.15.15.1.2.1" style="font-size:90%;">‡</span></sup><span class="ltx_text" id="S5.T6.21.15.15.1.3" style="font-size:90%;"> (</span><span class="ltx_text ltx_font_bold" id="S5.T6.21.15.15.1.4" style="font-size:90%;">top 30</span><span class="ltx_text" id="S5.T6.21.15.15.1.5" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib63" title="">OpenAI</a></cite><span class="ltx_text" id="S5.T6.21.15.15.1.6" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.2.1" style="font-size:90%;">Unk.</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.3.1" style="font-size:90%;">79.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.4.1" style="font-size:90%;">83.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.5.1" style="font-size:90%;">85.1</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.6.1" style="font-size:90%;">92.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.7.1" style="font-size:90%;">95.5</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.8.1" style="font-size:90%;">96.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.9.1" style="font-size:90%;">79.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.10.1" style="font-size:90%;">83.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.11.1" style="font-size:90%;">86.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.12.1" style="font-size:90%;">53.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.13.1" style="font-size:90%;">57.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.14.1" style="font-size:90%;">61.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.15.1" style="font-size:90%;">52.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.16.1" style="font-size:90%;">61.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.21.15.15.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.21.15.15.17.1" style="font-size:90%;">70.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.26">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.23.17.26.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.26.1.1" style="font-size:90%;">Our Model</span></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T6.23.17.26.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"></td>
</tr>
<tr class="ltx_tr" id="S5.T6.22.16.16" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left" id="S5.T6.22.16.16.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.2.1" style="font-size:90%;background-color:#E0F3EB;">RankRAG 8B <span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.2.1.1">(top 100)</span></span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.22.16.16.1.m1.1" style="background-color:#E0F3EB;"><semantics id="S5.T6.22.16.16.1.m1.1a"><mo id="S5.T6.22.16.16.1.m1.1.1" mathbackground="#E0F3EB" mathsize="90%" xref="S5.T6.22.16.16.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.22.16.16.1.m1.1b"><csymbol cd="latexml" id="S5.T6.22.16.16.1.m1.1.1.cmml" xref="S5.T6.22.16.16.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.22.16.16.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.22.16.16.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S5.T6.22.16.16.1.1" style="font-size:90%;background-color:#E0F3EB;">50k</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.3.1" style="font-size:90%;background-color:#E0F3EB;">80.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.4.1" style="font-size:90%;background-color:#E0F3EB;">84.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.5.1" style="font-size:90%;background-color:#E0F3EB;">86.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.6.1" style="font-size:90%;background-color:#E0F3EB;">93.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.7.1" style="font-size:90%;background-color:#E0F3EB;">95.4</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.8.1" style="font-size:90%;background-color:#E0F3EB;">97.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.9.1" style="font-size:90%;background-color:#E0F3EB;">81.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.10.1" style="font-size:90%;background-color:#E0F3EB;">84.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.11.1" style="font-size:90%;background-color:#E0F3EB;">87.0</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.12.1" style="font-size:90%;background-color:#E0F3EB;">57.6</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.13.1" style="font-size:90%;background-color:#E0F3EB;">61.8</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.22.16.16.14.1" style="font-size:90%;background-color:#E0F3EB;">65.2</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.15.1" style="font-size:90%;background-color:#E0F3EB;">60.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.16.1" style="font-size:90%;background-color:#E0F3EB;">65.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.22.16.16.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.22.16.16.17.1" style="font-size:90%;background-color:#E0F3EB;">73.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.23.17.17" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T6.23.17.17.2" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.2.1" style="font-size:90%;background-color:#E0F3EB;">RankRAG 70B <span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.2.1.1">(top 30)</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.1" style="padding-top:-0.2pt;padding-bottom:-0.2pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.23.17.17.1.m1.1" style="background-color:#E0F3EB;"><semantics id="S5.T6.23.17.17.1.m1.1a"><mo id="S5.T6.23.17.17.1.m1.1.1" mathbackground="#E0F3EB" mathsize="90%" xref="S5.T6.23.17.17.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.23.17.17.1.m1.1b"><csymbol cd="latexml" id="S5.T6.23.17.17.1.m1.1.1.cmml" xref="S5.T6.23.17.17.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.23.17.17.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.23.17.17.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S5.T6.23.17.17.1.1" style="font-size:90%;background-color:#E0F3EB;">50k</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.3" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.3.1" style="font-size:90%;background-color:#E0F3EB;">80.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.4" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.4.1" style="font-size:90%;background-color:#E0F3EB;">84.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.5" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.5.1" style="font-size:90%;background-color:#E0F3EB;">85.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.6" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.6.1" style="font-size:90%;background-color:#E0F3EB;">93.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.7" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.7.1" style="font-size:90%;background-color:#E0F3EB;">95.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.8" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.8.1" style="font-size:90%;background-color:#E0F3EB;">97.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.9" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.9.1" style="font-size:90%;background-color:#E0F3EB;">81.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.10" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.10.1" style="font-size:90%;background-color:#E0F3EB;">84.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.11" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.11.1" style="font-size:90%;background-color:#E0F3EB;">86.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.12" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.12.1" style="font-size:90%;background-color:#E0F3EB;">56.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.13" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.13.1" style="font-size:90%;background-color:#E0F3EB;">59.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.14" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text" id="S5.T6.23.17.17.14.1" style="font-size:90%;background-color:#E0F3EB;">62.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.15" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.15.1" style="font-size:90%;background-color:#E0F3EB;">61.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.16" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.16.1" style="font-size:90%;background-color:#E0F3EB;">66.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.23.17.17.17" style="padding-top:-0.2pt;padding-bottom:-0.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.23.17.17.17.1" style="font-size:90%;background-color:#E0F3EB;">74.6</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>A Closer Look at the Ranking Module</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">As the context ranking serves as a core step in RankRAG, we take a closer look at this component.
All the studies are done using Llama3-8B as the backbone.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS5.p2.1.1">RankRAG is Data-efficient.</span> Previous approaches that infuse context ranking into the RAG pipeline usually involve a separate reranking model.
To compare our model with these baselines, we evaluate four models (BERT <cite class="ltx_cite ltx_citemacro_citep">(Glass et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib19" title="">2022</a>)</cite>/T5 <cite class="ltx_cite ltx_citemacro_citep">(Nogueira et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib61" title="">2020</a>)</cite>/Llama3 <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib54" title="">2023</a>)</cite>) fine-tuned on the full MS MARCO passage ranking dataset, a strong off-the-shelf reranker model BGE-ranker, and two OpenAI GPT-series models. For the GPT-series models, we use the token probability of ‘<span class="ltx_text ltx_font_typewriter" id="S5.SS5.p2.1.2">True</span>’ as a proxy for the relevance score<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-logprobs" title="">https://platform.openai.com/docs/api-reference/chat/create#chat-create-logprobs</a></span></span></span>.
These models are then used to rerank top-retrieved passages by Dragon, similar to our approach.
Surprisingly, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.T6" title="Table 6 ‣ 5.4 Experiment on Domain-specific RAG Benchmarks ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">6</span></a>, RankRAG achieves better recall over dedicated ranking models trained on <math alttext="10\times" class="ltx_math_unparsed" display="inline" id="S5.SS5.p2.1.m1.1"><semantics id="S5.SS5.p2.1.m1.1a"><mrow id="S5.SS5.p2.1.m1.1b"><mn id="S5.SS5.p2.1.m1.1.1">10</mn><mo id="S5.SS5.p2.1.m1.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS5.p2.1.m1.1c">10\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.1.m1.1d">10 ×</annotation></semantics></math> more ranking data for most cases.
Besides, RankRAG can still outperform the BGE-ranker on most tasks, which has been extensively trained on more than 1 million ranking pairs, including some that overlap with our evaluation tasks.
This advantage is likely due to the adaptable nature of our model’s training, where the ranking data closely resembles the general RAG fine-tuning data.
Directly using ChatQA-1.5 to rank passages <em class="ltx_emph ltx_font_italic" id="S5.SS5.p2.1.3">hurts</em> the performance, indicating the necessity of incorporating ranking data into instruction fine-tuning.</p>
</div>
<div class="ltx_para" id="S5.SS5.p3">
<p class="ltx_p" id="S5.SS5.p3.1">We further study the relation between the number of context ranking data and final performance. As shown in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:num_ranking</span>, with 5k ranking data only (<math alttext="\sim 1\%" class="ltx_Math" display="inline" id="S5.SS5.p3.1.m1.1"><semantics id="S5.SS5.p3.1.m1.1a"><mrow id="S5.SS5.p3.1.m1.1.1" xref="S5.SS5.p3.1.m1.1.1.cmml"><mi id="S5.SS5.p3.1.m1.1.1.2" xref="S5.SS5.p3.1.m1.1.1.2.cmml"></mi><mo id="S5.SS5.p3.1.m1.1.1.1" xref="S5.SS5.p3.1.m1.1.1.1.cmml">∼</mo><mrow id="S5.SS5.p3.1.m1.1.1.3" xref="S5.SS5.p3.1.m1.1.1.3.cmml"><mn id="S5.SS5.p3.1.m1.1.1.3.2" xref="S5.SS5.p3.1.m1.1.1.3.2.cmml">1</mn><mo id="S5.SS5.p3.1.m1.1.1.3.1" xref="S5.SS5.p3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.1.m1.1b"><apply id="S5.SS5.p3.1.m1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS5.p3.1.m1.1.1.1.cmml" xref="S5.SS5.p3.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.SS5.p3.1.m1.1.1.2.cmml" xref="S5.SS5.p3.1.m1.1.1.2">absent</csymbol><apply id="S5.SS5.p3.1.m1.1.1.3.cmml" xref="S5.SS5.p3.1.m1.1.1.3"><csymbol cd="latexml" id="S5.SS5.p3.1.m1.1.1.3.1.cmml" xref="S5.SS5.p3.1.m1.1.1.3.1">percent</csymbol><cn id="S5.SS5.p3.1.m1.1.1.3.2.cmml" type="integer" xref="S5.SS5.p3.1.m1.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.1.m1.1c">\sim 1\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.1.m1.1d">∼ 1 %</annotation></semantics></math> of the MS MARCO dataset), RankRAG can already obtain very compelling results, while further increasing the number of ranking data to 50k yields non-marginal gains.
This finding confirms RankRAG’s data efficiency – achieving effective performance with a modest amount of ranking data and maintaining adaptability across various tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p4">
<p class="ltx_p" id="S5.SS5.p4.9"><span class="ltx_text ltx_font_bold" id="S5.SS5.p4.9.1">Performance v.s. Time-efficiency for RankRAG.</span>
One specific caveat for scaling up model size is the increment in the latency overhead — as mentioned in §<a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S4.SS3" title="4.3 RankRAG Inference: Retrieve-Rerank-Generate Pipeline ‣ 4 RankRAG ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">4.3</span></a>, it requires sample-wise ranking which incurs additional time.
To study the relation between the time efficiency and performance, we change the <math alttext="N" class="ltx_Math" display="inline" id="S5.SS5.p4.1.m1.1"><semantics id="S5.SS5.p4.1.m1.1a"><mi id="S5.SS5.p4.1.m1.1.1" xref="S5.SS5.p4.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.1.m1.1b"><ci id="S5.SS5.p4.1.m1.1.1.cmml" xref="S5.SS5.p4.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.1.m1.1d">italic_N</annotation></semantics></math> used in reranking and plot the relation of <math alttext="N" class="ltx_Math" display="inline" id="S5.SS5.p4.2.m2.1"><semantics id="S5.SS5.p4.2.m2.1a"><mi id="S5.SS5.p4.2.m2.1.1" xref="S5.SS5.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.2.m2.1b"><ci id="S5.SS5.p4.2.m2.1.1.cmml" xref="S5.SS5.p4.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.2.m2.1d">italic_N</annotation></semantics></math> and final accuracy in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:performance_efficiency</span>, from which
we observe that even with <math alttext="N=20" class="ltx_Math" display="inline" id="S5.SS5.p4.3.m3.1"><semantics id="S5.SS5.p4.3.m3.1a"><mrow id="S5.SS5.p4.3.m3.1.1" xref="S5.SS5.p4.3.m3.1.1.cmml"><mi id="S5.SS5.p4.3.m3.1.1.2" xref="S5.SS5.p4.3.m3.1.1.2.cmml">N</mi><mo id="S5.SS5.p4.3.m3.1.1.1" xref="S5.SS5.p4.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS5.p4.3.m3.1.1.3" xref="S5.SS5.p4.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.3.m3.1b"><apply id="S5.SS5.p4.3.m3.1.1.cmml" xref="S5.SS5.p4.3.m3.1.1"><eq id="S5.SS5.p4.3.m3.1.1.1.cmml" xref="S5.SS5.p4.3.m3.1.1.1"></eq><ci id="S5.SS5.p4.3.m3.1.1.2.cmml" xref="S5.SS5.p4.3.m3.1.1.2">𝑁</ci><cn id="S5.SS5.p4.3.m3.1.1.3.cmml" type="integer" xref="S5.SS5.p4.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.3.m3.1c">N=20</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.3.m3.1d">italic_N = 20</annotation></semantics></math>, RankRAG still improve the baseline model without reranking.
While reranking across <math alttext="N=20" class="ltx_Math" display="inline" id="S5.SS5.p4.4.m4.1"><semantics id="S5.SS5.p4.4.m4.1a"><mrow id="S5.SS5.p4.4.m4.1.1" xref="S5.SS5.p4.4.m4.1.1.cmml"><mi id="S5.SS5.p4.4.m4.1.1.2" xref="S5.SS5.p4.4.m4.1.1.2.cmml">N</mi><mo id="S5.SS5.p4.4.m4.1.1.1" xref="S5.SS5.p4.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS5.p4.4.m4.1.1.3" xref="S5.SS5.p4.4.m4.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.4.m4.1b"><apply id="S5.SS5.p4.4.m4.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1"><eq id="S5.SS5.p4.4.m4.1.1.1.cmml" xref="S5.SS5.p4.4.m4.1.1.1"></eq><ci id="S5.SS5.p4.4.m4.1.1.2.cmml" xref="S5.SS5.p4.4.m4.1.1.2">𝑁</ci><cn id="S5.SS5.p4.4.m4.1.1.3.cmml" type="integer" xref="S5.SS5.p4.4.m4.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.4.m4.1c">N=20</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.4.m4.1d">italic_N = 20</annotation></semantics></math> to <math alttext="100" class="ltx_Math" display="inline" id="S5.SS5.p4.5.m5.1"><semantics id="S5.SS5.p4.5.m5.1a"><mn id="S5.SS5.p4.5.m5.1.1" xref="S5.SS5.p4.5.m5.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.SS5.p4.5.m5.1b"><cn id="S5.SS5.p4.5.m5.1.1.cmml" type="integer" xref="S5.SS5.p4.5.m5.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p4.5.m5.1c">100</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.5.m5.1d">100</annotation></semantics></math> improves the exact match score by 5.9% to 9.1% across three tasks, it incurs an additional <math alttext="0.9\times" class="ltx_math_unparsed" display="inline" id="S5.SS5.p4.6.m6.1"><semantics id="S5.SS5.p4.6.m6.1a"><mrow id="S5.SS5.p4.6.m6.1b"><mn id="S5.SS5.p4.6.m6.1.1">0.9</mn><mo id="S5.SS5.p4.6.m6.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS5.p4.6.m6.1c">0.9\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.6.m6.1d">0.9 ×</annotation></semantics></math> to <math alttext="6.0\times" class="ltx_math_unparsed" display="inline" id="S5.SS5.p4.7.m7.1"><semantics id="S5.SS5.p4.7.m7.1a"><mrow id="S5.SS5.p4.7.m7.1b"><mn id="S5.SS5.p4.7.m7.1.1">6.0</mn><mo id="S5.SS5.p4.7.m7.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS5.p4.7.m7.1c">6.0\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.7.m7.1d">6.0 ×</annotation></semantics></math> increase in time – <em class="ltx_emph ltx_font_italic" id="S5.SS5.p4.9.2">significantly less</em> than the <math alttext="20\times" class="ltx_math_unparsed" display="inline" id="S5.SS5.p4.8.m8.1"><semantics id="S5.SS5.p4.8.m8.1a"><mrow id="S5.SS5.p4.8.m8.1b"><mn id="S5.SS5.p4.8.m8.1.1">20</mn><mo id="S5.SS5.p4.8.m8.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS5.p4.8.m8.1c">20\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.8.m8.1d">20 ×</annotation></semantics></math> to <math alttext="100\times" class="ltx_math_unparsed" display="inline" id="S5.SS5.p4.9.m9.1"><semantics id="S5.SS5.p4.9.m9.1a"><mrow id="S5.SS5.p4.9.m9.1b"><mn id="S5.SS5.p4.9.m9.1.1">100</mn><mo id="S5.SS5.p4.9.m9.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS5.p4.9.m9.1c">100\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p4.9.m9.1d">100 ×</annotation></semantics></math> increase one might expect.</p>
</div>
<figure class="ltx_figure" id="S5.SS5.fig1">
</figure>
<figure class="ltx_table" id="S5.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T7.4.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="S5.T7.5.2" style="font-size:90%;">A case study on the top-retrieved context and predictions on NQ dataset, illustrating the effectiveness of RankRAG-8B over ChatQA-1.5-8B. <span class="ltx_text" id="S5.T7.5.2.1" style="color:#FF0000;">Red</span> text denotes distractors, while <span class="ltx_text" id="S5.T7.5.2.2" style="color:#009B55;">green</span> stands for evidences. RankRAG is able to find the correct answer via extract more evidence with reranking.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T7.6" style="width:433.6pt;height:221.4pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-121.2pt,61.7pt) scale(0.641396332083255,0.641396332083255) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T7.6.1">
<tr class="ltx_tr" id="S5.T7.6.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" colspan="2" id="S5.T7.6.1.1.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_text ltx_font_bold" id="S5.T7.6.1.1.1.1">Q</span>: who hosted and won the inagural world cup? <span class="ltx_text ltx_font_bold" id="S5.T7.6.1.1.1.2">A</span>: Uruguay</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.6.1.2.1" rowspan="5" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.2.1.1">
<span class="ltx_p" id="S5.T7.6.1.2.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.2.1.1.1.1">ChatQA-1.5</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.6.1.2.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.2.2.1">
<span class="ltx_p" id="S5.T7.6.1.2.2.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.2.2.1.1.1">Passage 1</span>: FIFA World Cup second round on home soil in 1982. <span class="ltx_text" id="S5.T7.6.1.2.2.1.1.2" style="color:#FF0000;">England</span> (1966) won its only title while playing as a host nation. <span class="ltx_text" id="S5.T7.6.1.2.2.1.1.3" style="color:#009B55;">Uruguay (1930)</span>, Italy (1934), Argentina (1978) and France (1998) won their first titles as host nations but have gone on to win again, while <span class="ltx_text" id="S5.T7.6.1.2.2.1.1.4" style="color:#FF0000;">Germany (1974) won their second title on home soil</span>…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.3.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.3.1.1">
<span class="ltx_p" id="S5.T7.6.1.3.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.3.1.1.1.1">Passage 2</span>: FIFA World Cup hosts country is now chosen in a vote by FIFA’s Congress … Only Mexico, Italy, France, <span class="ltx_text" id="S5.T7.6.1.3.1.1.1.2" style="color:#FF0000;">Germany</span> (West Germany) until shortly after the 1990 World Cup) and Brazil have hosted the event on two occasions.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.4.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.4.1.1">
<span class="ltx_p" id="S5.T7.6.1.4.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.4.1.1.1.1">Passage 3</span>: CONCACAF hosts, beating the bids of Canada and the United States, and thereby became the first nation to host two World Cups. This second World Cup in <span class="ltx_text" id="S5.T7.6.1.4.1.1.1.2" style="color:#FF0000;">Mexico</span> came 16 years after the first one in 1970…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.5.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.5.1.1">
<span class="ltx_p" id="S5.T7.6.1.5.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.5.1.1.1.1">Passage 4</span>: 1998 FIFA World Cup Africa made their first appearances in the finals. <span class="ltx_text" id="S5.T7.6.1.5.1.1.1.2" style="color:#FF0000;">France</span> was awarded the 1998 World Cup on 2 July 1992 by the executive committee of FIFA during a general meeting in Zürich, Switzerland. They defeated Morocco by 12 votes to 7.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.6.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.6.1.1">
<span class="ltx_p" id="S5.T7.6.1.6.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.6.1.1.1.1">Passage 5</span>: 2026 FIFA World Cup be hosted by one of the remaining four confederations: CONCACAF (North America; last hosted in 1994), CAF (Africa; last hosted in 2010), CONMEBOL (South America; last hosted in 2014), or OFC (Oceania, never hosted before)…  <span class="ltx_text ltx_font_bold" id="S5.T7.6.1.6.1.1.1.2" style="background-color:#FFD9D9;">Prediction<span class="ltx_text ltx_font_medium" id="S5.T7.6.1.6.1.1.1.2.1">: <em class="ltx_emph ltx_font_italic" id="S5.T7.6.1.6.1.1.1.2.1.1" style="background-color:#FFD9D9;">Germany</em> (✘)</span></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S5.T7.6.1.7.1" rowspan="13" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.7.1.1">
<span class="ltx_p" id="S5.T7.6.1.7.1.1.1" style="width:51.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.7.1.1.1.1">RankRAG</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T7.6.1.7.2" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.7.2.1">
<span class="ltx_p" id="S5.T7.6.1.7.2.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.7.2.1.1.1">Passage 1</span>: FIFA World Cup second round on home soil in 1982. England (1966) won its only title while playing as a host nation. <span class="ltx_text" id="S5.T7.6.1.7.2.1.1.2" style="color:#009B55;">Uruguay (1930)</span>, Italy (1934), Argentina (1978) and France (1998) won their first titles as host nations but have gone on to win again, while <span class="ltx_text" id="S5.T7.6.1.7.2.1.1.3" style="color:#FF0000;">Germany (1974) won their second title on home soil</span>…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.8.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.8.1.1">
<span class="ltx_p" id="S5.T7.6.1.8.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.8.1.1.1.1">Passage 2</span>: Timeline of association football penalty kicks. Thirteen teams enter <span class="ltx_text" id="S5.T7.6.1.8.1.1.1.2" style="color:#009B55;">the first World Cup, held in Uruguay. The hosts beat Argentina 4–2 in the final.</span> Contested between the top national teams of continental Europe, Dr. Gerö Cup’ first edition is won by Italy.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.9.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.9.1.1">
<span class="ltx_p" id="S5.T7.6.1.9.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.9.1.1.1.1">Passage 3</span>: The Uruguay national football team represents Uruguay in international association football and is controlled by the Uruguayan Football Association. They have won the Copa América 15 times, the most successful national team in the tournament, the most recent title being the 2011 edition. <span class="ltx_text" id="S5.T7.6.1.9.1.1.1.2" style="color:#009B55;">The team has won the FIFA World Cup twice, including the first World Cup in 1930 as hosts</span>, defeating Argentina 4–2 in the final.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S5.T7.6.1.10.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.10.1.1">
<span class="ltx_p" id="S5.T7.6.1.10.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.10.1.1.1.1">Passage 4</span>: FIFA World Cup hosts country is now chosen in a vote by FIFA’s Congress. The decision is currently made roughly seven years in advance of the tournament, though the hosts for the 2022 tournament were chosen at the same time as those for the 2018 tournament.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.1.11">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S5.T7.6.1.11.1" style="padding-top:-0.25pt;padding-bottom:-0.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S5.T7.6.1.11.1.1">
<span class="ltx_p" id="S5.T7.6.1.11.1.1.1" style="width:597.5pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.6.1.11.1.1.1.1">Passage 5</span>: CONCACAF hosts, beating the bids of Canada and the United States, and thereby became the first nation to host two World Cups. This second World Cup in <span class="ltx_text" id="S5.T7.6.1.11.1.1.1.2" style="color:#FF0000;">Mexico</span> came 16 years after the first one in 1970…  <span class="ltx_text ltx_font_bold" id="S5.T7.6.1.11.1.1.1.3" style="background-color:#D9F0E5;">Prediction<span class="ltx_text ltx_font_medium" id="S5.T7.6.1.11.1.1.1.3.1">: <em class="ltx_emph ltx_font_italic" id="S5.T7.6.1.11.1.1.1.3.1.1" style="background-color:#D9F0E5;">Uruguay</em> (✓)</span></span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Case Study</h3>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#S5.T7" title="Table 7 ‣ 5.5 A Closer Look at the Ranking Module ‣ 5 Experiments ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">7</span></a>
presents a case study on NQ dataset, where we observe that using retriever only yield noisy contexts, as there are several distractors, and some contexts (e.g. Passage 4/5 for ChatQA-1.5) are unhelpful.
However, the utilization of reranking uncovers <em class="ltx_emph ltx_font_italic" id="S5.SS6.p1.1.1">two additional</em> relevant passages, aiding the model in providing the correct answer. More case studies are provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A7" title="Appendix G Additional Case Studies ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">G</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we introduce a new RAG framework, RankRAG, which instruction-tunes a single LLM for both ranking and answer generation.
We find that the instruction tuned LLMs can outperform existing expert ranking models by only adding a small fraction of ranking data into the training blend.
We compare our RankRAG with the state-of-the-art RAG models on comprehensive knowledge-intensive benchmarks and demonstrate RankRAG significantly outperform all of them on nine general-domain and five biomedical benchmarks for RAG.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adlakha et al. (2022)</span>
<span class="ltx_bibblock">
Adlakha, V., Dhuliawala, S., Suleman, K., de Vries, H., and Reddy, S.

</span>
<span class="ltx_bibblock">Topiocqa: Open-domain conversational question answering with topic switching.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">TACL</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et al. (2023)</span>
<span class="ltx_bibblock">
Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2305.10403</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2023)</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Model card and evaluations for claude models.

</span>
<span class="ltx_bibblock">2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. (2024a)</span>
<span class="ltx_bibblock">
Asai, A., Wu, Z., Wang, Y., Sil, A., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Self-RAG: Learning to retrieve, generate, and critique through self-reflection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">ICLR</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. (2024b)</span>
<span class="ltx_bibblock">
Asai, A., Zhong, Z., Chen, D., Koh, P. W., Zettlemoyer, L., Hajishirzi, H., and Yih, W.-t.

</span>
<span class="ltx_bibblock">Reliable, adaptable, and attributable language models with retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2403.03187</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bajaj et al. (2016)</span>
<span class="ltx_bibblock">
Bajaj, P., Campos, D., Craswell, N., Deng, L., Gao, J., Liu, X., Majumder, R., McNamara, A., Mitra, B., Nguyen, T., et al.

</span>
<span class="ltx_bibblock">Ms marco: A human generated machine reading comprehension dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:1611.09268</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berant et al. (2013)</span>
<span class="ltx_bibblock">
Berant, J., Chou, A., Frostig, R., and Liang, P.

</span>
<span class="ltx_bibblock">Semantic parsing on freebase from question-answer pairs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">EMNLP</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud et al. (2022)</span>
<span class="ltx_bibblock">
Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G. B., Lespiau, J.-B., Damoc, B., Clark, A., et al.

</span>
<span class="ltx_bibblock">Improving language models by retrieving from trillions of tokens.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">ICML</em>. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023a)</span>
<span class="ltx_bibblock">
Chen, J., Xiao, S., Zhang, P., Luo, K., Lian, D., and Liu, Z.

</span>
<span class="ltx_bibblock">Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023b)</span>
<span class="ltx_bibblock">
Chen, Z., Cano, A. H., Romanou, A., Bonnet, A., Matoba, K., Salvi, F., Pagliardini, M., Fan, S., Köpf, A., Mohtashami, A., et al.

</span>
<span class="ltx_bibblock">Meditron-70b: Scaling medical pretraining for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2311.16079</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2024)</span>
<span class="ltx_bibblock">
Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">JMLR</em>, 25(70), 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conover et al. (2023)</span>
<span class="ltx_bibblock">
Conover, M., Hayes, M., Mathur, A., Xie, J., Wan, J., Shah, S., Ghodsi, A., Wendell, P., Zaharia, M., and Xin, R.

</span>
<span class="ltx_bibblock">Free Dolly: Introducing the world’s first truly open instruction-tuned llm, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dasigi et al. (2019)</span>
<span class="ltx_bibblock">
Dasigi, P., Liu, N. F., Marasović, A., Smith, N. A., and Gardner, M.

</span>
<span class="ltx_bibblock">Quoref: A reading comprehension dataset with questions requiring coreferential reasoning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">EMNLP</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeepSeek (2024)</span>
<span class="ltx_bibblock">
DeepSeek.

</span>
<span class="ltx_bibblock">Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022)</span>
<span class="ltx_bibblock">
Du, N., Huang, Y., Dai, A. M., Tong, S., Lepikhin, D., Xu, Y., Krikun, M., Zhou, Y., Yu, A. W., Firat, O., et al.

</span>
<span class="ltx_bibblock">Glam: Efficient scaling of language models with mixture-of-experts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">ICML</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et al. (2019)</span>
<span class="ltx_bibblock">
Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M.

</span>
<span class="ltx_bibblock">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">NAACL</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. (2019)</span>
<span class="ltx_bibblock">
Fan, A., Jernite, Y., Perez, E., Grangier, D., Weston, J., and Auli, M.

</span>
<span class="ltx_bibblock">Eli5: Long form question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">ACL</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2020)</span>
<span class="ltx_bibblock">
Feng, S., Wan, H., Gunasekara, C., Patel, S., Joshi, S., and Lastras, L.

</span>
<span class="ltx_bibblock">doc2dial: A goal-oriented document-grounded dialogue dataset.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">EMNLP</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glass et al. (2022)</span>
<span class="ltx_bibblock">
Glass, M., Rossiello, G., Chowdhury, M. F. M., Naik, A., Cai, P., and Gliozzo, A.

</span>
<span class="ltx_bibblock">Re2G: Retrieve, rerank, generate.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">NAACL</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et al. (2020)</span>
<span class="ltx_bibblock">
Guu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M.

</span>
<span class="ltx_bibblock">Retrieval augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">ICML</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021)</span>
<span class="ltx_bibblock">
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">ICLR</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2020)</span>
<span class="ltx_bibblock">
Ho, X., Nguyen, A.-K. D., Sugawara, S., and Aizawa, A.

</span>
<span class="ltx_bibblock">Constructing a multi-hop qa dataset for comprehensive evaluation of reasoning steps.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">COLING</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et al. (2023)</span>
<span class="ltx_bibblock">
Honovich, O., Scialom, T., Levy, O., and Schick, T.

</span>
<span class="ltx_bibblock">Unnatural instructions: Tuning language models with (almost) no human labor.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">ACL</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
Huang, J., Ping, W., Xu, P., Shoeybi, M., Chang, K. C.-C., and Catanzaro, B.

</span>
<span class="ltx_bibblock">Raven: In-context learning with retrieval augmented encoder-decoder language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2308.07922</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard &amp; Grave (2021)</span>
<span class="ltx_bibblock">
Izacard, G. and Grave, E.

</span>
<span class="ltx_bibblock">Leveraging passage retrieval with generative models for open domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">EACL</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2022)</span>
<span class="ltx_bibblock">
Izacard, G., Caron, M., Hosseini, L., Riedel, S., Bojanowski, P., Joulin, A., and Grave, E.

</span>
<span class="ltx_bibblock">Unsupervised dense information retrieval with contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">TMLR</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2023)</span>
<span class="ltx_bibblock">
Izacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., and Grave, E.

</span>
<span class="ltx_bibblock">Atlas: Few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">JMLR</em>, 24(251):1–43, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong et al. (2024)</span>
<span class="ltx_bibblock">
Jeong, S., Baek, J., Cho, S., Hwang, S. J., and Park, J. C.

</span>
<span class="ltx_bibblock">Adaptive-rag: Learning to adapt retrieval-augmented large language models through question complexity.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">NAACL</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., Chaplot, D. S., Casas, D. d. l., Hanna, E. B., et al.

</span>
<span class="ltx_bibblock">Mixtral of experts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2401.04088</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Jiang, Z., Xu, F. F., Gao, L., Sun, Z., Liu, Q., Dwivedi-Yu, J., Yang, Y., Callan, J., and Neubig, G.

</span>
<span class="ltx_bibblock">Active retrieval augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">EMNLP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2021)</span>
<span class="ltx_bibblock">
Jin, D., Pan, E., Oufattole, N., Weng, W.-H., Fang, H., and Szolovits, P.

</span>
<span class="ltx_bibblock">What disease does this patient have? a large-scale open domain question answering dataset from medical exams.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Applied Sciences</em>, 11(14):6421, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2019)</span>
<span class="ltx_bibblock">
Jin, Q., Dhingra, B., Liu, Z., Cohen, W., and Lu, X.

</span>
<span class="ltx_bibblock">Pubmedqa: A dataset for biomedical research question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">EMNLP</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2023)</span>
<span class="ltx_bibblock">
Jin, Q., Kim, W., Chen, Q., Comeau, D. C., Yeganova, L., Wilbur, W. J., and Lu, Z.

</span>
<span class="ltx_bibblock">Medcpt: Contrastive pre-trained transformers with large-scale pubmed search logs for zero-shot biomedical information retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Bioinformatics</em>, 39(11), 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et al. (2017)</span>
<span class="ltx_bibblock">
Joshi, M., Choi, E., Weld, D., and Zettlemoyer, L.

</span>
<span class="ltx_bibblock">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ACL</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W.-t.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">EMNLP</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasai et al. (2023)</span>
<span class="ltx_bibblock">
Kasai, J., Sakaguchi, K., yoichi takahashi, Bras, R. L., Asai, A., Yu, X. V., Radev, D., Smith, N. A., Choi, Y., and Inui, K.

</span>
<span class="ltx_bibblock">Realtime QA: What’s the answer right now?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">NeurIPS</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalifa et al. (2023)</span>
<span class="ltx_bibblock">
Khalifa, M., Logeswaran, L., Lee, M., Lee, H., and Wang, L.

</span>
<span class="ltx_bibblock">Few-shot reranking for multi-hop QA via language model prompting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">ACL</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab et al. (2022)</span>
<span class="ltx_bibblock">
Khattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M.

</span>
<span class="ltx_bibblock">Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2212.14024</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023)</span>
<span class="ltx_bibblock">
Kim, H., Hessel, J., Jiang, L., Lu, X., Yu, Y., Zhou, P., Bras, R. L., Alikhani, M., Kim, G., Sap, M., et al.

</span>
<span class="ltx_bibblock">Soda: Million-scale dialogue distillation with social commonsense contextualization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">EMNLP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Ba (2014)</span>
<span class="ltx_bibblock">
Kingma, D. P. and Ba, J.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kočiskỳ et al. (2018)</span>
<span class="ltx_bibblock">
Kočiskỳ, T., Schwarz, J., Blunsom, P., Dyer, C., Hermann, K. M., Melis, G., and Grefenstette, E.

</span>
<span class="ltx_bibblock">The narrativeqa reading comprehension challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">TACL</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al. (2019)</span>
<span class="ltx_bibblock">
Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., et al.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">TACL</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köpf et al. (2023)</span>
<span class="ltx_bibblock">
Köpf, A., Kilcher, Y., von Rütte, D., Anagnostidis, S., Tam, Z.-R., Stevens, K., Barhoum, A., Duc, N. M., Stanley, O., Nagyfi, R., ES, S., Suri, S., Glushkov, D., Dantuluri, A., Maguire, A., Schuhmann, C., Nguyen, H., and Mattick, A.

</span>
<span class="ltx_bibblock">Openassistant conversations - democratizing large language model alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv: 2304.07327</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lazaridou et al. (2022)</span>
<span class="ltx_bibblock">
Lazaridou, A., Gribovskaya, E., Stokowiec, W., and Grigorev, N.

</span>
<span class="ltx_bibblock">Internet-augmented language models through few-shot prompting for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2203.05115</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2024)</span>
<span class="ltx_bibblock">
Lee, C., Roy, R., Xu, M., Raiman, J., Shoeybi, M., Catanzaro, B., and Ping, W.

</span>
<span class="ltx_bibblock">Nv-embed: Improved techniques for training llms as generalist embedding models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2405.17428</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., et al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">NeurIPS</em>, 33, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2019)</span>
<span class="ltx_bibblock">
Lin, K., Tafjord, O., Clark, P., and Gardner, M.

</span>
<span class="ltx_bibblock">Reasoning over paragraph effects in situations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Workshop on Machine Reading for Question Answering</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2023)</span>
<span class="ltx_bibblock">
Lin, S.-C., Asai, A., Li, M., Oguz, B., Lin, J., Mehdad, Y., Yih, W.-t., and Chen, X.

</span>
<span class="ltx_bibblock">How to train your dragon: Diverse augmentation towards generalizable dense retrieval.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Findings of EMNLP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
Lin, X. V., Chen, X., Chen, M., Shi, W., Lomeli, M., James, R., Rodriguez, P., Kahn, J., Szilvasy, G., Lewis, M., Zettlemoyer, L., and tau Yih, W.

</span>
<span class="ltx_bibblock">RA-DIT: Retrieval-augmented dual instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">ICLR</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Liu, Z., Ping, W., Roy, R., Xu, P., Shoeybi, M., and Catanzaro, B.

</span>
<span class="ltx_bibblock">Chatqa: Surpassing gpt-4 on conversational qa and rag.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2401.10225</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et al. (2023)</span>
<span class="ltx_bibblock">
Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H. W., Tay, Y., Zhou, D., Le, Q. V., et al.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">ICML</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luan et al. (2021)</span>
<span class="ltx_bibblock">
Luan, Y., Eisenstein, J., Toutanova, K., and Collins, M.

</span>
<span class="ltx_bibblock">Sparse, dense, and attentional representations for text retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">TACL</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2023)</span>
<span class="ltx_bibblock">
Luo, H., Chuang, Y.-S., Gong, Y., Zhang, T., Kim, Y., Wu, X., Fox, D., Meng, H., and Glass, J.

</span>
<span class="ltx_bibblock">Sail: Search-augmented instruction learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2305.15225</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Ma, X., Wang, L., Yang, N., Wei, F., and Lin, J.

</span>
<span class="ltx_bibblock">Fine-tuning llama for multi-stage text retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2310.08319</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallen et al. (2023)</span>
<span class="ltx_bibblock">
Mallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">ACL</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Menon et al. (2022)</span>
<span class="ltx_bibblock">
Menon, A., Jayasumana, S., Rawat, A. S., Kim, S., Reddi, S., and Kumar, S.

</span>
<span class="ltx_bibblock">In defense of dual-encoders for neural ranking.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">ICML</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meta-AI (2024)</span>
<span class="ltx_bibblock">
Meta-AI.

</span>
<span class="ltx_bibblock">Llama 3 model card.

</span>
<span class="ltx_bibblock">2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mistral (2024)</span>
<span class="ltx_bibblock">
Mistral.

</span>
<span class="ltx_bibblock">Mixtral 8x22b.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://mistral.ai/news/mixtral-8x22b/" title="">https://mistral.ai/news/mixtral-8x22b/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra et al. (2018)</span>
<span class="ltx_bibblock">
Mitra, B., Craswell, N., et al.

</span>
<span class="ltx_bibblock">An introduction to neural information retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Foundations and Trends® in Information Retrieval</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et al. (2024)</span>
<span class="ltx_bibblock">
Muennighoff, N., Su, H., Wang, L., Yang, N., Wei, F., Yu, T., Singh, A., and Kiela, D.

</span>
<span class="ltx_bibblock">Generative representational instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2402.09906</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nogueira et al. (2020)</span>
<span class="ltx_bibblock">
Nogueira, R., Jiang, Z., Pradeep, R., and Lin, J.

</span>
<span class="ltx_bibblock">Document ranking with a pretrained sequence-to-sequence model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Findings of EMNLP</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Introducing ChatGPT, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oren et al. (2024)</span>
<span class="ltx_bibblock">
Oren, Y., Meister, N., Chatterji, N. S., Ladhak, F., and Hashimoto, T.

</span>
<span class="ltx_bibblock">Proving test set contamination in black-box language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">ICLR</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">NeurIPS</em>, 35, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal et al. (2022)</span>
<span class="ltx_bibblock">
Pal, A., Umapathi, L. K., and Sankarasubbu, M.

</span>
<span class="ltx_bibblock">Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">CHIL</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et al. (2021)</span>
<span class="ltx_bibblock">
Petroni, F., Piktus, A., Fan, A., Lewis, P., Yazdani, M., De Cao, N., Thorne, J., Jernite, Y., Karpukhin, V., Maillard, J., Plachouras, V., Rocktäschel, T., and Riedel, S.

</span>
<span class="ltx_bibblock">KILT: a benchmark for knowledge intensive language tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">NAACL</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al. (2024)</span>
<span class="ltx_bibblock">
Qin, Z., Jagerman, R., Hui, K., Zhuang, H., Wu, J., Shen, J., Liu, T., Liu, J., Metzler, D., Wang, X., et al.

</span>
<span class="ltx_bibblock">Large language models are effective text rankers with pairwise ranking prompting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">Findings of NAACL</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al. (2016)</span>
<span class="ltx_bibblock">
Rajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P.

</span>
<span class="ltx_bibblock">Squad: 100,000+ questions for machine comprehension of text.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">EMNLP</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram et al. (2023)</span>
<span class="ltx_bibblock">
Ram, O., Levine, Y., Dalmedigos, I., Muhlgay, D., Shashua, A., Leyton-Brown, K., and Shoham, Y.

</span>
<span class="ltx_bibblock">In-context retrieval-augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">TACL</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et al. (2004)</span>
<span class="ltx_bibblock">
Robertson, S., Zaragoza, H., and Taylor, M.

</span>
<span class="ltx_bibblock">Simple bm25 extension to multiple weighted fields.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">CIKM</em>, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et al. (2021)</span>
<span class="ltx_bibblock">
Sachan, D. S., Reddy, S., Hamilton, W. L., Dyer, C., and Yogatama, D.

</span>
<span class="ltx_bibblock">End-to-end training of multi-document reader and retriever for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">NeurIPS</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao et al. (2023)</span>
<span class="ltx_bibblock">
Shao, Z., Gong, Y., Shen, Y., Huang, M., Duan, N., and Chen, W.

</span>
<span class="ltx_bibblock">Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Findings of EMNLP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2024)</span>
<span class="ltx_bibblock">
Shi, W., Min, S., Yasunaga, M., Seo, M., James, R., Lewis, M., Zettlemoyer, L., and Yih, W.-t.

</span>
<span class="ltx_bibblock">Replug: Retrieval-augmented black-box language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">NAACL</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Sun, W., Yan, L., Ma, X., Wang, S., Ren, P., Chen, Z., Yin, D., and Ren, Z.

</span>
<span class="ltx_bibblock">Is ChatGPT good at search? investigating large language models as re-ranking agents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">EMNLP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et al. (2021)</span>
<span class="ltx_bibblock">
Thakur, N., Reimers, N., Rücklé, A., Srivastava, A., and Gurevych, I.

</span>
<span class="ltx_bibblock">Beir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">NeurIPS</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thorne et al. (2018)</span>
<span class="ltx_bibblock">
Thorne, J., Vlachos, A., Christodoulopoulos, C., and Mittal, A.

</span>
<span class="ltx_bibblock">Fever: A large-scale dataset for fact extraction and verification.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">NAACL</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trischler et al. (2017)</span>
<span class="ltx_bibblock">
Trischler, A., Wang, T., Yuan, X., Harris, J., Sordoni, A., Bachman, P., and Suleman, K.

</span>
<span class="ltx_bibblock">Newsqa: A machine comprehension dataset.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">RepL4NLP Workshop at ACL</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trivedi et al. (2023)</span>
<span class="ltx_bibblock">
Trivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A.

</span>
<span class="ltx_bibblock">Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">ACL</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsatsaronis et al. (2015)</span>
<span class="ltx_bibblock">
Tsatsaronis, G., Balikas, G., Malakasiotis, P., Partalas, I., Zschunke, M., Alvers, M. R., Weissenborn, D., Krithara, A., Petridis, S., Polychronopoulos, D., et al.

</span>
<span class="ltx_bibblock">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">BMC bioinformatics</em>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Wang, B., Ping, W., McAfee, L., Xu, P., Li, B., Shoeybi, M., and Catanzaro, B.

</span>
<span class="ltx_bibblock">Instructretro: Instruction tuning post retrieval-augmented pretraining.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">ICML</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Wang, L., Yang, N., Huang, X., Jiao, B., Yang, L., Jiang, D., Majumder, R., and Wei, F.

</span>
<span class="ltx_bibblock">Text embeddings by weakly-supervised contrastive pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">arXiv preprint arXiv:2212.03533</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Wang, L., Yang, N., Huang, X., Yang, L., Majumder, R., and Wei, F.

</span>
<span class="ltx_bibblock">Improving text embeddings with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">arXiv preprint arXiv:2401.00368</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A., Khashabi, D., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">ACL</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023c)</span>
<span class="ltx_bibblock">
Wang, Z., Araki, J., Jiang, Z., Parvez, M. R., and Neubig, G.

</span>
<span class="ltx_bibblock">Learning to filter context for retrieval-augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">arXiv preprint arXiv:2311.08377</em>, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">ICLR</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2024)</span>
<span class="ltx_bibblock">
Wu, C., Lin, W., Zhang, X., Zhang, Y., Xie, W., and Wang, Y.

</span>
<span class="ltx_bibblock">Pmc-llama: toward building open-source language models for medicine.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">JAMIA</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Wu, Z., Parish, R., Cheng, H., Min, S., Ammanabrolu, P., Ostendorf, M., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Inscit: Information-seeking conversations with mixed-initiative interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">TACL</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al. (2024)</span>
<span class="ltx_bibblock">
Xiong, G., Jin, Q., Lu, Z., and Zhang, A.

</span>
<span class="ltx_bibblock">Benchmarking retrieval-augmented generation for medicine.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">arXiv preprint arXiv:2402.13178</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024a)</span>
<span class="ltx_bibblock">
Xu, F., Shi, W., and Choi, E.

</span>
<span class="ltx_bibblock">RECOMP: Improving retrieval-augmented LMs with context compression and selective augmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">ICLR</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024b)</span>
<span class="ltx_bibblock">
Xu, P., Ping, W., Wu, X., McAfee, L., Zhu, C., Liu, Z., Subramanian, S., Bakhturina, E., Shoeybi, M., and Catanzaro, B.

</span>
<span class="ltx_bibblock">Retrieval meets long context large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">ICLR</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2018)</span>
<span class="ltx_bibblock">
Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W. W., Salakhutdinov, R., and Manning, C. D.

</span>
<span class="ltx_bibblock">HotpotQA: A dataset for diverse, explainable multi-hop question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">EMNLP</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoran et al. (2024)</span>
<span class="ltx_bibblock">
Yoran, O., Wolfson, T., Ram, O., and Berant, J.

</span>
<span class="ltx_bibblock">Making retrieval-augmented language models robust to irrelevant context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">ICLR</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023a)</span>
<span class="ltx_bibblock">
Yu, W., Iter, D., Wang, S., Xu, Y., Ju, M., Sanyal, S., Zhu, C., Zeng, M., and Jiang, M.

</span>
<span class="ltx_bibblock">Generate rather than retrieve: Large language models are strong context generators.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">ICLR</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023b)</span>
<span class="ltx_bibblock">
Yu, W., Zhang, H., Pan, X., Ma, K., Wang, H., and Yu, D.

</span>
<span class="ltx_bibblock">Chain-of-note: Enhancing robustness in retrieval-augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">arXiv preprint arXiv:2311.09210</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Yu, W., Zhang, Z., Liang, Z., Jiang, M., and Sabharwal, A.

</span>
<span class="ltx_bibblock">Improving language models via plug-and-play retrieval feedback, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Yu, Y., Xiong, C., Sun, S., Zhang, C., and Overwijk, A.

</span>
<span class="ltx_bibblock">Coco-dr: Combating distribution shift in zero-shot dense retrieval with contrastive and distributionally robust learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">EMNLP</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Zhang, T., Patil, S. G., Jain, N., Shen, S., Zaharia, M., Stoica, I., and Gonzalez, J. E.

</span>
<span class="ltx_bibblock">Raft: Adapting language model to domain specific rag.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">arXiv preprint arXiv:2403.10131</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
Zhu, F., Lei, W., Huang, Y., Wang, C., Zhang, S., Lv, J., Feng, F., and Chua, T.-S.

</span>
<span class="ltx_bibblock">Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">ACL</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2024)</span>
<span class="ltx_bibblock">
Zhu, Y., Zhang, P., Zhang, C., Chen, Y., Xie, B., Dou, Z., Liu, Z., and Wen, J.-R.

</span>
<span class="ltx_bibblock">Inters: Unlocking the power of large language models in search with instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">ACL</em>, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset Description</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">The information for 14 datasets used in RankRAG is listed as follows.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Main Experiments</h3>
<div class="ltx_para" id="A1.SS1.p1">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">NQ</span> <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib42" title="">2019</a>)</cite> is a widely used question-answering dataset constructed with Wikipedia. The questions are constructed from the Google search engine, and the answers are identified as text spans in the Wikipedia article.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">TriviaQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib34" title="">2017</a>)</cite> is a challenging QA dataset containing question-answer pairs from trivia enthusiasts and independently gathered evidence documents.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i3.p1.1.1">PopQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Mallen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib55" title="">2023</a>)</cite> is an entity-centric QA dataset concentrated on long-tail entities. For PopQA, we follow <cite class="ltx_cite ltx_citemacro_citep">(Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib4" title="">2024a</a>)</cite> to use the long-tail subset, consisting of questions on 1399 rare entities whose monthly Wikipedia page views are less than 100.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i4.p1.1.1">HotpotQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib93" title="">2018</a>)</cite> is a multi-hop QA dataset, where the goal is to answer complex questions that require understanding and linking information from multiple documents.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i5.p1.1.1">2WikimQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib22" title="">2020</a>)</cite> is also a multi-hop QA designed to test machine understanding across two different Wikipedia entities, evaluating the ability of systems to handle cross-lingual and cross-cultural retrieval and question answering.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p" id="A1.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i6.p1.1.1">FEVER</span> <cite class="ltx_cite ltx_citemacro_citep">(Thorne et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib77" title="">2018</a>)</cite> is a fact verification dataset aimed at supporting research into the automatic verification of factual claims. It consists of claims that are manually verified against evidence from Wikipedia, providing a benchmark for fact-checking systems. </p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i7.p1">
<p class="ltx_p" id="A1.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i7.p1.1.1">Doc2Dial</span> <cite class="ltx_cite ltx_citemacro_citep">(Feng et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib18" title="">2020</a>)</cite> is a document-grounded conversational QA dataset covering four domains: DMV, SSA, VA, and Student Aid. Each sample comprises a dialogue where a user poses queries regarding the document, and an agent responds those questions. The average document length is around 101K words.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i8.p1">
<p class="ltx_p" id="A1.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i8.p1.1.1">TopiOCQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Adlakha et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib1" title="">2022</a>)</cite> is grounded on the whole Wikipedia. It incorporates topic switching and requires the agent to search the entire Wikipedia for answers to user questions. </p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i9.p1">
<p class="ltx_p" id="A1.I1.i9.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i9.p1.1.1">INSCIT</span> <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib89" title="">2023</a>)</cite> is also grounded on the whole Wikipedia. It studies the case where user questions are under-specified and require clarification.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Biomedical Benchmarks</h3>
<div class="ltx_para" id="A1.SS2.p1">
<ul class="ltx_itemize" id="A1.I2">
<li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i1.p1">
<p class="ltx_p" id="A1.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i1.p1.1.1">MMLU-med</span> <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib21" title="">2021</a>)</cite> is a subset of six tasks related to biomedicine, including anatomy, clinical knowledge, professional medicine, human genetics, college medicine, and college biology. It contains 1089 questions in total.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i2.p1">
<p class="ltx_p" id="A1.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i2.p1.1.1">MedQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib31" title="">2021</a>)</cite> is collected from the US Medical Licensing Examination, contaiing 1273 four-option multiple-choice questions focused on real-world scenarios from professional medical board exams.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i3.p1">
<p class="ltx_p" id="A1.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i3.p1.1.1">MedMCQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Pal et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib66" title="">2022</a>)</cite> includes multiple-choice questions derived from Indian medical entrance exams, covering 2400 healthcare topics across 21 medical subjects. We use the 4,183-question development set from MedMCQA, as the test set lacks provided ground truths.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i4.p1">
<p class="ltx_p" id="A1.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i4.p1.1.1">PubmedQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib32" title="">2019</a>)</cite> is a biomedical research QA dataset consisting of 1000 manually annotated questions based on PubMed abstracts. Answers in PubMedQA are structured as yes/no/maybe to reflect the validity of the questions.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i5.p1">
<p class="ltx_p" id="A1.I2.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i5.p1.1.1">BioASQ</span> <cite class="ltx_cite ltx_citemacro_citep">(Tsatsaronis et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib81" title="">2015</a>)</cite> includes 618 questions constructed from biomedical literature without providing the ground truth snippets, challenging RAG systems to infer answers independently.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Data Blending Details for Ranking-enhanced Instruction Finetuning</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">The dataset blending ratio for Stage-II is as follows:</p>
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1">Drop: 0.069</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1">narrativeqa: 0.09</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1">quoref: 0.026</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i4.p1">
<p class="ltx_p" id="A2.I1.i4.p1.1">ropes: 0.026</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i5.p1">
<p class="ltx_p" id="A2.I1.i5.p1.1">Squad (Retrieval-augmented QA): 0.09</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i6.p1">
<p class="ltx_p" id="A2.I1.i6.p1.1">Squad (Retrieval-augmented Ranking): 0.02</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i7.p1">
<p class="ltx_p" id="A2.I1.i7.p1.1">WebQuestions (Retrieval-augmented QA): 0.09</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i8.p1">
<p class="ltx_p" id="A2.I1.i8.p1.1">WebQuestions (Retrieval-augmented Ranking): 0.02</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i9.p1">
<p class="ltx_p" id="A2.I1.i9.p1.1">newsqa: 0.09</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i10.p1">
<p class="ltx_p" id="A2.I1.i10.p1.1">tatqa-arithmetic: 0.15</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i11.p1">
<p class="ltx_p" id="A2.I1.i11.p1.1">tatqa-others: 0.08</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i12" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i12.p1">
<p class="ltx_p" id="A2.I1.i12.p1.1">ConvQA: 0.2</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i13" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i13.p1">
<p class="ltx_p" id="A2.I1.i13.p1.1">MS MARCO ranking: 0.15</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i14" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i14.p1">
<p class="ltx_p" id="A2.I1.i14.p1.1">ConvQA ranking: 0.03</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i15" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i15.p1">
<p class="ltx_p" id="A2.I1.i15.p1.1">SFT: 0.2</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">The ratio for each dataset is further normalized to ensure the total ratio equals to 1.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prompt Formats of Instruction Tuning</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Stage I: Supervised Fine-tuning</h3>
<div class="ltx_para" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">The format template of LLM inputs in stage-I is as follows:</p>
</div>
<div class="ltx_para" id="A3.SS1.p2">
<pre class="ltx_verbatim ltx_font_typewriter" id="A3.SS1.p2.1">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

User: {Question 1}

Assistant: {Answer 1}

...

User: {Latest Question}

Assistant:
</pre>
</div>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Stage-II: Unified Instruction-Tuning for Ranking and Generation</h3>
<div class="ltx_para" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">The format template of LLM inputs in stage-II are as follows:</p>
</div>
<div class="ltx_para" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.1">1) Context-rich QA data</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A3.SS2.p2.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage: {(Gold) Passage containing relevant context for QA}

User: {Question 1}

Assistant: {Answer 1}

...

User: {Latest Question}

Assistant:
</pre>
</div>
<div class="ltx_para" id="A3.SS2.p3">
<p class="ltx_p" id="A3.SS2.p3.1">We tailor specific user instructions for various dataset types. For instance:</p>
</div>
<div class="ltx_para" id="A3.SS2.p4">
<p class="ltx_p" id="A3.SS2.p4.1">For datasets requiring short answers (such as DROP, NarrativeQA, Quoref, ROPES, SQuAD1.1, SQuAD2.0, NewsQA), we use: "Answer the following question with a short span."</p>
</div>
<div class="ltx_para" id="A3.SS2.p5">
<p class="ltx_p" id="A3.SS2.p5.1">For datasets that necessitate long answers (such as Synthetic_ConvQA), we instruct: "Please give a full and complete answer for the question."</p>
</div>
<div class="ltx_para" id="A3.SS2.p6">
<p class="ltx_p" id="A3.SS2.p6.1">For datasets involving arithmetic calculations or number extraction from the context (such as TAT-QA), we specify: "Answer the following question with a number from the context or through math arithmetic."</p>
</div>
<div class="ltx_para" id="A3.SS2.p7">
<p class="ltx_p" id="A3.SS2.p7.1">For datasets that may require both short and long answers (such as TAT-QA-Others), we direct: "Answer the following question with a short span, or a full and complete answer."</p>
</div>
<div class="ltx_para" id="A3.SS2.p8">
<p class="ltx_p" id="A3.SS2.p8.1">2) Retrieval-augmented QA data</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A3.SS2.p8.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage 1: {(Shuffled) Passage 1}

Passage 2: {(Shuffled) Passage 2}

Passage 3: {(Shuffled) Passage 3}

Passage 4: {(Shuffled) Passage 4}

Passage 5: {(Shuffled) Passage 5}

...

User: {Question}

Assistant:
</pre>
</div>
<div class="ltx_para" id="A3.SS2.p9">
<p class="ltx_p" id="A3.SS2.p9.1">3) Context ranking data</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A3.SS2.p9.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage: {Passage 1}

User: {For the question &lt;question&gt;, access whether the passage is relevant to the
question. Return True if relevant, otherwise False. }

Assistant:
</pre>
</div>
<div class="ltx_para" id="A3.SS2.p10">
<p class="ltx_p" id="A3.SS2.p10.1">4) Retrieval-augmented ranking data</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A3.SS2.p10.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage 1: {(Shuffled) Passage 1}

Passage 2: {(Shuffled) Passage 2}

Passage 3: {(Shuffled) Passage 3}

Passage 4: {(Shuffled) Passage 4}

Passage 5: {(Shuffled) Passage 5}

User: {For the question &lt;question&gt;, access whether the above passages are relevant
to the question. Return all the relevant passage id. }

Assistant:
</pre>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Prompt Formats of Target Tasks</h2>
<section class="ltx_subsection" id="A4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Context Ranking</h3>
<div class="ltx_para" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">NQ/TriviaQA/HotpotQA/PopQA:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A4.SS1.p1.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage: {Passage}

User: {For the question &lt;question&gt;, access whether the passage is relevant to the
question. Return True if relevant, otherwise False. }

Assistant:
</pre>
</div>
<div class="ltx_para" id="A4.SS1.p2">
<p class="ltx_p" id="A4.SS1.p2.1">FEVER:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A4.SS1.p2.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage: {Passage}

User: {For the claim &lt;claim&gt;, access whether the passage is relevant to the
claim. Return True if relevant, otherwise False. }

Assistant:
</pre>
</div>
<div class="ltx_para" id="A4.SS1.p3">
<p class="ltx_p" id="A4.SS1.p3.1">Doc2dial, Inscit, TopiocQA:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A4.SS1.p3.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage: {Passage}

User: {Question 1}

Assistant: {Answer 1}

...

User: {For the question &lt;latest question&gt;, access whether the passage is relevant
to the question. Return True if relevant, otherwise False. }

Assistant:
</pre>
</div>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>RAG</h3>
<div class="ltx_para" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.1">NQ/TriviaQA/HotpotQA/PopQA:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A4.SS2.p1.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage 1: {Rerank Top Passage 1}

Passage 2: {Rerank Top Passage 2}

Passage 3: {Rerank Top Passage 3}

Passage 4: {Rerank Top Passage 4}

Passage 5: {Rerank Top Passage 5}

...

User: {Question}. Answer the above question with a short phrase.

Assistant:
</pre>
</div>
<div class="ltx_para" id="A4.SS2.p2">
<p class="ltx_p" id="A4.SS2.p2.1">Fever:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A4.SS2.p2.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage 1: {Rerank Top Passage 1}

Passage 2: {Rerank Top Passage 2}

Passage 3: {Rerank Top Passage 3}

Passage 4: {Rerank Top Passage 4}

Passage 5: {Rerank Top Passage 5}

...

User: Answer the following question with True or False. Is the claim ’&lt;claim&gt;’ correct?

Assistant:
</pre>
</div>
<div class="ltx_para" id="A4.SS2.p3">
<p class="ltx_p" id="A4.SS2.p3.1">Doc2dial, Inscit, TopiOCQA:</p>
<pre class="ltx_verbatim ltx_font_typewriter" id="A4.SS2.p3.2">
System: This is a chat between a user and an artificial intelligence assistant.
The assistant gives helpful, detailed, and polite answers to the user’s questions
based on the context. The assistant should also indicate when the answer cannot be
found in the context.

Passage 1: {Rerank Top Passage 1}

Passage 2: {Rerank Top Passage 2}

Passage 3: {Rerank Top Passage 3}

Passage 4: {Rerank Top Passage 4}

Passage 5: {Rerank Top Passage 5}

User: {Question 1}

Assistant: {Answer 1}

...
User: {Latest Question}

Assistant:
</pre>
</div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional Experiment Results</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Ranking Performance Using DPR and Contriever as Retrievers <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="A5.SS1.1.m1.1"><semantics id="A5.SS1.1.m1.1b"><mi class="ltx_font_mathcaligraphic" id="A5.SS1.1.m1.1.1" xref="A5.SS1.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.1.m1.1c"><ci id="A5.SS1.1.m1.1.1.cmml" xref="A5.SS1.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.1.m1.1d">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.1.m1.1e">caligraphic_R</annotation></semantics></math>
</h3>
<div class="ltx_para" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A5.T8" title="Table 8 ‣ E.1 Ranking Performance Using DPR and Contriever as Retrievers ℛ ‣ Appendix E Additional Experiment Results ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">8</span></a> shows the ranking performance of RankRAG-8B using DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>)</cite> and Contriever <cite class="ltx_cite ltx_citemacro_citep">(Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib26" title="">2022</a>)</cite> on three datasets. There are consistent performance gains for all tasks, indicating that RankRAG can apply to many popular retrieval models to improve the quality of retrieved contents.</p>
</div>
<figure class="ltx_table" id="A5.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A5.T8.2.1.1" style="font-size:90%;">Table 8</span>: </span><span class="ltx_text" id="A5.T8.3.2" style="font-size:90%;">Answer Recall Comparison Before and After Ranking on 3 Representative Datasets.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A5.T8.4" style="width:325.2pt;height:201.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.0pt,7.4pt) scale(0.931502805680792,0.931502805680792) ;">
<table class="ltx_tabular ltx_align_middle" id="A5.T8.4.1">
<tr class="ltx_tr" id="A5.T8.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A5.T8.4.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.1.1.1">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A5.T8.4.1.1.2"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.1.2.1">DPR</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A5.T8.4.1.1.3"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.1.3.1">Contriever</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.2.1">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.2.2">R@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.2.3">R@20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.2.4">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.2.5">R@10</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T8.4.1.2.6">R@20</td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T8.4.1.3.1">Before Ranking</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.3.2">69.50%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.3.3">76.20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.3.4">81.00%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.3.5">67.60%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.3.6">75.24%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T8.4.1.3.7">80.67%</td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.4" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left" id="A5.T8.4.1.4.1"><span class="ltx_text" id="A5.T8.4.1.4.1.1" style="background-color:#E0F3EB;">     w/ RankRAG</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.4.2"><span class="ltx_text" id="A5.T8.4.1.4.2.1" style="background-color:#E0F3EB;">77.95%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.4.3"><span class="ltx_text" id="A5.T8.4.1.4.3.1" style="background-color:#E0F3EB;">81.70%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.4.4"><span class="ltx_text" id="A5.T8.4.1.4.4.1" style="background-color:#E0F3EB;">84.56%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.4.5"><span class="ltx_text" id="A5.T8.4.1.4.5.1" style="background-color:#E0F3EB;">75.32%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.4.6"><span class="ltx_text" id="A5.T8.4.1.4.6.1" style="background-color:#E0F3EB;">80.18%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T8.4.1.4.7"><span class="ltx_text" id="A5.T8.4.1.4.7.1" style="background-color:#E0F3EB;">84.70%</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T8.4.1.5.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.5.1.1">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A5.T8.4.1.5.2"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.5.2.1">DPR</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A5.T8.4.1.5.3"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.5.3.1">Contriever</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.6.1">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.6.2">R@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.6.3">R@20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.6.4">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.6.5">R@10</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T8.4.1.6.6">R@20</td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T8.4.1.7.1">Before Ranking</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.7.2">67.80%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.7.3">74.20%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.7.4">80.30%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.7.5">81.95%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.7.6">86.76%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T8.4.1.7.7">90.08%</td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.8" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left" id="A5.T8.4.1.8.1"><span class="ltx_text" id="A5.T8.4.1.8.1.1" style="background-color:#E0F3EB;">     w/ RankRAG</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.8.2"><span class="ltx_text" id="A5.T8.4.1.8.2.1" style="background-color:#E0F3EB;">77.73%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.8.3"><span class="ltx_text" id="A5.T8.4.1.8.3.1" style="background-color:#E0F3EB;">79.40%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.8.4"><span class="ltx_text" id="A5.T8.4.1.8.4.1" style="background-color:#E0F3EB;">84.74%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.8.5"><span class="ltx_text" id="A5.T8.4.1.8.5.1" style="background-color:#E0F3EB;">88.71%</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.4.1.8.6"><span class="ltx_text" id="A5.T8.4.1.8.6.1" style="background-color:#E0F3EB;">90.05%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T8.4.1.8.7"><span class="ltx_text" id="A5.T8.4.1.8.7.1" style="background-color:#E0F3EB;">92.59%</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T8.4.1.9.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.9.1.1">PopQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A5.T8.4.1.9.2"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.9.2.1">DPR</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A5.T8.4.1.9.3"><span class="ltx_text ltx_font_bold" id="A5.T8.4.1.9.3.1">Contriever</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.10">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.10.1">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.10.2">R@10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.10.3">R@20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.10.4">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.10.5">R@10</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T8.4.1.10.6">R@20</td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="A5.T8.4.1.11.1">Before Ranking</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.11.2">43.60%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.11.3">48.90%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.11.4">54.25%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.11.5">60.61%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.4.1.11.6">65.54%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T8.4.1.11.7">69.90%</td>
</tr>
<tr class="ltx_tr" id="A5.T8.4.1.12" style="background-color:#E0F3EB;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A5.T8.4.1.12.1"><span class="ltx_text" id="A5.T8.4.1.12.1.1" style="background-color:#E0F3EB;">     w/ RankRAG</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.4.1.12.2"><span class="ltx_text" id="A5.T8.4.1.12.2.1" style="background-color:#E0F3EB;">50.32%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.4.1.12.3"><span class="ltx_text" id="A5.T8.4.1.12.3.1" style="background-color:#E0F3EB;">53.75%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.4.1.12.4"><span class="ltx_text" id="A5.T8.4.1.12.4.1" style="background-color:#E0F3EB;">57.76%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.4.1.12.5"><span class="ltx_text" id="A5.T8.4.1.12.5.1" style="background-color:#E0F3EB;">65.11%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.4.1.12.6"><span class="ltx_text" id="A5.T8.4.1.12.6.1" style="background-color:#E0F3EB;">68.41%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="A5.T8.4.1.12.7"><span class="ltx_text" id="A5.T8.4.1.12.7.1" style="background-color:#E0F3EB;">71.77%</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>RAG Performance with Different <math alttext="k" class="ltx_Math" display="inline" id="A5.SS2.1.m1.1"><semantics id="A5.SS2.1.m1.1b"><mi id="A5.SS2.1.m1.1.1" xref="A5.SS2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.1.m1.1c"><ci id="A5.SS2.1.m1.1.1.cmml" xref="A5.SS2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.1.m1.1e">italic_k</annotation></semantics></math>
</h3>
<div class="ltx_para" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.2">We also show the performance of RankRAG with different context size <math alttext="k" class="ltx_Math" display="inline" id="A5.SS2.p1.1.m1.1"><semantics id="A5.SS2.p1.1.m1.1a"><mi id="A5.SS2.p1.1.m1.1.1" xref="A5.SS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.1.m1.1b"><ci id="A5.SS2.p1.1.m1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p1.1.m1.1d">italic_k</annotation></semantics></math> in figure <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A5.F11" title="Figure 11 ‣ E.2 RAG Performance with Different 𝑘 ‣ Appendix E Additional Experiment Results ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">11</span></a>.
From the result, we observe that different from the trend of vanilla RAG approaches (without ranking), <math alttext="k=5" class="ltx_Math" display="inline" id="A5.SS2.p1.2.m2.1"><semantics id="A5.SS2.p1.2.m2.1a"><mrow id="A5.SS2.p1.2.m2.1.1" xref="A5.SS2.p1.2.m2.1.1.cmml"><mi id="A5.SS2.p1.2.m2.1.1.2" xref="A5.SS2.p1.2.m2.1.1.2.cmml">k</mi><mo id="A5.SS2.p1.2.m2.1.1.1" xref="A5.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="A5.SS2.p1.2.m2.1.1.3" xref="A5.SS2.p1.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.2.m2.1b"><apply id="A5.SS2.p1.2.m2.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1"><eq id="A5.SS2.p1.2.m2.1.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1.1"></eq><ci id="A5.SS2.p1.2.m2.1.1.2.cmml" xref="A5.SS2.p1.2.m2.1.1.2">𝑘</ci><cn id="A5.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="A5.SS2.p1.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.2.m2.1c">k=5</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p1.2.m2.1d">italic_k = 5</annotation></semantics></math> already works well for most datasets. This effectiveness stems from the reranking step, which prioritizes the most relevant contexts at the top, reducing the necessity to include additional contexts.</p>
</div>
<figure class="ltx_figure" id="A5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="188" id="A5.F11.g1" src="x2.png" width="706"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A5.F11.4.2.1" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text" id="A5.F11.2.1" style="font-size:90%;">Performance of RankRAG on different context size <math alttext="k" class="ltx_Math" display="inline" id="A5.F11.2.1.m1.1"><semantics id="A5.F11.2.1.m1.1b"><mi id="A5.F11.2.1.m1.1.1" xref="A5.F11.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A5.F11.2.1.m1.1c"><ci id="A5.F11.2.1.m1.1.1.cmml" xref="A5.F11.2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.2.1.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A5.F11.2.1.m1.1e">italic_k</annotation></semantics></math>.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Performance of NQ and Trivia QA on DPR Splits</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">We observe that the NQ and TriviaQA datasets exist in two versions: one used by the DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib35" title="">2020</a>)</cite> and FiD <cite class="ltx_cite ltx_citemacro_citep">(Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib25" title="">2021</a>)</cite> papers, which include 3610 and 11316 questions for NQ and TriviaQA, respectively. In contrast, the KILT benchmark <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib67" title="">2021</a>)</cite> utilizes only subsets of these, comprising 2837 and 5355 examples for NQ and TriviaQA, respectively. It is noteworthy that many recent studies report performance metrics on these datasets without clarifying which version was employed for evaluation.</p>
</div>
<div class="ltx_para" id="A6.p2">
<p class="ltx_p" id="A6.p2.1">To facilitate an <em class="ltx_emph ltx_font_italic" id="A6.p2.1.1">honest</em> and <em class="ltx_emph ltx_font_italic" id="A6.p2.1.2">fair</em> comparison, we present the performance of RankRAG on both datasets using the DPR splits in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A6.T9" title="Table 9 ‣ Appendix F Performance of NQ and Trivia QA on DPR Splits ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">9</span></a>. Notably, regardless of the subset used, RankRAG consistently outperforms both ChatQA and Llama-3-instruct, our direct competitors, as well as other methods utilizing InstructGPT as backbones. We aim for these results to assist the community in making accurate comparisons when referring to the performance of RankRAG.</p>
</div>
<figure class="ltx_table" id="A6.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A6.T9.2.1.1" style="font-size:90%;">Table 9</span>: </span><span class="ltx_text" id="A6.T9.3.2" style="font-size:90%;">Performance Across Models. </span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A6.T9.4" style="width:368.6pt;height:365.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.6pt,24.3pt) scale(0.882413056035369,0.882413056035369) ;">
<table class="ltx_tabular ltx_align_middle" id="A6.T9.4.1">
<tr class="ltx_tr" id="A6.T9.4.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T9.4.1.1.1"><span class="ltx_text ltx_font_bold" id="A6.T9.4.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A6.T9.4.1.1.2"><span class="ltx_text ltx_font_bold" id="A6.T9.4.1.1.2.1">Model Configuration</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T9.4.1.1.3"><span class="ltx_text ltx_font_bold" id="A6.T9.4.1.1.3.1">NQ EM (%)</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="A6.T9.4.1.1.4"><span class="ltx_text ltx_font_bold" id="A6.T9.4.1.1.4.1">TriviaQA EM / Acc. (%)</span></td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A6.T9.4.1.2.1"><em class="ltx_emph ltx_font_italic" id="A6.T9.4.1.2.1.1">Representative Baselines</em></td>
<td class="ltx_td ltx_border_t" id="A6.T9.4.1.2.2"></td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.3.1" rowspan="6"><span class="ltx_text" id="A6.T9.4.1.3.1.1">OpenAI GPT</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.3.2">GPT-3.5-0613</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.3.3">35.2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.3.4">70.1 / 81.3</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.4">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.4.1">GPT-3.5-0613 RAG</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.4.2">42.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.4.3">65.8 / 76.7</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.5">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.5.1">GPT-4-0613</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.5.2">37.2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.5.3"><span class="ltx_text ltx_font_bold" id="A6.T9.4.1.5.3.1">72.6 / 85.1</span></td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.6">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.6.1">GPT-4-0613 RAG</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.6.2">36.2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.6.3">61.2 / 75.9</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.7">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.7.1">GPT-4-turbo-2024-0409</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.7.2">38.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.7.3">68.0 / 84.5</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.8">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.8.1">GPT-4-turbo-2024-0409 RAG</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.8.2">36.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.8.3">57.6 / 79.2</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.9">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A6.T9.4.1.9.1"><em class="ltx_emph ltx_font_italic" id="A6.T9.4.1.9.1.1">Using Llama-2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib78" title="">2023</a>)</cite> as the backbone LLM</em></td>
<td class="ltx_td ltx_border_t" id="A6.T9.4.1.9.2"></td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.10.1">Llama-2-Chat</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.10.2">Llama-2 RAG 70B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.10.3">37.7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.10.4">65.6 / –</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.11.1" rowspan="3"><span class="ltx_text" id="A6.T9.4.1.11.1.1">ChatQA-1.0</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.11.2">Llama-2 7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.11.3">37.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.11.4">62.4 / 74.3</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.12">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.12.1">Llama-2 13B</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.12.2">43.9</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.12.3">66.6 / 76.9</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.13">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.13.1">Llama-2 70B</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.13.2">45.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.13.3">69.8 / 80.2</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.14.1" rowspan="3"><span class="ltx_text" id="A6.T9.4.1.14.1.1">RankRAG</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.14.2">Llama-2 7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.14.3">42.4</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.14.4">68.3 / 78.9</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.15">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.15.1">Llama-2 13B</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.15.2">46.2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.15.3">69.5 / 80.0</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.16">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.16.1">Llama-2 70B</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.16.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="A6.T9.4.1.16.2.1">48.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.16.3">72.3 / 82.6</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.17">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A6.T9.4.1.17.1"><em class="ltx_emph ltx_font_italic" id="A6.T9.4.1.17.1.1">Using Llama-3 <cite class="ltx_cite ltx_citemacro_citep">(Meta-AI, <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#bib.bib57" title="">2024</a>)</cite> as the backbone LLM</em></td>
<td class="ltx_td ltx_border_t" id="A6.T9.4.1.17.2"></td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.18">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.18.1" rowspan="2"><span class="ltx_text" id="A6.T9.4.1.18.1.1">Llama-3-Instruct</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.18.2">Llama-3-Instruct RAG 8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.18.3">27.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.18.4">57.1 / 74.6</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.19">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.19.1">Llama-3-Instruct RAG 70B</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.19.2">37.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.19.3">67.6 / 79.6</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.20">
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.20.1" rowspan="2"><span class="ltx_text" id="A6.T9.4.1.20.1.1">ChatQA-1.5</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.20.2">Llama-3 8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.20.3">44.1</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.20.4">65.4 / 75.8</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.21">
<td class="ltx_td ltx_align_left" id="A6.T9.4.1.21.1">Llama-3 70B</td>
<td class="ltx_td ltx_align_center" id="A6.T9.4.1.21.2">46.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T9.4.1.21.3">69.0 / 80.4</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.22">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A6.T9.4.1.22.1" rowspan="2"><span class="ltx_text" id="A6.T9.4.1.22.1.1">RankRAG</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A6.T9.4.1.22.2">Llama-3 8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T9.4.1.22.3">46.1</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T9.4.1.22.4">68.8 / 79.9</td>
</tr>
<tr class="ltx_tr" id="A6.T9.4.1.23">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A6.T9.4.1.23.1">Llama-3 70B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T9.4.1.23.2"><span class="ltx_text ltx_font_bold" id="A6.T9.4.1.23.2.1">50.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="A6.T9.4.1.23.3">
<span class="ltx_text ltx_font_bold" id="A6.T9.4.1.23.3.1">72.6</span> / <span class="ltx_text ltx_framed ltx_framed_underline" id="A6.T9.4.1.23.3.2">82.9</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Additional Case Studies</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">Tables <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A7.T10" title="Table 10 ‣ Appendix G Additional Case Studies ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2407.02485v1#A7.T11" title="Table 11 ‣ Appendix G Additional Case Studies ‣ RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs"><span class="ltx_text ltx_ref_tag">11</span></a> provide additional examples from the PopQA and HotpotQA datasets, which focus on long-tailed and multi-hop QA. These tasks are particularly challenging for retrievers, making it difficult to obtain relevant context from the corpus. Consequently, ChatQA-1.5 often struggles to produce the correct answers. However, the reranking step in RankRAG helps counteract poor initial retrieval by finding more pertinent evidence. Coupled with RAG-oriented finetuning, RankRAG effectively filters out distracting entities and pinpoints the correct answers.</p>
</div>
<figure class="ltx_table" id="A7.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A7.T10.4.1.1" style="font-size:90%;">Table 10</span>: </span><span class="ltx_text" id="A7.T10.5.2" style="font-size:90%;">A case study on the top-retrieved context and predictions on PopQA dataset, illustrating the effectiveness of RankRAG-8B over ChatQA-1.5-8B. <span class="ltx_text" id="A7.T10.5.2.1" style="color:#FF0000;">Red</span> text denotes distractors, while <span class="ltx_text" id="A7.T10.5.2.2" style="color:#009B55;">green</span> stands for evidences. </span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T10.6" style="width:433.6pt;height:316.2pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-91.3pt,66.5pt) scale(0.703579894737785,0.703579894737785) ;">
<table class="ltx_tabular ltx_align_middle" id="A7.T10.6.1">
<tr class="ltx_tr" id="A7.T10.6.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" colspan="2" id="A7.T10.6.1.1.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_text ltx_font_bold" id="A7.T10.6.1.1.1.1">Q</span>: Who is the author of The Universe Around Us?  <span class="ltx_text ltx_font_bold" id="A7.T10.6.1.1.1.2">A</span>: James Hopwood Jeans / James Jeans / Sir James Jeans / Sir James Hopwood Jeans</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T10.6.1.2.1" rowspan="5" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.2.1.1">
<span class="ltx_p" id="A7.T10.6.1.2.1.1.1" style="width:48.4pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.2.1.1.1.1">ChatQA-1.5</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T10.6.1.2.2" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.2.2.1">
<span class="ltx_p" id="A7.T10.6.1.2.2.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.2.2.1.1.1">Passage 1</span>: <span class="ltx_text" id="A7.T10.6.1.2.2.1.1.2" style="color:#FF0000;">Hooper</span> is the author of two books published by Smithsonian Books/HarperCollins. The first, Dark Cosmos: In Search of our Universe’s Missing Mass and Energy (2006) was named a notable book by Seed Magazine. His second book, Nature’s Blueprint: Supersymmetry and the Search for a Unified Theory of Matter and Force (2008), was called "essential reading" by New Scientist…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.3.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.3.1.1">
<span class="ltx_p" id="A7.T10.6.1.3.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.3.1.1.1.1">Passage 2</span>: <span class="ltx_text" id="A7.T10.6.1.3.1.1.1.2" style="color:#FF0000;">Fraknoi</span> is the author or co-author of 14 books in the field of astronomy. He was the lead author of Voyages through the Universe, an introductory college astronomy textbook published by Brooks-Cole, which went through three editions. In the 1980s, he co-edited with Byron Preiss two collections of science articles and science fiction stories, "The Universe" and "The Planets." With Sidney Wolff, Fraknoi founded and was co-editor of the first on-line journal devoted to astronomy education, "Astronomy Education Review"…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.4.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.4.1.1">
<span class="ltx_p" id="A7.T10.6.1.4.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.4.1.1.1.1">Passage 3</span>: The Universe" and "The Planets." With <span class="ltx_text" id="A7.T10.6.1.4.1.1.1.2" style="color:#FF0000;">Sidney Wolff, Fraknoi</span> founded and was co-editor of the first on-line journal devoted to astronomy education, "Astronomy Education Review". He edited two collections of resources for K-12 teachers, The Universe at Your Fingertips and More Universe at Your Fingertips published through the Astronomical Society of…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.5.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.5.1.1">
<span class="ltx_p" id="A7.T10.6.1.5.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.5.1.1.1.1">Passage 4</span>: <span class="ltx_text" id="A7.T10.6.1.5.1.1.1.2" style="color:#FF0000;">Lincoln Kinnear Barnett</span> (1909–1979) was an editor and author, most notably at Life Magazine for many years. Lincoln Barnett wrote a number of books, including "The Universe and Doctor Einstein"</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.6.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.6.1.1">
<span class="ltx_p" id="A7.T10.6.1.6.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.6.1.1.1.1">Passage 5</span>: The Universe Maker is a science fiction novel by American author <span class="ltx_text" id="A7.T10.6.1.6.1.1.1.2" style="color:#FF0000;">A.E. van Vogt</span>, published in 1953 by Ace Books as an Ace Double with The World of Null-A. It is based on the authorś "The Shadow Men" (Startling Stories, 1950). Set 400 years into the future, the main character is Morton Cargill, a U.S. Army officer who served in the Korean War…  <span class="ltx_text ltx_font_bold" id="A7.T10.6.1.6.1.1.1.3" style="background-color:#FFD9D9;">Prediction<span class="ltx_text ltx_font_medium" id="A7.T10.6.1.6.1.1.1.3.1">: Lincoln Barnett (✘)</span></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A7.T10.6.1.7.1" rowspan="15" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.7.1.1">
<span class="ltx_p" id="A7.T10.6.1.7.1.1.1" style="width:48.4pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.7.1.1.1.1">RankRAG</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T10.6.1.7.2" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.7.2.1">
<span class="ltx_p" id="A7.T10.6.1.7.2.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.7.2.1.1.1">Passage 1</span>: <span class="ltx_text" id="A7.T10.6.1.7.2.1.1.2" style="color:#009B55;">The Universe Around Us is a science book written by English astrophysicist Sir James Jeans</span>, first published in 1929 by the Syndics of the Cambridge University Press….</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.8.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.8.1.1">
<span class="ltx_p" id="A7.T10.6.1.8.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.8.1.1.1.1">Passage 2</span>: These books made Jeans fairly well known as an expositor of the revolutionary scientific discoveries of his day, especially in relativity and physical cosmology. In 1939, the Journal of the British Astronomical Association reported that Jeans was going to stand as a candidate for</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.9.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.9.1.1">
<span class="ltx_p" id="A7.T10.6.1.9.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.9.1.1.1.1">Passage 3</span>: <span class="ltx_text" id="A7.T10.6.1.9.1.1.1.2" style="color:#009B55;">James Jeans</span> books for the lay public, including "The Stars in Their Courses" (1931), "<span class="ltx_text" id="A7.T10.6.1.9.1.1.1.3" style="color:#009B55;">The Universe Around Us</span>", "Through Space and Time" (1934), "The New Background of Science" (1933), and "The Mysterious Universe.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T10.6.1.10.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.10.1.1">
<span class="ltx_p" id="A7.T10.6.1.10.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.10.1.1.1.1">Passage 4</span>: The Universe Around Us no special scientific knowledge. Parts of the book cover the same ground as various lectures I have recently delivered to University and other audiences, including a course of wireless talks I gave last autumn. It has been found necessary to rewrite these almost in their entirety, so that very few sentences remain in their original form, but those who have asked me to publish my lectures and wireless talks will find the substance of them in the present book.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T10.6.1.11">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A7.T10.6.1.11.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T10.6.1.11.1.1">
<span class="ltx_p" id="A7.T10.6.1.11.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T10.6.1.11.1.1.1.1">Passage 5</span>:Lincoln Barnett Lincoln Kinnear Barnett (1909–1979) was an editor and author, most notably at Life Magazine for many years. Lincoln Barnett wrote a number of books, including "The Universe and Doctor Einstein", "The World We Live In", and "The Treasure of Our Tongue". The Universe and Doctor Einstein is a laymanś introduction to the theory of relativity. It includes a foreword by Albert Einstein, and has been reprinted several times…  <span class="ltx_text ltx_font_bold" id="A7.T10.6.1.11.1.1.1.2" style="background-color:#D9F0E5;">Prediction<span class="ltx_text ltx_font_medium" id="A7.T10.6.1.11.1.1.1.2.1">: Sir James Jeans (✓)</span></span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A7.T11">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A7.T11.4.1.1" style="font-size:90%;">Table 11</span>: </span><span class="ltx_text" id="A7.T11.5.2" style="font-size:90%;">A case study on the top-retrieved context and predictions on HotpotQA dataset, illustrating the effectiveness of RankRAG-8B over ChatQA-1.5-8B. <span class="ltx_text" id="A7.T11.5.2.1" style="color:#FF0000;">Red</span> text denotes distractors, while <span class="ltx_text" id="A7.T11.5.2.2" style="color:#009B55;">green</span> stands for evidences. </span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T11.6" style="width:433.6pt;height:400.5pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-91.3pt,84.2pt) scale(0.703579894737785,0.703579894737785) ;">
<table class="ltx_tabular ltx_align_middle" id="A7.T11.6.1">
<tr class="ltx_tr" id="A7.T11.6.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" colspan="2" id="A7.T11.6.1.1.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_text ltx_font_bold" id="A7.T11.6.1.1.1.1">Q</span>: Which song did Eminem and Rihanna collaborate on after their other collaboration song in studio album "Unapologetic?"  <span class="ltx_text ltx_font_bold" id="A7.T11.6.1.1.1.2">A</span>: The Monster</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T11.6.1.2.1" rowspan="5" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.2.1.1">
<span class="ltx_p" id="A7.T11.6.1.2.1.1.1" style="width:48.4pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.2.1.1.1.1">ChatQA-1.5</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T11.6.1.2.2" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.2.2.1">
<span class="ltx_p" id="A7.T11.6.1.2.2.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.2.2.1.1.1">Passage 1</span>: Unapologetic is the seventh studio album by Barbadian singer Rihanna. It was released on November 19, 2012, by Def Jam Recordings and SRP Records. It was recorded between June and November 2012, during promotion of her sixth album, "<span class="ltx_text" id="A7.T11.6.1.2.2.1.1.2" style="color:#FF0000;">Talk That Talk</span>" (2011). As executive producer, Rihanna enlisted previous collaborators The-Dream, David Guetta, Chase &amp; Status, and StarGate to work alongside new collaborators such as Parker Ighile, Mike Will Made-It, and Labrinth…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.3.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.3.1.1">
<span class="ltx_p" id="A7.T11.6.1.3.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.3.1.1.1.1">Passage 2</span>: Def Jam France announced via Twitter that Rihanna would release a new single the upcoming week while her seventh studio album was scheduled to be released in November 2012. On October 11, 2012, in one of her tweets revealed that the title of her new album is "Unapologetic" alongside with its cover. "<span class="ltx_text" id="A7.T11.6.1.3.1.1.1.2" style="color:#FF0000;">What Now</span>" was written by British singer-songwriter Livvi Franc together with Rihanna, Parker Ighile and Nathan Cassells, while the production of the song was done by the latter two. Ighile and Cassells…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.4.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.4.1.1">
<span class="ltx_p" id="A7.T11.6.1.4.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.4.1.1.1.1">Passage 3</span>: Justin then went on to co write "<span class="ltx_text" id="A7.T11.6.1.4.1.1.1.2" style="color:#FF0000;">Stay</span>" with Mikky Ekko and recorded by Barbadian singer Rihanna for her seventh studio album, "Unapologetic" (2012). It features guest vocals by Mikky Ekko, and was released as the second single from the album on 7 January 2013. The song reached the top five of twenty-four countries worldwide including number four in the UK and number three on the US Billboard Hot 100, becoming Rihanna’s twenty-fourth top ten on the latter chart…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.5.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.5.1.1">
<span class="ltx_p" id="A7.T11.6.1.5.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.5.1.1.1.1">Passage 4</span>: Via her official Twitter account, Rihanna posted series of "teasing" tweets announcing her seventh studio album. On October 11, 2012, in one of her tweets revealed that the title of her new album is "Unapologetic" alongside with its cover. "Jump" is the overall seventh and final single off Unapologetic. It was written by Kevin Cossom and M. B. Williams together with its producers StarGate (Mikkel S. Eriksen and Tor Erik Hermansen) and Chase &amp; Status (Saul Milton</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.6.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.6.1.1">
<span class="ltx_p" id="A7.T11.6.1.6.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.6.1.1.1.1">Passage 5</span>: copies of the song were sold in the UK, making "<span class="ltx_text" id="A7.T11.6.1.6.1.1.1.2" style="color:#FF0000;">Love the Way You Lie</span>" the country’s biggest-selling song of 2010. The same year, a sequel to the single, titled "<span class="ltx_text" id="A7.T11.6.1.6.1.1.1.3" style="color:#FF0000;">Love the Way You Lie (Part II)</span>" was released as part of Rihanna’s fifth studio album "Loud"; it mainly views matters from the female protagonist perspective. In November 2012, Eminem and Rihanna collaborated again on "<span class="ltx_text" id="A7.T11.6.1.6.1.1.1.4" style="color:#FF0000;">Numb</span>", which was included on Rihanna’s seventh album "Unapologetic"…  <span class="ltx_text ltx_font_bold" id="A7.T11.6.1.6.1.1.1.5" style="background-color:#FFD9D9;">Prediction<span class="ltx_text ltx_font_medium" id="A7.T11.6.1.6.1.1.1.5.1">: Love the Way You Lie (✘)</span></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A7.T11.6.1.7.1" rowspan="20" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.7.1.1">
<span class="ltx_p" id="A7.T11.6.1.7.1.1.1" style="width:48.4pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.7.1.1.1.1">RankRAG</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T11.6.1.7.2" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.7.2.1">
<span class="ltx_p" id="A7.T11.6.1.7.2.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.7.2.1.1.1">Passage 1</span>: <span class="ltx_text" id="A7.T11.6.1.7.2.1.1.2" style="color:#009B55;">The Monster (song)</span>. Copies of the song were sold in the UK, making "Love the Way You Lie" the country’s biggest-selling song of 2010. The same year, a sequel to the single, titled "Love the Way You Lie (Part II)" was released as part of Rihanna’s fifth studio album "Loud"; it mainly views matters from the female protagonist perspective. In November 2012, Eminem and Rihanna collaborated again on "Numb", which was included on Rihanna’s seventh album "Unapologetic"….</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.8.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.8.1.1">
<span class="ltx_p" id="A7.T11.6.1.8.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.8.1.1.1.1">Passage 2</span>: "<span class="ltx_text" id="A7.T11.6.1.8.1.1.1.2" style="color:#FF0000;">Numb</span>" is a song by Barbadian singer Rihanna from her seventh studio album "Unapologetic" (2012). It features guest vocals by American rapper Eminem, making it the pair’s third collaboration since the two official versions of "Love the Way You Lie". Following the album’s release, "Numb" charted on multiple charts worldwide including in Canada, the United Kingdom and the United States. "Numb" lasts for a duration of .</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.9.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.9.1.1">
<span class="ltx_p" id="A7.T11.6.1.9.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.9.1.1.1.1">Passage 3</span>: Eminem also wanted to experiment with "retro, vintage" sounds such as beatbreaks and scratches, and he felt that Rubin could help him "take that to another level." Rihanna, with whom Eminem previously collaborated on "<span class="ltx_text" id="A7.T11.6.1.9.1.1.1.2" style="color:#FF0000;">Love the Way You Lie</span>" from Eminem’s previous studio effort, "Recovery" (2010), was featured on the song "<span class="ltx_text" id="A7.T11.6.1.9.1.1.1.3" style="color:#009B55;">The Monster</span>". On September 11, 2013, she hinted at the…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T11.6.1.10.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.10.1.1">
<span class="ltx_p" id="A7.T11.6.1.10.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.10.1.1.1.1">Passage 4</span>: together with Jay-Z, Bono and The Edge for the same campaign to alleviate the 2010 Haiti earthquake. In summer 2010, Rihanna collaborated with rapper Eminem on "Love the Way You Lie", which was a major worldwide success, reaching No. 1 in over 20 countries. Reaching number 2, the song became the biggest-selling song of 2010 in the UK and the first of Rihanna’s singles to sell over a million copies in the country. In October 2010, Rihanna switched managers …</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T11.6.1.11">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A7.T11.6.1.11.1" style="padding-top:-0.4pt;padding-bottom:-0.4pt;">
<span class="ltx_inline-block ltx_align_top" id="A7.T11.6.1.11.1.1">
<span class="ltx_p" id="A7.T11.6.1.11.1.1.1" style="width:540.6pt;"><span class="ltx_text ltx_font_bold" id="A7.T11.6.1.11.1.1.1.1">Passage 5</span>: Eminem asked for more tracks and subsequently heard "Love the Way You Lie". He chose it and told his manager Paul Rosenberg he wanted to collaborate with the Barbadian singer Rihanna. Eminem told Skyrock, "It’s one of those tracks that I felt like only she could pull it off." Rosenberg sent the track to Rihanna, who accepted Eminem’s request "at the last moment." Eminem then wrote the rapped verses.  <span class="ltx_text ltx_font_bold" id="A7.T11.6.1.11.1.1.1.2" style="background-color:#D9F0E5;">Prediction<span class="ltx_text ltx_font_medium" id="A7.T11.6.1.11.1.1.1.2.1">: The Monster (✓)</span></span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul  2 17:55:20 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
