<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations</title>
<!--Generated on Tue Oct 15 02:21:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.10315v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1" title="In 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Ingestion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS1" title="In 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1.1 </span>zedx file processing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS2" title="In 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1.2 </span>Text Segmentation</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS2.Px1" title="In 1.1.2 Text Segmentation ‚Ä£ 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Segmentation Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS2.Px2" title="In 1.1.2 Text Segmentation ‚Ä£ 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Eliminating Path Influence in Segmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS3" title="In 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1.3 </span>Image Information Extraction</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS3.Px1" title="In 1.1.3 Image Information Extraction ‚Ä£ 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Image Content Extraction Using a Multimodal Large Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1.SSS3.Px2" title="In 1.1.3 Image Information Extraction ‚Ä£ 1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Image Filtering Based on Various Rules</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2" title="In 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>RAG Pipeline</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS1" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.1 </span>Query Rewriting</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS1.Px1" title="In 1.2.1 Query Rewriting ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Query Expansion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS1.Px2" title="In 1.2.1 Query Rewriting ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">HyDE</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS2" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.2 </span>Dual-route Sparse Retrieval for Coarse Ranking</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS2.Px1" title="In 1.2.2 Dual-route Sparse Retrieval for Coarse Ranking ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Chinese Tokenizer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS2.Px2" title="In 1.2.2 Dual-route Sparse Retrieval for Coarse Ranking ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Stopword List</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS2.Px3" title="In 1.2.2 Dual-route Sparse Retrieval for Coarse Ranking ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Dual-route Retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS2.Px4" title="In 1.2.2 Dual-route Sparse Retrieval for Coarse Ranking ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Retrieval Process</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS3" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.3 </span>Dense Retrieval for Coarse Ranking</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS3.Px1" title="In 1.2.3 Dense Retrieval for Coarse Ranking ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Retrieval Process</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS4" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.4 </span>LLM Reranker Re-ranking</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS4.Px1" title="In 1.2.4 LLM Reranker Re-ranking ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Re-ranking Process</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.5 </span>Multi-route Ranking Fusion</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5.Px1" title="In 1.2.5 Multi-route Ranking Fusion ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Fusion Algorithm</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5.Px2" title="In 1.2.5 Multi-route Ranking Fusion ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Coarse Ranking Fusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5.Px3" title="In 1.2.5 Multi-route Ranking Fusion ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Re-ranking Fusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS6" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.6 </span>LLM Answer Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS7" title="In 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2.7 </span>LLM Answer Optimization</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Accuracy</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS1" title="In 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Abbreviations Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS1.SSS0.Px1" title="In 2.1 Abbreviations Introduction ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS1.SSS0.Px2" title="In 2.1 Abbreviations Introduction ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Coarse Ranking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS1.SSS0.Px3" title="In 2.1 Abbreviations Introduction ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Re-ranking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS1.SSS0.Px4" title="In 2.1 Abbreviations Introduction ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Fusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS1.SSS0.Px5" title="In 2.1 Abbreviations Introduction ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Document Expansion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS2" title="In 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Preliminary Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS3" title="In 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Semi-final Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS4" title="In 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Exploratory Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS4.SSS1" title="In 2.4 Exploratory Experiments ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.1 </span>Query Rewriting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.SS4.SSS2" title="In 2.4 Exploratory Experiments ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.2 </span>Prompt Types</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S3" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Resource Consumption</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S4" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Deployment Difficulty</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Inference Latency</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS1" title="In 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Standard Scheme</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS1.SSS0.Px1" title="In 5.1 Standard Scheme ‚Ä£ 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Standard Time Delay</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS1.SSS0.Px2" title="In 5.1 Standard Scheme ‚Ä£ 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Removing Answer Integration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS1.SSS0.Px3" title="In 5.1 Standard Scheme ‚Ä£ 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Increasing Re-ranking Batch Size</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS1.SSS0.Px4" title="In 5.1 Standard Scheme ‚Ä£ 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Full Process Acceleration Scheme</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS2" title="In 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>BM25 Acceleration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS3" title="In 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Reranker Acceleration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.SS4" title="In 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Context Compression</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S6" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Scalability</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S6.SS0.SSS0.Px1" title="In 6 Scalability ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">Document Scalability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S6.SS0.SSS0.Px2" title="In 6 Scalability ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title">User Scalability</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S7" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Question-and-Answer Prompt Templates</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1.SS1" title="In Appendix A Question-and-Answer Prompt Templates ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Markdown Format Question-and-Answer Template</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1.SS2" title="In Appendix A Question-and-Answer Prompt Templates ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Chain of Thought Question-and-Answer Template</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1.SS3" title="In Appendix A Question-and-Answer Prompt Templates ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Focused Question-and-Answer Template</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A2" title="In EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Answer Integration Template</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zhangchi Feng<sup class="ltx_sup" id="id1.1.id1">1</sup>, Dongdong Kuang<sup class="ltx_sup" id="id2.2.id2">1</sup>, Zhongyuan Wang<sup class="ltx_sup" id="id3.3.id3">1</sup>,
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id4.4.id4">Zhijie Nie<sup class="ltx_sup" id="id4.4.id4.1"><span class="ltx_text ltx_font_medium" id="id4.4.id4.1.1">1</span></sup>, Yaowei Zheng<sup class="ltx_sup" id="id4.4.id4.2"><span class="ltx_text ltx_font_medium" id="id4.4.id4.2.1">1</span></sup>, Richong Zhang<sup class="ltx_sup" id="id4.4.id4.3"><span class="ltx_text ltx_font_medium" id="id4.4.id4.3.1">1</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id4.4.id4.4"><span class="ltx_text ltx_font_medium" id="id4.4.id4.4.1">1</span></sup>CCSE, School of Computer Science and Engineering, Beihang University, Beijing, China
<br class="ltx_break"/></span><span class="ltx_text ltx_font_typewriter" id="id5.5.id5">{zcmuller,kuangdd,wangzy23,hiyouga}@buaa.edu.cn</span><span class="ltx_text ltx_font_bold" id="id6.6.id6">, </span><span class="ltx_text ltx_font_typewriter" id="id7.7.id7">{niezj,zhangrc}@act.buaa.edu.cn</span><span class="ltx_text ltx_font_bold" id="id8.8.id8">
</span>
</span><span class="ltx_author_notes"><span class="ltx_text ltx_font_bold" id="id9.9.id1">¬†¬†Corresponding author</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id10.id1">This paper presents EasyRAG, a simple, lightweight, and efficient retrieval-augmented generation framework for automated network operations<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This work is a technical report of our solution at the 2024 (7th) CCF International AIOps Challenge. The official website of the Challenge is <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://competition.aiops-challenge.com" title="">https://competition.aiops-challenge.com</a></span></span></span>. Our framework has three advantages. The first is <span class="ltx_text ltx_font_bold" id="id10.id1.1">accurate question answering</span>. We designed a straightforward RAG scheme based on (1) a specific data processing workflow (2) dual-route sparse retrieval for coarse ranking (3) LLM Reranker for reranking (4) LLM answer generation and optimization. This approach achieved first place in the GLM4 track in the preliminary round and second place in the GLM4 track in the semifinals. The second is <span class="ltx_text ltx_font_bold" id="id10.id1.2">simple deployment</span>. Our method primarily consists of BM25 retrieval and BGE-reranker reranking, requiring no fine-tuning of any models, occupying minimal VRAM, easy to deploy, and highly scalable; we provide a flexible code library with various search and generation strategies, facilitating custom process implementation. The last one is <span class="ltx_text ltx_font_bold" id="id10.id1.3">efficient inference</span>. We designed an efficient inference acceleration scheme for the entire coarse ranking, reranking, and generation process that significantly reduces the inference latency of RAG while maintaining a good level of accuracy; each acceleration scheme can be plug-and-play into any component of the RAG process, consistently enhancing the efficiency of the RAG system. Our code and data are released at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/BUAADreamer/EasyRAG" title="">https://github.com/BUAADreamer/EasyRAG</a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
Zhangchi Feng<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.1.1">1</span></sup>, Dongdong Kuang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.2.1">1</span></sup>, Zhongyuan Wang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.1.1.1.1.3.1">1</span></sup>,</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.2.2.1.1">Zhijie Nie<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.1"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.2.2.1.1.1.1">1</span></sup>, Yaowei Zheng<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.2"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.2.2.1.1.2.1">1</span></sup>, Richong Zhang<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.3"><span class="ltx_text ltx_font_medium" id="p1.1.2.1.1.2.2.1.1.3.1">1</span></sup><span class="ltx_note ltx_role_thanks" id="p1.1.2.1.1.2.2.1.1.4"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">thanks: </span>¬†¬†Corresponding author</span></span></span></span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1">1</sup>CCSE, School of Computer Science and Engineering, Beihang University, Beijing, China</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.4.4.1.1">{zcmuller,kuangdd,wangzy23,hiyouga}@buaa.edu.cn</span>, <span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.4.4.1.2">{niezj,zhangrc}@act.buaa.edu.cn</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Our solution can be summarized by Fig.¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1</span></a>, which includes a data processing workflow (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS1" title="1.1 Ingestion ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.1</span></a>) and the RAG process (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2" title="1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.2</span></a>).</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="279" id="S1.F1.g1" src="extracted/5927071/pics/overview.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>EasyRAG Framework</figcaption>
</figure>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Ingestion</h3>
<section class="ltx_subsubsection" id="S1.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.1.1 </span>zedx file processing</h4>
<div class="ltx_para" id="S1.SS1.SSS1.p1">
<p class="ltx_p" id="S1.SS1.SSS1.p1.1">Due to the discovery that the original processing script missed some files, we have reprocessed the zedx files using the following steps:</p>
</div>
<div class="ltx_para" id="S1.SS1.SSS1.p2">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">zedx Decompression</span>: Decompress the official source data from four .zedx files, obtaining four packages of HTML documents.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Path Parsing</span>: Read the <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.2">knowledge path</span> and the actual <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.3">file path</span> from the nodetree.xml in each document package.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Document Extraction</span>: Extract the text, image titles, and image paths from each HTML document using BeautifulSoup.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">Saving</span>: Save the document text in txt format, maintaining the relative location consistent with the HTML document. Also, save the knowledge path, file path, and image path information.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsubsection" id="S1.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.1.2 </span>Text Segmentation</h4>
<section class="ltx_paragraph" id="S1.SS1.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Segmentation Settings</h5>
<div class="ltx_para" id="S1.SS1.SSS2.Px1.p1">
<p class="ltx_p" id="S1.SS1.SSS2.Px1.p1.1">We used SentenceSplitter for document segmentation, initially splitting into sentences using Chinese punctuation, then merging according to the set text block size. The used block size (chunk-size) is 1024, and the block overlap size (chunk-overlap) is 200.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS1.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Eliminating Path Influence in Segmentation</h5>
<div class="ltx_para" id="S1.SS1.SSS2.Px2.p1">
<p class="ltx_p" id="S1.SS1.SSS2.Px2.p1.1">In practice, we found that the original implementation of llama-index used a simple but unstable method of handling path information, subtracting the file path length from the text length to determine the actual text length used. This approach could cause different segmentation results with the same chunk-size and chunk-overlap, depending on the data path. During the preliminary competition, we observed that changing paths could lead to a fluctuation of up to 3 percentage points in the final evaluation results, which is obviously unacceptable in practice. To address this issue, we implemented a custom segmentation class that eliminates the use of path length, thereby ensuring stable reproducibility.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S1.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.1.3 </span>Image Information Extraction</h4>
<section class="ltx_paragraph" id="S1.SS1.SSS3.Px1">
<h5 class="ltx_title ltx_title_paragraph">Image Content Extraction Using a Multimodal Large Model</h5>
<div class="ltx_para" id="S1.SS1.SSS3.Px1.p1">
<p class="ltx_p" id="S1.SS1.SSS3.Px1.p1.1">First, we extracted information from all images using GLM-4V-9B¬†<cite class="ltx_cite ltx_citemacro_cite">GLM et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib3" title="">2024</a>)</cite>. We found that the following simple prompt achieves good results:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.SSS3.Px1.p2">
<svg class="ltx_picture" height="39.86" id="S1.SS1.SSS3.Px1.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,39.86) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 33.95 C 0 37.21 2.64 39.86 5.91 39.86 L 594.09 39.86 C 597.36 39.86 600 37.21 600 33.95 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 33.95 C 1.97 36.13 3.73 37.89 5.91 37.89 L 594.09 37.89 C 596.27 37.89 598.03 36.13 598.03 33.95 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S1.SS1.SSS3.Px1.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S1.SS1.SSS3.Px1.p2.pic1.1.1.1.1.1.1">Briefly describe the image</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS1.SSS3.Px2">
<h5 class="ltx_title ltx_title_paragraph">Image Filtering Based on Various Rules</h5>
<div class="ltx_para" id="S1.SS1.SSS3.Px2.p1">
<p class="ltx_p" id="S1.SS1.SSS3.Px2.p1.1">We found that a small number of images are beneficial for the final question answering, but not all images are useful. Therefore, we designed a flexible strategy to filter out useless images using the following steps:</p>
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1">Use the PP-OCRv4 model<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_href" href="https://github.com/PaddlePaddle/PaddleOCR" title="">https://github.com/PaddlePaddle/PaddleOCR</a></span></span></span> to extract text content from images and filter out images that do not contain Chinese.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1">Filter images whose titles contain specific keywords (e.g., network diagrams, architecture).</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I2.i3.p1">
<p class="ltx_p" id="S1.I2.i3.p1.1">Filter images that are referenced in the text in a specific way (e.g., configuration as shown in Figure x, file as shown in Figure x).</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S1.SS1.SSS3.Px2.p1.2">With these filtering steps, we reduced the number of images from an original 6000 to fewer than 200. Notably, the filtering process is easily configurable, allowing for tuning to suit real-world scenarios.</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>RAG Pipeline</h3>
<section class="ltx_subsubsection" id="S1.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.1 </span>Query Rewriting</h4>
<div class="ltx_para" id="S1.SS2.SSS1.p1">
<p class="ltx_p" id="S1.SS2.SSS1.p1.1">During the competition, given that the queries were very brief and we identified issues with some queries being semantically awkward or having unclear keywords. For instance, "What types of alarms are there in EMSPLuS?" and "What are the sources of faults?". Before inputting these queries into the RAG Pipeline, we used a Large Language Model (LLM, GLM4) for query rewriting, which involved two methods: query expansion and Hypothetical Document Embedding (HyDE) <cite class="ltx_cite ltx_citemacro_citep">(Gao et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib2" title="">2022</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S1.SS2.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Query Expansion</h5>
<div class="ltx_para" id="S1.SS2.SSS1.Px1.p1">
<p class="ltx_p" id="S1.SS2.SSS1.Px1.p1.1">During the preliminary round, we summarized the characteristics of queries in the current operational maintenance scenario:</p>
<ul class="ltx_itemize" id="S1.I3">
<li class="ltx_item" id="S1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I3.i1.p1">
<p class="ltx_p" id="S1.I3.i1.p1.1">Technical keywords in queries are crucial.</p>
</div>
</li>
<li class="ltx_item" id="S1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I3.i2.p1">
<p class="ltx_p" id="S1.I3.i2.p1.1">Queries are short and vary greatly in the amount of information provided.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.SS2.SSS1.Px1.p1.2">In this context, we attempted to summarize the key terms in the queries or other potentially relevant keywords using the LLM, i.e., using the LLM‚Äôs knowledge for keyword association and summary in the fields of operation and communication. This is referred to as <span class="ltx_text ltx_font_bold" id="S1.SS2.SSS1.Px1.p1.2.1">keyword expansion</span>.</p>
</div>
<div class="ltx_para" id="S1.SS2.SSS1.Px1.p2">
<p class="ltx_p" id="S1.SS2.SSS1.Px1.p2.1">After manually annotating several data points with keywords and potential associations, we utilized the LLM (GLM4) for few-shot keyword summarization and expansion. Following <cite class="ltx_cite ltx_citemacro_citep">(Wang et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib10" title="">2023</a>)</cite>, we generated new queries by directly concatenating the expanded keywords with the original query and then re-summarizing them using a large language model.</p>
</div>
<div class="ltx_para" id="S1.SS2.SSS1.Px1.p3">
<p class="ltx_p" id="S1.SS2.SSS1.Px1.p3.5">Let <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px1.p3.1.m1.1"><semantics id="S1.SS2.SSS1.Px1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S1.SS2.SSS1.Px1.p3.1.m1.1.1" xref="S1.SS2.SSS1.Px1.p3.1.m1.1.1.cmml">‚Ñí</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px1.p3.1.m1.1b"><ci id="S1.SS2.SSS1.Px1.p3.1.m1.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.1.m1.1.1">‚Ñí</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px1.p3.1.m1.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px1.p3.1.m1.1d">caligraphic_L</annotation></semantics></math> represent the Large Language Model LLM, with <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px1.p3.2.m2.1"><semantics id="S1.SS2.SSS1.Px1.p3.2.m2.1a"><mi id="S1.SS2.SSS1.Px1.p3.2.m2.1.1" xref="S1.SS2.SSS1.Px1.p3.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px1.p3.2.m2.1b"><ci id="S1.SS2.SSS1.Px1.p3.2.m2.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px1.p3.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px1.p3.2.m2.1d">italic_q</annotation></semantics></math> and <math alttext="p" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px1.p3.3.m3.1"><semantics id="S1.SS2.SSS1.Px1.p3.3.m3.1a"><mi id="S1.SS2.SSS1.Px1.p3.3.m3.1.1" xref="S1.SS2.SSS1.Px1.p3.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px1.p3.3.m3.1b"><ci id="S1.SS2.SSS1.Px1.p3.3.m3.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.3.m3.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px1.p3.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px1.p3.3.m3.1d">italic_p</annotation></semantics></math> denoting the initial query and the prompt, respectively. <math alttext="p_{exp}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px1.p3.4.m4.1"><semantics id="S1.SS2.SSS1.Px1.p3.4.m4.1a"><msub id="S1.SS2.SSS1.Px1.p3.4.m4.1.1" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.cmml"><mi id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.2" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.2.cmml">p</mi><mrow id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.cmml"><mi id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.2" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.2.cmml">e</mi><mo id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.1" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.1.cmml">‚Å¢</mo><mi id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.3" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.3.cmml">x</mi><mo id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.1a" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.1.cmml">‚Å¢</mo><mi id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.4" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px1.p3.4.m4.1b"><apply id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1">subscript</csymbol><ci id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.2.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.2">ùëù</ci><apply id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3"><times id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.1.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.1"></times><ci id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.2.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.2">ùëí</ci><ci id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.3.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.3">ùë•</ci><ci id="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.4.cmml" xref="S1.SS2.SSS1.Px1.p3.4.m4.1.1.3.4">ùëù</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px1.p3.4.m4.1c">p_{exp}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px1.p3.4.m4.1d">italic_p start_POSTSUBSCRIPT italic_e italic_x italic_p end_POSTSUBSCRIPT</annotation></semantics></math> represents the expanded query prompt, including manually annotated data points, and <math alttext="p_{sum}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px1.p3.5.m5.1"><semantics id="S1.SS2.SSS1.Px1.p3.5.m5.1a"><msub id="S1.SS2.SSS1.Px1.p3.5.m5.1.1" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.cmml"><mi id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.2" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.2.cmml">p</mi><mrow id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.cmml"><mi id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.2" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.2.cmml">s</mi><mo id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.1" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.1.cmml">‚Å¢</mo><mi id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.3" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.3.cmml">u</mi><mo id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.1a" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.1.cmml">‚Å¢</mo><mi id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.4" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.4.cmml">m</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px1.p3.5.m5.1b"><apply id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.1.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1">subscript</csymbol><ci id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.2.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.2">ùëù</ci><apply id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3"><times id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.1.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.1"></times><ci id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.2.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.2">ùë†</ci><ci id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.3.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.3">ùë¢</ci><ci id="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.4.cmml" xref="S1.SS2.SSS1.Px1.p3.5.m5.1.1.3.4">ùëö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px1.p3.5.m5.1c">p_{sum}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px1.p3.5.m5.1d">italic_p start_POSTSUBSCRIPT italic_s italic_u italic_m end_POSTSUBSCRIPT</annotation></semantics></math> represents the prompt for summarizing and concatenating the sentence and expanded keywords using the large model.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS2.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">HyDE</h5>
<div class="ltx_para" id="S1.SS2.SSS1.Px2.p1">
<p class="ltx_p" id="S1.SS2.SSS1.Px2.p1.1">In situations where queries lack specificity or identifiable elements, making it difficult for both dense and sparse retrieval methods to locate the target document, we designed a set of hypothetical document embedding methods, inspired by <cite class="ltx_cite ltx_citemacro_cite">Gao et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib2" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.SS2.SSS1.Px2.p2">
<p class="ltx_p" id="S1.SS2.SSS1.Px2.p2.5">For the generation of fictional documents, we devised two approaches, as shown in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.F2" title="Figure 2 ‚Ä£ HyDE ‚Ä£ 1.2.1 Query Rewriting ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">2</span></a>. Initially, following the paper‚Äôs methodology, we input the prompt <math alttext="p_{hy}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p2.1.m1.1"><semantics id="S1.SS2.SSS1.Px2.p2.1.m1.1a"><msub id="S1.SS2.SSS1.Px2.p2.1.m1.1.1" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.cmml"><mi id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.2" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.2.cmml">p</mi><mrow id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.cmml"><mi id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.2" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.2.cmml">h</mi><mo id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.1" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.3" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.3.cmml">y</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p2.1.m1.1b"><apply id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.2.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.2">ùëù</ci><apply id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3"><times id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.1.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.1"></times><ci id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.2.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.2">‚Ñé</ci><ci id="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.3.cmml" xref="S1.SS2.SSS1.Px2.p2.1.m1.1.1.3.3">ùë¶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p2.1.m1.1c">p_{hy}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p2.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_h italic_y end_POSTSUBSCRIPT</annotation></semantics></math> and the original question <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p2.2.m2.1"><semantics id="S1.SS2.SSS1.Px2.p2.2.m2.1a"><mi id="S1.SS2.SSS1.Px2.p2.2.m2.1.1" xref="S1.SS2.SSS1.Px2.p2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p2.2.m2.1b"><ci id="S1.SS2.SSS1.Px2.p2.2.m2.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p2.2.m2.1d">italic_q</annotation></semantics></math> into the large language model <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p2.3.m3.1"><semantics id="S1.SS2.SSS1.Px2.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S1.SS2.SSS1.Px2.p2.3.m3.1.1" xref="S1.SS2.SSS1.Px2.p2.3.m3.1.1.cmml">‚Ñí</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p2.3.m3.1b"><ci id="S1.SS2.SSS1.Px2.p2.3.m3.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.3.m3.1.1">‚Ñí</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p2.3.m3.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p2.3.m3.1d">caligraphic_L</annotation></semantics></math> to produce the fictional document <math alttext="q^{\prime}_{0}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p2.4.m4.1"><semantics id="S1.SS2.SSS1.Px2.p2.4.m4.1a"><msubsup id="S1.SS2.SSS1.Px2.p2.4.m4.1.1" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.cmml"><mi id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.2" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.2.cmml">q</mi><mn id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.3" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.3.cmml">0</mn><mo id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.3" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p2.4.m4.1b"><apply id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1">subscript</csymbol><apply id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.cmml" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.1.cmml" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1">superscript</csymbol><ci id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.2.cmml" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.2">ùëû</ci><ci id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.3.cmml" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.2.3">‚Ä≤</ci></apply><cn id="S1.SS2.SSS1.Px2.p2.4.m4.1.1.3.cmml" type="integer" xref="S1.SS2.SSS1.Px2.p2.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p2.4.m4.1c">q^{\prime}_{0}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p2.4.m4.1d">italic_q start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>. However, during the semifinals, we discovered that such fictional documents contained a significant amount of irrelevant keywords and redundant information due to the large model‚Äôs hallucinations, greatly affecting the effectiveness of the retrieval process. Therefore, we attempted to minimize the hallucinations and redundant information in the initial fictional document <math alttext="q^{\prime}_{0}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p2.5.m5.1"><semantics id="S1.SS2.SSS1.Px2.p2.5.m5.1a"><msubsup id="S1.SS2.SSS1.Px2.p2.5.m5.1.1" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.cmml"><mi id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.2" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.2.cmml">q</mi><mn id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.3" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.3.cmml">0</mn><mo id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.3" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p2.5.m5.1b"><apply id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1">subscript</csymbol><apply id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.cmml" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.1.cmml" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1">superscript</csymbol><ci id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.2.cmml" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.2">ùëû</ci><ci id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.3.cmml" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.2.3">‚Ä≤</ci></apply><cn id="S1.SS2.SSS1.Px2.p2.5.m5.1.1.3.cmml" type="integer" xref="S1.SS2.SSS1.Px2.p2.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p2.5.m5.1c">q^{\prime}_{0}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p2.5.m5.1d">italic_q start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> by using the BM25 algorithm and dense retrieval (using GTE-QWEN encoding) to identify the most relevant top1 document and use it for context prompting.</p>
</div>
<div class="ltx_para" id="S1.SS2.SSS1.Px2.p3">
<p class="ltx_p" id="S1.SS2.SSS1.Px2.p3.4">For the generated fictional documents, we also adopted two application methods: 1. Using the fictional document <math alttext="q^{\prime}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p3.1.m1.1"><semantics id="S1.SS2.SSS1.Px2.p3.1.m1.1a"><msup id="S1.SS2.SSS1.Px2.p3.1.m1.1.1" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1.cmml"><mi id="S1.SS2.SSS1.Px2.p3.1.m1.1.1.2" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1.2.cmml">q</mi><mo id="S1.SS2.SSS1.Px2.p3.1.m1.1.1.3" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p3.1.m1.1b"><apply id="S1.SS2.SSS1.Px2.p3.1.m1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p3.1.m1.1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1">superscript</csymbol><ci id="S1.SS2.SSS1.Px2.p3.1.m1.1.1.2.cmml" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1.2">ùëû</ci><ci id="S1.SS2.SSS1.Px2.p3.1.m1.1.1.3.cmml" xref="S1.SS2.SSS1.Px2.p3.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p3.1.m1.1c">q^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p3.1.m1.1d">italic_q start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> combined with the original document <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p3.2.m2.1"><semantics id="S1.SS2.SSS1.Px2.p3.2.m2.1a"><mi id="S1.SS2.SSS1.Px2.p3.2.m2.1.1" xref="S1.SS2.SSS1.Px2.p3.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p3.2.m2.1b"><ci id="S1.SS2.SSS1.Px2.p3.2.m2.1.1.cmml" xref="S1.SS2.SSS1.Px2.p3.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p3.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p3.2.m2.1d">italic_q</annotation></semantics></math> for <span class="ltx_text ltx_font_bold" id="S1.SS2.SSS1.Px2.p3.4.1">coarse ranking</span> retrieval. 2. Using only the fictional document <math alttext="q^{\prime}" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p3.3.m3.1"><semantics id="S1.SS2.SSS1.Px2.p3.3.m3.1a"><msup id="S1.SS2.SSS1.Px2.p3.3.m3.1.1" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1.cmml"><mi id="S1.SS2.SSS1.Px2.p3.3.m3.1.1.2" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1.2.cmml">q</mi><mo id="S1.SS2.SSS1.Px2.p3.3.m3.1.1.3" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p3.3.m3.1b"><apply id="S1.SS2.SSS1.Px2.p3.3.m3.1.1.cmml" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS1.Px2.p3.3.m3.1.1.1.cmml" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1">superscript</csymbol><ci id="S1.SS2.SSS1.Px2.p3.3.m3.1.1.2.cmml" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1.2">ùëû</ci><ci id="S1.SS2.SSS1.Px2.p3.3.m3.1.1.3.cmml" xref="S1.SS2.SSS1.Px2.p3.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p3.3.m3.1c">q^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p3.3.m3.1d">italic_q start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> combined with the original document <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS1.Px2.p3.4.m4.1"><semantics id="S1.SS2.SSS1.Px2.p3.4.m4.1a"><mi id="S1.SS2.SSS1.Px2.p3.4.m4.1.1" xref="S1.SS2.SSS1.Px2.p3.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS1.Px2.p3.4.m4.1b"><ci id="S1.SS2.SSS1.Px2.p3.4.m4.1.1.cmml" xref="S1.SS2.SSS1.Px2.p3.4.m4.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS1.Px2.p3.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS1.Px2.p3.4.m4.1d">italic_q</annotation></semantics></math> for <span class="ltx_text ltx_font_bold" id="S1.SS2.SSS1.Px2.p3.4.2">re-ranking</span> of retrieval results.</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="268" id="S1.F2.g1" src="extracted/5927071/pics/rag-fig.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Process of generating hypothetical documents</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsubsection" id="S1.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.2 </span>Dual-route Sparse Retrieval for Coarse Ranking</h4>
<div class="ltx_para" id="S1.SS2.SSS2.p1">
<p class="ltx_p" id="S1.SS2.SSS2.p1.1">In the sparse retrieval section, we utilized the BM25 algorithm to construct the retriever. The core idea of BM25 is based on term frequency (TF) and inverse document frequency (IDF), and it also incorporates document length information to calculate the relevance between the document and query <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS2.p1.1.m1.1"><semantics id="S1.SS2.SSS2.p1.1.m1.1a"><mi id="S1.SS2.SSS2.p1.1.m1.1.1" xref="S1.SS2.SSS2.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS2.p1.1.m1.1b"><ci id="S1.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S1.SS2.SSS2.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS2.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS2.p1.1.m1.1d">italic_q</annotation></semantics></math>. Specifically, the BM25 retriever primarily consists of a Chinese tokenizer and a stopword list. We will introduce each component in detail.</p>
</div>
<section class="ltx_paragraph" id="S1.SS2.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Chinese Tokenizer</h5>
<div class="ltx_para" id="S1.SS2.SSS2.Px1.p1">
<p class="ltx_p" id="S1.SS2.SSS2.Px1.p1.1">For the Chinese tokenizer, we used the widely known jieba Chinese tokenizer<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_href" href="https://github.com/fxsjy/jieba" title="">https://github.com/fxsjy/jieba</a></span></span></span>, which is lightweight and supports multi-threaded mode to accelerate tokenization and part-of-speech analysis. It also allows for customization of word frequency or dictionaries to adjust tokenization preferences. For the tokenizer, we also attempted to customize the vocabulary; in the current 5G communication maintenance scenario, we chose a related IT field lexicon collected by Tsinghua University<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_href" href="http://thuocl.thunlp.org" title="">http://thuocl.thunlp.org</a></span></span></span> loaded into the tokenizer. However, the results in practice were mediocre, so we ultimately continued using the original jieba lexicon.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS2.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Stopword List</h5>
<div class="ltx_para" id="S1.SS2.SSS2.Px2.p1">
<p class="ltx_p" id="S1.SS2.SSS2.Px2.p1.1">For the Chinese stopword list, we adopted the common Chinese stopword list collected by Harbin Institute of Technology<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_href" href="https://github.com/goto456/stopwords" title="">https://github.com/goto456/stopwords</a></span></span></span> as a reference for filtering out meaningless words during Chinese tokenization. By filtering out irrelevant words and special symbols, we improve the hit rate of valid keywords and increase the recall rate of correct documents.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS2.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Dual-route Retrieval</h5>
<div class="ltx_para" id="S1.SS2.SSS2.Px3.p1">
<p class="ltx_p" id="S1.SS2.SSS2.Px3.p1.1">The BM25 dual-route retrieval for coarse ranking consists of text block retrieval and path retrieval.</p>
<ol class="ltx_enumerate" id="S1.I4">
<li class="ltx_item" id="S1.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I4.i1.p1">
<p class="ltx_p" id="S1.I4.i1.p1.1">Text block retrieval. Use BM25 to search the segmented text blocks, recalling the top 192 text blocks with a coarse ranking score greater than 0.</p>
</div>
</li>
<li class="ltx_item" id="S1.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I4.i2.p1">
<p class="ltx_p" id="S1.I4.i2.p1.1">Path retrieval. Considering that some questions are highly relevant to our extracted knowledge paths, such as the question "How many types of VNF elasticity are there?", where both VNF and elasticity can be directly found in related knowledge paths. Hence, we designed a path search using BM25 to search the knowledge paths, recalling the top 6 text blocks with a coarse ranking score greater than 0.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS2.SSS2.Px4">
<h5 class="ltx_title ltx_title_paragraph">Retrieval Process</h5>
<div class="ltx_para" id="S1.SS2.SSS2.Px4.p1">
<p class="ltx_p" id="S1.SS2.SSS2.Px4.p1.1">The BM25 retriever follows the document retrieval process below for a given query <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS2.Px4.p1.1.m1.1"><semantics id="S1.SS2.SSS2.Px4.p1.1.m1.1a"><mi id="S1.SS2.SSS2.Px4.p1.1.m1.1.1" xref="S1.SS2.SSS2.Px4.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS2.Px4.p1.1.m1.1b"><ci id="S1.SS2.SSS2.Px4.p1.1.m1.1.1.cmml" xref="S1.SS2.SSS2.Px4.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS2.Px4.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS2.Px4.p1.1.m1.1d">italic_q</annotation></semantics></math>:</p>
<ol class="ltx_enumerate" id="S1.I5">
<li class="ltx_item" id="S1.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I5.i1.p1">
<p class="ltx_p" id="S1.I5.i1.p1.1">Document Expansion. For text block retrieval, we concatenate the file path and each text block together to serve as expanded documents for retrieval.</p>
</div>
</li>
<li class="ltx_item" id="S1.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I5.i2.p1">
<p class="ltx_p" id="S1.I5.i2.p1.1">Document Preprocessing. First, filter all documents (text blocks or paths) with stopwords, then use the Chinese tokenizer for tokenization, and pre-compute the IDF scores of the documents.</p>
</div>
</li>
<li class="ltx_item" id="S1.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I5.i3.p1">
<p class="ltx_p" id="S1.I5.i3.p1.1">Query Processing. Filter the query <math alttext="q" class="ltx_Math" display="inline" id="S1.I5.i3.p1.1.m1.1"><semantics id="S1.I5.i3.p1.1.m1.1a"><mi id="S1.I5.i3.p1.1.m1.1.1" xref="S1.I5.i3.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.I5.i3.p1.1.m1.1b"><ci id="S1.I5.i3.p1.1.m1.1.1.cmml" xref="S1.I5.i3.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I5.i3.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.I5.i3.p1.1.m1.1d">italic_q</annotation></semantics></math> with stopwords and perform Chinese tokenization.</p>
</div>
</li>
<li class="ltx_item" id="S1.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I5.i4.p1">
<p class="ltx_p" id="S1.I5.i4.p1.1">Similarity Recall. Count the keywords of query <math alttext="q" class="ltx_Math" display="inline" id="S1.I5.i4.p1.1.m1.1"><semantics id="S1.I5.i4.p1.1.m1.1a"><mi id="S1.I5.i4.p1.1.m1.1.1" xref="S1.I5.i4.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.I5.i4.p1.1.m1.1b"><ci id="S1.I5.i4.p1.1.m1.1.1.cmml" xref="S1.I5.i4.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I5.i4.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.I5.i4.p1.1.m1.1d">italic_q</annotation></semantics></math> and calculate the TF values of each document, compute the relevance scores based on TF and IDF values, and recall relevant documents based on scores.</p>
</div>
</li>
<li class="ltx_item" id="S1.I5.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S1.I5.i5.p1">
<p class="ltx_p" id="S1.I5.i5.p1.1">File Path Filtering. For text block retrieval, we use the file paths provided in the competition to compare metadata, filtering out text blocks from other sources.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S1.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.3 </span>Dense Retrieval for Coarse Ranking</h4>
<div class="ltx_para" id="S1.SS2.SSS3.p1">
<p class="ltx_p" id="S1.SS2.SSS3.p1.1">In the dense retrieval section, we employed the gte-Qwen2-7B-instruct model developed by Alibaba<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_href" href="https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct" title="">https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct</a></span></span></span>¬†<cite class="ltx_cite ltx_citemacro_cite">Li et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib6" title="">2023</a>)</cite>, which has achieved advanced results on the MTEB benchmark.</p>
</div>
<section class="ltx_paragraph" id="S1.SS2.SSS3.Px1">
<h5 class="ltx_title ltx_title_paragraph">Retrieval Process</h5>
<div class="ltx_para" id="S1.SS2.SSS3.Px1.p1">
<p class="ltx_p" id="S1.SS2.SSS3.Px1.p1.1">The dense retriever for a given query <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS3.Px1.p1.1.m1.1"><semantics id="S1.SS2.SSS3.Px1.p1.1.m1.1a"><mi id="S1.SS2.SSS3.Px1.p1.1.m1.1.1" xref="S1.SS2.SSS3.Px1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS3.Px1.p1.1.m1.1b"><ci id="S1.SS2.SSS3.Px1.p1.1.m1.1.1.cmml" xref="S1.SS2.SSS3.Px1.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS3.Px1.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS3.Px1.p1.1.m1.1d">italic_q</annotation></semantics></math> follows the specific document retrieval process as outlined below:</p>
<ol class="ltx_enumerate" id="S1.I6">
<li class="ltx_item" id="S1.I6.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I6.i1.p1">
<p class="ltx_p" id="S1.I6.i1.p1.1">Document Expansion. We concatenate the file path with each text block to serve as expanded documents for retrieval.</p>
</div>
</li>
<li class="ltx_item" id="S1.I6.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I6.i2.p1">
<p class="ltx_p" id="S1.I6.i2.p1.1">Document Encoding. All text blocks are input into the model to be encoded and the representations are stored in a Qdrant<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_href" href="https://qdrant.tech/" title="">https://qdrant.tech/</a></span></span></span> vector database.</p>
</div>
</li>
<li class="ltx_item" id="S1.I6.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I6.i3.p1">
<p class="ltx_p" id="S1.I6.i3.p1.1">Query Encoding. Using a query prompt template, we transform <math alttext="q" class="ltx_Math" display="inline" id="S1.I6.i3.p1.1.m1.1"><semantics id="S1.I6.i3.p1.1.m1.1a"><mi id="S1.I6.i3.p1.1.m1.1.1" xref="S1.I6.i3.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.I6.i3.p1.1.m1.1b"><ci id="S1.I6.i3.p1.1.m1.1.1.cmml" xref="S1.I6.i3.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I6.i3.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.I6.i3.p1.1.m1.1d">italic_q</annotation></semantics></math> into an input suitable for the GTE model and encode it using the model.</p>
</div>
</li>
<li class="ltx_item" id="S1.I6.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I6.i4.p1">
<p class="ltx_p" id="S1.I6.i4.p1.1">Similarity Recall. During retrieval, cosine similarity is used for matching, recalling the top 288 text blocks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I6.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S1.I6.i5.p1">
<p class="ltx_p" id="S1.I6.i5.p1.1">File Path Filtering. Using the file paths provided in the competition, we employ a Qdrant filter to eliminate text blocks from other sources.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S1.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.4 </span>LLM Reranker Re-ranking</h4>
<div class="ltx_para" id="S1.SS2.SSS4.p1">
<p class="ltx_p" id="S1.SS2.SSS4.p1.1">We utilized the bge-reranker-v2-minicpm-layerwise model¬†<cite class="ltx_cite ltx_citemacro_cite">Chen et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib1" title="">2024</a>)</cite>, a LLM Reranker trained on a hybrid of multiple multilingual ranking datasets using MiniCPM-2B-dpo-bf16. This model exhibits advanced ranking performance in both Chinese and English and includes accompanying tool code, which can be conveniently fine-tuned for specific scenarios.</p>
</div>
<section class="ltx_paragraph" id="S1.SS2.SSS4.Px1">
<h5 class="ltx_title ltx_title_paragraph">Re-ranking Process</h5>
<div class="ltx_para" id="S1.SS2.SSS4.Px1.p1">
<p class="ltx_p" id="S1.SS2.SSS4.Px1.p1.2">The LLM-Reranker for a given query <math alttext="q" class="ltx_Math" display="inline" id="S1.SS2.SSS4.Px1.p1.1.m1.1"><semantics id="S1.SS2.SSS4.Px1.p1.1.m1.1a"><mi id="S1.SS2.SSS4.Px1.p1.1.m1.1.1" xref="S1.SS2.SSS4.Px1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS4.Px1.p1.1.m1.1b"><ci id="S1.SS2.SSS4.Px1.p1.1.m1.1.1.cmml" xref="S1.SS2.SSS4.Px1.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS4.Px1.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS4.Px1.p1.1.m1.1d">italic_q</annotation></semantics></math> and <math alttext="k^{\prime}" class="ltx_Math" display="inline" id="S1.SS2.SSS4.Px1.p1.2.m2.1"><semantics id="S1.SS2.SSS4.Px1.p1.2.m2.1a"><msup id="S1.SS2.SSS4.Px1.p1.2.m2.1.1" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1.cmml"><mi id="S1.SS2.SSS4.Px1.p1.2.m2.1.1.2" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1.2.cmml">k</mi><mo id="S1.SS2.SSS4.Px1.p1.2.m2.1.1.3" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.SS2.SSS4.Px1.p1.2.m2.1b"><apply id="S1.SS2.SSS4.Px1.p1.2.m2.1.1.cmml" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S1.SS2.SSS4.Px1.p1.2.m2.1.1.1.cmml" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1">superscript</csymbol><ci id="S1.SS2.SSS4.Px1.p1.2.m2.1.1.2.cmml" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1.2">ùëò</ci><ci id="S1.SS2.SSS4.Px1.p1.2.m2.1.1.3.cmml" xref="S1.SS2.SSS4.Px1.p1.2.m2.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.SSS4.Px1.p1.2.m2.1c">k^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.SSS4.Px1.p1.2.m2.1d">italic_k start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> coarsely ranked text blocks follows the specific document ranking process as outlined below:</p>
<ol class="ltx_enumerate" id="S1.I7">
<li class="ltx_item" id="S1.I7.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I7.i1.p1">
<p class="ltx_p" id="S1.I7.i1.p1.1">Document Expansion. We concatenate the knowledge paths with each text block to serve as expanded documents for retrieval.</p>
</div>
</li>
<li class="ltx_item" id="S1.I7.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I7.i2.p1">
<p class="ltx_p" id="S1.I7.i2.p1.3">Text Processing. Combine <math alttext="q" class="ltx_Math" display="inline" id="S1.I7.i2.p1.1.m1.1"><semantics id="S1.I7.i2.p1.1.m1.1a"><mi id="S1.I7.i2.p1.1.m1.1.1" xref="S1.I7.i2.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S1.I7.i2.p1.1.m1.1b"><ci id="S1.I7.i2.p1.1.m1.1.1.cmml" xref="S1.I7.i2.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I7.i2.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S1.I7.i2.p1.1.m1.1d">italic_q</annotation></semantics></math> with the <math alttext="k^{\prime}" class="ltx_Math" display="inline" id="S1.I7.i2.p1.2.m2.1"><semantics id="S1.I7.i2.p1.2.m2.1a"><msup id="S1.I7.i2.p1.2.m2.1.1" xref="S1.I7.i2.p1.2.m2.1.1.cmml"><mi id="S1.I7.i2.p1.2.m2.1.1.2" xref="S1.I7.i2.p1.2.m2.1.1.2.cmml">k</mi><mo id="S1.I7.i2.p1.2.m2.1.1.3" xref="S1.I7.i2.p1.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.I7.i2.p1.2.m2.1b"><apply id="S1.I7.i2.p1.2.m2.1.1.cmml" xref="S1.I7.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S1.I7.i2.p1.2.m2.1.1.1.cmml" xref="S1.I7.i2.p1.2.m2.1.1">superscript</csymbol><ci id="S1.I7.i2.p1.2.m2.1.1.2.cmml" xref="S1.I7.i2.p1.2.m2.1.1.2">ùëò</ci><ci id="S1.I7.i2.p1.2.m2.1.1.3.cmml" xref="S1.I7.i2.p1.2.m2.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I7.i2.p1.2.m2.1c">k^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.I7.i2.p1.2.m2.1d">italic_k start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> text blocks to form <math alttext="k^{\prime}" class="ltx_Math" display="inline" id="S1.I7.i2.p1.3.m3.1"><semantics id="S1.I7.i2.p1.3.m3.1a"><msup id="S1.I7.i2.p1.3.m3.1.1" xref="S1.I7.i2.p1.3.m3.1.1.cmml"><mi id="S1.I7.i2.p1.3.m3.1.1.2" xref="S1.I7.i2.p1.3.m3.1.1.2.cmml">k</mi><mo id="S1.I7.i2.p1.3.m3.1.1.3" xref="S1.I7.i2.p1.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S1.I7.i2.p1.3.m3.1b"><apply id="S1.I7.i2.p1.3.m3.1.1.cmml" xref="S1.I7.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S1.I7.i2.p1.3.m3.1.1.1.cmml" xref="S1.I7.i2.p1.3.m3.1.1">superscript</csymbol><ci id="S1.I7.i2.p1.3.m3.1.1.2.cmml" xref="S1.I7.i2.p1.3.m3.1.1.2">ùëò</ci><ci id="S1.I7.i2.p1.3.m3.1.1.3.cmml" xref="S1.I7.i2.p1.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I7.i2.p1.3.m3.1c">k^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S1.I7.i2.p1.3.m3.1d">italic_k start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> query-document pairs, which are then input into the tokenizer to generate input data for the LLM.</p>
</div>
</li>
<li class="ltx_item" id="S1.I7.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I7.i3.p1">
<p class="ltx_p" id="S1.I7.i3.p1.1">Similarity Ranking. The input data is fed into the LLM to obtain re-ranking scores for the query and each text block, and the blocks are sorted according to these scores. The highest ranked <math alttext="k" class="ltx_Math" display="inline" id="S1.I7.i3.p1.1.m1.1"><semantics id="S1.I7.i3.p1.1.m1.1a"><mi id="S1.I7.i3.p1.1.m1.1.1" xref="S1.I7.i3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.I7.i3.p1.1.m1.1b"><ci id="S1.I7.i3.p1.1.m1.1.1.cmml" xref="S1.I7.i3.p1.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I7.i3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.I7.i3.p1.1.m1.1d">italic_k</annotation></semantics></math> (typically 6) text blocks are returned.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S1.SS2.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.5 </span>Multi-route Ranking Fusion</h4>
<section class="ltx_paragraph" id="S1.SS2.SSS5.Px1">
<h5 class="ltx_title ltx_title_paragraph">Fusion Algorithm</h5>
<div class="ltx_para" id="S1.SS2.SSS5.Px1.p1">
<p class="ltx_p" id="S1.SS2.SSS5.Px1.p1.1">Since we designed multiple routes for coarse retrieval, it is also necessary to design corresponding ranking fusion strategies. We primarily used two strategies: simple merging and Reciprocal Rank Fusion (RRF). The simple merging strategy directly de-duplicates and merges text blocks obtained from multiple routes. Reciprocal Rank Fusion sums the reciprocals of the ranks of the same document across multiple retrieval paths to compute the fusion score for re-ranking.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS2.SSS5.Px2">
<h5 class="ltx_title ltx_title_paragraph">Coarse Ranking Fusion</h5>
<div class="ltx_para" id="S1.SS2.SSS5.Px2.p1">
<p class="ltx_p" id="S1.SS2.SSS5.Px2.p1.1">The most straightforward use of ranking fusion is to merge the text blocks obtained from multi-route coarse retrieval into a single set of text blocks, which are then passed to the Reranker for re-ranking. In the semifinals, we used simple merging to combine results from two sparse retrieval routes.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS2.SSS5.Px3">
<h5 class="ltx_title ltx_title_paragraph">Re-ranking Fusion</h5>
<div class="ltx_para" id="S1.SS2.SSS5.Px3.p1">
<p class="ltx_p" id="S1.SS2.SSS5.Px3.p1.1">We can also perform fusion after coarse ranking and re-ranking for each route. In the preliminary rounds, we fused text blocks from sparse and dense retrieval routes. For these two routes, we designed three re-ranking fusion methods. (1) Use RRF to merge the results after coarse and fine ranking. (2) Input the text blocks from each route into the LLM to obtain respective answers, selecting the longer answer as the final one. (3) Input the text blocks from each route into the LLM to obtain respective answers and directly concatenate the answers from all routes.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S1.SS2.SSS6">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.6 </span>LLM Answer Generation</h4>
<div class="ltx_para" id="S1.SS2.SSS6.p1">
<p class="ltx_p" id="S1.SS2.SSS6.p1.1">In this section, we first concatenate the contents of the top 6 text blocks obtained from re-ranking using the following template to create a context string:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS2.SSS6.p2">
<svg class="ltx_picture" height="74.6" id="S1.SS2.SSS6.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,74.6) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 68.7 C 0 71.96 2.64 74.6 5.91 74.6 L 594.09 74.6 C 597.36 74.6 600 71.96 600 68.7 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 68.7 C 1.97 70.87 3.73 72.64 5.91 72.64 L 594.09 72.64 C 596.27 72.64 598.03 70.87 598.03 68.7 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="47.05" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S1.SS2.SSS6.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S1.SS2.SSS6.p2.pic1.1.1.1.1.1.1">### Document 0: {chunk_i}</span>
<span class="ltx_p" id="S1.SS2.SSS6.p2.pic1.1.1.1.1.1.2">‚Ä¶</span>
<span class="ltx_p" id="S1.SS2.SSS6.p2.pic1.1.1.1.1.1.3">### Document 5: {chunk_i}</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S1.SS2.SSS6.p3">
<p class="ltx_p" id="S1.SS2.SSS6.p3.1">Note that the text blocks input into GLM4 here include concatenated image content, whereas the text blocks in the previous coarse and re-ranking processes did not include image content.</p>
</div>
<div class="ltx_para" id="S1.SS2.SSS6.p4">
<p class="ltx_p" id="S1.SS2.SSS6.p4.1">We then combine the context string and the question using the following question-and-answer template, and input it into GLM4 to obtain an answer:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS2.SSS6.p5">
<svg class="ltx_picture" height="136.64" id="S1.SS2.SSS6.p5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,136.64) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 130.74 C 0 134 2.64 136.64 5.91 136.64 L 594.09 136.64 C 597.36 136.64 600 134 600 130.74 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 130.74 C 1.97 132.91 3.73 134.67 5.91 134.67 L 594.09 134.67 C 596.27 134.67 598.03 132.91 598.03 130.74 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="109.08" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.1">The context information is as follows:</span>
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.2">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.3">{context_str}</span>
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.4">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.5">Please answer the following question based on the context information and not your own knowledge. Answers can be itemized. If the context does not contain relevant information, you may respond with "uncertain" and should not restate the context information:</span>
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.6">{query_str}</span>
<span class="ltx_p" id="S1.SS2.SSS6.p5.pic1.1.1.1.1.1.7">Answer:</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S1.SS2.SSS6.p6">
<p class="ltx_p" id="S1.SS2.SSS6.p6.1">Additionally, we have designed other formats of question-and-answer templates. Inspired by Chain-of-Thought¬†<cite class="ltx_cite ltx_citemacro_cite">Wei et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib11" title="">2022</a>)</cite>, we designed a Chain-of-Thought question-and-answer template (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1.SS2" title="A.2 Chain of Thought Question-and-Answer Template ‚Ä£ Appendix A Question-and-Answer Prompt Templates ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">A.2</span></a>). Drawing from COSTAR¬†<cite class="ltx_cite ltx_citemacro_cite">Teo (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib9" title="">2023</a>)</cite>, we designed a markdown format question-and-answer template (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1.SS1" title="A.1 Markdown Format Question-and-Answer Template ‚Ä£ Appendix A Question-and-Answer Prompt Templates ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">A.1</span></a>). To emphasize the importance of the top1 document, we designed a focused question-and-answer template (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A1.SS3" title="A.3 Focused Question-and-Answer Template ‚Ä£ Appendix A Question-and-Answer Prompt Templates ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">A.3</span></a>). Related experimental results are discussed therein.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S1.SS2.SSS7">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">1.2.7 </span>LLM Answer Optimization</h4>
<div class="ltx_para" id="S1.SS2.SSS7.p1">
<p class="ltx_p" id="S1.SS2.SSS7.p1.1">Due to our observation that the LLM gives attention to each text block, which may result in the effective information from the top1 text block not being fully utilized, we designed an answer integration prompt (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#A2" title="Appendix B Answer Integration Template ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">B</span></a>). This prompt allows us to integrate and supplement the answers derived from the 6 text blocks using the top1 text block, leading to the final answer.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S1.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S1.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S1.T1.1.1.1.1" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1.1">id</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.2" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.2.1">data</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.3" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.3.1">chunk</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.4" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.4.1">coarse ranking</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.5" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.5.1">re-ranking</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.6" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.6.1">fusion</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.1.1.1.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.7.1">accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T1.1.2.1.1" style="padding-left:13.0pt;padding-right:13.0pt;">0</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}0}‚Éù,3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.5" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.2.1.7" style="padding-left:13.0pt;padding-right:13.0pt;">57.86</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.3.2.1" style="padding-left:13.0pt;padding-right:13.0pt;">1</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.5" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.3.2.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.3.2.7.1">68.59</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.4.3.1" style="padding-left:13.0pt;padding-right:13.0pt;">2</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.5" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.4.3.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.4.3.7.1">69.55</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T1.1.5.4.1" style="padding-left:13.0pt;padding-right:13.0pt;">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.5.4.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.5.4.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.5.4.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,192</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.5.4.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{0}}‚Éù,8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.5.4.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.5.4.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.5.4.7.1">73.73</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.6.5.1" style="padding-left:13.0pt;padding-right:13.0pt;">4</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.6.5.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.6.5.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.6.5.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,256</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.6.5.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{0}}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.6.5.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.6.5.7" style="padding-left:13.0pt;padding-right:13.0pt;">70.68</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.7.6.1" style="padding-left:13.0pt;padding-right:13.0pt;">5</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.7.6.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.7.6.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.7.6.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}2}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.7.6.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{1}}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.7.6.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.7.6.7" style="padding-left:13.0pt;padding-right:13.0pt;">69.25</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T1.1.8.7.1" style="padding-left:13.0pt;padding-right:13.0pt;">6</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.8.7.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{0}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.8.7.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.8.7.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,288</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.8.7.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.8.7.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.8.7.7" style="padding-left:13.0pt;padding-right:13.0pt;">77.07</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.9.8.1" style="padding-left:13.0pt;padding-right:13.0pt;">7</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.9.8.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.9.8.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.9.8.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,288</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.9.8.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.9.8.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.9.8.7" style="padding-left:13.0pt;padding-right:13.0pt;">77.51</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.10.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.10.9.1" style="padding-left:13.0pt;padding-right:13.0pt;">8</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.10.9.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.10.9.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.10.9.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,288</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.10.9.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.10.9.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.10.9.7" style="padding-left:13.0pt;padding-right:13.0pt;">77.92</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.11.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.11.10.1" style="padding-left:13.0pt;padding-right:13.0pt;">9</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.11.10.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.11.10.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.11.10.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}1}‚Éù,256</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.11.10.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,8</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.11.10.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.11.10.7" style="padding-left:13.0pt;padding-right:13.0pt;">78.49</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.12.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.12.11.1" style="padding-left:13.0pt;padding-right:13.0pt;">10</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.12.11.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.12.11.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.12.11.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.12.11.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.12.11.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.12.11.7" style="padding-left:13.0pt;padding-right:13.0pt;">80.90</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.13.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.13.12.1" style="padding-left:13.0pt;padding-right:13.0pt;">11</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.13.12.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.13.12.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,50</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.13.12.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.13.12.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.13.12.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.13.12.7" style="padding-left:13.0pt;padding-right:13.0pt;">81.38</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.14.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.14.13.1" style="padding-left:13.0pt;padding-right:13.0pt;">12</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.14.13.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.14.13.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,100</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.14.13.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.14.13.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.14.13.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.14.13.7" style="padding-left:13.0pt;padding-right:13.0pt;">81.77</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.15.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.15.14.1" style="padding-left:13.0pt;padding-right:13.0pt;">13</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.15.14.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.15.14.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,100</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.15.14.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.15.14.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.15.14.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.15.14.7" style="padding-left:13.0pt;padding-right:13.0pt;">81.88</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.16.15">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.16.15.1" style="padding-left:13.0pt;padding-right:13.0pt;">14</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.16.15.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.16.15.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.16.15.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.16.15.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{2}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.16.15.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.16.15.7" style="padding-left:13.0pt;padding-right:13.0pt;">82.87</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.17.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.17.16.1" style="padding-left:13.0pt;padding-right:13.0pt;">15</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.17.16.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.17.16.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.17.16.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.17.16.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.17.16.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.17.16.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.17.16.7.1">82.97</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.18.17">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.18.17.1" style="padding-left:13.0pt;padding-right:13.0pt;">16</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.18.17.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.18.17.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.18.17.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}4}‚Éù,288</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.18.17.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.18.17.6" style="padding-left:13.0pt;padding-right:13.0pt;">-</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.18.17.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.18.17.7.1">83.02</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.19.18">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T1.1.19.18.1" style="padding-left:13.0pt;padding-right:13.0pt;">17</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.19.18.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.19.18.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.19.18.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}4}‚Éù,288 \small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.19.18.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.19.18.6" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{green}0}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.19.18.7" style="padding-left:13.0pt;padding-right:13.0pt;">81.80</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.20.19">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.20.19.1" style="padding-left:13.0pt;padding-right:13.0pt;">18</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.20.19.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.20.19.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.20.19.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}4}‚Éù,288 \small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.20.19.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.20.19.6" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{green}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.20.19.7" style="padding-left:13.0pt;padding-right:13.0pt;">82.50</td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.21.20">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.21.20.1" style="padding-left:13.0pt;padding-right:13.0pt;">19</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.21.20.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.21.20.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.21.20.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}4}‚Éù,288 \small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.21.20.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.21.20.6" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{green}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.21.20.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.21.20.7.1">83.45</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.22.21">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T1.1.22.21.1" style="padding-left:13.0pt;padding-right:13.0pt;">20</th>
<td class="ltx_td ltx_align_center" id="S1.T1.1.22.21.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.22.21.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.22.21.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}4}‚Éù,288 \small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.22.21.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.22.21.6" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{green}3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T1.1.22.21.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.22.21.7.1">83.70</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.23.22">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S1.T1.1.23.22.1" style="padding-left:13.0pt;padding-right:13.0pt;">21</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.23.22.2" style="padding-left:13.0pt;padding-right:13.0pt;">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.23.22.3" style="padding-left:13.0pt;padding-right:13.0pt;">1024,200</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.23.22.4" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{blue}4}‚Éù,288 \small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.23.22.5" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.23.22.6" style="padding-left:13.0pt;padding-right:13.0pt;">\small{\color{green}4}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.23.22.7" style="padding-left:13.0pt;padding-right:13.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.23.22.7.1">84.38</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Preliminary round experimental results. In the ‚ÄôChunk‚Äô column, the two numbers represent chunk_size and chunk_overlap, respectively. In the ‚ÄôCoarse Ranking‚Äô and ‚ÄôRe-ranking‚Äô columns, multiple search paths are separated by spaces, and within each search path, the components separated by commas represent the retrieval/sorting method and top-k, respectively.</figcaption>
</figure>
<figure class="ltx_table" id="S1.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S1.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S1.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.1.1">id</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.2.1">data</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.3.1">chunk</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.4.1">coarse ranking</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.5.1">re-ranking</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.6.1">fusion</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.7.1">image</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.8.1">answer merge</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T2.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.1.1.9.1">accuracy</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T2.1.2.2.1">0</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.2">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.3">960,200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.4">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.2.2.9.1">91.53</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.3.3.1">1</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.2">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.3">960,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.4">\small{\color{blue}4}‚Éù,288</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.3.3.9">88.40</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.4.4.1">2</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.2">\small{2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.3">960,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.4">\small{\color{blue}4}‚Éù,288 \small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.6">\small{\color{green}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.4.4.9">90.00</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.5.5.1">3</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.4">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.5.5.9">90.26</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.6.6.1">4</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.2">\small{4}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.4">\small{\color{blue}3}‚Éù,192</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.6.6.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.6.6.9.1">91.38</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T2.1.7.7.1">5</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.3">1024,200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.7.7.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.7.7.9.1">92.70</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.8.8.1">6</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.8.8.9">89.30</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.9.9.1">7</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.9.9.9">87.12</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.10.10.1">8</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.5">\small{\textcolor{red}{3}}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.10.10.9">92.43</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.11.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.11.11.1">9</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.11.11.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.11.11.9.1">93.11</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.12.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.12.12.1">10</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.7">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.12.12.9">90.17</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.13.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T2.1.13.13.1">11</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.3">1024,200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.7">OCR Filter</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.13.13.9">92.5</td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.14.14.1">12</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.6">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.7">Rule Filter</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.14.14.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.14.14.9.1">94.24</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.15.15">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S1.T2.1.15.15.1">13</th>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.3">1024,200</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù \small{\color{blue}5}‚Éù,6</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.6">\small{\color{green}0}‚Éù</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.7">Rule Filter</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.8">-</td>
<td class="ltx_td ltx_align_center" id="S1.T2.1.15.15.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.15.15.9.1">94.49</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.16.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S1.T2.1.16.16.1">14</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.3">1024,200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù \small{\color{blue}5}‚Éù,6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.6">\small{\color{green}0}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.7">Rule Filter</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.8">document concat</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T2.1.16.16.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.16.16.9.1">96.65</span></td>
</tr>
<tr class="ltx_tr" id="S1.T2.1.17.17">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S1.T2.1.17.17.1">15</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.2">\small{3}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.3">1024,200</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.4">\small{\color{blue}3}‚Éù,192,\small{\color{purple}2}‚Éù \small{\color{blue}5}‚Éù,6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.5">\small{\textcolor{red}{3}}‚Éù,6,\small{\color{purple}1}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.6">\small{\color{green}0}‚Éù</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.7">Rule Filter</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.8">prompt merge</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T2.1.17.17.9"><span class="ltx_text ltx_font_bold" id="S1.T2.1.17.17.9.1">95.72</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Semi-final experimental results. In the ‚ÄôChunk‚Äô column, the two numbers represent chunk_size and chunk_overlap, respectively. In the ‚ÄôCoarse Ranking‚Äô and ‚ÄôRe-ranking‚Äô columns, multiple search paths are separated by spaces, and within each search path, the components separated by commas represent the retrieval/sorting method, top-k, and the type of document expansion (if no expansion is applied, it is not listed).</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Accuracy</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Abbreviations Introduction</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">For ease of writing, we first introduce some important component identifiers.</p>
</div>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Data</h5>
<div class="ltx_para" id="S2.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.1">\small{0}‚Éù represents the official processed txt data. \small{1}‚Éù represents our own processed version 0 txt data, which supplements some missing data compared to the official data. \small{2}‚Éù is similar to \small{1}‚Éù, but each txt begins with a concatenated knowledge path. \small{3}‚Éù represents our own processed version 1 txt data, which retains more markdown-structured data consistent with the official data compared to version 0. \small{4}‚Éù is similar to \small{3}‚Éù but begins each txt with a concatenated knowledge path.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Coarse Ranking</h5>
<div class="ltx_para" id="S2.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.1">\small{\color{blue}0}‚Éù represents bge-small-zh-v1.5, \small{\color{blue}1}‚Éù represents bge-base-zh-v1.5, \small{\color{blue}2}‚Éù represents bce-embedding-base_v1, \small{\color{blue}3}‚Éù represents bm25 text block retrieval, \small{\color{blue}4}‚Éù represents gte-Qwen2-7B-instruct, \small{\color{blue}5}‚Éù represents bm25 knowledge path retrieval.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Re-ranking</h5>
<div class="ltx_para" id="S2.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px3.p1.1">\small{\textcolor{red}{0}}‚Éù represents bge-reranker-v2-m3, \small{\textcolor{red}{1}}‚Éù represents bce-reranker-base_v1, \small{\textcolor{red}{2}}‚Éù represents the 40-layer bge-reranker-v2-minicpm-layerwise, \small{\textcolor{red}{3}}‚Éù represents the 28-layer bge-reranker-v2-minicpm-layerwise.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Fusion</h5>
<div class="ltx_para" id="S2.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px4.p1.1">\small{\color{green}0}‚Éù represents simple merging for coarse ranking, \small{\color{green}1}‚Éù represents RRF fusion for coarse ranking, \small{\color{green}2}‚Éù represents re-ranking fusion using method¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5.Px3" title="Re-ranking Fusion ‚Ä£ 1.2.5 Multi-route Ranking Fusion ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.2.5</span></a>, \small{\color{green}3}‚Éù represents re-ranking fusion using method¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5.Px3" title="Re-ranking Fusion ‚Ä£ 1.2.5 Multi-route Ranking Fusion ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.2.5</span></a>, \small{\color{green}4}‚Éù represents re-ranking fusion using method¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS5.Px3" title="Re-ranking Fusion ‚Ä£ 1.2.5 Multi-route Ranking Fusion ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.2.5</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS1.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Document Expansion</h5>
<div class="ltx_para" id="S2.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S2.SS1.SSS0.Px5.p1.1">In the Coarse Rank and Re-rank columns, \small{\color{purple}1}‚Éù indicates that the document concatenates the file path, \small{\color{purple}2}‚Éù indicates that the document concatenates the knowledge path.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Preliminary Experiments</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In the preliminary round, our main results are displayed in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.T1" title="Table 1 ‚Ä£ 1.2.7 LLM Answer Optimization ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1</span></a>, and improvements were made in the following four stages:</p>
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">Single-route coarse retrieval (0-2). We explored the retrieval effects of the bge-zh-v1.5 series (small, base, large) and bm25. We found that bge-base-zh-v1.5 and bm25 performed best when the top 8 results were taken; too many or too few results could lead to inaccuracies in LLM comprehension or a lack of necessary information.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">Re-ranking based on BERT-Reranker (3-5). We explored the effects of BERT-based bge series rerankers and bce-reranker-base_v1, finding that bge-reranker-v2-m3 performed best. The best results for coarse ranking were between 192-288, and re-ranking performed best at top 8.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">Re-ranking based on LLM-Reranker (6-16). In this part, we made the following explorations: (1) We explored the effects of LLM-based bge series rerankers, finding that bge-reranker-v2-minicpm-layerwise significantly outperformed BERT-based rerankers, bringing an improvement of more than 3 percentage points. (2) We explored the dense retrieval effects of LLM-based embedding models, finding that gte-Qwen2-7B-Instruct, due to longer context lengths and a larger model size, performed better than the bge-zh-v1.5 series. (3) We perfected the data processing workflow, supplementing missing data from the official process, which brought a 1 percentage point improvement. (4) We optimized chunk parameters, finding that increasing chunk-overlap to preserve more complete semantic information brought a 2 percentage point improvement.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1">Dual-route sorting fusion (17-21). In this part, we explored the impact of different sorting fusion strategies for sparse and dense routes on the results. Among them, coarse ranking fusion performed lower than the results of both routes. In re-ranking fusion, all three methods achieved higher results than the individual routes. The operations of answer concatenation and taking the longer answer, due to the need to generate an answer separately for each route before fusion, are less efficient and unstable. Therefore, in general practice, the first type of re-ranking fusion strategy is preferred, i.e., RRF fusion of the results reranked separately for each route, serving as the final context input into the LLM.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Semi-final Experiments</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">In the preliminary round, we displayed our main results in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.T2" title="Table 2 ‚Ä£ 1.2.7 LLM Answer Optimization ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">2</span></a>, and we made improvements through the following four stages:</p>
<ol class="ltx_enumerate" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p" id="S2.I2.i1.p1.1">Exploration of Coarse Ranking Schemes (0-4). We optimized the data processing from the preliminary round, preserving more structured semantic information, and explored some of the better strategies from the preliminary round. We found that dense retrieval performed poorly, while BM25 alone could achieve good results.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p" id="S2.I2.i2.p1.1">Document Extension for Sorting (5-10). We explored the impact of appending path strings to each text block during coarse and fine ranking. We found that adding paths during coarse ranking brought significant gains, and appending file paths during fine ranking provided certain benefits. We ultimately selected a document extension scheme where knowledge paths were inserted during coarse ranking and file paths during fine ranking. This part brought about a 2% improvement.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S2.I2.i3.p1">
<p class="ltx_p" id="S2.I2.i3.p1.1">Utilization of Image Information (11-13). In this part, we explored the use of image information and found that the number of images after coarse screening with OCR in Chinese was large and varied. After fine screening with rules, we achieved a 1% improvement over previous methods.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S2.I2.i4.p1">
<p class="ltx_p" id="S2.I2.i4.p1.1">Answer Optimization (14-15). We discovered that concatenating the top1 text block with the answer could lead to a 2% improvement. Considering its practical effectiveness, we designed answer integration prompts that allow the LLM to supplement and optimize the answer in conjunction with the top1 text block, improving performance by about 2%.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Exploratory Experiments</h3>
<section class="ltx_subsubsection" id="S2.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1 </span>Query Rewriting</h4>
<div class="ltx_para" id="S2.SS4.SSS1.p1">
<p class="ltx_p" id="S2.SS4.SSS1.p1.1">For the query expansion and HyDE methods mentioned in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS1" title="1.2.1 Query Rewriting ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.2.1</span></a>, we tested them during both the preliminary and semi-final stages, with results displayed in Tables¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.T3" title="Table 3 ‚Ä£ 2.4.1 Query Rewriting ‚Ä£ 2.4 Exploratory Experiments ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.T4" title="Table 4 ‚Ä£ 2.4.1 Query Rewriting ‚Ä£ 2.4 Exploratory Experiments ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">4</span></a>, respectively. Overall, since the query terms in the preliminary and semi-final competitions were already relatively specific, query rewriting did not bring any benefit. These rewriting methods might be more effective when user queries are incomplete.</p>
</div>
<figure class="ltx_table" id="S2.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T3.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T3.1.1.1.2.1">Preliminary Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T3.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T3.1.2.1.1">Original</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S2.T3.1.2.1.2.1">82.0</span></td>
</tr>
<tr class="ltx_tr" id="S2.T3.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T3.1.3.2.1">Concat</td>
<td class="ltx_td ltx_align_center" id="S2.T3.1.3.2.2">78.2</td>
</tr>
<tr class="ltx_tr" id="S2.T3.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T3.1.4.3.1">Summary</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T3.1.4.3.2">79.4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Rewrite Performance</figcaption>
</figure>
<figure class="ltx_table" id="S2.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T4.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T4.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T4.1.1.1.2.1">Semifinal Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T4.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T4.1.2.1.1">Original</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T4.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S2.T4.1.2.1.2.1">92.7</span></td>
</tr>
<tr class="ltx_tr" id="S2.T4.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T4.1.3.2.1">Retrieval+HyDE</td>
<td class="ltx_td ltx_align_center" id="S2.T4.1.3.2.2">89.2</td>
</tr>
<tr class="ltx_tr" id="S2.T4.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T4.1.4.3.1">rerank+HyDE</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T4.1.4.3.2">88.2</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>HyDE Performance</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S2.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2 </span>Prompt Types</h4>
<div class="ltx_para" id="S2.SS4.SSS2.p1">
<p class="ltx_p" id="S2.SS4.SSS2.p1.1">We tested different prompt types mentioned in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S1.SS2.SSS6" title="1.2.6 LLM Answer Generation ‚Ä£ 1.2 RAG Pipeline ‚Ä£ 1 Introduction ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">1.2.6</span></a> during the semi-final stage, and the results are shown in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S2.T5" title="Table 5 ‚Ä£ 2.4.2 Prompt Types ‚Ä£ 2.4 Exploratory Experiments ‚Ä£ 2 Accuracy ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">5</span></a>. We found that the best results were still achieved with simple question-and-answer prompts. The Chain-of-Thought question-and-answer template led to too much explanatory output, the Markdown format question-and-answer template resulted in some extraneous characters, and the focused question-and-answer template did not significantly differ from the original template. Furthermore, through extensive experimentation with more prompts, we discovered that the GLM4 performs better with simpler prompts; more complex, structured prompts tend to have a negative impact.</p>
</div>
<figure class="ltx_table" id="S2.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T5.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T5.1.1.1.1.1">Prompt Type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T5.1.1.1.2.1">Semi-final Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T5.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S2.T5.1.2.1.1">Normal QA Template</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T5.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S2.T5.1.2.1.2.1">94.49</span></td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T5.1.3.2.1">CoT QA Template</td>
<td class="ltx_td ltx_align_center" id="S2.T5.1.3.2.2">89.75</td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S2.T5.1.4.3.1">Markdown Format QA Template</td>
<td class="ltx_td ltx_align_center" id="S2.T5.1.4.3.2">92.27</td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S2.T5.1.5.4.1">Focused QA Template</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T5.1.5.4.2">93.51</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Effects of Different Prompts</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Resource Consumption</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In our RAG process, only the Reranker requires significant GPU memory consumption. Thanks to enabling bfloat16, model loading requires only 5GB of GPU memory<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We also experimented with <span class="ltx_text ltx_font_bold" id="footnote8.1">8-bit quantization</span> and <span class="ltx_text ltx_font_bold" id="footnote8.2">pruning</span> as model compression techniques. While these methods reduce memory usage, they also significantly degrade performance, warranting further research.</span></span></span>. With the default batch size of 32, the total GPU memory consumption during inference is 12GB.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Deployment Difficulty</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The RAG framework is encapsulated as a process class, facilitating easy loading and use, allowing for one-click deployment. We provide a Docker deployment script, with the Docker image size being approximately 28GB. We also offer API deployment scripts based on FastAPI<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://fastapi.tiangolo.com/" title="">https://fastapi.tiangolo.com/</a></span></span></span> and a WebUI based on Streamlit<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://streamlit.io/" title="">https://streamlit.io/</a></span></span></span>, making it convenient for use.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Inference Latency</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Standard Scheme</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Standard Time Delay</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">In the semi-final‚Äôs standard scheme, we set the batch size for re-ranking to 32, with the inference latency for a question being 26 seconds, of which document sorting takes 6 seconds, and calling GLM4 twice takes 20 seconds.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Removing Answer Integration</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">By eliminating the answer integration step and directly returning the top 6 generated answers, only one call to GLM4 is needed, reducing the inference latency to 16 seconds.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Increasing Re-ranking Batch Size</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">Increasing the batch size to 256 increases the GPU memory usage but can reduce the inference latency to 24 seconds.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Full Process Acceleration Scheme</h5>
<div class="ltx_para" id="S5.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px4.p1.1">Beyond simple optimization strategies, we have also designed a full process acceleration scheme, which will be introduced in the following three subsections. This scheme aims to reduce time costs at each step. Due to the instability of GLM4 outputs, all experiments in this section terminate after the first generation of answers, without the final answer integration step, allowing for a more rigorous comparison of the impact of various acceleration methods on performance.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>BM25 Acceleration</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Since our retrieval stage relies heavily on BM25 for keyword matching, we introduced the bm25s¬†<cite class="ltx_cite ltx_citemacro_cite">L√π (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib8" title="">2024</a>)</cite> library to optimize the speed of BM25 retrieval.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T6.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.1.1">Implementation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.2.1">Time (s)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T6.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.3.1">Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.2.1.1">BM25Okapi</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.2.1.2">17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.2.1.3">94.49</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S5.T6.1.3.2.1.1">BM25s</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.3.2.2">0.05</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.1.3.2.3">94.24</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Effects of BM25 acceleration on the test set. Time represents the total search time for 103 questions related to BM25, and accuracy represents the evaluation score of the final generated answers.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Reranker Acceleration</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We used the bge-reranker-v2-minicpm-layerwise model developed by the Zhejiang University‚Äôs Institute for AI¬†<cite class="ltx_cite ltx_citemacro_cite">Chen et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib1" title="">2024</a>)</cite> as the LLM Reranker. This model supports customization of the number of inference layers, allowing selection from 8-40 layers based on one‚Äôs needs and resource constraints, thus reducing GPU memory overhead. In our preliminary experiments, we found that <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">28 layers</span> performed <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.2">slightly better than 40 layers</span>, with a difference of about 0.2 points, consistent with the empirical research conclusions given in the original repository. Therefore, both the preliminary and semi-final accuracy experiments utilized 28 layers.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">However, since the Reranker is time-consuming in practical inference, we considered whether fewer layers could be used to speed up the process. Classic early-exit techniques in BERT, such as FastBERT¬†<cite class="ltx_cite ltx_citemacro_cite">Liu et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib7" title="">2020</a>)</cite> and DeeBERT¬†<cite class="ltx_cite ltx_citemacro_cite">Xin et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib12" title="">2020</a>)</cite>, use information entropy exceeding a threshold as the condition for early exit, which is computationally intensive and results in unstable effects. Therefore, we designed a model early-exit algorithm based on maximum similarity selection, that is, for each query, we check if the softmax similarity output at the 12th layer in the first batch contains any values exceeding a certain threshold; if so, this query is inferred using just 12 layers, otherwise, 28 layers are used. We conducted an experiment using an A100 40G GPU to explore inference time, GPU memory usage, and accuracy at a batch size of 32, comparing different layers and early-exit methods. We randomly selected 10 queries and chose 192 text blocks for each, including 6 ground truth text blocks sorted using 28 layers in the complete RAG and 186 other random blocks. We predicted the sum of softmax scores of ground truth blocks relative to all blocks using various methods. Then, we assessed the similarity accuracy by dividing the predicted proportion by the proportion obtained with 28 layers, and compared the ranking accuracy of predicted ground truth with the 28-layer results, yielding the results shown in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.T7" title="Table 7 ‚Ä£ 5.3 Reranker Acceleration ‚Ä£ 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">7</span></a>. It can be seen that our proposed model early-exit method, while reducing inference time by 33%, is able to maintain ranking results consistent with those obtained using 28 layers directly, surpassing the entropy selection methods.</p>
</div>
<figure class="ltx_table" id="S5.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T7.1.1.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.1.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.1.1.1.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.2.1">Time(s)</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.1.1.1.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.3.1">Similarity(%)</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.1.1.1.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.4.1">Rank</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T7.1.2.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.2.1.1" style="padding-left:1.0pt;padding-right:1.0pt;">8-layer</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.2.1.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.2.1.2.1">1.67</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.2.1.3" style="padding-left:1.0pt;padding-right:1.0pt;">73</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.2.1.4" style="padding-left:1.0pt;padding-right:1.0pt;">2.5</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.3.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.3.2.1" style="padding-left:1.0pt;padding-right:1.0pt;">12-layer</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.3.2.2" style="padding-left:1.0pt;padding-right:1.0pt;">2.20</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.3.2.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.3.2.3.1">88</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.3.2.4" style="padding-left:1.0pt;padding-right:1.0pt;">3.2</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.4.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.4.3.1" style="padding-left:1.0pt;padding-right:1.0pt;">20-layer</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.4.3.2" style="padding-left:1.0pt;padding-right:1.0pt;">3.58</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.4.3.3" style="padding-left:1.0pt;padding-right:1.0pt;">86</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.4.3.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.4.3.4.1">4.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.5.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.5.4.1" style="padding-left:1.0pt;padding-right:1.0pt;">28-layer</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.5.4.2" style="padding-left:1.0pt;padding-right:1.0pt;">5.25</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.5.4.3" style="padding-left:1.0pt;padding-right:1.0pt;">100</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.5.4.4" style="padding-left:1.0pt;padding-right:1.0pt;">6.0</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.6.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.6.5.1" style="padding-left:1.0pt;padding-right:1.0pt;">40-layer</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.6.5.2" style="padding-left:1.0pt;padding-right:1.0pt;">7.71</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.6.5.3" style="padding-left:1.0pt;padding-right:1.0pt;">100</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.6.5.4" style="padding-left:1.0pt;padding-right:1.0pt;">5.4</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.7.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.7.6.1" style="padding-left:1.0pt;padding-right:1.0pt;">Maximum (0.1)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.7.6.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.7.6.2.1">2.59</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.7.6.3" style="padding-left:1.0pt;padding-right:1.0pt;">90</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T7.1.7.6.4" style="padding-left:1.0pt;padding-right:1.0pt;">3.7</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.8.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.8.7.1" style="padding-left:1.0pt;padding-right:1.0pt;">Maximum (0.2)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.8.7.2" style="padding-left:1.0pt;padding-right:1.0pt;">3.55</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.8.7.3" style="padding-left:1.0pt;padding-right:1.0pt;">96</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.8.7.4" style="padding-left:1.0pt;padding-right:1.0pt;">4.5</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.9.8">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.9.8.1" style="padding-left:1.0pt;padding-right:1.0pt;">Maximum (0.4)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.9.8.2" style="padding-left:1.0pt;padding-right:1.0pt;">4.57</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.9.8.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.9.8.3.1">97</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.9.8.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.1.9.8.4.1">5.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.10.9">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.10.9.1" style="padding-left:1.0pt;padding-right:1.0pt;">Entropy (0.2)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.10.9.2" style="padding-left:1.0pt;padding-right:1.0pt;">2.74</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.10.9.3" style="padding-left:1.0pt;padding-right:1.0pt;">89</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.10.9.4" style="padding-left:1.0pt;padding-right:1.0pt;">3.4</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.11.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.11.10.1" style="padding-left:1.0pt;padding-right:1.0pt;">Entropy (0.4)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.11.10.2" style="padding-left:1.0pt;padding-right:1.0pt;">3.37</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.11.10.3" style="padding-left:1.0pt;padding-right:1.0pt;">91</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.T7.1.11.10.4" style="padding-left:1.0pt;padding-right:1.0pt;">3.6</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.12.11">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T7.1.12.11.1" style="padding-left:1.0pt;padding-right:1.0pt;">Entropy (0.6)</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T7.1.12.11.2" style="padding-left:1.0pt;padding-right:1.0pt;">4.01</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T7.1.12.11.3" style="padding-left:1.0pt;padding-right:1.0pt;">91</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T7.1.12.11.4" style="padding-left:1.0pt;padding-right:1.0pt;">4.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Reranker Acceleration Experiment</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Context Compression</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We designed a context compression method based on BM25 semantic similarity, which we call BM25-Extract. For each chunk, we first split it into sentences, then use BM25 to calculate the similarity between the query and each chunk, and finally add sentences to the list in order of decreasing similarity until a set compression rate is reached. The sentences are then concatenated in their original relative positions. We compared BM25-Extract with advanced context compression methods LLMLingua¬†<cite class="ltx_cite ltx_citemacro_cite">Jiang et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib4" title="">2023a</a>)</cite> and LongLLMLingua¬†<cite class="ltx_cite ltx_citemacro_cite">Jiang et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#bib.bib5" title="">2023b</a>)</cite> as shown in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2410.10315v2#S5.T8" title="Table 8 ‚Ä£ 5.4 Context Compression ‚Ä£ 5 Inference Latency ‚Ä£ EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations"><span class="ltx_text ltx_ref_tag">8</span></a>. Our method has advantages of no GPU memory usage, faster speed, and higher accuracy, making it evidently more effective for cost-sensitive operational maintenance tasks.</p>
</div>
<figure class="ltx_table" id="S5.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T8.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T8.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.1.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.1.1.1">Compression Algorithm</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.1.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.1.2.1">Compression Rate (%)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.1.1.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.1.3.1">Tokens Saved</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.1.1.1.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.1.4.1">Accuracy</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T8.1.1.1.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.1.5.1">Time (s)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.2.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">Original Context</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.2.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">100</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.2.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.2.1.4" style="padding-left:3.0pt;padding-right:3.0pt;">94.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.2.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">9.30</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.3.2">
<td class="ltx_td ltx_align_center" id="S5.T8.1.3.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">LLMLingua(0.5)</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.3.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">62.80</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.3.2.3" style="padding-left:3.0pt;padding-right:3.0pt;">143k</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.3.2.4" style="padding-left:3.0pt;padding-right:3.0pt;">83.44</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.3.2.5" style="padding-left:3.0pt;padding-right:3.0pt;">10.47</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.4.3">
<td class="ltx_td ltx_align_center" id="S5.T8.1.4.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">LongLLMLingua(0.5)</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.4.3.2" style="padding-left:3.0pt;padding-right:3.0pt;">62.80</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.4.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">143k</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.4.3.4" style="padding-left:3.0pt;padding-right:3.0pt;">80.86</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.4.3.5" style="padding-left:3.0pt;padding-right:3.0pt;">10.52</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.5.4">
<td class="ltx_td ltx_align_center" id="S5.T8.1.5.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_text ltx_font_bold" id="S5.T8.1.5.4.1.1">BM25-Extract</span>(0.5)</td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.5.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.5.4.2.1">55.92</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.5.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.5.4.3.1">160k</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.5.4.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.5.4.4.1">86.48</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.1.5.4.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.5.4.5.1">7.70</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.6.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.6.5.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_text ltx_font_bold" id="S5.T8.1.6.5.1.1">BM25-Extract</span>(0.8)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.6.5.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.6.5.2.1">83.84</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.6.5.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.6.5.3.1">59k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.6.5.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.6.5.4.1">89.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.1.6.5.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S5.T8.1.6.5.5.1">8.12</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Effects of context compression on the test set. Compression rate refers to the ratio of the length of the compressed prompt to the original prompt; tokens saved refers to the reduction in context string length divided by the empirical value of 1.6 to estimate the number of tokens saved; time refers to the average time per question from document retrieval to answer generation, including context compression and GLM4 generation time.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Scalability</h2>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Document Scalability</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.1">Our solution is primarily based on BM25 retrieval and Reranker re-ranking, requiring only processing of the latest documents, followed by re-segmentation and IDF value calculation. The entire process has a small time overhead and can be completed within 5 minutes.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">User Scalability</h5>
<div class="ltx_para" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">Our solution has low GPU memory usage, and we have designed inference acceleration methods for various stages, allowing the use of specific optimization strategies depending on the user‚Äôs scale. Even using a fully unaccelerated solution, a single 80GB GPU can support at least six RAG processes, returning answers to users within half a minute.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This paper presents EasyRAG, an accurate, lightweight, efficient, flexible, and scalable retrieval-augmented question-answering framework aimed at automated network operations.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et¬†al. (2024)</span>
<span class="ltx_bibblock">
Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.03216" title="">Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Preprint</em>, arXiv:2402.03216.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et¬†al. (2022)</span>
<span class="ltx_bibblock">
Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2022.

</span>
<span class="ltx_bibblock">Precise zero-shot dense retrieval without relevance labels.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2212.10496</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GLM et¬†al. (2024)</span>
<span class="ltx_bibblock">
Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da¬†Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng¬†Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, and Zihan Wang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2406.12793" title="">Chatglm: A family of large language models from glm-130b to glm-4 all tools</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arXiv:2406.12793.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et¬†al. (2023a)</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.825" title="">LLMLingua: Compressing prompts for accelerated inference of large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 13358‚Äì13376, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et¬†al. (2023b)</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023b.

</span>
<span class="ltx_bibblock">Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2310.06839</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et¬†al. (2023)</span>
<span class="ltx_bibblock">
Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan Zhang. 2023.

</span>
<span class="ltx_bibblock">Towards general text embeddings with multi-stage contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2308.03281</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et¬†al. (2020)</span>
<span class="ltx_bibblock">
Weijie Liu, Peng Zhou, Zhiruo Wang, Zhe Zhao, Haotang Deng, and Qi¬†Ju. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.537" title="">FastBERT: a self-distilling BERT with adaptive inference time</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 6035‚Äì6044, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">L√π (2024)</span>
<span class="ltx_bibblock">
Xing¬†Han L√π. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2407.03618" title="">Bm25s: Orders of magnitude faster lexical search via eager sparse scoring</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Preprint</em>, arXiv:2407.03618.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Teo (2023)</span>
<span class="ltx_bibblock">
Sheila Teo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://medium.com/towards-data-science/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41" title="">How i won singapore‚Äôs gpt-4 prompt engineering competition</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et¬†al. (2023)</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock">Query2doc: Query expansion with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2303.07678</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et¬†al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed¬†Chi, Quoc¬†V Le, Denny Zhou, et¬†al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in neural information processing systems</em>, 35:24824‚Äì24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xin et¬†al. (2020)</span>
<span class="ltx_bibblock">
Ji¬†Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy Lin. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.204" title="">DeeBERT: Dynamic early exiting for accelerating BERT inference</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 2246‚Äì2251, Online. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Question-and-Answer Prompt Templates</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Markdown Format Question-and-Answer Template</h3>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<svg class="ltx_picture" height="222.51" id="A1.SS1.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,222.51) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 216.6 C 0 219.86 2.64 222.51 5.91 222.51 L 594.09 222.51 C 597.36 222.51 600 219.86 600 216.6 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 216.6 C 1.97 218.78 3.73 220.54 5.91 220.54 L 594.09 220.54 C 596.27 220.54 598.03 218.78 598.03 216.6 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="194.95" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS1.p1.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.1">## Objective</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.2">Please, based on the information from k private domain documents about 5G operational maintenance, answer the given question.</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.3">## Requirements</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.4">1. You may itemize your answer; be as detailed and specific as possible.</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.5">2. Do not merely repeat information from the context.</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.6">3. Do not use your own knowledge; rely solely on the content from the context documents.</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.7">## Context</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.8">{context_str}</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.9">## Question</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.10">{query_str}</span>
<span class="ltx_p" id="A1.SS1.p1.pic1.1.1.1.1.1.11">## Answer</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Chain of Thought Question-and-Answer Template</h3>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<svg class="ltx_picture" height="103.43" id="A1.SS2.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,103.43) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 97.53 C 0 100.79 2.64 103.43 5.91 103.43 L 594.09 103.43 C 597.36 103.43 600 100.79 600 97.53 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 97.53 C 1.97 99.7 3.73 101.46 5.91 101.46 L 594.09 101.46 C 596.27 101.46 598.03 99.7 598.03 97.53 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="75.87" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS2.p1.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.1">Context information as follows:</span>
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.2">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.3">{context_str}</span>
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.4">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.5">Please answer the following question based on the context information rather than your own knowledge. Think step by step, first provide an analysis process, then generate an answer:</span>
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.6">{query_str}</span>
<span class="ltx_p" id="A1.SS2.p1.pic1.1.1.1.1.1.7">Answer:</span>
</span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Focused Question-and-Answer Template</h3>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<svg class="ltx_picture" height="136.64" id="A1.SS3.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,136.64) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 130.74 C 0 134 2.64 136.64 5.91 136.64 L 594.09 136.64 C 597.36 136.64 600 134 600 130.74 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 130.74 C 1.97 132.91 3.73 134.67 5.91 134.67 L 594.09 134.67 C 596.27 134.67 598.03 132.91 598.03 130.74 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="109.08" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.p1.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.1">Context information as follows:</span>
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.2">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.3">{context_str}</span>
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.4">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.5">Please answer the following question based on the context information rather than your own knowledge. You may itemize your answer. Document 0‚Äôs content is particularly important, consider it carefully. If the context does not contain relevant knowledge, you may respond with ‚Äôuncertain‚Äô. Do not simply restate the context information:</span>
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.6">{query_str}</span>
<span class="ltx_p" id="A1.SS3.p1.pic1.1.1.1.1.1.7">Answer:</span>
</span></foreignobject></g></g></svg>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Answer Integration Template</h2>
<div class="ltx_para ltx_noindent" id="A2.p1">
<svg class="ltx_picture" height="186.45" id="A2.p1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,186.45) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 180.55 C 0 183.81 2.64 186.45 5.91 186.45 L 594.09 186.45 C 597.36 186.45 600 183.81 600 180.55 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 180.55 C 1.97 182.72 3.73 184.49 5.91 184.49 L 594.09 184.49 C 596.27 184.49 598.03 182.72 598.03 180.55 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="158.89" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.p1.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.1">Context:</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.2">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.3">{top1_content_str}</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.4">‚Äî‚Äî‚Äî-</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.5">You will see a question and a corresponding reference answer</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.6">Please, based on the context knowledge and not your own knowledge, supplement the reference answer to make it more complete in addressing the question</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.7">Please note, strictly retain every character of the reference answer and reasonably integrate your supplement with the reference answer to produce a longer, more complete answer containing more terms and itemization</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.8">Question:</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.9">{query_str}</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.10">Reference answer:</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.11">{answer_str}</span>
<span class="ltx_p" id="A2.p1.pic1.1.1.1.1.1.12">New answer:</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct 15 02:21:40 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
