<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation</title>
<!--Generated on Sun Jul 21 20:57:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.15268v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S1" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S2" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3.SS1" title="In 3 Methodology ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Fact-aware Multimodal Retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3.SS2" title="In 3 Methodology ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Retrieval Augmentation for Accurate Radiology Report Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S4" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Evaluation Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS1" title="In 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Overall Performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS2" title="In 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS3" title="In 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Fact-aware Capability Control</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS4" title="In 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Fact-aware Capability Propagation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS5" title="In 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Case Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S6" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S7" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#A1" title="In Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#A1.SS1" title="In Appendix A Appendix ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Retriever Training Procedure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#A1.SS2" title="In Appendix A Appendix ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>RAG Finetuning Procedure</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical
Radiology Report Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Liwen Sun<sup class="ltx_sup" id="3.3.1">∗</sup>, James Zhao<sup class="ltx_sup" id="4.4.2">∗</sup>, Megan Han, Chenyan Xiong 
<br class="ltx_break"/>School of Computer Science, Carnegie Mellon University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="5.5.3">{liwens,jjzhao2,wenjingh,cx}@andrew.cmu.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="6.1">Multimodal foundation models hold significant potential for automating radiology report generation, thereby assisting clinicians in diagnosing cardiac diseases.
However, generated reports often suffer from serious factual inaccuracy.
In this paper, we introduce a fact-aware multimodal retrieval-augmented pipeline in generating accurate radiology reports (FactMM-RAG).
We first leverage RadGraph to mine factual report pairs, then integrate factual knowledge to train a universal multimodal retriever.
Given a radiology image, our retriever can identify high-quality reference reports to augment multimodal foundation models, thus enhancing the factual completeness and correctness of report generation.
Experiments on two benchmark datasets show that our multimodal retriever outperforms state-of-the-art retrievers on both language generation and radiology-specific metrics, up to 6.5% and 2% score in F1CheXbert and F1RadGraph.
Further analysis indicates that employing our factually-informed training strategy imposes an effective supervision signal, without relying on explicit diagnostic label guidance, and successfully propagates fact-aware capabilities from the multimodal retriever to the multimodal foundation model in radiology report generation.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code will be public upon acceptance.</span></span></span><span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>These authors contributed equally to this work.</span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.2">
<p class="ltx_p" id="p1.2.3"><span class="ltx_text ltx_font_bold" id="p1.2.3.1">Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical
Radiology Report Generation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.2.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.2.2.2" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.2.2.2.2">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.2.2.2.2.2">
<span class="ltx_td ltx_align_center" id="p1.2.2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="p1.2.2.2.2.2.2.2">Liwen Sun<sup class="ltx_sup" id="p1.2.2.2.2.2.2.2.1"><span class="ltx_text ltx_font_medium" id="p1.2.2.2.2.2.2.2.1.1">∗</span></sup>, James Zhao<sup class="ltx_sup" id="p1.2.2.2.2.2.2.2.2"><span class="ltx_text ltx_font_medium" id="p1.2.2.2.2.2.2.2.2.1">∗</span></sup>, Megan Han, Chenyan Xiong</span></span></span>
<span class="ltx_tr" id="p1.2.2.2.2.3.1">
<span class="ltx_td ltx_align_center" id="p1.2.2.2.2.3.1.1">School of Computer Science, Carnegie Mellon University</span></span>
<span class="ltx_tr" id="p1.2.2.2.2.4.2">
<span class="ltx_td ltx_align_center" id="p1.2.2.2.2.4.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.2.2.2.2.4.2.1.1">{liwens,jjzhao2,wenjingh,cx}@andrew.cmu.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction </h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Within hospitals worldwide, chest radiology serves as a critical technique in identifying cardiac diseases and abnormalities.
Results of a chest radiograph are typically consolidated in a radiology report, including the source X-ray and a radiologist-produced findings section detailing clinical observations.
Manually generating these reports, however, can be both time-consuming and potentially inaccessible in under-resourced hospitals <cite class="ltx_cite ltx_citemacro_citep">(Speets et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib37" title="">2006</a>; Iyeke et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib16" title="">2022</a>)</cite>.
Recent multimodal foundation models have exhibited remarkable capabilities in challenging healthcare tasks, motivating an automation of this process to enhance physicians’ efficiency on clinical decision-making and improve patient health outcomes <cite class="ltx_cite ltx_citemacro_citep">(Çallı et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib54" title="">2021</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib23" title="">2023</a>; Moor et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib29" title="">2023</a>; Tu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib41" title="">2023</a>; Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib38" title="">2024</a>)</cite>.
<br class="ltx_break"/>
<br class="ltx_break"/>Although prior medical multimodal foundation models have demonstrated promising capabilities on report generation given the radiology image, they still suffer from serious hallucinations by generating factually inaccurate reports <cite class="ltx_cite ltx_citemacro_citep">(Pal et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib31" title="">2023</a>; Ahmad et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib1" title="">2023</a>; Pal and Sankarasubbu, <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib30" title="">2024</a>)</cite>.
Factual correctness is especially critical in chest radiology domains, as minute textual differences can drastically invert radiology report meaning and downstream prescribed treatments <cite class="ltx_cite ltx_citemacro_citep">(Delbrouck et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib7" title="">2022</a>; Xie et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib44" title="">2023</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib26" title="">2024</a>)</cite>.
Retrieval-Augmented Generation (RAG) has emerged as a popular paradigm to address this issue by grounding text generation with retrieved relevant knowledge given a query <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib21" title="">2021</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib4" title="">2022</a>; Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib11" title="">2024</a>)</cite>.
However, developing medical multimodal retrievers remains challenging, requiring retrievers to bridge the gap between symptomatic image semantics and factually-equivalent report text.
<br class="ltx_break"/>
<br class="ltx_break"/>To capture fine-grained details in chest radiographs and improve the factual completeness of generated reports, we introduce FactMM-RAG, a fact-aware multimodal retrieval-augmented pipeline for generating accurate radiology reports given a radiology image.
By designing a novel report pair-mining procedure incorporating factual knowledge, we develop a fact-aware retriever to augment multimodal foundation models in generating accurate chest X-ray radiology reports.
Specifically, we first leverage RadGraph <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib18" title="">2021</a>)</cite> to mine factually-oriented report pairs by annotating consistent radiology entities and relations between query and reference reports with certain abnormalities.
Next, we train a universal multimodal encoding architecture through mined report pairs to conduct multimodal dense retrieval.
Given an unseen patient’s radiology image, our retriever encodes it and searches for the most similar factually-informed reference report from an available report corpus.
Passing them together into a multimodal foundation model unlocks its fact-aware potential to generate more accurate radiology reports.
<br class="ltx_break"/>
<br class="ltx_break"/>Our experiments reveal that our retriever outperforms all state-of-the-art retrievers in both language generation and clinically relevant metrics on the MIMIC-CXR and CheXpert datasets, achieving up to 6.5% and 2% score in F1CheXbert and F1RadGraph for final RAG evaluation.
We also investigate our retriever’s fact-aware capability controlled by factual similarity thresholds and confirm that our factually-informed training strategy can impose a useful supervision signal without relying on explicit diagnostic label guidance.
Further analysis through retrieval evaluation metrics shows that the fact-aware capability of our retriever can be effectively propagated to the multimodal foundation models.
Lastly, our case study highlights that among reports describing the same symptom from different retrievers, those generated by our model are more accurate and achieve greater factual correctness.
<br class="ltx_break"/>
<br class="ltx_break"/>Our main contributions can be summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a fact-aware medical multimodal retriever to augment multimodal foundation models in generating accurate chest X-ray radiology reports.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We design a method for mining factually-informed radiology report pairs that trains multimodal encoders to retrieve high-quality reference reports.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrate that on two benchmark datasets, our medical multimodal retriever outperforms state-of-the-art medical multimodal retrievers on both language generation and clinically relevant metrics.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p1.2">The rest of this paper is organized as follows.
We review related work in in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S2" title="2 Related Work ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">2</span></a>. We discuss the pipeline of FactMM-RAG in Sections <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3" title="3 Methodology ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">3</span></a>. Section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S4" title="4 Experimental Setup ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5" title="5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">5</span></a> discuss our experimental setup and results.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="244" id="S2.F1.g1" src="extracted/5746006/Figures/overview.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of the FactMM-RAG system. It mainly contains three stages: (1) Leveraging RadGraph to characterize each radiology report and mine factually-informed report pairs; (2) Integrating factual knowledge into the training of the universal multimodal retriever; (3) Given the radiology image, employing the fact-aware multimodal retriever to search for factually-informed reference reports and augmenting the multimodal foundation model in generating accurate radiology reports.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Retrieval Augmented Generation.</span> Retrieval Augmented Generation, utilizing external knowledge to enhance language models, has shown great promise in text-generation performance on factual accuracy especially for Open-Domain QA. <cite class="ltx_cite ltx_citemacro_citep">(Borgeaud et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib2" title="">2022</a>; Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib17" title="">2022</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Guu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib12" title="">2020</a>); Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib21" title="">2021</a>)</cite> involve end-to-end training through both generators and retrievers;
<cite class="ltx_cite ltx_citemacro_citet">Shi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib35" title="">2023</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib48" title="">2023b</a>)</cite> adapt the end-to-end pattern by employing black-box LLM training signal propagation for retriever tuning.
Further works have expanded RAG to multiple modalities, employing unified image-text encoders <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib32" title="">2021</a>)</cite> or separate pretrained encoders <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib9" title="">2021</a>; Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib33" title="">2023</a>)</cite> and plugging retrieved documents into multimodal foundation models <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib4" title="">2022</a>; Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib13" title="">2023</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Yasunaga et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib45" title="">2023</a>)</cite> similarly integrates multimodal retrieval with both text and image generation capabilities.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p1.1.2">Medical Multimodal Retriever.</span>
Joint training of image-text pairs in a shared embedding space, as exemplified by CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib32" title="">2021</a>)</cite>, facilitates visual and textual modality interactions, providing flexible representations for general-domain downstream tasks.
Adapting general-domain multimodal retrievers to medical domains, however, is non-trivial due to the necessity of specialized knowledge.
<cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib51" title="">2022</a>)</cite> introduces an unsupervised approach for radiology image representation learning from paired text descriptions.
<cite class="ltx_cite ltx_citemacro_citet">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib14" title="">2021</a>)</cite> leverages global image-report and local sub-region features for multimodal retrieval and classification.
<cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib42" title="">2022</a>); You et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib46" title="">2023</a>)</cite> propose medical knowledge extraction for constructing contrastive learning image-text pairs.
<cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib49" title="">2024</a>)</cite> addresses the limited diversity within medical datasets, curating a large biomedical image-text collection towards a biomedical multimodal foundation model.
Nevertheless, these existing medical multimodal retrievers neglect specific image information and do not adequately emphasize factual accuracy, resulting in imprecision when retrieving radiology reports.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S2.p1.1.3">Medical Multimodal Foundation Model.</span>
Significant efforts have been made in applying multimodal foundation models to the medical imaging domain <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib23" title="">2023</a>; Moor et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib29" title="">2023</a>; Tu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib41" title="">2023</a>; Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib38" title="">2024</a>)</cite>.
As chest X-ray radiology is the most commonly performed imaging examination, tailored medical multimodal foundation models for this critical area has gathered much attention <cite class="ltx_cite ltx_citemacro_citep">(Chambon et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib3" title="">2022</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib5" title="">2021</a>; Thawkar et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib40" title="">2023</a>; Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib43" title="">2023</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib6" title="">2024</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Jain et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib18" title="">2021</a>)</cite> advances this area by designing a novel information extraction schema to structure radiology reports from chest radiographs;
<cite class="ltx_cite ltx_citemacro_citet">Miura et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib28" title="">2021</a>); Delbrouck et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib7" title="">2022</a>)</cite> take a step forward, using reinforcement learning from semantic rewards to improve the factual quality of generated radiology reports;
<cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib6" title="">2024</a>)</cite> recently has also developed an instruction-tuned multimodal foundation model capable of sophisticated interpretation and analysis of chest X-rays.
<br class="ltx_break"/>
<br class="ltx_break"/>One closely related line of work to ours is retrieval-based radiology report generation given only radiology images.
For instance, <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib22" title="">2018</a>)</cite> proposes a retrieval policy module to update radiology reports via hierarchical reinforcement learning;
<cite class="ltx_cite ltx_citemacro_citet">Endo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib10" title="">2021</a>)</cite> employs image-text embeddings from contrastive learning for retrieval-augmented radiology report generation;
<cite class="ltx_cite ltx_citemacro_citet">Ramesh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib34" title="">2022</a>)</cite> proposes synthesizing additional reports and reducing hallucinations from reference report priors to improve report generation.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology </h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we present the overall methodology of FactMM-RAG.
We first detail the training procedure of our fact-aware medical multimodal retriever in Section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3.SS1" title="3.1 Fact-aware Multimodal Retrieval ‣ 3 Methodology ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
We then provide the pipeline for retrieval-augmented radiology report generation with our multimodal retriever in section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3.SS2" title="3.2 Retrieval Augmentation for Accurate Radiology Report Generation ‣ 3 Methodology ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">3.2</span></a>. The overview is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S2.F1" title="Figure 1 ‣ 2 Related Work ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Fact-aware Multimodal Retrieval</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">This section discusses the training process of the multimodal retriever with factual knowledge. Each patient in the corpus has a chest X-ray radiology image along with its corresponding report.
We begin by annotating each report using RadGraph <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib18" title="">2021</a>)</cite>, then constructing factual report pairs to train our multimodal retriever.
We describe these steps as follows.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.4.1">Chest Radiograph Annotation.</span>
Since radiology reports are free-text, we utilize the RadGraph information extraction tool to extract structured knowledge graphs from them.
Specifically, RadGraph employs named entity recognition and relation extraction models to identify radiological entities (e.g. carina, lungs, abnormalities) and the clinical relations between them (e.g. modify, located at, suggestive of).
Each radiology report is then segmented into distinct regions and stored as <math alttext="[(\texttt{entity}_{1},\texttt{entity label}_{1},\texttt{relation}_{1}),(%
\texttt{entity}_{2},\\
\texttt{entity label}_{2},\texttt{relation}_{2}),\ldots]" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.3"><semantics id="S3.SS1.p1.1.m1.3a"><mrow id="S3.SS1.p1.1.m1.3.3.2" xref="S3.SS1.p1.1.m1.3.3.3.cmml"><mo id="S3.SS1.p1.1.m1.3.3.2.3" stretchy="false" xref="S3.SS1.p1.1.m1.3.3.3.cmml">[</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.4.cmml"><mo id="S3.SS1.p1.1.m1.2.2.1.1.3.4" stretchy="false" xref="S3.SS1.p1.1.m1.2.2.1.1.4.cmml">(</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2a.cmml">entity</mtext><mn id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.1.m1.2.2.1.1.3.5" xref="S3.SS1.p1.1.m1.2.2.1.1.4.cmml">,</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.2.2.1.1.2.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.2a.cmml">entity label</mtext><mn id="S3.SS1.p1.1.m1.2.2.1.1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.3.cmml">1</mn></msub><mo id="S3.SS1.p1.1.m1.2.2.1.1.3.6" xref="S3.SS1.p1.1.m1.2.2.1.1.4.cmml">,</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.2.2.1.1.3.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3.2a.cmml">relation</mtext><mn id="S3.SS1.p1.1.m1.2.2.1.1.3.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3.3.cmml">1</mn></msub><mo id="S3.SS1.p1.1.m1.2.2.1.1.3.7" stretchy="false" xref="S3.SS1.p1.1.m1.2.2.1.1.4.cmml">)</mo></mrow><mo id="S3.SS1.p1.1.m1.3.3.2.4" xref="S3.SS1.p1.1.m1.3.3.3.cmml">,</mo><mrow id="S3.SS1.p1.1.m1.3.3.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.4.cmml"><mo id="S3.SS1.p1.1.m1.3.3.2.2.3.4" stretchy="false" xref="S3.SS1.p1.1.m1.3.3.2.2.4.cmml">(</mo><msub id="S3.SS1.p1.1.m1.3.3.2.2.1.1" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.3.3.2.2.1.1.2" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1.2a.cmml">entity</mtext><mn id="S3.SS1.p1.1.m1.3.3.2.2.1.1.3" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1.3.cmml">2</mn></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.3.5" xref="S3.SS1.p1.1.m1.3.3.2.2.4.cmml">,</mo><msub id="S3.SS1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.3.3.2.2.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.2a.cmml">entity label</mtext><mn id="S3.SS1.p1.1.m1.3.3.2.2.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.3.6" xref="S3.SS1.p1.1.m1.3.3.2.2.4.cmml">,</mo><msub id="S3.SS1.p1.1.m1.3.3.2.2.3.3" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.3.3.2.2.3.3.2" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3.2a.cmml">relation</mtext><mn id="S3.SS1.p1.1.m1.3.3.2.2.3.3.3" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3.3.cmml">2</mn></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.3.7" stretchy="false" xref="S3.SS1.p1.1.m1.3.3.2.2.4.cmml">)</mo></mrow><mo id="S3.SS1.p1.1.m1.3.3.2.5" xref="S3.SS1.p1.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p1.1.m1.3.3.2.6" stretchy="false" xref="S3.SS1.p1.1.m1.3.3.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.3b"><list id="S3.SS1.p1.1.m1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2"><vector id="S3.SS1.p1.1.m1.2.2.1.1.4.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.3"><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2a.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2">entity</mtext></ci><cn id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.2.2.2a.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.2.2.1.1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.2">entity label</mtext></ci><cn id="S3.SS1.p1.1.m1.2.2.1.1.2.2.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.3">1</cn></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.3.3.2a.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.2.2.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3.2">relation</mtext></ci><cn id="S3.SS1.p1.1.m1.2.2.1.1.3.3.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2.1.1.3.3.3">1</cn></apply></vector><vector id="S3.SS1.p1.1.m1.3.3.2.2.4.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.3"><apply id="S3.SS1.p1.1.m1.3.3.2.2.1.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.1.1.2a.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.3.3.2.2.1.1.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1.2">entity</mtext></ci><cn id="S3.SS1.p1.1.m1.3.3.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.3.3.2.2.1.1.3">2</cn></apply><apply id="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.2.2a.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.2">entity label</mtext></ci><cn id="S3.SS1.p1.1.m1.3.3.2.2.2.2.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.3">2</cn></apply><apply id="S3.SS1.p1.1.m1.3.3.2.2.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.3.3.2a.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S3.SS1.p1.1.m1.3.3.2.2.3.3.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3.2">relation</mtext></ci><cn id="S3.SS1.p1.1.m1.3.3.2.2.3.3.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.3.3.2.2.3.3.3">2</cn></apply></vector><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">…</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.3c">[(\texttt{entity}_{1},\texttt{entity label}_{1},\texttt{relation}_{1}),(%
\texttt{entity}_{2},\\
\texttt{entity label}_{2},\texttt{relation}_{2}),\ldots]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.3d">[ ( entity start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , entity label start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , relation start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ( entity start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , entity label start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , relation start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , … ]</annotation></semantics></math>.
After characterizing the chest radiograph for each report in the training corpus, we construct factual report pairs.

<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.4.2">Factual Report Pairs Mining.</span>
Each report has an associated medical label describing the symptom.
We first utilize the query report to search for other reports with the same symptom, aiming to eliminate false negatives when constructing report pairs.
Rather than solely relying on the diagnostic labels, we further capture the factually-oriented pathology semantics between different reports. Following F1RadGraph <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib18" title="">2021</a>)</cite>,
we calculate the factual similarity <math alttext="s(q_{txt},d_{txt})" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.2"><semantics id="S3.SS1.p1.2.m2.2a"><mrow id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.2.2.4" xref="S3.SS1.p1.2.m2.2.2.4.cmml">s</mi><mo id="S3.SS1.p1.2.m2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.3.cmml">⁢</mo><mrow id="S3.SS1.p1.2.m2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.3.cmml"><mo id="S3.SS1.p1.2.m2.2.2.2.2.3" stretchy="false" xref="S3.SS1.p1.2.m2.2.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.2.m2.1.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.1.1.1.1.1.2.cmml">q</mi><mrow id="S3.SS1.p1.2.m2.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.2.m2.1.1.1.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.3.cmml">x</mi><mo id="S3.SS1.p1.2.m2.1.1.1.1.1.3.1a" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.3.4" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS1.p1.2.m2.2.2.2.2.4" xref="S3.SS1.p1.2.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.cmml">d</mi><mrow id="S3.SS1.p1.2.m2.2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.3.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.2.cmml">t</mi><mo id="S3.SS1.p1.2.m2.2.2.2.2.2.3.1" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.3.3" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.3.cmml">x</mi><mo id="S3.SS1.p1.2.m2.2.2.2.2.2.3.1a" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.3.4" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS1.p1.2.m2.2.2.2.2.5" stretchy="false" xref="S3.SS1.p1.2.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.2b"><apply id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2"><times id="S3.SS1.p1.2.m2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.3"></times><ci id="S3.SS1.p1.2.m2.2.2.4.cmml" xref="S3.SS1.p1.2.m2.2.2.4">𝑠</ci><interval closure="open" id="S3.SS1.p1.2.m2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2"><apply id="S3.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.2">𝑞</ci><apply id="S3.SS1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3"><times id="S3.SS1.p1.2.m2.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.3">𝑥</ci><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.3.4.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2">𝑑</ci><apply id="S3.SS1.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3"><times id="S3.SS1.p1.2.m2.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.1"></times><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.2">𝑡</ci><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.3">𝑥</ci><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.3.4.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.4">𝑡</ci></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.2c">s(q_{txt},d_{txt})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.2d">italic_s ( italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> between query report <math alttext="q_{txt}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">q</mi><mrow id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.3.m3.1.1.3.1" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">x</mi><mo id="S3.SS1.p1.3.m3.1.1.3.1a" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.3.m3.1.1.3.4" xref="S3.SS1.p1.3.m3.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑞</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><times id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.1"></times><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">𝑥</ci><ci id="S3.SS1.p1.3.m3.1.1.3.4.cmml" xref="S3.SS1.p1.3.m3.1.1.3.4">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">q_{txt}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and other reports <math alttext="d_{txt}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">d</mi><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">x</mi><mo id="S3.SS1.p1.4.m4.1.1.3.1a" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.1.1.3.4" xref="S3.SS1.p1.4.m4.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝑑</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><times id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1"></times><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">𝑥</ci><ci id="S3.SS1.p1.4.m4.1.1.3.4.cmml" xref="S3.SS1.p1.4.m4.1.1.3.4">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">d_{txt}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT</annotation></semantics></math> in the annotated format as follows,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle s(q_{txt},d_{txt})=\frac{2\cdot(\hat{q}_{txt}\cap\hat{d}_{txt})}%
{\text{length}(\hat{q}_{txt})\cdot\text{length}(\hat{d}_{txt})}," class="ltx_Math" display="inline" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml"><mi id="S3.E1.m1.4.4.1.1.2.4" xref="S3.E1.m1.4.4.1.1.2.4.cmml">s</mi><mo id="S3.E1.m1.4.4.1.1.2.3" xref="S3.E1.m1.4.4.1.1.2.3.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.1.1.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml"><mo id="S3.E1.m1.4.4.1.1.2.2.2.3" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">(</mo><msub id="S3.E1.m1.4.4.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml">q</mi><mrow id="S3.E1.m1.4.4.1.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.3.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.1.3.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.3.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.3.cmml">x</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.1.3.1a" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.3.4" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.4.4.1.1.2.2.2.4" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">,</mo><msub id="S3.E1.m1.4.4.1.1.2.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.2.cmml">d</mi><mrow id="S3.E1.m1.4.4.1.1.2.2.2.2.3" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.cmml"><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.3.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.2.cmml">t</mi><mo id="S3.E1.m1.4.4.1.1.2.2.2.2.3.1" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.3.3" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.3.cmml">x</mi><mo id="S3.E1.m1.4.4.1.1.2.2.2.2.3.1a" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.3.4" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.4.4.1.1.2.2.2.5" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml">=</mo><mstyle displaystyle="true" id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mfrac id="S3.E1.m1.3.3a" xref="S3.E1.m1.3.3.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">2</mn><mo id="S3.E1.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.1.2.cmml">⋅</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml">q</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.2.1" xref="S3.E1.m1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.3.1" xref="S3.E1.m1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.cmml">x</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.4" xref="S3.E1.m1.1.1.1.1.1.1.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">∩</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml">d</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml">x</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.4" xref="S3.E1.m1.1.1.1.1.1.1.3.3.4.cmml">t</mi></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mrow id="S3.E1.m1.2.2.2.1" xref="S3.E1.m1.2.2.2.1.cmml"><mrow id="S3.E1.m1.2.2.2.1.1" xref="S3.E1.m1.2.2.2.1.1.cmml"><mtext id="S3.E1.m1.2.2.2.1.1.3" xref="S3.E1.m1.2.2.2.1.1.3a.cmml">length</mtext><mo id="S3.E1.m1.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.2.1.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.2.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.2.1.1.1.1.1.cmml"><mover accent="true" id="S3.E1.m1.2.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.2.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.2.1.1.1.1.1.2.2.cmml">q</mi><mo id="S3.E1.m1.2.2.2.1.1.1.1.1.2.1" xref="S3.E1.m1.2.2.2.1.1.1.1.1.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.2.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.2.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E1.m1.2.2.2.1.1.1.1.1.3.1" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.2.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.3.cmml">x</mi><mo id="S3.E1.m1.2.2.2.1.1.1.1.1.3.1a" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.2.1.1.1.1.1.3.4" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.2.2.2.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E1.m1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.2.1.2" rspace="0.222em" xref="S3.E1.m1.2.2.2.1.2.cmml">⋅</mo><mtext id="S3.E1.m1.2.2.2.1.3" xref="S3.E1.m1.2.2.2.1.3a.cmml">length</mtext></mrow><mo id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.3.2.1" xref="S3.E1.m1.3.3.3.2.1.1.cmml"><mo id="S3.E1.m1.3.3.3.2.1.2" stretchy="false" xref="S3.E1.m1.3.3.3.2.1.1.cmml">(</mo><msub id="S3.E1.m1.3.3.3.2.1.1" xref="S3.E1.m1.3.3.3.2.1.1.cmml"><mover accent="true" id="S3.E1.m1.3.3.3.2.1.1.2" xref="S3.E1.m1.3.3.3.2.1.1.2.cmml"><mi id="S3.E1.m1.3.3.3.2.1.1.2.2" xref="S3.E1.m1.3.3.3.2.1.1.2.2.cmml">d</mi><mo id="S3.E1.m1.3.3.3.2.1.1.2.1" xref="S3.E1.m1.3.3.3.2.1.1.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.3.3.3.2.1.1.3" xref="S3.E1.m1.3.3.3.2.1.1.3.cmml"><mi id="S3.E1.m1.3.3.3.2.1.1.3.2" xref="S3.E1.m1.3.3.3.2.1.1.3.2.cmml">t</mi><mo id="S3.E1.m1.3.3.3.2.1.1.3.1" xref="S3.E1.m1.3.3.3.2.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.3.2.1.1.3.3" xref="S3.E1.m1.3.3.3.2.1.1.3.3.cmml">x</mi><mo id="S3.E1.m1.3.3.3.2.1.1.3.1a" xref="S3.E1.m1.3.3.3.2.1.1.3.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.3.2.1.1.3.4" xref="S3.E1.m1.3.3.3.2.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.3.3.3.2.1.3" stretchy="false" xref="S3.E1.m1.3.3.3.2.1.1.cmml">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1"><eq id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3"></eq><apply id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"><times id="S3.E1.m1.4.4.1.1.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.3"></times><ci id="S3.E1.m1.4.4.1.1.2.4.cmml" xref="S3.E1.m1.4.4.1.1.2.4">𝑠</ci><interval closure="open" id="S3.E1.m1.4.4.1.1.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2"><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2">𝑞</ci><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3"><times id="S3.E1.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.3">𝑥</ci><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.E1.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.2">𝑑</ci><apply id="S3.E1.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3"><times id="S3.E1.m1.4.4.1.1.2.2.2.2.3.1.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.1"></times><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.3.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.2">𝑡</ci><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.3.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.3">𝑥</ci><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.3.4.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.4">𝑡</ci></apply></apply></interval></apply><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><divide id="S3.E1.m1.3.3.4.cmml" xref="S3.E1.m1.3.3"></divide><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><ci id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2">⋅</ci><cn id="S3.E1.m1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.3">2</cn><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><intersect id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></intersect><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2"><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2">𝑞</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3"><times id="S3.E1.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3">𝑥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.4">𝑡</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2">𝑑</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2">𝑡</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3">𝑥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.4">𝑡</ci></apply></apply></apply></apply><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><times id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3"></times><apply id="S3.E1.m1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.1"><ci id="S3.E1.m1.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.1.2">⋅</ci><apply id="S3.E1.m1.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1"><times id="S3.E1.m1.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.2"></times><ci id="S3.E1.m1.2.2.2.1.1.3a.cmml" xref="S3.E1.m1.2.2.2.1.1.3"><mtext id="S3.E1.m1.2.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.3">length</mtext></ci><apply id="S3.E1.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.2"><ci id="S3.E1.m1.2.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.2.1">^</ci><ci id="S3.E1.m1.2.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.2.2">𝑞</ci></apply><apply id="S3.E1.m1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3"><times id="S3.E1.m1.2.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.2.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.E1.m1.2.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.3">𝑥</ci><ci id="S3.E1.m1.2.2.2.1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.2.2.2.1.1.1.1.1.3.4">𝑡</ci></apply></apply></apply><ci id="S3.E1.m1.2.2.2.1.3a.cmml" xref="S3.E1.m1.2.2.2.1.3"><mtext id="S3.E1.m1.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.1.3">length</mtext></ci></apply><apply id="S3.E1.m1.3.3.3.2.1.1.cmml" xref="S3.E1.m1.3.3.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.1.1.1.cmml" xref="S3.E1.m1.3.3.3.2.1">subscript</csymbol><apply id="S3.E1.m1.3.3.3.2.1.1.2.cmml" xref="S3.E1.m1.3.3.3.2.1.1.2"><ci id="S3.E1.m1.3.3.3.2.1.1.2.1.cmml" xref="S3.E1.m1.3.3.3.2.1.1.2.1">^</ci><ci id="S3.E1.m1.3.3.3.2.1.1.2.2.cmml" xref="S3.E1.m1.3.3.3.2.1.1.2.2">𝑑</ci></apply><apply id="S3.E1.m1.3.3.3.2.1.1.3.cmml" xref="S3.E1.m1.3.3.3.2.1.1.3"><times id="S3.E1.m1.3.3.3.2.1.1.3.1.cmml" xref="S3.E1.m1.3.3.3.2.1.1.3.1"></times><ci id="S3.E1.m1.3.3.3.2.1.1.3.2.cmml" xref="S3.E1.m1.3.3.3.2.1.1.3.2">𝑡</ci><ci id="S3.E1.m1.3.3.3.2.1.1.3.3.cmml" xref="S3.E1.m1.3.3.3.2.1.1.3.3">𝑥</ci><ci id="S3.E1.m1.3.3.3.2.1.1.3.4.cmml" xref="S3.E1.m1.3.3.3.2.1.1.3.4">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\displaystyle s(q_{txt},d_{txt})=\frac{2\cdot(\hat{q}_{txt}\cap\hat{d}_{txt})}%
{\text{length}(\hat{q}_{txt})\cdot\text{length}(\hat{d}_{txt})},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">italic_s ( italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ) = divide start_ARG 2 ⋅ ( over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ∩ over^ start_ARG italic_d end_ARG start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG length ( over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ) ⋅ length ( over^ start_ARG italic_d end_ARG start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ) end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.6">where <math alttext="\hat{q}_{txt},\hat{h}_{txt}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m1.2"><semantics id="S3.SS1.p1.5.m1.2a"><mrow id="S3.SS1.p1.5.m1.2.2.2" xref="S3.SS1.p1.5.m1.2.2.3.cmml"><msub id="S3.SS1.p1.5.m1.1.1.1.1" xref="S3.SS1.p1.5.m1.1.1.1.1.cmml"><mover accent="true" id="S3.SS1.p1.5.m1.1.1.1.1.2" xref="S3.SS1.p1.5.m1.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.5.m1.1.1.1.1.2.2" xref="S3.SS1.p1.5.m1.1.1.1.1.2.2.cmml">q</mi><mo id="S3.SS1.p1.5.m1.1.1.1.1.2.1" xref="S3.SS1.p1.5.m1.1.1.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p1.5.m1.1.1.1.1.3" xref="S3.SS1.p1.5.m1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.5.m1.1.1.1.1.3.2" xref="S3.SS1.p1.5.m1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.5.m1.1.1.1.1.3.1" xref="S3.SS1.p1.5.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.5.m1.1.1.1.1.3.3" xref="S3.SS1.p1.5.m1.1.1.1.1.3.3.cmml">x</mi><mo id="S3.SS1.p1.5.m1.1.1.1.1.3.1a" xref="S3.SS1.p1.5.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.5.m1.1.1.1.1.3.4" xref="S3.SS1.p1.5.m1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS1.p1.5.m1.2.2.2.3" xref="S3.SS1.p1.5.m1.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.5.m1.2.2.2.2" xref="S3.SS1.p1.5.m1.2.2.2.2.cmml"><mover accent="true" id="S3.SS1.p1.5.m1.2.2.2.2.2" xref="S3.SS1.p1.5.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.5.m1.2.2.2.2.2.2" xref="S3.SS1.p1.5.m1.2.2.2.2.2.2.cmml">h</mi><mo id="S3.SS1.p1.5.m1.2.2.2.2.2.1" xref="S3.SS1.p1.5.m1.2.2.2.2.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p1.5.m1.2.2.2.2.3" xref="S3.SS1.p1.5.m1.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.5.m1.2.2.2.2.3.2" xref="S3.SS1.p1.5.m1.2.2.2.2.3.2.cmml">t</mi><mo id="S3.SS1.p1.5.m1.2.2.2.2.3.1" xref="S3.SS1.p1.5.m1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.5.m1.2.2.2.2.3.3" xref="S3.SS1.p1.5.m1.2.2.2.2.3.3.cmml">x</mi><mo id="S3.SS1.p1.5.m1.2.2.2.2.3.1a" xref="S3.SS1.p1.5.m1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.5.m1.2.2.2.2.3.4" xref="S3.SS1.p1.5.m1.2.2.2.2.3.4.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m1.2b"><list id="S3.SS1.p1.5.m1.2.2.3.cmml" xref="S3.SS1.p1.5.m1.2.2.2"><apply id="S3.SS1.p1.5.m1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p1.5.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.2"><ci id="S3.SS1.p1.5.m1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.2.1">^</ci><ci id="S3.SS1.p1.5.m1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.2.2">𝑞</ci></apply><apply id="S3.SS1.p1.5.m1.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.3"><times id="S3.SS1.p1.5.m1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.3.1"></times><ci id="S3.SS1.p1.5.m1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.5.m1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.3.3">𝑥</ci><ci id="S3.SS1.p1.5.m1.1.1.1.1.3.4.cmml" xref="S3.SS1.p1.5.m1.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.SS1.p1.5.m1.2.2.2.2.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m1.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p1.5.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.2"><ci id="S3.SS1.p1.5.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.2.1">^</ci><ci id="S3.SS1.p1.5.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.2.2">ℎ</ci></apply><apply id="S3.SS1.p1.5.m1.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.3"><times id="S3.SS1.p1.5.m1.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.3.1"></times><ci id="S3.SS1.p1.5.m1.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.3.2">𝑡</ci><ci id="S3.SS1.p1.5.m1.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.3.3">𝑥</ci><ci id="S3.SS1.p1.5.m1.2.2.2.2.3.4.cmml" xref="S3.SS1.p1.5.m1.2.2.2.2.3.4">𝑡</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m1.2c">\hat{q}_{txt},\hat{h}_{txt}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m1.2d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT</annotation></semantics></math> denotes reports with only annotated entities and relations in RadGraph structured form. We then set a strict threshold <math alttext="\delta" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m2.1"><semantics id="S3.SS1.p1.6.m2.1a"><mi id="S3.SS1.p1.6.m2.1.1" xref="S3.SS1.p1.6.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m2.1b"><ci id="S3.SS1.p1.6.m2.1.1.cmml" xref="S3.SS1.p1.6.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m2.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m2.1d">italic_δ</annotation></semantics></math> to filter out searched reports with low similarity score:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx2">
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle N_{q_{txt}}=\{d_{txt}\in D|s(q_{txt},d_{txt})&gt;\delta\}." class="ltx_Math" display="inline" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.4.cmml"><mi id="S3.E2.m1.1.1.1.1.4.2" xref="S3.E2.m1.1.1.1.1.4.2.cmml">N</mi><msub id="S3.E2.m1.1.1.1.1.4.3" xref="S3.E2.m1.1.1.1.1.4.3.cmml"><mi id="S3.E2.m1.1.1.1.1.4.3.2" xref="S3.E2.m1.1.1.1.1.4.3.2.cmml">q</mi><mrow id="S3.E2.m1.1.1.1.1.4.3.3" xref="S3.E2.m1.1.1.1.1.4.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.4.3.3.2" xref="S3.E2.m1.1.1.1.1.4.3.3.2.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.4.3.3.1" xref="S3.E2.m1.1.1.1.1.4.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.4.3.3.3" xref="S3.E2.m1.1.1.1.1.4.3.3.3.cmml">x</mi><mo id="S3.E2.m1.1.1.1.1.4.3.3.1a" xref="S3.E2.m1.1.1.1.1.4.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.4.3.3.4" xref="S3.E2.m1.1.1.1.1.4.3.3.4.cmml">t</mi></mrow></msub></msub><mo id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.3.cmml"><mo id="S3.E2.m1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.2.3.1.cmml">{</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2.cmml">d</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.2.3.1" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.3.cmml">x</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.2.3.1a" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.2.3.4" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">∈</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml">D</mi></mrow><mo id="S3.E2.m1.1.1.1.1.2.2.4" lspace="0em" rspace="0em" xref="S3.E2.m1.1.1.1.1.2.3.1.cmml">|</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.2.2.4.cmml">s</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml"><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.2.cmml">q</mi><mrow id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.3.cmml">x</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.1a" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.4" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.2.cmml">d</mi><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.2.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.3.cmml">x</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.1a" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.4" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.5" stretchy="false" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.3.cmml">&gt;</mo><mi id="S3.E2.m1.1.1.1.1.2.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.2.4.cmml">δ</mi></mrow><mo id="S3.E2.m1.1.1.1.1.2.2.5" stretchy="false" xref="S3.E2.m1.1.1.1.1.2.3.1.cmml">}</mo></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" lspace="0em" xref="S3.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"></eq><apply id="S3.E2.m1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.4.1.cmml" xref="S3.E2.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.4.2.cmml" xref="S3.E2.m1.1.1.1.1.4.2">𝑁</ci><apply id="S3.E2.m1.1.1.1.1.4.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.4.3.1.cmml" xref="S3.E2.m1.1.1.1.1.4.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.4.3.2.cmml" xref="S3.E2.m1.1.1.1.1.4.3.2">𝑞</ci><apply id="S3.E2.m1.1.1.1.1.4.3.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3.3"><times id="S3.E2.m1.1.1.1.1.4.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.4.3.3.1"></times><ci id="S3.E2.m1.1.1.1.1.4.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.4.3.3.2">𝑡</ci><ci id="S3.E2.m1.1.1.1.1.4.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3.3.3">𝑥</ci><ci id="S3.E2.m1.1.1.1.1.4.3.3.4.cmml" xref="S3.E2.m1.1.1.1.1.4.3.3.4">𝑡</ci></apply></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2"><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3">conditional-set</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"><in id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"></in><apply id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2">𝑑</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3"><times id="S3.E2.m1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.3">𝑥</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.4">𝑡</ci></apply></apply><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">𝐷</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><gt id="S3.E2.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.3"></gt><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><times id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3"></times><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.4.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.4">𝑠</ci><interval closure="open" id="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2"><apply id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.2">𝑞</ci><apply id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.1"></times><ci id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.2">𝑡</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.3">𝑥</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.4.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.2">𝑑</ci><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3"><times id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.1"></times><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.2">𝑡</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.3">𝑥</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.4.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.2.3.4">𝑡</ci></apply></apply></interval></apply><ci id="S3.E2.m1.1.1.1.1.2.2.2.4.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.4">𝛿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle N_{q_{txt}}=\{d_{txt}\in D|s(q_{txt},d_{txt})&gt;\delta\}.</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">italic_N start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT = { italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ∈ italic_D | italic_s ( italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT ) &gt; italic_δ } .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.11">where <math alttext="N_{q_{txt}}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m1.1"><semantics id="S3.SS1.p1.7.m1.1a"><msub id="S3.SS1.p1.7.m1.1.1" xref="S3.SS1.p1.7.m1.1.1.cmml"><mi id="S3.SS1.p1.7.m1.1.1.2" xref="S3.SS1.p1.7.m1.1.1.2.cmml">N</mi><msub id="S3.SS1.p1.7.m1.1.1.3" xref="S3.SS1.p1.7.m1.1.1.3.cmml"><mi id="S3.SS1.p1.7.m1.1.1.3.2" xref="S3.SS1.p1.7.m1.1.1.3.2.cmml">q</mi><mrow id="S3.SS1.p1.7.m1.1.1.3.3" xref="S3.SS1.p1.7.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.7.m1.1.1.3.3.2" xref="S3.SS1.p1.7.m1.1.1.3.3.2.cmml">t</mi><mo id="S3.SS1.p1.7.m1.1.1.3.3.1" xref="S3.SS1.p1.7.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.7.m1.1.1.3.3.3" xref="S3.SS1.p1.7.m1.1.1.3.3.3.cmml">x</mi><mo id="S3.SS1.p1.7.m1.1.1.3.3.1a" xref="S3.SS1.p1.7.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.7.m1.1.1.3.3.4" xref="S3.SS1.p1.7.m1.1.1.3.3.4.cmml">t</mi></mrow></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m1.1b"><apply id="S3.SS1.p1.7.m1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m1.1.1.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2">𝑁</ci><apply id="S3.SS1.p1.7.m1.1.1.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.3.1.cmml" xref="S3.SS1.p1.7.m1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.7.m1.1.1.3.2.cmml" xref="S3.SS1.p1.7.m1.1.1.3.2">𝑞</ci><apply id="S3.SS1.p1.7.m1.1.1.3.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3"><times id="S3.SS1.p1.7.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.7.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.2">𝑡</ci><ci id="S3.SS1.p1.7.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.3">𝑥</ci><ci id="S3.SS1.p1.7.m1.1.1.3.3.4.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.4">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m1.1c">N_{q_{txt}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m1.1d">italic_N start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> denotes factual positive report pairs for <math alttext="q_{txt}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m2.1"><semantics id="S3.SS1.p1.8.m2.1a"><msub id="S3.SS1.p1.8.m2.1.1" xref="S3.SS1.p1.8.m2.1.1.cmml"><mi id="S3.SS1.p1.8.m2.1.1.2" xref="S3.SS1.p1.8.m2.1.1.2.cmml">q</mi><mrow id="S3.SS1.p1.8.m2.1.1.3" xref="S3.SS1.p1.8.m2.1.1.3.cmml"><mi id="S3.SS1.p1.8.m2.1.1.3.2" xref="S3.SS1.p1.8.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.8.m2.1.1.3.1" xref="S3.SS1.p1.8.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.8.m2.1.1.3.3" xref="S3.SS1.p1.8.m2.1.1.3.3.cmml">x</mi><mo id="S3.SS1.p1.8.m2.1.1.3.1a" xref="S3.SS1.p1.8.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.8.m2.1.1.3.4" xref="S3.SS1.p1.8.m2.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m2.1b"><apply id="S3.SS1.p1.8.m2.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m2.1.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m2.1.1.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2">𝑞</ci><apply id="S3.SS1.p1.8.m2.1.1.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3"><times id="S3.SS1.p1.8.m2.1.1.3.1.cmml" xref="S3.SS1.p1.8.m2.1.1.3.1"></times><ci id="S3.SS1.p1.8.m2.1.1.3.2.cmml" xref="S3.SS1.p1.8.m2.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.8.m2.1.1.3.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3">𝑥</ci><ci id="S3.SS1.p1.8.m2.1.1.3.4.cmml" xref="S3.SS1.p1.8.m2.1.1.3.4">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m2.1c">q_{txt}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m2.1d">italic_q start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m3.1"><semantics id="S3.SS1.p1.9.m3.1a"><mi id="S3.SS1.p1.9.m3.1.1" xref="S3.SS1.p1.9.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m3.1b"><ci id="S3.SS1.p1.9.m3.1.1.cmml" xref="S3.SS1.p1.9.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m3.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m3.1d">italic_D</annotation></semantics></math> is the total training corpus.
Since each query report is associated with a corresponding radiology image, these factual report pairs can also be applied to the query report’s radiology image.
Next, we train our multimodal retriever with mined factual report pairs.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.11.1">Multimodal Dense Retrieval.</span> Following previous work <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite>, we universally encode each query image <math alttext="q_{img}" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m4.1"><semantics id="S3.SS1.p1.10.m4.1a"><msub id="S3.SS1.p1.10.m4.1.1" xref="S3.SS1.p1.10.m4.1.1.cmml"><mi id="S3.SS1.p1.10.m4.1.1.2" xref="S3.SS1.p1.10.m4.1.1.2.cmml">q</mi><mrow id="S3.SS1.p1.10.m4.1.1.3" xref="S3.SS1.p1.10.m4.1.1.3.cmml"><mi id="S3.SS1.p1.10.m4.1.1.3.2" xref="S3.SS1.p1.10.m4.1.1.3.2.cmml">i</mi><mo id="S3.SS1.p1.10.m4.1.1.3.1" xref="S3.SS1.p1.10.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.10.m4.1.1.3.3" xref="S3.SS1.p1.10.m4.1.1.3.3.cmml">m</mi><mo id="S3.SS1.p1.10.m4.1.1.3.1a" xref="S3.SS1.p1.10.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.10.m4.1.1.3.4" xref="S3.SS1.p1.10.m4.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m4.1b"><apply id="S3.SS1.p1.10.m4.1.1.cmml" xref="S3.SS1.p1.10.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m4.1.1.1.cmml" xref="S3.SS1.p1.10.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m4.1.1.2.cmml" xref="S3.SS1.p1.10.m4.1.1.2">𝑞</ci><apply id="S3.SS1.p1.10.m4.1.1.3.cmml" xref="S3.SS1.p1.10.m4.1.1.3"><times id="S3.SS1.p1.10.m4.1.1.3.1.cmml" xref="S3.SS1.p1.10.m4.1.1.3.1"></times><ci id="S3.SS1.p1.10.m4.1.1.3.2.cmml" xref="S3.SS1.p1.10.m4.1.1.3.2">𝑖</ci><ci id="S3.SS1.p1.10.m4.1.1.3.3.cmml" xref="S3.SS1.p1.10.m4.1.1.3.3">𝑚</ci><ci id="S3.SS1.p1.10.m4.1.1.3.4.cmml" xref="S3.SS1.p1.10.m4.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m4.1c">q_{img}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m4.1d">italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT</annotation></semantics></math> and other image-text pairs <math alttext="(d_{txt},d_{img})" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m5.2"><semantics id="S3.SS1.p1.11.m5.2a"><mrow id="S3.SS1.p1.11.m5.2.2.2" xref="S3.SS1.p1.11.m5.2.2.3.cmml"><mo id="S3.SS1.p1.11.m5.2.2.2.3" stretchy="false" xref="S3.SS1.p1.11.m5.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.11.m5.1.1.1.1" xref="S3.SS1.p1.11.m5.1.1.1.1.cmml"><mi id="S3.SS1.p1.11.m5.1.1.1.1.2" xref="S3.SS1.p1.11.m5.1.1.1.1.2.cmml">d</mi><mrow id="S3.SS1.p1.11.m5.1.1.1.1.3" xref="S3.SS1.p1.11.m5.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.11.m5.1.1.1.1.3.2" xref="S3.SS1.p1.11.m5.1.1.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p1.11.m5.1.1.1.1.3.1" xref="S3.SS1.p1.11.m5.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.11.m5.1.1.1.1.3.3" xref="S3.SS1.p1.11.m5.1.1.1.1.3.3.cmml">x</mi><mo id="S3.SS1.p1.11.m5.1.1.1.1.3.1a" xref="S3.SS1.p1.11.m5.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.11.m5.1.1.1.1.3.4" xref="S3.SS1.p1.11.m5.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS1.p1.11.m5.2.2.2.4" xref="S3.SS1.p1.11.m5.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.11.m5.2.2.2.2" xref="S3.SS1.p1.11.m5.2.2.2.2.cmml"><mi id="S3.SS1.p1.11.m5.2.2.2.2.2" xref="S3.SS1.p1.11.m5.2.2.2.2.2.cmml">d</mi><mrow id="S3.SS1.p1.11.m5.2.2.2.2.3" xref="S3.SS1.p1.11.m5.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.11.m5.2.2.2.2.3.2" xref="S3.SS1.p1.11.m5.2.2.2.2.3.2.cmml">i</mi><mo id="S3.SS1.p1.11.m5.2.2.2.2.3.1" xref="S3.SS1.p1.11.m5.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.11.m5.2.2.2.2.3.3" xref="S3.SS1.p1.11.m5.2.2.2.2.3.3.cmml">m</mi><mo id="S3.SS1.p1.11.m5.2.2.2.2.3.1a" xref="S3.SS1.p1.11.m5.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.11.m5.2.2.2.2.3.4" xref="S3.SS1.p1.11.m5.2.2.2.2.3.4.cmml">g</mi></mrow></msub><mo id="S3.SS1.p1.11.m5.2.2.2.5" stretchy="false" xref="S3.SS1.p1.11.m5.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m5.2b"><interval closure="open" id="S3.SS1.p1.11.m5.2.2.3.cmml" xref="S3.SS1.p1.11.m5.2.2.2"><apply id="S3.SS1.p1.11.m5.1.1.1.1.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m5.1.1.1.1.1.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m5.1.1.1.1.2.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1.2">𝑑</ci><apply id="S3.SS1.p1.11.m5.1.1.1.1.3.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1.3"><times id="S3.SS1.p1.11.m5.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1.3.1"></times><ci id="S3.SS1.p1.11.m5.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1.3.2">𝑡</ci><ci id="S3.SS1.p1.11.m5.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1.3.3">𝑥</ci><ci id="S3.SS1.p1.11.m5.1.1.1.1.3.4.cmml" xref="S3.SS1.p1.11.m5.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.SS1.p1.11.m5.2.2.2.2.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m5.2.2.2.2.1.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.11.m5.2.2.2.2.2.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2.2">𝑑</ci><apply id="S3.SS1.p1.11.m5.2.2.2.2.3.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2.3"><times id="S3.SS1.p1.11.m5.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2.3.1"></times><ci id="S3.SS1.p1.11.m5.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2.3.2">𝑖</ci><ci id="S3.SS1.p1.11.m5.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2.3.3">𝑚</ci><ci id="S3.SS1.p1.11.m5.2.2.2.2.3.4.cmml" xref="S3.SS1.p1.11.m5.2.2.2.2.3.4">𝑔</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m5.2c">(d_{txt},d_{img})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m5.2d">( italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT )</annotation></semantics></math> in the training corpus, using one encoder, MARVEL:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx3">
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{q}" class="ltx_Math" display="inline" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">𝐪</mi><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝐪</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle\mathbf{q}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">bold_q</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{MARVEL}(q_{img});" class="ltx_Math" display="inline" id="S3.E3.m2.1"><semantics id="S3.E3.m2.1a"><mrow id="S3.E3.m2.1.1.1" xref="S3.E3.m2.1.1.1.1.cmml"><mrow id="S3.E3.m2.1.1.1.1" xref="S3.E3.m2.1.1.1.1.cmml"><mi id="S3.E3.m2.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.3.cmml"></mi><mo id="S3.E3.m2.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m2.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.cmml"><mtext id="S3.E3.m2.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.3a.cmml">MARVEL</mtext><mo id="S3.E3.m2.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m2.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m2.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.2.cmml">q</mi><mrow id="S3.E3.m2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S3.E3.m2.1.1.1.1.1.1.1.1.3.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.3.cmml">m</mi><mo id="S3.E3.m2.1.1.1.1.1.1.1.1.3.1a" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.3.4" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.4.cmml">g</mi></mrow></msub><mo id="S3.E3.m2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m2.1.1.1.2" xref="S3.E3.m2.1.1.1.1.cmml">;</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m2.1b"><apply id="S3.E3.m2.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1"><eq id="S3.E3.m2.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.2"></eq><csymbol cd="latexml" id="S3.E3.m2.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.3">absent</csymbol><apply id="S3.E3.m2.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1"><times id="S3.E3.m2.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.2"></times><ci id="S3.E3.m2.1.1.1.1.1.3a.cmml" xref="S3.E3.m2.1.1.1.1.1.3"><mtext id="S3.E3.m2.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.3">MARVEL</mtext></ci><apply id="S3.E3.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.2">𝑞</ci><apply id="S3.E3.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3"><times id="S3.E3.m2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.2">𝑖</ci><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.3">𝑚</ci><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.3.4">𝑔</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m2.1c">\displaystyle=\text{MARVEL}(q_{img});</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m2.1d">= MARVEL ( italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT ) ;</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{d}" class="ltx_Math" display="inline" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">𝐝</mi><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝐝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\displaystyle\mathbf{d}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">bold_d</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{MARVEL}(d_{txt},d_{img})," class="ltx_Math" display="inline" id="S3.E4.m2.1"><semantics id="S3.E4.m2.1a"><mrow id="S3.E4.m2.1.1.1" xref="S3.E4.m2.1.1.1.1.cmml"><mrow id="S3.E4.m2.1.1.1.1" xref="S3.E4.m2.1.1.1.1.cmml"><mi id="S3.E4.m2.1.1.1.1.4" xref="S3.E4.m2.1.1.1.1.4.cmml"></mi><mo id="S3.E4.m2.1.1.1.1.3" xref="S3.E4.m2.1.1.1.1.3.cmml">=</mo><mrow id="S3.E4.m2.1.1.1.1.2" xref="S3.E4.m2.1.1.1.1.2.cmml"><mtext id="S3.E4.m2.1.1.1.1.2.4" xref="S3.E4.m2.1.1.1.1.2.4a.cmml">MARVEL</mtext><mo id="S3.E4.m2.1.1.1.1.2.3" xref="S3.E4.m2.1.1.1.1.2.3.cmml">⁢</mo><mrow id="S3.E4.m2.1.1.1.1.2.2.2" xref="S3.E4.m2.1.1.1.1.2.2.3.cmml"><mo id="S3.E4.m2.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E4.m2.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E4.m2.1.1.1.1.1.1.1.1" xref="S3.E4.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m2.1.1.1.1.1.1.1.1.2" xref="S3.E4.m2.1.1.1.1.1.1.1.1.2.cmml">d</mi><mrow id="S3.E4.m2.1.1.1.1.1.1.1.1.3" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m2.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E4.m2.1.1.1.1.1.1.1.1.3.1" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E4.m2.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.3.cmml">x</mi><mo id="S3.E4.m2.1.1.1.1.1.1.1.1.3.1a" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E4.m2.1.1.1.1.1.1.1.1.3.4" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.E4.m2.1.1.1.1.2.2.2.4" xref="S3.E4.m2.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E4.m2.1.1.1.1.2.2.2.2" xref="S3.E4.m2.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E4.m2.1.1.1.1.2.2.2.2.2" xref="S3.E4.m2.1.1.1.1.2.2.2.2.2.cmml">d</mi><mrow id="S3.E4.m2.1.1.1.1.2.2.2.2.3" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.E4.m2.1.1.1.1.2.2.2.2.3.2" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.2.cmml">i</mi><mo id="S3.E4.m2.1.1.1.1.2.2.2.2.3.1" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E4.m2.1.1.1.1.2.2.2.2.3.3" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.3.cmml">m</mi><mo id="S3.E4.m2.1.1.1.1.2.2.2.2.3.1a" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E4.m2.1.1.1.1.2.2.2.2.3.4" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.4.cmml">g</mi></mrow></msub><mo id="S3.E4.m2.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E4.m2.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m2.1.1.1.2" xref="S3.E4.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m2.1b"><apply id="S3.E4.m2.1.1.1.1.cmml" xref="S3.E4.m2.1.1.1"><eq id="S3.E4.m2.1.1.1.1.3.cmml" xref="S3.E4.m2.1.1.1.1.3"></eq><csymbol cd="latexml" id="S3.E4.m2.1.1.1.1.4.cmml" xref="S3.E4.m2.1.1.1.1.4">absent</csymbol><apply id="S3.E4.m2.1.1.1.1.2.cmml" xref="S3.E4.m2.1.1.1.1.2"><times id="S3.E4.m2.1.1.1.1.2.3.cmml" xref="S3.E4.m2.1.1.1.1.2.3"></times><ci id="S3.E4.m2.1.1.1.1.2.4a.cmml" xref="S3.E4.m2.1.1.1.1.2.4"><mtext id="S3.E4.m2.1.1.1.1.2.4.cmml" xref="S3.E4.m2.1.1.1.1.2.4">MARVEL</mtext></ci><interval closure="open" id="S3.E4.m2.1.1.1.1.2.2.3.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2"><apply id="S3.E4.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1.2">𝑑</ci><apply id="S3.E4.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3"><times id="S3.E4.m2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.E4.m2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.3">𝑥</ci><ci id="S3.E4.m2.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E4.m2.1.1.1.1.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.E4.m2.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m2.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E4.m2.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2.2">𝑑</ci><apply id="S3.E4.m2.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3"><times id="S3.E4.m2.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.1"></times><ci id="S3.E4.m2.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.2">𝑖</ci><ci id="S3.E4.m2.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.3">𝑚</ci><ci id="S3.E4.m2.1.1.1.1.2.2.2.2.3.4.cmml" xref="S3.E4.m2.1.1.1.1.2.2.2.2.3.4">𝑔</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m2.1c">\displaystyle=\text{MARVEL}(d_{txt},d_{img}),</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m2.1d">= MARVEL ( italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.12">where each image-text pair is represented as a single embedding.
We then model the relevance score <math alttext="f(q,d)" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m1.2"><semantics id="S3.SS1.p1.12.m1.2a"><mrow id="S3.SS1.p1.12.m1.2.3" xref="S3.SS1.p1.12.m1.2.3.cmml"><mi id="S3.SS1.p1.12.m1.2.3.2" xref="S3.SS1.p1.12.m1.2.3.2.cmml">f</mi><mo id="S3.SS1.p1.12.m1.2.3.1" xref="S3.SS1.p1.12.m1.2.3.1.cmml">⁢</mo><mrow id="S3.SS1.p1.12.m1.2.3.3.2" xref="S3.SS1.p1.12.m1.2.3.3.1.cmml"><mo id="S3.SS1.p1.12.m1.2.3.3.2.1" stretchy="false" xref="S3.SS1.p1.12.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p1.12.m1.1.1" xref="S3.SS1.p1.12.m1.1.1.cmml">q</mi><mo id="S3.SS1.p1.12.m1.2.3.3.2.2" xref="S3.SS1.p1.12.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.12.m1.2.2" xref="S3.SS1.p1.12.m1.2.2.cmml">d</mi><mo id="S3.SS1.p1.12.m1.2.3.3.2.3" stretchy="false" xref="S3.SS1.p1.12.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m1.2b"><apply id="S3.SS1.p1.12.m1.2.3.cmml" xref="S3.SS1.p1.12.m1.2.3"><times id="S3.SS1.p1.12.m1.2.3.1.cmml" xref="S3.SS1.p1.12.m1.2.3.1"></times><ci id="S3.SS1.p1.12.m1.2.3.2.cmml" xref="S3.SS1.p1.12.m1.2.3.2">𝑓</ci><interval closure="open" id="S3.SS1.p1.12.m1.2.3.3.1.cmml" xref="S3.SS1.p1.12.m1.2.3.3.2"><ci id="S3.SS1.p1.12.m1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1">𝑞</ci><ci id="S3.SS1.p1.12.m1.2.2.cmml" xref="S3.SS1.p1.12.m1.2.2">𝑑</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m1.2c">f(q,d)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.12.m1.2d">italic_f ( italic_q , italic_d )</annotation></semantics></math> between the query image and other image-text pairs by cosine similarity:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx4">
<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle f(q,d)=\cos(\mathbf{q},\mathbf{d})." class="ltx_Math" display="inline" id="S3.E5.m1.6"><semantics id="S3.E5.m1.6a"><mrow id="S3.E5.m1.6.6.1" xref="S3.E5.m1.6.6.1.1.cmml"><mrow id="S3.E5.m1.6.6.1.1" xref="S3.E5.m1.6.6.1.1.cmml"><mrow id="S3.E5.m1.6.6.1.1.2" xref="S3.E5.m1.6.6.1.1.2.cmml"><mi id="S3.E5.m1.6.6.1.1.2.2" xref="S3.E5.m1.6.6.1.1.2.2.cmml">f</mi><mo id="S3.E5.m1.6.6.1.1.2.1" xref="S3.E5.m1.6.6.1.1.2.1.cmml">⁢</mo><mrow id="S3.E5.m1.6.6.1.1.2.3.2" xref="S3.E5.m1.6.6.1.1.2.3.1.cmml"><mo id="S3.E5.m1.6.6.1.1.2.3.2.1" stretchy="false" xref="S3.E5.m1.6.6.1.1.2.3.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">q</mi><mo id="S3.E5.m1.6.6.1.1.2.3.2.2" xref="S3.E5.m1.6.6.1.1.2.3.1.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">d</mi><mo id="S3.E5.m1.6.6.1.1.2.3.2.3" stretchy="false" xref="S3.E5.m1.6.6.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.6.6.1.1.1" xref="S3.E5.m1.6.6.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.6.6.1.1.3.2" xref="S3.E5.m1.6.6.1.1.3.1.cmml"><mi id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml">cos</mi><mo id="S3.E5.m1.6.6.1.1.3.2a" xref="S3.E5.m1.6.6.1.1.3.1.cmml">⁡</mo><mrow id="S3.E5.m1.6.6.1.1.3.2.1" xref="S3.E5.m1.6.6.1.1.3.1.cmml"><mo id="S3.E5.m1.6.6.1.1.3.2.1.1" stretchy="false" xref="S3.E5.m1.6.6.1.1.3.1.cmml">(</mo><mi id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml">𝐪</mi><mo id="S3.E5.m1.6.6.1.1.3.2.1.2" xref="S3.E5.m1.6.6.1.1.3.1.cmml">,</mo><mi id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml">𝐝</mi><mo id="S3.E5.m1.6.6.1.1.3.2.1.3" stretchy="false" xref="S3.E5.m1.6.6.1.1.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.6.6.1.2" lspace="0em" xref="S3.E5.m1.6.6.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.6b"><apply id="S3.E5.m1.6.6.1.1.cmml" xref="S3.E5.m1.6.6.1"><eq id="S3.E5.m1.6.6.1.1.1.cmml" xref="S3.E5.m1.6.6.1.1.1"></eq><apply id="S3.E5.m1.6.6.1.1.2.cmml" xref="S3.E5.m1.6.6.1.1.2"><times id="S3.E5.m1.6.6.1.1.2.1.cmml" xref="S3.E5.m1.6.6.1.1.2.1"></times><ci id="S3.E5.m1.6.6.1.1.2.2.cmml" xref="S3.E5.m1.6.6.1.1.2.2">𝑓</ci><interval closure="open" id="S3.E5.m1.6.6.1.1.2.3.1.cmml" xref="S3.E5.m1.6.6.1.1.2.3.2"><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑞</ci><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">𝑑</ci></interval></apply><apply id="S3.E5.m1.6.6.1.1.3.1.cmml" xref="S3.E5.m1.6.6.1.1.3.2"><cos id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3"></cos><ci id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4">𝐪</ci><ci id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5">𝐝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.6c">\displaystyle f(q,d)=\cos(\mathbf{q},\mathbf{d}).</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.6d">italic_f ( italic_q , italic_d ) = roman_cos ( bold_q , bold_d ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.15">To inject factually-oriented medical knowledge into multimodal retrieval, we train the encoder to minimize the following loss,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=-\sum_{q_{img}\in D}\sum_{d^{+}\in N_{q_{img}}}\log\frac{e^{f(%
\mathbf{q},\mathbf{d}^{+})/\tau}}{e^{f(\mathbf{q},\mathbf{d}^{+})/\tau}+\sum_{%
\mathbf{d}^{-}}e^{f(\mathbf{q},\mathbf{d}^{-})/\tau}}," class="ltx_Math" display="block" id="S3.E6.m1.7"><semantics id="S3.E6.m1.7a"><mrow id="S3.E6.m1.7.7.1" xref="S3.E6.m1.7.7.1.1.cmml"><mrow id="S3.E6.m1.7.7.1.1" xref="S3.E6.m1.7.7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.7.7.1.1.2" xref="S3.E6.m1.7.7.1.1.2.cmml">ℒ</mi><mo id="S3.E6.m1.7.7.1.1.1" xref="S3.E6.m1.7.7.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.7.7.1.1.3" xref="S3.E6.m1.7.7.1.1.3.cmml"><mo id="S3.E6.m1.7.7.1.1.3a" xref="S3.E6.m1.7.7.1.1.3.cmml">−</mo><mrow id="S3.E6.m1.7.7.1.1.3.2" xref="S3.E6.m1.7.7.1.1.3.2.cmml"><munder id="S3.E6.m1.7.7.1.1.3.2.1" xref="S3.E6.m1.7.7.1.1.3.2.1.cmml"><mo id="S3.E6.m1.7.7.1.1.3.2.1.2" movablelimits="false" rspace="0em" xref="S3.E6.m1.7.7.1.1.3.2.1.2.cmml">∑</mo><mrow id="S3.E6.m1.7.7.1.1.3.2.1.3" xref="S3.E6.m1.7.7.1.1.3.2.1.3.cmml"><msub id="S3.E6.m1.7.7.1.1.3.2.1.3.2" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.1.3.2.2" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.2.cmml">q</mi><mrow id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.2" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.2.cmml">i</mi><mo id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.1" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.3" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.3.cmml">m</mi><mo id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.1a" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.4" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.4.cmml">g</mi></mrow></msub><mo id="S3.E6.m1.7.7.1.1.3.2.1.3.1" xref="S3.E6.m1.7.7.1.1.3.2.1.3.1.cmml">∈</mo><mi id="S3.E6.m1.7.7.1.1.3.2.1.3.3" xref="S3.E6.m1.7.7.1.1.3.2.1.3.3.cmml">D</mi></mrow></munder><mrow id="S3.E6.m1.7.7.1.1.3.2.2" xref="S3.E6.m1.7.7.1.1.3.2.2.cmml"><munder id="S3.E6.m1.7.7.1.1.3.2.2.1" xref="S3.E6.m1.7.7.1.1.3.2.2.1.cmml"><mo id="S3.E6.m1.7.7.1.1.3.2.2.1.2" movablelimits="false" xref="S3.E6.m1.7.7.1.1.3.2.2.1.2.cmml">∑</mo><mrow id="S3.E6.m1.7.7.1.1.3.2.2.1.3" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.cmml"><msup id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.2" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.2.cmml">d</mi><mo id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.3" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.3.cmml">+</mo></msup><mo id="S3.E6.m1.7.7.1.1.3.2.2.1.3.1" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.1.cmml">∈</mo><msub id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.2" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.2.cmml">N</mi><msub id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.2" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.2.cmml">q</mi><mrow id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.2" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.2.cmml">i</mi><mo id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.1" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.3" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.3.cmml">m</mi><mo id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.1a" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.4" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.4.cmml">g</mi></mrow></msub></msub></mrow></munder><mrow id="S3.E6.m1.7.7.1.1.3.2.2.2" xref="S3.E6.m1.7.7.1.1.3.2.2.2.cmml"><mi id="S3.E6.m1.7.7.1.1.3.2.2.2.1" xref="S3.E6.m1.7.7.1.1.3.2.2.2.1.cmml">log</mi><mo id="S3.E6.m1.7.7.1.1.3.2.2.2a" lspace="0.167em" xref="S3.E6.m1.7.7.1.1.3.2.2.2.cmml">⁡</mo><mfrac id="S3.E6.m1.6.6" xref="S3.E6.m1.6.6.cmml"><msup id="S3.E6.m1.2.2.2" xref="S3.E6.m1.2.2.2.cmml"><mi id="S3.E6.m1.2.2.2.4" xref="S3.E6.m1.2.2.2.4.cmml">e</mi><mrow id="S3.E6.m1.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.cmml"><mrow id="S3.E6.m1.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.cmml"><mi id="S3.E6.m1.2.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.2.3.cmml">f</mi><mo id="S3.E6.m1.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.2.cmml">⁢</mo><mrow id="S3.E6.m1.2.2.2.2.2.2.1.1" xref="S3.E6.m1.2.2.2.2.2.2.1.2.cmml"><mo id="S3.E6.m1.2.2.2.2.2.2.1.1.2" stretchy="false" xref="S3.E6.m1.2.2.2.2.2.2.1.2.cmml">(</mo><mi id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml">𝐪</mi><mo id="S3.E6.m1.2.2.2.2.2.2.1.1.3" xref="S3.E6.m1.2.2.2.2.2.2.1.2.cmml">,</mo><msup id="S3.E6.m1.2.2.2.2.2.2.1.1.1" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1.cmml"><mi id="S3.E6.m1.2.2.2.2.2.2.1.1.1.2" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1.2.cmml">𝐝</mi><mo id="S3.E6.m1.2.2.2.2.2.2.1.1.1.3" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1.3.cmml">+</mo></msup><mo id="S3.E6.m1.2.2.2.2.2.2.1.1.4" stretchy="false" xref="S3.E6.m1.2.2.2.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.3.cmml">/</mo><mi id="S3.E6.m1.2.2.2.2.2.4" xref="S3.E6.m1.2.2.2.2.2.4.cmml">τ</mi></mrow></msup><mrow id="S3.E6.m1.6.6.6" xref="S3.E6.m1.6.6.6.cmml"><msup id="S3.E6.m1.6.6.6.6" xref="S3.E6.m1.6.6.6.6.cmml"><mi id="S3.E6.m1.6.6.6.6.2" xref="S3.E6.m1.6.6.6.6.2.cmml">e</mi><mrow id="S3.E6.m1.4.4.4.2.2" xref="S3.E6.m1.4.4.4.2.2.cmml"><mrow id="S3.E6.m1.4.4.4.2.2.2" xref="S3.E6.m1.4.4.4.2.2.2.cmml"><mi id="S3.E6.m1.4.4.4.2.2.2.3" xref="S3.E6.m1.4.4.4.2.2.2.3.cmml">f</mi><mo id="S3.E6.m1.4.4.4.2.2.2.2" xref="S3.E6.m1.4.4.4.2.2.2.2.cmml">⁢</mo><mrow id="S3.E6.m1.4.4.4.2.2.2.1.1" xref="S3.E6.m1.4.4.4.2.2.2.1.2.cmml"><mo id="S3.E6.m1.4.4.4.2.2.2.1.1.2" stretchy="false" xref="S3.E6.m1.4.4.4.2.2.2.1.2.cmml">(</mo><mi id="S3.E6.m1.3.3.3.1.1.1" xref="S3.E6.m1.3.3.3.1.1.1.cmml">𝐪</mi><mo id="S3.E6.m1.4.4.4.2.2.2.1.1.3" xref="S3.E6.m1.4.4.4.2.2.2.1.2.cmml">,</mo><msup id="S3.E6.m1.4.4.4.2.2.2.1.1.1" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1.cmml"><mi id="S3.E6.m1.4.4.4.2.2.2.1.1.1.2" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1.2.cmml">𝐝</mi><mo id="S3.E6.m1.4.4.4.2.2.2.1.1.1.3" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1.3.cmml">+</mo></msup><mo id="S3.E6.m1.4.4.4.2.2.2.1.1.4" stretchy="false" xref="S3.E6.m1.4.4.4.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.4.2.2.3" xref="S3.E6.m1.4.4.4.2.2.3.cmml">/</mo><mi id="S3.E6.m1.4.4.4.2.2.4" xref="S3.E6.m1.4.4.4.2.2.4.cmml">τ</mi></mrow></msup><mo id="S3.E6.m1.6.6.6.5" rspace="0.055em" xref="S3.E6.m1.6.6.6.5.cmml">+</mo><mrow id="S3.E6.m1.6.6.6.7" xref="S3.E6.m1.6.6.6.7.cmml"><msub id="S3.E6.m1.6.6.6.7.1" xref="S3.E6.m1.6.6.6.7.1.cmml"><mo id="S3.E6.m1.6.6.6.7.1.2" xref="S3.E6.m1.6.6.6.7.1.2.cmml">∑</mo><msup id="S3.E6.m1.6.6.6.7.1.3" xref="S3.E6.m1.6.6.6.7.1.3.cmml"><mi id="S3.E6.m1.6.6.6.7.1.3.2" xref="S3.E6.m1.6.6.6.7.1.3.2.cmml">𝐝</mi><mo id="S3.E6.m1.6.6.6.7.1.3.3" xref="S3.E6.m1.6.6.6.7.1.3.3.cmml">−</mo></msup></msub><msup id="S3.E6.m1.6.6.6.7.2" xref="S3.E6.m1.6.6.6.7.2.cmml"><mi id="S3.E6.m1.6.6.6.7.2.2" xref="S3.E6.m1.6.6.6.7.2.2.cmml">e</mi><mrow id="S3.E6.m1.6.6.6.4.2" xref="S3.E6.m1.6.6.6.4.2.cmml"><mrow id="S3.E6.m1.6.6.6.4.2.2" xref="S3.E6.m1.6.6.6.4.2.2.cmml"><mi id="S3.E6.m1.6.6.6.4.2.2.3" xref="S3.E6.m1.6.6.6.4.2.2.3.cmml">f</mi><mo id="S3.E6.m1.6.6.6.4.2.2.2" xref="S3.E6.m1.6.6.6.4.2.2.2.cmml">⁢</mo><mrow id="S3.E6.m1.6.6.6.4.2.2.1.1" xref="S3.E6.m1.6.6.6.4.2.2.1.2.cmml"><mo id="S3.E6.m1.6.6.6.4.2.2.1.1.2" stretchy="false" xref="S3.E6.m1.6.6.6.4.2.2.1.2.cmml">(</mo><mi id="S3.E6.m1.5.5.5.3.1.1" xref="S3.E6.m1.5.5.5.3.1.1.cmml">𝐪</mi><mo id="S3.E6.m1.6.6.6.4.2.2.1.1.3" xref="S3.E6.m1.6.6.6.4.2.2.1.2.cmml">,</mo><msup id="S3.E6.m1.6.6.6.4.2.2.1.1.1" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1.cmml"><mi id="S3.E6.m1.6.6.6.4.2.2.1.1.1.2" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1.2.cmml">𝐝</mi><mo id="S3.E6.m1.6.6.6.4.2.2.1.1.1.3" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1.3.cmml">−</mo></msup><mo id="S3.E6.m1.6.6.6.4.2.2.1.1.4" stretchy="false" xref="S3.E6.m1.6.6.6.4.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.6.6.6.4.2.3" xref="S3.E6.m1.6.6.6.4.2.3.cmml">/</mo><mi id="S3.E6.m1.6.6.6.4.2.4" xref="S3.E6.m1.6.6.6.4.2.4.cmml">τ</mi></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><mo id="S3.E6.m1.7.7.1.2" xref="S3.E6.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.7b"><apply id="S3.E6.m1.7.7.1.1.cmml" xref="S3.E6.m1.7.7.1"><eq id="S3.E6.m1.7.7.1.1.1.cmml" xref="S3.E6.m1.7.7.1.1.1"></eq><ci id="S3.E6.m1.7.7.1.1.2.cmml" xref="S3.E6.m1.7.7.1.1.2">ℒ</ci><apply id="S3.E6.m1.7.7.1.1.3.cmml" xref="S3.E6.m1.7.7.1.1.3"><minus id="S3.E6.m1.7.7.1.1.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3"></minus><apply id="S3.E6.m1.7.7.1.1.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2"><apply id="S3.E6.m1.7.7.1.1.3.2.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.7.7.1.1.3.2.1.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1">subscript</csymbol><sum id="S3.E6.m1.7.7.1.1.3.2.1.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.2"></sum><apply id="S3.E6.m1.7.7.1.1.3.2.1.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3"><in id="S3.E6.m1.7.7.1.1.3.2.1.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.1"></in><apply id="S3.E6.m1.7.7.1.1.3.2.1.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.7.7.1.1.3.2.1.3.2.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2">subscript</csymbol><ci id="S3.E6.m1.7.7.1.1.3.2.1.3.2.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.2">𝑞</ci><apply id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3"><times id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.1"></times><ci id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.2">𝑖</ci><ci id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.3">𝑚</ci><ci id="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.4.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.2.3.4">𝑔</ci></apply></apply><ci id="S3.E6.m1.7.7.1.1.3.2.1.3.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.1.3.3">𝐷</ci></apply></apply><apply id="S3.E6.m1.7.7.1.1.3.2.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2"><apply id="S3.E6.m1.7.7.1.1.3.2.2.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.7.7.1.1.3.2.2.1.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1">subscript</csymbol><sum id="S3.E6.m1.7.7.1.1.3.2.2.1.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.2"></sum><apply id="S3.E6.m1.7.7.1.1.3.2.2.1.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3"><in id="S3.E6.m1.7.7.1.1.3.2.2.1.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.1"></in><apply id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2">superscript</csymbol><ci id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.2">𝑑</ci><plus id="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.2.3"></plus></apply><apply id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3">subscript</csymbol><ci id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.2">𝑁</ci><apply id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3">subscript</csymbol><ci id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.2">𝑞</ci><apply id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3"><times id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.1"></times><ci id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.2">𝑖</ci><ci id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.3.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.3">𝑚</ci><ci id="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.4.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.1.3.3.3.3.4">𝑔</ci></apply></apply></apply></apply></apply><apply id="S3.E6.m1.7.7.1.1.3.2.2.2.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.2"><log id="S3.E6.m1.7.7.1.1.3.2.2.2.1.cmml" xref="S3.E6.m1.7.7.1.1.3.2.2.2.1"></log><apply id="S3.E6.m1.6.6.cmml" xref="S3.E6.m1.6.6"><divide id="S3.E6.m1.6.6.7.cmml" xref="S3.E6.m1.6.6"></divide><apply id="S3.E6.m1.2.2.2.cmml" xref="S3.E6.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2">superscript</csymbol><ci id="S3.E6.m1.2.2.2.4.cmml" xref="S3.E6.m1.2.2.2.4">𝑒</ci><apply id="S3.E6.m1.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2"><divide id="S3.E6.m1.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.3"></divide><apply id="S3.E6.m1.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2"><times id="S3.E6.m1.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2"></times><ci id="S3.E6.m1.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.3">𝑓</ci><interval closure="open" id="S3.E6.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.1"><ci id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1">𝐪</ci><apply id="S3.E6.m1.2.2.2.2.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1">superscript</csymbol><ci id="S3.E6.m1.2.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1.2">𝐝</ci><plus id="S3.E6.m1.2.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.1.1.3"></plus></apply></interval></apply><ci id="S3.E6.m1.2.2.2.2.2.4.cmml" xref="S3.E6.m1.2.2.2.2.2.4">𝜏</ci></apply></apply><apply id="S3.E6.m1.6.6.6.cmml" xref="S3.E6.m1.6.6.6"><plus id="S3.E6.m1.6.6.6.5.cmml" xref="S3.E6.m1.6.6.6.5"></plus><apply id="S3.E6.m1.6.6.6.6.cmml" xref="S3.E6.m1.6.6.6.6"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.6.1.cmml" xref="S3.E6.m1.6.6.6.6">superscript</csymbol><ci id="S3.E6.m1.6.6.6.6.2.cmml" xref="S3.E6.m1.6.6.6.6.2">𝑒</ci><apply id="S3.E6.m1.4.4.4.2.2.cmml" xref="S3.E6.m1.4.4.4.2.2"><divide id="S3.E6.m1.4.4.4.2.2.3.cmml" xref="S3.E6.m1.4.4.4.2.2.3"></divide><apply id="S3.E6.m1.4.4.4.2.2.2.cmml" xref="S3.E6.m1.4.4.4.2.2.2"><times id="S3.E6.m1.4.4.4.2.2.2.2.cmml" xref="S3.E6.m1.4.4.4.2.2.2.2"></times><ci id="S3.E6.m1.4.4.4.2.2.2.3.cmml" xref="S3.E6.m1.4.4.4.2.2.2.3">𝑓</ci><interval closure="open" id="S3.E6.m1.4.4.4.2.2.2.1.2.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.1"><ci id="S3.E6.m1.3.3.3.1.1.1.cmml" xref="S3.E6.m1.3.3.3.1.1.1">𝐪</ci><apply id="S3.E6.m1.4.4.4.2.2.2.1.1.1.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.2.2.2.1.1.1.1.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1">superscript</csymbol><ci id="S3.E6.m1.4.4.4.2.2.2.1.1.1.2.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1.2">𝐝</ci><plus id="S3.E6.m1.4.4.4.2.2.2.1.1.1.3.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.1.1.3"></plus></apply></interval></apply><ci id="S3.E6.m1.4.4.4.2.2.4.cmml" xref="S3.E6.m1.4.4.4.2.2.4">𝜏</ci></apply></apply><apply id="S3.E6.m1.6.6.6.7.cmml" xref="S3.E6.m1.6.6.6.7"><apply id="S3.E6.m1.6.6.6.7.1.cmml" xref="S3.E6.m1.6.6.6.7.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.7.1.1.cmml" xref="S3.E6.m1.6.6.6.7.1">subscript</csymbol><sum id="S3.E6.m1.6.6.6.7.1.2.cmml" xref="S3.E6.m1.6.6.6.7.1.2"></sum><apply id="S3.E6.m1.6.6.6.7.1.3.cmml" xref="S3.E6.m1.6.6.6.7.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.7.1.3.1.cmml" xref="S3.E6.m1.6.6.6.7.1.3">superscript</csymbol><ci id="S3.E6.m1.6.6.6.7.1.3.2.cmml" xref="S3.E6.m1.6.6.6.7.1.3.2">𝐝</ci><minus id="S3.E6.m1.6.6.6.7.1.3.3.cmml" xref="S3.E6.m1.6.6.6.7.1.3.3"></minus></apply></apply><apply id="S3.E6.m1.6.6.6.7.2.cmml" xref="S3.E6.m1.6.6.6.7.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.7.2.1.cmml" xref="S3.E6.m1.6.6.6.7.2">superscript</csymbol><ci id="S3.E6.m1.6.6.6.7.2.2.cmml" xref="S3.E6.m1.6.6.6.7.2.2">𝑒</ci><apply id="S3.E6.m1.6.6.6.4.2.cmml" xref="S3.E6.m1.6.6.6.4.2"><divide id="S3.E6.m1.6.6.6.4.2.3.cmml" xref="S3.E6.m1.6.6.6.4.2.3"></divide><apply id="S3.E6.m1.6.6.6.4.2.2.cmml" xref="S3.E6.m1.6.6.6.4.2.2"><times id="S3.E6.m1.6.6.6.4.2.2.2.cmml" xref="S3.E6.m1.6.6.6.4.2.2.2"></times><ci id="S3.E6.m1.6.6.6.4.2.2.3.cmml" xref="S3.E6.m1.6.6.6.4.2.2.3">𝑓</ci><interval closure="open" id="S3.E6.m1.6.6.6.4.2.2.1.2.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.1"><ci id="S3.E6.m1.5.5.5.3.1.1.cmml" xref="S3.E6.m1.5.5.5.3.1.1">𝐪</ci><apply id="S3.E6.m1.6.6.6.4.2.2.1.1.1.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.4.2.2.1.1.1.1.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1">superscript</csymbol><ci id="S3.E6.m1.6.6.6.4.2.2.1.1.1.2.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1.2">𝐝</ci><minus id="S3.E6.m1.6.6.6.4.2.2.1.1.1.3.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.1.1.3"></minus></apply></interval></apply><ci id="S3.E6.m1.6.6.6.4.2.4.cmml" xref="S3.E6.m1.6.6.6.4.2.4">𝜏</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.7c">\mathcal{L}=-\sum_{q_{img}\in D}\sum_{d^{+}\in N_{q_{img}}}\log\frac{e^{f(%
\mathbf{q},\mathbf{d}^{+})/\tau}}{e^{f(\mathbf{q},\mathbf{d}^{+})/\tau}+\sum_{%
\mathbf{d}^{-}}e^{f(\mathbf{q},\mathbf{d}^{-})/\tau}},</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.7d">caligraphic_L = - ∑ start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT ∈ italic_D end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_d start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ∈ italic_N start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_log divide start_ARG italic_e start_POSTSUPERSCRIPT italic_f ( bold_q , bold_d start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) / italic_τ end_POSTSUPERSCRIPT end_ARG start_ARG italic_e start_POSTSUPERSCRIPT italic_f ( bold_q , bold_d start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) / italic_τ end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT bold_d start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_f ( bold_q , bold_d start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ) / italic_τ end_POSTSUPERSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.14">where <math alttext="d^{+}" class="ltx_Math" display="inline" id="S3.SS1.p1.13.m1.1"><semantics id="S3.SS1.p1.13.m1.1a"><msup id="S3.SS1.p1.13.m1.1.1" xref="S3.SS1.p1.13.m1.1.1.cmml"><mi id="S3.SS1.p1.13.m1.1.1.2" xref="S3.SS1.p1.13.m1.1.1.2.cmml">d</mi><mo id="S3.SS1.p1.13.m1.1.1.3" xref="S3.SS1.p1.13.m1.1.1.3.cmml">+</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m1.1b"><apply id="S3.SS1.p1.13.m1.1.1.cmml" xref="S3.SS1.p1.13.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m1.1.1.1.cmml" xref="S3.SS1.p1.13.m1.1.1">superscript</csymbol><ci id="S3.SS1.p1.13.m1.1.1.2.cmml" xref="S3.SS1.p1.13.m1.1.1.2">𝑑</ci><plus id="S3.SS1.p1.13.m1.1.1.3.cmml" xref="S3.SS1.p1.13.m1.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m1.1c">d^{+}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.13.m1.1d">italic_d start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math> are obtained through factual report pair mining and <math alttext="d^{-}" class="ltx_Math" display="inline" id="S3.SS1.p1.14.m2.1"><semantics id="S3.SS1.p1.14.m2.1a"><msup id="S3.SS1.p1.14.m2.1.1" xref="S3.SS1.p1.14.m2.1.1.cmml"><mi id="S3.SS1.p1.14.m2.1.1.2" xref="S3.SS1.p1.14.m2.1.1.2.cmml">d</mi><mo id="S3.SS1.p1.14.m2.1.1.3" xref="S3.SS1.p1.14.m2.1.1.3.cmml">−</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m2.1b"><apply id="S3.SS1.p1.14.m2.1.1.cmml" xref="S3.SS1.p1.14.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.14.m2.1.1.1.cmml" xref="S3.SS1.p1.14.m2.1.1">superscript</csymbol><ci id="S3.SS1.p1.14.m2.1.1.2.cmml" xref="S3.SS1.p1.14.m2.1.1.2">𝑑</ci><minus id="S3.SS1.p1.14.m2.1.1.3.cmml" xref="S3.SS1.p1.14.m2.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m2.1c">d^{-}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.14.m2.1d">italic_d start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT</annotation></semantics></math> are in-batch negative samples <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib20" title="">2020</a>)</cite>.
Then, we use our multimodal retriever and foundation model to perform retrieval-augmented radiology finding generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Retrieval Augmentation for Accurate Radiology Report Generation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.5">Given our trained fact-aware multimodal retriever, we encode the query image and each report in the training corpus.
Then, we retrieve the report with the highest relevance score to the query image as the factually-informed relevant report.
Subsequently, we pass the query image along with the relevant report into a multimodal foundation model to perform retrieval-augmented generation training.
The multimodal foundation model is finetuned by standard autogressive loss,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=-\frac{1}{n}\log\prod_{i}^{n}p_{\theta}(y_{i}|q_{img},d_{txt}^{*},%
x_{\texttt{instr}},y_{&lt;i})," class="ltx_Math" display="block" id="S3.E7.m1.1"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.3.cmml">ℒ</mi><mo id="S3.E7.m1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.1.1.1.1.1a" xref="S3.E7.m1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mfrac id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml"><mn id="S3.E7.m1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.1.1.3.2.cmml">1</mn><mi id="S3.E7.m1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.1.1.3.3.cmml">n</mi></mfrac><mo id="S3.E7.m1.1.1.1.1.1.1.2" lspace="0.167em" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.1.1.1.1.1.1.4" xref="S3.E7.m1.1.1.1.1.1.1.4.cmml">log</mi><mo id="S3.E7.m1.1.1.1.1.1.1.2a" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.cmml"><munderover id="S3.E7.m1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E7.m1.1.1.1.1.1.1.1.2.2.2" movablelimits="false" xref="S3.E7.m1.1.1.1.1.1.1.1.2.2.2.cmml">∏</mo><mi id="S3.E7.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.E7.m1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.1.1.1.1.1.1.1.2.3.cmml">n</mi></munderover><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.2.cmml">y</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.3.cmml">i</mi></msub><mo fence="false" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.5.cmml">|</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.5.cmml"><msub id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">q</mi><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">m</mi><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4.cmml">g</mi></mrow></msub><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.5" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.5.cmml">,</mo><msubsup id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">d</mi><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml">t</mi><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml">x</mi><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1a" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.4" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.4.cmml">t</mi></mrow><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">∗</mo></msubsup><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.6" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.5.cmml">,</mo><msub id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">x</mi><mtext class="ltx_mathvariant_monospace" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.3a.cmml">instr</mtext></msub><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.7" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.5.cmml">,</mo><msub id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.2.cmml">y</mi><mrow id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.2.cmml"></mi><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.1.cmml">&lt;</mo><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.3.cmml">i</mi></mrow></msub></mrow></mrow><mo id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><eq id="S3.E7.m1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.2"></eq><ci id="S3.E7.m1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3">ℒ</ci><apply id="S3.E7.m1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"><minus id="S3.E7.m1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1"></minus><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1"><times id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2"></times><apply id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3"><divide id="S3.E7.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3"></divide><cn id="S3.E7.m1.1.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.E7.m1.1.1.1.1.1.1.3.2">1</cn><ci id="S3.E7.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.3">𝑛</ci></apply><log id="S3.E7.m1.1.1.1.1.1.1.4.cmml" xref="S3.E7.m1.1.1.1.1.1.1.4"></log><apply id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1"><apply id="S3.E7.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2">subscript</csymbol><csymbol cd="latexml" id="S3.E7.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2.2.2">product</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply><ci id="S3.E7.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.2.3">𝑛</ci></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1"><times id="S3.E7.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3.2">𝑝</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.5">conditional</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.2">𝑦</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.6.3">𝑖</ci></apply><list id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.5.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4"><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑞</ci><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝑖</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑚</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.4">𝑔</ci></apply></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2">𝑑</ci><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3"><times id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1"></times><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2">𝑡</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3">𝑥</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.4.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.4">𝑡</ci></apply></apply><times id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3"></times></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.2">𝑥</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.3a.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.3"><mtext class="ltx_mathvariant_monospace" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" mathsize="70%" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.3">instr</mtext></ci></apply><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.2">𝑦</ci><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3"><lt id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.1"></lt><csymbol cd="latexml" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.2">absent</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.1.4.4.4.3.3">𝑖</ci></apply></apply></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\mathcal{L}=-\frac{1}{n}\log\prod_{i}^{n}p_{\theta}(y_{i}|q_{img},d_{txt}^{*},%
x_{\texttt{instr}},y_{&lt;i}),</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.1d">caligraphic_L = - divide start_ARG 1 end_ARG start_ARG italic_n end_ARG roman_log ∏ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT , italic_x start_POSTSUBSCRIPT instr end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.4">where <math alttext="q_{img}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">q</mi><mrow id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml">m</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1a" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.4" xref="S3.SS2.p1.1.m1.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝑞</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><times id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.1"></times><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">𝑖</ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3">𝑚</ci><ci id="S3.SS2.p1.1.m1.1.1.3.4.cmml" xref="S3.SS2.p1.1.m1.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">q_{img}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT</annotation></semantics></math> is the query image, <math alttext="d_{txt}^{*}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msubsup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">d</mi><mrow id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.3.2" xref="S3.SS2.p1.2.m2.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.3" xref="S3.SS2.p1.2.m2.1.1.2.3.3.cmml">x</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3.1a" xref="S3.SS2.p1.2.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.2.m2.1.1.2.3.4" xref="S3.SS2.p1.2.m2.1.1.2.3.4.cmml">t</mi></mrow><mo id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">𝑑</ci><apply id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3"><times id="S3.SS2.p1.2.m2.1.1.2.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.1"></times><ci id="S3.SS2.p1.2.m2.1.1.2.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.2">𝑡</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.3">𝑥</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.4.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3.4">𝑡</ci></apply></apply><times id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">d_{txt}^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math> is the retrieved factually-informed relevant report, <math alttext="x_{\texttt{instr}}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">x</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3a.cmml">instr</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">𝑥</ci><ci id="S3.SS2.p1.3.m3.1.1.3a.cmml" xref="S3.SS2.p1.3.m3.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S3.SS2.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS2.p1.3.m3.1.1.3">instr</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">x_{\texttt{instr}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_x start_POSTSUBSCRIPT instr end_POSTSUBSCRIPT</annotation></semantics></math> is the prompt instruction, and <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_y</annotation></semantics></math> is the ground-truth report.
During inference, we retrieve a relevant report from the training corpus using an unseen patient X-ray image, and pass them into the multimodal foundation model to generate findings with higher factual accuracy.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Dataset.</span> Following <cite class="ltx_cite ltx_citemacro_citet">Delbrouck et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib8" title="">2023</a>)</cite>, we use the processed MIMIC-CXR <cite class="ltx_cite ltx_citemacro_cite">Johnson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib19" title="">2019</a>)</cite> to train both retriever and foundation model.
This dataset contains 125,417 training radiology image-report pairs, 991 validation pairs, and 1,624 test pairs.
They are sourced from the Beth Israel Deaconess Medical Center.
CheXpert <cite class="ltx_cite ltx_citemacro_cite">Irvin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib15" title="">2019</a>)</cite> is another chest X-ray dataset from Stanford Health Care.
Since it contains complete finding reports only for a testing dataset containing 1000 pairs, we use it as zero-shot evaluation.

<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.p1.1.2">Evaluation Metrics.</span> We evaluate our proposed system using both natural language generation and medically-tailored evaluation metrics. 
<br class="ltx_break"/>
<br class="ltx_break"/>For language fluency measures, we use ROUGE-L <cite class="ltx_cite ltx_citemacro_cite">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib24" title="">2004</a>)</cite> to evaluate the longest common subsequence overlap between the generated and reference findings, and BERTScore <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib50" title="">2020a</a>)</cite> to evaluate non-clinical semantic sentence similarity.
<br class="ltx_break"/>
<br class="ltx_break"/>For clinical accuracy measures, we employ CheXbert <cite class="ltx_cite ltx_citemacro_cite">Smit et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib36" title="">2020</a>)</cite> to generate the ground-truth diagnostic labels for finding reports, identifying 14 different types of observations.
Following <cite class="ltx_cite ltx_citemacro_citet">Delbrouck et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib8" title="">2023</a>)</cite>, we then calculate the F1CheXbert <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib52" title="">2020b</a>)</cite>, which is the F1-score for 5 observations (Cardiomegaly, Edema, Consolidation, Atelectasis, Pleural Effusion) by comparing the generated report with the reference report’s classifications.
Beyond using the limited diagnostic labels for evaluation, we also adopt F1RadGraph <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib18" title="">2021</a>)</cite> to measure factual correctness by calculating the overlap in radiological entities and clinical relations between the generated report and the reference report.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.p1.1.3">Baselines.</span>
We mainly compare our retriever with other baselines under multimodal RAG setting.
We include the following baselines, CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib32" title="">2021</a>)</cite> is a multimodal retriever pretrained from general-domain image-text pairs;
GLoRIA <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib14" title="">2021</a>)</cite> leverages attention-weighted image regions with contextual words to learn localized and global representations for radiology images and reports;
MedCLIP <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib42" title="">2022</a>)</cite> and CXR-CLIP <cite class="ltx_cite ltx_citemacro_citep">(You et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib46" title="">2023</a>)</cite> build upon CLIP and utilize diagnostic labels as training signals for learning radiology image and text representations;
BiomedCLIP <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib49" title="">2024</a>)</cite> extends the radiology-specific dataset and pretrains on a larger magnitude of biomedical data to learn multimodal representations;
Med-MARVEL utilizes universal encoder MARVEL <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite> to conduct contrastive learning on each patient’s self image-report pair without further training on factual image-report pairs.
<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.p1.1.4">Implementation Details.</span> In our experiments, we use MARVEL <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite> as our multimodal retriever backbone.
MARVEL is a language model based on T5-ANCE <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib47" title="">2023a</a>)</cite>, trained with modality-balanced hard negatives.
We use LLaVA <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib25" title="">2023</a>)</cite> as our multimodal foundation model backbone.
Since each radiology study contains multiple image views for each patient, we select the frontal view.
We also concatenate the finding and impression sections to form the X-ray report.
To reduce training costs and address factual report pair imbalances, we rerank the retrieved reports by factual similarity and use the top 2 factual report pairs for each query to train our multimodal retriever.
We leave the training details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#A1" title="Appendix A Appendix ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:433.6pt;height:103.4pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-200.4pt,47.6pt) scale(0.519667538237214,0.519667538237214) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T1.1.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.2.1">MIMIC-CXR</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.3.1">CheXpert</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.1.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.2.1">Factual Similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.3.1">Textual Similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.4.1">Factual Similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.5.1">Textual Similarity</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T1.1.1.3.3.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.2">F1CheXbert</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.3">F1RadGraph</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.4">ROUGE-L</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.5">BERTScore</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.6">F1CheXbert</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.7">F1RadGraph</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.8">ROUGE-L</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.9">BERTScore</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.4.4.1">No Retriever</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.2">0.496</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.3">0.234</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.4">0.294</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.5">0.549</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.6">0.371</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.7">0.173</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.8">0.231</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.9">0.469</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.5.5.1">CLIP <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib32" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.2">0.507</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.3">0.241</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.4">0.300</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.5">0.552</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.6">0.381</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.7">0.172</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.8">0.231</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.9">0.468</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.6.6.1">GLoRIA <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib14" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.2">0.476</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.3">0.232</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.4">0.294</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.5">0.543</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.6">0.397</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.7">0.173</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.8">0.231</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.6.6.9">0.468</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.7.7.1">MedCLIP <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib42" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.2">0.517</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.3">0.238</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.4">0.298</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.5">0.549</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.6">0.408</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.7">0.182</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.8">0.238</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.7.7.9">0.471</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.8.8.1">CXR-CLIP <cite class="ltx_cite ltx_citemacro_cite">You et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib46" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.2">0.501</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.3">0.243</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.4">0.302</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.5">0.553</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.6">0.406</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.7">0.183</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.8">0.241</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.8.8.9">0.471</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.9.9.1">BiomedCLIP <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib49" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.2">0.502</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.3">0.233</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.4">0.293</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.5">0.546</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.6">0.380</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.7">0.173</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.8">0.232</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.9.9.9">0.469</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.10.10.1">Med-MARVEL <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.2">0.537</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.3">0.237</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.4">0.306</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.5">0.549</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.6">0.454</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.7">0.185</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.8">0.243</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.10.10.9">0.472</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.1.1.11.11.1">FactMM-RAG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.2.1">0.602</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.3.1">0.257</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.4.1">0.307</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.5.1">0.561</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.6"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.6.1">0.475</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.7"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.7.1">0.185</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.8"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.8.1">0.236</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.1.11.11.9"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.11.11.9.1">0.475</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overall performance of FactMM-RAG and baselines under the multimodal retrieval-augmentation setting. Models are evaluated by textual similarity and factual similarity between generated and reference reports. FactMM-RAG outperforms the best baseline with p-value &lt; 0.05. </figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel" id="S4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="483" id="S4.F2.sf1.g1" src="extracted/5746006/Figures/Hyperparameter_Search/hyperparameter_search_chex_0.0.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>F1CheXbert Threshold: 0.0</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel" id="S4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="483" id="S4.F2.sf2.g1" src="extracted/5746006/Figures/Hyperparameter_Search/hyperparameter_search_chex_0.4.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>F1CheXbert Threshold: 0.4</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel" id="S4.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="483" id="S4.F2.sf3.g1" src="extracted/5746006/Figures/Hyperparameter_Search/hyperparameter_search_chex_0.8.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>F1CheXbert Threshold: 0.8</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel" id="S4.F2.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="483" id="S4.F2.sf4.g1" src="extracted/5746006/Figures/Hyperparameter_Search/hyperparameter_search_chex_1.0.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>F1CheXbert Threshold: 1.0</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Factual performance of FactMM-RAG controlled by different F1CheXbert and F1RadGraph thresholds.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section, we present our experimental results.
We first evaluate the overall performance between different retrievers under two settings in section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS1" title="5.1 Overall Performance ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
Next, we discuss the ablation studies in section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS2" title="5.2 Ablation Study ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">5.2</span></a>.
We then explore the fact-aware capability of our retriever in section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.F3" title="Figure 3 ‣ 5.3 Fact-aware Capability Control ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">3</span></a> and section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS4" title="5.4 Fact-aware Capability Propagation ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">5.4</span></a>.
Lastly, we show the superiority of our retriever through a case study in section <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.SS5" title="5.5 Case Study ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">5.5</span></a>.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Overall Performance</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The results of our fact-aware RAG system are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S4.T1" title="Table 1 ‣ 4 Experimental Setup ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">1</span></a>.
In MIMIC-CXR, FactMM-RAG outperforms state-of-the-art retrievers by a significant margin, up to 6.5% in F1CheXbert and 2% in F1RadGraph.
In the CheXpert zero-shot evaluation, FactMM-RAG outperforms state-of-the-art retrievers by 2% and 1.2% in these two metrics, indicating our retriever’s generalization capability compared to other models.
<br class="ltx_break"/>
<br class="ltx_break"/>Besides, we can observe that adopting the baseline retrievers on top of multimodal foundation models only yields marginal gains compared to the finetuning of foundation model generation without retrieval-augmentation.
This shows that reports retrieved by baseline retrievers are factually-inferior to those from our retriever, potentially passing misleading information that prevents the foundation model from generating factual reports. 
<br class="ltx_break"/>
<br class="ltx_break"/>Specifically, compared to the retriever Med-MARVEL, we also observe factual-correctness performance gain based on two clinical metrics.
Both use the same universal encoder backbone, but FactMM-RAG benefits from the injected factual medical knowledge, allowing it to search for the most similar and factually correct reports, thereby assisting the multimodal foundation model in generating more accurate reports.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.4" style="width:433.6pt;height:155.4pt;vertical-align:-5.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-200.4pt,69.2pt) scale(0.519667538237214,0.519667538237214) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.4.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.4.4.5.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T2.4.4.5.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T2.4.4.5.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.5.1.2.1">MIMIC-CXR</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T2.4.4.5.1.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.5.1.3.1">CheXpert</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.6.2.1"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.1.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.4.4.6.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.2.1">Factual Similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.4.4.6.2.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.3.1">Textual Similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.4.4.6.2.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.4.1">Factual Similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.4.4.6.2.5"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.5.1">Textual Similarity</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.7.3">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.4.4.7.3.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.2">F1CheXbert</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.3">F1RadGraph</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.4">ROUGE-L</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.5">BERTScore</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.6">F1CheXbert</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.7">F1RadGraph</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.8">ROUGE-L</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.7.3.9">BERTScore</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="9" id="S5.T2.4.4.8.4.1">
<span class="ltx_text ltx_font_bold" id="S5.T2.4.4.8.4.1.1">Setting</span>: Multimodal Retrieval</th>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.4.9.5.1">CLIP <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib32" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.2">0.341</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.3">0.160</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.4">0.238</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.5">0.489</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.6">0.285</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.7">0.130</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.8">0.207</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.9.5.9">0.439</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.10.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.10.6.1">GLoRIA <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib14" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.2">0.346</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.3">0.137</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.4">0.211</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.5">0.453</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.6">0.359</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.7">0.135</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.8">0.216</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.10.6.9">0.447</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.11.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.11.7.1">MedCLIP <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib42" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.2">0.539</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.3">0.198</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.4">0.261</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.5">0.508</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.6">0.478</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.7">0.161</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.8">0.225</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.11.7.9">0.454</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.12.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.12.8.1">CXR-CLIP <cite class="ltx_cite ltx_citemacro_cite">You et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib46" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.2">0.516</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.3">0.215</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.4">0.277</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.5">0.524</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.6">0.444</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.7">0.167</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.8">0.230</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.12.8.9">0.458</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.13.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.13.9.1">BiomedCLIP <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib49" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.2">0.502</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.3">0.233</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.4">0.293</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.5">0.546</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.6">0.386</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.7">0.142</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.8">0.216</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.13.9.9">0.441</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.14.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.14.10.1">Med-MARVEL <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.2">0.550</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.3">0.212</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.4">0.279</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.5">0.525</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.6">0.479</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.7">0.160</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.8">0.222</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.14.10.9">0.454</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.15.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.4.4.15.11.1">FactMM-RAG</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.2.1">0.605</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.3.1">0.249</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.4.1">0.297</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.5"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.5.1">0.547</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.6"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.6.1">0.491</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.7"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.7.1">0.174</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.8"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.8.1">0.237</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.15.11.9"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.15.11.9.1">0.467</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.16.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="9" id="S5.T2.4.4.16.12.1">
<span class="ltx_text ltx_font_bold" id="S5.T2.4.4.16.12.1.1">Setting</span>: Multimodal Retrieval Augmented Generation</th>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.1.1.1.1">ClueWeb-LLaVA<sub class="ltx_sub" id="S5.T2.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T2.1.1.1.1.1.1">1.5</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.2.1">0.602</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.3">0.257</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.4">0.307</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.5">0.561</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.6.1">0.495</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.7">0.180</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.8.1">0.239</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.1.9">0.473</td>
</tr>
<tr class="ltx_tr" id="S5.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.2.2.2.1">WebQA-LLaVA<sub class="ltx_sub" id="S5.T2.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S5.T2.2.2.2.1.1.1">1.5</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.2">0.572</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T2.2.2.2.3.1">0.262</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.4">0.304</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.5">0.562</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.6">0.456</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.7">0.184</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.8">0.237</td>
<td class="ltx_td ltx_align_center" id="S5.T2.2.2.2.9"><span class="ltx_text ltx_font_bold" id="S5.T2.2.2.2.9.1">0.474</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.3.3.1">Med-MARVEL-LLaVA<sub class="ltx_sub" id="S5.T2.3.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S5.T2.3.3.3.1.1.1">1.5</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.2">0.581</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.3">0.260</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.4"><span class="ltx_text ltx_font_bold" id="S5.T2.3.3.3.4.1">0.311</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.5"><span class="ltx_text ltx_font_bold" id="S5.T2.3.3.3.5.1">0.563</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.6">0.475</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.7"><span class="ltx_text ltx_font_bold" id="S5.T2.3.3.3.7.1">0.185</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.8">0.236</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.3.3.9"><span class="ltx_text ltx_font_bold" id="S5.T2.3.3.3.9.1">0.474</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.4.4.4.1">ClueWeb-LLaVA<sub class="ltx_sub" id="S5.T2.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S5.T2.4.4.4.1.1.1">1.6</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.2">0.601</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.3">0.252</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.4">0.303</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.5">0.558</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.6">0.492</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.7">0.178</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.8">0.237</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.4.9">0.471</td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S5.T2.4.5">[]</p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation study of FactMM-RAG including multimodal retrieval and backbone variation.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Ablation Study </h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Multimodal Retrieval.</span> Instead of relying on the multimodal foundation model to generate reports, we also evaluate the performance of the multimodal retrievers by directly encoding radiology images from the testing corpus and searching for the closest report from the training corpus for comparison with ground-truth reports.
Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.T2" title="Table 2 ‣ 5.1 Overall Performance ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">2</span></a> shows that our retriever also achieves the best factual retrieval performance compared to other baselines under this setting across two datasets.
This demonstrates that training the multimodal retriever with mined factually-informed report pairs can enhance its radiology image understanding capabilities and directly align it with precise reports.

<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">Backbone Variation.</span> We also investigate the impact of different retriever and foundation model backbones on radiology report generation in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.T2" title="Table 2 ‣ 5.1 Overall Performance ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.
We initialize our retriever model from two checkpoints: WebQA and ClueWeb in <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite>.
We observe that the ClueWeb checkpoint provides a marginal gain compared to the WebQA checkpoint.
This can be attributed to the larger scale of the ClueWeb dataset used for pretraining.
We also utilize Med-MARVEL as our retriever backbone, which exhibits similar performance to other backbones after training.
This implies that even if our retriever is initialized with a backbone from a general domain, our factually-informed training strategy enables it to fully leverage medical knowledge and quickly adapt to the radiology-specific domain without degrading performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Fact-aware Capability Control</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The factual similarity threshold in Equation <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S3.E1" title="In 3.1 Fact-aware Multimodal Retrieval ‣ 3 Methodology ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">1</span></a> plays a critical role in controlling the fact-awareness of our multimodal retriever.
We examine the performance of FactMM-RAG under different thresholds, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S4.F2" title="Figure 2 ‣ 4 Experimental Setup ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">2</span></a>.
Not only utilizing F1RadGraph thresholds, we also employ F1CheXbert to curate additional thresholds from the report’s diagnostic labels to mine report pairs.
<br class="ltx_break"/>
<br class="ltx_break"/>Under the same F1CheXbert threshold for mining report pairs, we observe that an increase in the F1RadGraph threshold correlates with an improvement in factual performance.
However, adopting stricter thresholds for identifying report pairs does not yield further improvements and reaches saturation.
After calculating the average number of report pairs per query, we find that high thresholds can exclude many relevant report pairs, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.F3" title="Figure 3 ‣ 5.3 Fact-aware Capability Control ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">3</span></a>. This exclusion results in the potential loss of factually useful pairs, thereby hindering the training of our multimodal retriever driven by additional factual medical knowledge.
<br class="ltx_break"/>
<br class="ltx_break"/>Rather than relying on diagnostic labels from CheXbert to identify high-quality report pairs, Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S4.F2.sf1" title="In Figure 2 ‣ 4 Experimental Setup ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">2(a)</span></a> demonstrates that the F1RadGraph threshold alone can also effectively mine factual report pairs for training our multimodal retriever.
As the F1RadGraph threshold increases, FactMM-RAG even matches the performance under high threshold settings in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S4.F2.sf4" title="In Figure 2 ‣ 4 Experimental Setup ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">2(d)</span></a>.
This signifies that employing our training strategy with curated factual query-report pairs still imposes useful supervision signals without relying on explicit diagnostic label guidance.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="S5.F3.g1" src="x1.png" width="398"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Retrieval evaluation of FactMM-RAG with different F1CheXbert and F1RadGraph thresholds.</figcaption>
</figure>
<figure class="ltx_table" id="S5.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.2" style="width:433.6pt;height:411.2pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-143.0pt,135.4pt) scale(0.60259641075639,0.60259641075639) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.2.2.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.2.2.3.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.1.1">Radiology Image</span></th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.2.2.3.1.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.3.1.2.1">
<span class="ltx_p" id="S5.T3.2.2.3.1.2.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.2.1.1.1">Med-MARVEL</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.2.2.3.1.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.3.1.3.1">
<span class="ltx_p" id="S5.T3.2.2.3.1.3.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.3.1.1.1">FactMM-RAG</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S5.T3.2.2.3.1.4">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.3.1.4.1">
<span class="ltx_p" id="S5.T3.2.2.3.1.4.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.2.2.3.1.4.1.1.1">Reference</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.1.1.1.1"><span class="ltx_text" id="S5.T3.1.1.1.1.1" style="position:relative; bottom:0.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="260" id="S5.T3.1.1.1.1.1.g1" src="extracted/5746006/Figures/case_study1.jpg" width="216"/></span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.1.1.1.2.1">
<span class="ltx_p" id="S5.T3.1.1.1.2.1.1" style="width:170.7pt;">Single portable view of the chest. <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.2.1.1.1" style="color:#00FFFF;">There are bilateral pleural effusions,</span> moderate on the left and small on the right. <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.2.1.1.2" style="color:#00FFFF;">There is also pulmonary vascular redistribution and hazy alveolar infiltrate. cardiac silhouette is enlarged</span> but unchanged. Median sternotomy wires and mediastinal clips are again noted.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.1.1.1.3.1">
<span class="ltx_p" id="S5.T3.1.1.1.3.1.1" style="width:170.7pt;">A left-sided pacemaker is in place with leads terminating in the right atrium and right ventricle.<span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.3.1.1.1"> <span class="ltx_text" id="S5.T3.1.1.1.3.1.1.1.1" style="color:#FF8000;">The patient is status post median sternotomy and CABG.</span></span> The heart is moderately enlarged. <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.3.1.1.2"> <span class="ltx_text" id="S5.T3.1.1.1.3.1.1.2.1" style="color:#00FFFF;">There is mild pulmonary edema. A small left pleural effusion is present.</span></span> <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.3.1.1.3"> <span class="ltx_text" id="S5.T3.1.1.1.3.1.1.3.1" style="color:#FF0000;">There is atelectasis at the left lung base.</span> <span class="ltx_text" id="S5.T3.1.1.1.3.1.1.3.2" style="color:#FF8000;">No pneumothorax is seen.</span></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.1.1.1.4.1">
<span class="ltx_p" id="S5.T3.1.1.1.4.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.4.1.1.1" style="color:#FF8000;">The patient is status post median sternotomy and CABG.</span> Left-sided dual-chamber pacemaker is noted with leads terminating in right atrium and right ventricle, unchanged. Cardiomegaly is similar. <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.4.1.1.2" style="color:#00FFFF;">There is continued mild to moderate pulmonary edema</span>, slightly improved compared to the prior exam. <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.4.1.1.3" style="color:#00FFFF;">Small layering bilateral pleural effusions</span> also may be slightly decreased in the interval. <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.4.1.1.4"> <span class="ltx_text" id="S5.T3.1.1.1.4.1.1.4.1" style="color:#FF0000;">Bibasilar airspace opacities likely reflect atelectasis.</span></span> <span class="ltx_text ltx_font_italic" id="S5.T3.1.1.1.4.1.1.5" style="color:#FF8000;">There is no pneumothorax.</span> No acute osseous abnormalities are visualized.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.2.2.4.1.1">F1RadGraph</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.4.1.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.4.1.2.1">
<span class="ltx_p" id="S5.T3.2.2.4.1.2.1.1" style="width:170.7pt;">0.218</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.4.1.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.4.1.3.1">
<span class="ltx_p" id="S5.T3.2.2.4.1.3.1.1" style="width:170.7pt;">0.413</span>
</span>
</td>
<td class="ltx_td ltx_align_top ltx_border_t" id="S5.T3.2.2.4.1.4"></td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2.5.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.2.2.5.2.1">CheXbert Observations</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.5.2.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.5.2.2.1">
<span class="ltx_p" id="S5.T3.2.2.5.2.2.1.1" style="width:170.7pt;">Cardiomegaly, Edema, Pleural Effusion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.5.2.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.5.2.3.1">
<span class="ltx_p" id="S5.T3.2.2.5.2.3.1.1" style="width:170.7pt;">Cardiomegaly, Edema, Atelectasis, Pleural Effusion</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.2.2.5.2.4">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.5.2.4.1">
<span class="ltx_p" id="S5.T3.2.2.5.2.4.1.1" style="width:170.7pt;">Cardiomegaly, Edema, Atelectasis, Pleural Effusion</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.2.2.2.1"><span class="ltx_text" id="S5.T3.2.2.2.1.1" style="position:relative; bottom:0.0pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="248" id="S5.T3.2.2.2.1.1.g1" src="extracted/5746006/Figures/case_study2.jpg" width="216"/></span></th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.2.2.1">
<span class="ltx_p" id="S5.T3.2.2.2.2.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.2.1.1.1" style="color:#00FFFF;">The heart is mildly enlarged. The aorta is mildly tortuous<span class="ltx_text ltx_font_upright" id="S5.T3.2.2.2.2.1.1.1.1">.</span></span> The mediastinal and hilar contours appear unchanged. <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.2.1.1.2" style="color:#00FFFF;">There is no pleural effusion or pneumothorax.</span> Streaky left basilar opacity suggests minor atelectasis. <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.2.1.1.3" style="color:#00FFFF;">There is no definite pleural effusion or pneumothorax.</span> The bones appear demineralized. There is mild-to-moderate rightward convex curvature centered along the mid thoracic spine.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.2.3.1">
<span class="ltx_p" id="S5.T3.2.2.2.3.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.3.1.1.1" style="color:#00FFFF;">Heart size is mildly enlarged. The aorta is tortuous.</span> Mediastinal and hilar contours are otherwise unremarkable.<span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.3.1.1.2" style="color:#FF8000;"> Pulmonary vasculature is normal.</span> Linear opacities in the left lower lobe are compatible with subsegmental atelectasis.
<span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.3.1.1.3" style="color:#00FFFF;"> No focal consolidation, pleural effusion or pneumothorax is present.</span> <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.3.1.1.4" style="color:#FF8000;">There are no acute osseous abnormalities.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S5.T3.2.2.2.4">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.2.4.1">
<span class="ltx_p" id="S5.T3.2.2.2.4.1.1" style="width:170.7pt;"><span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.4.1.1.1" style="color:#00FFFF;">Moderate enlargement of the cardiac silhouette </span>with a left ventricular predominance is unchanged. <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.4.1.1.2" style="color:#00FFFF;">The aorta remains tortuous</span>, and the hilar contours are stable. <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.4.1.1.3" style="color:#FF8000;">Pulmonary vascularity is not engorged.</span> There is minimal atelectasis within the lung bases, but <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.4.1.1.4" style="color:#00FFFF;">no focal consolidation is present. No pleural effusion or pneumothorax is identified<span class="ltx_text ltx_font_upright" id="S5.T3.2.2.2.4.1.1.4.1">.</span></span> <span class="ltx_text ltx_font_italic" id="S5.T3.2.2.2.4.1.1.5" style="color:#FF8000;">There are no acute osseous abnormalities.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2.6.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.2.2.6.3.1">F1RadGraph</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.6.3.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.6.3.2.1">
<span class="ltx_p" id="S5.T3.2.2.6.3.2.1.1" style="width:170.7pt;">0.333</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S5.T3.2.2.6.3.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.6.3.3.1">
<span class="ltx_p" id="S5.T3.2.2.6.3.3.1.1" style="width:170.7pt;">0.526</span>
</span>
</td>
<td class="ltx_td ltx_align_top ltx_border_t" id="S5.T3.2.2.6.3.4"></td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2.7.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.2.2.7.4.1">CheXbert Observations</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.2.2.7.4.2">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.7.4.2.1">
<span class="ltx_p" id="S5.T3.2.2.7.4.2.1.1" style="width:170.7pt;">Cardiomegaly, Atelectasis</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.2.2.7.4.3">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.7.4.3.1">
<span class="ltx_p" id="S5.T3.2.2.7.4.3.1.1" style="width:170.7pt;">Cardiomegaly, Atelectasis</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" id="S5.T3.2.2.7.4.4">
<span class="ltx_inline-block ltx_align_top" id="S5.T3.2.2.7.4.4.1">
<span class="ltx_p" id="S5.T3.2.2.7.4.4.1.1" style="width:170.7pt;">Cardiomegaly, Atelectasis</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>One case study from MIMIC-CXR. <span class="ltx_text" id="S5.T3.6.1" style="color:#00FFFF;">Cyan</span> text indicates radiological consistency with the ground-truth report. <span class="ltx_text" id="S5.T3.7.2" style="color:#FF8000;">Orange</span> text highlights extra accurate details provided by FactMM-RAG compared to Med-MARVEL. <span class="ltx_text" id="S5.T3.8.3" style="color:#FF0000;">Red</span> text denotes observations missing in Med-MARVEL. </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Fact-aware Capability Propagation </h3>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="670" id="S5.F4.sf1.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Multimodal Retrieval</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="670" id="S5.F4.sf2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Multimodal RAG</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Analysis of fact-aware capability propagation evaluated by MRR retrieval metric.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">To further understand the benefits of our retriever for the foundation model, we explore the effective propagation of fact-aware capabilities from the retriever to the foundation model.
To demonstrate this behavior, we use the mined factual report pairs as reference reports for the query report.
We then use the retrieval metric Mean Reciprocal Rank (MRR) as an intermediate evaluation, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.F4" title="Figure 4 ‣ 5.4 Fact-aware Capability Propagation ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">4</span></a>.
From the plot, we observe that as training progresses, the retrieval metric increases alongside two clinical metrics.
This factually-oriented upward trend in our retriever’s performance in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.F4.sf1" title="In Figure 4 ‣ 5.4 Fact-aware Capability Propagation ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">4(a)</span></a> is also reflected in the foundation model’s performance in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.F4.sf2" title="In Figure 4 ‣ 5.4 Fact-aware Capability Propagation ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">4(b)</span></a>.
This indicates that employing a factually-informed reference report selection strategy to train our multimodal retriever can also enhance the foundation model’s ability to generate factually accurate radiology reports.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Case Study</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">In this section, we present two examples from MIMIC-CXR to qualitatively analyze our retriever’s fact-aware capability, as illustrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#S5.T3" title="Table 3 ‣ 5.3 Fact-aware Capability Control ‣ 5 Evaluation Results ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">3</span></a>.
In the first example, we observe that FactMM-RAG provides symptom observations consistent with the ground-truth report and generates more accurate factual details compared to Med-MARVEL, e.g., “post median sternotomy, atelectasis, not pneumothorax”;
In the second example, we further observe that although both retrievers generate reports with diagnostic labels matching the ground-truth report, FactMM-RAG provides additional details compared to Med-MARVEL, such as “pulmonary vasculature is normal, no acute osseous abnormalities”.
These characteristics confirm that adopting our fact-aware retriever can assist multimodal foundation models in generating more accurate radiology reports.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we aim at improving radiology report generation by introducing a fact-informed medical multimodal retriever for retrieval-augmented generation.
In particular, we utilize RadGraph to annotate chest radiograph reports and mine clinically-relevant pairs.
We integrate factual information into a universal multimodal retriever, presenting FactMM-RAG, a fact-aware multimodal retrieval-augmented radiology report generation pipeline.
FactMM-RAG outperforms all state-of-the-art retrievers evaluated by factual correctness and textual coherence for final report generation in MIMIC-CXR and CheXpert datasets.
We further confirm the benefit of our multimodal retriever from the analysis of fact-aware capability control and propagation.
Given the pervasive applications of machine learning in clinical diagnoses using chest X-rays, we hope our factual-informed approach inspires further work in multimodal generative artificial intelligence in healthcare contexts.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Despite the strong performance of our FactMM-RAG pipeline, we acknowledge potential limitations of our proposed method.
In particular, our work only emphasizes chest radiology domains.
It also worth exploring our retrieval-augmented factual report generation pipeline in broader medical domains, such as brain scan or histology datasets.
<br class="ltx_break"/>
<br class="ltx_break"/>Another concern lies in the chosen evaluation metrics, F1RadGraph and F1CheXbert.
F1CheXbert reflects high-level observational accuracy, while F1RadGraph assesses the correctness of radiology entities and clinical relationships. However, other radiologically-specific metrics, such as report conciseness and clarity, should also be considered <cite class="ltx_cite ltx_citemacro_citep">(Sureka et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib39" title="">2014</a>)</cite>.
Ideally, we should incorporate methods of evaluation directly aligned with human evaluations or involve domain expertise itself in our pair-mining and final evaluation procedure.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad et al. (2023)</span>
<span class="ltx_bibblock">
Muhammad Aurangzeb Ahmad, Ilker Yaramis, and Taposh Dutta Roy. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2311.01463" title="">Creating trustworthy llms: Dealing with hallucinations in healthcare ai</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Preprint</em>, arXiv:2311.01463.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud et al. (2022)</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2112.04426" title="">Improving language models by retrieving from trillions of tokens</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Preprint</em>, arXiv:2112.04426.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chambon et al. (2022)</span>
<span class="ltx_bibblock">
Pierre Chambon, Christian Bluethgen, Jean-Benoit Delbrouck, Rogier Van der Sluijs, Małgorzata Połacin, Juan Manuel Zambrano Chaves, Tanishq Mathew Abraham, Shivanshu Purohit, Curtis P. Langlotz, and Akshay Chaudhari. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2211.12737" title="">Roentgen: Vision-language foundation model for chest x-ray generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arXiv:2211.12737.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hexiang Hu, Xi Chen, Pat Verga, and William W. Cohen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2210.02928" title="">Murag: Multimodal retrieval-augmented generator for open question answering over images and text</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Preprint</em>, arXiv:2210.02928.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Zhihong Chen, Yaling Shen, Yan Song, and Xiang Wan. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.459" title="">Cross-modal memory networks for radiology report generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 5904–5914, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Zhihong Chen, Maya Varma, Jean-Benoit Delbrouck, Magdalini Paschali, Louis Blankemeier, Dave Van Veen, Jeya Maria Jose Valanarasu, Alaa Youssef, Joseph Paul Cohen, Eduardo Pontes Reis, Emily B. Tsai, Andrew Johnston, Cameron Olsen, Tanishq Mathew Abraham, Sergios Gatidis, Akshay S. Chaudhari, and Curtis Langlotz. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2401.12208" title="">Chexagent: Towards a foundation model for chest x-ray interpretation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Preprint</em>, arXiv:2401.12208.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Delbrouck et al. (2022)</span>
<span class="ltx_bibblock">
Jean-Benoit Delbrouck, Pierre Chambon, Christian Bluethgen, Emily Tsai, Omar Almusa, and Curtis Langlotz. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-emnlp.319" title="">Improving the Factual Correctness of Radiology Report Generation with Semantic Rewards</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 4348–4360, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Delbrouck et al. (2023)</span>
<span class="ltx_bibblock">
Jean-Benoit Delbrouck, Maya Varma, Pierre Chambon, and Curtis Langlotz. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.bionlp-1.45" title="">Overview of the RadSum23 Shared Task on Multi-modal and Multi-anatomical Radiology Report Summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks</em>, pages 478–482, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al. (2021)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2010.11929" title="">An image is worth 16x16 words: Transformers for image recognition at scale</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Preprint</em>, arXiv:2010.11929.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Endo et al. (2021)</span>
<span class="ltx_bibblock">
Mark Endo, Rayan Krishnan, Viswesh Krishna, Andrew Y. Ng, and Pranav Rajpurkar. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v158/endo21a.html" title="">Retrieval-based chest x-ray report generation using a pre-trained contrastive language-image model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of Machine Learning for Health</em>, volume 158 of <em class="ltx_emph ltx_font_italic" id="bib.bib10.2.2">Proceedings of Machine Learning Research</em>, pages 209–219. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2024)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2312.10997" title="">Retrieval-augmented generation for large language models: A survey</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint</em>, arXiv:2312.10997.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2002.08909" title="">Realm: Retrieval-augmented language model pre-training</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Preprint</em>, arXiv:2002.08909.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2023)</span>
<span class="ltx_bibblock">
Ziniu Hu, Ahmet Iscen, Chen Sun, Zirui Wang, Kai-Wei Chang, Yizhou Sun, Cordelia Schmid, David A. Ross, and Alireza Fathi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2212.05221" title="">Reveal: Retrieval-augmented visual-language pre-training with multi-source multimodal knowledge memory</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Preprint</em>, arXiv:2212.05221.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2021)</span>
<span class="ltx_bibblock">
Shih-Cheng Huang, Liyue Shen, Matthew P Lungren, and Serena Yeung. 2021.

</span>
<span class="ltx_bibblock">GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-Efficient Medical Image Recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pages 3942–3951.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Irvin et al. (2019)</span>
<span class="ltx_bibblock">
Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A. Mong, Safwan S. Halabi, Jesse K. Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz, Bhavik N. Patel, Matthew P. Lungren, and Andrew Y. Ng. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1901.07031" title="">CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Preprint</em>, arXiv:1901.07031.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyeke et al. (2022)</span>
<span class="ltx_bibblock">
Lucky Iyeke, Rebecca Moss, Rachel Hall, Jun Wang, Lovleen Sandhu, Benjamin Appold, Ella Kalontar, Dimitra Menoudakos, Mahesh Ramnarine, Samuel P. LaVine, Seungwoo Ahn, and Michelle Richman. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.7759/cureus.29817" title="">Reducing unnecessary ’admission’ chest x-rays: An initiative to minimize low-value care</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Cureus</em>, 14(10):e29817.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2208.03299" title="">Atlas: Few-shot learning with retrieval augmented language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Preprint</em>, arXiv:2208.03299.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. (2021)</span>
<span class="ltx_bibblock">
Saahil Jain, Ashwin Agrawal, Adriel Saporta, Steven QH Truong, Du Nguyen Duong, Tan Bui, Pierre Chambon, Yuhao Zhang, Matthew P. Lungren, Andrew Y. Ng, Curtis P. Langlotz, and Pranav Rajpurkar. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2106.14463" title="">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Preprint</em>, arXiv:2106.14463.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. (2019)</span>
<span class="ltx_bibblock">
Alistair E. W. Johnson, Tom J. Pollard, Seth J. Berkowitz, Nathaniel R. Greenbaum, Matthew P. Lungren, Chih-ying Deng, Roger G. Mark, and Steven Horng. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1038/s41597-019-0322-0" title="">MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Scientific Data</em>, 6(1).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen tau Yih. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2004.04906" title="">Dense passage retrieval for open-domain question answering</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Preprint</em>, arXiv:2004.04906.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2021)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2005.11401" title="">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arXiv:2005.11401.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2018)</span>
<span class="ltx_bibblock">
Christy Y. Li, Xiaodan Liang, Zhiting Hu, and Eric P. Xing. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1805.08298" title="">Hybrid retrieval-generation reinforced agent for medical image report generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Preprint</em>, arXiv:1805.08298.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Llava-med: Training a large language-and-vision assistant for biomedicine in one day.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2306.00890</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:964287" title="">Rouge: A package for automatic evaluation of summaries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2304.08485" title="">Visual Instruction Tuning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2304.08485.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Kang Liu, Zhuoqi Ma, Mengmeng Liu, Zhicheng Jiao, Xiaolu Kang, Qiguang Miao, and Kun Xie. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2405.09586" title="">Factual serialization enhancement: A key innovation for chest x-ray report generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Preprint</em>, arXiv:2405.09586.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1711.05101" title="">Decoupled weight decay regularization</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Preprint</em>, arXiv:1711.05101.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miura et al. (2021)</span>
<span class="ltx_bibblock">
Yasuhide Miura, Yuhao Zhang, Emily Bao Tsai, Curtis P. Langlotz, and Dan Jurafsky. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2010.10042" title="">Improving factual completeness and consistency of image-to-text radiology report generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Preprint</em>, arXiv:2010.10042.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moor et al. (2023)</span>
<span class="ltx_bibblock">
Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, Yash Dalmia, Jure Leskovec, Cyril Zakka, Eduardo Pontes Reis, and Pranav Rajpurkar. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v225/moor23a.html" title="">Med-flamingo: a multimodal medical few-shot learner</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 3rd Machine Learning for Health Symposium</em>, volume 225 of <em class="ltx_emph ltx_font_italic" id="bib.bib29.2.2">Proceedings of Machine Learning Research</em>, pages 353–367. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal and Sankarasubbu (2024)</span>
<span class="ltx_bibblock">
Ankit Pal and Malaikannan Sankarasubbu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.07023" title="">Gemini goes to med school: Exploring the capabilities of multimodal large language models on medical challenge problems &amp; hallucinations</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Preprint</em>, arXiv:2402.07023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal et al. (2023)</span>
<span class="ltx_bibblock">
Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.15343" title="">Med-halt: Medical domain hallucination test for large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Preprint</em>, arXiv:2307.15343.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2103.00020" title="">Learning Transferable Visual Models From Natural Language Supervision</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Preprint</em>, arXiv:2103.00020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2023)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1910.10683" title="">Exploring the limits of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Preprint</em>, arXiv:1910.10683.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2022)</span>
<span class="ltx_bibblock">
Vignav Ramesh, Nathan Andrew Chi, and Pranav Rajpurkar. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2210.06340" title="">Improving radiology report generation systems by removing hallucinated references to non-existent priors</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Preprint</em>, arXiv:2210.06340.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen tau Yih. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2301.12652" title="">Replug: Retrieval-augmented black-box language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Preprint</em>, arXiv:2301.12652.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smit et al. (2020)</span>
<span class="ltx_bibblock">
Akshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj Pareek, Andrew Y. Ng, and Matthew P. Lungren. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2004.09167" title="">Chexbert: Combining automatic labelers and expert annotations for accurate radiology report labeling using bert</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Preprint</em>, arXiv:2004.09167.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Speets et al. (2006)</span>
<span class="ltx_bibblock">
Annemiek M. Speets, Yolanda van der Graaf, Arno W. Hoes, Sjouke Kalmijn, Arnold P. Sachs, Matthijs J. Rutten, Jan W. Gratama, Annemiek D. Montauban van Swijndregt, and Willem P. Mali. 2006.

</span>
<span class="ltx_bibblock">Chest radiography in general practice: Indications, diagnostic yield, and consequences for patient management.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">The British Journal of General Practice: The Journal of the Royal College of General Practitioners</em>, 56(529):574–578.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2024)</span>
<span class="ltx_bibblock">
Liwen Sun, Abhineet Agarwal, Aaron Kornblith, Bin Yu, and Chenyan Xiong. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.13448" title="">Ed-copilot: Reduce emergency department wait time with language model diagnostic assistance</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Preprint</em>, arXiv:2402.13448.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sureka et al. (2014)</span>
<span class="ltx_bibblock">
Binit Sureka et al. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://link.gale.com/apps/doc/A416342585/AONE?u=anon~8d1a1cee&amp;sid=googleScholar&amp;xid=2b3f1ebd" title="">Seven c’s of effective radiology reporting</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">The Journal of National Accreditation Board for Hospitals &amp; Healthcare Providers</em>, 1(1):17.

</span>
<span class="ltx_bibblock">Accessed 14 June 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thawkar et al. (2023)</span>
<span class="ltx_bibblock">
Omkar Thawkar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Jorma Laaksonen, and Fahad Shahbaz Khan. 2023.

</span>
<span class="ltx_bibblock">Xraygpt: Chest radiographs summarization using large medical vision-language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv: 2306.07971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al. (2023)</span>
<span class="ltx_bibblock">
Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed Amin, Pi-Chuan Chang, Andrew Carroll, Chuck Lau, Ryutaro Tanno, Ira Ktena, Basil Mustafa, Aakanksha Chowdhery, Yun Liu, Simon Kornblith, David Fleet, Philip Mansfield, Sushant Prakash, Renee Wong, Sunny Virmani, Christopher Semturs, S Sara Mahdavi, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Joelle Barral, Dale Webster, Greg S. Corrado, Yossi Matias, Karan Singhal, Pete Florence, Alan Karthikesalingam, and Vivek Natarajan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.14334" title="">Towards generalist biomedical ai</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Preprint</em>, arXiv:2307.14334.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Zifeng Wang, Zhenbang Wu, Dinesh Agarwal, and Jimeng Sun. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2210.10163" title="">Medclip: Contrastive learning from unpaired medical images and text</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Preprint</em>, arXiv:2210.10163.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.02463" title="">Towards generalist foundation model for radiology by leveraging web-scale 2d&amp;3d medical data</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Preprint</em>, arXiv:2308.02463.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2023)</span>
<span class="ltx_bibblock">
Qianqian Xie, Jiayu Zhou, Yifan Peng, and Fei Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.08335" title="">Factreranker: Fact-guided reranker for faithful radiology report summarization</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Preprint</em>, arXiv:2303.08335.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yasunaga et al. (2023)</span>
<span class="ltx_bibblock">
Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, and Wen tau Yih. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2211.12561" title="">Retrieval-augmented multimodal language modeling</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Preprint</em>, arXiv:2211.12561.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">You et al. (2023)</span>
<span class="ltx_bibblock">
Kihyun You, Jawook Gu, Jiyeon Ham, Beomhee Park, Jiho Kim, Eun K. Hong, Woonhyuk Baek, and Byungseok Roh. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1007/978-3-031-43895-0_10" title="">Cxr-clip: Toward large scale chest x-ray language-image pre-training</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Medical Image Computing and Computer Assisted Intervention – MICCAI 2023</em>, pages 101–111. Springer Nature Switzerland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023a)</span>
<span class="ltx_bibblock">
Shi Yu, Zhenghao Liu, Chenyan Xiong, and Zhiyuan Liu. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3539618.3591813" title="">Openmatch-v2: An all-in-one multi-modality plm-based information retrieval toolkit</a>.

</span>
<span class="ltx_bibblock">pages 3160–3164.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023b)</span>
<span class="ltx_bibblock">
Zichun Yu, Chenyan Xiong, Shi Yu, and Zhiyuan Liu. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.17331" title="">Augmentation-adapted retriever improves generalization of language models as generic plug-in</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Preprint</em>, arXiv:2305.17331.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Sheng Zhang, Yanbo Xu, Naoto Usuyama, Hanwen Xu, Jaspreet Bagga, Robert Tinn, Sam Preston, Rajesh Rao, Mu Wei, Naveen Valluri, Cliff Wong, Andrea Tupini, Yu Wang, Matt Mazzola, Swadheen Shukla, Lars Liden, Jianfeng Gao, Matthew P. Lungren, Tristan Naumann, Sheng Wang, and Hoifung Poon. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.00915" title="">Biomedclip: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Preprint</em>, arXiv:2303.00915.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020a)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1904.09675" title="">Bertscore: Evaluating text generation with bert</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Preprint</em>, arXiv:1904.09675.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher D. Manning, and Curtis P. Langlotz. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2010.00747" title="">Contrastive Learning of Medical Visual Representations from Paired Images and Text</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Preprint</em>, arXiv:2010.00747.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020b)</span>
<span class="ltx_bibblock">
Yuhao Zhang, Derek Merck, Emily Bao Tsai, Christopher D. Manning, and Curtis P. Langlotz. 2020b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1911.02541" title="">Optimizing the factual correctness of a summary: A study of summarizing radiology reports</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Preprint</em>, arXiv:1911.02541.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Tianshuo Zhou, Sen Mei, Xinze Li, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu, Yu Gu, and Ge Yu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.14037" title="">MARVEL: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Preprint</em>, arXiv:2310.14037.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Çallı et al. (2021)</span>
<span class="ltx_bibblock">
Erdi Çallı, Ecem Sogancioglu, Bram van Ginneken, Kicky G. van Leeuwen, and Keelin Murphy. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1016/j.media.2021.102125" title="">Deep learning for chest x-ray analysis: A survey</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Medical Image Analysis</em>, 72:102125.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Retriever Training Procedure</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">To training our fact-aware multimodal retriever, we not only use mined factual report pairs as positive reports to the query image, but also incorporate the query image’s corresponding report.
Following <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib47" title="">2023a</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib53" title="">2024</a>)</cite>, we also adopt modality-balanced hard negatives to train the retriever after in-batch negative training from the multimodal dense retrieval stage.
We use AdamW <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib27" title="">2019</a>)</cite> as our optimizer and training epochs = 15, early stopping epoch = 5, batch size = 32, learning rate = 5e-6, and the temperature hyperparameter <math alttext="\tau" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mi id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><ci id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">italic_τ</annotation></semantics></math> = 0.01. For our MARVEL backbone, we use T5-ANCE <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib47" title="">2023a</a>)</cite> as the text encoder and vision transformer <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#bib.bib9" title="">2021</a>)</cite> as the vision encoder. Models are trained using 1 NVIDIA RTX A6000 for 10 hours.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>RAG Finetuning Procedure</h3>
<figure class="ltx_figure" id="A1.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A1.F5.1"><span class="ltx_text ltx_font_bold" id="A1.F5.1.1">Visual Question Answering</span>:</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg class="ltx_picture ltx_figure_panel" height="39.86" id="A1.F5.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,39.86) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 33.95 C 0 37.21 2.64 39.86 5.91 39.86 L 594.09 39.86 C 597.36 39.86 600 37.21 600 33.95 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 33.95 C 1.97 36.13 3.73 37.89 5.91 37.89 L 594.09 37.89 C 596.27 37.89 598.03 36.13 598.03 33.95 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F5.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.F5.pic1.1.1.1.1.1.1">Generate a radiology report from this image: <span class="ltx_text ltx_font_typewriter" id="A1.F5.pic1.1.1.1.1.1.1.1">&lt;image&gt;</span></span>
</span></foreignobject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel" id="A1.F5.2"><span class="ltx_text ltx_font_bold" id="A1.F5.2.1">Retrieval Augmented Generation</span>:</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg class="ltx_picture ltx_figure_panel" height="56.46" id="A1.F5.pic2" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,56.46) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 50.56 C 0 53.82 2.64 56.46 5.91 56.46 L 594.09 56.46 C 597.36 56.46 600 53.82 600 50.56 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 50.56 C 1.97 52.73 3.73 54.49 5.91 54.49 L 594.09 54.49 C 596.27 54.49 598.03 52.73 598.03 50.56 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F5.pic2.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="A1.F5.pic2.1.1.1.1.1.1">Here is a report of a related patient: "<span class="ltx_text ltx_font_typewriter" id="A1.F5.pic2.1.1.1.1.1.1.1">&lt;document&gt;</span>"</span>
<span class="ltx_p" id="A1.F5.pic2.1.1.1.1.1.2">Generate a radiology report from this image: <span class="ltx_text ltx_font_typewriter" id="A1.F5.pic2.1.1.1.1.1.2.1">&lt;image&gt;</span></span>
</span></foreignobject></g></g></svg></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Prompt templates for Visual Question Answering and Retrieval Augmented Generation</figcaption>
</figure>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.2">To create a RAG dataset for fine-tuning LLaVA, we search the nearest-neighbor document <math alttext="d_{txt}^{*}" class="ltx_Math" display="inline" id="A1.SS2.p1.1.m1.1"><semantics id="A1.SS2.p1.1.m1.1a"><msubsup id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml"><mi id="A1.SS2.p1.1.m1.1.1.2.2" xref="A1.SS2.p1.1.m1.1.1.2.2.cmml">d</mi><mrow id="A1.SS2.p1.1.m1.1.1.2.3" xref="A1.SS2.p1.1.m1.1.1.2.3.cmml"><mi id="A1.SS2.p1.1.m1.1.1.2.3.2" xref="A1.SS2.p1.1.m1.1.1.2.3.2.cmml">t</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.3" xref="A1.SS2.p1.1.m1.1.1.2.3.3.cmml">x</mi><mo id="A1.SS2.p1.1.m1.1.1.2.3.1a" xref="A1.SS2.p1.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="A1.SS2.p1.1.m1.1.1.2.3.4" xref="A1.SS2.p1.1.m1.1.1.2.3.4.cmml">t</mi></mrow><mo id="A1.SS2.p1.1.m1.1.1.3" xref="A1.SS2.p1.1.m1.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><apply id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1">superscript</csymbol><apply id="A1.SS2.p1.1.m1.1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.1.1.2.1.cmml" xref="A1.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS2.p1.1.m1.1.1.2.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2.2">𝑑</ci><apply id="A1.SS2.p1.1.m1.1.1.2.3.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3"><times id="A1.SS2.p1.1.m1.1.1.2.3.1.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.1"></times><ci id="A1.SS2.p1.1.m1.1.1.2.3.2.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.2">𝑡</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.3.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.3">𝑥</ci><ci id="A1.SS2.p1.1.m1.1.1.2.3.4.cmml" xref="A1.SS2.p1.1.m1.1.1.2.3.4">𝑡</ci></apply></apply><times id="A1.SS2.p1.1.m1.1.1.3.cmml" xref="A1.SS2.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">d_{txt}^{*}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.m1.1d">italic_d start_POSTSUBSCRIPT italic_t italic_x italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math> for a query image <math alttext="q_{img}" class="ltx_Math" display="inline" id="A1.SS2.p1.2.m2.1"><semantics id="A1.SS2.p1.2.m2.1a"><msub id="A1.SS2.p1.2.m2.1.1" xref="A1.SS2.p1.2.m2.1.1.cmml"><mi id="A1.SS2.p1.2.m2.1.1.2" xref="A1.SS2.p1.2.m2.1.1.2.cmml">q</mi><mrow id="A1.SS2.p1.2.m2.1.1.3" xref="A1.SS2.p1.2.m2.1.1.3.cmml"><mi id="A1.SS2.p1.2.m2.1.1.3.2" xref="A1.SS2.p1.2.m2.1.1.3.2.cmml">i</mi><mo id="A1.SS2.p1.2.m2.1.1.3.1" xref="A1.SS2.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.p1.2.m2.1.1.3.3" xref="A1.SS2.p1.2.m2.1.1.3.3.cmml">m</mi><mo id="A1.SS2.p1.2.m2.1.1.3.1a" xref="A1.SS2.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.p1.2.m2.1.1.3.4" xref="A1.SS2.p1.2.m2.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m2.1b"><apply id="A1.SS2.p1.2.m2.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.2.m2.1.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="A1.SS2.p1.2.m2.1.1.2.cmml" xref="A1.SS2.p1.2.m2.1.1.2">𝑞</ci><apply id="A1.SS2.p1.2.m2.1.1.3.cmml" xref="A1.SS2.p1.2.m2.1.1.3"><times id="A1.SS2.p1.2.m2.1.1.3.1.cmml" xref="A1.SS2.p1.2.m2.1.1.3.1"></times><ci id="A1.SS2.p1.2.m2.1.1.3.2.cmml" xref="A1.SS2.p1.2.m2.1.1.3.2">𝑖</ci><ci id="A1.SS2.p1.2.m2.1.1.3.3.cmml" xref="A1.SS2.p1.2.m2.1.1.3.3">𝑚</ci><ci id="A1.SS2.p1.2.m2.1.1.3.4.cmml" xref="A1.SS2.p1.2.m2.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m2.1c">q_{img}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.2.m2.1d">italic_q start_POSTSUBSCRIPT italic_i italic_m italic_g end_POSTSUBSCRIPT</annotation></semantics></math> using a retriever’s embeddings.
We filter out any results that involve retrieving a patient’s own report, the same patient’s other studies, or malformed reports in the training dataset (specified by being less than 5 characters).
We apply the prompt templates in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.15268v1#A1.F5" title="Figure 5 ‣ A.2 RAG Finetuning Procedure ‣ Appendix A Appendix ‣ Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation"><span class="ltx_text ltx_ref_tag">5</span></a>, and fine-tune LLaVA-1.5 for one epoch. Models are trained using 8x NVIDIA RTX A6000 for 4 hours, with epochs=1, learning rate=2e-5, global batch size=128, from vicuna-7b-v1.5 checkpoint.
We save the checkpoint after one full pass of the training dataset for final evaluation.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Jul 21 20:57:27 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
