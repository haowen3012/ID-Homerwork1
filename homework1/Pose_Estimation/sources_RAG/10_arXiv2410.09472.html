<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac.</title>
<!--Generated on Sat Oct 12 10:12:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Zero-shot AAC,  CLAP,  LLM,  RAG
" lang="en" name="keywords"/>
<base href="/html/2410.09472v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S1" title="In DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2" title="In DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Methods</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS1" title="In II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Overview</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS2" title="In II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Retrieval-augmented Generation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS3" title="In II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">Projection-based Decoding </span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS4" title="In II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-D</span> </span><span class="ltx_text ltx_font_italic">Domain Adaptation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3" title="In DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Experimental Settings</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3.SS1" title="In III Experimental Settings â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3.SS2" title="In III Experimental Settings â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Experimental Setup</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3.SS3" title="In III Experimental Settings â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Implementation Details</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4" title="In DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.SS1" title="In IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Main Results</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.SS2" title="In IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Ablation Study</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S5" title="In DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusion and future work</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_inline-block ltx_minipage ltx_align_top" id="id13.id1" style="width:433.6pt;">
<span class="ltx_p" id="id13.id1.1">DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning</span>
</span>
<span class="ltx_note ltx_role_thanks" id="id1.1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span><sup class="ltx_sup" id="id1.1.1"><span class="ltx_text ltx_font_italic" id="id1.1.1.1">â€ </span></sup>Qiuqiang Kong and Xie Chen are the corresponding authors.</span></span></span>
<span class="ltx_note ltx_role_thanks" id="id2.2"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span><sup class="ltx_sup" id="id2.2.1">âˆ—</sup>Codes and models will be available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac" style="font-size:70%;" title="">https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac</a><span class="ltx_text ltx_font_typewriter" id="id2.2.2" style="font-size:70%;">. </span></span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">

Xiquan Li<sup class="ltx_sup" id="id14.11.id1">1</sup>,
Wenxi Chen<sup class="ltx_sup" id="id15.12.id2">1</sup>,
Ziyang Ma<sup class="ltx_sup" id="id16.13.id3">1</sup>,
Xuenan Xu<sup class="ltx_sup" id="id17.14.id4">1</sup>,
Yuzhe Liang<sup class="ltx_sup" id="id18.15.id5">1</sup>,
Zhisheng Zheng<sup class="ltx_sup" id="id19.16.id6">1</sup>, 
<br class="ltx_break"/>Qiuqiang Kong<sup class="ltx_sup" id="id20.17.id7"><span class="ltx_text ltx_font_italic" id="id20.17.id7.1">2â€ </span></sup>,
Xie Chen<sup class="ltx_sup" id="id21.18.id8"><span class="ltx_text ltx_font_italic" id="id21.18.id8.1">1â€ </span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><sup class="ltx_sup" id="id22.19.id1">1</sup><span class="ltx_text ltx_font_italic" id="id23.20.id2">MoE Key Lab of Artificial Intelligence, X-LANCE Lab, Shanghai Jiao Tong University, China</span>
</span>
<span class="ltx_contact ltx_role_affiliation"><sup class="ltx_sup" id="id24.21.id1">2</sup><span class="ltx_text ltx_font_italic" id="id25.22.id2">Department of Electronics Engineering, The Chinese University of Hong Kong, China</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id26.id1">While automated audio captioning (AAC) has made notable progress, traditional fully supervised AAC models still face two critical challenges: the need for expensive audio-text pair data for training and performance degradation when transferring across domains.
To overcome these limitations, we present DRCap, a data-efficient and flexible zero-shot audio captioning system that requires text-only data for training and can quickly adapt to new domains without additional fine-tuning.
DRCap integrates a contrastive language-audio pre-training (CLAP) model and a large-language model (LLM) as its backbone.
During training, the model predicts the ground-truth caption with a fixed text encoder from CLAP, whereas, during inference, the text encoder is replaced with the audio encoder to generate captions for audio clips in a zero-shot manner.
To mitigate the modality gap of the CLAP model, we use both the projection strategy from the encoder side and the retrieval-augmented generation strategy from the decoder side.
Specifically, audio embeddings are first projected onto a text embedding support to absorb extensive semantic information within the joint multi-modal space of CLAP.
At the same time, similar captions retrieved from a datastore are fed as prompts to instruct the LLM, incorporating external knowledge to take full advantage of its strong generative capability.
Conditioned on both the projected CLAP embedding and the retrieved similar captions, the model is able to produce a more accurate and semantically rich textual description.
By tailoring the text embedding support and the caption datastore to the target domain, DRCap acquires a robust ability to adapt to new domains in a training-free manner.
Experimental results demonstrate that DRCap outperforms all other zero-shot models in in-domain scenarios and achieves state-of-the-art performance in cross-domain scenarios.
</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Zero-shot AAC, CLAP, LLM, RAG

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Automated audio captioning (AAC) is a cross-modal translation task that seeks to generate natural language descriptions for given audio clips <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib1" title="">1</a>]</cite>. This process involves detailing the audio in terms of events, acoustic scenes, temporal relationships, actions, object interactions, and environmental context <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib2" title="">2</a>]</cite>.
Conventional AAC models often employ an encoder-decoder architecture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib3" title="">3</a>]</cite>, where an audio encoder extracts fine-grained audio features and a text decoder generates captions auto-regressively conditioned on these audio representations. The audio encoders used in previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib8" title="">8</a>]</cite> are often pre-trained on tasks such as audio tagging or sound event detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib11" title="">11</a>]</cite>, while the text decoders are pre-trained large language models (LLMs) with extensive encyclopedic knowledge, such as BART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib12" title="">12</a>]</cite> or GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib13" title="">13</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite the significant strides made in AAC, most fully supervised models still rely on extensively human-annotated datasets for training. However, data scarcity remains a critical issue for AAC, as annotating audio data demands careful attention and complex analysis for accuracy. Moreover, given the diversity in audio concepts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib6" title="">6</a>]</cite> and annotation styles across different datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib14" title="">14</a>]</cite>, existing fully supervised models often lack the flexibility to generalize to new domains, leading to diminished performance in cross-domain evaluations, where training and test data come from two distinct datasets.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To overcome these challenges, researchers proposed zero-shot audio captioning framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib19" title="">19</a>]</cite>, which seeks to generate captions without training on costly audio-text pair data. These works typically leverage the multi-modal capabilities of the CLAP model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib22" title="">22</a>]</cite>.
To bridge the modality gap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib23" title="">23</a>]</cite> of CLAP, Deshmukh <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib15" title="">15</a>]</cite> and Kouzelis <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib17" title="">17</a>]</cite> injected Gaussian noise into CLAP latents, while Zhang <span class="ltx_text ltx_font_italic" id="S1.p3.1.3">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>]</cite> crafted soft and hard prompts. However, adding noise can diminish the rich semantic information within the CLAP multi-modal space, while the fixed-category hard prompt in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>]</cite> risks misleading the decoder.
Moreover, text decoders in previous works struggle to decode CLAP latents into accurate descriptions containing multiple sound events.
A stronger LLM is required to fully leverage this joint multi-modal space.
As a result, although existing zero-shot audio captioning models demonstrate strong performance in cross-domain scenarios, they still lag significantly behind fully supervised models in in-domain scenarios.</p>
</div>
<figure class="ltx_figure ltx_minipage ltx_align_bottom" id="S1.F1.11" style="width:433.6pt;">
<p class="ltx_p ltx_align_center ltx_align_center" id="S1.F1.1.1"><span class="ltx_text" id="S1.F1.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S1.F1.1.1.1.g1" src="x1.png" width="926"/></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Left: Overview of the CLAP model. Right: Overview of the proposed DRCap. Based on the aligned multi-modal space of CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib20" title="">20</a>]</cite>, during training, DRCap learns to decode the text embedding to reconstruct the caption. Only the linear mapping network <math alttext="m" class="ltx_Math" display="inline" id="S1.F1.7.7.m1.1"><semantics id="S1.F1.7.7.m1.1b"><mi id="S1.F1.7.7.m1.1.1" xref="S1.F1.7.7.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S1.F1.7.7.m1.1c"><ci id="S1.F1.7.7.m1.1.1.cmml" xref="S1.F1.7.7.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.7.7.m1.1d">m</annotation><annotation encoding="application/x-llamapun" id="S1.F1.7.7.m1.1e">italic_m</annotation></semantics></math> is trained, while the LLM is fine-tuned using the LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib24" title="">24</a>]</cite> method. During inference, the audio embedding is first projected onto a text embedding support <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S1.F1.8.8.m2.1"><semantics id="S1.F1.8.8.m2.1b"><mi class="ltx_font_mathcaligraphic" id="S1.F1.8.8.m2.1.1" xref="S1.F1.8.8.m2.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S1.F1.8.8.m2.1c"><ci id="S1.F1.8.8.m2.1.1.cmml" xref="S1.F1.8.8.m2.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.8.8.m2.1d">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.8.8.m2.1e">caligraphic_S</annotation></semantics></math>, mitigating the modality gap. Similar captions retrieved from the datastore <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S1.F1.9.9.m3.1"><semantics id="S1.F1.9.9.m3.1b"><mrow id="S1.F1.9.9.m3.1.1" xref="S1.F1.9.9.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F1.9.9.m3.1.1.2" xref="S1.F1.9.9.m3.1.1.2.cmml">ğ’Ÿ</mi><mo id="S1.F1.9.9.m3.1.1.1" xref="S1.F1.9.9.m3.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S1.F1.9.9.m3.1.1.3" xref="S1.F1.9.9.m3.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.9.9.m3.1c"><apply id="S1.F1.9.9.m3.1.1.cmml" xref="S1.F1.9.9.m3.1.1"><times id="S1.F1.9.9.m3.1.1.1.cmml" xref="S1.F1.9.9.m3.1.1.1"></times><ci id="S1.F1.9.9.m3.1.1.2.cmml" xref="S1.F1.9.9.m3.1.1.2">ğ’Ÿ</ci><ci id="S1.F1.9.9.m3.1.1.3.cmml" xref="S1.F1.9.9.m3.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.9.9.m3.1d">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.9.9.m3.1e">caligraphic_D caligraphic_S</annotation></semantics></math> are used as prompts to instruct the LLM, producing accurate and semantically rich descriptions. Both the text embedding support <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S1.F1.10.10.m4.1"><semantics id="S1.F1.10.10.m4.1b"><mi class="ltx_font_mathcaligraphic" id="S1.F1.10.10.m4.1.1" xref="S1.F1.10.10.m4.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S1.F1.10.10.m4.1c"><ci id="S1.F1.10.10.m4.1.1.cmml" xref="S1.F1.10.10.m4.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.10.10.m4.1d">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.10.10.m4.1e">caligraphic_S</annotation></semantics></math> and the datastore <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S1.F1.11.11.m5.1"><semantics id="S1.F1.11.11.m5.1b"><mrow id="S1.F1.11.11.m5.1.1" xref="S1.F1.11.11.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.F1.11.11.m5.1.1.2" xref="S1.F1.11.11.m5.1.1.2.cmml">ğ’Ÿ</mi><mo id="S1.F1.11.11.m5.1.1.1" xref="S1.F1.11.11.m5.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S1.F1.11.11.m5.1.1.3" xref="S1.F1.11.11.m5.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.11.11.m5.1c"><apply id="S1.F1.11.11.m5.1.1.cmml" xref="S1.F1.11.11.m5.1.1"><times id="S1.F1.11.11.m5.1.1.1.cmml" xref="S1.F1.11.11.m5.1.1.1"></times><ci id="S1.F1.11.11.m5.1.1.2.cmml" xref="S1.F1.11.11.m5.1.1.2">ğ’Ÿ</ci><ci id="S1.F1.11.11.m5.1.1.3.cmml" xref="S1.F1.11.11.m5.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.11.11.m5.1d">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.11.11.m5.1e">caligraphic_D caligraphic_S</annotation></semantics></math> could be changed in the inference stage, offering DRCap the flexibility to adapt to new domains.
</figcaption>
</figure>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we propose DRCap, a data-efficient and transferable audio captioning system that leverages the synergy between CLAP and LLM.
Based on the aligned multi-modal space of CLAP, DRCap requires only textual data for training, where a Vicuna-7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib25" title="">25</a>]</cite> is fine-tuned with LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib24" title="">24</a>]</cite> to reconstruct the original caption from the CLAP text embedding.
During inference, the text encoder is replaced by the audio encoder.
To mitigate the modality gap and enhance the semantic richness of the generated caption, we use both the projection strategy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib26" title="">26</a>]</cite> from the encoder side and the retrieval-augmented generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib27" title="">27</a>]</cite> strategy from the decoder side.
Specifically, audio embeddings are first projected onto a text embedding support, incorporating textual information while retaining their original acoustic features. At the same time, semantically similar captions retrieved from an external datastore are fed as prompts to direct the LLM, harnessing its strong generative abilities to create more accurate descriptions.
Moreover, both the text embedding support and the caption datastore can be customized to match the target domain, providing our model with robust adaptability to new domains.
Experimental results demonstrate that DRCap performs comparably to fully supervised methods in in-domain scenarios and achieves state-of-the-art results in cross-domain scenarios.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Methods</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">Overview</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.4">We leverage the joint multi-modal space of CLAP to perform text-only training and then infer on audio clips in a zero-shot manner.
As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S1.F1.11" title="Figure 1 â€£ I Introduction â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">1</span></a> (left), CLAP jointly trains an audio encoder <math alttext="f_{a}(\cdot)" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.2" xref="S2.SS1.p1.1.m1.1.2.cmml"><msub id="S2.SS1.p1.1.m1.1.2.2" xref="S2.SS1.p1.1.m1.1.2.2.cmml"><mi id="S2.SS1.p1.1.m1.1.2.2.2" xref="S2.SS1.p1.1.m1.1.2.2.2.cmml">f</mi><mi id="S2.SS1.p1.1.m1.1.2.2.3" xref="S2.SS1.p1.1.m1.1.2.2.3.cmml">a</mi></msub><mo id="S2.SS1.p1.1.m1.1.2.1" xref="S2.SS1.p1.1.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SS1.p1.1.m1.1.2.3.2" xref="S2.SS1.p1.1.m1.1.2.cmml"><mo id="S2.SS1.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.1.m1.1.2.cmml">(</mo><mo id="S2.SS1.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S2.SS1.p1.1.m1.1.1.cmml">â‹…</mo><mo id="S2.SS1.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.2"><times id="S2.SS1.p1.1.m1.1.2.1.cmml" xref="S2.SS1.p1.1.m1.1.2.1"></times><apply id="S2.SS1.p1.1.m1.1.2.2.cmml" xref="S2.SS1.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.2.2.1.cmml" xref="S2.SS1.p1.1.m1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.2.2.2.cmml" xref="S2.SS1.p1.1.m1.1.2.2.2">ğ‘“</ci><ci id="S2.SS1.p1.1.m1.1.2.2.3.cmml" xref="S2.SS1.p1.1.m1.1.2.2.3">ğ‘</ci></apply><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">f_{a}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( â‹… )</annotation></semantics></math> and a text encoder <math alttext="f_{t}(\cdot)" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mrow id="S2.SS1.p1.2.m2.1.2" xref="S2.SS1.p1.2.m2.1.2.cmml"><msub id="S2.SS1.p1.2.m2.1.2.2" xref="S2.SS1.p1.2.m2.1.2.2.cmml"><mi id="S2.SS1.p1.2.m2.1.2.2.2" xref="S2.SS1.p1.2.m2.1.2.2.2.cmml">f</mi><mi id="S2.SS1.p1.2.m2.1.2.2.3" xref="S2.SS1.p1.2.m2.1.2.2.3.cmml">t</mi></msub><mo id="S2.SS1.p1.2.m2.1.2.1" xref="S2.SS1.p1.2.m2.1.2.1.cmml">â¢</mo><mrow id="S2.SS1.p1.2.m2.1.2.3.2" xref="S2.SS1.p1.2.m2.1.2.cmml"><mo id="S2.SS1.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.2.m2.1.2.cmml">(</mo><mo id="S2.SS1.p1.2.m2.1.1" lspace="0em" rspace="0em" xref="S2.SS1.p1.2.m2.1.1.cmml">â‹…</mo><mo id="S2.SS1.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.2.cmml" xref="S2.SS1.p1.2.m2.1.2"><times id="S2.SS1.p1.2.m2.1.2.1.cmml" xref="S2.SS1.p1.2.m2.1.2.1"></times><apply id="S2.SS1.p1.2.m2.1.2.2.cmml" xref="S2.SS1.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.2.2.1.cmml" xref="S2.SS1.p1.2.m2.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.2.2.2.cmml" xref="S2.SS1.p1.2.m2.1.2.2.2">ğ‘“</ci><ci id="S2.SS1.p1.2.m2.1.2.2.3.cmml" xref="S2.SS1.p1.2.m2.1.2.2.3">ğ‘¡</ci></apply><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">f_{t}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( â‹… )</annotation></semantics></math> to align semantically similar audio-text pairs in a shared embedding space. After training, <math alttext="f_{a}(a)\approx f_{t}(t)" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.2"><semantics id="S2.SS1.p1.3.m3.2a"><mrow id="S2.SS1.p1.3.m3.2.3" xref="S2.SS1.p1.3.m3.2.3.cmml"><mrow id="S2.SS1.p1.3.m3.2.3.2" xref="S2.SS1.p1.3.m3.2.3.2.cmml"><msub id="S2.SS1.p1.3.m3.2.3.2.2" xref="S2.SS1.p1.3.m3.2.3.2.2.cmml"><mi id="S2.SS1.p1.3.m3.2.3.2.2.2" xref="S2.SS1.p1.3.m3.2.3.2.2.2.cmml">f</mi><mi id="S2.SS1.p1.3.m3.2.3.2.2.3" xref="S2.SS1.p1.3.m3.2.3.2.2.3.cmml">a</mi></msub><mo id="S2.SS1.p1.3.m3.2.3.2.1" xref="S2.SS1.p1.3.m3.2.3.2.1.cmml">â¢</mo><mrow id="S2.SS1.p1.3.m3.2.3.2.3.2" xref="S2.SS1.p1.3.m3.2.3.2.cmml"><mo id="S2.SS1.p1.3.m3.2.3.2.3.2.1" stretchy="false" xref="S2.SS1.p1.3.m3.2.3.2.cmml">(</mo><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">a</mi><mo id="S2.SS1.p1.3.m3.2.3.2.3.2.2" stretchy="false" xref="S2.SS1.p1.3.m3.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p1.3.m3.2.3.1" xref="S2.SS1.p1.3.m3.2.3.1.cmml">â‰ˆ</mo><mrow id="S2.SS1.p1.3.m3.2.3.3" xref="S2.SS1.p1.3.m3.2.3.3.cmml"><msub id="S2.SS1.p1.3.m3.2.3.3.2" xref="S2.SS1.p1.3.m3.2.3.3.2.cmml"><mi id="S2.SS1.p1.3.m3.2.3.3.2.2" xref="S2.SS1.p1.3.m3.2.3.3.2.2.cmml">f</mi><mi id="S2.SS1.p1.3.m3.2.3.3.2.3" xref="S2.SS1.p1.3.m3.2.3.3.2.3.cmml">t</mi></msub><mo id="S2.SS1.p1.3.m3.2.3.3.1" xref="S2.SS1.p1.3.m3.2.3.3.1.cmml">â¢</mo><mrow id="S2.SS1.p1.3.m3.2.3.3.3.2" xref="S2.SS1.p1.3.m3.2.3.3.cmml"><mo id="S2.SS1.p1.3.m3.2.3.3.3.2.1" stretchy="false" xref="S2.SS1.p1.3.m3.2.3.3.cmml">(</mo><mi id="S2.SS1.p1.3.m3.2.2" xref="S2.SS1.p1.3.m3.2.2.cmml">t</mi><mo id="S2.SS1.p1.3.m3.2.3.3.3.2.2" stretchy="false" xref="S2.SS1.p1.3.m3.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.2b"><apply id="S2.SS1.p1.3.m3.2.3.cmml" xref="S2.SS1.p1.3.m3.2.3"><approx id="S2.SS1.p1.3.m3.2.3.1.cmml" xref="S2.SS1.p1.3.m3.2.3.1"></approx><apply id="S2.SS1.p1.3.m3.2.3.2.cmml" xref="S2.SS1.p1.3.m3.2.3.2"><times id="S2.SS1.p1.3.m3.2.3.2.1.cmml" xref="S2.SS1.p1.3.m3.2.3.2.1"></times><apply id="S2.SS1.p1.3.m3.2.3.2.2.cmml" xref="S2.SS1.p1.3.m3.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.2.3.2.2.1.cmml" xref="S2.SS1.p1.3.m3.2.3.2.2">subscript</csymbol><ci id="S2.SS1.p1.3.m3.2.3.2.2.2.cmml" xref="S2.SS1.p1.3.m3.2.3.2.2.2">ğ‘“</ci><ci id="S2.SS1.p1.3.m3.2.3.2.2.3.cmml" xref="S2.SS1.p1.3.m3.2.3.2.2.3">ğ‘</ci></apply><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">ğ‘</ci></apply><apply id="S2.SS1.p1.3.m3.2.3.3.cmml" xref="S2.SS1.p1.3.m3.2.3.3"><times id="S2.SS1.p1.3.m3.2.3.3.1.cmml" xref="S2.SS1.p1.3.m3.2.3.3.1"></times><apply id="S2.SS1.p1.3.m3.2.3.3.2.cmml" xref="S2.SS1.p1.3.m3.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.2.3.3.2.1.cmml" xref="S2.SS1.p1.3.m3.2.3.3.2">subscript</csymbol><ci id="S2.SS1.p1.3.m3.2.3.3.2.2.cmml" xref="S2.SS1.p1.3.m3.2.3.3.2.2">ğ‘“</ci><ci id="S2.SS1.p1.3.m3.2.3.3.2.3.cmml" xref="S2.SS1.p1.3.m3.2.3.3.2.3">ğ‘¡</ci></apply><ci id="S2.SS1.p1.3.m3.2.2.cmml" xref="S2.SS1.p1.3.m3.2.2">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.2c">f_{a}(a)\approx f_{t}(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.2d">italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_a ) â‰ˆ italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t )</annotation></semantics></math> holds for any audio-text pair <math alttext="(a,t)" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.2"><semantics id="S2.SS1.p1.4.m4.2a"><mrow id="S2.SS1.p1.4.m4.2.3.2" xref="S2.SS1.p1.4.m4.2.3.1.cmml"><mo id="S2.SS1.p1.4.m4.2.3.2.1" stretchy="false" xref="S2.SS1.p1.4.m4.2.3.1.cmml">(</mo><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">a</mi><mo id="S2.SS1.p1.4.m4.2.3.2.2" xref="S2.SS1.p1.4.m4.2.3.1.cmml">,</mo><mi id="S2.SS1.p1.4.m4.2.2" xref="S2.SS1.p1.4.m4.2.2.cmml">t</mi><mo id="S2.SS1.p1.4.m4.2.3.2.3" stretchy="false" xref="S2.SS1.p1.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.2b"><interval closure="open" id="S2.SS1.p1.4.m4.2.3.1.cmml" xref="S2.SS1.p1.4.m4.2.3.2"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">ğ‘</ci><ci id="S2.SS1.p1.4.m4.2.2.cmml" xref="S2.SS1.p1.4.m4.2.2">ğ‘¡</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.2c">(a,t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.2d">( italic_a , italic_t )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.11">Given a raw caption <math alttext="t\in\mathcal{T}" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">t</mi><mo id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">ğ’¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><in id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1"></in><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">ğ‘¡</ci><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">ğ’¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">t\in\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_t âˆˆ caligraphic_T</annotation></semantics></math>, where <math alttext="\mathcal{T}" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">caligraphic_T</annotation></semantics></math> represents a caption corpus, the objective in text-only training is to decode its CLAP text embedding <math alttext="E_{t}=f_{t}(t)" class="ltx_Math" display="inline" id="S2.SS1.p2.3.m3.1"><semantics id="S2.SS1.p2.3.m3.1a"><mrow id="S2.SS1.p2.3.m3.1.2" xref="S2.SS1.p2.3.m3.1.2.cmml"><msub id="S2.SS1.p2.3.m3.1.2.2" xref="S2.SS1.p2.3.m3.1.2.2.cmml"><mi id="S2.SS1.p2.3.m3.1.2.2.2" xref="S2.SS1.p2.3.m3.1.2.2.2.cmml">E</mi><mi id="S2.SS1.p2.3.m3.1.2.2.3" xref="S2.SS1.p2.3.m3.1.2.2.3.cmml">t</mi></msub><mo id="S2.SS1.p2.3.m3.1.2.1" xref="S2.SS1.p2.3.m3.1.2.1.cmml">=</mo><mrow id="S2.SS1.p2.3.m3.1.2.3" xref="S2.SS1.p2.3.m3.1.2.3.cmml"><msub id="S2.SS1.p2.3.m3.1.2.3.2" xref="S2.SS1.p2.3.m3.1.2.3.2.cmml"><mi id="S2.SS1.p2.3.m3.1.2.3.2.2" xref="S2.SS1.p2.3.m3.1.2.3.2.2.cmml">f</mi><mi id="S2.SS1.p2.3.m3.1.2.3.2.3" xref="S2.SS1.p2.3.m3.1.2.3.2.3.cmml">t</mi></msub><mo id="S2.SS1.p2.3.m3.1.2.3.1" xref="S2.SS1.p2.3.m3.1.2.3.1.cmml">â¢</mo><mrow id="S2.SS1.p2.3.m3.1.2.3.3.2" xref="S2.SS1.p2.3.m3.1.2.3.cmml"><mo id="S2.SS1.p2.3.m3.1.2.3.3.2.1" stretchy="false" xref="S2.SS1.p2.3.m3.1.2.3.cmml">(</mo><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">t</mi><mo id="S2.SS1.p2.3.m3.1.2.3.3.2.2" stretchy="false" xref="S2.SS1.p2.3.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.2.cmml" xref="S2.SS1.p2.3.m3.1.2"><eq id="S2.SS1.p2.3.m3.1.2.1.cmml" xref="S2.SS1.p2.3.m3.1.2.1"></eq><apply id="S2.SS1.p2.3.m3.1.2.2.cmml" xref="S2.SS1.p2.3.m3.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.2.2.1.cmml" xref="S2.SS1.p2.3.m3.1.2.2">subscript</csymbol><ci id="S2.SS1.p2.3.m3.1.2.2.2.cmml" xref="S2.SS1.p2.3.m3.1.2.2.2">ğ¸</ci><ci id="S2.SS1.p2.3.m3.1.2.2.3.cmml" xref="S2.SS1.p2.3.m3.1.2.2.3">ğ‘¡</ci></apply><apply id="S2.SS1.p2.3.m3.1.2.3.cmml" xref="S2.SS1.p2.3.m3.1.2.3"><times id="S2.SS1.p2.3.m3.1.2.3.1.cmml" xref="S2.SS1.p2.3.m3.1.2.3.1"></times><apply id="S2.SS1.p2.3.m3.1.2.3.2.cmml" xref="S2.SS1.p2.3.m3.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.2.3.2.1.cmml" xref="S2.SS1.p2.3.m3.1.2.3.2">subscript</csymbol><ci id="S2.SS1.p2.3.m3.1.2.3.2.2.cmml" xref="S2.SS1.p2.3.m3.1.2.3.2.2">ğ‘“</ci><ci id="S2.SS1.p2.3.m3.1.2.3.2.3.cmml" xref="S2.SS1.p2.3.m3.1.2.3.2.3">ğ‘¡</ci></apply><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">E_{t}=f_{t}(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.3.m3.1d">italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t )</annotation></semantics></math> back into the original caption <math alttext="t" class="ltx_Math" display="inline" id="S2.SS1.p2.4.m4.1"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.4.m4.1d">italic_t</annotation></semantics></math>. To achieve this, we train a lightweight linear mapping network <math alttext="m" class="ltx_Math" display="inline" id="S2.SS1.p2.5.m5.1"><semantics id="S2.SS1.p2.5.m5.1a"><mi id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">m</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.5.m5.1d">italic_m</annotation></semantics></math> to align the CLAP latent space with the LLM, producing <math alttext="e_{t}=m(E_{t})" class="ltx_Math" display="inline" id="S2.SS1.p2.6.m6.1"><semantics id="S2.SS1.p2.6.m6.1a"><mrow id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml"><msub id="S2.SS1.p2.6.m6.1.1.3" xref="S2.SS1.p2.6.m6.1.1.3.cmml"><mi id="S2.SS1.p2.6.m6.1.1.3.2" xref="S2.SS1.p2.6.m6.1.1.3.2.cmml">e</mi><mi id="S2.SS1.p2.6.m6.1.1.3.3" xref="S2.SS1.p2.6.m6.1.1.3.3.cmml">t</mi></msub><mo id="S2.SS1.p2.6.m6.1.1.2" xref="S2.SS1.p2.6.m6.1.1.2.cmml">=</mo><mrow id="S2.SS1.p2.6.m6.1.1.1" xref="S2.SS1.p2.6.m6.1.1.1.cmml"><mi id="S2.SS1.p2.6.m6.1.1.1.3" xref="S2.SS1.p2.6.m6.1.1.1.3.cmml">m</mi><mo id="S2.SS1.p2.6.m6.1.1.1.2" xref="S2.SS1.p2.6.m6.1.1.1.2.cmml">â¢</mo><mrow id="S2.SS1.p2.6.m6.1.1.1.1.1" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><mo id="S2.SS1.p2.6.m6.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS1.p2.6.m6.1.1.1.1.1.1" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.6.m6.1.1.1.1.1.1.2" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml">E</mi><mi id="S2.SS1.p2.6.m6.1.1.1.1.1.1.3" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p2.6.m6.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1"><eq id="S2.SS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2"></eq><apply id="S2.SS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.3.1.cmml" xref="S2.SS1.p2.6.m6.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.3.2.cmml" xref="S2.SS1.p2.6.m6.1.1.3.2">ğ‘’</ci><ci id="S2.SS1.p2.6.m6.1.1.3.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.SS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1.1"><times id="S2.SS1.p2.6.m6.1.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.1.2"></times><ci id="S2.SS1.p2.6.m6.1.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.1.3">ğ‘š</ci><apply id="S2.SS1.p2.6.m6.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.2">ğ¸</ci><ci id="S2.SS1.p2.6.m6.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">e_{t}=m(E_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.6.m6.1d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_m ( italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>. The LLM then reconstructs the original caption using <math alttext="e_{t}" class="ltx_Math" display="inline" id="S2.SS1.p2.7.m7.1"><semantics id="S2.SS1.p2.7.m7.1a"><msub id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><mi id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml">e</mi><mi id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2">ğ‘’</ci><ci id="S2.SS1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">e_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.7.m7.1d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> along with an additional encoded prompt discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS2" title="II-B Retrieval-augmented Generation â€£ II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-B</span></span></a>. During inference, given an audio clip <math alttext="a" class="ltx_Math" display="inline" id="S2.SS1.p2.8.m8.1"><semantics id="S2.SS1.p2.8.m8.1a"><mi id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><ci id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">a</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.8.m8.1d">italic_a</annotation></semantics></math>, we replace the text encoder with the audio encoder of the CLAP model, extracting the audio embedding <math alttext="E_{a}=f_{a}(a)" class="ltx_Math" display="inline" id="S2.SS1.p2.9.m9.1"><semantics id="S2.SS1.p2.9.m9.1a"><mrow id="S2.SS1.p2.9.m9.1.2" xref="S2.SS1.p2.9.m9.1.2.cmml"><msub id="S2.SS1.p2.9.m9.1.2.2" xref="S2.SS1.p2.9.m9.1.2.2.cmml"><mi id="S2.SS1.p2.9.m9.1.2.2.2" xref="S2.SS1.p2.9.m9.1.2.2.2.cmml">E</mi><mi id="S2.SS1.p2.9.m9.1.2.2.3" xref="S2.SS1.p2.9.m9.1.2.2.3.cmml">a</mi></msub><mo id="S2.SS1.p2.9.m9.1.2.1" xref="S2.SS1.p2.9.m9.1.2.1.cmml">=</mo><mrow id="S2.SS1.p2.9.m9.1.2.3" xref="S2.SS1.p2.9.m9.1.2.3.cmml"><msub id="S2.SS1.p2.9.m9.1.2.3.2" xref="S2.SS1.p2.9.m9.1.2.3.2.cmml"><mi id="S2.SS1.p2.9.m9.1.2.3.2.2" xref="S2.SS1.p2.9.m9.1.2.3.2.2.cmml">f</mi><mi id="S2.SS1.p2.9.m9.1.2.3.2.3" xref="S2.SS1.p2.9.m9.1.2.3.2.3.cmml">a</mi></msub><mo id="S2.SS1.p2.9.m9.1.2.3.1" xref="S2.SS1.p2.9.m9.1.2.3.1.cmml">â¢</mo><mrow id="S2.SS1.p2.9.m9.1.2.3.3.2" xref="S2.SS1.p2.9.m9.1.2.3.cmml"><mo id="S2.SS1.p2.9.m9.1.2.3.3.2.1" stretchy="false" xref="S2.SS1.p2.9.m9.1.2.3.cmml">(</mo><mi id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml">a</mi><mo id="S2.SS1.p2.9.m9.1.2.3.3.2.2" stretchy="false" xref="S2.SS1.p2.9.m9.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.1b"><apply id="S2.SS1.p2.9.m9.1.2.cmml" xref="S2.SS1.p2.9.m9.1.2"><eq id="S2.SS1.p2.9.m9.1.2.1.cmml" xref="S2.SS1.p2.9.m9.1.2.1"></eq><apply id="S2.SS1.p2.9.m9.1.2.2.cmml" xref="S2.SS1.p2.9.m9.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.2.2.1.cmml" xref="S2.SS1.p2.9.m9.1.2.2">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.2.2.2.cmml" xref="S2.SS1.p2.9.m9.1.2.2.2">ğ¸</ci><ci id="S2.SS1.p2.9.m9.1.2.2.3.cmml" xref="S2.SS1.p2.9.m9.1.2.2.3">ğ‘</ci></apply><apply id="S2.SS1.p2.9.m9.1.2.3.cmml" xref="S2.SS1.p2.9.m9.1.2.3"><times id="S2.SS1.p2.9.m9.1.2.3.1.cmml" xref="S2.SS1.p2.9.m9.1.2.3.1"></times><apply id="S2.SS1.p2.9.m9.1.2.3.2.cmml" xref="S2.SS1.p2.9.m9.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.2.3.2.1.cmml" xref="S2.SS1.p2.9.m9.1.2.3.2">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.2.3.2.2.cmml" xref="S2.SS1.p2.9.m9.1.2.3.2.2">ğ‘“</ci><ci id="S2.SS1.p2.9.m9.1.2.3.2.3.cmml" xref="S2.SS1.p2.9.m9.1.2.3.2.3">ğ‘</ci></apply><ci id="S2.SS1.p2.9.m9.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.1c">E_{a}=f_{a}(a)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.9.m9.1d">italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_a )</annotation></semantics></math>.
Due to the modality gap between audio and text embeddings, directly feeding <math alttext="E_{a}" class="ltx_Math" display="inline" id="S2.SS1.p2.10.m10.1"><semantics id="S2.SS1.p2.10.m10.1a"><msub id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml"><mi id="S2.SS1.p2.10.m10.1.1.2" xref="S2.SS1.p2.10.m10.1.1.2.cmml">E</mi><mi id="S2.SS1.p2.10.m10.1.1.3" xref="S2.SS1.p2.10.m10.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.1b"><apply id="S2.SS1.p2.10.m10.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.2">ğ¸</ci><ci id="S2.SS1.p2.10.m10.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.1c">E_{a}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.10.m10.1d">italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> to the LLM through <math alttext="m" class="ltx_Math" display="inline" id="S2.SS1.p2.11.m11.1"><semantics id="S2.SS1.p2.11.m11.1a"><mi id="S2.SS1.p2.11.m11.1.1" xref="S2.SS1.p2.11.m11.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.11.m11.1b"><ci id="S2.SS1.p2.11.m11.1.1.cmml" xref="S2.SS1.p2.11.m11.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.11.m11.1c">m</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.11.m11.1d">italic_m</annotation></semantics></math> will yield sub-optimal results.
To address this issue and enhance the quality of generated captions, we employ both the retrieval-augmented generation strategy from the decoder side and the projection strategy from the encoder side, detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS2" title="II-B Retrieval-augmented Generation â€£ II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-B</span></span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS3" title="II-C Projection-based Decoding â€£ II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-C</span></span></a> respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.5.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.6.2">Retrieval-augmented Generation</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Retrieval-Augmented Generation (RAG) combines information retrieval from a datastore with a generative model, allowing it to generate more accurate, context-aware outputs by incorporating external knowledge.
DRCap leverages the RAG method to take full advantage of the generative capabilities of the LLM, bridging the modality gap and improving its ability in describing unseen sound events.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.4">During training, given a raw caption <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">italic_t</annotation></semantics></math>, we use its CLAP text embedding <math alttext="E_{t}=f_{t}(t)" class="ltx_Math" display="inline" id="S2.SS2.p2.2.m2.1"><semantics id="S2.SS2.p2.2.m2.1a"><mrow id="S2.SS2.p2.2.m2.1.2" xref="S2.SS2.p2.2.m2.1.2.cmml"><msub id="S2.SS2.p2.2.m2.1.2.2" xref="S2.SS2.p2.2.m2.1.2.2.cmml"><mi id="S2.SS2.p2.2.m2.1.2.2.2" xref="S2.SS2.p2.2.m2.1.2.2.2.cmml">E</mi><mi id="S2.SS2.p2.2.m2.1.2.2.3" xref="S2.SS2.p2.2.m2.1.2.2.3.cmml">t</mi></msub><mo id="S2.SS2.p2.2.m2.1.2.1" xref="S2.SS2.p2.2.m2.1.2.1.cmml">=</mo><mrow id="S2.SS2.p2.2.m2.1.2.3" xref="S2.SS2.p2.2.m2.1.2.3.cmml"><msub id="S2.SS2.p2.2.m2.1.2.3.2" xref="S2.SS2.p2.2.m2.1.2.3.2.cmml"><mi id="S2.SS2.p2.2.m2.1.2.3.2.2" xref="S2.SS2.p2.2.m2.1.2.3.2.2.cmml">f</mi><mi id="S2.SS2.p2.2.m2.1.2.3.2.3" xref="S2.SS2.p2.2.m2.1.2.3.2.3.cmml">t</mi></msub><mo id="S2.SS2.p2.2.m2.1.2.3.1" xref="S2.SS2.p2.2.m2.1.2.3.1.cmml">â¢</mo><mrow id="S2.SS2.p2.2.m2.1.2.3.3.2" xref="S2.SS2.p2.2.m2.1.2.3.cmml"><mo id="S2.SS2.p2.2.m2.1.2.3.3.2.1" stretchy="false" xref="S2.SS2.p2.2.m2.1.2.3.cmml">(</mo><mi id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">t</mi><mo id="S2.SS2.p2.2.m2.1.2.3.3.2.2" stretchy="false" xref="S2.SS2.p2.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><apply id="S2.SS2.p2.2.m2.1.2.cmml" xref="S2.SS2.p2.2.m2.1.2"><eq id="S2.SS2.p2.2.m2.1.2.1.cmml" xref="S2.SS2.p2.2.m2.1.2.1"></eq><apply id="S2.SS2.p2.2.m2.1.2.2.cmml" xref="S2.SS2.p2.2.m2.1.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.2.2.1.cmml" xref="S2.SS2.p2.2.m2.1.2.2">subscript</csymbol><ci id="S2.SS2.p2.2.m2.1.2.2.2.cmml" xref="S2.SS2.p2.2.m2.1.2.2.2">ğ¸</ci><ci id="S2.SS2.p2.2.m2.1.2.2.3.cmml" xref="S2.SS2.p2.2.m2.1.2.2.3">ğ‘¡</ci></apply><apply id="S2.SS2.p2.2.m2.1.2.3.cmml" xref="S2.SS2.p2.2.m2.1.2.3"><times id="S2.SS2.p2.2.m2.1.2.3.1.cmml" xref="S2.SS2.p2.2.m2.1.2.3.1"></times><apply id="S2.SS2.p2.2.m2.1.2.3.2.cmml" xref="S2.SS2.p2.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.2.3.2.1.cmml" xref="S2.SS2.p2.2.m2.1.2.3.2">subscript</csymbol><ci id="S2.SS2.p2.2.m2.1.2.3.2.2.cmml" xref="S2.SS2.p2.2.m2.1.2.3.2.2">ğ‘“</ci><ci id="S2.SS2.p2.2.m2.1.2.3.2.3.cmml" xref="S2.SS2.p2.2.m2.1.2.3.2.3">ğ‘¡</ci></apply><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">E_{t}=f_{t}(t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t )</annotation></semantics></math> to retrieve semantically similar captions from the datastore <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S2.SS2.p2.3.m3.1"><semantics id="S2.SS2.p2.3.m3.1a"><mrow id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.3.m3.1.1.2" xref="S2.SS2.p2.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mo id="S2.SS2.p2.3.m3.1.1.1" xref="S2.SS2.p2.3.m3.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.3.m3.1.1.3" xref="S2.SS2.p2.3.m3.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><apply id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1"><times id="S2.SS2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1.1"></times><ci id="S2.SS2.p2.3.m3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.1.1.2">ğ’Ÿ</ci><ci id="S2.SS2.p2.3.m3.1.1.3.cmml" xref="S2.SS2.p2.3.m3.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.3.m3.1d">caligraphic_D caligraphic_S</annotation></semantics></math>. The retrieval process for a candidate caption <math alttext="t_{i}\in\mathcal{DS}" class="ltx_Math" display="inline" id="S2.SS2.p2.4.m4.1"><semantics id="S2.SS2.p2.4.m4.1a"><mrow id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml"><msub id="S2.SS2.p2.4.m4.1.1.2" xref="S2.SS2.p2.4.m4.1.1.2.cmml"><mi id="S2.SS2.p2.4.m4.1.1.2.2" xref="S2.SS2.p2.4.m4.1.1.2.2.cmml">t</mi><mi id="S2.SS2.p2.4.m4.1.1.2.3" xref="S2.SS2.p2.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS2.p2.4.m4.1.1.1" xref="S2.SS2.p2.4.m4.1.1.1.cmml">âˆˆ</mo><mrow id="S2.SS2.p2.4.m4.1.1.3" xref="S2.SS2.p2.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1.3.2" xref="S2.SS2.p2.4.m4.1.1.3.2.cmml">ğ’Ÿ</mi><mo id="S2.SS2.p2.4.m4.1.1.3.1" xref="S2.SS2.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1.3.3" xref="S2.SS2.p2.4.m4.1.1.3.3.cmml">ğ’®</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><apply id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1"><in id="S2.SS2.p2.4.m4.1.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1.1"></in><apply id="S2.SS2.p2.4.m4.1.1.2.cmml" xref="S2.SS2.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p2.4.m4.1.1.2.1.cmml" xref="S2.SS2.p2.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS2.p2.4.m4.1.1.2.2.cmml" xref="S2.SS2.p2.4.m4.1.1.2.2">ğ‘¡</ci><ci id="S2.SS2.p2.4.m4.1.1.2.3.cmml" xref="S2.SS2.p2.4.m4.1.1.2.3">ğ‘–</ci></apply><apply id="S2.SS2.p2.4.m4.1.1.3.cmml" xref="S2.SS2.p2.4.m4.1.1.3"><times id="S2.SS2.p2.4.m4.1.1.3.1.cmml" xref="S2.SS2.p2.4.m4.1.1.3.1"></times><ci id="S2.SS2.p2.4.m4.1.1.3.2.cmml" xref="S2.SS2.p2.4.m4.1.1.3.2">ğ’Ÿ</ci><ci id="S2.SS2.p2.4.m4.1.1.3.3.cmml" xref="S2.SS2.p2.4.m4.1.1.3.3">ğ’®</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">t_{i}\in\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.4.m4.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ caligraphic_D caligraphic_S</annotation></semantics></math> is based on the cosine similarity between their respective CLAP text embeddings, calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S(t,t_{\text{i}})=\frac{f_{t}(t)\cdot f_{t}(t_{\text{i}})}{\|f_{t}(t)\|\cdot\|%
f_{t}(t_{\text{i}})\|}" class="ltx_Math" display="block" id="S2.E1.m1.7"><semantics id="S2.E1.m1.7a"><mrow id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml"><mrow id="S2.E1.m1.7.7.1" xref="S2.E1.m1.7.7.1.cmml"><mi id="S2.E1.m1.7.7.1.3" xref="S2.E1.m1.7.7.1.3.cmml">S</mi><mo id="S2.E1.m1.7.7.1.2" xref="S2.E1.m1.7.7.1.2.cmml">â¢</mo><mrow id="S2.E1.m1.7.7.1.1.1" xref="S2.E1.m1.7.7.1.1.2.cmml"><mo id="S2.E1.m1.7.7.1.1.1.2" stretchy="false" xref="S2.E1.m1.7.7.1.1.2.cmml">(</mo><mi id="S2.E1.m1.6.6" xref="S2.E1.m1.6.6.cmml">t</mi><mo id="S2.E1.m1.7.7.1.1.1.3" xref="S2.E1.m1.7.7.1.1.2.cmml">,</mo><msub id="S2.E1.m1.7.7.1.1.1.1" xref="S2.E1.m1.7.7.1.1.1.1.cmml"><mi id="S2.E1.m1.7.7.1.1.1.1.2" xref="S2.E1.m1.7.7.1.1.1.1.2.cmml">t</mi><mtext id="S2.E1.m1.7.7.1.1.1.1.3" xref="S2.E1.m1.7.7.1.1.1.1.3a.cmml">i</mtext></msub><mo id="S2.E1.m1.7.7.1.1.1.4" stretchy="false" xref="S2.E1.m1.7.7.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.7.7.2" xref="S2.E1.m1.7.7.2.cmml">=</mo><mfrac id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml"><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><mrow id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.4.cmml"><mrow id="S2.E1.m1.2.2.2.4.2" xref="S2.E1.m1.2.2.2.4.2.cmml"><msub id="S2.E1.m1.2.2.2.4.2.2" xref="S2.E1.m1.2.2.2.4.2.2.cmml"><mi id="S2.E1.m1.2.2.2.4.2.2.2" xref="S2.E1.m1.2.2.2.4.2.2.2.cmml">f</mi><mi id="S2.E1.m1.2.2.2.4.2.2.3" xref="S2.E1.m1.2.2.2.4.2.2.3.cmml">t</mi></msub><mo id="S2.E1.m1.2.2.2.4.2.1" xref="S2.E1.m1.2.2.2.4.2.1.cmml">â¢</mo><mrow id="S2.E1.m1.2.2.2.4.2.3.2" xref="S2.E1.m1.2.2.2.4.2.cmml"><mo id="S2.E1.m1.2.2.2.4.2.3.2.1" stretchy="false" xref="S2.E1.m1.2.2.2.4.2.cmml">(</mo><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">t</mi><mo id="S2.E1.m1.2.2.2.4.2.3.2.2" rspace="0.055em" stretchy="false" xref="S2.E1.m1.2.2.2.4.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.2.4.1" rspace="0.222em" xref="S2.E1.m1.2.2.2.4.1.cmml">â‹…</mo><msub id="S2.E1.m1.2.2.2.4.3" xref="S2.E1.m1.2.2.2.4.3.cmml"><mi id="S2.E1.m1.2.2.2.4.3.2" xref="S2.E1.m1.2.2.2.4.3.2.cmml">f</mi><mi id="S2.E1.m1.2.2.2.4.3.3" xref="S2.E1.m1.2.2.2.4.3.3.cmml">t</mi></msub></mrow><mo id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml">â¢</mo><mrow id="S2.E1.m1.2.2.2.2.1" xref="S2.E1.m1.2.2.2.2.1.1.cmml"><mo id="S2.E1.m1.2.2.2.2.1.2" stretchy="false" xref="S2.E1.m1.2.2.2.2.1.1.cmml">(</mo><msub id="S2.E1.m1.2.2.2.2.1.1" xref="S2.E1.m1.2.2.2.2.1.1.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.2" xref="S2.E1.m1.2.2.2.2.1.1.2.cmml">t</mi><mtext id="S2.E1.m1.2.2.2.2.1.1.3" xref="S2.E1.m1.2.2.2.2.1.1.3a.cmml">i</mtext></msub><mo id="S2.E1.m1.2.2.2.2.1.3" stretchy="false" xref="S2.E1.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E1.m1.5.5.5" xref="S2.E1.m1.5.5.5.cmml"><mrow id="S2.E1.m1.4.4.4.2.1" xref="S2.E1.m1.4.4.4.2.2.cmml"><mo id="S2.E1.m1.4.4.4.2.1.2" stretchy="false" xref="S2.E1.m1.4.4.4.2.2.1.cmml">â€–</mo><mrow id="S2.E1.m1.4.4.4.2.1.1" xref="S2.E1.m1.4.4.4.2.1.1.cmml"><msub id="S2.E1.m1.4.4.4.2.1.1.2" xref="S2.E1.m1.4.4.4.2.1.1.2.cmml"><mi id="S2.E1.m1.4.4.4.2.1.1.2.2" xref="S2.E1.m1.4.4.4.2.1.1.2.2.cmml">f</mi><mi id="S2.E1.m1.4.4.4.2.1.1.2.3" xref="S2.E1.m1.4.4.4.2.1.1.2.3.cmml">t</mi></msub><mo id="S2.E1.m1.4.4.4.2.1.1.1" xref="S2.E1.m1.4.4.4.2.1.1.1.cmml">â¢</mo><mrow id="S2.E1.m1.4.4.4.2.1.1.3.2" xref="S2.E1.m1.4.4.4.2.1.1.cmml"><mo id="S2.E1.m1.4.4.4.2.1.1.3.2.1" stretchy="false" xref="S2.E1.m1.4.4.4.2.1.1.cmml">(</mo><mi id="S2.E1.m1.3.3.3.1" xref="S2.E1.m1.3.3.3.1.cmml">t</mi><mo id="S2.E1.m1.4.4.4.2.1.1.3.2.2" stretchy="false" xref="S2.E1.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.4.2.1.3" rspace="0.055em" stretchy="false" xref="S2.E1.m1.4.4.4.2.2.1.cmml">â€–</mo></mrow><mo id="S2.E1.m1.5.5.5.4" rspace="0.222em" xref="S2.E1.m1.5.5.5.4.cmml">â‹…</mo><mrow id="S2.E1.m1.5.5.5.3.1" xref="S2.E1.m1.5.5.5.3.2.cmml"><mo id="S2.E1.m1.5.5.5.3.1.2" stretchy="false" xref="S2.E1.m1.5.5.5.3.2.1.cmml">â€–</mo><mrow id="S2.E1.m1.5.5.5.3.1.1" xref="S2.E1.m1.5.5.5.3.1.1.cmml"><msub id="S2.E1.m1.5.5.5.3.1.1.3" xref="S2.E1.m1.5.5.5.3.1.1.3.cmml"><mi id="S2.E1.m1.5.5.5.3.1.1.3.2" xref="S2.E1.m1.5.5.5.3.1.1.3.2.cmml">f</mi><mi id="S2.E1.m1.5.5.5.3.1.1.3.3" xref="S2.E1.m1.5.5.5.3.1.1.3.3.cmml">t</mi></msub><mo id="S2.E1.m1.5.5.5.3.1.1.2" xref="S2.E1.m1.5.5.5.3.1.1.2.cmml">â¢</mo><mrow id="S2.E1.m1.5.5.5.3.1.1.1.1" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.cmml"><mo id="S2.E1.m1.5.5.5.3.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.5.5.5.3.1.1.1.1.1" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.cmml"><mi id="S2.E1.m1.5.5.5.3.1.1.1.1.1.2" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.2.cmml">t</mi><mtext id="S2.E1.m1.5.5.5.3.1.1.1.1.1.3" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.3a.cmml">i</mtext></msub><mo id="S2.E1.m1.5.5.5.3.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.5.5.5.3.1.3" stretchy="false" xref="S2.E1.m1.5.5.5.3.2.1.cmml">â€–</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.7b"><apply id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7"><eq id="S2.E1.m1.7.7.2.cmml" xref="S2.E1.m1.7.7.2"></eq><apply id="S2.E1.m1.7.7.1.cmml" xref="S2.E1.m1.7.7.1"><times id="S2.E1.m1.7.7.1.2.cmml" xref="S2.E1.m1.7.7.1.2"></times><ci id="S2.E1.m1.7.7.1.3.cmml" xref="S2.E1.m1.7.7.1.3">ğ‘†</ci><interval closure="open" id="S2.E1.m1.7.7.1.1.2.cmml" xref="S2.E1.m1.7.7.1.1.1"><ci id="S2.E1.m1.6.6.cmml" xref="S2.E1.m1.6.6">ğ‘¡</ci><apply id="S2.E1.m1.7.7.1.1.1.1.cmml" xref="S2.E1.m1.7.7.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.1.1.1.1.1.cmml" xref="S2.E1.m1.7.7.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.7.7.1.1.1.1.2.cmml" xref="S2.E1.m1.7.7.1.1.1.1.2">ğ‘¡</ci><ci id="S2.E1.m1.7.7.1.1.1.1.3a.cmml" xref="S2.E1.m1.7.7.1.1.1.1.3"><mtext id="S2.E1.m1.7.7.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E1.m1.7.7.1.1.1.1.3">i</mtext></ci></apply></interval></apply><apply id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5"><divide id="S2.E1.m1.5.5.6.cmml" xref="S2.E1.m1.5.5"></divide><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><times id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3"></times><apply id="S2.E1.m1.2.2.2.4.cmml" xref="S2.E1.m1.2.2.2.4"><ci id="S2.E1.m1.2.2.2.4.1.cmml" xref="S2.E1.m1.2.2.2.4.1">â‹…</ci><apply id="S2.E1.m1.2.2.2.4.2.cmml" xref="S2.E1.m1.2.2.2.4.2"><times id="S2.E1.m1.2.2.2.4.2.1.cmml" xref="S2.E1.m1.2.2.2.4.2.1"></times><apply id="S2.E1.m1.2.2.2.4.2.2.cmml" xref="S2.E1.m1.2.2.2.4.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.4.2.2.1.cmml" xref="S2.E1.m1.2.2.2.4.2.2">subscript</csymbol><ci id="S2.E1.m1.2.2.2.4.2.2.2.cmml" xref="S2.E1.m1.2.2.2.4.2.2.2">ğ‘“</ci><ci id="S2.E1.m1.2.2.2.4.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4.2.2.3">ğ‘¡</ci></apply><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">ğ‘¡</ci></apply><apply id="S2.E1.m1.2.2.2.4.3.cmml" xref="S2.E1.m1.2.2.2.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.4.3.1.cmml" xref="S2.E1.m1.2.2.2.4.3">subscript</csymbol><ci id="S2.E1.m1.2.2.2.4.3.2.cmml" xref="S2.E1.m1.2.2.2.4.3.2">ğ‘“</ci><ci id="S2.E1.m1.2.2.2.4.3.3.cmml" xref="S2.E1.m1.2.2.2.4.3.3">ğ‘¡</ci></apply></apply><apply id="S2.E1.m1.2.2.2.2.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.2">ğ‘¡</ci><ci id="S2.E1.m1.2.2.2.2.1.1.3a.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3"><mtext id="S2.E1.m1.2.2.2.2.1.1.3.cmml" mathsize="70%" xref="S2.E1.m1.2.2.2.2.1.1.3">i</mtext></ci></apply></apply><apply id="S2.E1.m1.5.5.5.cmml" xref="S2.E1.m1.5.5.5"><ci id="S2.E1.m1.5.5.5.4.cmml" xref="S2.E1.m1.5.5.5.4">â‹…</ci><apply id="S2.E1.m1.4.4.4.2.2.cmml" xref="S2.E1.m1.4.4.4.2.1"><csymbol cd="latexml" id="S2.E1.m1.4.4.4.2.2.1.cmml" xref="S2.E1.m1.4.4.4.2.1.2">norm</csymbol><apply id="S2.E1.m1.4.4.4.2.1.1.cmml" xref="S2.E1.m1.4.4.4.2.1.1"><times id="S2.E1.m1.4.4.4.2.1.1.1.cmml" xref="S2.E1.m1.4.4.4.2.1.1.1"></times><apply id="S2.E1.m1.4.4.4.2.1.1.2.cmml" xref="S2.E1.m1.4.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.2.1.1.2.1.cmml" xref="S2.E1.m1.4.4.4.2.1.1.2">subscript</csymbol><ci id="S2.E1.m1.4.4.4.2.1.1.2.2.cmml" xref="S2.E1.m1.4.4.4.2.1.1.2.2">ğ‘“</ci><ci id="S2.E1.m1.4.4.4.2.1.1.2.3.cmml" xref="S2.E1.m1.4.4.4.2.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.E1.m1.3.3.3.1.cmml" xref="S2.E1.m1.3.3.3.1">ğ‘¡</ci></apply></apply><apply id="S2.E1.m1.5.5.5.3.2.cmml" xref="S2.E1.m1.5.5.5.3.1"><csymbol cd="latexml" id="S2.E1.m1.5.5.5.3.2.1.cmml" xref="S2.E1.m1.5.5.5.3.1.2">norm</csymbol><apply id="S2.E1.m1.5.5.5.3.1.1.cmml" xref="S2.E1.m1.5.5.5.3.1.1"><times id="S2.E1.m1.5.5.5.3.1.1.2.cmml" xref="S2.E1.m1.5.5.5.3.1.1.2"></times><apply id="S2.E1.m1.5.5.5.3.1.1.3.cmml" xref="S2.E1.m1.5.5.5.3.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.5.3.1.1.3.1.cmml" xref="S2.E1.m1.5.5.5.3.1.1.3">subscript</csymbol><ci id="S2.E1.m1.5.5.5.3.1.1.3.2.cmml" xref="S2.E1.m1.5.5.5.3.1.1.3.2">ğ‘“</ci><ci id="S2.E1.m1.5.5.5.3.1.1.3.3.cmml" xref="S2.E1.m1.5.5.5.3.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.E1.m1.5.5.5.3.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.5.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.5.3.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.5.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.5.5.5.3.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.2">ğ‘¡</ci><ci id="S2.E1.m1.5.5.5.3.1.1.1.1.1.3a.cmml" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.3"><mtext id="S2.E1.m1.5.5.5.3.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E1.m1.5.5.5.3.1.1.1.1.1.3">i</mtext></ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.7c">S(t,t_{\text{i}})=\frac{f_{t}(t)\cdot f_{t}(t_{\text{i}})}{\|f_{t}(t)\|\cdot\|%
f_{t}(t_{\text{i}})\|}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.7d">italic_S ( italic_t , italic_t start_POSTSUBSCRIPT i end_POSTSUBSCRIPT ) = divide start_ARG italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t ) â‹… italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT i end_POSTSUBSCRIPT ) end_ARG start_ARG âˆ¥ italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t ) âˆ¥ â‹… âˆ¥ italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT i end_POSTSUBSCRIPT ) âˆ¥ end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p2.10">We noticed, however, that naively selecting the top <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p2.5.m1.1"><semantics id="S2.SS2.p2.5.m1.1a"><mi id="S2.SS2.p2.5.m1.1.1" xref="S2.SS2.p2.5.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m1.1b"><ci id="S2.SS2.p2.5.m1.1.1.cmml" xref="S2.SS2.p2.5.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.5.m1.1d">italic_k</annotation></semantics></math> most similar captions can lead the LLM to become lazy, merely reproducing one of the <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p2.6.m2.1"><semantics id="S2.SS2.p2.6.m2.1a"><mi id="S2.SS2.p2.6.m2.1.1" xref="S2.SS2.p2.6.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.6.m2.1b"><ci id="S2.SS2.p2.6.m2.1.1.cmml" xref="S2.SS2.p2.6.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.6.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.6.m2.1d">italic_k</annotation></semantics></math> captions as the output, neglecting <math alttext="e_{t}" class="ltx_Math" display="inline" id="S2.SS2.p2.7.m3.1"><semantics id="S2.SS2.p2.7.m3.1a"><msub id="S2.SS2.p2.7.m3.1.1" xref="S2.SS2.p2.7.m3.1.1.cmml"><mi id="S2.SS2.p2.7.m3.1.1.2" xref="S2.SS2.p2.7.m3.1.1.2.cmml">e</mi><mi id="S2.SS2.p2.7.m3.1.1.3" xref="S2.SS2.p2.7.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.7.m3.1b"><apply id="S2.SS2.p2.7.m3.1.1.cmml" xref="S2.SS2.p2.7.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.7.m3.1.1.1.cmml" xref="S2.SS2.p2.7.m3.1.1">subscript</csymbol><ci id="S2.SS2.p2.7.m3.1.1.2.cmml" xref="S2.SS2.p2.7.m3.1.1.2">ğ‘’</ci><ci id="S2.SS2.p2.7.m3.1.1.3.cmml" xref="S2.SS2.p2.7.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.7.m3.1c">e_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.7.m3.1d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. To mitigate this issue and improve the modelâ€™s robustness, we proposed a similarity selection strategy, defining a similarity range <math alttext="[S_{\text{min}},S_{\text{max}}]" class="ltx_Math" display="inline" id="S2.SS2.p2.8.m4.2"><semantics id="S2.SS2.p2.8.m4.2a"><mrow id="S2.SS2.p2.8.m4.2.2.2" xref="S2.SS2.p2.8.m4.2.2.3.cmml"><mo id="S2.SS2.p2.8.m4.2.2.2.3" stretchy="false" xref="S2.SS2.p2.8.m4.2.2.3.cmml">[</mo><msub id="S2.SS2.p2.8.m4.1.1.1.1" xref="S2.SS2.p2.8.m4.1.1.1.1.cmml"><mi id="S2.SS2.p2.8.m4.1.1.1.1.2" xref="S2.SS2.p2.8.m4.1.1.1.1.2.cmml">S</mi><mtext id="S2.SS2.p2.8.m4.1.1.1.1.3" xref="S2.SS2.p2.8.m4.1.1.1.1.3a.cmml">min</mtext></msub><mo id="S2.SS2.p2.8.m4.2.2.2.4" xref="S2.SS2.p2.8.m4.2.2.3.cmml">,</mo><msub id="S2.SS2.p2.8.m4.2.2.2.2" xref="S2.SS2.p2.8.m4.2.2.2.2.cmml"><mi id="S2.SS2.p2.8.m4.2.2.2.2.2" xref="S2.SS2.p2.8.m4.2.2.2.2.2.cmml">S</mi><mtext id="S2.SS2.p2.8.m4.2.2.2.2.3" xref="S2.SS2.p2.8.m4.2.2.2.2.3a.cmml">max</mtext></msub><mo id="S2.SS2.p2.8.m4.2.2.2.5" stretchy="false" xref="S2.SS2.p2.8.m4.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.8.m4.2b"><interval closure="closed" id="S2.SS2.p2.8.m4.2.2.3.cmml" xref="S2.SS2.p2.8.m4.2.2.2"><apply id="S2.SS2.p2.8.m4.1.1.1.1.cmml" xref="S2.SS2.p2.8.m4.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m4.1.1.1.1.1.cmml" xref="S2.SS2.p2.8.m4.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.8.m4.1.1.1.1.2.cmml" xref="S2.SS2.p2.8.m4.1.1.1.1.2">ğ‘†</ci><ci id="S2.SS2.p2.8.m4.1.1.1.1.3a.cmml" xref="S2.SS2.p2.8.m4.1.1.1.1.3"><mtext id="S2.SS2.p2.8.m4.1.1.1.1.3.cmml" mathsize="70%" xref="S2.SS2.p2.8.m4.1.1.1.1.3">min</mtext></ci></apply><apply id="S2.SS2.p2.8.m4.2.2.2.2.cmml" xref="S2.SS2.p2.8.m4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m4.2.2.2.2.1.cmml" xref="S2.SS2.p2.8.m4.2.2.2.2">subscript</csymbol><ci id="S2.SS2.p2.8.m4.2.2.2.2.2.cmml" xref="S2.SS2.p2.8.m4.2.2.2.2.2">ğ‘†</ci><ci id="S2.SS2.p2.8.m4.2.2.2.2.3a.cmml" xref="S2.SS2.p2.8.m4.2.2.2.2.3"><mtext id="S2.SS2.p2.8.m4.2.2.2.2.3.cmml" mathsize="70%" xref="S2.SS2.p2.8.m4.2.2.2.2.3">max</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.8.m4.2c">[S_{\text{min}},S_{\text{max}}]</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.8.m4.2d">[ italic_S start_POSTSUBSCRIPT min end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT max end_POSTSUBSCRIPT ]</annotation></semantics></math> from which <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p2.9.m5.1"><semantics id="S2.SS2.p2.9.m5.1a"><mi id="S2.SS2.p2.9.m5.1.1" xref="S2.SS2.p2.9.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.9.m5.1b"><ci id="S2.SS2.p2.9.m5.1.1.cmml" xref="S2.SS2.p2.9.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.9.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.9.m5.1d">italic_k</annotation></semantics></math> captions are randomly selected. If fewer than <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p2.10.m6.1"><semantics id="S2.SS2.p2.10.m6.1a"><mi id="S2.SS2.p2.10.m6.1.1" xref="S2.SS2.p2.10.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.10.m6.1b"><ci id="S2.SS2.p2.10.m6.1.1.cmml" xref="S2.SS2.p2.10.m6.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.10.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.10.m6.1d">italic_k</annotation></semantics></math> captions fall within this range, only the qualifying captions are used as input. The effectiveness of our strategy is verified in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.SS2" title="IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.3">Additionally, the model is given a fixed prompt (<span class="ltx_text ltx_font_italic" id="S2.SS2.p3.3.1">e.g.,</span> â€œDescribe the audio you hearâ€) to help the LLM better understand the task. The similar captions and the fixed prompt are encoded using the tokenizer of the LLM. Let <math alttext="e_{s}" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><msub id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">e</mi><mi id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">ğ‘’</ci><ci id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">e_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="e_{p}" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><msub id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml"><mi id="S2.SS2.p3.2.m2.1.1.2" xref="S2.SS2.p3.2.m2.1.1.2.cmml">e</mi><mi id="S2.SS2.p3.2.m2.1.1.3" xref="S2.SS2.p3.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><apply id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.1.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p3.2.m2.1.1.2.cmml" xref="S2.SS2.p3.2.m2.1.1.2">ğ‘’</ci><ci id="S2.SS2.p3.2.m2.1.1.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">e_{p}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">italic_e start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> denote the encoded embeddings of the similar captions and the fixed prompt. The model is trained to minimize the cross-entropy loss conditioned on <math alttext="z=\text{Concat}(e_{t},e_{s},e_{p})" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m3.3"><semantics id="S2.SS2.p3.3.m3.3a"><mrow id="S2.SS2.p3.3.m3.3.3" xref="S2.SS2.p3.3.m3.3.3.cmml"><mi id="S2.SS2.p3.3.m3.3.3.5" xref="S2.SS2.p3.3.m3.3.3.5.cmml">z</mi><mo id="S2.SS2.p3.3.m3.3.3.4" xref="S2.SS2.p3.3.m3.3.3.4.cmml">=</mo><mrow id="S2.SS2.p3.3.m3.3.3.3" xref="S2.SS2.p3.3.m3.3.3.3.cmml"><mtext id="S2.SS2.p3.3.m3.3.3.3.5" xref="S2.SS2.p3.3.m3.3.3.3.5a.cmml">Concat</mtext><mo id="S2.SS2.p3.3.m3.3.3.3.4" xref="S2.SS2.p3.3.m3.3.3.3.4.cmml">â¢</mo><mrow id="S2.SS2.p3.3.m3.3.3.3.3.3" xref="S2.SS2.p3.3.m3.3.3.3.3.4.cmml"><mo id="S2.SS2.p3.3.m3.3.3.3.3.3.4" stretchy="false" xref="S2.SS2.p3.3.m3.3.3.3.3.4.cmml">(</mo><msub id="S2.SS2.p3.3.m3.1.1.1.1.1.1" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p3.3.m3.1.1.1.1.1.1.2" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1.2.cmml">e</mi><mi id="S2.SS2.p3.3.m3.1.1.1.1.1.1.3" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS2.p3.3.m3.3.3.3.3.3.5" xref="S2.SS2.p3.3.m3.3.3.3.3.4.cmml">,</mo><msub id="S2.SS2.p3.3.m3.2.2.2.2.2.2" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2.cmml"><mi id="S2.SS2.p3.3.m3.2.2.2.2.2.2.2" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2.2.cmml">e</mi><mi id="S2.SS2.p3.3.m3.2.2.2.2.2.2.3" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2.3.cmml">s</mi></msub><mo id="S2.SS2.p3.3.m3.3.3.3.3.3.6" xref="S2.SS2.p3.3.m3.3.3.3.3.4.cmml">,</mo><msub id="S2.SS2.p3.3.m3.3.3.3.3.3.3" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3.cmml"><mi id="S2.SS2.p3.3.m3.3.3.3.3.3.3.2" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3.2.cmml">e</mi><mi id="S2.SS2.p3.3.m3.3.3.3.3.3.3.3" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3.3.cmml">p</mi></msub><mo id="S2.SS2.p3.3.m3.3.3.3.3.3.7" stretchy="false" xref="S2.SS2.p3.3.m3.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.3b"><apply id="S2.SS2.p3.3.m3.3.3.cmml" xref="S2.SS2.p3.3.m3.3.3"><eq id="S2.SS2.p3.3.m3.3.3.4.cmml" xref="S2.SS2.p3.3.m3.3.3.4"></eq><ci id="S2.SS2.p3.3.m3.3.3.5.cmml" xref="S2.SS2.p3.3.m3.3.3.5">ğ‘§</ci><apply id="S2.SS2.p3.3.m3.3.3.3.cmml" xref="S2.SS2.p3.3.m3.3.3.3"><times id="S2.SS2.p3.3.m3.3.3.3.4.cmml" xref="S2.SS2.p3.3.m3.3.3.3.4"></times><ci id="S2.SS2.p3.3.m3.3.3.3.5a.cmml" xref="S2.SS2.p3.3.m3.3.3.3.5"><mtext id="S2.SS2.p3.3.m3.3.3.3.5.cmml" xref="S2.SS2.p3.3.m3.3.3.3.5">Concat</mtext></ci><vector id="S2.SS2.p3.3.m3.3.3.3.3.4.cmml" xref="S2.SS2.p3.3.m3.3.3.3.3.3"><apply id="S2.SS2.p3.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1.2">ğ‘’</ci><ci id="S2.SS2.p3.3.m3.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S2.SS2.p3.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.2.2.2.2.2.2.1.cmml" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2">subscript</csymbol><ci id="S2.SS2.p3.3.m3.2.2.2.2.2.2.2.cmml" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2.2">ğ‘’</ci><ci id="S2.SS2.p3.3.m3.2.2.2.2.2.2.3.cmml" xref="S2.SS2.p3.3.m3.2.2.2.2.2.2.3">ğ‘ </ci></apply><apply id="S2.SS2.p3.3.m3.3.3.3.3.3.3.cmml" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.3.3.3.3.3.3.1.cmml" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3">subscript</csymbol><ci id="S2.SS2.p3.3.m3.3.3.3.3.3.3.2.cmml" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3.2">ğ‘’</ci><ci id="S2.SS2.p3.3.m3.3.3.3.3.3.3.3.cmml" xref="S2.SS2.p3.3.m3.3.3.3.3.3.3.3">ğ‘</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.3c">z=\text{Concat}(e_{t},e_{s},e_{p})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m3.3d">italic_z = Concat ( italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT )</annotation></semantics></math>:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S2.E2">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E2X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{CE}}=-\frac{1}{L_{t}}\sum_{i=1}^{L_{t}}\log p(%
t_{i}|z,t_{1},...,t_{i-1})" class="ltx_Math" display="inline" id="S2.E2X.2.1.1.m1.3"><semantics id="S2.E2X.2.1.1.m1.3a"><mrow id="S2.E2X.2.1.1.m1.3.3" xref="S2.E2X.2.1.1.m1.3.3.cmml"><msub id="S2.E2X.2.1.1.m1.3.3.3" xref="S2.E2X.2.1.1.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2X.2.1.1.m1.3.3.3.2" xref="S2.E2X.2.1.1.m1.3.3.3.2.cmml">â„’</mi><mtext id="S2.E2X.2.1.1.m1.3.3.3.3" xref="S2.E2X.2.1.1.m1.3.3.3.3a.cmml">CE</mtext></msub><mo id="S2.E2X.2.1.1.m1.3.3.2" xref="S2.E2X.2.1.1.m1.3.3.2.cmml">=</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1" xref="S2.E2X.2.1.1.m1.3.3.1.cmml"><mo id="S2.E2X.2.1.1.m1.3.3.1a" xref="S2.E2X.2.1.1.m1.3.3.1.cmml">âˆ’</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.cmml"><mstyle displaystyle="true" id="S2.E2X.2.1.1.m1.3.3.1.1.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.cmml"><mfrac id="S2.E2X.2.1.1.m1.3.3.1.1.3a" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.cmml"><mn id="S2.E2X.2.1.1.m1.3.3.1.1.3.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.2.cmml">1</mn><msub id="S2.E2X.2.1.1.m1.3.3.1.1.3.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.3.3.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3.2.cmml">L</mi><mi id="S2.E2X.2.1.1.m1.3.3.1.1.3.3.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3.3.cmml">t</mi></msub></mfrac></mstyle><mo id="S2.E2X.2.1.1.m1.3.3.1.1.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.2.cmml">â¢</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E2X.2.1.1.m1.3.3.1.1.1.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.cmml"><munderover id="S2.E2X.2.1.1.m1.3.3.1.1.1.2a" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.cmml"><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.2" movablelimits="false" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.2.cmml">i</mi><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.3.cmml">1</mn></mrow><msub id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.2.cmml">L</mi><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.3.cmml">t</mi></msub></munderover></mstyle><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.cmml"><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.1.cmml">log</mi><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3a" lspace="0.167em" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.cmml">â¡</mo><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.2.cmml">p</mi></mrow><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.2.cmml">â¢</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml"><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.2" stretchy="false" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml"><msub id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.2.cmml">t</mi><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.3.cmml">i</mi></msub><mo fence="false" id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E2X.2.1.1.m1.1.1" xref="S2.E2X.2.1.1.m1.1.1.cmml">z</mi><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mn id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.4" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.3.cmml">,</mo><mi id="S2.E2X.2.1.1.m1.2.2" mathvariant="normal" xref="S2.E2X.2.1.1.m1.2.2.cmml">â€¦</mi><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.5" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.2.cmml">t</mi><mrow id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.2" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.2.cmml">i</mi><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.1" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.1.cmml">âˆ’</mo><mn id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.3" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.3" stretchy="false" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2X.2.1.1.m1.3b"><apply id="S2.E2X.2.1.1.m1.3.3.cmml" xref="S2.E2X.2.1.1.m1.3.3"><eq id="S2.E2X.2.1.1.m1.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.2"></eq><apply id="S2.E2X.2.1.1.m1.3.3.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.3"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.3">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.3.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.3.2">â„’</ci><ci id="S2.E2X.2.1.1.m1.3.3.3.3a.cmml" xref="S2.E2X.2.1.1.m1.3.3.3.3"><mtext id="S2.E2X.2.1.1.m1.3.3.3.3.cmml" mathsize="70%" xref="S2.E2X.2.1.1.m1.3.3.3.3">CE</mtext></ci></apply><apply id="S2.E2X.2.1.1.m1.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1"><minus id="S2.E2X.2.1.1.m1.3.3.1.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1"></minus><apply id="S2.E2X.2.1.1.m1.3.3.1.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1"><times id="S2.E2X.2.1.1.m1.3.3.1.1.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.2"></times><apply id="S2.E2X.2.1.1.m1.3.3.1.1.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.3"><divide id="S2.E2X.2.1.1.m1.3.3.1.1.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.3"></divide><cn id="S2.E2X.2.1.1.m1.3.3.1.1.3.2.cmml" type="integer" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.2">1</cn><apply id="S2.E2X.2.1.1.m1.3.3.1.1.3.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.3.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.3.3.1.1.3.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3.2">ğ¿</ci><ci id="S2.E2X.2.1.1.m1.3.3.1.1.3.3.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.3.3.3">ğ‘¡</ci></apply></apply><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1"><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2">superscript</csymbol><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.2"></sum><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3"><eq id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.1"></eq><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.2">ğ‘–</ci><cn id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.3.cmml" type="integer" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.2">ğ¿</ci><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.2.3.3">ğ‘¡</ci></apply></apply><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1"><times id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.2"></times><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3"><log id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.1"></log><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.3.2">ğ‘</ci></apply><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.2">ğ‘¡</ci><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4.3">ğ‘–</ci></apply><list id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2"><ci id="S2.E2X.2.1.1.m1.1.1.cmml" xref="S2.E2X.2.1.1.m1.1.1">ğ‘§</ci><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">ğ‘¡</ci><cn id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S2.E2X.2.1.1.m1.2.2.cmml" xref="S2.E2X.2.1.1.m1.2.2">â€¦</ci><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.2">ğ‘¡</ci><apply id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3"><minus id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.1"></minus><ci id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.2.cmml" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.2">ğ‘–</ci><cn id="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.3.cmml" type="integer" xref="S2.E2X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2.2.2.3.3">1</cn></apply></apply></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2X.2.1.1.m1.3c">\displaystyle\mathcal{L}_{\text{CE}}=-\frac{1}{L_{t}}\sum_{i=1}^{L_{t}}\log p(%
t_{i}|z,t_{1},...,t_{i-1})</annotation><annotation encoding="application/x-llamapun" id="S2.E2X.2.1.1.m1.3d">caligraphic_L start_POSTSUBSCRIPT CE end_POSTSUBSCRIPT = - divide start_ARG 1 end_ARG start_ARG italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT roman_log italic_p ( italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z , italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_t start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S2.SS2.p3.9">Where <math alttext="e_{t}=m(f_{t}(t))" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m1.2"><semantics id="S2.SS2.p3.4.m1.2a"><mrow id="S2.SS2.p3.4.m1.2.2" xref="S2.SS2.p3.4.m1.2.2.cmml"><msub id="S2.SS2.p3.4.m1.2.2.3" xref="S2.SS2.p3.4.m1.2.2.3.cmml"><mi id="S2.SS2.p3.4.m1.2.2.3.2" xref="S2.SS2.p3.4.m1.2.2.3.2.cmml">e</mi><mi id="S2.SS2.p3.4.m1.2.2.3.3" xref="S2.SS2.p3.4.m1.2.2.3.3.cmml">t</mi></msub><mo id="S2.SS2.p3.4.m1.2.2.2" xref="S2.SS2.p3.4.m1.2.2.2.cmml">=</mo><mrow id="S2.SS2.p3.4.m1.2.2.1" xref="S2.SS2.p3.4.m1.2.2.1.cmml"><mi id="S2.SS2.p3.4.m1.2.2.1.3" xref="S2.SS2.p3.4.m1.2.2.1.3.cmml">m</mi><mo id="S2.SS2.p3.4.m1.2.2.1.2" xref="S2.SS2.p3.4.m1.2.2.1.2.cmml">â¢</mo><mrow id="S2.SS2.p3.4.m1.2.2.1.1.1" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml"><mo id="S2.SS2.p3.4.m1.2.2.1.1.1.2" stretchy="false" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p3.4.m1.2.2.1.1.1.1" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml"><msub id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.cmml"><mi id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.2" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.2.cmml">f</mi><mi id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.3" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS2.p3.4.m1.2.2.1.1.1.1.1" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.1.cmml">â¢</mo><mrow id="S2.SS2.p3.4.m1.2.2.1.1.1.1.3.2" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml"><mo id="S2.SS2.p3.4.m1.2.2.1.1.1.1.3.2.1" stretchy="false" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S2.SS2.p3.4.m1.1.1" xref="S2.SS2.p3.4.m1.1.1.cmml">t</mi><mo id="S2.SS2.p3.4.m1.2.2.1.1.1.1.3.2.2" stretchy="false" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p3.4.m1.2.2.1.1.1.3" stretchy="false" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m1.2b"><apply id="S2.SS2.p3.4.m1.2.2.cmml" xref="S2.SS2.p3.4.m1.2.2"><eq id="S2.SS2.p3.4.m1.2.2.2.cmml" xref="S2.SS2.p3.4.m1.2.2.2"></eq><apply id="S2.SS2.p3.4.m1.2.2.3.cmml" xref="S2.SS2.p3.4.m1.2.2.3"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m1.2.2.3.1.cmml" xref="S2.SS2.p3.4.m1.2.2.3">subscript</csymbol><ci id="S2.SS2.p3.4.m1.2.2.3.2.cmml" xref="S2.SS2.p3.4.m1.2.2.3.2">ğ‘’</ci><ci id="S2.SS2.p3.4.m1.2.2.3.3.cmml" xref="S2.SS2.p3.4.m1.2.2.3.3">ğ‘¡</ci></apply><apply id="S2.SS2.p3.4.m1.2.2.1.cmml" xref="S2.SS2.p3.4.m1.2.2.1"><times id="S2.SS2.p3.4.m1.2.2.1.2.cmml" xref="S2.SS2.p3.4.m1.2.2.1.2"></times><ci id="S2.SS2.p3.4.m1.2.2.1.3.cmml" xref="S2.SS2.p3.4.m1.2.2.1.3">ğ‘š</ci><apply id="S2.SS2.p3.4.m1.2.2.1.1.1.1.cmml" xref="S2.SS2.p3.4.m1.2.2.1.1.1"><times id="S2.SS2.p3.4.m1.2.2.1.1.1.1.1.cmml" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.1"></times><apply id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.cmml" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.1.cmml" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2">subscript</csymbol><ci id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.2.cmml" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.2">ğ‘“</ci><ci id="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.3.cmml" xref="S2.SS2.p3.4.m1.2.2.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.SS2.p3.4.m1.1.1.cmml" xref="S2.SS2.p3.4.m1.1.1">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m1.2c">e_{t}=m(f_{t}(t))</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m1.2d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_m ( italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t ) )</annotation></semantics></math> is the mapped CLAP text embedding, <math alttext="L_{t}" class="ltx_Math" display="inline" id="S2.SS2.p3.5.m2.1"><semantics id="S2.SS2.p3.5.m2.1a"><msub id="S2.SS2.p3.5.m2.1.1" xref="S2.SS2.p3.5.m2.1.1.cmml"><mi id="S2.SS2.p3.5.m2.1.1.2" xref="S2.SS2.p3.5.m2.1.1.2.cmml">L</mi><mi id="S2.SS2.p3.5.m2.1.1.3" xref="S2.SS2.p3.5.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m2.1b"><apply id="S2.SS2.p3.5.m2.1.1.cmml" xref="S2.SS2.p3.5.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.5.m2.1.1.1.cmml" xref="S2.SS2.p3.5.m2.1.1">subscript</csymbol><ci id="S2.SS2.p3.5.m2.1.1.2.cmml" xref="S2.SS2.p3.5.m2.1.1.2">ğ¿</ci><ci id="S2.SS2.p3.5.m2.1.1.3.cmml" xref="S2.SS2.p3.5.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m2.1c">L_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.5.m2.1d">italic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the length of the input caption <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.p3.6.m3.1"><semantics id="S2.SS2.p3.6.m3.1a"><mi id="S2.SS2.p3.6.m3.1.1" xref="S2.SS2.p3.6.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m3.1b"><ci id="S2.SS2.p3.6.m3.1.1.cmml" xref="S2.SS2.p3.6.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.6.m3.1d">italic_t</annotation></semantics></math>, <math alttext="t_{i}" class="ltx_Math" display="inline" id="S2.SS2.p3.7.m4.1"><semantics id="S2.SS2.p3.7.m4.1a"><msub id="S2.SS2.p3.7.m4.1.1" xref="S2.SS2.p3.7.m4.1.1.cmml"><mi id="S2.SS2.p3.7.m4.1.1.2" xref="S2.SS2.p3.7.m4.1.1.2.cmml">t</mi><mi id="S2.SS2.p3.7.m4.1.1.3" xref="S2.SS2.p3.7.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m4.1b"><apply id="S2.SS2.p3.7.m4.1.1.cmml" xref="S2.SS2.p3.7.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m4.1.1.1.cmml" xref="S2.SS2.p3.7.m4.1.1">subscript</csymbol><ci id="S2.SS2.p3.7.m4.1.1.2.cmml" xref="S2.SS2.p3.7.m4.1.1.2">ğ‘¡</ci><ci id="S2.SS2.p3.7.m4.1.1.3.cmml" xref="S2.SS2.p3.7.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m4.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.7.m4.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the <math alttext="i" class="ltx_Math" display="inline" id="S2.SS2.p3.8.m5.1"><semantics id="S2.SS2.p3.8.m5.1a"><mi id="S2.SS2.p3.8.m5.1.1" xref="S2.SS2.p3.8.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.8.m5.1b"><ci id="S2.SS2.p3.8.m5.1.1.cmml" xref="S2.SS2.p3.8.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.8.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.8.m5.1d">italic_i</annotation></semantics></math>-th token of <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.p3.9.m6.1"><semantics id="S2.SS2.p3.9.m6.1a"><mi id="S2.SS2.p3.9.m6.1.1" xref="S2.SS2.p3.9.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.9.m6.1b"><ci id="S2.SS2.p3.9.m6.1.1.cmml" xref="S2.SS2.p3.9.m6.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.9.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.9.m6.1d">italic_t</annotation></semantics></math>. During training, we froze the CLAP encoder and trained only the linear mapping network, while applying LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib24" title="">24</a>]</cite> to fine-tune the large language model, which significantly enhanced training efficiency.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.4">During inference, given an audio clip <math alttext="a" class="ltx_Math" display="inline" id="S2.SS2.p4.1.m1.1"><semantics id="S2.SS2.p4.1.m1.1a"><mi id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.1.m1.1d">italic_a</annotation></semantics></math>, the text-to-text retrieval is replaced with the audio-to-text retrieval, where we use the CLAP audio embedding <math alttext="E_{a}=f_{a}(a)" class="ltx_Math" display="inline" id="S2.SS2.p4.2.m2.1"><semantics id="S2.SS2.p4.2.m2.1a"><mrow id="S2.SS2.p4.2.m2.1.2" xref="S2.SS2.p4.2.m2.1.2.cmml"><msub id="S2.SS2.p4.2.m2.1.2.2" xref="S2.SS2.p4.2.m2.1.2.2.cmml"><mi id="S2.SS2.p4.2.m2.1.2.2.2" xref="S2.SS2.p4.2.m2.1.2.2.2.cmml">E</mi><mi id="S2.SS2.p4.2.m2.1.2.2.3" xref="S2.SS2.p4.2.m2.1.2.2.3.cmml">a</mi></msub><mo id="S2.SS2.p4.2.m2.1.2.1" xref="S2.SS2.p4.2.m2.1.2.1.cmml">=</mo><mrow id="S2.SS2.p4.2.m2.1.2.3" xref="S2.SS2.p4.2.m2.1.2.3.cmml"><msub id="S2.SS2.p4.2.m2.1.2.3.2" xref="S2.SS2.p4.2.m2.1.2.3.2.cmml"><mi id="S2.SS2.p4.2.m2.1.2.3.2.2" xref="S2.SS2.p4.2.m2.1.2.3.2.2.cmml">f</mi><mi id="S2.SS2.p4.2.m2.1.2.3.2.3" xref="S2.SS2.p4.2.m2.1.2.3.2.3.cmml">a</mi></msub><mo id="S2.SS2.p4.2.m2.1.2.3.1" xref="S2.SS2.p4.2.m2.1.2.3.1.cmml">â¢</mo><mrow id="S2.SS2.p4.2.m2.1.2.3.3.2" xref="S2.SS2.p4.2.m2.1.2.3.cmml"><mo id="S2.SS2.p4.2.m2.1.2.3.3.2.1" stretchy="false" xref="S2.SS2.p4.2.m2.1.2.3.cmml">(</mo><mi id="S2.SS2.p4.2.m2.1.1" xref="S2.SS2.p4.2.m2.1.1.cmml">a</mi><mo id="S2.SS2.p4.2.m2.1.2.3.3.2.2" stretchy="false" xref="S2.SS2.p4.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.2.m2.1b"><apply id="S2.SS2.p4.2.m2.1.2.cmml" xref="S2.SS2.p4.2.m2.1.2"><eq id="S2.SS2.p4.2.m2.1.2.1.cmml" xref="S2.SS2.p4.2.m2.1.2.1"></eq><apply id="S2.SS2.p4.2.m2.1.2.2.cmml" xref="S2.SS2.p4.2.m2.1.2.2"><csymbol cd="ambiguous" id="S2.SS2.p4.2.m2.1.2.2.1.cmml" xref="S2.SS2.p4.2.m2.1.2.2">subscript</csymbol><ci id="S2.SS2.p4.2.m2.1.2.2.2.cmml" xref="S2.SS2.p4.2.m2.1.2.2.2">ğ¸</ci><ci id="S2.SS2.p4.2.m2.1.2.2.3.cmml" xref="S2.SS2.p4.2.m2.1.2.2.3">ğ‘</ci></apply><apply id="S2.SS2.p4.2.m2.1.2.3.cmml" xref="S2.SS2.p4.2.m2.1.2.3"><times id="S2.SS2.p4.2.m2.1.2.3.1.cmml" xref="S2.SS2.p4.2.m2.1.2.3.1"></times><apply id="S2.SS2.p4.2.m2.1.2.3.2.cmml" xref="S2.SS2.p4.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.p4.2.m2.1.2.3.2.1.cmml" xref="S2.SS2.p4.2.m2.1.2.3.2">subscript</csymbol><ci id="S2.SS2.p4.2.m2.1.2.3.2.2.cmml" xref="S2.SS2.p4.2.m2.1.2.3.2.2">ğ‘“</ci><ci id="S2.SS2.p4.2.m2.1.2.3.2.3.cmml" xref="S2.SS2.p4.2.m2.1.2.3.2.3">ğ‘</ci></apply><ci id="S2.SS2.p4.2.m2.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.2.m2.1c">E_{a}=f_{a}(a)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_a )</annotation></semantics></math> to retrieve <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.p4.3.m3.1"><semantics id="S2.SS2.p4.3.m3.1a"><mi id="S2.SS2.p4.3.m3.1.1" xref="S2.SS2.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.3.m3.1b"><ci id="S2.SS2.p4.3.m3.1.1.cmml" xref="S2.SS2.p4.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.3.m3.1d">italic_k</annotation></semantics></math> most similar captions. The cross-modal similarity for a candidate caption <math alttext="t_{i}\in\mathcal{DS}" class="ltx_Math" display="inline" id="S2.SS2.p4.4.m4.1"><semantics id="S2.SS2.p4.4.m4.1a"><mrow id="S2.SS2.p4.4.m4.1.1" xref="S2.SS2.p4.4.m4.1.1.cmml"><msub id="S2.SS2.p4.4.m4.1.1.2" xref="S2.SS2.p4.4.m4.1.1.2.cmml"><mi id="S2.SS2.p4.4.m4.1.1.2.2" xref="S2.SS2.p4.4.m4.1.1.2.2.cmml">t</mi><mi id="S2.SS2.p4.4.m4.1.1.2.3" xref="S2.SS2.p4.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS2.p4.4.m4.1.1.1" xref="S2.SS2.p4.4.m4.1.1.1.cmml">âˆˆ</mo><mrow id="S2.SS2.p4.4.m4.1.1.3" xref="S2.SS2.p4.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p4.4.m4.1.1.3.2" xref="S2.SS2.p4.4.m4.1.1.3.2.cmml">ğ’Ÿ</mi><mo id="S2.SS2.p4.4.m4.1.1.3.1" xref="S2.SS2.p4.4.m4.1.1.3.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p4.4.m4.1.1.3.3" xref="S2.SS2.p4.4.m4.1.1.3.3.cmml">ğ’®</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.4.m4.1b"><apply id="S2.SS2.p4.4.m4.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1"><in id="S2.SS2.p4.4.m4.1.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1.1"></in><apply id="S2.SS2.p4.4.m4.1.1.2.cmml" xref="S2.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p4.4.m4.1.1.2.1.cmml" xref="S2.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS2.p4.4.m4.1.1.2.2.cmml" xref="S2.SS2.p4.4.m4.1.1.2.2">ğ‘¡</ci><ci id="S2.SS2.p4.4.m4.1.1.2.3.cmml" xref="S2.SS2.p4.4.m4.1.1.2.3">ğ‘–</ci></apply><apply id="S2.SS2.p4.4.m4.1.1.3.cmml" xref="S2.SS2.p4.4.m4.1.1.3"><times id="S2.SS2.p4.4.m4.1.1.3.1.cmml" xref="S2.SS2.p4.4.m4.1.1.3.1"></times><ci id="S2.SS2.p4.4.m4.1.1.3.2.cmml" xref="S2.SS2.p4.4.m4.1.1.3.2">ğ’Ÿ</ci><ci id="S2.SS2.p4.4.m4.1.1.3.3.cmml" xref="S2.SS2.p4.4.m4.1.1.3.3">ğ’®</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.4.m4.1c">t_{i}\in\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.4.m4.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ caligraphic_D caligraphic_S</annotation></semantics></math> is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S(a,t_{i})=\frac{f_{a}(a)\cdot f_{t}(t_{i})}{\|f_{a}(a)\|\cdot\|f_{t}(t_{i})\|}" class="ltx_Math" display="block" id="S2.E3.m1.7"><semantics id="S2.E3.m1.7a"><mrow id="S2.E3.m1.7.7" xref="S2.E3.m1.7.7.cmml"><mrow id="S2.E3.m1.7.7.1" xref="S2.E3.m1.7.7.1.cmml"><mi id="S2.E3.m1.7.7.1.3" xref="S2.E3.m1.7.7.1.3.cmml">S</mi><mo id="S2.E3.m1.7.7.1.2" xref="S2.E3.m1.7.7.1.2.cmml">â¢</mo><mrow id="S2.E3.m1.7.7.1.1.1" xref="S2.E3.m1.7.7.1.1.2.cmml"><mo id="S2.E3.m1.7.7.1.1.1.2" stretchy="false" xref="S2.E3.m1.7.7.1.1.2.cmml">(</mo><mi id="S2.E3.m1.6.6" xref="S2.E3.m1.6.6.cmml">a</mi><mo id="S2.E3.m1.7.7.1.1.1.3" xref="S2.E3.m1.7.7.1.1.2.cmml">,</mo><msub id="S2.E3.m1.7.7.1.1.1.1" xref="S2.E3.m1.7.7.1.1.1.1.cmml"><mi id="S2.E3.m1.7.7.1.1.1.1.2" xref="S2.E3.m1.7.7.1.1.1.1.2.cmml">t</mi><mi id="S2.E3.m1.7.7.1.1.1.1.3" xref="S2.E3.m1.7.7.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E3.m1.7.7.1.1.1.4" stretchy="false" xref="S2.E3.m1.7.7.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.7.7.2" xref="S2.E3.m1.7.7.2.cmml">=</mo><mfrac id="S2.E3.m1.5.5" xref="S2.E3.m1.5.5.cmml"><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml"><mrow id="S2.E3.m1.2.2.2.4" xref="S2.E3.m1.2.2.2.4.cmml"><mrow id="S2.E3.m1.2.2.2.4.2" xref="S2.E3.m1.2.2.2.4.2.cmml"><msub id="S2.E3.m1.2.2.2.4.2.2" xref="S2.E3.m1.2.2.2.4.2.2.cmml"><mi id="S2.E3.m1.2.2.2.4.2.2.2" xref="S2.E3.m1.2.2.2.4.2.2.2.cmml">f</mi><mi id="S2.E3.m1.2.2.2.4.2.2.3" xref="S2.E3.m1.2.2.2.4.2.2.3.cmml">a</mi></msub><mo id="S2.E3.m1.2.2.2.4.2.1" xref="S2.E3.m1.2.2.2.4.2.1.cmml">â¢</mo><mrow id="S2.E3.m1.2.2.2.4.2.3.2" xref="S2.E3.m1.2.2.2.4.2.cmml"><mo id="S2.E3.m1.2.2.2.4.2.3.2.1" stretchy="false" xref="S2.E3.m1.2.2.2.4.2.cmml">(</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">a</mi><mo id="S2.E3.m1.2.2.2.4.2.3.2.2" rspace="0.055em" stretchy="false" xref="S2.E3.m1.2.2.2.4.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.2.2.2.4.1" rspace="0.222em" xref="S2.E3.m1.2.2.2.4.1.cmml">â‹…</mo><msub id="S2.E3.m1.2.2.2.4.3" xref="S2.E3.m1.2.2.2.4.3.cmml"><mi id="S2.E3.m1.2.2.2.4.3.2" xref="S2.E3.m1.2.2.2.4.3.2.cmml">f</mi><mi id="S2.E3.m1.2.2.2.4.3.3" xref="S2.E3.m1.2.2.2.4.3.3.cmml">t</mi></msub></mrow><mo id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.2.3.cmml">â¢</mo><mrow id="S2.E3.m1.2.2.2.2.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mo id="S2.E3.m1.2.2.2.2.1.2" stretchy="false" xref="S2.E3.m1.2.2.2.2.1.1.cmml">(</mo><msub id="S2.E3.m1.2.2.2.2.1.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.2.cmml">t</mi><mi id="S2.E3.m1.2.2.2.2.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.3.cmml">i</mi></msub><mo id="S2.E3.m1.2.2.2.2.1.3" stretchy="false" xref="S2.E3.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E3.m1.5.5.5" xref="S2.E3.m1.5.5.5.cmml"><mrow id="S2.E3.m1.4.4.4.2.1" xref="S2.E3.m1.4.4.4.2.2.cmml"><mo id="S2.E3.m1.4.4.4.2.1.2" stretchy="false" xref="S2.E3.m1.4.4.4.2.2.1.cmml">â€–</mo><mrow id="S2.E3.m1.4.4.4.2.1.1" xref="S2.E3.m1.4.4.4.2.1.1.cmml"><msub id="S2.E3.m1.4.4.4.2.1.1.2" xref="S2.E3.m1.4.4.4.2.1.1.2.cmml"><mi id="S2.E3.m1.4.4.4.2.1.1.2.2" xref="S2.E3.m1.4.4.4.2.1.1.2.2.cmml">f</mi><mi id="S2.E3.m1.4.4.4.2.1.1.2.3" xref="S2.E3.m1.4.4.4.2.1.1.2.3.cmml">a</mi></msub><mo id="S2.E3.m1.4.4.4.2.1.1.1" xref="S2.E3.m1.4.4.4.2.1.1.1.cmml">â¢</mo><mrow id="S2.E3.m1.4.4.4.2.1.1.3.2" xref="S2.E3.m1.4.4.4.2.1.1.cmml"><mo id="S2.E3.m1.4.4.4.2.1.1.3.2.1" stretchy="false" xref="S2.E3.m1.4.4.4.2.1.1.cmml">(</mo><mi id="S2.E3.m1.3.3.3.1" xref="S2.E3.m1.3.3.3.1.cmml">a</mi><mo id="S2.E3.m1.4.4.4.2.1.1.3.2.2" stretchy="false" xref="S2.E3.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.4.2.1.3" rspace="0.055em" stretchy="false" xref="S2.E3.m1.4.4.4.2.2.1.cmml">â€–</mo></mrow><mo id="S2.E3.m1.5.5.5.4" rspace="0.222em" xref="S2.E3.m1.5.5.5.4.cmml">â‹…</mo><mrow id="S2.E3.m1.5.5.5.3.1" xref="S2.E3.m1.5.5.5.3.2.cmml"><mo id="S2.E3.m1.5.5.5.3.1.2" stretchy="false" xref="S2.E3.m1.5.5.5.3.2.1.cmml">â€–</mo><mrow id="S2.E3.m1.5.5.5.3.1.1" xref="S2.E3.m1.5.5.5.3.1.1.cmml"><msub id="S2.E3.m1.5.5.5.3.1.1.3" xref="S2.E3.m1.5.5.5.3.1.1.3.cmml"><mi id="S2.E3.m1.5.5.5.3.1.1.3.2" xref="S2.E3.m1.5.5.5.3.1.1.3.2.cmml">f</mi><mi id="S2.E3.m1.5.5.5.3.1.1.3.3" xref="S2.E3.m1.5.5.5.3.1.1.3.3.cmml">t</mi></msub><mo id="S2.E3.m1.5.5.5.3.1.1.2" xref="S2.E3.m1.5.5.5.3.1.1.2.cmml">â¢</mo><mrow id="S2.E3.m1.5.5.5.3.1.1.1.1" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.cmml"><mo id="S2.E3.m1.5.5.5.3.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.cmml">(</mo><msub id="S2.E3.m1.5.5.5.3.1.1.1.1.1" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.cmml"><mi id="S2.E3.m1.5.5.5.3.1.1.1.1.1.2" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.2.cmml">t</mi><mi id="S2.E3.m1.5.5.5.3.1.1.1.1.1.3" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E3.m1.5.5.5.3.1.1.1.1.3" stretchy="false" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.5.5.5.3.1.3" stretchy="false" xref="S2.E3.m1.5.5.5.3.2.1.cmml">â€–</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.7b"><apply id="S2.E3.m1.7.7.cmml" xref="S2.E3.m1.7.7"><eq id="S2.E3.m1.7.7.2.cmml" xref="S2.E3.m1.7.7.2"></eq><apply id="S2.E3.m1.7.7.1.cmml" xref="S2.E3.m1.7.7.1"><times id="S2.E3.m1.7.7.1.2.cmml" xref="S2.E3.m1.7.7.1.2"></times><ci id="S2.E3.m1.7.7.1.3.cmml" xref="S2.E3.m1.7.7.1.3">ğ‘†</ci><interval closure="open" id="S2.E3.m1.7.7.1.1.2.cmml" xref="S2.E3.m1.7.7.1.1.1"><ci id="S2.E3.m1.6.6.cmml" xref="S2.E3.m1.6.6">ğ‘</ci><apply id="S2.E3.m1.7.7.1.1.1.1.cmml" xref="S2.E3.m1.7.7.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.1.1.1.1.1.cmml" xref="S2.E3.m1.7.7.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.7.7.1.1.1.1.2.cmml" xref="S2.E3.m1.7.7.1.1.1.1.2">ğ‘¡</ci><ci id="S2.E3.m1.7.7.1.1.1.1.3.cmml" xref="S2.E3.m1.7.7.1.1.1.1.3">ğ‘–</ci></apply></interval></apply><apply id="S2.E3.m1.5.5.cmml" xref="S2.E3.m1.5.5"><divide id="S2.E3.m1.5.5.6.cmml" xref="S2.E3.m1.5.5"></divide><apply id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2"><times id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.3"></times><apply id="S2.E3.m1.2.2.2.4.cmml" xref="S2.E3.m1.2.2.2.4"><ci id="S2.E3.m1.2.2.2.4.1.cmml" xref="S2.E3.m1.2.2.2.4.1">â‹…</ci><apply id="S2.E3.m1.2.2.2.4.2.cmml" xref="S2.E3.m1.2.2.2.4.2"><times id="S2.E3.m1.2.2.2.4.2.1.cmml" xref="S2.E3.m1.2.2.2.4.2.1"></times><apply id="S2.E3.m1.2.2.2.4.2.2.cmml" xref="S2.E3.m1.2.2.2.4.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.4.2.2.1.cmml" xref="S2.E3.m1.2.2.2.4.2.2">subscript</csymbol><ci id="S2.E3.m1.2.2.2.4.2.2.2.cmml" xref="S2.E3.m1.2.2.2.4.2.2.2">ğ‘“</ci><ci id="S2.E3.m1.2.2.2.4.2.2.3.cmml" xref="S2.E3.m1.2.2.2.4.2.2.3">ğ‘</ci></apply><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">ğ‘</ci></apply><apply id="S2.E3.m1.2.2.2.4.3.cmml" xref="S2.E3.m1.2.2.2.4.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.4.3.1.cmml" xref="S2.E3.m1.2.2.2.4.3">subscript</csymbol><ci id="S2.E3.m1.2.2.2.4.3.2.cmml" xref="S2.E3.m1.2.2.2.4.3.2">ğ‘“</ci><ci id="S2.E3.m1.2.2.2.4.3.3.cmml" xref="S2.E3.m1.2.2.2.4.3.3">ğ‘¡</ci></apply></apply><apply id="S2.E3.m1.2.2.2.2.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2">ğ‘¡</ci><ci id="S2.E3.m1.2.2.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3">ğ‘–</ci></apply></apply><apply id="S2.E3.m1.5.5.5.cmml" xref="S2.E3.m1.5.5.5"><ci id="S2.E3.m1.5.5.5.4.cmml" xref="S2.E3.m1.5.5.5.4">â‹…</ci><apply id="S2.E3.m1.4.4.4.2.2.cmml" xref="S2.E3.m1.4.4.4.2.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.4.2.2.1.cmml" xref="S2.E3.m1.4.4.4.2.1.2">norm</csymbol><apply id="S2.E3.m1.4.4.4.2.1.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1"><times id="S2.E3.m1.4.4.4.2.1.1.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1"></times><apply id="S2.E3.m1.4.4.4.2.1.1.2.cmml" xref="S2.E3.m1.4.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.4.2.1.1.2.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.2">subscript</csymbol><ci id="S2.E3.m1.4.4.4.2.1.1.2.2.cmml" xref="S2.E3.m1.4.4.4.2.1.1.2.2">ğ‘“</ci><ci id="S2.E3.m1.4.4.4.2.1.1.2.3.cmml" xref="S2.E3.m1.4.4.4.2.1.1.2.3">ğ‘</ci></apply><ci id="S2.E3.m1.3.3.3.1.cmml" xref="S2.E3.m1.3.3.3.1">ğ‘</ci></apply></apply><apply id="S2.E3.m1.5.5.5.3.2.cmml" xref="S2.E3.m1.5.5.5.3.1"><csymbol cd="latexml" id="S2.E3.m1.5.5.5.3.2.1.cmml" xref="S2.E3.m1.5.5.5.3.1.2">norm</csymbol><apply id="S2.E3.m1.5.5.5.3.1.1.cmml" xref="S2.E3.m1.5.5.5.3.1.1"><times id="S2.E3.m1.5.5.5.3.1.1.2.cmml" xref="S2.E3.m1.5.5.5.3.1.1.2"></times><apply id="S2.E3.m1.5.5.5.3.1.1.3.cmml" xref="S2.E3.m1.5.5.5.3.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.5.3.1.1.3.1.cmml" xref="S2.E3.m1.5.5.5.3.1.1.3">subscript</csymbol><ci id="S2.E3.m1.5.5.5.3.1.1.3.2.cmml" xref="S2.E3.m1.5.5.5.3.1.1.3.2">ğ‘“</ci><ci id="S2.E3.m1.5.5.5.3.1.1.3.3.cmml" xref="S2.E3.m1.5.5.5.3.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.E3.m1.5.5.5.3.1.1.1.1.1.cmml" xref="S2.E3.m1.5.5.5.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.5.3.1.1.1.1.1.1.cmml" xref="S2.E3.m1.5.5.5.3.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.5.5.5.3.1.1.1.1.1.2.cmml" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.2">ğ‘¡</ci><ci id="S2.E3.m1.5.5.5.3.1.1.1.1.1.3.cmml" xref="S2.E3.m1.5.5.5.3.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.7c">S(a,t_{i})=\frac{f_{a}(a)\cdot f_{t}(t_{i})}{\|f_{a}(a)\|\cdot\|f_{t}(t_{i})\|}</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.7d">italic_S ( italic_a , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = divide start_ARG italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_a ) â‹… italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG âˆ¥ italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_a ) âˆ¥ â‹… âˆ¥ italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) âˆ¥ end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p4.5">The similarity selection is turned off, and instead, we choose the most similar captions to provide the LLM with maximum information, since the audio-to-text retrieval during inference is significantly harder than the text-to-text retrieval during training.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Performance comparison of AAC models for in-domain scenarios.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S2.T1.2" style="width:433.6pt;height:131.5pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-111.3pt,33.6pt) scale(0.660725273220893,0.660725273220893) ;">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.2.2.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.2.2.3.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.3.1.1.1">Method</span></td>
<td class="ltx_td ltx_border_tt" id="S2.T1.2.2.3.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S2.T1.2.2.3.1.3">
<span class="ltx_text ltx_font_bold" id="S2.T1.2.2.3.1.3.1">Clotho</span> (%)</td>
<td class="ltx_td ltx_border_tt" id="S2.T1.2.2.3.1.4"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S2.T1.2.2.3.1.5">
<span class="ltx_text ltx_font_bold" id="S2.T1.2.2.3.1.5.1">AudioCaps</span> (%)</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.4.2">
<td class="ltx_td" id="S2.T1.2.2.4.2.1"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.2">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.3">CIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.4">SPICE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.5">SPIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.6">FENSE</td>
<td class="ltx_td" id="S2.T1.2.2.4.2.7"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.8">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.9">CIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.10">SPICE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.11">SPIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.4.2.12">FENSE</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.5.3" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="13" id="S2.T1.2.2.5.3.1"><span class="ltx_text ltx_font_italic" id="S2.T1.2.2.5.3.1.1" style="background-color:#F2F2F2;">Fully Supervised Audio Captioning</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.6.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.1">Prefix AAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib4" title="">4</a>]</cite>
</td>
<td class="ltx_td ltx_border_t" id="S2.T1.2.2.6.4.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.3">17.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.4">39.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.5">11.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.6">25.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.7">-</td>
<td class="ltx_td ltx_border_t" id="S2.T1.2.2.6.4.8"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.9">24.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.10">73.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.11">17.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.12">45.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.6.4.13">-</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.7.5">
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.1">RECAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib6" title="">6</a>]</cite>
</td>
<td class="ltx_td" id="S2.T1.2.2.7.5.2"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.3">17.7</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.4">41.1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.5">12.5</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.6">22.4</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.7">-</td>
<td class="ltx_td" id="S2.T1.2.2.7.5.8"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.9"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.7.5.9.1">25.6</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.10">75.1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.11">18.6</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.12">47.1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.7.5.13">-</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.2">
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.3">EnCLAP-large <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib28" title="">28</a>]</cite>
</td>
<td class="ltx_td" id="S2.T1.2.2.2.4"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.5.1">18.2</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.6"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.6.1">42.6</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.7"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.7.1">12.9</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.8"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.8.1">27.8</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1">50.7<sup class="ltx_sup" id="S2.T1.1.1.1.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S2.T1.1.1.1.1.1.1.1">a</span></sup></span></td>
<td class="ltx_td" id="S2.T1.2.2.2.9"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.10">25.5</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.11"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.11.1">80.3</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.12"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.12.1">18.8</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.13"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.13.1">49.5</span></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.2.2.1">65.5<sup class="ltx_sup" id="S2.T1.2.2.2.2.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S2.T1.2.2.2.2.1.1.1">a</span></sup></span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.8.6" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="13" id="S2.T1.2.2.8.6.1"><span class="ltx_text ltx_font_italic" id="S2.T1.2.2.8.6.1.1" style="background-color:#F2F2F2;">Zero-shot Audio Captioning</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.9.7">
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.1">ZerAuCap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib18" title="">18</a>]</cite>
</td>
<td class="ltx_td ltx_border_t" id="S2.T1.2.2.9.7.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.3">9.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.4">14.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.5">5.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.6">9.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.7">-</td>
<td class="ltx_td ltx_border_t" id="S2.T1.2.2.9.7.8"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.9">12.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.10">28.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.11">8.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.12">18.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.9.7.13">-</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.10.8">
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.1">WSAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib17" title="">17</a>]</cite>
</td>
<td class="ltx_td" id="S2.T1.2.2.10.8.2"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.3">17.4</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.4">37.1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.5">12.3</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.6">24.7</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.7">-</td>
<td class="ltx_td" id="S2.T1.2.2.10.8.8"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.9">24.1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.10">63.3</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.11">17.3</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.12">40.3</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.10.8.13">-</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.11.9">
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.1">Zhang <span class="ltx_text ltx_font_italic" id="S2.T1.2.2.11.9.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>]</cite>
</td>
<td class="ltx_td" id="S2.T1.2.2.11.9.2"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.3">17.5</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.4">41.1</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.5">12.2</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.6">26.7</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.7">48.8</td>
<td class="ltx_td" id="S2.T1.2.2.11.9.8"></td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.9">22.0</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.10">64.4</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.11">15.6</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.12">40.0</td>
<td class="ltx_td ltx_align_center" id="S2.T1.2.2.11.9.13">-</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.2.12.10">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.1">DRCap (ours)</td>
<td class="ltx_td ltx_border_bb" id="S2.T1.2.2.12.10.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.3"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.3.1">18.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.4"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.4.1">43.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.5"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.5.1">13.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.6"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.6.1">28.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.7"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.7.1">53.0</span></td>
<td class="ltx_td ltx_border_bb" id="S2.T1.2.2.12.10.8"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.9"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.9.1">25.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.10"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.10.1">71.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.11"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.11.1">18.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.12"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.12.1">45.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.2.2.12.10.13"><span class="ltx_text ltx_font_bold" id="S2.T1.2.2.12.10.13.1">65.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><sup class="ltx_sup" id="S2.I1.i1.p1.1.1"><span class="ltx_text ltx_font_italic" id="S2.I1.i1.p1.1.1.1" style="font-size:80%;">a</span></sup><span class="ltx_text" id="S2.I1.i1.p1.1.2" style="font-size:80%;">: We evaluated metrics not reported in the original papers using the officially released checkpoint.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.5.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.6.2">Projection-based Decoding </span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.9">Moreover, during inference, instead of directly feeding the audio embedding <math alttext="E_{a}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><msub id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><mi id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">E</mi><mi id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">ğ¸</ci><ci id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">E_{a}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> to the linear mapper <math alttext="m" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">italic_m</annotation></semantics></math>, we first project it into the text embedding space of the CLAP model.
Assuming that the system is trained on a caption corpus <math alttext="\mathcal{T}=\{t_{1},t_{2},...,t_{N}\}" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m3.4"><semantics id="S2.SS3.p1.3.m3.4a"><mrow id="S2.SS3.p1.3.m3.4.4" xref="S2.SS3.p1.3.m3.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.3.m3.4.4.5" xref="S2.SS3.p1.3.m3.4.4.5.cmml">ğ’¯</mi><mo id="S2.SS3.p1.3.m3.4.4.4" xref="S2.SS3.p1.3.m3.4.4.4.cmml">=</mo><mrow id="S2.SS3.p1.3.m3.4.4.3.3" xref="S2.SS3.p1.3.m3.4.4.3.4.cmml"><mo id="S2.SS3.p1.3.m3.4.4.3.3.4" stretchy="false" xref="S2.SS3.p1.3.m3.4.4.3.4.cmml">{</mo><msub id="S2.SS3.p1.3.m3.2.2.1.1.1" xref="S2.SS3.p1.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS3.p1.3.m3.2.2.1.1.1.2" xref="S2.SS3.p1.3.m3.2.2.1.1.1.2.cmml">t</mi><mn id="S2.SS3.p1.3.m3.2.2.1.1.1.3" xref="S2.SS3.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.p1.3.m3.4.4.3.3.5" xref="S2.SS3.p1.3.m3.4.4.3.4.cmml">,</mo><msub id="S2.SS3.p1.3.m3.3.3.2.2.2" xref="S2.SS3.p1.3.m3.3.3.2.2.2.cmml"><mi id="S2.SS3.p1.3.m3.3.3.2.2.2.2" xref="S2.SS3.p1.3.m3.3.3.2.2.2.2.cmml">t</mi><mn id="S2.SS3.p1.3.m3.3.3.2.2.2.3" xref="S2.SS3.p1.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS3.p1.3.m3.4.4.3.3.6" xref="S2.SS3.p1.3.m3.4.4.3.4.cmml">,</mo><mi id="S2.SS3.p1.3.m3.1.1" mathvariant="normal" xref="S2.SS3.p1.3.m3.1.1.cmml">â€¦</mi><mo id="S2.SS3.p1.3.m3.4.4.3.3.7" xref="S2.SS3.p1.3.m3.4.4.3.4.cmml">,</mo><msub id="S2.SS3.p1.3.m3.4.4.3.3.3" xref="S2.SS3.p1.3.m3.4.4.3.3.3.cmml"><mi id="S2.SS3.p1.3.m3.4.4.3.3.3.2" xref="S2.SS3.p1.3.m3.4.4.3.3.3.2.cmml">t</mi><mi id="S2.SS3.p1.3.m3.4.4.3.3.3.3" xref="S2.SS3.p1.3.m3.4.4.3.3.3.3.cmml">N</mi></msub><mo id="S2.SS3.p1.3.m3.4.4.3.3.8" stretchy="false" xref="S2.SS3.p1.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.4b"><apply id="S2.SS3.p1.3.m3.4.4.cmml" xref="S2.SS3.p1.3.m3.4.4"><eq id="S2.SS3.p1.3.m3.4.4.4.cmml" xref="S2.SS3.p1.3.m3.4.4.4"></eq><ci id="S2.SS3.p1.3.m3.4.4.5.cmml" xref="S2.SS3.p1.3.m3.4.4.5">ğ’¯</ci><set id="S2.SS3.p1.3.m3.4.4.3.4.cmml" xref="S2.SS3.p1.3.m3.4.4.3.3"><apply id="S2.SS3.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS3.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS3.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS3.p1.3.m3.2.2.1.1.1.2">ğ‘¡</ci><cn id="S2.SS3.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS3.p1.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS3.p1.3.m3.3.3.2.2.2.cmml" xref="S2.SS3.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS3.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS3.p1.3.m3.3.3.2.2.2.2">ğ‘¡</ci><cn id="S2.SS3.p1.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS3.p1.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">â€¦</ci><apply id="S2.SS3.p1.3.m3.4.4.3.3.3.cmml" xref="S2.SS3.p1.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.4.4.3.3.3.1.cmml" xref="S2.SS3.p1.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S2.SS3.p1.3.m3.4.4.3.3.3.2.cmml" xref="S2.SS3.p1.3.m3.4.4.3.3.3.2">ğ‘¡</ci><ci id="S2.SS3.p1.3.m3.4.4.3.3.3.3.cmml" xref="S2.SS3.p1.3.m3.4.4.3.3.3.3">ğ‘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.4c">\mathcal{T}=\{t_{1},t_{2},...,t_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.3.m3.4d">caligraphic_T = { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_t start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="N" class="ltx_Math" display="inline" id="S2.SS3.p1.4.m4.1"><semantics id="S2.SS3.p1.4.m4.1a"><mi id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><ci id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.4.m4.1d">italic_N</annotation></semantics></math> denotes the size of <math alttext="\mathcal{T}" class="ltx_Math" display="inline" id="S2.SS3.p1.5.m5.1"><semantics id="S2.SS3.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.5.m5.1.1" xref="S2.SS3.p1.5.m5.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.1b"><ci id="S2.SS3.p1.5.m5.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.1c">\mathcal{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.5.m5.1d">caligraphic_T</annotation></semantics></math>. We can accumulate the text embeddings used during training, creating an embedding support <math alttext="\mathcal{S}=\{E_{1},E_{2},...,E_{N}\}" class="ltx_Math" display="inline" id="S2.SS3.p1.6.m6.4"><semantics id="S2.SS3.p1.6.m6.4a"><mrow id="S2.SS3.p1.6.m6.4.4" xref="S2.SS3.p1.6.m6.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.6.m6.4.4.5" xref="S2.SS3.p1.6.m6.4.4.5.cmml">ğ’®</mi><mo id="S2.SS3.p1.6.m6.4.4.4" xref="S2.SS3.p1.6.m6.4.4.4.cmml">=</mo><mrow id="S2.SS3.p1.6.m6.4.4.3.3" xref="S2.SS3.p1.6.m6.4.4.3.4.cmml"><mo id="S2.SS3.p1.6.m6.4.4.3.3.4" stretchy="false" xref="S2.SS3.p1.6.m6.4.4.3.4.cmml">{</mo><msub id="S2.SS3.p1.6.m6.2.2.1.1.1" xref="S2.SS3.p1.6.m6.2.2.1.1.1.cmml"><mi id="S2.SS3.p1.6.m6.2.2.1.1.1.2" xref="S2.SS3.p1.6.m6.2.2.1.1.1.2.cmml">E</mi><mn id="S2.SS3.p1.6.m6.2.2.1.1.1.3" xref="S2.SS3.p1.6.m6.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.p1.6.m6.4.4.3.3.5" xref="S2.SS3.p1.6.m6.4.4.3.4.cmml">,</mo><msub id="S2.SS3.p1.6.m6.3.3.2.2.2" xref="S2.SS3.p1.6.m6.3.3.2.2.2.cmml"><mi id="S2.SS3.p1.6.m6.3.3.2.2.2.2" xref="S2.SS3.p1.6.m6.3.3.2.2.2.2.cmml">E</mi><mn id="S2.SS3.p1.6.m6.3.3.2.2.2.3" xref="S2.SS3.p1.6.m6.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS3.p1.6.m6.4.4.3.3.6" xref="S2.SS3.p1.6.m6.4.4.3.4.cmml">,</mo><mi id="S2.SS3.p1.6.m6.1.1" mathvariant="normal" xref="S2.SS3.p1.6.m6.1.1.cmml">â€¦</mi><mo id="S2.SS3.p1.6.m6.4.4.3.3.7" xref="S2.SS3.p1.6.m6.4.4.3.4.cmml">,</mo><msub id="S2.SS3.p1.6.m6.4.4.3.3.3" xref="S2.SS3.p1.6.m6.4.4.3.3.3.cmml"><mi id="S2.SS3.p1.6.m6.4.4.3.3.3.2" xref="S2.SS3.p1.6.m6.4.4.3.3.3.2.cmml">E</mi><mi id="S2.SS3.p1.6.m6.4.4.3.3.3.3" xref="S2.SS3.p1.6.m6.4.4.3.3.3.3.cmml">N</mi></msub><mo id="S2.SS3.p1.6.m6.4.4.3.3.8" stretchy="false" xref="S2.SS3.p1.6.m6.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.4b"><apply id="S2.SS3.p1.6.m6.4.4.cmml" xref="S2.SS3.p1.6.m6.4.4"><eq id="S2.SS3.p1.6.m6.4.4.4.cmml" xref="S2.SS3.p1.6.m6.4.4.4"></eq><ci id="S2.SS3.p1.6.m6.4.4.5.cmml" xref="S2.SS3.p1.6.m6.4.4.5">ğ’®</ci><set id="S2.SS3.p1.6.m6.4.4.3.4.cmml" xref="S2.SS3.p1.6.m6.4.4.3.3"><apply id="S2.SS3.p1.6.m6.2.2.1.1.1.cmml" xref="S2.SS3.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.6.m6.2.2.1.1.1.1.cmml" xref="S2.SS3.p1.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.6.m6.2.2.1.1.1.2.cmml" xref="S2.SS3.p1.6.m6.2.2.1.1.1.2">ğ¸</ci><cn id="S2.SS3.p1.6.m6.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS3.p1.6.m6.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS3.p1.6.m6.3.3.2.2.2.cmml" xref="S2.SS3.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p1.6.m6.3.3.2.2.2.1.cmml" xref="S2.SS3.p1.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S2.SS3.p1.6.m6.3.3.2.2.2.2.cmml" xref="S2.SS3.p1.6.m6.3.3.2.2.2.2">ğ¸</ci><cn id="S2.SS3.p1.6.m6.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS3.p1.6.m6.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS3.p1.6.m6.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1">â€¦</ci><apply id="S2.SS3.p1.6.m6.4.4.3.3.3.cmml" xref="S2.SS3.p1.6.m6.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p1.6.m6.4.4.3.3.3.1.cmml" xref="S2.SS3.p1.6.m6.4.4.3.3.3">subscript</csymbol><ci id="S2.SS3.p1.6.m6.4.4.3.3.3.2.cmml" xref="S2.SS3.p1.6.m6.4.4.3.3.3.2">ğ¸</ci><ci id="S2.SS3.p1.6.m6.4.4.3.3.3.3.cmml" xref="S2.SS3.p1.6.m6.4.4.3.3.3.3">ğ‘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.4c">\mathcal{S}=\{E_{1},E_{2},...,E_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.6.m6.4d">caligraphic_S = { italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_E start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="E_{i}=f_{t}(t_{i})" class="ltx_Math" display="inline" id="S2.SS3.p1.7.m7.1"><semantics id="S2.SS3.p1.7.m7.1a"><mrow id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml"><msub id="S2.SS3.p1.7.m7.1.1.3" xref="S2.SS3.p1.7.m7.1.1.3.cmml"><mi id="S2.SS3.p1.7.m7.1.1.3.2" xref="S2.SS3.p1.7.m7.1.1.3.2.cmml">E</mi><mi id="S2.SS3.p1.7.m7.1.1.3.3" xref="S2.SS3.p1.7.m7.1.1.3.3.cmml">i</mi></msub><mo id="S2.SS3.p1.7.m7.1.1.2" xref="S2.SS3.p1.7.m7.1.1.2.cmml">=</mo><mrow id="S2.SS3.p1.7.m7.1.1.1" xref="S2.SS3.p1.7.m7.1.1.1.cmml"><msub id="S2.SS3.p1.7.m7.1.1.1.3" xref="S2.SS3.p1.7.m7.1.1.1.3.cmml"><mi id="S2.SS3.p1.7.m7.1.1.1.3.2" xref="S2.SS3.p1.7.m7.1.1.1.3.2.cmml">f</mi><mi id="S2.SS3.p1.7.m7.1.1.1.3.3" xref="S2.SS3.p1.7.m7.1.1.1.3.3.cmml">t</mi></msub><mo id="S2.SS3.p1.7.m7.1.1.1.2" xref="S2.SS3.p1.7.m7.1.1.1.2.cmml">â¢</mo><mrow id="S2.SS3.p1.7.m7.1.1.1.1.1" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.cmml"><mo id="S2.SS3.p1.7.m7.1.1.1.1.1.2" stretchy="false" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS3.p1.7.m7.1.1.1.1.1.1" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.cmml"><mi id="S2.SS3.p1.7.m7.1.1.1.1.1.1.2" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.2.cmml">t</mi><mi id="S2.SS3.p1.7.m7.1.1.1.1.1.1.3" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS3.p1.7.m7.1.1.1.1.1.3" stretchy="false" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.1b"><apply id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1"><eq id="S2.SS3.p1.7.m7.1.1.2.cmml" xref="S2.SS3.p1.7.m7.1.1.2"></eq><apply id="S2.SS3.p1.7.m7.1.1.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.3.1.cmml" xref="S2.SS3.p1.7.m7.1.1.3">subscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.3.2.cmml" xref="S2.SS3.p1.7.m7.1.1.3.2">ğ¸</ci><ci id="S2.SS3.p1.7.m7.1.1.3.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3">ğ‘–</ci></apply><apply id="S2.SS3.p1.7.m7.1.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1.1"><times id="S2.SS3.p1.7.m7.1.1.1.2.cmml" xref="S2.SS3.p1.7.m7.1.1.1.2"></times><apply id="S2.SS3.p1.7.m7.1.1.1.3.cmml" xref="S2.SS3.p1.7.m7.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.1.3.1.cmml" xref="S2.SS3.p1.7.m7.1.1.1.3">subscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.1.3.2.cmml" xref="S2.SS3.p1.7.m7.1.1.1.3.2">ğ‘“</ci><ci id="S2.SS3.p1.7.m7.1.1.1.3.3.cmml" xref="S2.SS3.p1.7.m7.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.SS3.p1.7.m7.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.1.1.1.1.2.cmml" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="S2.SS3.p1.7.m7.1.1.1.1.1.1.3.cmml" xref="S2.SS3.p1.7.m7.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.1c">E_{i}=f_{t}(t_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.7.m7.1d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. For a given audio embedding <math alttext="E_{a}" class="ltx_Math" display="inline" id="S2.SS3.p1.8.m8.1"><semantics id="S2.SS3.p1.8.m8.1a"><msub id="S2.SS3.p1.8.m8.1.1" xref="S2.SS3.p1.8.m8.1.1.cmml"><mi id="S2.SS3.p1.8.m8.1.1.2" xref="S2.SS3.p1.8.m8.1.1.2.cmml">E</mi><mi id="S2.SS3.p1.8.m8.1.1.3" xref="S2.SS3.p1.8.m8.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m8.1b"><apply id="S2.SS3.p1.8.m8.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.8.m8.1.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS3.p1.8.m8.1.1.2.cmml" xref="S2.SS3.p1.8.m8.1.1.2">ğ¸</ci><ci id="S2.SS3.p1.8.m8.1.1.3.cmml" xref="S2.SS3.p1.8.m8.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.8.m8.1c">E_{a}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.8.m8.1d">italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>, its corresponding projected text-like embedding <math alttext="E_{t}^{\prime}" class="ltx_Math" display="inline" id="S2.SS3.p1.9.m9.1"><semantics id="S2.SS3.p1.9.m9.1a"><msubsup id="S2.SS3.p1.9.m9.1.1" xref="S2.SS3.p1.9.m9.1.1.cmml"><mi id="S2.SS3.p1.9.m9.1.1.2.2" xref="S2.SS3.p1.9.m9.1.1.2.2.cmml">E</mi><mi id="S2.SS3.p1.9.m9.1.1.2.3" xref="S2.SS3.p1.9.m9.1.1.2.3.cmml">t</mi><mo id="S2.SS3.p1.9.m9.1.1.3" xref="S2.SS3.p1.9.m9.1.1.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m9.1b"><apply id="S2.SS3.p1.9.m9.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.1.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1">superscript</csymbol><apply id="S2.SS3.p1.9.m9.1.1.2.cmml" xref="S2.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.1.1.2.1.cmml" xref="S2.SS3.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS3.p1.9.m9.1.1.2.2.cmml" xref="S2.SS3.p1.9.m9.1.1.2.2">ğ¸</ci><ci id="S2.SS3.p1.9.m9.1.1.2.3.cmml" xref="S2.SS3.p1.9.m9.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.SS3.p1.9.m9.1.1.3.cmml" xref="S2.SS3.p1.9.m9.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.9.m9.1c">E_{t}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.9.m9.1d">italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> could be obtained by performing a weighted combination of the text embeddings within the support:</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S2.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E_{t}^{\prime}=\sum_{i=1}^{N}\frac{\exp\left((E_{a}^{\top}\cdot E_{i})/\tau%
\right)}{\sum_{j=1}^{N}\exp\left((E_{a}^{\top}\cdot E_{j})/\tau\right)}\cdot E%
_{i}" class="ltx_Math" display="block" id="S2.E4.m1.4"><semantics id="S2.E4.m1.4a"><mrow id="S2.E4.m1.4.5" xref="S2.E4.m1.4.5.cmml"><msubsup id="S2.E4.m1.4.5.2" xref="S2.E4.m1.4.5.2.cmml"><mi id="S2.E4.m1.4.5.2.2.2" xref="S2.E4.m1.4.5.2.2.2.cmml">E</mi><mi id="S2.E4.m1.4.5.2.2.3" xref="S2.E4.m1.4.5.2.2.3.cmml">t</mi><mo id="S2.E4.m1.4.5.2.3" xref="S2.E4.m1.4.5.2.3.cmml">â€²</mo></msubsup><mo id="S2.E4.m1.4.5.1" rspace="0.111em" xref="S2.E4.m1.4.5.1.cmml">=</mo><mrow id="S2.E4.m1.4.5.3" xref="S2.E4.m1.4.5.3.cmml"><munderover id="S2.E4.m1.4.5.3.1" xref="S2.E4.m1.4.5.3.1.cmml"><mo id="S2.E4.m1.4.5.3.1.2.2" movablelimits="false" xref="S2.E4.m1.4.5.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E4.m1.4.5.3.1.2.3" xref="S2.E4.m1.4.5.3.1.2.3.cmml"><mi id="S2.E4.m1.4.5.3.1.2.3.2" xref="S2.E4.m1.4.5.3.1.2.3.2.cmml">i</mi><mo id="S2.E4.m1.4.5.3.1.2.3.1" xref="S2.E4.m1.4.5.3.1.2.3.1.cmml">=</mo><mn id="S2.E4.m1.4.5.3.1.2.3.3" xref="S2.E4.m1.4.5.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E4.m1.4.5.3.1.3" xref="S2.E4.m1.4.5.3.1.3.cmml">N</mi></munderover><mrow id="S2.E4.m1.4.5.3.2" xref="S2.E4.m1.4.5.3.2.cmml"><mfrac id="S2.E4.m1.4.4" xref="S2.E4.m1.4.4.cmml"><mrow id="S2.E4.m1.2.2.2.2" xref="S2.E4.m1.2.2.2.3.cmml"><mi id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">exp</mi><mo id="S2.E4.m1.2.2.2.2a" xref="S2.E4.m1.2.2.2.3.cmml">â¡</mo><mrow id="S2.E4.m1.2.2.2.2.1" xref="S2.E4.m1.2.2.2.3.cmml"><mo id="S2.E4.m1.2.2.2.2.1.2" xref="S2.E4.m1.2.2.2.3.cmml">(</mo><mrow id="S2.E4.m1.2.2.2.2.1.1" xref="S2.E4.m1.2.2.2.2.1.1.cmml"><mrow id="S2.E4.m1.2.2.2.2.1.1.1.1" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.cmml"><mo id="S2.E4.m1.2.2.2.2.1.1.1.1.2" stretchy="false" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.2.2.2.2.1.1.1.1.1" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.cmml"><msubsup id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.cmml"><mi id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.2" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.2.cmml">E</mi><mi id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.3" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.3.cmml">a</mi><mo id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.3" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.3.cmml">âŠ¤</mo></msubsup><mo id="S2.E4.m1.2.2.2.2.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.1.cmml">â‹…</mo><msub id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.2" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.2.cmml">E</mi><mi id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.3" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.E4.m1.2.2.2.2.1.1.1.1.3" stretchy="false" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E4.m1.2.2.2.2.1.1.2" xref="S2.E4.m1.2.2.2.2.1.1.2.cmml">/</mo><mi id="S2.E4.m1.2.2.2.2.1.1.3" xref="S2.E4.m1.2.2.2.2.1.1.3.cmml">Ï„</mi></mrow><mo id="S2.E4.m1.2.2.2.2.1.3" xref="S2.E4.m1.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S2.E4.m1.4.4.4" xref="S2.E4.m1.4.4.4.cmml"><msubsup id="S2.E4.m1.4.4.4.3" xref="S2.E4.m1.4.4.4.3.cmml"><mo id="S2.E4.m1.4.4.4.3.2.2" xref="S2.E4.m1.4.4.4.3.2.2.cmml">âˆ‘</mo><mrow id="S2.E4.m1.4.4.4.3.2.3" xref="S2.E4.m1.4.4.4.3.2.3.cmml"><mi id="S2.E4.m1.4.4.4.3.2.3.2" xref="S2.E4.m1.4.4.4.3.2.3.2.cmml">j</mi><mo id="S2.E4.m1.4.4.4.3.2.3.1" xref="S2.E4.m1.4.4.4.3.2.3.1.cmml">=</mo><mn id="S2.E4.m1.4.4.4.3.2.3.3" xref="S2.E4.m1.4.4.4.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E4.m1.4.4.4.3.3" xref="S2.E4.m1.4.4.4.3.3.cmml">N</mi></msubsup><mrow id="S2.E4.m1.4.4.4.2.1" xref="S2.E4.m1.4.4.4.2.2.cmml"><mi id="S2.E4.m1.3.3.3.1" xref="S2.E4.m1.3.3.3.1.cmml">exp</mi><mo id="S2.E4.m1.4.4.4.2.1a" xref="S2.E4.m1.4.4.4.2.2.cmml">â¡</mo><mrow id="S2.E4.m1.4.4.4.2.1.1" xref="S2.E4.m1.4.4.4.2.2.cmml"><mo id="S2.E4.m1.4.4.4.2.1.1.2" xref="S2.E4.m1.4.4.4.2.2.cmml">(</mo><mrow id="S2.E4.m1.4.4.4.2.1.1.1" xref="S2.E4.m1.4.4.4.2.1.1.1.cmml"><mrow id="S2.E4.m1.4.4.4.2.1.1.1.1.1" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.cmml"><mo id="S2.E4.m1.4.4.4.2.1.1.1.1.1.2" stretchy="false" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.cmml"><msubsup id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.cmml"><mi id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.2" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.2.cmml">E</mi><mi id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.3" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.3.cmml">a</mi><mo id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.3" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.3.cmml">âŠ¤</mo></msubsup><mo id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.1.cmml">â‹…</mo><msub id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.2" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.2.cmml">E</mi><mi id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.3" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S2.E4.m1.4.4.4.2.1.1.1.1.1.3" stretchy="false" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E4.m1.4.4.4.2.1.1.1.2" xref="S2.E4.m1.4.4.4.2.1.1.1.2.cmml">/</mo><mi id="S2.E4.m1.4.4.4.2.1.1.1.3" xref="S2.E4.m1.4.4.4.2.1.1.1.3.cmml">Ï„</mi></mrow><mo id="S2.E4.m1.4.4.4.2.1.1.3" xref="S2.E4.m1.4.4.4.2.2.cmml">)</mo></mrow></mrow></mrow></mfrac><mo id="S2.E4.m1.4.5.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.E4.m1.4.5.3.2.1.cmml">â‹…</mo><msub id="S2.E4.m1.4.5.3.2.2" xref="S2.E4.m1.4.5.3.2.2.cmml"><mi id="S2.E4.m1.4.5.3.2.2.2" xref="S2.E4.m1.4.5.3.2.2.2.cmml">E</mi><mi id="S2.E4.m1.4.5.3.2.2.3" xref="S2.E4.m1.4.5.3.2.2.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.4b"><apply id="S2.E4.m1.4.5.cmml" xref="S2.E4.m1.4.5"><eq id="S2.E4.m1.4.5.1.cmml" xref="S2.E4.m1.4.5.1"></eq><apply id="S2.E4.m1.4.5.2.cmml" xref="S2.E4.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.5.2.1.cmml" xref="S2.E4.m1.4.5.2">superscript</csymbol><apply id="S2.E4.m1.4.5.2.2.cmml" xref="S2.E4.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.5.2.2.1.cmml" xref="S2.E4.m1.4.5.2">subscript</csymbol><ci id="S2.E4.m1.4.5.2.2.2.cmml" xref="S2.E4.m1.4.5.2.2.2">ğ¸</ci><ci id="S2.E4.m1.4.5.2.2.3.cmml" xref="S2.E4.m1.4.5.2.2.3">ğ‘¡</ci></apply><ci id="S2.E4.m1.4.5.2.3.cmml" xref="S2.E4.m1.4.5.2.3">â€²</ci></apply><apply id="S2.E4.m1.4.5.3.cmml" xref="S2.E4.m1.4.5.3"><apply id="S2.E4.m1.4.5.3.1.cmml" xref="S2.E4.m1.4.5.3.1"><csymbol cd="ambiguous" id="S2.E4.m1.4.5.3.1.1.cmml" xref="S2.E4.m1.4.5.3.1">superscript</csymbol><apply id="S2.E4.m1.4.5.3.1.2.cmml" xref="S2.E4.m1.4.5.3.1"><csymbol cd="ambiguous" id="S2.E4.m1.4.5.3.1.2.1.cmml" xref="S2.E4.m1.4.5.3.1">subscript</csymbol><sum id="S2.E4.m1.4.5.3.1.2.2.cmml" xref="S2.E4.m1.4.5.3.1.2.2"></sum><apply id="S2.E4.m1.4.5.3.1.2.3.cmml" xref="S2.E4.m1.4.5.3.1.2.3"><eq id="S2.E4.m1.4.5.3.1.2.3.1.cmml" xref="S2.E4.m1.4.5.3.1.2.3.1"></eq><ci id="S2.E4.m1.4.5.3.1.2.3.2.cmml" xref="S2.E4.m1.4.5.3.1.2.3.2">ğ‘–</ci><cn id="S2.E4.m1.4.5.3.1.2.3.3.cmml" type="integer" xref="S2.E4.m1.4.5.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E4.m1.4.5.3.1.3.cmml" xref="S2.E4.m1.4.5.3.1.3">ğ‘</ci></apply><apply id="S2.E4.m1.4.5.3.2.cmml" xref="S2.E4.m1.4.5.3.2"><ci id="S2.E4.m1.4.5.3.2.1.cmml" xref="S2.E4.m1.4.5.3.2.1">â‹…</ci><apply id="S2.E4.m1.4.4.cmml" xref="S2.E4.m1.4.4"><divide id="S2.E4.m1.4.4.5.cmml" xref="S2.E4.m1.4.4"></divide><apply id="S2.E4.m1.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2"><exp id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1"></exp><apply id="S2.E4.m1.2.2.2.2.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1"><divide id="S2.E4.m1.2.2.2.2.1.1.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.2"></divide><apply id="S2.E4.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1"><ci id="S2.E4.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.1">â‹…</ci><apply id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.2">ğ¸</ci><ci id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.2.3">ğ‘</ci></apply><csymbol cd="latexml" id="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.2.3">top</csymbol></apply><apply id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.2">ğ¸</ci><ci id="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply><ci id="S2.E4.m1.2.2.2.2.1.1.3.cmml" xref="S2.E4.m1.2.2.2.2.1.1.3">ğœ</ci></apply></apply><apply id="S2.E4.m1.4.4.4.cmml" xref="S2.E4.m1.4.4.4"><apply id="S2.E4.m1.4.4.4.3.cmml" xref="S2.E4.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.3.1.cmml" xref="S2.E4.m1.4.4.4.3">superscript</csymbol><apply id="S2.E4.m1.4.4.4.3.2.cmml" xref="S2.E4.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.3.2.1.cmml" xref="S2.E4.m1.4.4.4.3">subscript</csymbol><sum id="S2.E4.m1.4.4.4.3.2.2.cmml" xref="S2.E4.m1.4.4.4.3.2.2"></sum><apply id="S2.E4.m1.4.4.4.3.2.3.cmml" xref="S2.E4.m1.4.4.4.3.2.3"><eq id="S2.E4.m1.4.4.4.3.2.3.1.cmml" xref="S2.E4.m1.4.4.4.3.2.3.1"></eq><ci id="S2.E4.m1.4.4.4.3.2.3.2.cmml" xref="S2.E4.m1.4.4.4.3.2.3.2">ğ‘—</ci><cn id="S2.E4.m1.4.4.4.3.2.3.3.cmml" type="integer" xref="S2.E4.m1.4.4.4.3.2.3.3">1</cn></apply></apply><ci id="S2.E4.m1.4.4.4.3.3.cmml" xref="S2.E4.m1.4.4.4.3.3">ğ‘</ci></apply><apply id="S2.E4.m1.4.4.4.2.2.cmml" xref="S2.E4.m1.4.4.4.2.1"><exp id="S2.E4.m1.3.3.3.1.cmml" xref="S2.E4.m1.3.3.3.1"></exp><apply id="S2.E4.m1.4.4.4.2.1.1.1.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1"><divide id="S2.E4.m1.4.4.4.2.1.1.1.2.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.2"></divide><apply id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1"><ci id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.1">â‹…</ci><apply id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.2">ğ¸</ci><ci id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.2.3">ğ‘</ci></apply><csymbol cd="latexml" id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.2.3">top</csymbol></apply><apply id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.2">ğ¸</ci><ci id="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.1.1.1.3.3">ğ‘—</ci></apply></apply><ci id="S2.E4.m1.4.4.4.2.1.1.1.3.cmml" xref="S2.E4.m1.4.4.4.2.1.1.1.3">ğœ</ci></apply></apply></apply></apply><apply id="S2.E4.m1.4.5.3.2.2.cmml" xref="S2.E4.m1.4.5.3.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.4.5.3.2.2.1.cmml" xref="S2.E4.m1.4.5.3.2.2">subscript</csymbol><ci id="S2.E4.m1.4.5.3.2.2.2.cmml" xref="S2.E4.m1.4.5.3.2.2.2">ğ¸</ci><ci id="S2.E4.m1.4.5.3.2.2.3.cmml" xref="S2.E4.m1.4.5.3.2.2.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.4c">E_{t}^{\prime}=\sum_{i=1}^{N}\frac{\exp\left((E_{a}^{\top}\cdot E_{i})/\tau%
\right)}{\sum_{j=1}^{N}\exp\left((E_{a}^{\top}\cdot E_{j})/\tau\right)}\cdot E%
_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.4d">italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT divide start_ARG roman_exp ( ( italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT â‹… italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_Ï„ ) end_ARG start_ARG âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_exp ( ( italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT â‹… italic_E start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) / italic_Ï„ ) end_ARG â‹… italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p2.4">Where <math alttext="\tau" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">italic_Ï„</annotation></semantics></math> is a temperature parameter, the projected vector <math alttext="E_{t}^{\prime}" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.1"><semantics id="S2.SS3.p2.2.m2.1a"><msubsup id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><mi id="S2.SS3.p2.2.m2.1.1.2.2" xref="S2.SS3.p2.2.m2.1.1.2.2.cmml">E</mi><mi id="S2.SS3.p2.2.m2.1.1.2.3" xref="S2.SS3.p2.2.m2.1.1.2.3.cmml">t</mi><mo id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">superscript</csymbol><apply id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2.2">ğ¸</ci><ci id="S2.SS3.p2.2.m2.1.1.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">E_{t}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> can capture the extensive semantic information from the support, while retaining its original acoustic features. <math alttext="E_{t}^{\prime}" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><msubsup id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml"><mi id="S2.SS3.p2.3.m3.1.1.2.2" xref="S2.SS3.p2.3.m3.1.1.2.2.cmml">E</mi><mi id="S2.SS3.p2.3.m3.1.1.2.3" xref="S2.SS3.p2.3.m3.1.1.2.3.cmml">t</mi><mo id="S2.SS3.p2.3.m3.1.1.3" xref="S2.SS3.p2.3.m3.1.1.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">superscript</csymbol><apply id="S2.SS3.p2.3.m3.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.2.1.cmml" xref="S2.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.2.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2.2">ğ¸</ci><ci id="S2.SS3.p2.3.m3.1.1.2.3.cmml" xref="S2.SS3.p2.3.m3.1.1.2.3">ğ‘¡</ci></apply><ci id="S2.SS3.p2.3.m3.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">E_{t}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> is then aligned with the LLM through the linear mapper <math alttext="m" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m4.1"><semantics id="S2.SS3.p2.4.m4.1a"><mi id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><ci id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m4.1d">italic_m</annotation></semantics></math>. Conditioned on both the CLAP embedding and the encoded similar captions, the LLM is able to generate accurate and semantically rich textual descriptions in a zero-shot manner.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS4.5.1.1">II-D</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS4.6.2">Domain Adaptation</span>
</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.6">With the assistance of the text embedding support <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.1"><semantics id="S2.SS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.1b"><ci id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.1.m1.1d">caligraphic_S</annotation></semantics></math> and the caption datastore <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S2.SS4.p1.2.m2.1"><semantics id="S2.SS4.p1.2.m2.1a"><mrow id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.2.m2.1.1.2" xref="S2.SS4.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mo id="S2.SS4.p1.2.m2.1.1.1" xref="S2.SS4.p1.2.m2.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.2.m2.1.1.3" xref="S2.SS4.p1.2.m2.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><apply id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1"><times id="S2.SS4.p1.2.m2.1.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1.1"></times><ci id="S2.SS4.p1.2.m2.1.1.2.cmml" xref="S2.SS4.p1.2.m2.1.1.2">ğ’Ÿ</ci><ci id="S2.SS4.p1.2.m2.1.1.3.cmml" xref="S2.SS4.p1.2.m2.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.2.m2.1d">caligraphic_D caligraphic_S</annotation></semantics></math>, DRCap is capable of generating precise and meaningfully detailed captions. Moreover, the modifiability of both <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS4.p1.3.m3.1"><semantics id="S2.SS4.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.3.m3.1.1" xref="S2.SS4.p1.3.m3.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.3.m3.1b"><ci id="S2.SS4.p1.3.m3.1.1.cmml" xref="S2.SS4.p1.3.m3.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.3.m3.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.3.m3.1d">caligraphic_S</annotation></semantics></math> and <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S2.SS4.p1.4.m4.1"><semantics id="S2.SS4.p1.4.m4.1a"><mrow id="S2.SS4.p1.4.m4.1.1" xref="S2.SS4.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.4.m4.1.1.2" xref="S2.SS4.p1.4.m4.1.1.2.cmml">ğ’Ÿ</mi><mo id="S2.SS4.p1.4.m4.1.1.1" xref="S2.SS4.p1.4.m4.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.4.m4.1.1.3" xref="S2.SS4.p1.4.m4.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.4.m4.1b"><apply id="S2.SS4.p1.4.m4.1.1.cmml" xref="S2.SS4.p1.4.m4.1.1"><times id="S2.SS4.p1.4.m4.1.1.1.cmml" xref="S2.SS4.p1.4.m4.1.1.1"></times><ci id="S2.SS4.p1.4.m4.1.1.2.cmml" xref="S2.SS4.p1.4.m4.1.1.2">ğ’Ÿ</ci><ci id="S2.SS4.p1.4.m4.1.1.3.cmml" xref="S2.SS4.p1.4.m4.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.4.m4.1c">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.4.m4.1d">caligraphic_D caligraphic_S</annotation></semantics></math> provides DRCap with the flexibility to quickly adapt to new domains. When encountering new sound event domains, relevant captions can be integrated into the text embedding support and the datastore. The multi-modal latent space of CLAP could then provide semantically rich projected embeddings to decode, with similar captions guiding the LLM to describe the audio. Notably, no further training is needed for this entire process. The construction of <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S2.SS4.p1.5.m5.1"><semantics id="S2.SS4.p1.5.m5.1a"><mrow id="S2.SS4.p1.5.m5.1.1" xref="S2.SS4.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.5.m5.1.1.2" xref="S2.SS4.p1.5.m5.1.1.2.cmml">ğ’Ÿ</mi><mo id="S2.SS4.p1.5.m5.1.1.1" xref="S2.SS4.p1.5.m5.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.5.m5.1.1.3" xref="S2.SS4.p1.5.m5.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.5.m5.1b"><apply id="S2.SS4.p1.5.m5.1.1.cmml" xref="S2.SS4.p1.5.m5.1.1"><times id="S2.SS4.p1.5.m5.1.1.1.cmml" xref="S2.SS4.p1.5.m5.1.1.1"></times><ci id="S2.SS4.p1.5.m5.1.1.2.cmml" xref="S2.SS4.p1.5.m5.1.1.2">ğ’Ÿ</ci><ci id="S2.SS4.p1.5.m5.1.1.3.cmml" xref="S2.SS4.p1.5.m5.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.5.m5.1c">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.5.m5.1d">caligraphic_D caligraphic_S</annotation></semantics></math> and <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S2.SS4.p1.6.m6.1"><semantics id="S2.SS4.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.6.m6.1.1" xref="S2.SS4.p1.6.m6.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.6.m6.1b"><ci id="S2.SS4.p1.6.m6.1.1.cmml" xref="S2.SS4.p1.6.m6.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.6.m6.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.6.m6.1d">caligraphic_S</annotation></semantics></math> will be discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3.SS2" title="III-B Experimental Setup â€£ III Experimental Settings â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Experimental Settings</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Datasets</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We train and evaluate DRCap on two most widely used AAC datasets, AudioCaps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib29" title="">29</a>]</cite> and Clotho <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib30" title="">30</a>]</cite>. AudioCaps is a subset of AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib31" title="">31</a>]</cite> that has been reannotated with caption labels. Each audio clip is annotated with a single caption for the training set and five captions for the validation and test sets. Our downloaded version contains 49274 examples for the training set, 494 for the validation set, and 957 for the test set.
Clotho consists of audio clips sourced from Freesound, each labeled with 5 captions. In our experiment, we use version 2.1 of Clotho, which contains 3839 examples in the training set, 1045 in the validation set, and 1045 in the test set.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The frozen CLAP model employed to extract audio and text embeddings is trained on WavCaps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib32" title="">32</a>]</cite> and Sound-VECaps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib33" title="">33</a>]</cite>. WavCaps comprises approximately 400k audio clips sourced from AudioSet-SL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib34" title="">34</a>]</cite>, BBC Sound Effects, FreeSound, and SoundBible, while Sound-VECaps contains approximately 1.6M audio clips sourced from AudioSet. Both datasets are weakly annotated with the assistance of ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib35" title="">35</a>]</cite>. We filtered out the audio clips in the dataset that overlap with AudioCaps or Clotho, assuming that the target-domain audio data are unavailable during training.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Performance comparison of AAC models for cross-domain scenarios.
</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S3.T2.4" style="width:433.6pt;height:119.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-112.8pt,30.8pt) scale(0.657758500908749,0.657758500908749) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.2.2.2">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.2.2.2.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.3.1">Method</span></td>
<td class="ltx_td ltx_border_tt" id="S3.T2.2.2.2.4"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T2.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">AudioCaps</span> <math alttext="\Longrightarrow" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T2.1.1.1.1.m1.1.1.cmml">âŸ¹</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">âŸ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\Longrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.m1.1d">âŸ¹</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.2">Clotho</span> (%)</td>
<td class="ltx_td ltx_border_tt" id="S3.T2.2.2.2.5"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S3.T2.2.2.2.2">
<span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.2.1">Clotho</span> <math alttext="\Longrightarrow" class="ltx_Math" display="inline" id="S3.T2.2.2.2.2.m1.1"><semantics id="S3.T2.2.2.2.2.m1.1a"><mo id="S3.T2.2.2.2.2.m1.1.1" stretchy="false" xref="S3.T2.2.2.2.2.m1.1.1.cmml">âŸ¹</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.m1.1b"><ci id="S3.T2.2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.2.m1.1.1">âŸ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.m1.1c">\Longrightarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.2.m1.1d">âŸ¹</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.2.2">AudioCaps</span> (%)</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.5.1">
<td class="ltx_td" id="S3.T2.4.4.5.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.2">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.3">CIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.4">SPICE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.5">SPIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.6">FENSE</td>
<td class="ltx_td" id="S3.T2.4.4.5.1.7"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.8">METEOR</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.9">CIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.10">SPICE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.11">SPIDEr</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.5.1.12">FENSE</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.6.2" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="13" id="S3.T2.4.4.6.2.1"><span class="ltx_text ltx_font_italic" id="S3.T2.4.4.6.2.1.1" style="background-color:#F2F2F2;">Fully Supervised Audio Captioning</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.1">EnCLAP-large<sup class="ltx_sup" id="S3.T2.3.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S3.T2.3.3.3.1.1.1">a</span></sup> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib28" title="">28</a>]</cite>
</td>
<td class="ltx_td ltx_border_t" id="S3.T2.3.3.3.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.3">11.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.4">13.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.5">5.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.6">9.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.7">36.1</td>
<td class="ltx_td ltx_border_t" id="S3.T2.3.3.3.8"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.9">13.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.10">17.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.11">8.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.12">12.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.3.13">38.8</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.7.3">
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.1">Prefix AAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib4" title="">4</a>]</cite>
</td>
<td class="ltx_td" id="S3.T2.4.4.7.3.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.3">11.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.4">19.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.5">7.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.6">13.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.7">-</td>
<td class="ltx_td" id="S3.T2.4.4.7.3.8"></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.9">14.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.10">21.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.11">8.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.12">14.7</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.7.3.13">-</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.8.4">
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.1">RECAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib6" title="">6</a>]</cite>
</td>
<td class="ltx_td" id="S3.T2.4.4.8.4.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.3.1">15.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.4.1">33.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.5"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.5.1">10.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.6"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.6.1">20.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.7">-</td>
<td class="ltx_td" id="S3.T2.4.4.8.4.8"></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.9"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.9.1">16.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.10"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.10.1">35.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.11"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.11.1">11.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.12"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.8.4.12.1">20.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.8.4.13">-</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.9.5" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="13" id="S3.T2.4.4.9.5.1"><span class="ltx_text ltx_font_italic" id="S3.T2.4.4.9.5.1.1" style="background-color:#F2F2F2;">Zero-shot Audio Captioning</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.1">WSAC<sup class="ltx_sup" id="S3.T2.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S3.T2.4.4.4.1.1.1">b</span></sup> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib17" title="">17</a>]</cite>
</td>
<td class="ltx_td ltx_border_t" id="S3.T2.4.4.4.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.3">12.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.4">20.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.5">8.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.6">14.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.7">-</td>
<td class="ltx_td ltx_border_t" id="S3.T2.4.4.4.8"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.9">17.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.10">25.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.11">12.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.12">18.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.4.4.13">-</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.10.6">
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.1">Zhang <span class="ltx_text ltx_font_italic" id="S3.T2.4.4.10.6.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>]</cite>
</td>
<td class="ltx_td" id="S3.T2.4.4.10.6.2"></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.3">13.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.4">24.8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.5">9.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.6">17.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.7">-</td>
<td class="ltx_td" id="S3.T2.4.4.10.6.8"></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.9">18.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.10">33.7</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.11">12.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.12">23.0</td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.10.6.13">52.1</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.11.7">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.1">DRCap</td>
<td class="ltx_td ltx_border_bb" id="S3.T2.4.4.11.7.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.3.1">15.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.4.1">34.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.5"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.5.1">10.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.6"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.6.1">22.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.7"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.7.1">51.7</span></td>
<td class="ltx_td ltx_border_bb" id="S3.T2.4.4.11.7.8"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.9"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.9.1">22.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.10"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.10.1">44.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.11"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.11.1">17.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.12"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.12.1">30.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.11.7.13"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.11.7.13.1">62.6</span></td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.2"><sup class="ltx_sup" id="S3.I1.i1.p1.2.1"><span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.2.1.1" style="font-size:80%;">a</span></sup><span class="ltx_text" id="S3.I1.i1.p1.2.2" style="font-size:80%;">: Metrics were evaluated on our test split using the officially released checkpoint. </span><sup class="ltx_sup" id="S3.I1.i1.p1.2.3"><span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.2.3.1" style="font-size:80%;">b</span></sup><span class="ltx_text" id="S3.I1.i1.p1.2.4" style="font-size:80%;">: Results are provided by Zhang </span><span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.2.5" style="font-size:80%;">et al.</span><span class="ltx_text" id="S3.I1.i1.p1.2.6" style="font-size:80%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.I1.i1.p1.2.7.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a><span class="ltx_text" id="S3.I1.i1.p1.2.8.2" style="font-size:80%;">]</span></cite><span class="ltx_text" id="S3.I1.i1.p1.2.9" style="font-size:80%;"> based on their re-implementation.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Experimental Setup</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.7">To evaluate the comprehensive performance of DRCap, we conduct experiments in both in-domain and cross-domain setups: (1) We train and evaluate the model on the same dataset <math alttext="\mathcal{D}_{source}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">s</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1a" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.4" xref="S3.SS2.p1.1.m1.1.1.3.4.cmml">u</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1b" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.5" xref="S3.SS2.p1.1.m1.1.1.3.5.cmml">r</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1c" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.6" xref="S3.SS2.p1.1.m1.1.1.3.6.cmml">c</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1d" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.7" xref="S3.SS2.p1.1.m1.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ’Ÿ</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><times id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.1"></times><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">ğ‘ </ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.p1.1.m1.1.1.3.4.cmml" xref="S3.SS2.p1.1.m1.1.1.3.4">ğ‘¢</ci><ci id="S3.SS2.p1.1.m1.1.1.3.5.cmml" xref="S3.SS2.p1.1.m1.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS2.p1.1.m1.1.1.3.6.cmml" xref="S3.SS2.p1.1.m1.1.1.3.6">ğ‘</ci><ci id="S3.SS2.p1.1.m1.1.1.3.7.cmml" xref="S3.SS2.p1.1.m1.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{D}_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, using the standard split. (2) We train the model on the training set of <math alttext="\mathcal{D}_{source}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.2" xref="S3.SS2.p1.2.m2.1.1.3.2.cmml">s</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.cmml">o</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1a" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.4" xref="S3.SS2.p1.2.m2.1.1.3.4.cmml">u</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1b" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.5" xref="S3.SS2.p1.2.m2.1.1.3.5.cmml">r</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1c" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.6" xref="S3.SS2.p1.2.m2.1.1.3.6.cmml">c</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1d" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.7" xref="S3.SS2.p1.2.m2.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ’Ÿ</ci><apply id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><times id="S3.SS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3.1"></times><ci id="S3.SS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.2">ğ‘ </ci><ci id="S3.SS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.p1.2.m2.1.1.3.4.cmml" xref="S3.SS2.p1.2.m2.1.1.3.4">ğ‘¢</ci><ci id="S3.SS2.p1.2.m2.1.1.3.5.cmml" xref="S3.SS2.p1.2.m2.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS2.p1.2.m2.1.1.3.6.cmml" xref="S3.SS2.p1.2.m2.1.1.3.6">ğ‘</ci><ci id="S3.SS2.p1.2.m2.1.1.3.7.cmml" xref="S3.SS2.p1.2.m2.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathcal{D}_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, and evaluate on the test set of another dataset <math alttext="\mathcal{D}_{target}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml"><mi id="S3.SS2.p1.3.m3.1.1.3.2" xref="S3.SS2.p1.3.m3.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p1.3.m3.1.1.3.1" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.3.m3.1.1.3.3" xref="S3.SS2.p1.3.m3.1.1.3.3.cmml">a</mi><mo id="S3.SS2.p1.3.m3.1.1.3.1a" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.3.m3.1.1.3.4" xref="S3.SS2.p1.3.m3.1.1.3.4.cmml">r</mi><mo id="S3.SS2.p1.3.m3.1.1.3.1b" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.3.m3.1.1.3.5" xref="S3.SS2.p1.3.m3.1.1.3.5.cmml">g</mi><mo id="S3.SS2.p1.3.m3.1.1.3.1c" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.3.m3.1.1.3.6" xref="S3.SS2.p1.3.m3.1.1.3.6.cmml">e</mi><mo id="S3.SS2.p1.3.m3.1.1.3.1d" xref="S3.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.3.m3.1.1.3.7" xref="S3.SS2.p1.3.m3.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğ’Ÿ</ci><apply id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3"><times id="S3.SS2.p1.3.m3.1.1.3.1.cmml" xref="S3.SS2.p1.3.m3.1.1.3.1"></times><ci id="S3.SS2.p1.3.m3.1.1.3.2.cmml" xref="S3.SS2.p1.3.m3.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.p1.3.m3.1.1.3.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3">ğ‘</ci><ci id="S3.SS2.p1.3.m3.1.1.3.4.cmml" xref="S3.SS2.p1.3.m3.1.1.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.p1.3.m3.1.1.3.5.cmml" xref="S3.SS2.p1.3.m3.1.1.3.5">ğ‘”</ci><ci id="S3.SS2.p1.3.m3.1.1.3.6.cmml" xref="S3.SS2.p1.3.m3.1.1.3.6">ğ‘’</ci><ci id="S3.SS2.p1.3.m3.1.1.3.7.cmml" xref="S3.SS2.p1.3.m3.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathcal{D}_{target}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. During inference, for scenario (1), we use all text embeddings accumulated in the training stage as the support <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">caligraphic_S</annotation></semantics></math> mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS3" title="II-C Projection-based Decoding â€£ II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-C</span></span></a>, which corresponds to the text embeddings of all captions in the training set of <math alttext="\mathcal{D}_{source}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.3.2.cmml">s</mi><mo id="S3.SS2.p1.5.m5.1.1.3.1" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.5.m5.1.1.3.3" xref="S3.SS2.p1.5.m5.1.1.3.3.cmml">o</mi><mo id="S3.SS2.p1.5.m5.1.1.3.1a" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.5.m5.1.1.3.4" xref="S3.SS2.p1.5.m5.1.1.3.4.cmml">u</mi><mo id="S3.SS2.p1.5.m5.1.1.3.1b" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.5.m5.1.1.3.5" xref="S3.SS2.p1.5.m5.1.1.3.5.cmml">r</mi><mo id="S3.SS2.p1.5.m5.1.1.3.1c" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.5.m5.1.1.3.6" xref="S3.SS2.p1.5.m5.1.1.3.6.cmml">c</mi><mo id="S3.SS2.p1.5.m5.1.1.3.1d" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.5.m5.1.1.3.7" xref="S3.SS2.p1.5.m5.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">ğ’Ÿ</ci><apply id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3"><times id="S3.SS2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.3.1"></times><ci id="S3.SS2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.3.2">ğ‘ </ci><ci id="S3.SS2.p1.5.m5.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3.3">ğ‘œ</ci><ci id="S3.SS2.p1.5.m5.1.1.3.4.cmml" xref="S3.SS2.p1.5.m5.1.1.3.4">ğ‘¢</ci><ci id="S3.SS2.p1.5.m5.1.1.3.5.cmml" xref="S3.SS2.p1.5.m5.1.1.3.5">ğ‘Ÿ</ci><ci id="S3.SS2.p1.5.m5.1.1.3.6.cmml" xref="S3.SS2.p1.5.m5.1.1.3.6">ğ‘</ci><ci id="S3.SS2.p1.5.m5.1.1.3.7.cmml" xref="S3.SS2.p1.5.m5.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\mathcal{D}_{source}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">caligraphic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>. For (2), we curate the text embedding support by encoding all captions from the training set of <math alttext="\mathcal{D}_{target}" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m6.1"><semantics id="S3.SS2.p1.6.m6.1a"><msub id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml"><mi id="S3.SS2.p1.6.m6.1.1.3.2" xref="S3.SS2.p1.6.m6.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p1.6.m6.1.1.3.1" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.6.m6.1.1.3.3" xref="S3.SS2.p1.6.m6.1.1.3.3.cmml">a</mi><mo id="S3.SS2.p1.6.m6.1.1.3.1a" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.6.m6.1.1.3.4" xref="S3.SS2.p1.6.m6.1.1.3.4.cmml">r</mi><mo id="S3.SS2.p1.6.m6.1.1.3.1b" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.6.m6.1.1.3.5" xref="S3.SS2.p1.6.m6.1.1.3.5.cmml">g</mi><mo id="S3.SS2.p1.6.m6.1.1.3.1c" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.6.m6.1.1.3.6" xref="S3.SS2.p1.6.m6.1.1.3.6.cmml">e</mi><mo id="S3.SS2.p1.6.m6.1.1.3.1d" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p1.6.m6.1.1.3.7" xref="S3.SS2.p1.6.m6.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">ğ’Ÿ</ci><apply id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3"><times id="S3.SS2.p1.6.m6.1.1.3.1.cmml" xref="S3.SS2.p1.6.m6.1.1.3.1"></times><ci id="S3.SS2.p1.6.m6.1.1.3.2.cmml" xref="S3.SS2.p1.6.m6.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.p1.6.m6.1.1.3.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3.3">ğ‘</ci><ci id="S3.SS2.p1.6.m6.1.1.3.4.cmml" xref="S3.SS2.p1.6.m6.1.1.3.4">ğ‘Ÿ</ci><ci id="S3.SS2.p1.6.m6.1.1.3.5.cmml" xref="S3.SS2.p1.6.m6.1.1.3.5">ğ‘”</ci><ci id="S3.SS2.p1.6.m6.1.1.3.6.cmml" xref="S3.SS2.p1.6.m6.1.1.3.6">ğ‘’</ci><ci id="S3.SS2.p1.6.m6.1.1.3.7.cmml" xref="S3.SS2.p1.6.m6.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\mathcal{D}_{target}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m6.1d">caligraphic_D start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. In both settings, we utilize a caption datastore <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m7.1"><semantics id="S3.SS2.p1.7.m7.1a"><mrow id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">ğ’Ÿ</mi><mo id="S3.SS2.p1.7.m7.1.1.1" xref="S3.SS2.p1.7.m7.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><times id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1.1"></times><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">ğ’Ÿ</ci><ci id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m7.1d">caligraphic_D caligraphic_S</annotation></semantics></math> consisting of 450k captions sourced from WavCaps and the training sets of AudioCaps and Clotho.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">In line with other audio captioning research, we use common captioning metrics, including METEOR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib36" title="">36</a>]</cite>, SPICE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib37" title="">37</a>]</cite>, CIDEr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib38" title="">38</a>]</cite>, SPIDEr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib39" title="">39</a>]</cite> and FENSE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib40" title="">40</a>]</cite>. For all metrics, higher scores indicate better performance.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Implementation Details</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">DRCap was trained for 40,000 steps on AudioCaps and 20,000 steps on Clotho, with a peak learning rate of 1e-5, 1000 warm-up steps followed by a linear decay. We use the Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib41" title="">41</a>]</cite> and a batch size of 4. Validation was performed every 1000 steps, where the checkpoint with the lowest validation loss was saved for evaluation. Number of captions retrieved is set to <math alttext="k=3" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">k</mi><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><eq id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></eq><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ‘˜</ci><cn id="S3.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">k=3</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_k = 3</annotation></semantics></math>, and the range of similarity selection is fixed as <math alttext="S_{min}=0.75,\ S_{max}=0.85" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.2"><semantics id="S3.SS3.p1.2.m2.2a"><mrow id="S3.SS3.p1.2.m2.2.2.2" xref="S3.SS3.p1.2.m2.2.2.3.cmml"><mrow id="S3.SS3.p1.2.m2.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.cmml"><msub id="S3.SS3.p1.2.m2.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.2.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.2.cmml">S</mi><mrow id="S3.SS3.p1.2.m2.1.1.1.1.2.3" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.2.3.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.2.cmml">m</mi><mo id="S3.SS3.p1.2.m2.1.1.1.1.2.3.1" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS3.p1.2.m2.1.1.1.1.2.3.3" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.3.cmml">i</mi><mo id="S3.SS3.p1.2.m2.1.1.1.1.2.3.1a" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS3.p1.2.m2.1.1.1.1.2.3.4" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.4.cmml">n</mi></mrow></msub><mo id="S3.SS3.p1.2.m2.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.2.m2.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.3.cmml">0.75</mn></mrow><mo id="S3.SS3.p1.2.m2.2.2.2.3" rspace="0.667em" xref="S3.SS3.p1.2.m2.2.2.3a.cmml">,</mo><mrow id="S3.SS3.p1.2.m2.2.2.2.2" xref="S3.SS3.p1.2.m2.2.2.2.2.cmml"><msub id="S3.SS3.p1.2.m2.2.2.2.2.2" xref="S3.SS3.p1.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.2.m2.2.2.2.2.2.2" xref="S3.SS3.p1.2.m2.2.2.2.2.2.2.cmml">S</mi><mrow id="S3.SS3.p1.2.m2.2.2.2.2.2.3" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.cmml"><mi id="S3.SS3.p1.2.m2.2.2.2.2.2.3.2" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.2.cmml">m</mi><mo id="S3.SS3.p1.2.m2.2.2.2.2.2.3.1" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.1.cmml">â¢</mo><mi id="S3.SS3.p1.2.m2.2.2.2.2.2.3.3" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.3.cmml">a</mi><mo id="S3.SS3.p1.2.m2.2.2.2.2.2.3.1a" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.1.cmml">â¢</mo><mi id="S3.SS3.p1.2.m2.2.2.2.2.2.3.4" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.4.cmml">x</mi></mrow></msub><mo id="S3.SS3.p1.2.m2.2.2.2.2.1" xref="S3.SS3.p1.2.m2.2.2.2.2.1.cmml">=</mo><mn id="S3.SS3.p1.2.m2.2.2.2.2.3" xref="S3.SS3.p1.2.m2.2.2.2.2.3.cmml">0.85</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.2b"><apply id="S3.SS3.p1.2.m2.2.2.3.cmml" xref="S3.SS3.p1.2.m2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.2.2.3a.cmml" xref="S3.SS3.p1.2.m2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS3.p1.2.m2.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1"><eq id="S3.SS3.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1"></eq><apply id="S3.SS3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.2">ğ‘†</ci><apply id="S3.SS3.p1.2.m2.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3"><times id="S3.SS3.p1.2.m2.1.1.1.1.2.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.1"></times><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.2">ğ‘š</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.3">ğ‘–</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.2.3.4.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.2.3.4">ğ‘›</ci></apply></apply><cn id="S3.SS3.p1.2.m2.1.1.1.1.3.cmml" type="float" xref="S3.SS3.p1.2.m2.1.1.1.1.3">0.75</cn></apply><apply id="S3.SS3.p1.2.m2.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2"><eq id="S3.SS3.p1.2.m2.2.2.2.2.1.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.1"></eq><apply id="S3.SS3.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.2">ğ‘†</ci><apply id="S3.SS3.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3"><times id="S3.SS3.p1.2.m2.2.2.2.2.2.3.1.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.1"></times><ci id="S3.SS3.p1.2.m2.2.2.2.2.2.3.2.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.2">ğ‘š</ci><ci id="S3.SS3.p1.2.m2.2.2.2.2.2.3.3.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.3">ğ‘</ci><ci id="S3.SS3.p1.2.m2.2.2.2.2.2.3.4.cmml" xref="S3.SS3.p1.2.m2.2.2.2.2.2.3.4">ğ‘¥</ci></apply></apply><cn id="S3.SS3.p1.2.m2.2.2.2.2.3.cmml" type="float" xref="S3.SS3.p1.2.m2.2.2.2.2.3">0.85</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.2c">S_{min}=0.75,\ S_{max}=0.85</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.2d">italic_S start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT = 0.75 , italic_S start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT = 0.85</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">The CLAP model, which employed the text encoder RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib42" title="">42</a>]</cite> and the audio encoder HTS-AT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib10" title="">10</a>]</cite>, was trained on WavCaps and Sound-VECaps, with a batch size of 256, a peak learning rate of 5e-5 for 15 epochs. Training followed a cosine annealing schedule with a 2-epoch warm-up phase, and the model from the final epoch was used.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">The implementation was based on the open-source project SLAM-LLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib43" title="">43</a>]</cite>. The entire training process was conducted on a single NVIDIA A800 GPU, taking approximately 40 hours for CLAP training and 4 hours for DRCap training.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Results</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Main Results</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.T1" title="TABLE I â€£ II-B Retrieval-augmented Generation â€£ II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">I</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3.T2" title="TABLE II â€£ III-A Datasets â€£ III Experimental Settings â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">II</span></a> present the performance of DRCap in both in-domain and cross-domain settings. We compare DRCapâ€™s performance with fully-supervised AAC models: EnCLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib28" title="">28</a>]</cite>, Prefix-AAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib4" title="">4</a>]</cite>, and RECAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib6" title="">6</a>]</cite>, all of which are open-source and not trained with additional data.
We further compare DRCap with zero-shot audio captioning models ZerAuCap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib18" title="">18</a>]</cite>, WSAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib17" title="">17</a>]</cite> and Zhang <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>]</cite>. ZerAuCap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib18" title="">18</a>]</cite> uses CLAP to guide the LLM to generate descriptions, WSAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib17" title="">17</a>]</cite> trains a text decoder using the prefix language modeling paradigm conditioned on CLAP embeddings, while Zhang <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib16" title="">16</a>]</cite> crafts soft and hard prompts to bridge the modality gap between audio and text embeddings of CLAP.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">DRCap surpasses all competitive zero-shot audio captioning systems for in-domain scenarios by a large margin and is comparable with other fully-supervised methods. For cross-domain scenarios, it achieves state-of-the-art results across all metrics, highlighting its robust domain-transfer capability.
Furthermore, we found that DRCap outperforms other methods in terms of the FENSE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#bib.bib40" title="">40</a>]</cite> score in both two scenarios. We hypothesize that this advantage is due to DRCapâ€™s ability to utilize the semantically rich joint multi-modal space of CLAP, which allows it to generate more refined captions.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Ablation Study</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We conduct a comprehensive ablation study to validate each component of DRCap.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Similarity Selection</span> We turned off the similarity selection discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S2.SS2" title="II-B Retrieval-augmented Generation â€£ II Methods â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-B</span></span></a>, instead selecting the top <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_k</annotation></semantics></math> most similar captions during training.
Since the ground-truth captions are available in the training stage, the retrieved most similar captions closely match the target in both semantics and vocabulary. This could lead the LLM to simply copy one of the retrieved captions with minor changes, trivializing the captioning task. However, during inference, without access to textual information, audio-to-text retrieval struggles to match the quality of text-to-text retrieval, and simply copying the retrieved captions hinders the modelâ€™s performance, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T3" title="TABLE III â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">III</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T4" title="TABLE IV â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">IV</span></a>. Our proposed similarity selection strategy significantly alleviates the learning collapse and compels the LLM to take into account both the CLAP embedding and the retrieved captions, which improves generation quality in both in-domain and cross-domain settings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Retrieval-augmented Generation. </span>We dropped all the similar captions in both the training and inference stages to evaluate the impact of RAG. As illustrated in table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T3" title="TABLE III â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">III</span></a> and table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T4" title="TABLE IV â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">IV</span></a>, conditioning solely on CLAP embeddings results in inferior performance across all metrics in both scenarios, showing the advantage of similar captions in guiding the LLM to generate more accurate descriptions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">LLM Fine-tuning. </span>We froze the LLM during training to conduct the ablation study on LoRA. Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T3" title="TABLE III â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">III</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T4" title="TABLE IV â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">IV</span></a> highlight the significance of efficient LLM fine-tuning. Integrating LoRA adapters proved effective in aligning the CLAP latent space with the LLM.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Ablation Study of DRCap for in-domain scenarios</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S4.T3.2" style="width:433.6pt;height:160.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(46.4pt,-17.1pt) scale(1.27212902052666,1.27212902052666) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.2.2.3.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.1.1">Main Components</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="S4.T3.2.2.3.1.2">
<span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1.2.1">AudioCaps</span> (%)</th>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.2.4.2.1">METEOR</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.2.4.2.2">CIDEr</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.2.4.2.3">SPICE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.2.4.2.4">SPIDEr</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.2.4.2.5">FENSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.2.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.2.2.5.1.1">DRCap</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.5.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.5.1.2.1">25.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.5.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.5.1.3.1">71.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.5.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.5.1.4.1">18.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.5.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.5.1.5.1">45.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.5.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.5.1.6.1">65.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.1.1.1.1">Â Â â€ƒ- w/o SS<sup class="ltx_sup" id="S4.T3.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.1.1.1.1">a</span></sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.2">21.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.3">59.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.4">15.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.5">37.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.1.6">61.8</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.6.2.1">Â Â â€ƒ- w/o RAG</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.2">25.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.3">69.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.4">18.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.5">43.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.6.2.6">65.5</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.2.7.3.1">Â Â â€ƒ- w/o LoRA</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.2">23.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.3">64.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.4">16.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.5">40.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.7.3.6">64.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T3.2.2.2.1">Â Â â€ƒ- w/o PD<sup class="ltx_sup" id="S4.T3.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.1.1.1">b</span></sup>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.2">19.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.3">31.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.4">13.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.5">22.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.2.2.6">55.4</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.2"><sup class="ltx_sup" id="S4.I1.i1.p1.2.1"><span class="ltx_text ltx_font_italic" id="S4.I1.i1.p1.2.1.1" style="font-size:80%;">a</span></sup><span class="ltx_text" id="S4.I1.i1.p1.2.2" style="font-size:80%;">: SS: similarity selection, </span><sup class="ltx_sup" id="S4.I1.i1.p1.2.3"><span class="ltx_text ltx_font_italic" id="S4.I1.i1.p1.2.3.1" style="font-size:80%;">b</span></sup><span class="ltx_text" id="S4.I1.i1.p1.2.4" style="font-size:80%;">: PD: projection-based decoding.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Ablation Study of DRCap for cross-domain scenarios</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S4.T4.4" style="width:433.6pt;height:183.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(46.4pt,-19.6pt) scale(1.27212902052666,1.27212902052666) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T4.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.2.1">Main Components</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="S4.T4.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1.1">AudioCaps <math alttext="\Longrightarrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">âŸ¹</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">âŸ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">\Longrightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.1.m1.1d">âŸ¹</annotation></semantics></math> Clotho</span> (%)</th>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4.5.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.4.5.1.1">METEOR</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.4.5.1.2">CIDEr</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.4.5.1.3">SPICE</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.4.5.1.4">SPIDEr</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.4.5.1.5">FENSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.4.4.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.4.4.6.1.1">DRCap</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.4.6.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.6.1.2.1">15.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.4.6.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.6.1.3.1">34.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.4.6.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.6.1.4.1">10.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.4.6.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.6.1.5.1">22.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.4.6.1.6"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.6.1.6.1">51.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.2.2.2.1">Â Â â€ƒ- w/o SS<sup class="ltx_sup" id="S4.T4.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.2.2.2.1.1.1">a</span></sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.2.2">13.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.2.3">22.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.2.4">8.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.2.5">15.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.2.2.6">46.0</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.4.4.7.2.1">Â Â â€ƒ- w/o RAG</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.7.2.2">14.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.7.2.3">30.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.7.2.4">10.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.7.2.5">20.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.7.2.6">51.3</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.4.4.8.3.1">Â Â â€ƒ- w/o LoRA</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.8.3.2">14.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.8.3.3">29.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.8.3.4">9.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.8.3.5">19.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.8.3.6">51.1</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.3.3.3.1">Â Â â€ƒ- w/o TD<sup class="ltx_sup" id="S4.T4.3.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.3.3.3.1.1.1">b</span></sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3.2">13.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3.3">27.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3.4">9.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3.5">18.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3.6">50.6</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T4.4.4.4.1">Â Â â€ƒ- w/o PD<sup class="ltx_sup" id="S4.T4.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.4.4.4.1.1.1">c</span></sup>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.4.4.2">13.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.4.4.3">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.4.4.4">8.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.4.4.5">15.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.4.4.6">46.4</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.3"><sup class="ltx_sup" id="S4.I2.i1.p1.3.1"><span class="ltx_text ltx_font_italic" id="S4.I2.i1.p1.3.1.1" style="font-size:80%;">a</span></sup><span class="ltx_text" id="S4.I2.i1.p1.3.2" style="font-size:80%;">: SS denotes similarity selection. </span><sup class="ltx_sup" id="S4.I2.i1.p1.3.3"><span class="ltx_text ltx_font_italic" id="S4.I2.i1.p1.3.3.1" style="font-size:80%;">b</span></sup><span class="ltx_text" id="S4.I2.i1.p1.3.4" style="font-size:80%;">: TD denotes target domain information. </span><sup class="ltx_sup" id="S4.I2.i1.p1.3.5"><span class="ltx_text ltx_font_italic" id="S4.I2.i1.p1.3.5.1" style="font-size:80%;">c</span></sup><span class="ltx_text" id="S4.I2.i1.p1.3.6" style="font-size:80%;">: PD denotes projection-based decoding.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.3"><span class="ltx_text ltx_font_bold" id="S4.SS2.p5.3.1">Projection-based Decoding</span>
We directly fed the audio embedding <math alttext="e_{a}" class="ltx_Math" display="inline" id="S4.SS2.p5.1.m1.1"><semantics id="S4.SS2.p5.1.m1.1a"><msub id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml"><mi id="S4.SS2.p5.1.m1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.2.cmml">e</mi><mi id="S4.SS2.p5.1.m1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p5.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.2">ğ‘’</ci><ci id="S4.SS2.p5.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">e_{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.1.m1.1d">italic_e start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> to the linear mapping network <math alttext="m" class="ltx_Math" display="inline" id="S4.SS2.p5.2.m2.1"><semantics id="S4.SS2.p5.2.m2.1a"><mi id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><ci id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">m</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.2.m2.1d">italic_m</annotation></semantics></math> without using projection during inference to assess the benefit of projection-based decoding (PD). As illustrated in table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T3" title="TABLE III â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">III</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T4" title="TABLE IV â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">IV</span></a>, the modality gap caused a significant drop in performance when <math alttext="e_{a}" class="ltx_Math" display="inline" id="S4.SS2.p5.3.m3.1"><semantics id="S4.SS2.p5.3.m3.1a"><msub id="S4.SS2.p5.3.m3.1.1" xref="S4.SS2.p5.3.m3.1.1.cmml"><mi id="S4.SS2.p5.3.m3.1.1.2" xref="S4.SS2.p5.3.m3.1.1.2.cmml">e</mi><mi id="S4.SS2.p5.3.m3.1.1.3" xref="S4.SS2.p5.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m3.1b"><apply id="S4.SS2.p5.3.m3.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.3.m3.1.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p5.3.m3.1.1.2.cmml" xref="S4.SS2.p5.3.m3.1.1.2">ğ‘’</ci><ci id="S4.SS2.p5.3.m3.1.1.3.cmml" xref="S4.SS2.p5.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.3.m3.1c">e_{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.3.m3.1d">italic_e start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> was used directly, while PD effectively bridge the discrepancy between audio and text embeddings.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.5"><span class="ltx_text ltx_font_bold" id="S4.SS2.p6.5.1">Target Domain Information. </span>
In this study, we assume that no prior knowledge of the target domain is provided for cross-domain scenarios. Specifically, during inference, we use captions from the training set of <math alttext="\mathcal{D}_{source}" class="ltx_Math" display="inline" id="S4.SS2.p6.1.m1.1"><semantics id="S4.SS2.p6.1.m1.1a"><msub id="S4.SS2.p6.1.m1.1.1" xref="S4.SS2.p6.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p6.1.m1.1.1.2" xref="S4.SS2.p6.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S4.SS2.p6.1.m1.1.1.3" xref="S4.SS2.p6.1.m1.1.1.3.cmml"><mi id="S4.SS2.p6.1.m1.1.1.3.2" xref="S4.SS2.p6.1.m1.1.1.3.2.cmml">s</mi><mo id="S4.SS2.p6.1.m1.1.1.3.1" xref="S4.SS2.p6.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.1.m1.1.1.3.3" xref="S4.SS2.p6.1.m1.1.1.3.3.cmml">o</mi><mo id="S4.SS2.p6.1.m1.1.1.3.1a" xref="S4.SS2.p6.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.1.m1.1.1.3.4" xref="S4.SS2.p6.1.m1.1.1.3.4.cmml">u</mi><mo id="S4.SS2.p6.1.m1.1.1.3.1b" xref="S4.SS2.p6.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.1.m1.1.1.3.5" xref="S4.SS2.p6.1.m1.1.1.3.5.cmml">r</mi><mo id="S4.SS2.p6.1.m1.1.1.3.1c" xref="S4.SS2.p6.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.1.m1.1.1.3.6" xref="S4.SS2.p6.1.m1.1.1.3.6.cmml">c</mi><mo id="S4.SS2.p6.1.m1.1.1.3.1d" xref="S4.SS2.p6.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.1.m1.1.1.3.7" xref="S4.SS2.p6.1.m1.1.1.3.7.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.m1.1b"><apply id="S4.SS2.p6.1.m1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.1.m1.1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p6.1.m1.1.1.2.cmml" xref="S4.SS2.p6.1.m1.1.1.2">ğ’Ÿ</ci><apply id="S4.SS2.p6.1.m1.1.1.3.cmml" xref="S4.SS2.p6.1.m1.1.1.3"><times id="S4.SS2.p6.1.m1.1.1.3.1.cmml" xref="S4.SS2.p6.1.m1.1.1.3.1"></times><ci id="S4.SS2.p6.1.m1.1.1.3.2.cmml" xref="S4.SS2.p6.1.m1.1.1.3.2">ğ‘ </ci><ci id="S4.SS2.p6.1.m1.1.1.3.3.cmml" xref="S4.SS2.p6.1.m1.1.1.3.3">ğ‘œ</ci><ci id="S4.SS2.p6.1.m1.1.1.3.4.cmml" xref="S4.SS2.p6.1.m1.1.1.3.4">ğ‘¢</ci><ci id="S4.SS2.p6.1.m1.1.1.3.5.cmml" xref="S4.SS2.p6.1.m1.1.1.3.5">ğ‘Ÿ</ci><ci id="S4.SS2.p6.1.m1.1.1.3.6.cmml" xref="S4.SS2.p6.1.m1.1.1.3.6">ğ‘</ci><ci id="S4.SS2.p6.1.m1.1.1.3.7.cmml" xref="S4.SS2.p6.1.m1.1.1.3.7">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.1c">\mathcal{D}_{source}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_s italic_o italic_u italic_r italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> to construct <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S4.SS2.p6.2.m2.1"><semantics id="S4.SS2.p6.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p6.2.m2.1.1" xref="S4.SS2.p6.2.m2.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m2.1b"><ci id="S4.SS2.p6.2.m2.1.1.cmml" xref="S4.SS2.p6.2.m2.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m2.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.2.m2.1d">caligraphic_S</annotation></semantics></math>, rather than using captions from the training set of <math alttext="\mathcal{D}_{target}" class="ltx_Math" display="inline" id="S4.SS2.p6.3.m3.1"><semantics id="S4.SS2.p6.3.m3.1a"><msub id="S4.SS2.p6.3.m3.1.1" xref="S4.SS2.p6.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p6.3.m3.1.1.2" xref="S4.SS2.p6.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S4.SS2.p6.3.m3.1.1.3" xref="S4.SS2.p6.3.m3.1.1.3.cmml"><mi id="S4.SS2.p6.3.m3.1.1.3.2" xref="S4.SS2.p6.3.m3.1.1.3.2.cmml">t</mi><mo id="S4.SS2.p6.3.m3.1.1.3.1" xref="S4.SS2.p6.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.3.m3.1.1.3.3" xref="S4.SS2.p6.3.m3.1.1.3.3.cmml">a</mi><mo id="S4.SS2.p6.3.m3.1.1.3.1a" xref="S4.SS2.p6.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.3.m3.1.1.3.4" xref="S4.SS2.p6.3.m3.1.1.3.4.cmml">r</mi><mo id="S4.SS2.p6.3.m3.1.1.3.1b" xref="S4.SS2.p6.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.3.m3.1.1.3.5" xref="S4.SS2.p6.3.m3.1.1.3.5.cmml">g</mi><mo id="S4.SS2.p6.3.m3.1.1.3.1c" xref="S4.SS2.p6.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.3.m3.1.1.3.6" xref="S4.SS2.p6.3.m3.1.1.3.6.cmml">e</mi><mo id="S4.SS2.p6.3.m3.1.1.3.1d" xref="S4.SS2.p6.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.3.m3.1.1.3.7" xref="S4.SS2.p6.3.m3.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.3.m3.1b"><apply id="S4.SS2.p6.3.m3.1.1.cmml" xref="S4.SS2.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.3.m3.1.1.1.cmml" xref="S4.SS2.p6.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p6.3.m3.1.1.2.cmml" xref="S4.SS2.p6.3.m3.1.1.2">ğ’Ÿ</ci><apply id="S4.SS2.p6.3.m3.1.1.3.cmml" xref="S4.SS2.p6.3.m3.1.1.3"><times id="S4.SS2.p6.3.m3.1.1.3.1.cmml" xref="S4.SS2.p6.3.m3.1.1.3.1"></times><ci id="S4.SS2.p6.3.m3.1.1.3.2.cmml" xref="S4.SS2.p6.3.m3.1.1.3.2">ğ‘¡</ci><ci id="S4.SS2.p6.3.m3.1.1.3.3.cmml" xref="S4.SS2.p6.3.m3.1.1.3.3">ğ‘</ci><ci id="S4.SS2.p6.3.m3.1.1.3.4.cmml" xref="S4.SS2.p6.3.m3.1.1.3.4">ğ‘Ÿ</ci><ci id="S4.SS2.p6.3.m3.1.1.3.5.cmml" xref="S4.SS2.p6.3.m3.1.1.3.5">ğ‘”</ci><ci id="S4.SS2.p6.3.m3.1.1.3.6.cmml" xref="S4.SS2.p6.3.m3.1.1.3.6">ğ‘’</ci><ci id="S4.SS2.p6.3.m3.1.1.3.7.cmml" xref="S4.SS2.p6.3.m3.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.3.m3.1c">\mathcal{D}_{target}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. Additionally, all captions from <math alttext="\mathcal{D}_{target}" class="ltx_Math" display="inline" id="S4.SS2.p6.4.m4.1"><semantics id="S4.SS2.p6.4.m4.1a"><msub id="S4.SS2.p6.4.m4.1.1" xref="S4.SS2.p6.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p6.4.m4.1.1.2" xref="S4.SS2.p6.4.m4.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S4.SS2.p6.4.m4.1.1.3" xref="S4.SS2.p6.4.m4.1.1.3.cmml"><mi id="S4.SS2.p6.4.m4.1.1.3.2" xref="S4.SS2.p6.4.m4.1.1.3.2.cmml">t</mi><mo id="S4.SS2.p6.4.m4.1.1.3.1" xref="S4.SS2.p6.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.4.m4.1.1.3.3" xref="S4.SS2.p6.4.m4.1.1.3.3.cmml">a</mi><mo id="S4.SS2.p6.4.m4.1.1.3.1a" xref="S4.SS2.p6.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.4.m4.1.1.3.4" xref="S4.SS2.p6.4.m4.1.1.3.4.cmml">r</mi><mo id="S4.SS2.p6.4.m4.1.1.3.1b" xref="S4.SS2.p6.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.4.m4.1.1.3.5" xref="S4.SS2.p6.4.m4.1.1.3.5.cmml">g</mi><mo id="S4.SS2.p6.4.m4.1.1.3.1c" xref="S4.SS2.p6.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.4.m4.1.1.3.6" xref="S4.SS2.p6.4.m4.1.1.3.6.cmml">e</mi><mo id="S4.SS2.p6.4.m4.1.1.3.1d" xref="S4.SS2.p6.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S4.SS2.p6.4.m4.1.1.3.7" xref="S4.SS2.p6.4.m4.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.4.m4.1b"><apply id="S4.SS2.p6.4.m4.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p6.4.m4.1.1.1.cmml" xref="S4.SS2.p6.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p6.4.m4.1.1.2.cmml" xref="S4.SS2.p6.4.m4.1.1.2">ğ’Ÿ</ci><apply id="S4.SS2.p6.4.m4.1.1.3.cmml" xref="S4.SS2.p6.4.m4.1.1.3"><times id="S4.SS2.p6.4.m4.1.1.3.1.cmml" xref="S4.SS2.p6.4.m4.1.1.3.1"></times><ci id="S4.SS2.p6.4.m4.1.1.3.2.cmml" xref="S4.SS2.p6.4.m4.1.1.3.2">ğ‘¡</ci><ci id="S4.SS2.p6.4.m4.1.1.3.3.cmml" xref="S4.SS2.p6.4.m4.1.1.3.3">ğ‘</ci><ci id="S4.SS2.p6.4.m4.1.1.3.4.cmml" xref="S4.SS2.p6.4.m4.1.1.3.4">ğ‘Ÿ</ci><ci id="S4.SS2.p6.4.m4.1.1.3.5.cmml" xref="S4.SS2.p6.4.m4.1.1.3.5">ğ‘”</ci><ci id="S4.SS2.p6.4.m4.1.1.3.6.cmml" xref="S4.SS2.p6.4.m4.1.1.3.6">ğ‘’</ci><ci id="S4.SS2.p6.4.m4.1.1.3.7.cmml" xref="S4.SS2.p6.4.m4.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.4.m4.1c">\mathcal{D}_{target}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.4.m4.1d">caligraphic_D start_POSTSUBSCRIPT italic_t italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math> are excluded from the datastore <math alttext="\mathcal{DS}" class="ltx_Math" display="inline" id="S4.SS2.p6.5.m5.1"><semantics id="S4.SS2.p6.5.m5.1a"><mrow id="S4.SS2.p6.5.m5.1.1" xref="S4.SS2.p6.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p6.5.m5.1.1.2" xref="S4.SS2.p6.5.m5.1.1.2.cmml">ğ’Ÿ</mi><mo id="S4.SS2.p6.5.m5.1.1.1" xref="S4.SS2.p6.5.m5.1.1.1.cmml">â¢</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p6.5.m5.1.1.3" xref="S4.SS2.p6.5.m5.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.5.m5.1b"><apply id="S4.SS2.p6.5.m5.1.1.cmml" xref="S4.SS2.p6.5.m5.1.1"><times id="S4.SS2.p6.5.m5.1.1.1.cmml" xref="S4.SS2.p6.5.m5.1.1.1"></times><ci id="S4.SS2.p6.5.m5.1.1.2.cmml" xref="S4.SS2.p6.5.m5.1.1.2">ğ’Ÿ</ci><ci id="S4.SS2.p6.5.m5.1.1.3.cmml" xref="S4.SS2.p6.5.m5.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.5.m5.1c">\mathcal{DS}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p6.5.m5.1d">caligraphic_D caligraphic_S</annotation></semantics></math>. As shown in table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S4.T4" title="TABLE IV â€£ IV-B Ablation Study â€£ IV Experimental Results â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">IV</span></a>, incorporating domain knowledge greatly improves DRCapâ€™s cross-domain performance, demonstrating its adaptability during inference. Moreover, despite the absence of target domain knowledge, DRCap still performs competitively with state-of-the-art methods, as indicated in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.09472v1#S3.T2" title="TABLE II â€£ III-A Datasets â€£ III Experimental Settings â€£ DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning â€ Qiuqiang Kong and Xie Chen are the corresponding authors. âˆ—Codes and models will be available at https://github.com/X-LANCE/SLAM-LLM/tree/main/examples/drcap_zeroshot_aac."><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusion and future work</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We present DRCap, a data-efficient and flexible audio captioning model that requires only textual data for training and can quickly adapt to other domains.
Based on the CLAP model and the LLM, DRCap leverages projection-based decoding and retrieval-augmented generation to mitigate the modality gap.
Conditioned on both the projected CLAP embedding and the retrieved similar captions, DRCap could produce more accurate and semantically rich descriptions.
The replaceability of the text embedding support and the caption datastore guarantees the adaptability of the model. Experimental results show that DRCap outperforms other zero-shot audio captioning models in in-domain scenarios and achieves state-of-the-art performance in cross-domain scenarios.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
X.Â Mei, X.Â Liu, M.Â D. Plumbley, and W.Â Wang, â€œAutomated audio captioning: An overview of recent progress and new challenges,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">EURASIP journal on audio, speech, and music processing</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
X.Â Xu, Z.Â Xie, M.Â Wu, and K.Â Yu, â€œBeyond the status quo: A contemporary survey of advances and challenges in audio captioning,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
I.Â Sutskever, O.Â Vinyals, and Q.Â V. Le, â€œSequence to sequence learning with neural networks,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proc. NeurIPS</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M.Â Kim, K.Â Sung-Bin, and T.-H. Oh, â€œPrefix tuning for automated audio captioning,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proc. ICASSP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
T.Â Pellegrini, I.Â Khalfaoui-Hassani, E.Â LabbÃ©, and T.Â Masquelier, â€œAdapting a ConvNeXt model to audio classification on AudioSet,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2306.00830</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S.Â Ghosh, S.Â Kumar, C.Â K.Â R. Evuru, R.Â Duraiswami, and D.Â Manocha, â€œRecap: retrieval-augmented audio captioning,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proc. ICASSP</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S.-L. Wu, X.Â Chang, G.Â Wichern, J.-w. Jung, F.Â Germain, J.Â LeÂ Roux, and S.Â Watanabe, â€œImproving audio captioning models with fine-grained audio features, text embedding supervision, and LLM mix-up augmentation,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proc. ICASSP</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
W.Â Chen, X.Â Li, Z.Â Ma, Y.Â Liang, A.Â Jiang, Z.Â Zheng, Y.Â Qian, P.Â Fan, W.-Q. Zhang, C.Â Lu <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">etÂ al.</em>, â€œSjtu-thu automated audio captioning system for dcase 2024,â€ DCASE Challenge, Tech. Rep, Tech. Rep., 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Q.Â Kong, Y.Â Cao, T.Â Iqbal, Y.Â Wang, W.Â Wang, and M.Â D. Plumbley, â€œPANNs: Large-scale pretrained audio neural networks for audio pattern recognition,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
K.Â Chen, X.Â Du, B.Â Zhu, Z.Â Ma, T.Â Berg-Kirkpatrick, and S.Â Dubnov, â€œHTS-AT: A hierarchical token-semantic audio transformer for sound classification and detection,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proc. ICASSP</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
W.Â Chen, Y.Â Liang, Z.Â Ma, Z.Â Zheng, and X.Â Chen, â€œEAT: Self-supervised pre-training with efficient audio transformer,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proc. IJCAI</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M.Â Lewis, Y.Â Liu, N.Â Goyal, M.Â Ghazvininejad, A.Â Mohamed, O.Â Levy, V.Â Stoyanov, and L.Â Zettlemoyer, â€œBART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:1910.13461</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
A.Â Radford, J.Â Wu, R.Â Child, D.Â Luan, D.Â Amodei, I.Â Sutskever <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">etÂ al.</em>, â€œLanguage models are unsupervised multitask learners,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib13.2.2">OpenAI blog</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
I.Â MartinÂ Morato and A.Â Mesaros, â€œDiversity and bias in audio captioning datasets,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">DCASE</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
S.Â Deshmukh, B.Â Elizalde, D.Â Emmanouilidou, B.Â Raj, R.Â Singh, and H.Â Wang, â€œTraining audio captioning models without audio,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proc. ICASSP</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y.Â Zhang, X.Â Xu, R.Â Du, H.Â Liu, Y.Â Dong, Z.-H. Tan, W.Â Wang, and Z.Â Ma, â€œZero-shot audio captioning using soft and hard prompts,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2406.06295</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
T.Â Kouzelis and V.Â Katsouros, â€œWeakly-supervised automated audio captioning via text only training,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2309.12242</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
L.Â Salewski, S.Â Fauth, A.Â Koepke, and Z.Â Akata, â€œZero-shot audio captioning with audio-language model guidance and audio context keywords,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2311.08396</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
T.Â Shaharabany, A.Â Shaulov, and L.Â Wolf, â€œZero-shot audio captioning via audibility guidance,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2309.03884</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y.Â Wu, K.Â Chen, T.Â Zhang, Y.Â Hui, T.Â Berg-Kirkpatrick, and S.Â Dubnov, â€œLarge-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proc. ICASSP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
B.Â Elizalde, S.Â Deshmukh, M.Â AlÂ Ismail, and H.Â Wang, â€œClap learning audio concepts from natural language supervision,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proc. ICASSP</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
B.Â Elizalde, S.Â Deshmukh, and H.Â Wang, â€œNatural language supervision for general-purpose audio representations,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proc. ICASSP</em>.Â Â Â IEEE, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
V.Â W. Liang, Y.Â Zhang, Y.Â Kwon, S.Â Yeung, and J.Â Y. Zou, â€œMind the gap: Understanding the modality gap in multi-modal contrastive representation learning,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proc. NeurIPS</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
E.Â J. Hu, Y.Â Shen, P.Â Wallis, Z.Â Allen-Zhu, Y.Â Li, S.Â Wang, L.Â Wang, and W.Â Chen, â€œLoRA: Low-rank adaptation of large language models,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proc. ICLR</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
W.-L. Chiang, Z.Â Li, Z.Â Lin, Y.Â Sheng, Z.Â Wu, H.Â Zhang, L.Â Zheng, S.Â Zhuang, Y.Â Zhuang, J.Â E. Gonzalez <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">etÂ al.</em>, â€œVicuna: An open-source chatbot impressing GPT-4 with 90% ChatGPT quality, march 2023,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib25.2.2">URL https://lmsys. org/blog/2023-03-30-vicuna</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
W.Â Li, L.Â Zhu, L.Â Wen, and Y.Â Yang, â€œDeCap: Decoding clip latents for zero-shot captioning via text-only training,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2303.03032</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
P.Â Lewis, E.Â Perez, A.Â Piktus, F.Â Petroni, V.Â Karpukhin, N.Â Goyal, H.Â KÃ¼ttler, M.Â Lewis, W.-t. Yih, T.Â RocktÃ¤schel <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">etÂ al.</em>, â€œRetrieval-augmented generation for knowledge-intensive NLP tasks,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2">Proc. NeurIPS</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J.Â Kim, J.Â Jung, J.Â Lee, and S.Â H. Woo, â€œEnCLAP: Combining neural audio codec and audio-text joint embedding for automated audio captioning,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proc. ICASSP</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
C.Â D. Kim, B.Â Kim, H.Â Lee, and G.Â Kim, â€œAudiocaps: Generating captions for audios in the wild,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proc. NAACL</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
K.Â Drossos, S.Â Lipping, and T.Â Virtanen, â€œClotho: An audio captioning dataset,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proc. ICASSP</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J.Â F. Gemmeke, D.Â P. Ellis, D.Â Freedman, A.Â Jansen, W.Â Lawrence, R.Â C. Moore, M.Â Plakal, and M.Â Ritter, â€œAudio Set: An ontology and human-labeled dataset for audio events,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proc. ICASSP</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
X.Â Mei, C.Â Meng, H.Â Liu, Q.Â Kong, T.Â Ko, C.Â Zhao, M.Â D. Plumbley, Y.Â Zou, and W.Â Wang, â€œWavCaps: A ChatGPT-assisted weakly-labelled audio captioning dataset for audio-language multimodal research,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Y.Â Yuan, D.Â Jia, X.Â Zhuang, Y.Â Chen, Z.Â Liu, Z.Â Chen, Y.Â Wang, Y.Â Wang, X.Â Liu, M.Â D. Plumbley <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">etÂ al.</em>, â€œImproving audio generation with visual enhanced caption,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib33.2.2">arXiv preprint arXiv:2407.04416</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S.Â Hershey, D.Â P. Ellis, E.Â Fonseca, A.Â Jansen, C.Â Liu, R.Â C. Moore, and M.Â Plakal, â€œThe benefit of temporally-strong labels in audio event classification,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proc. ICASSP</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J.Â Schulman, B.Â Zoph, C.Â Kim, J.Â Hilton, J.Â Menick, J.Â Weng, J.Â F.Â C. Uribe, L.Â Fedus, L.Â Metz, M.Â Pokorny <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">etÂ al.</em>, â€œIntroducing ChatGPT,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib35.2.2">OpenAI Blog</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
S.Â Banerjee and A.Â Lavie, â€œMETEOR: An automatic metric for MT evaluation with improved correlation with human judgments,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proc. ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</em>, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
P.Â Anderson, B.Â Fernando, M.Â Johnson <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">etÂ al.</em>, â€œSPICE: Semantic propositional image caption evaluation,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib37.2.2">Proc. ECCV</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
R.Â Vedantam, C.Â LawrenceÂ Zitnick, and D.Â Parikh, â€œCIDEr: Consensus-based image description evaluation,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proc. CVPR</em>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
S.Â Liu, Z.Â Zhu, N.Â Ye, S.Â Guadarrama, and K.Â Murphy, â€œImproved image captioning via policy gradient optimization of SPIDEr,â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proc. ICCV</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Z.Â Zhou, Z.Â Zhang, X.Â Xu, Z.Â Xie, M.Â Wu, and K.Â Q. Zhu, â€œCan audio captions be evaluated with image caption metrics?â€ in <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proc. ICASSP</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
D.Â P. Kingma, â€œAdam: A method for stochastic optimization,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Y.Â Liu, M.Â Ott, N.Â Goyal, J.Â Du, M.Â Joshi, D.Â Chen, O.Â Levy, M.Â Lewis, L.Â Zettlemoyer, and V.Â Stoyanov, â€œRoBERTa: A robustly optimized BERT pretraining approach,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Z.Â Ma, G.Â Yang, Y.Â Yang, Z.Â Gao, J.Â Wang, Z.Â Du, F.Â Yu, Q.Â Chen, S.Â Zheng, S.Â Zhang <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">etÂ al.</em>, â€œAn embarrassingly simple approach for LLM with strong ASR capacity,â€ <em class="ltx_emph ltx_font_italic" id="bib.bib43.2.2">arXiv preprint arXiv:2402.08846</em>, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Oct 12 10:12:52 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
