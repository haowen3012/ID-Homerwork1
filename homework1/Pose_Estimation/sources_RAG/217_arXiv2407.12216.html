<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation</title>
<!--Generated on Sun Oct  6 16:14:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="" lang="en" name="keywords"/>
<base href="/html/2407.12216v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S1" title="In Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S2" title="In Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">KG-based RAG Failure Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S3" title="In Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Mindful-RAG</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S4" title="In Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experiments and Results</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S5" title="In Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S6" title="In Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Discussion and Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Garima Agrawal,
Tharindu Kumarage,
Zeyad Alghamdi, and
Huan Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">School of Computing and Augmented Intelligence, Arizona State University, Tempe, USA 
<br class="ltx_break"/>Email: {garima.agrawal, kskumara, zalgham1, huanliu}@asu.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1"><span class="ltx_text" id="id1.id1.1">Large Language Models (LLMs) excel at generating coherent text but often struggle with knowledge-intensive queries, particularly in domain-specific and factual question-answering tasks. Retrieval-augmented generation (RAG) systems have emerged as a promising solution by integrating external knowledge sources, such as structured knowledge graphs (KGs). While KG-based RAG approaches have demonstrated value, current state-of-the-art solutions frequently fall short, failing to deliver accurate and reliable answers even when the necessary factual knowledge is available. In this paper, we present a critical analysis of failure points in existing KG-based RAG methods, identifying eight key areas of concern, including misinterpretation of question context, incorrect relation mapping, and ineffective ambiguity resolution. We argue that these failures primarily stem from design limitations in current KG-RAG systems, such as inadequate attention to discerning user intent and insufficient alignment of retrieved knowledge with the contextual demands of the query. Based on this analysis, we propose a new approach for KG-RAG systems, termed Mindful-RAG, which re-engineers the retrieval process to be more intent-driven and contextually aware. By enhancing reasoning capabilities, improving constraint identification, and addressing the structural limitations of knowledge graphs, we aim to improve the reliability and effectiveness of KG-RAG systems. To validate this approach, we developed a proof-of-concept by integrating the principles of Mindful-RAG into an existing KG-RAG system. The Mindful-RAG approach seeks to deliver more robust, accurate, and contextually aligned AI-driven knowledge retrieval systems, with potential applications in critical domains such as healthcare, legal, research, and scientific discovery, where precision and reliability are paramount.</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
<span class="ltx_text" id="id2.id1">
LLMs, Knowledge Graphs (KG), Retrieval Augmented Generation (RAG), Hallucinations, Points of Failure
</span>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs) have revolutionized natural language processing, excelling in various tasks. However, they frequently generate hallucinated responses when dealing with domain-specific or knowledge-intensive queries <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib1" title="">1</a>]</cite>. This limitation has led to the development of Retrieval-augmented Generation (RAG) methods, which enable LLMs to access and incorporate external knowledge sources, such as structured knowledge graphs (KGs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib3" title="">3</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite the promise of RAG methods, particularly those integrating KGs, significant challenges persist. Even with access to relevant information, these systems often fail to provide accurate answers, especially as query complexity increases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib6" title="">6</a>]</cite>. To better understand these limitations, We conducted a study to critically analyze the failure points in existing KG-based RAG methods. Our investigation identified eight critical failure points in these systems, which we categorized into two primary areas:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Reasoning Failures</span>: LLMs struggle to accurately interpret user queries and leverage contextual information, resulting in a misalignment between retrieved knowledge and query intent.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Structural Limitations</span>: These failures primarily arise from insufficient attention to the structure of knowledge sources, such as knowledge graphs, and the use of inappropriate evaluation metrics.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Given these persistent issues, there is a pressing need to look beyond conventional approaches and critically reassess how KG-RAG systems are designed. To address these challenges, we propose <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Mindful-RAG</span>, an approach that re-engineers the retrieval process to be more intent-driven and contextually aware. Mindful-RAG is not merely an alternative method; it represents a comprehensive approach aimed at the development of more effective KG-RAG systems. Unlike traditional methods that primarily rely on semantic similarity or structural cues, Mindful-RAG suggests to leverage the intrinsic parametric knowledge of LLMs to accurately discern the intent behind queries. This approach not only guides the retrieval process to ensure that the extracted context from the KG is relevant but also aligns it with the original intent of the query. Additionally, Mindful-RAG introduces advanced contextual alignment techniques for efficient knowledge graph navigation and incorporates a validation step to ensure the generated response meets the intended requirements. To validate this approach, we developed a proof-of-concept that integrates Mindful-RAG into an existing KG-RAG system through prompt engineering. Preliminary experiments on WebQSP and MetaQA datasets indicate promising results compared to existing state-of-the-art methods, particularly in reducing reasoning errors by enhancing the focus on understanding query objectives and improving contextual alignment.
In this paper, we make the following key contributions:</p>
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1">A comprehensive error analysis of KG-based RAG methods, identifying eight critical failure points and highlighting design limitations in state-of-the-art frameworks, particularly in addressing question intent and achieving contextual alignment in vanilla-RAG systems.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1">The introduction of a proof-of-concept that opens a novel research direction, redefining the RAG pipeline by leveraging LLMs‚Äô parametric memory for enhanced intent identification and contextual alignment.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S1.p3.2">By addressing these fundamental challenges, Mindful-RAG aims to create more robust, accurate, and contextually aligned AI-driven knowledge retrieval systems, particularly in precision-critical fields such as healthcare, legal, research, and scientific discovery.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">KG-based RAG Failure Analysis</span>
</h2>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table I: </span>KG-Based RAG Failure Analysis</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S2.T1.1" style="width:433.6pt;height:372.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-56.2pt,48.3pt) scale(0.794287535535829,0.794287535535829) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.1.1.1.1" style="background-color:#D9D9D9;">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1" style="background-color:#D9D9D9;">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.1" style="width:71.1pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.1">Error Category</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.2.1" style="background-color:#D9D9D9;">
<span class="ltx_p" id="S2.T1.1.1.1.1.2.1.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.2.1.1.1">Error Type</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.3.1" style="background-color:#D9D9D9;">
<span class="ltx_p" id="S2.T1.1.1.1.1.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.3.1.1.1">Description</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.4.1" style="background-color:#D9D9D9;">
<span class="ltx_p" id="S2.T1.1.1.1.1.4.1.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.4.1.1.1">Representative Failed Example(s)</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.2.1.1.1">
<span class="ltx_p" id="S2.T1.1.1.2.1.1.1.1" style="width:71.1pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.2.1.1.1.1.1">Reasoning Failures</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.2.1.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.2.1.2.1">
<span class="ltx_p" id="S2.T1.1.1.2.1.2.1.1" style="width:85.4pt;"><span class="ltx_text ltx_align_left" id="S2.T1.1.1.2.1.2.1.1.1" style="background-color:#B3B3B3;">Misinterpretation of Question‚Äôs Context</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.2.1.3.1">
<span class="ltx_p" id="S2.T1.1.1.2.1.3.1.1" style="width:142.3pt;">LLMs misinterpret the question or fail to understand specific requirements of the question.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.2.1.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.2.1.4.1">
<span class="ltx_p" id="S2.T1.1.1.2.1.4.1.1" style="width:199.2pt;">
<span class="ltx_itemize" id="S2.I1">
<span class="ltx_item" id="S2.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I1.i1.p1">
<span class="ltx_p" id="S2.I1.i1.p1.1">Failed to relate <span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Justin Bieber‚Äôs</span> birthplace to his country of birth, focusing on city-level information instead of the required higher geographical context.</span>
</span></span>
<span class="ltx_item" id="S2.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I1.i2.p1">
<span class="ltx_p" id="S2.I1.i2.p1.1">Incorrectly identified the location of <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Fukushima Daiichi</span> nuclear plant, choosing the city <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.2">‚ÄôFukushima‚Äô</span> instead of the correct town <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.3">‚ÄôOkuma‚Äô</span> and country <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.4">‚ÄôJapan‚Äô</span>.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.2.1.1">
<span class="ltx_p" id="S2.T1.1.1.3.2.1.1.1" style="width:71.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.3.2.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.2.2.1">
<span class="ltx_p" id="S2.T1.1.1.3.2.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.3.2.2.1.1.1" style="background-color:#B3B3B3;">Incorrect Relation Mapping</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.2.3.1">
<span class="ltx_p" id="S2.T1.1.1.3.2.3.1.1" style="width:142.3pt;">LLMs often choose relations that do not correctly address the question.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.3.2.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.3.2.4.1">
<span class="ltx_p" id="S2.T1.1.1.3.2.4.1.1" style="width:199.2pt;">For a question about where <span class="ltx_text ltx_align_left ltx_font_bold" id="S2.T1.1.1.3.2.4.1.1.1">Andy Murray</span> started playing tennis, choosing <span class="ltx_text ltx_align_left ltx_font_italic" id="S2.T1.1.1.3.2.4.1.1.2">people.person.place_of_birth</span> suggests a misunderstanding of the question‚Äôs intent.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.4.3.1.1">
<span class="ltx_p" id="S2.T1.1.1.4.3.1.1.1" style="width:71.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.4.3.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.4.3.2.1">
<span class="ltx_p" id="S2.T1.1.1.4.3.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.4.3.2.1.1.1" style="background-color:#B3B3B3;">Ambiguity in Question or Data</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.4.3.3.1">
<span class="ltx_p" id="S2.T1.1.1.4.3.3.1.1" style="width:142.3pt;">LLMs fail to identify key terms and their meanings or implications across various contexts from the provided KG triples.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.4.3.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.4.3.4.1">
<span class="ltx_p" id="S2.T1.1.1.4.3.4.1.1" style="width:199.2pt;">
<span class="ltx_itemize" id="S2.I2">
<span class="ltx_item" id="S2.I2.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I2.i1.p1">
<span class="ltx_p" id="S2.I2.i1.p1.1">Could not identify the <span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">Serbian language</span> from the list of languages spoken in <span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.2">Serbia</span>.</span>
</span></span>
<span class="ltx_item" id="S2.I2.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I2.i2.p1">
<span class="ltx_p" id="S2.I2.i2.p1.1">Failed to recognize that a query was about the <span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">‚Äùmost‚Äù exported item</span>, not just any exported item.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.5.4.1.1">
<span class="ltx_p" id="S2.T1.1.1.5.4.1.1.1" style="width:71.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.5.4.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.5.4.2.1">
<span class="ltx_p" id="S2.T1.1.1.5.4.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.5.4.2.1.1.1" style="background-color:#B3B3B3;">Specificity or Precision Errors</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.5.4.3.1">
<span class="ltx_p" id="S2.T1.1.1.5.4.3.1.1" style="width:142.3pt;">LLMs often misinterpret questions requiring aggregated responses as specific, singular answers. They also struggle with temporal context.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.5.4.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.5.4.4.1">
<span class="ltx_p" id="S2.T1.1.1.5.4.4.1.1" style="width:199.2pt;">
<span class="ltx_itemize" id="S2.I3">
<span class="ltx_item" id="S2.I3.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I3.i1.p1">
<span class="ltx_p" id="S2.I3.i1.p1.1">Picked <span class="ltx_text ltx_font_bold" id="S2.I3.i1.p1.1.1">2000</span> as <span class="ltx_text ltx_font_bold" id="S2.I3.i1.p1.1.2">George W. Bush‚Äôs</span> election year without considering his two elections (<span class="ltx_text ltx_font_bold" id="S2.I3.i1.p1.1.3">2000 and 2004</span>).</span>
</span></span>
<span class="ltx_item" id="S2.I3.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I3.i2.p1">
<span class="ltx_p" id="S2.I3.i2.p1.1">Selected <span class="ltx_text ltx_font_bold" id="S2.I3.i2.p1.1.1">‚ÄôSue Douglas‚Äô</span> as <span class="ltx_text ltx_font_bold" id="S2.I3.i2.p1.1.2">Niall Ferguson‚Äôs</span> spouse instead of finding the current spouse, <span class="ltx_text ltx_font_bold" id="S2.I3.i2.p1.1.3">‚ÄôAyaan Hirsi Ali‚Äô</span>, ignoring multiple spouse possibilities.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.6.5.1.1">
<span class="ltx_p" id="S2.T1.1.1.6.5.1.1.1" style="width:71.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.6.5.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.6.5.2.1">
<span class="ltx_p" id="S2.T1.1.1.6.5.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.6.5.2.1.1.1" style="background-color:#B3B3B3;">Constraint Identification Error</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.6.5.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.6.5.3.1">
<span class="ltx_p" id="S2.T1.1.1.6.5.3.1.1" style="width:142.3pt;">LLMs fail to correctly identify or apply constraints provided or implied in the question.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.6.5.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.6.5.4.1">
<span class="ltx_p" id="S2.T1.1.1.6.5.4.1.1" style="width:199.2pt;">
<span class="ltx_itemize" id="S2.I4">
<span class="ltx_item" id="S2.I4.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I4.i1.p1">
<span class="ltx_p" id="S2.I4.i1.p1.1">Could not effectively narrow the search for <span class="ltx_text ltx_font_bold" id="S2.I4.i1.p1.1.1">Jackie Robinson‚Äôs</span> first team.</span>
</span></span>
<span class="ltx_item" id="S2.I4.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<span class="ltx_para" id="S2.I4.i2.p1">
<span class="ltx_p" id="S2.I4.i2.p1.1">For ‚ÄùWho played Bilbo in Lord of the Rings?‚Äù, LLMs identified <span class="ltx_text ltx_font_bold" id="S2.I4.i2.p1.1.1">‚ÄùOld Bilbo‚Äù</span> and specific films but failed to derive a single definitive answer.</span>
</span></span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.7.6.1.1">
<span class="ltx_p" id="S2.T1.1.1.7.6.1.1.1" style="width:71.1pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.7.6.1.1.1.1">Structural Limitation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.7.6.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.7.6.2.1">
<span class="ltx_p" id="S2.T1.1.1.7.6.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.7.6.2.1.1.1" style="background-color:#B3B3B3;">Encoding Issues</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.7.6.3.1">
<span class="ltx_p" id="S2.T1.1.1.7.6.3.1.1" style="width:142.3pt;">Compound value types (CVTs) in KGs represent complex data. If mismanaged or unrecognized by LLMs, they may be misinterpreted as final answers.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.7.6.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.7.6.4.1">
<span class="ltx_p" id="S2.T1.1.1.7.6.4.1.1" style="width:199.2pt;">For ‚ÄôWhere is the Sony Ericsson Company?‚Äô, the model correctly identifies relations but mistakenly selects CVT_0 as the final answer due to CVT node linking.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S2.T1.1.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.8.7.1.1">
<span class="ltx_p" id="S2.T1.1.1.8.7.1.1.1" style="width:71.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.8.7.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.8.7.2.1">
<span class="ltx_p" id="S2.T1.1.1.8.7.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.8.7.2.1.1.1" style="background-color:#B3B3B3;">Inappropriate Evaluation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.8.7.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.8.7.3.1">
<span class="ltx_p" id="S2.T1.1.1.8.7.3.1.1" style="width:142.3pt;">The exact match (EM) module only accepts fully correct answers and sometimes fails due to misinterpreting the required depth of information or mis-aligning with expected answer format.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.8.7.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.8.7.4.1">
<span class="ltx_p" id="S2.T1.1.1.8.7.4.1.1" style="width:199.2pt;">For ‚ÄôWhat year did the Orioles go to the World Series?‚Äô, the model retrieved correct years (1983, 1970, 1966) but failed to match the expected format <span class="ltx_text ltx_align_left ltx_font_bold" id="S2.T1.1.1.8.7.4.1.1.1">[1983 World Series, 1970 World Series, 1966 World Series]</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.1.9.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="S2.T1.1.1.9.8.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.9.8.1.1">
<span class="ltx_p" id="S2.T1.1.1.9.8.1.1.1" style="width:71.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.8.2" style="background-color:#B3B3B3;">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.9.8.2.1">
<span class="ltx_p" id="S2.T1.1.1.9.8.2.1.1" style="width:85.4pt;"><span class="ltx_text" id="S2.T1.1.1.9.8.2.1.1.1" style="background-color:#B3B3B3;">Limited Query Processing</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.8.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.9.8.3.1">
<span class="ltx_p" id="S2.T1.1.1.9.8.3.1.1" style="width:142.3pt;">Instances where the model recognizes that further information is required for a conclusive answer, yet receives no feedback, indicating a gap in programming or query processing.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S2.T1.1.1.9.8.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.9.8.4.1">
<span class="ltx_p" id="S2.T1.1.1.9.8.4.1.1" style="width:199.2pt;">The model responds <span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="S2.T1.1.1.9.8.4.1.1.1">‚ÄôNeed More Information‚Äô</span> for ‚ÄôWhat is the name of the San Francisco newspaper?‚Äô but receives no further feedback.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Various methodologies have been developed to enhance LLMs with KG-based RAG systems. By leveraging structured and meticulously curated knowledge from these graphs, the retrieved information is more likely to be factually accurate.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.2">We assessed the effectiveness of these methods and analyzed their accuracy in retrieving information for fact-based question-answering (QA) tasks using a KG. Although most of these models surpass the performance of zero-shot QA conducted directly from various standard LLMs, there is still considerable scope for improvement. For our study, we chose the WebQuestionsSP (WebQSP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib7" title="">7</a>]</cite> dataset for knowledge graph question answering (KGQA), which is frequently utilized by KG-based RAG methods<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib8" title="">8</a>]</cite>. This dataset, based on the Freebase KG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib9" title="">9</a>]</cite>, consists of questions that require up to two or three-hop reasoning to identify the correct answer entity, utilizing Hits@<math alttext="k" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">italic_k</annotation></semantics></math> as the evaluation metric to determine if the top-<math alttext="k" class="ltx_Math" display="inline" id="S2.p2.2.m2.1"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.p2.2.m2.1d">italic_k</annotation></semantics></math> predicted answer is accurate. It includes approximately 1600 test samples. The vanilla ChatGPT (GPT-3.5) accuracy in zero-shot setting without any external knowledge is 61.2%.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">StructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib10" title="">10</a>]</cite> is a state-of-the-art approach that leverages LLM‚Äôs capabilities for reasoning with evidence extracted from a KG. This method involves extracting a sub-graph from a KG by matching the topic entities in the question. The LLM is then directly employed to identify useful relations and extract relevant triples from the sub-graph, guiding it to effectively traverse and reason within the graph structure. The Hits@1 accuracy of StructGPT on the WebQSP dataset, when utilizing ChatGPT (GPT-3.5) for question-answering tasks, was reported to be 72.6%. In this study, we have chosen StructGPT as our reference model to analyze the current SOTA developments of KG-based RAGs in the QA setting.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">We began our analysis by closely examining the failure instances of StructGPT on the WebQSP dataset. We meticulously reviewed logs from around 435 error cases to understand the model‚Äôs behavior during the reasoning process. Initially, we manually analyzed 10% of these error samples to identify common error types. Building on this manual analysis, we developed an LLM-assisted pipeline using few-shot samples to categorize the remaining errors and identify any additional error types. We then employed LLM-critic to provide recommendations and identify recurring themes based on our analysis and category mapping. These LLM-generated suggestions were subsequently validated through manual review. This detailed examination allowed us to pinpoint distinct error patterns, leading to the identification of eight primary error categories. These issues were further organized into two main divisions: <span class="ltx_text ltx_font_italic" id="S2.p4.1.1">Reasoning Failures</span>, which encompass errors arising from reasoning deficiencies, and <span class="ltx_text ltx_font_italic" id="S2.p4.1.2">Structural Limitations</span>, which include structural issues within the knowledge graph.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.p5.1.1">Reasoning Failures:</span> Most failures stem from the LLMs‚Äô inability to reason correctly. These issues primarily include a failure to accurately understand the question, leading to difficulty in mapping the question to the available information. Additionally, LLMs struggle to effectively apply the cues in the question to narrow down the relevant entities. They also often fail to apply specific constraints that logically limit the search space. Generally, LLMs have difficulty grasping specifics such as temporal context, aggregating or summarizing answers, and disambiguating among multiple choices. Furthermore, they frequently choose incorrect relations, particularly in complex queries requiring multi-hop reasoning, finding it challenging to focus on the relevant elements necessary to formulate an answer. In Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S2.T1" title="Table I ‚Ä£ II KG-based RAG Failure Analysis ‚Ä£ Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">I</span></a>, we detail various reasoning failures, each illustrated with an example.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p6">
<p class="ltx_p" id="S2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.p6.1.1">Structural Limitations:</span> These issues occur when knowledge becomes inaccessible due to limitations in the structural design of the knowledge base or inefficient processing methods. In Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S2.T1" title="Table I ‚Ä£ II KG-based RAG Failure Analysis ‚Ä£ Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">I</span></a>, we categorize these challenges under structural issues, limited query processing, and the selection of inappropriate evaluation metrics.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">In this work, our primary focus is on addressing errors stemming from reasoning failures in LLM models and enhancing their reasoning capabilities. Structural limitations, on the other hand, can be resolved through careful programming and the selection of more appropriate evaluation metrics. Our analysis of reasoning error samples reveals two main challenges: <span class="ltx_text ltx_font_bold" id="S2.p7.1.1">(i)</span> Models frequently fail to grasp the question‚Äôs intent, relying primarily on structural cues and semantic similarity to extract relevant relations and generate answers. <span class="ltx_text ltx_font_bold" id="S2.p7.1.2">(ii)</span> They struggle to align the question‚Äôs context with the available information.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1">This inability to comprehend intent and context leads to incorrect relation rankings and the misapplication of constraints. A review of response logs from both failed and successful interactions reveals that the LLM relies heavily on semantic matching. While this approach suffices for simple queries, it falls short in handling complex questions that demand multi-hop reasoning and deep contextual understanding. Therefore, improving intent identification and context alignment is essential for enhancing model performance.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Mindful-RAG</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In response to our findings, we introduce <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">Mindful-RAG</span>, designed to address two critical gaps: the lack of question-intent identification and the insufficient contextual alignment with available knowledge. This approach employs a strategic hybrid method that integrates the model‚Äôs intrinsic parametric knowledge with non-parametric external knowledge from a KG. The following steps provide a detailed overview of our design and methodology, each accompanied by an illustrative example.</p>
</div>
<div class="ltx_para" id="S3.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Step 1. Identify key Entities and relevant Tokens:</span> The first step is to pinpoint the key entities within a question to facilitate the extraction of pertinent information from an external KG or a sub-graph within a KG. Additionally, in our method, we task the LLM model with identifying other significant tokens that may be crucial for answering the question. For instance, consider the question from WebQSP, <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.2">‚ÄúWho is Niall Ferguson‚Äôs wife?‚Äù</span> The key entity identified by the model is <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.3">‚ÄòNiall Ferguson‚Äô</span>, and the other relevant token is <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.4">‚Äòwife‚Äô</span>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Step 2. Identify the Intent:</span> In this step, we leverage the LLM‚Äôs understanding to discern the intent behind the question, prompting it to focus on keywords and phrases that clarify the depth and scope of the intent. For instance, in the provided example, the model identifies the question‚Äôs intent as <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.2">‚Äúidentify spouse‚Äù</span>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Step 3. Identify the Context:</span> Next, the model was instructed to understand and analyze the context of the question, which is essential for formulating an accurate response. For the provided example, the model identifies relevant contextual aspects such as <span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.1.2">‚Äúpersonal relationships,‚Äù ‚Äúmarital status,‚Äù and ‚Äúcurrent spouse.‚Äù</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Step 4. Candidate Relation Extraction:</span> Next, the key entity relations are extracted from the sub-graph within one-hop distance. For our example, the candidate relations include information about the subject‚Äôs profession, personal life, and societal role.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">Step 5. Intent-Based Filtering and Contextual Ranking of Relations:</span> In this step, the model conducts a detailed analysis to filter and rank the extracted relations and entities based on the question‚Äôs intent, ensuring relevance and accuracy. Relations are ranked according to their contextual significance, with the top-<math alttext="k" class="ltx_Math" display="inline" id="S3.I1.i5.p1.1.m1.1"><semantics id="S3.I1.i5.p1.1.m1.1a"><mi id="S3.I1.i5.p1.1.m1.1.1" xref="S3.I1.i5.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i5.p1.1.m1.1b"><ci id="S3.I1.i5.p1.1.m1.1.1.cmml" xref="S3.I1.i5.p1.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i5.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i5.p1.1.m1.1d">italic_k</annotation></semantics></math> relations being selected. For example, considering the intent and context in the given scenario, the model identifies <span class="ltx_text ltx_font_italic" id="S3.I1.i5.p1.1.2">‚Äúpeople.person.spouse_s‚Äù</span> as the most relevant relation.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i6.p1">
<p class="ltx_p" id="S3.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i6.p1.1.1">Step 6. Contextual Alignment of Constraints:</span> In this step, the model considers temporal and geographical constraints by utilizing relevant data from various indicators to address more complex queries. This process ensures that responses are accurately tailored to specific times, locations, or historical periods. Once constraints are identified, the model aligns them contextually and refines the list of candidate entities. For example, in our scenario, the model identified constraints such as names of spouses, marriage start and end times, and the location of the ceremony. It then narrowed the list to potential spouses and extracted all related triples. Finally, the model aligned this information with the context of the ‚Äòcurrent spouse,‚Äô resulting in the correct response of <span class="ltx_text ltx_font_italic" id="S3.I1.i6.p1.1.2">‚ÄòAyaan Hirsi Ali‚Äô</span>, in contrast to existing methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib10" title="">10</a>]</cite>, where the LLM incorrectly selected the first name on the spouse list, <span class="ltx_text ltx_font_italic" id="S3.I1.i6.p1.1.3">‚ÄòSue Douglas‚Äô</span>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i7.p1">
<p class="ltx_p" id="S3.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i7.p1.1.1">Step 7. Intent-Based Feedback:</span> In the final step, the model is prompted to validate whether the final answer aligns with the initially identified intent and context of the question. If the answer does not meet these criteria, the model is instructed to revisit <span class="ltx_text ltx_font_bold" id="S3.I1.i7.p1.1.2">Step 5 and 6</span> to further refine its response.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Similarly, the model adeptly contextualizes and aggregates pertinent information in other instances. For example, when asked, <span class="ltx_text ltx_font_italic" id="S3.p3.1.1">‚ÄúWhat songs did Justin Bieber write?‚Äù</span> it successfully compiles all relevant songs. In response to, <span class="ltx_text ltx_font_italic" id="S3.p3.1.2">‚ÄúWhat is the state flower of Arizona?‚Äù</span> it identifies <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.3">‚ÄòArizona‚Äô</span> as the key entity, with <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.4">‚Äòstate‚Äô</span> and <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.5">‚Äòflower‚Äô</span> as relevant tokens. It correctly interprets the intent to <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.6">‚Äúidentify state flower‚Äù</span> and recognizes the context of <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.7">‚Äòbotany,‚Äô ‚Äôstate symbols,‚Äô</span> and <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p3.1.8">‚ÄòArizona‚Äôs official flora‚Äô</span> choosing the appropriate relation: <span class="ltx_text ltx_font_italic" id="S3.p3.1.9">‚Äúgovernment.governmental_jurisdiction.official_symbols.‚Äù</span>
In contrast, traditional methods only identify <span class="ltx_text ltx_font_italic" id="S3.p3.1.10">‚ÄòArizona‚Äô</span> as the key entity, often missing the broader context, leading to choosing incorrect relations, <span class="ltx_text ltx_font_italic" id="S3.p3.1.11">‚Äúbase.locations.states_and_provinces.country‚Äù</span> and answer stating the state flower of Arizona is unknown.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.p4.1.1">Mindful-RAG</span> leverages the LLM‚Äôs intrinsic understanding in the first three steps to identify not only the key entities but also to gather additional information such as relevant tokens, intent, and current context, all of which are essential for accurately answering the question.
These steps enable the model to appropriately filter relations and align constraints with the current context. By incorporating these steps, the LLM becomes more mindful of the specific elements to consider. In the final two steps, the LLM is prompted to tailor its response and align it with specific constraints such as time, location, and any requirements for aggregating an answer.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experiments and Results</span>
</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Datasets:</span> We evaluate our approach on two benchmark KGQA datasets, specifically WebQSP and MetaQA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib11" title="">11</a>]</cite>. MetaQA features questions related to the movie domain, with answers up to three hops away from the topic entities in a movie KG (based on OMDb). Here, we focused only on 3-hop questions.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In our analysis of the WebQSP dataset, we evaluated several baseline methods: KAPING <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib12" title="">12</a>]</cite>, Retrieve-Rewrite-Answer (RRA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib13" title="">13</a>]</cite>, Reasoning on Graphs (RoG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib14" title="">14</a>]</cite>, and StructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib10" title="">10</a>]</cite>. For MetaQA (3-hop), StructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib10" title="">10</a>]</cite> served as the baseline. The results for these methods were taken directly from the respective publications. In our experiments, we adapted the base code of StructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib10" title="">10</a>]</cite> and modified it only for improved reasoning as outlined in the previous section. We also examined the performance of ChatGPT without RAG on both datasets. The results, presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#S4.F1" title="Figure 1 ‚Ä£ IV Experiments and Results ‚Ä£ Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation"><span class="ltx_text ltx_ref_tag">1</span></a>, show that Mindful-RAG, shows promising improvement in accuracy of reasoning error cases achieving a Hits@1 of 84% on WebQSP and 82% on MetaQA. Additional accuracy improvements can be achieved by addressing structural issues and incorporating partial answers to enhance precision, rather than relying solely on exact matches.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">The primary goal of this study is to explore methods for mitigating reasoning errors in KG-RAG systems. It is important to emphasize that our approach serves as an initial demonstration of the potential in combining the parametric knowledge of models with non-parametric external knowledge. More advanced RAG methods could be developed in the future to significantly surpass the performance of our approach.</p>
</div>
<figure class="ltx_figure" id="S4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="234" id="S4.F1.g1" src="x1.png" width="398"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Mindful-RAG results on WebQSP and MetaQA</figcaption>
</figure>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Recent efforts to enhance RAG systems have focused on various improvements. Siriwardhana et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib15" title="">15</a>]</cite> aimed to improve domain adaptation for Open Domain Question Answering (ODQA) by jointly training the retriever and generator and enriching the Wikipedia-based knowledge base with healthcare and news content. RAFT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib16" title="">16</a>]</cite> enhances RAG by customizing language models for specific domains in open-book QA. Self-RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib17" title="">17</a>]</cite> aims to increase the factual accuracy of LLMs through adaptive self-critique and retrieval-generation feedback loops. Fit-RAG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib18" title="">18</a>]</cite> introduces a method that uses detailed prompts to ensure deep question understanding and clear reasoning in fact retrieval. Domain-specific knowledge graphs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib22" title="">22</a>]</cite> have been effectively employed in KG-based RAG systems within LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib25" title="">25</a>]</cite> for question-answering tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.12216v2#bib.bib27" title="">27</a>]</cite>. While most efforts focus on enhancing LLMs by augmenting knowledge graphs with relevant facts, there has been limited work on improving the reasoning capabilities of LLMs during knowledge retrieval. Our research with Mindful-RAG aims to establish a road map for advancing these methods by leveraging the model‚Äôs inherent knowledge for better question understanding.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Discussion and Conclusion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We conducted an error analysis of KG-based RAG methods integrated with LLMs for question-answering tasks, identifying eight critical failure points, categorized into reasoning failures and structural limitations. Reasoning failures involve LLMs struggling with understanding questions and leveraging contextual clues, particularly in cases involving temporal context and complex relational reasoning. Structural limitations pertain to inadequate attention to the structure of the knowledge base and weaknesses in evaluation metrics. These challenges highlight areas for improvement, especially in handling complex, multi-hop queries. To address these issues, we propose Mindful-RAG, designed to enhance intent-driven retrieval and ensure contextually coherent responses, directly targeting the identified deficiencies. While our approach focuses on mitigating reasoning-based failures, future research could explore addressing structural issues through the use of feedback and human-in-the-loop input. Additionally, combining vector-based search with KG-based sub-graph retrieval represents a promising direction for enhancing LLM performance in knowledge-intensive tasks.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This material is based upon work supported by
the National Science Foundation under Grant No.
2335666.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Z.¬†Ji, N.¬†Lee, R.¬†Frieske, T.¬†Yu, D.¬†Su, Y.¬†Xu, E.¬†Ishii, Y.¬†J. Bang, A.¬†Madotto, and P.¬†Fung, ‚ÄúSurvey of hallucination in natural language generation,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">ACM Computing Surveys</em>, vol.¬†55, no.¬†12, pp. 1‚Äì38, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J.¬†Li, Y.¬†Yuan, and Z.¬†Zhang, ‚ÄúEnhancing llm factual accuracy with rag to counter hallucinations: A case study on domain-specific queries in private knowledge-bases,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2403.10446</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y.¬†Ding, W.¬†Fan, L.¬†Ning, S.¬†Wang, H.¬†Li, D.¬†Yin, T.-S. Chua, and Q.¬†Li, ‚ÄúA survey on rag meets llms: Towards retrieval-augmented large language models,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2405.06211</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Y.¬†Gao, Y.¬†Xiong, X.¬†Gao, K.¬†Jia, J.¬†Pan, Y.¬†Bi, Y.¬†Dai, J.¬†Sun, and H.¬†Wang, ‚ÄúRetrieval-augmented generation for large language models: A survey,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2312.10997</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G.¬†Agrawal, T.¬†Kumarage, Z.¬†Alghami, and H.¬†Liu, ‚ÄúCan knowledge graphs reduce hallucinations in llms?: A survey,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2311.07914</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S.¬†Jeong, J.¬†Baek, S.¬†Cho, S.¬†J. Hwang, and J.¬†C. Park, ‚ÄúAdaptive-rag: Learning to adapt retrieval-augmented large language models through question complexity,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2403.14403</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
W.-t. Yih, M.¬†Richardson, C.¬†Meek, M.-W. Chang, and J.¬†Suh, ‚ÄúThe value of semantic parse labeling for knowledge base question answering,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, 2016, pp. 201‚Äì206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y.¬†Tan, D.¬†Min, Y.¬†Li, W.¬†Li, N.¬†Hu, Y.¬†Chen, and G.¬†Qi, ‚ÄúCan chatgpt replace traditional kbqa models? an in-depth analysis of the question answering performance of the gpt llm family,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Semantic Web Conference</em>.¬†¬†¬†Springer, 2023, pp. 348‚Äì367.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
K.¬†Bollacker, C.¬†Evans, P.¬†Paritosh, T.¬†Sturge, and J.¬†Taylor, ‚ÄúFreebase: a collaboratively created graph database for structuring human knowledge,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</em>, 2008, pp. 1247‚Äì1250.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J.¬†Jiang, K.¬†Zhou, Z.¬†Dong, K.¬†Ye, W.¬†X. Zhao, and J.-R. Wen, ‚ÄúStructgpt: A general framework for large language model to reason over structured data,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2305.09645</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y.¬†Zhang, H.¬†Dai, Z.¬†Kozareva, A.¬†Smola, and L.¬†Song, ‚ÄúVariational reasoning for question answering with knowledge graph,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, vol.¬†32, no.¬†1, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J.¬†Baek, A.¬†F. Aji, and A.¬†Saffari, ‚ÄúKnowledge-augmented language model prompting for zero-shot knowledge graph question answering,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2306.04136</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y.¬†Wu, N.¬†Hu, G.¬†Qi, S.¬†Bi, J.¬†Ren, A.¬†Xie, and W.¬†Song, ‚ÄúRetrieve-rewrite-answer: A kg-to-text enhanced llms framework for knowledge graph question answering,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2309.11206</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L.¬†Luo, Y.-F. Li, G.¬†Haffari, and S.¬†Pan, ‚ÄúReasoning on graphs: Faithful and interpretable large language model reasoning,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2310.01061</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
S.¬†Siriwardhana, R.¬†Weerasekera, E.¬†Wen, T.¬†Kaluarachchi, R.¬†Rana, and S.¬†Nanayakkara, ‚ÄúImproving the domain adaptation of retrieval augmented generation (rag) models for open domain question answering,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Transactions of the Association for Computational Linguistics</em>, vol.¬†11, pp. 1‚Äì17, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
T.¬†Zhang, S.¬†G. Patil, N.¬†Jain, S.¬†Shen, M.¬†Zaharia, I.¬†Stoica, and J.¬†E. Gonzalez, ‚ÄúRaft: Adapting language model to domain specific rag,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2403.10131</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A.¬†Asai, Z.¬†Wu, Y.¬†Wang, A.¬†Sil, and H.¬†Hajishirzi, ‚ÄúSelf-rag: Learning to retrieve, generate, and critique through self-reflection,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2310.11511</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Y.¬†Mao, X.¬†Dong, W.¬†Xu, Y.¬†Gao, B.¬†Wei, and Y.¬†Zhang, ‚ÄúFit-rag: Black-box rag with factual information and token reduction,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2403.14374</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
B.¬†Abu-Salih, ‚ÄúDomain-specific knowledge graphs: A survey,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Journal of Network and Computer Applications</em>, vol. 185, p. 103076, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
G.¬†Agrawal, Y.¬†Deng, J.¬†Park, H.¬†Liu, and Y.-C. Chen, ‚ÄúBuilding knowledge graphs from unstructured texts: Applications and impact analyses in cybersecurity education,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Information</em>, vol.¬†13, no.¬†11, p. 526, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
X.¬†Tang, Z.¬†Feng, Y.¬†Xiao, M.¬†Wang, T.¬†Ye, Y.¬†Zhou, J.¬†Meng, B.¬†Zhang, and D.¬†Zhang, ‚ÄúConstruction and application of an ontology-based domain-specific knowledge graph for petroleum exploration and development,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Geoscience Frontiers</em>, vol.¬†14, no.¬†5, p. 101426, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G.¬†Agrawal, K.¬†Pal, Y.¬†Deng, H.¬†Liu, and C.¬†Baral, ‚ÄúAiseckg: Knowledge graph dataset for cybersecurity education,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">AAAI-MAKE 2023: Challenges Requiring the Combination of Machine Learning 2023</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J.¬†Delile, S.¬†Mukherjee, A.¬†Van¬†Pamel, and L.¬†Zhukov, ‚ÄúGraph-based retriever captures the long tail of biomedical knowledge,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2402.12352</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
X.¬†Jiang, R.¬†Zhang, Y.¬†Xu, R.¬†Qiu, Y.¬†Fang, Z.¬†Wang, J.¬†Tang, H.¬†Ding, X.¬†Chu, J.¬†Zhao <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">et¬†al.</em>, ‚ÄúHykge: A hypothesis knowledge graph enhanced framework for accurate and reliable medical llms responses.‚Äù

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
G.¬†Agrawal, K.¬†Pal, Y.¬†Deng, H.¬†Liu, and Y.-C. Chen, ‚ÄúCyberq: Generating questions and answers for cybersecurity education using knowledge graph-augmented llms,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol.¬†38, no.¬†21, 2024, pp. 23‚Äâ164‚Äì23‚Äâ172.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y.¬†Zhao, Z.¬†Li, and J.¬†Wang, ‚ÄúLb-kbqa: Large-language-model and bert based knowledge-based question and answering system,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2402.05130</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
G.¬†Agrawal, D.¬†Bertsekas, and H.¬†Liu, ‚ÄúAuction-based learning for question answering over knowledge graphs,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Information</em>, vol.¬†14, no.¬†6, p. 336, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Oct  6 16:14:59 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
