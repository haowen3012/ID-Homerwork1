<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM</title>
<!--Generated on Fri Oct 11 15:14:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.11557v4/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S1" title="In A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2" title="In A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS1" title="In 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Paper collection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS2" title="In 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Labelling and Indexing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS3" title="In 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Q&amp;A corpus data based on spectral knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS3.SSS1" title="In 2.3 Q&amp;A corpus data based on spectral knowledge ‚Ä£ 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Question focus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS3.SSS2" title="In 2.3 Q&amp;A corpus data based on spectral knowledge ‚Ä£ 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Question split and construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS3.SSS3" title="In 2.3 Q&amp;A corpus data based on spectral knowledge ‚Ä£ 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.3 </span>Answer generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S2.SS3.SSS4" title="In 2.3 Q&amp;A corpus data based on spectral knowledge ‚Ä£ 2 Datasets ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.4 </span>Data Cleaning</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S3" title="In A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S3.SS1" title="In 3 Method ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Question parsing and Entity extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S3.SS2" title="In 3 Method ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Retrieval Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S3.SS3" title="In 3 Method ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Generating output according to knowledge and task indicator</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4" title="In A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4.SS1" title="In 4 Experiment ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Detail of Implementation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4.SS2" title="In 4 Experiment ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Base models and Baseline</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4.SS3" title="In 4 Experiment ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4.SS4" title="In 4 Experiment ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Evaluation on LLM for extracting entity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4.SS5" title="In 4 Experiment ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Evaluation of the knowledge Retrieve</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S4.SS6" title="In 4 Experiment ‚Ä£ A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Evaluation on LLM for generating response</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S5" title="In A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#S6" title="In A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitation</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><a class="ltx_ref ltx_href" href="https://orcid.org/0009-0004-5522-0884" title=""><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="8" id="id1.1.1.g1" src="x1.png" width="8"/> Jiheng Liang</a>
<br class="ltx_break"/>School of Physics
<br class="ltx_break"/>State Key Laboratory of Optoelectronic Materials and Technologies
<br class="ltx_break"/>Sun Yat-Sen University
<br class="ltx_break"/>Guangzhou, 510275, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id1">liangjh65@mail2.sysu.edu.cn</span>
<br class="ltx_break"/>&amp;<a class="ltx_ref ltx_href" href="https://orcid.org/0000-0002-9763-8806" title=""><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="8" id="id2.2.2.g1" src="x2.png" width="8"/> Ziru Yu<span class="ltx_note ltx_role_footnote" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Corresponding author</span></span></span></a>
<br class="ltx_break"/>School of Automation Science and Engineering
<br class="ltx_break"/>South China University of Technology
<br class="ltx_break"/>Guangzhou, 510641, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id5.5.id2">202010102782@mail.scut.edu.cn</span>
<br class="ltx_break"/>&amp;<a class="ltx_ref ltx_href" href="https://orcid.org/0009-0000-1945-1045" title=""><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="8" id="id3.3.3.g1" src="x3.png" width="8"/> Zujie Xie,</a> Xiangyang Yu
<br class="ltx_break"/>School of Physics
<br class="ltx_break"/>State Key Laboratory of Optoelectronic Materials and Technologies
<br class="ltx_break"/>Nanchang Research Institute
Sun Yat-Sen University
<br class="ltx_break"/>Guangzhou, 510275, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id6.6.id3">(xiezj8,cesyxy)@mail2.sysu.edu.cn</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id7.id1">Large Language Model (LLM) has demonstrated significant success in a range of natural language processing (NLP) tasks within general domain. The emergence of LLM has introduced innovative methodologies across diverse fields, including the natural sciences. Researchers aim to implement automated, concurrent process driven by LLM to supplant conventional manual, repetitive and labor-intensive work. In the domain of spectral analysis and detection, it is imperative for researchers to autonomously acquire pertinent knowledge across various research objects, which encompasses the spectroscopic techniques and the chemometric methods that are employed in experiments and analysis. Paradoxically, despite the recognition of spectroscopic detection as an effective analytical method, the fundamental process of knowledge retrieval remains both time-intensive and repetitive. In response to this challenge, we first introduced the Spectral Detection and Analysis Based Paper(SDAAP) dataset, which is the first open-source textual knowledge dataset for spectral analysis and detection and contains annotated literature data as well as corresponding knowledge instruction data. Subsequently, we also designed an automated Q&amp;A framework based on the SDAAP dataset, which can retrieve relevant knowledge and generate high-quality responses by extracting entities in the input as retrieval parameters. It is worth noting that: within this framework, LLM is only used as a tool to provide generalizability, while RAG technique is used to accurately capture the source of the knowledge.This approach not only improves the quality of the generated responses, but also ensures the traceability of the knowledge. Experimental results show that our framework generates responses with more reliable expertise compared to the baseline.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Since Chat-GPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib1" title="">1</a>]</cite> came out of nowhere in late 2022, the concept of Large Language Model (LLM), which is a sophisticated deep learning model based on the Transformer with parameter sizes reaching into the tens of billions, has come back to the forefront of researchers‚Äô minds. The development of LLM has got significant attention due to the extensive knowledge and impressive interaction with humans. What‚Äôs more, the incredible ability of LLM about extracting implicit information from prompts with appropriate instruction-following distinguishes itself among most of previous deep learning models. Compared to their previous smaller counterparts, LLMs also demonstrate potent generalisation across various Natural Language Processing (NLP) tasks, illustrating their capacity to resolve unseen or intricate challenges in different domains. Currently, LLMs have demonstrated commendable performance in general domains<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib2" title="">2</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib3" title="">3</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib4" title="">4</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib5" title="">5</a>]</cite>. Furthermore and naturally, researchers want to introduce LLM in the natural science, a field that places a high demand on logical thinking, to relieve the extremely time-consuming and labour-intensive in practical applications. For instance, spectroscopy-based detection technology is a widely used analytical method with important applications in both the natural sciences and industry. However, for arbitrary samples, the spectroscopic techniques (e.g., Ultraviolet spectrum; Near-Infrared spectrum) and stoichiometric methods (e.g., Preprocessing method; Machine learning method) used in the experiment need to be determined based on past relevant studies because of the poor migration of model. Researchers have to spend a lot of time on the information collection of relevant data in the preliminary stage of the research, which is the most time-consuming and repetitive task in spectral analysis. Now, LLM can learn from large knowledge database and then can be used to provide related information about analyzed object including different points mentioned earlier, which may fully accelerate the procedure of spectral detection in different objects.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, a significant challenge in adapting LLM to the domain of spectral detection is the phenomenon of hallucination<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib6" title="">6</a>]</cite> concerning specialized knowledge. The general knowledge possessed by these models frequently proves inadequate when applied to specialized fields, primarily due to a deficiency in domain-specific expertise. Figure 1 shows the limitations of Chat-GPT 4 in answering questions in the field of spectral detection without source. Without the support of professional knowledge, it is difficult for general large models such as Chat-GPT 4 to generate accurate answers in professional fields. Given the high demand for reliability in the field of spectral detection, it is essential to enhance the knowledge base associated with LLM. This initiative is critical to ensure that LLM can provide accurate and dependable information to researchers engaged in spectral analysis methodologies. Instruction-tuned LLM, exemplified by InstructGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib7" title="">7</a>]</cite>, serve as the primary method to mitigate LLM into novel domains. This adaptation is achieved by constructing Instruction Fine-Tuning (IFT) data from knowledge database, thereby augmenting the expertise of LLM through supervised fine-tuning (SFT) and improving its interactive capabilities.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S1.F1.g1" src="x4.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The limitations of GPT 4 to answer questions in the field of spectral detection without sources</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">But Initially, it is important to note that the majority of existing relevant datasets are predominantly concentrated in the domains of bioscience<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib8" title="">8</a>]</cite> and medicine<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib9" title="">9</a>]</cite>. In contrast, the field of spectral analysis, which is considered relatively traditional, is characterized by a limited availability of open-source datasets. Most of datasets in this domain is primarily represented by spectral curves of specific sample types and is notably deficient in textual datasets suitable for NLP applications. Consequently, if there is an intention to adapt LLM to a spectral-related domain, it may be necessary to independently develop the requisite scientific datasets.Furthermore, it is indeed more challenging than one might expect for LLM can comprehend specialized knowledge and generate accurate, knowledge-consistent responses solely through SFT method<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib10" title="">10</a>]</cite> without undergoing additional pretraining. Recent studies have explored the integration of LLM with external application programming interfaces (APIs) to specific domains to improve the precision of model outputs<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib11" title="">11</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib12" title="">12</a>]</cite>. However, these methodologies necessitate operation on external servers, and the associated tasks are both financially burdensome and subject to network limitations, which may impede the progress of LLMs in scientific advancement.Lastly, from the perspective of a natural science researcher, scholars frequently concentrate on the foundational sources of knowledge, such as specific literature or knowledge bases, to facilitate their subsequent exploration of additional relevant information. However, an approach that relies solely on Instruction-tuned for LLM refinement may necessitate further annotation of knowledge sources within the IFT data if the intention is to cite the source of knowledge in the generated responses. This method does not instill a high degree of confidence in the accuracy of the outputs, representing a significant limitation. An alternative strategy involves the use of Retrieval Augmented Generation (RAG)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib13" title="">13</a>]</cite>, which leverages specialized databases to retrieve pertinent knowledge from data sources and generate responses accordingly. In essence, RAG integrates information retrieval methodologies with the generative capabilities of LLM, thereby addressing the limitations of Instruction-tuned techniques by direct access to data sources through annotations within databases conveniently. Much previous work<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib14" title="">14</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib15" title="">15</a>]</cite> has used a similar approach to source knowledge.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In our work, considering that professional literature constitutes a valuable repository of advanced knowledge, research findings, and engineering methodologies, we firstly present the Spectral Detection and Analysis Based Paper (SDAAP) dataset as a foundational source of knowledge. SDAAP encompasses information from relevant publications spanning the years 2014 to 2023, with each entry meticulously categorized such as the research object, the spectroscopic techniques employed, and the associated chemometric parameters. In addition to the labeled literature, SDAAP incorporates IFT data derived from the insights of all the publications in dataset; each IFT data also includes the relevant knowledge and its corresponding literature source, facilitating SFT process. The total number of IFT data amounts to more than 20,000 entries. Subsequently, based on SDAAP, we developed a automatic Q&amp;A framework in related domain, which can parse and extract the entity and question formats present in a query, employing the parsing outcomes as query parameters to retrieve pertinent spectral detection knowledge. LLM can then reference this retrieved knowledge to generate a response to the input query. Furthermore, our framework does not rely on instruction-tuning to facilitate the acquisition of new knowledge by LLM, but rather uses it as tool to provide generalizability. Instead, pertinent knowledge can be obtained in a relatively controlled manner through retrieval techniques, thereby enhancing the quality and reliability of the generated responses and ensuring the provision of accurate knowledge sources. In summary, our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">‚Ä¢We develop the SDAAP dataset, the first systematically organized open-source textual knowledge dataset for spectral analysis and detection. This dataset comprises annotated literature data alongside corresponding knowledge instruction data, thereby addressing a significant gap in textual datasets within the domain and establishing a foundational resource for the subsequent application of LLM in this area.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">‚Ä¢We designed a knowledge quiz framework based on the SDAAP dataset. The framework can generates high-quality and reliable responses by parsing questions and retrieving the knowledge associated with them, thereby responding the question of various Q&amp;A scenarios within the domain of spectral detection analysis and reducing the repetitive labour. Further details regarding the project are accessible on our GitHub page: coming soon.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">‚Ä¢Within our question-and-answer framework, we integrate techniques of Instruction tuning and retrieval-augmented generation (RAG). The LLM serves only as a tool to enhance generalizability, while RAG techniques are employed to accurately acquire the source of knowledge, thereby ensuring traceability of knowledge While augmenting quality of response.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Datasets</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">As is mentioned previously, the process of retrieving pertinent information within the context of industrial grading and detection through spectral analysis is predominantly characterized by repetitive works, resulting significant inefficient use of time. Leveraging LLM, an advanced computer science technology, can effectively streamline these repetitive tasks and release a substantial amount of human resources. In order do this, our research endeavors to incorporate LLM into spectral analysis to provide rapid and dependable responses to queries based on existing knowledge.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Recently, the mainstream approach to migrating LLM to a new domain has been to fine-tune LLM based on specialized corpora so that it can be adapted to the corresponding verticals<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib16" title="">16</a>]</cite>. However, very few existing open-source corpus datasets related to scientific and technical disciplines contain expertise related to spectral analysis. This means that there is a lack of professional datasets tailored for spectral analysis. Given the limited availability of open-source corpus dataset related to spectral analysis, this study opts to independently create a relevant dataset and its corresponding corpus from literature within the professional field. These corpus resources are then applied in our designed framework (see in Section 3) for reliable spectral detection knowledge question and answer (Q&amp;A) tasks. This section outlines the methodology employed for dataset construction, as well as the distribution of labels sourced from the dataset literature. Subsequently, a corpus dataset is constructed and made available, which can be utilized for various future research endeavors.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Paper collection</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In the context of paper collection focusing on spectral analysis using machine learning methods, the Web of Science was employed as an indexing tool to gather relevant scholarly literature comprising various domains (e.g. food, biology, energy‚Ä¶). Considering the prevalent use of machine learning methods in interdisciplinary research since 2015 approximately, scholarly paper published within the past decade (2013-2023) were selected for analysis. Various keyword combinations were utilized for the search, and subsequent operations, including paper de-duplication by human intervention, were conducted on the aggregated search results. A total of 4461 thesis were obtained through this screening process. It is important to note that all these papers are accessible in full-text format from reputable publishers like Nature, Springer, Elsevier, MDPI, among others. The scope of this resource transcends the English language to encompass a broader spectral detection of related knowledge. In the following Figure 2, an analysis of the publication timeline of these papers reveals a noticeable increase in the application of spectral analysis with machine learning method in detection and other areas. This trend underscores the significance of the research endeavor. Subsequently, a web-scraping tool was utilized to extract content from various publishers and convert it into plain text for further processing.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S2.F2.g1" src="x5.png" width="555"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of scientific paper dataset</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Labelling and Indexing</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">During a comprehensive spectral analysis investigation, researchers consistently focus on specific configurations at first. To effectively retrieve essential information from academic literature, it is essential to categorize profession academic papers into distinct labels that can be seamlessly integrated into our spectral Q&amp;A framework, thereby facilitating further research by independent scholars.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">In the first stage of spectral detection studies, researchers must select specific spectral methods, such as Near-Infrared spectrum (NIR), Ultraviolet spectrum (UV), Raman spectroscopy, among others, depending on the characteristics of the object and properties under investigation. Traditionally, this kind of process has been time-consuming as researchers are required to repeatedly search for and review numerous papers that are relevant to their study topic. Consequently, we primarily categorize this type of information across all papers within our datasets into the special kind of Label A. Through the automated retrieval facilitated based on Label A by our framework, researchers are able to efficiently access pertinent information related to their own research with different spectral detection method, thereby streamlining the process and minimizing tedious tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Once the spectral method employed in the experiment and its pertinent specifics have been identified, the selection of the machine learning technique and its associated parameters becomes crucial during the data processing stage. We synthesized and categorized the machine learning information extracted from the papers in our datasets into a class of Label B that is distinct from Label A, including preprocessing techniques, feature processing methods, and models for further analysis.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">In brief, the extracted labels from any one of papers in our datasets can be divided into two primary sections: Label A is utilizes for summarizing essential information, such as spectral method, and directing researchers towards papers that are most pertinent to their inquiry; Label B is focuses on providing insights into machine learning techniques employed in the paper. These labels aid in pinpointing relevant and valuable literature that pertains to various inquiries posed in the knowledge quiz concerning spectral detection.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">For instance, we presented a selection of labels derived from some papers within our datasets in the Figure 3 provided below. The methodology involves utilizing Chat-GPT to extract labels from the papers, followed by a manual data cleaning process to rectify any inaccuracies. Notably, majority of labels are only obtained from the abstract section of the papers. Since that abstracts encapsulate the core elements of the literature, encompassing objectives, methods, conclusions, etc., most of labels we need can be extracted from it, and this minimizes copyright issues. In instances where labels cannot be directly derived from the abstract, such as preprocessing methods and machine learning models, the paper is converted into embedding vectors. Subsequently, relevant answers are retrieved based on maximum cosine similarity to extract the corresponding labels.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S2.F3.g1" src="x6.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Two categories of labels of scientific paper</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Q&amp;A corpus data based on spectral knowledge</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">It is widely acknowledged that Instruction Fine Tuning (IFT) data is crucial for the implementation of LLM in vertical domain and other Natural Language Processing tasks. Due to the absence of specialized IFT data for spectral detection and analysis, we have developed a framework to create IFT data automatically for each labeled literature in our datasets using Chat-GPT. This framework consists of four distinct stpdf as follows.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Question focus</h4>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS1.p1">
<p class="ltx_p" id="S2.SS3.SSS1.p1.1">Drawing upon prior knowledge within specific fields, we initially selected commonly encountered questions in practical scenarios. As an example, in the context of spectral analysis and detection research, we focus the category of spectral method, preprocessing methods, feature processing methods, metrics and outcomes, as well as machine learning models. These topics are frequently addressed in spectral analysis studies and are utilized to compile our Q&amp;A corpus data.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Question split and construction</h4>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS2.p1">
<p class="ltx_p" id="S2.SS3.SSS2.p1.1">A template was developed to facilitate the generation of the question component of the corpus. This template consists of two parts: Part A, which serves to define the research object, and Part B, which is utilized to create various question. By inputting the appropriate label of the paper as a prompt, users can efficiently employ Chat-GPT to generate diverse formats of question. This template is designed to be easily adaptable to different research subjects. The structure of the template is illustrated in the Figure 4 below.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3 </span>Answer generation</h4>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS3.p1">
<p class="ltx_p" id="S2.SS3.SSS3.p1.1">In the same way as second step, we embed the question and the label corresponding to the answer from paper into the prompt, and ask Chat-GPT to generate a formatted answer based on the information provided. Here, we only constructed limited types of Q&amp;A corpus data mentioned in section 2.3.1. To acquire additional Q&amp;A data, researchers can simply substitute Part B questions corresponding to different labels.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.4 </span>Data Cleaning</h4>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS4.p1">
<p class="ltx_p" id="S2.SS3.SSS4.p1.1">While the utilization of Chat-GPT for generating IFT data has become prevalent in cutting-edge research, there are still challenges that require human intervention. For instance, the extensive automated generation of Q&amp;A data using LLM driven approach always encounter obstacles related to inappropriate representation, just like "This study used (Method A) to (Object B)". Actually, the utilization of the phrase "This study" as the subject in typical question and answer interactions is not recommended. If a substantial portion of the generated data exhibits such issues, it may affect the application of these corpus data in downstream tasks. To address these concerns, manual intervention is employed to rectify similar problems, for instance, by replacing phrases like " This study used (Method A) to (Object B)" with "Related studies show that (Method A) can be used in (Object B)".</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS4.p2">
<p class="ltx_p" id="S2.SS3.SSS4.p2.1">Over all the following stpdf, we finally got high quality IFT data, totally including 22305 items based on different paper and each item include one question and matched answer with related knowledge in particular paper. All the corpus data were contained in our dataset and are publicly accessible.</p>
</div>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S2.F4.g1" src="x7.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Process for knowledge-based response generation. Step 1:
Extract the entity of the input question. Step 2: Acquire the knowledge from the SDAAP dataset. Step 3: Generate a response with acquiredknowledge.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">As mentioned earlier, extensive language models have a broad spectrum of applications across various fields, with one prominent example being the utilization of large models to develop specialized domain question-and-answer (Q&amp;A) systems<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib17" title="">17</a>]</cite>. By employing fine-tuning techniques, these large models can be further customized using specific domain data to enhance their understanding of vertical domain-specific information. This method significantly enhances the performance of large language models in a multitude of contexts<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib18" title="">18</a>]</cite>. The refined macro-models serve as modern expert systems, catering to the growing demand for tools that facilitate the rapid and accurate acquisition of pertinent knowledge to optimize time management. Nevertheless, the results produced by fine-tuned macro-language models may not always be dependable in domains where high-confidence outputs are essential, such as in the fields of biology, medicine, and industrial inspection. Furthermore, users often face challenges in accurately tracing the sources of the information provided in the responses, a particularly crucial aspect in scientific and technical research.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.2">To address these challenges, we employed a dual strategy involving the refinement of instructional methods and the utilization of RAG (Retrieval-Augmented Generation) to develop a question-and-answer (Q&amp;A) framework centered around a comprehensive language model, as shown in the Figure 5 below. Leveraging a meticulously curated dataset enriched with specialized literature as a foundational knowledge repository, we operationalized the Q&amp;A system within the domain of spectral detection and analysis. The framework, powered by an advanced language model, is adept at processing diverse question formats (<math alttext="q_{i}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><msub id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">q</mi><mi id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">ùëû</ci><ci id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>), retrieving relevant information from the knowledge base, and delivering accurate responses (<math alttext="r_{i}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">r</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ùëü</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">r_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>). Given that our knowledge repository is structured around annotated literature sources, each piece of information can be directly linked back to its respective source, enabling transparent tracking of the expertise underpinning the generated responses. Subsequently, we outline the three key elements comprising the framework: entity extraction and question parsing, knowledge retrieval, and response generation.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S3.F5.g1" src="x8.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Detailed framework of the Q&amp;A system</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Question parsing and Entity extraction</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For arbitrary question input, we need to obtain the object of related study indicated in the question at first. As an example, considering ‚ÄúIn the related study on the prediction of sweetness in apples, ‚Ä¶‚Äù, the process of extracting entity information related to the inquiry involves identifying the subject of the study (apples) and the specific aspect under investigation (sweetness). Typically, questions contain descriptive elements that pertain to the object of study, facilitating the extraction of relevant content in a more generalized manner.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S6.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle M(Prompt_{e},Ques)=E_{pre}" class="ltx_Math" display="inline" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.4.cmml">M</mi><mo id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.3.cmml">‚Å¢</mo><mrow id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.3.cmml"><mo id="S3.E1.m1.2.2.2.2.2.3" stretchy="false" xref="S3.E1.m1.2.2.2.2.3.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">P</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">r</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1a" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml">o</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1b" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.1.1.5.cmml">m</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1c" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.6" xref="S3.E1.m1.1.1.1.1.1.1.6.cmml">p</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1d" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><msub id="S3.E1.m1.1.1.1.1.1.1.7" xref="S3.E1.m1.1.1.1.1.1.1.7.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.7.2" xref="S3.E1.m1.1.1.1.1.1.1.7.2.cmml">t</mi><mi id="S3.E1.m1.1.1.1.1.1.1.7.3" xref="S3.E1.m1.1.1.1.1.1.1.7.3.cmml">e</mi></msub></mrow><mo id="S3.E1.m1.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.3.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml">Q</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml">u</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1a" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.2.4.cmml">e</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1b" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.2.2.2.2.5" xref="S3.E1.m1.2.2.2.2.2.2.5.cmml">s</mi></mrow><mo id="S3.E1.m1.2.2.2.2.2.5" stretchy="false" xref="S3.E1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.3.cmml">=</mo><msub id="S3.E1.m1.2.2.4" xref="S3.E1.m1.2.2.4.cmml"><mi id="S3.E1.m1.2.2.4.2" xref="S3.E1.m1.2.2.4.2.cmml">E</mi><mrow id="S3.E1.m1.2.2.4.3" xref="S3.E1.m1.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.4.3.2" xref="S3.E1.m1.2.2.4.3.2.cmml">p</mi><mo id="S3.E1.m1.2.2.4.3.1" xref="S3.E1.m1.2.2.4.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.4.3.3" xref="S3.E1.m1.2.2.4.3.3.cmml">r</mi><mo id="S3.E1.m1.2.2.4.3.1a" xref="S3.E1.m1.2.2.4.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.2.2.4.3.4" xref="S3.E1.m1.2.2.4.3.4.cmml">e</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><eq id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3"></eq><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><times id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.3"></times><ci id="S3.E1.m1.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.4">ùëÄ</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">ùëÉ</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">ùëü</ci><ci id="S3.E1.m1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4">ùëú</ci><ci id="S3.E1.m1.1.1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.1.1.5">ùëö</ci><ci id="S3.E1.m1.1.1.1.1.1.1.6.cmml" xref="S3.E1.m1.1.1.1.1.1.1.6">ùëù</ci><apply id="S3.E1.m1.1.1.1.1.1.1.7.cmml" xref="S3.E1.m1.1.1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.7.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.7">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.7.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.7.2">ùë°</ci><ci id="S3.E1.m1.1.1.1.1.1.1.7.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.7.3">ùëí</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><times id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"></times><ci id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">ùëÑ</ci><ci id="S3.E1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3">ùë¢</ci><ci id="S3.E1.m1.2.2.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.2.2.4">ùëí</ci><ci id="S3.E1.m1.2.2.2.2.2.2.5.cmml" xref="S3.E1.m1.2.2.2.2.2.2.5">ùë†</ci></apply></interval></apply><apply id="S3.E1.m1.2.2.4.cmml" xref="S3.E1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.4.1.cmml" xref="S3.E1.m1.2.2.4">subscript</csymbol><ci id="S3.E1.m1.2.2.4.2.cmml" xref="S3.E1.m1.2.2.4.2">ùê∏</ci><apply id="S3.E1.m1.2.2.4.3.cmml" xref="S3.E1.m1.2.2.4.3"><times id="S3.E1.m1.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.4.3.1"></times><ci id="S3.E1.m1.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.4.3.2">ùëù</ci><ci id="S3.E1.m1.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.4.3.3">ùëü</ci><ci id="S3.E1.m1.2.2.4.3.4.cmml" xref="S3.E1.m1.2.2.4.3.4">ùëí</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\displaystyle M(Prompt_{e},Ques)=E_{pre}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">italic_M ( italic_P italic_r italic_o italic_m italic_p italic_t start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_Q italic_u italic_e italic_s ) = italic_E start_POSTSUBSCRIPT italic_p italic_r italic_e end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle Loss_{Entity}(Ques)=Loss_{Entity}(E_{pre},Groundtruth)" class="ltx_Math" display="inline" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">L</mi><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.4" xref="S3.E2.m1.1.1.1.4.cmml">o</mi><mo id="S3.E2.m1.1.1.1.2a" xref="S3.E2.m1.1.1.1.2.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.5" xref="S3.E2.m1.1.1.1.5.cmml">s</mi><mo id="S3.E2.m1.1.1.1.2b" xref="S3.E2.m1.1.1.1.2.cmml">‚Å¢</mo><msub id="S3.E2.m1.1.1.1.6" xref="S3.E2.m1.1.1.1.6.cmml"><mi id="S3.E2.m1.1.1.1.6.2" xref="S3.E2.m1.1.1.1.6.2.cmml">s</mi><mrow id="S3.E2.m1.1.1.1.6.3" xref="S3.E2.m1.1.1.1.6.3.cmml"><mi id="S3.E2.m1.1.1.1.6.3.2" xref="S3.E2.m1.1.1.1.6.3.2.cmml">E</mi><mo id="S3.E2.m1.1.1.1.6.3.1" xref="S3.E2.m1.1.1.1.6.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.6.3.3" xref="S3.E2.m1.1.1.1.6.3.3.cmml">n</mi><mo id="S3.E2.m1.1.1.1.6.3.1a" xref="S3.E2.m1.1.1.1.6.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.6.3.4" xref="S3.E2.m1.1.1.1.6.3.4.cmml">t</mi><mo id="S3.E2.m1.1.1.1.6.3.1b" xref="S3.E2.m1.1.1.1.6.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.6.3.5" xref="S3.E2.m1.1.1.1.6.3.5.cmml">i</mi><mo id="S3.E2.m1.1.1.1.6.3.1c" xref="S3.E2.m1.1.1.1.6.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.6.3.6" xref="S3.E2.m1.1.1.1.6.3.6.cmml">t</mi><mo id="S3.E2.m1.1.1.1.6.3.1d" xref="S3.E2.m1.1.1.1.6.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.6.3.7" xref="S3.E2.m1.1.1.1.6.3.7.cmml">y</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.2c" xref="S3.E2.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">Q</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">u</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1a" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.1.1.4.cmml">e</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1b" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.1.1.1.1.5" xref="S3.E2.m1.1.1.1.1.1.1.5.cmml">s</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.4" xref="S3.E2.m1.3.3.4.cmml">=</mo><mrow id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml"><mi id="S3.E2.m1.3.3.3.4" xref="S3.E2.m1.3.3.3.4.cmml">L</mi><mo id="S3.E2.m1.3.3.3.3" xref="S3.E2.m1.3.3.3.3.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.5" xref="S3.E2.m1.3.3.3.5.cmml">o</mi><mo id="S3.E2.m1.3.3.3.3a" xref="S3.E2.m1.3.3.3.3.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.6" xref="S3.E2.m1.3.3.3.6.cmml">s</mi><mo id="S3.E2.m1.3.3.3.3b" xref="S3.E2.m1.3.3.3.3.cmml">‚Å¢</mo><msub id="S3.E2.m1.3.3.3.7" xref="S3.E2.m1.3.3.3.7.cmml"><mi id="S3.E2.m1.3.3.3.7.2" xref="S3.E2.m1.3.3.3.7.2.cmml">s</mi><mrow id="S3.E2.m1.3.3.3.7.3" xref="S3.E2.m1.3.3.3.7.3.cmml"><mi id="S3.E2.m1.3.3.3.7.3.2" xref="S3.E2.m1.3.3.3.7.3.2.cmml">E</mi><mo id="S3.E2.m1.3.3.3.7.3.1" xref="S3.E2.m1.3.3.3.7.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.7.3.3" xref="S3.E2.m1.3.3.3.7.3.3.cmml">n</mi><mo id="S3.E2.m1.3.3.3.7.3.1a" xref="S3.E2.m1.3.3.3.7.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.7.3.4" xref="S3.E2.m1.3.3.3.7.3.4.cmml">t</mi><mo id="S3.E2.m1.3.3.3.7.3.1b" xref="S3.E2.m1.3.3.3.7.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.7.3.5" xref="S3.E2.m1.3.3.3.7.3.5.cmml">i</mi><mo id="S3.E2.m1.3.3.3.7.3.1c" xref="S3.E2.m1.3.3.3.7.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.7.3.6" xref="S3.E2.m1.3.3.3.7.3.6.cmml">t</mi><mo id="S3.E2.m1.3.3.3.7.3.1d" xref="S3.E2.m1.3.3.3.7.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.7.3.7" xref="S3.E2.m1.3.3.3.7.3.7.cmml">y</mi></mrow></msub><mo id="S3.E2.m1.3.3.3.3c" xref="S3.E2.m1.3.3.3.3.cmml">‚Å¢</mo><mrow id="S3.E2.m1.3.3.3.2.2" xref="S3.E2.m1.3.3.3.2.3.cmml"><mo id="S3.E2.m1.3.3.3.2.2.3" stretchy="false" xref="S3.E2.m1.3.3.3.2.3.cmml">(</mo><msub id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.2.cmml">E</mi><mrow id="S3.E2.m1.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.3.2" xref="S3.E2.m1.2.2.2.1.1.1.3.2.cmml">p</mi><mo id="S3.E2.m1.2.2.2.1.1.1.3.1" xref="S3.E2.m1.2.2.2.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.2.2.2.1.1.1.3.3" xref="S3.E2.m1.2.2.2.1.1.1.3.3.cmml">r</mi><mo id="S3.E2.m1.2.2.2.1.1.1.3.1a" xref="S3.E2.m1.2.2.2.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.2.2.2.1.1.1.3.4" xref="S3.E2.m1.2.2.2.1.1.1.3.4.cmml">e</mi></mrow></msub><mo id="S3.E2.m1.3.3.3.2.2.4" xref="S3.E2.m1.3.3.3.2.3.cmml">,</mo><mrow id="S3.E2.m1.3.3.3.2.2.2" xref="S3.E2.m1.3.3.3.2.2.2.cmml"><mi id="S3.E2.m1.3.3.3.2.2.2.2" xref="S3.E2.m1.3.3.3.2.2.2.2.cmml">G</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.3" xref="S3.E2.m1.3.3.3.2.2.2.3.cmml">r</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1a" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.4" xref="S3.E2.m1.3.3.3.2.2.2.4.cmml">o</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1b" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.5" xref="S3.E2.m1.3.3.3.2.2.2.5.cmml">u</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1c" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.6" xref="S3.E2.m1.3.3.3.2.2.2.6.cmml">n</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1d" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.7" xref="S3.E2.m1.3.3.3.2.2.2.7.cmml">d</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1e" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.8" xref="S3.E2.m1.3.3.3.2.2.2.8.cmml">t</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1f" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.9" xref="S3.E2.m1.3.3.3.2.2.2.9.cmml">r</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1g" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.10" xref="S3.E2.m1.3.3.3.2.2.2.10.cmml">u</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1h" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.11" xref="S3.E2.m1.3.3.3.2.2.2.11.cmml">t</mi><mo id="S3.E2.m1.3.3.3.2.2.2.1i" xref="S3.E2.m1.3.3.3.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.3.3.3.2.2.2.12" xref="S3.E2.m1.3.3.3.2.2.2.12.cmml">h</mi></mrow><mo id="S3.E2.m1.3.3.3.2.2.5" stretchy="false" xref="S3.E2.m1.3.3.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"><eq id="S3.E2.m1.3.3.4.cmml" xref="S3.E2.m1.3.3.4"></eq><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">ùêø</ci><ci id="S3.E2.m1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.4">ùëú</ci><ci id="S3.E2.m1.1.1.1.5.cmml" xref="S3.E2.m1.1.1.1.5">ùë†</ci><apply id="S3.E2.m1.1.1.1.6.cmml" xref="S3.E2.m1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.6.1.cmml" xref="S3.E2.m1.1.1.1.6">subscript</csymbol><ci id="S3.E2.m1.1.1.1.6.2.cmml" xref="S3.E2.m1.1.1.1.6.2">ùë†</ci><apply id="S3.E2.m1.1.1.1.6.3.cmml" xref="S3.E2.m1.1.1.1.6.3"><times id="S3.E2.m1.1.1.1.6.3.1.cmml" xref="S3.E2.m1.1.1.1.6.3.1"></times><ci id="S3.E2.m1.1.1.1.6.3.2.cmml" xref="S3.E2.m1.1.1.1.6.3.2">ùê∏</ci><ci id="S3.E2.m1.1.1.1.6.3.3.cmml" xref="S3.E2.m1.1.1.1.6.3.3">ùëõ</ci><ci id="S3.E2.m1.1.1.1.6.3.4.cmml" xref="S3.E2.m1.1.1.1.6.3.4">ùë°</ci><ci id="S3.E2.m1.1.1.1.6.3.5.cmml" xref="S3.E2.m1.1.1.1.6.3.5">ùëñ</ci><ci id="S3.E2.m1.1.1.1.6.3.6.cmml" xref="S3.E2.m1.1.1.1.6.3.6">ùë°</ci><ci id="S3.E2.m1.1.1.1.6.3.7.cmml" xref="S3.E2.m1.1.1.1.6.3.7">ùë¶</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">ùëÑ</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">ùë¢</ci><ci id="S3.E2.m1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4">ùëí</ci><ci id="S3.E2.m1.1.1.1.1.1.1.5.cmml" xref="S3.E2.m1.1.1.1.1.1.1.5">ùë†</ci></apply></apply><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3"><times id="S3.E2.m1.3.3.3.3.cmml" xref="S3.E2.m1.3.3.3.3"></times><ci id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.4">ùêø</ci><ci id="S3.E2.m1.3.3.3.5.cmml" xref="S3.E2.m1.3.3.3.5">ùëú</ci><ci id="S3.E2.m1.3.3.3.6.cmml" xref="S3.E2.m1.3.3.3.6">ùë†</ci><apply id="S3.E2.m1.3.3.3.7.cmml" xref="S3.E2.m1.3.3.3.7"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.7.1.cmml" xref="S3.E2.m1.3.3.3.7">subscript</csymbol><ci id="S3.E2.m1.3.3.3.7.2.cmml" xref="S3.E2.m1.3.3.3.7.2">ùë†</ci><apply id="S3.E2.m1.3.3.3.7.3.cmml" xref="S3.E2.m1.3.3.3.7.3"><times id="S3.E2.m1.3.3.3.7.3.1.cmml" xref="S3.E2.m1.3.3.3.7.3.1"></times><ci id="S3.E2.m1.3.3.3.7.3.2.cmml" xref="S3.E2.m1.3.3.3.7.3.2">ùê∏</ci><ci id="S3.E2.m1.3.3.3.7.3.3.cmml" xref="S3.E2.m1.3.3.3.7.3.3">ùëõ</ci><ci id="S3.E2.m1.3.3.3.7.3.4.cmml" xref="S3.E2.m1.3.3.3.7.3.4">ùë°</ci><ci id="S3.E2.m1.3.3.3.7.3.5.cmml" xref="S3.E2.m1.3.3.3.7.3.5">ùëñ</ci><ci id="S3.E2.m1.3.3.3.7.3.6.cmml" xref="S3.E2.m1.3.3.3.7.3.6">ùë°</ci><ci id="S3.E2.m1.3.3.3.7.3.7.cmml" xref="S3.E2.m1.3.3.3.7.3.7">ùë¶</ci></apply></apply><interval closure="open" id="S3.E2.m1.3.3.3.2.3.cmml" xref="S3.E2.m1.3.3.3.2.2"><apply id="S3.E2.m1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2">ùê∏</ci><apply id="S3.E2.m1.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3"><times id="S3.E2.m1.2.2.2.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.1"></times><ci id="S3.E2.m1.2.2.2.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.2">ùëù</ci><ci id="S3.E2.m1.2.2.2.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.3">ùëü</ci><ci id="S3.E2.m1.2.2.2.1.1.1.3.4.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3.4">ùëí</ci></apply></apply><apply id="S3.E2.m1.3.3.3.2.2.2.cmml" xref="S3.E2.m1.3.3.3.2.2.2"><times id="S3.E2.m1.3.3.3.2.2.2.1.cmml" xref="S3.E2.m1.3.3.3.2.2.2.1"></times><ci id="S3.E2.m1.3.3.3.2.2.2.2.cmml" xref="S3.E2.m1.3.3.3.2.2.2.2">ùê∫</ci><ci id="S3.E2.m1.3.3.3.2.2.2.3.cmml" xref="S3.E2.m1.3.3.3.2.2.2.3">ùëü</ci><ci id="S3.E2.m1.3.3.3.2.2.2.4.cmml" xref="S3.E2.m1.3.3.3.2.2.2.4">ùëú</ci><ci id="S3.E2.m1.3.3.3.2.2.2.5.cmml" xref="S3.E2.m1.3.3.3.2.2.2.5">ùë¢</ci><ci id="S3.E2.m1.3.3.3.2.2.2.6.cmml" xref="S3.E2.m1.3.3.3.2.2.2.6">ùëõ</ci><ci id="S3.E2.m1.3.3.3.2.2.2.7.cmml" xref="S3.E2.m1.3.3.3.2.2.2.7">ùëë</ci><ci id="S3.E2.m1.3.3.3.2.2.2.8.cmml" xref="S3.E2.m1.3.3.3.2.2.2.8">ùë°</ci><ci id="S3.E2.m1.3.3.3.2.2.2.9.cmml" xref="S3.E2.m1.3.3.3.2.2.2.9">ùëü</ci><ci id="S3.E2.m1.3.3.3.2.2.2.10.cmml" xref="S3.E2.m1.3.3.3.2.2.2.10">ùë¢</ci><ci id="S3.E2.m1.3.3.3.2.2.2.11.cmml" xref="S3.E2.m1.3.3.3.2.2.2.11">ùë°</ci><ci id="S3.E2.m1.3.3.3.2.2.2.12.cmml" xref="S3.E2.m1.3.3.3.2.2.2.12">‚Ñé</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\displaystyle Loss_{Entity}(Ques)=Loss_{Entity}(E_{pre},Groundtruth)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_E italic_n italic_t italic_i italic_t italic_y end_POSTSUBSCRIPT ( italic_Q italic_u italic_e italic_s ) = italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_E italic_n italic_t italic_i italic_t italic_y end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_p italic_r italic_e end_POSTSUBSCRIPT , italic_G italic_r italic_o italic_u italic_n italic_d italic_t italic_r italic_u italic_t italic_h )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.2">Furthermore, it is essential to extract information concerning entities that are pertinent to the orientation of the question. In the context of spectral detection, questions of interest to researchers can be categorized into two main groups: the first pertains to the selection of spectral detection methods in experiments, while the second involves the modeling and calculation procedures post data acquisition. These distinct types of questions necessitate different approaches for addressing them effectively. For questions falling under the first category, which may involve various spectral detection methods for a given study, it is crucial to identify and compare analytical methods from relevant literature, considering factors such as accuracy and experimental conditions. Conversely, questions related to the second category may require additional information on the spectral category used and the specific objective of the inquiry to facilitate knowledge retrieval and response generation.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">To differentiate between these two question categories, a dichotomous indicator termed "<math alttext="task\_indicator" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">t</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">a</mi><mo id="S3.SS1.p2.1.m1.1.1.1a" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.4" xref="S3.SS1.p2.1.m1.1.1.4.cmml">s</mi><mo id="S3.SS1.p2.1.m1.1.1.1b" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.5" xref="S3.SS1.p2.1.m1.1.1.5.cmml">k</mi><mo id="S3.SS1.p2.1.m1.1.1.1c" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.6" mathvariant="normal" xref="S3.SS1.p2.1.m1.1.1.6.cmml">_</mi><mo id="S3.SS1.p2.1.m1.1.1.1d" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.7" xref="S3.SS1.p2.1.m1.1.1.7.cmml">i</mi><mo id="S3.SS1.p2.1.m1.1.1.1e" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.8" xref="S3.SS1.p2.1.m1.1.1.8.cmml">n</mi><mo id="S3.SS1.p2.1.m1.1.1.1f" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.9" xref="S3.SS1.p2.1.m1.1.1.9.cmml">d</mi><mo id="S3.SS1.p2.1.m1.1.1.1g" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.10" xref="S3.SS1.p2.1.m1.1.1.10.cmml">i</mi><mo id="S3.SS1.p2.1.m1.1.1.1h" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.11" xref="S3.SS1.p2.1.m1.1.1.11.cmml">c</mi><mo id="S3.SS1.p2.1.m1.1.1.1i" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.12" xref="S3.SS1.p2.1.m1.1.1.12.cmml">a</mi><mo id="S3.SS1.p2.1.m1.1.1.1j" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.13" xref="S3.SS1.p2.1.m1.1.1.13.cmml">t</mi><mo id="S3.SS1.p2.1.m1.1.1.1k" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.14" xref="S3.SS1.p2.1.m1.1.1.14.cmml">o</mi><mo id="S3.SS1.p2.1.m1.1.1.1l" xref="S3.SS1.p2.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS1.p2.1.m1.1.1.15" xref="S3.SS1.p2.1.m1.1.1.15.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><times id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></times><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ùë°</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ùëé</ci><ci id="S3.SS1.p2.1.m1.1.1.4.cmml" xref="S3.SS1.p2.1.m1.1.1.4">ùë†</ci><ci id="S3.SS1.p2.1.m1.1.1.5.cmml" xref="S3.SS1.p2.1.m1.1.1.5">ùëò</ci><ci id="S3.SS1.p2.1.m1.1.1.6.cmml" xref="S3.SS1.p2.1.m1.1.1.6">_</ci><ci id="S3.SS1.p2.1.m1.1.1.7.cmml" xref="S3.SS1.p2.1.m1.1.1.7">ùëñ</ci><ci id="S3.SS1.p2.1.m1.1.1.8.cmml" xref="S3.SS1.p2.1.m1.1.1.8">ùëõ</ci><ci id="S3.SS1.p2.1.m1.1.1.9.cmml" xref="S3.SS1.p2.1.m1.1.1.9">ùëë</ci><ci id="S3.SS1.p2.1.m1.1.1.10.cmml" xref="S3.SS1.p2.1.m1.1.1.10">ùëñ</ci><ci id="S3.SS1.p2.1.m1.1.1.11.cmml" xref="S3.SS1.p2.1.m1.1.1.11">ùëê</ci><ci id="S3.SS1.p2.1.m1.1.1.12.cmml" xref="S3.SS1.p2.1.m1.1.1.12">ùëé</ci><ci id="S3.SS1.p2.1.m1.1.1.13.cmml" xref="S3.SS1.p2.1.m1.1.1.13">ùë°</ci><ci id="S3.SS1.p2.1.m1.1.1.14.cmml" xref="S3.SS1.p2.1.m1.1.1.14">ùëú</ci><ci id="S3.SS1.p2.1.m1.1.1.15.cmml" xref="S3.SS1.p2.1.m1.1.1.15">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">task\_indicator</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_t italic_a italic_s italic_k _ italic_i italic_n italic_d italic_i italic_c italic_a italic_t italic_o italic_r</annotation></semantics></math>" is introduced in the questioning process. This indicator helps to categorize questions and determine the need for acquiring additional entity information based on the nature of the inquiry. For the first category of questions, there is no need to obtain any additional entity information; for the second category of questions, in addition to the previously obtained relevant content of the research object, we need to additionally obtain the two parts of the adopted spectral category and the question objective for subsequent knowledge retrieval and response generation. Given its capacity for generalization across various input forms and adeptness at addressing diverse inquiries, LLM-1 was employed in this study to extract entity information of two distinct types. Through fine-tuning the LLM-1 with task-specific data, it was able to efficiently and precisely retrieve the specified entity information. Further elaboration on the experimental results can be found in Section IV.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S3.F6.g1" src="x9.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Different approaches to two types of questions</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Retrieval Datasets</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.3">Following the extraction of entities, the query is transformed into a tuple comprising various instances, denoted as (<math alttext="q_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">q</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ùëû</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="e_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">e</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ùëí</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">e_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="task\_indicator" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">t</mi><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">a</mi><mo id="S3.SS2.p1.3.m3.1.1.1a" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.4" xref="S3.SS2.p1.3.m3.1.1.4.cmml">s</mi><mo id="S3.SS2.p1.3.m3.1.1.1b" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.5" xref="S3.SS2.p1.3.m3.1.1.5.cmml">k</mi><mo id="S3.SS2.p1.3.m3.1.1.1c" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.6" mathvariant="normal" xref="S3.SS2.p1.3.m3.1.1.6.cmml">_</mi><mo id="S3.SS2.p1.3.m3.1.1.1d" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.7" xref="S3.SS2.p1.3.m3.1.1.7.cmml">i</mi><mo id="S3.SS2.p1.3.m3.1.1.1e" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.8" xref="S3.SS2.p1.3.m3.1.1.8.cmml">n</mi><mo id="S3.SS2.p1.3.m3.1.1.1f" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.9" xref="S3.SS2.p1.3.m3.1.1.9.cmml">d</mi><mo id="S3.SS2.p1.3.m3.1.1.1g" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.10" xref="S3.SS2.p1.3.m3.1.1.10.cmml">i</mi><mo id="S3.SS2.p1.3.m3.1.1.1h" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.11" xref="S3.SS2.p1.3.m3.1.1.11.cmml">c</mi><mo id="S3.SS2.p1.3.m3.1.1.1i" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.12" xref="S3.SS2.p1.3.m3.1.1.12.cmml">a</mi><mo id="S3.SS2.p1.3.m3.1.1.1j" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.13" xref="S3.SS2.p1.3.m3.1.1.13.cmml">t</mi><mo id="S3.SS2.p1.3.m3.1.1.1k" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.14" xref="S3.SS2.p1.3.m3.1.1.14.cmml">o</mi><mo id="S3.SS2.p1.3.m3.1.1.1l" xref="S3.SS2.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p1.3.m3.1.1.15" xref="S3.SS2.p1.3.m3.1.1.15.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><times id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></times><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ùë°</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">ùëé</ci><ci id="S3.SS2.p1.3.m3.1.1.4.cmml" xref="S3.SS2.p1.3.m3.1.1.4">ùë†</ci><ci id="S3.SS2.p1.3.m3.1.1.5.cmml" xref="S3.SS2.p1.3.m3.1.1.5">ùëò</ci><ci id="S3.SS2.p1.3.m3.1.1.6.cmml" xref="S3.SS2.p1.3.m3.1.1.6">_</ci><ci id="S3.SS2.p1.3.m3.1.1.7.cmml" xref="S3.SS2.p1.3.m3.1.1.7">ùëñ</ci><ci id="S3.SS2.p1.3.m3.1.1.8.cmml" xref="S3.SS2.p1.3.m3.1.1.8">ùëõ</ci><ci id="S3.SS2.p1.3.m3.1.1.9.cmml" xref="S3.SS2.p1.3.m3.1.1.9">ùëë</ci><ci id="S3.SS2.p1.3.m3.1.1.10.cmml" xref="S3.SS2.p1.3.m3.1.1.10">ùëñ</ci><ci id="S3.SS2.p1.3.m3.1.1.11.cmml" xref="S3.SS2.p1.3.m3.1.1.11">ùëê</ci><ci id="S3.SS2.p1.3.m3.1.1.12.cmml" xref="S3.SS2.p1.3.m3.1.1.12">ùëé</ci><ci id="S3.SS2.p1.3.m3.1.1.13.cmml" xref="S3.SS2.p1.3.m3.1.1.13">ùë°</ci><ci id="S3.SS2.p1.3.m3.1.1.14.cmml" xref="S3.SS2.p1.3.m3.1.1.14">ùëú</ci><ci id="S3.SS2.p1.3.m3.1.1.15.cmml" xref="S3.SS2.p1.3.m3.1.1.15">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">task\_indicator</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_t italic_a italic_s italic_k _ italic_i italic_n italic_d italic_i italic_c italic_a italic_t italic_o italic_r</annotation></semantics></math>), which includes the original query, the identified entities, and the task indicator. During the process of knowledge retrieval, the parameter e_i is utilized to retrieve information from the knowledge repository. By organizing each document in the knowledge repository and extracting the relevant text labels, the challenge of document retrieval can be reframed as determining the similarity between the entity details extracted from the query and the document labels. Consequently, for knowledge retrieval, a cosine similarity retrieval approach based on vector embedding is employed. This involves evaluating the resemblance between the entities extracted from the query and the corresponding labels in the literature to identify highly pertinent literature related to the query subject. In addition to cosine similarity computation, two other methods were chosen as baseline techniques for comparison: BM25, a statistically driven retrieval method<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib19" title="">19</a>]</cite>; and the bag-of-words (BoW) model<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib20" title="">20</a>]</cite>. By contrasting the performance of cosine similarity retrieval with these two baseline methods within the knowledge repository, the effectiveness and precision of each method can be evaluated. Detailed experimental data and outcomes are presented in Section IV.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S6.EGx2">
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle M(Prompt_{K},Task_{i}ndicator,Knowledges)=knowledge" class="ltx_Math" display="inline" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mrow id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><mi id="S3.E3.m1.3.3.3.5" xref="S3.E3.m1.3.3.3.5.cmml">M</mi><mo id="S3.E3.m1.3.3.3.4" xref="S3.E3.m1.3.3.3.4.cmml">‚Å¢</mo><mrow id="S3.E3.m1.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.4.cmml"><mo id="S3.E3.m1.3.3.3.3.3.4" stretchy="false" xref="S3.E3.m1.3.3.3.3.4.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">P</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">r</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1a" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.1.1.4.cmml">o</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1b" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.5" xref="S3.E3.m1.1.1.1.1.1.1.5.cmml">m</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1c" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.6" xref="S3.E3.m1.1.1.1.1.1.1.6.cmml">p</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1d" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><msub id="S3.E3.m1.1.1.1.1.1.1.7" xref="S3.E3.m1.1.1.1.1.1.1.7.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.7.2" xref="S3.E3.m1.1.1.1.1.1.1.7.2.cmml">t</mi><mi id="S3.E3.m1.1.1.1.1.1.1.7.3" xref="S3.E3.m1.1.1.1.1.1.1.7.3.cmml">K</mi></msub></mrow><mo id="S3.E3.m1.3.3.3.3.3.5" xref="S3.E3.m1.3.3.3.3.4.cmml">,</mo><mrow id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml">T</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml">a</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1a" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.2.2.4.cmml">s</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1b" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><msub id="S3.E3.m1.2.2.2.2.2.2.5" xref="S3.E3.m1.2.2.2.2.2.2.5.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.5.2" xref="S3.E3.m1.2.2.2.2.2.2.5.2.cmml">k</mi><mi id="S3.E3.m1.2.2.2.2.2.2.5.3" xref="S3.E3.m1.2.2.2.2.2.2.5.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.2.2.2.2.1c" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.6" xref="S3.E3.m1.2.2.2.2.2.2.6.cmml">n</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1d" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.7" xref="S3.E3.m1.2.2.2.2.2.2.7.cmml">d</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1e" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.8" xref="S3.E3.m1.2.2.2.2.2.2.8.cmml">i</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1f" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.9" xref="S3.E3.m1.2.2.2.2.2.2.9.cmml">c</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1g" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.10" xref="S3.E3.m1.2.2.2.2.2.2.10.cmml">a</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1h" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.11" xref="S3.E3.m1.2.2.2.2.2.2.11.cmml">t</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1i" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.12" xref="S3.E3.m1.2.2.2.2.2.2.12.cmml">o</mi><mo id="S3.E3.m1.2.2.2.2.2.2.1j" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.2.2.2.2.2.2.13" xref="S3.E3.m1.2.2.2.2.2.2.13.cmml">r</mi></mrow><mo id="S3.E3.m1.3.3.3.3.3.6" xref="S3.E3.m1.3.3.3.3.4.cmml">,</mo><mrow id="S3.E3.m1.3.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.3.3.cmml"><mi id="S3.E3.m1.3.3.3.3.3.3.2" xref="S3.E3.m1.3.3.3.3.3.3.2.cmml">K</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.3.3.3.cmml">n</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1a" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.4" xref="S3.E3.m1.3.3.3.3.3.3.4.cmml">o</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1b" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.5" xref="S3.E3.m1.3.3.3.3.3.3.5.cmml">w</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1c" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.6" xref="S3.E3.m1.3.3.3.3.3.3.6.cmml">l</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1d" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.7" xref="S3.E3.m1.3.3.3.3.3.3.7.cmml">e</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1e" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.8" xref="S3.E3.m1.3.3.3.3.3.3.8.cmml">d</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1f" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.9" xref="S3.E3.m1.3.3.3.3.3.3.9.cmml">g</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1g" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.10" xref="S3.E3.m1.3.3.3.3.3.3.10.cmml">e</mi><mo id="S3.E3.m1.3.3.3.3.3.3.1h" xref="S3.E3.m1.3.3.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.3.3.3.3.11" xref="S3.E3.m1.3.3.3.3.3.3.11.cmml">s</mi></mrow><mo id="S3.E3.m1.3.3.3.3.3.7" stretchy="false" xref="S3.E3.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.4" xref="S3.E3.m1.3.3.4.cmml">=</mo><mrow id="S3.E3.m1.3.3.5" xref="S3.E3.m1.3.3.5.cmml"><mi id="S3.E3.m1.3.3.5.2" xref="S3.E3.m1.3.3.5.2.cmml">k</mi><mo id="S3.E3.m1.3.3.5.1" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.3" xref="S3.E3.m1.3.3.5.3.cmml">n</mi><mo id="S3.E3.m1.3.3.5.1a" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.4" xref="S3.E3.m1.3.3.5.4.cmml">o</mi><mo id="S3.E3.m1.3.3.5.1b" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.5" xref="S3.E3.m1.3.3.5.5.cmml">w</mi><mo id="S3.E3.m1.3.3.5.1c" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.6" xref="S3.E3.m1.3.3.5.6.cmml">l</mi><mo id="S3.E3.m1.3.3.5.1d" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.7" xref="S3.E3.m1.3.3.5.7.cmml">e</mi><mo id="S3.E3.m1.3.3.5.1e" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.8" xref="S3.E3.m1.3.3.5.8.cmml">d</mi><mo id="S3.E3.m1.3.3.5.1f" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.9" xref="S3.E3.m1.3.3.5.9.cmml">g</mi><mo id="S3.E3.m1.3.3.5.1g" xref="S3.E3.m1.3.3.5.1.cmml">‚Å¢</mo><mi id="S3.E3.m1.3.3.5.10" xref="S3.E3.m1.3.3.5.10.cmml">e</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.4.cmml" xref="S3.E3.m1.3.3.4"></eq><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><times id="S3.E3.m1.3.3.3.4.cmml" xref="S3.E3.m1.3.3.3.4"></times><ci id="S3.E3.m1.3.3.3.5.cmml" xref="S3.E3.m1.3.3.3.5">ùëÄ</ci><vector id="S3.E3.m1.3.3.3.3.4.cmml" xref="S3.E3.m1.3.3.3.3.3"><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">ùëÉ</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">ùëü</ci><ci id="S3.E3.m1.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.1.1.4">ùëú</ci><ci id="S3.E3.m1.1.1.1.1.1.1.5.cmml" xref="S3.E3.m1.1.1.1.1.1.1.5">ùëö</ci><ci id="S3.E3.m1.1.1.1.1.1.1.6.cmml" xref="S3.E3.m1.1.1.1.1.1.1.6">ùëù</ci><apply id="S3.E3.m1.1.1.1.1.1.1.7.cmml" xref="S3.E3.m1.1.1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.7.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.7">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.7.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.7.2">ùë°</ci><ci id="S3.E3.m1.1.1.1.1.1.1.7.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.7.3">ùêæ</ci></apply></apply><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><times id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1"></times><ci id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2">ùëá</ci><ci id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3">ùëé</ci><ci id="S3.E3.m1.2.2.2.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.2.2.2.4">ùë†</ci><apply id="S3.E3.m1.2.2.2.2.2.2.5.cmml" xref="S3.E3.m1.2.2.2.2.2.2.5"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.5.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.5">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.5.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.5.2">ùëò</ci><ci id="S3.E3.m1.2.2.2.2.2.2.5.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.5.3">ùëñ</ci></apply><ci id="S3.E3.m1.2.2.2.2.2.2.6.cmml" xref="S3.E3.m1.2.2.2.2.2.2.6">ùëõ</ci><ci id="S3.E3.m1.2.2.2.2.2.2.7.cmml" xref="S3.E3.m1.2.2.2.2.2.2.7">ùëë</ci><ci id="S3.E3.m1.2.2.2.2.2.2.8.cmml" xref="S3.E3.m1.2.2.2.2.2.2.8">ùëñ</ci><ci id="S3.E3.m1.2.2.2.2.2.2.9.cmml" xref="S3.E3.m1.2.2.2.2.2.2.9">ùëê</ci><ci id="S3.E3.m1.2.2.2.2.2.2.10.cmml" xref="S3.E3.m1.2.2.2.2.2.2.10">ùëé</ci><ci id="S3.E3.m1.2.2.2.2.2.2.11.cmml" xref="S3.E3.m1.2.2.2.2.2.2.11">ùë°</ci><ci id="S3.E3.m1.2.2.2.2.2.2.12.cmml" xref="S3.E3.m1.2.2.2.2.2.2.12">ùëú</ci><ci id="S3.E3.m1.2.2.2.2.2.2.13.cmml" xref="S3.E3.m1.2.2.2.2.2.2.13">ùëü</ci></apply><apply id="S3.E3.m1.3.3.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3.3.3"><times id="S3.E3.m1.3.3.3.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.3.3.3.1"></times><ci id="S3.E3.m1.3.3.3.3.3.3.2.cmml" xref="S3.E3.m1.3.3.3.3.3.3.2">ùêæ</ci><ci id="S3.E3.m1.3.3.3.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3.3.3.3">ùëõ</ci><ci id="S3.E3.m1.3.3.3.3.3.3.4.cmml" xref="S3.E3.m1.3.3.3.3.3.3.4">ùëú</ci><ci id="S3.E3.m1.3.3.3.3.3.3.5.cmml" xref="S3.E3.m1.3.3.3.3.3.3.5">ùë§</ci><ci id="S3.E3.m1.3.3.3.3.3.3.6.cmml" xref="S3.E3.m1.3.3.3.3.3.3.6">ùëô</ci><ci id="S3.E3.m1.3.3.3.3.3.3.7.cmml" xref="S3.E3.m1.3.3.3.3.3.3.7">ùëí</ci><ci id="S3.E3.m1.3.3.3.3.3.3.8.cmml" xref="S3.E3.m1.3.3.3.3.3.3.8">ùëë</ci><ci id="S3.E3.m1.3.3.3.3.3.3.9.cmml" xref="S3.E3.m1.3.3.3.3.3.3.9">ùëî</ci><ci id="S3.E3.m1.3.3.3.3.3.3.10.cmml" xref="S3.E3.m1.3.3.3.3.3.3.10">ùëí</ci><ci id="S3.E3.m1.3.3.3.3.3.3.11.cmml" xref="S3.E3.m1.3.3.3.3.3.3.11">ùë†</ci></apply></vector></apply><apply id="S3.E3.m1.3.3.5.cmml" xref="S3.E3.m1.3.3.5"><times id="S3.E3.m1.3.3.5.1.cmml" xref="S3.E3.m1.3.3.5.1"></times><ci id="S3.E3.m1.3.3.5.2.cmml" xref="S3.E3.m1.3.3.5.2">ùëò</ci><ci id="S3.E3.m1.3.3.5.3.cmml" xref="S3.E3.m1.3.3.5.3">ùëõ</ci><ci id="S3.E3.m1.3.3.5.4.cmml" xref="S3.E3.m1.3.3.5.4">ùëú</ci><ci id="S3.E3.m1.3.3.5.5.cmml" xref="S3.E3.m1.3.3.5.5">ùë§</ci><ci id="S3.E3.m1.3.3.5.6.cmml" xref="S3.E3.m1.3.3.5.6">ùëô</ci><ci id="S3.E3.m1.3.3.5.7.cmml" xref="S3.E3.m1.3.3.5.7">ùëí</ci><ci id="S3.E3.m1.3.3.5.8.cmml" xref="S3.E3.m1.3.3.5.8">ùëë</ci><ci id="S3.E3.m1.3.3.5.9.cmml" xref="S3.E3.m1.3.3.5.9">ùëî</ci><ci id="S3.E3.m1.3.3.5.10.cmml" xref="S3.E3.m1.3.3.5.10">ùëí</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\displaystyle M(Prompt_{K},Task_{i}ndicator,Knowledges)=knowledge</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">italic_M ( italic_P italic_r italic_o italic_m italic_p italic_t start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT , italic_T italic_a italic_s italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_n italic_d italic_i italic_c italic_a italic_t italic_o italic_r , italic_K italic_n italic_o italic_w italic_l italic_e italic_d italic_g italic_e italic_s ) = italic_k italic_n italic_o italic_w italic_l italic_e italic_d italic_g italic_e</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.4">Moreover, following the identification of relevant literature using cosine similarity retrieval, diverse knowledge extracted from the literature label based on the task_indicator is utilized to address the specific query associated with corresponding label. For instance, in cases where the task_indicator is denoted as the first category of questions, the top 10 literature pieces with the highest cosine scores are selected to present various spectral analysis techniques applicable for examining the research subject. Conversely, when the task_indicator is identified as the second category of questions, pertinent information is derived from the structured labels of the literature, such as preprocessing methodologies, feature processing techniques, and the machine learning models employed. In the other hand, where the queried object in the task_indicator is not predefined within the labels, the entire Abstract section of literature is considered as the source of knowledge. Although the abstract may not contain specific information pertinent to the inquiry at hand, it serves as a valuable repository of literature that could potentially offer pertinent insights for the research.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Generating output according to knowledge and task indicator</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.4">Finally, based on the original input query <math alttext="q" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_q</annotation></semantics></math>, the retrieved expertise <math alttext="k" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_k</annotation></semantics></math>, and the template prompt <math alttext="Prompt_{k}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">P</mi><mo id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">r</mi><mo id="S3.SS3.p1.3.m3.1.1.1a" xref="S3.SS3.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.3.m3.1.1.4" xref="S3.SS3.p1.3.m3.1.1.4.cmml">o</mi><mo id="S3.SS3.p1.3.m3.1.1.1b" xref="S3.SS3.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.3.m3.1.1.5" xref="S3.SS3.p1.3.m3.1.1.5.cmml">m</mi><mo id="S3.SS3.p1.3.m3.1.1.1c" xref="S3.SS3.p1.3.m3.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.3.m3.1.1.6" xref="S3.SS3.p1.3.m3.1.1.6.cmml">p</mi><mo id="S3.SS3.p1.3.m3.1.1.1d" xref="S3.SS3.p1.3.m3.1.1.1.cmml">‚Å¢</mo><msub id="S3.SS3.p1.3.m3.1.1.7" xref="S3.SS3.p1.3.m3.1.1.7.cmml"><mi id="S3.SS3.p1.3.m3.1.1.7.2" xref="S3.SS3.p1.3.m3.1.1.7.2.cmml">t</mi><mi id="S3.SS3.p1.3.m3.1.1.7.3" xref="S3.SS3.p1.3.m3.1.1.7.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><times id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1"></times><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">ùëÉ</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">ùëü</ci><ci id="S3.SS3.p1.3.m3.1.1.4.cmml" xref="S3.SS3.p1.3.m3.1.1.4">ùëú</ci><ci id="S3.SS3.p1.3.m3.1.1.5.cmml" xref="S3.SS3.p1.3.m3.1.1.5">ùëö</ci><ci id="S3.SS3.p1.3.m3.1.1.6.cmml" xref="S3.SS3.p1.3.m3.1.1.6">ùëù</ci><apply id="S3.SS3.p1.3.m3.1.1.7.cmml" xref="S3.SS3.p1.3.m3.1.1.7"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.7.1.cmml" xref="S3.SS3.p1.3.m3.1.1.7">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.7.2.cmml" xref="S3.SS3.p1.3.m3.1.1.7.2">ùë°</ci><ci id="S3.SS3.p1.3.m3.1.1.7.3.cmml" xref="S3.SS3.p1.3.m3.1.1.7.3">ùëò</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">Prompt_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_P italic_r italic_o italic_m italic_p italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> that splices the above two, we fine-tune a new LLM for generating the response <math alttext="R" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">ùëÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">R</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_R</annotation></semantics></math>, viz:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S6.EGx3">
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle M(Prompt_{K},q,c)=R_{pre}" class="ltx_Math" display="inline" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.cmml"><mi id="S3.E4.m1.3.3.1.3" xref="S3.E4.m1.3.3.1.3.cmml">M</mi><mo id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.2.cmml">‚Å¢</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.2.cmml"><mo id="S3.E4.m1.3.3.1.1.1.2" stretchy="false" xref="S3.E4.m1.3.3.1.1.2.cmml">(</mo><mrow id="S3.E4.m1.3.3.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">P</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.3.cmml">r</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.4.cmml">o</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1b" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.1.1.1.1.5" xref="S3.E4.m1.3.3.1.1.1.1.5.cmml">m</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1c" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.1.1.1.1.6" xref="S3.E4.m1.3.3.1.1.1.1.6.cmml">p</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1d" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml">‚Å¢</mo><msub id="S3.E4.m1.3.3.1.1.1.1.7" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.7.2" xref="S3.E4.m1.3.3.1.1.1.1.7.2.cmml">t</mi><mi id="S3.E4.m1.3.3.1.1.1.1.7.3" xref="S3.E4.m1.3.3.1.1.1.1.7.3.cmml">K</mi></msub></mrow><mo id="S3.E4.m1.3.3.1.1.1.3" xref="S3.E4.m1.3.3.1.1.2.cmml">,</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">q</mi><mo id="S3.E4.m1.3.3.1.1.1.4" xref="S3.E4.m1.3.3.1.1.2.cmml">,</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">c</mi><mo id="S3.E4.m1.3.3.1.1.1.5" stretchy="false" xref="S3.E4.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.2" xref="S3.E4.m1.3.3.2.cmml">=</mo><msub id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml"><mi id="S3.E4.m1.3.3.3.2" xref="S3.E4.m1.3.3.3.2.cmml">R</mi><mrow id="S3.E4.m1.3.3.3.3" xref="S3.E4.m1.3.3.3.3.cmml"><mi id="S3.E4.m1.3.3.3.3.2" xref="S3.E4.m1.3.3.3.3.2.cmml">p</mi><mo id="S3.E4.m1.3.3.3.3.1" xref="S3.E4.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.3.3.3" xref="S3.E4.m1.3.3.3.3.3.cmml">r</mi><mo id="S3.E4.m1.3.3.3.3.1a" xref="S3.E4.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.3.3.4" xref="S3.E4.m1.3.3.3.3.4.cmml">e</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><eq id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.2"></eq><apply id="S3.E4.m1.3.3.1.cmml" xref="S3.E4.m1.3.3.1"><times id="S3.E4.m1.3.3.1.2.cmml" xref="S3.E4.m1.3.3.1.2"></times><ci id="S3.E4.m1.3.3.1.3.cmml" xref="S3.E4.m1.3.3.1.3">ùëÄ</ci><vector id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"></times><ci id="S3.E4.m1.3.3.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2">ùëÉ</ci><ci id="S3.E4.m1.3.3.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.3">ùëü</ci><ci id="S3.E4.m1.3.3.1.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4">ùëú</ci><ci id="S3.E4.m1.3.3.1.1.1.1.5.cmml" xref="S3.E4.m1.3.3.1.1.1.1.5">ùëö</ci><ci id="S3.E4.m1.3.3.1.1.1.1.6.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6">ùëù</ci><apply id="S3.E4.m1.3.3.1.1.1.1.7.cmml" xref="S3.E4.m1.3.3.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.7.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.7">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.7.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.7.2">ùë°</ci><ci id="S3.E4.m1.3.3.1.1.1.1.7.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.7.3">ùêæ</ci></apply></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ùëû</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ùëê</ci></vector></apply><apply id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.3.1.cmml" xref="S3.E4.m1.3.3.3">subscript</csymbol><ci id="S3.E4.m1.3.3.3.2.cmml" xref="S3.E4.m1.3.3.3.2">ùëÖ</ci><apply id="S3.E4.m1.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3"><times id="S3.E4.m1.3.3.3.3.1.cmml" xref="S3.E4.m1.3.3.3.3.1"></times><ci id="S3.E4.m1.3.3.3.3.2.cmml" xref="S3.E4.m1.3.3.3.3.2">ùëù</ci><ci id="S3.E4.m1.3.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3.3">ùëü</ci><ci id="S3.E4.m1.3.3.3.3.4.cmml" xref="S3.E4.m1.3.3.3.3.4">ùëí</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\displaystyle M(Prompt_{K},q,c)=R_{pre}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">italic_M ( italic_P italic_r italic_o italic_m italic_p italic_t start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT , italic_q , italic_c ) = italic_R start_POSTSUBSCRIPT italic_p italic_r italic_e end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle M(Prompt_{A},q)=A_{pre}" class="ltx_Math" display="inline" id="S3.E5.m1.2"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml"><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.cmml"><mi id="S3.E5.m1.2.2.1.3" xref="S3.E5.m1.2.2.1.3.cmml">M</mi><mo id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.2.cmml">‚Å¢</mo><mrow id="S3.E5.m1.2.2.1.1.1" xref="S3.E5.m1.2.2.1.1.2.cmml"><mo id="S3.E5.m1.2.2.1.1.1.2" stretchy="false" xref="S3.E5.m1.2.2.1.1.2.cmml">(</mo><mrow id="S3.E5.m1.2.2.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.2.cmml">P</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.3.cmml">r</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1a" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.2.2.1.1.1.1.4" xref="S3.E5.m1.2.2.1.1.1.1.4.cmml">o</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1b" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.2.2.1.1.1.1.5" xref="S3.E5.m1.2.2.1.1.1.1.5.cmml">m</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1c" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.2.2.1.1.1.1.6" xref="S3.E5.m1.2.2.1.1.1.1.6.cmml">p</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1d" xref="S3.E5.m1.2.2.1.1.1.1.1.cmml">‚Å¢</mo><msub id="S3.E5.m1.2.2.1.1.1.1.7" xref="S3.E5.m1.2.2.1.1.1.1.7.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.7.2" xref="S3.E5.m1.2.2.1.1.1.1.7.2.cmml">t</mi><mi id="S3.E5.m1.2.2.1.1.1.1.7.3" xref="S3.E5.m1.2.2.1.1.1.1.7.3.cmml">A</mi></msub></mrow><mo id="S3.E5.m1.2.2.1.1.1.3" xref="S3.E5.m1.2.2.1.1.2.cmml">,</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">q</mi><mo id="S3.E5.m1.2.2.1.1.1.4" stretchy="false" xref="S3.E5.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml">=</mo><msub id="S3.E5.m1.2.2.3" xref="S3.E5.m1.2.2.3.cmml"><mi id="S3.E5.m1.2.2.3.2" xref="S3.E5.m1.2.2.3.2.cmml">A</mi><mrow id="S3.E5.m1.2.2.3.3" xref="S3.E5.m1.2.2.3.3.cmml"><mi id="S3.E5.m1.2.2.3.3.2" xref="S3.E5.m1.2.2.3.3.2.cmml">p</mi><mo id="S3.E5.m1.2.2.3.3.1" xref="S3.E5.m1.2.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.2.2.3.3.3" xref="S3.E5.m1.2.2.3.3.3.cmml">r</mi><mo id="S3.E5.m1.2.2.3.3.1a" xref="S3.E5.m1.2.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.2.2.3.3.4" xref="S3.E5.m1.2.2.3.3.4.cmml">e</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2"><eq id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2"></eq><apply id="S3.E5.m1.2.2.1.cmml" xref="S3.E5.m1.2.2.1"><times id="S3.E5.m1.2.2.1.2.cmml" xref="S3.E5.m1.2.2.1.2"></times><ci id="S3.E5.m1.2.2.1.3.cmml" xref="S3.E5.m1.2.2.1.3">ùëÄ</ci><interval closure="open" id="S3.E5.m1.2.2.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1"><apply id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1"></times><ci id="S3.E5.m1.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2">ùëÉ</ci><ci id="S3.E5.m1.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3">ùëü</ci><ci id="S3.E5.m1.2.2.1.1.1.1.4.cmml" xref="S3.E5.m1.2.2.1.1.1.1.4">ùëú</ci><ci id="S3.E5.m1.2.2.1.1.1.1.5.cmml" xref="S3.E5.m1.2.2.1.1.1.1.5">ùëö</ci><ci id="S3.E5.m1.2.2.1.1.1.1.6.cmml" xref="S3.E5.m1.2.2.1.1.1.1.6">ùëù</ci><apply id="S3.E5.m1.2.2.1.1.1.1.7.cmml" xref="S3.E5.m1.2.2.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.7.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.7">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.7.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.7.2">ùë°</ci><ci id="S3.E5.m1.2.2.1.1.1.1.7.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.7.3">ùê¥</ci></apply></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">ùëû</ci></interval></apply><apply id="S3.E5.m1.2.2.3.cmml" xref="S3.E5.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.3.1.cmml" xref="S3.E5.m1.2.2.3">subscript</csymbol><ci id="S3.E5.m1.2.2.3.2.cmml" xref="S3.E5.m1.2.2.3.2">ùê¥</ci><apply id="S3.E5.m1.2.2.3.3.cmml" xref="S3.E5.m1.2.2.3.3"><times id="S3.E5.m1.2.2.3.3.1.cmml" xref="S3.E5.m1.2.2.3.3.1"></times><ci id="S3.E5.m1.2.2.3.3.2.cmml" xref="S3.E5.m1.2.2.3.3.2">ùëù</ci><ci id="S3.E5.m1.2.2.3.3.3.cmml" xref="S3.E5.m1.2.2.3.3.3">ùëü</ci><ci id="S3.E5.m1.2.2.3.3.4.cmml" xref="S3.E5.m1.2.2.3.3.4">ùëí</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">\displaystyle M(Prompt_{A},q)=A_{pre}</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.2d">italic_M ( italic_P italic_r italic_o italic_m italic_p italic_t start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_q ) = italic_A start_POSTSUBSCRIPT italic_p italic_r italic_e end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
<tbody id="S3.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle Loss_{Attribute}(q)=Loss_{Attribute}(A_{pre},Groundtruth)" class="ltx_Math" display="inline" id="S3.E6.m1.3"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><mrow id="S3.E6.m1.3.3.4" xref="S3.E6.m1.3.3.4.cmml"><mi id="S3.E6.m1.3.3.4.2" xref="S3.E6.m1.3.3.4.2.cmml">L</mi><mo id="S3.E6.m1.3.3.4.1" xref="S3.E6.m1.3.3.4.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.3" xref="S3.E6.m1.3.3.4.3.cmml">o</mi><mo id="S3.E6.m1.3.3.4.1a" xref="S3.E6.m1.3.3.4.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.4" xref="S3.E6.m1.3.3.4.4.cmml">s</mi><mo id="S3.E6.m1.3.3.4.1b" xref="S3.E6.m1.3.3.4.1.cmml">‚Å¢</mo><msub id="S3.E6.m1.3.3.4.5" xref="S3.E6.m1.3.3.4.5.cmml"><mi id="S3.E6.m1.3.3.4.5.2" xref="S3.E6.m1.3.3.4.5.2.cmml">s</mi><mrow id="S3.E6.m1.3.3.4.5.3" xref="S3.E6.m1.3.3.4.5.3.cmml"><mi id="S3.E6.m1.3.3.4.5.3.2" xref="S3.E6.m1.3.3.4.5.3.2.cmml">A</mi><mo id="S3.E6.m1.3.3.4.5.3.1" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.3" xref="S3.E6.m1.3.3.4.5.3.3.cmml">t</mi><mo id="S3.E6.m1.3.3.4.5.3.1a" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.4" xref="S3.E6.m1.3.3.4.5.3.4.cmml">t</mi><mo id="S3.E6.m1.3.3.4.5.3.1b" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.5" xref="S3.E6.m1.3.3.4.5.3.5.cmml">r</mi><mo id="S3.E6.m1.3.3.4.5.3.1c" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.6" xref="S3.E6.m1.3.3.4.5.3.6.cmml">i</mi><mo id="S3.E6.m1.3.3.4.5.3.1d" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.7" xref="S3.E6.m1.3.3.4.5.3.7.cmml">b</mi><mo id="S3.E6.m1.3.3.4.5.3.1e" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.8" xref="S3.E6.m1.3.3.4.5.3.8.cmml">u</mi><mo id="S3.E6.m1.3.3.4.5.3.1f" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.9" xref="S3.E6.m1.3.3.4.5.3.9.cmml">t</mi><mo id="S3.E6.m1.3.3.4.5.3.1g" xref="S3.E6.m1.3.3.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.4.5.3.10" xref="S3.E6.m1.3.3.4.5.3.10.cmml">e</mi></mrow></msub><mo id="S3.E6.m1.3.3.4.1c" xref="S3.E6.m1.3.3.4.1.cmml">‚Å¢</mo><mrow id="S3.E6.m1.3.3.4.6.2" xref="S3.E6.m1.3.3.4.cmml"><mo id="S3.E6.m1.3.3.4.6.2.1" stretchy="false" xref="S3.E6.m1.3.3.4.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">q</mi><mo id="S3.E6.m1.3.3.4.6.2.2" stretchy="false" xref="S3.E6.m1.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml">=</mo><mrow id="S3.E6.m1.3.3.2" xref="S3.E6.m1.3.3.2.cmml"><mi id="S3.E6.m1.3.3.2.4" xref="S3.E6.m1.3.3.2.4.cmml">L</mi><mo id="S3.E6.m1.3.3.2.3" xref="S3.E6.m1.3.3.2.3.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.5" xref="S3.E6.m1.3.3.2.5.cmml">o</mi><mo id="S3.E6.m1.3.3.2.3a" xref="S3.E6.m1.3.3.2.3.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.6" xref="S3.E6.m1.3.3.2.6.cmml">s</mi><mo id="S3.E6.m1.3.3.2.3b" xref="S3.E6.m1.3.3.2.3.cmml">‚Å¢</mo><msub id="S3.E6.m1.3.3.2.7" xref="S3.E6.m1.3.3.2.7.cmml"><mi id="S3.E6.m1.3.3.2.7.2" xref="S3.E6.m1.3.3.2.7.2.cmml">s</mi><mrow id="S3.E6.m1.3.3.2.7.3" xref="S3.E6.m1.3.3.2.7.3.cmml"><mi id="S3.E6.m1.3.3.2.7.3.2" xref="S3.E6.m1.3.3.2.7.3.2.cmml">A</mi><mo id="S3.E6.m1.3.3.2.7.3.1" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.3" xref="S3.E6.m1.3.3.2.7.3.3.cmml">t</mi><mo id="S3.E6.m1.3.3.2.7.3.1a" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.4" xref="S3.E6.m1.3.3.2.7.3.4.cmml">t</mi><mo id="S3.E6.m1.3.3.2.7.3.1b" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.5" xref="S3.E6.m1.3.3.2.7.3.5.cmml">r</mi><mo id="S3.E6.m1.3.3.2.7.3.1c" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.6" xref="S3.E6.m1.3.3.2.7.3.6.cmml">i</mi><mo id="S3.E6.m1.3.3.2.7.3.1d" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.7" xref="S3.E6.m1.3.3.2.7.3.7.cmml">b</mi><mo id="S3.E6.m1.3.3.2.7.3.1e" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.8" xref="S3.E6.m1.3.3.2.7.3.8.cmml">u</mi><mo id="S3.E6.m1.3.3.2.7.3.1f" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.9" xref="S3.E6.m1.3.3.2.7.3.9.cmml">t</mi><mo id="S3.E6.m1.3.3.2.7.3.1g" xref="S3.E6.m1.3.3.2.7.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.7.3.10" xref="S3.E6.m1.3.3.2.7.3.10.cmml">e</mi></mrow></msub><mo id="S3.E6.m1.3.3.2.3c" xref="S3.E6.m1.3.3.2.3.cmml">‚Å¢</mo><mrow id="S3.E6.m1.3.3.2.2.2" xref="S3.E6.m1.3.3.2.2.3.cmml"><mo id="S3.E6.m1.3.3.2.2.2.3" stretchy="false" xref="S3.E6.m1.3.3.2.2.3.cmml">(</mo><msub id="S3.E6.m1.2.2.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.2.cmml">A</mi><mrow id="S3.E6.m1.2.2.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.3.2" xref="S3.E6.m1.2.2.1.1.1.1.3.2.cmml">p</mi><mo id="S3.E6.m1.2.2.1.1.1.1.3.1" xref="S3.E6.m1.2.2.1.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.2.2.1.1.1.1.3.3" xref="S3.E6.m1.2.2.1.1.1.1.3.3.cmml">r</mi><mo id="S3.E6.m1.2.2.1.1.1.1.3.1a" xref="S3.E6.m1.2.2.1.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.2.2.1.1.1.1.3.4" xref="S3.E6.m1.2.2.1.1.1.1.3.4.cmml">e</mi></mrow></msub><mo id="S3.E6.m1.3.3.2.2.2.4" xref="S3.E6.m1.3.3.2.2.3.cmml">,</mo><mrow id="S3.E6.m1.3.3.2.2.2.2" xref="S3.E6.m1.3.3.2.2.2.2.cmml"><mi id="S3.E6.m1.3.3.2.2.2.2.2" xref="S3.E6.m1.3.3.2.2.2.2.2.cmml">G</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.3" xref="S3.E6.m1.3.3.2.2.2.2.3.cmml">r</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1a" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.4" xref="S3.E6.m1.3.3.2.2.2.2.4.cmml">o</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1b" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.5" xref="S3.E6.m1.3.3.2.2.2.2.5.cmml">u</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1c" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.6" xref="S3.E6.m1.3.3.2.2.2.2.6.cmml">n</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1d" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.7" xref="S3.E6.m1.3.3.2.2.2.2.7.cmml">d</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1e" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.8" xref="S3.E6.m1.3.3.2.2.2.2.8.cmml">t</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1f" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.9" xref="S3.E6.m1.3.3.2.2.2.2.9.cmml">r</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1g" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.10" xref="S3.E6.m1.3.3.2.2.2.2.10.cmml">u</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1h" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.11" xref="S3.E6.m1.3.3.2.2.2.2.11.cmml">t</mi><mo id="S3.E6.m1.3.3.2.2.2.2.1i" xref="S3.E6.m1.3.3.2.2.2.2.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.3.3.2.2.2.2.12" xref="S3.E6.m1.3.3.2.2.2.2.12.cmml">h</mi></mrow><mo id="S3.E6.m1.3.3.2.2.2.5" stretchy="false" xref="S3.E6.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><eq id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"></eq><apply id="S3.E6.m1.3.3.4.cmml" xref="S3.E6.m1.3.3.4"><times id="S3.E6.m1.3.3.4.1.cmml" xref="S3.E6.m1.3.3.4.1"></times><ci id="S3.E6.m1.3.3.4.2.cmml" xref="S3.E6.m1.3.3.4.2">ùêø</ci><ci id="S3.E6.m1.3.3.4.3.cmml" xref="S3.E6.m1.3.3.4.3">ùëú</ci><ci id="S3.E6.m1.3.3.4.4.cmml" xref="S3.E6.m1.3.3.4.4">ùë†</ci><apply id="S3.E6.m1.3.3.4.5.cmml" xref="S3.E6.m1.3.3.4.5"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.4.5.1.cmml" xref="S3.E6.m1.3.3.4.5">subscript</csymbol><ci id="S3.E6.m1.3.3.4.5.2.cmml" xref="S3.E6.m1.3.3.4.5.2">ùë†</ci><apply id="S3.E6.m1.3.3.4.5.3.cmml" xref="S3.E6.m1.3.3.4.5.3"><times id="S3.E6.m1.3.3.4.5.3.1.cmml" xref="S3.E6.m1.3.3.4.5.3.1"></times><ci id="S3.E6.m1.3.3.4.5.3.2.cmml" xref="S3.E6.m1.3.3.4.5.3.2">ùê¥</ci><ci id="S3.E6.m1.3.3.4.5.3.3.cmml" xref="S3.E6.m1.3.3.4.5.3.3">ùë°</ci><ci id="S3.E6.m1.3.3.4.5.3.4.cmml" xref="S3.E6.m1.3.3.4.5.3.4">ùë°</ci><ci id="S3.E6.m1.3.3.4.5.3.5.cmml" xref="S3.E6.m1.3.3.4.5.3.5">ùëü</ci><ci id="S3.E6.m1.3.3.4.5.3.6.cmml" xref="S3.E6.m1.3.3.4.5.3.6">ùëñ</ci><ci id="S3.E6.m1.3.3.4.5.3.7.cmml" xref="S3.E6.m1.3.3.4.5.3.7">ùëè</ci><ci id="S3.E6.m1.3.3.4.5.3.8.cmml" xref="S3.E6.m1.3.3.4.5.3.8">ùë¢</ci><ci id="S3.E6.m1.3.3.4.5.3.9.cmml" xref="S3.E6.m1.3.3.4.5.3.9">ùë°</ci><ci id="S3.E6.m1.3.3.4.5.3.10.cmml" xref="S3.E6.m1.3.3.4.5.3.10">ùëí</ci></apply></apply><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">ùëû</ci></apply><apply id="S3.E6.m1.3.3.2.cmml" xref="S3.E6.m1.3.3.2"><times id="S3.E6.m1.3.3.2.3.cmml" xref="S3.E6.m1.3.3.2.3"></times><ci id="S3.E6.m1.3.3.2.4.cmml" xref="S3.E6.m1.3.3.2.4">ùêø</ci><ci id="S3.E6.m1.3.3.2.5.cmml" xref="S3.E6.m1.3.3.2.5">ùëú</ci><ci id="S3.E6.m1.3.3.2.6.cmml" xref="S3.E6.m1.3.3.2.6">ùë†</ci><apply id="S3.E6.m1.3.3.2.7.cmml" xref="S3.E6.m1.3.3.2.7"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.2.7.1.cmml" xref="S3.E6.m1.3.3.2.7">subscript</csymbol><ci id="S3.E6.m1.3.3.2.7.2.cmml" xref="S3.E6.m1.3.3.2.7.2">ùë†</ci><apply id="S3.E6.m1.3.3.2.7.3.cmml" xref="S3.E6.m1.3.3.2.7.3"><times id="S3.E6.m1.3.3.2.7.3.1.cmml" xref="S3.E6.m1.3.3.2.7.3.1"></times><ci id="S3.E6.m1.3.3.2.7.3.2.cmml" xref="S3.E6.m1.3.3.2.7.3.2">ùê¥</ci><ci id="S3.E6.m1.3.3.2.7.3.3.cmml" xref="S3.E6.m1.3.3.2.7.3.3">ùë°</ci><ci id="S3.E6.m1.3.3.2.7.3.4.cmml" xref="S3.E6.m1.3.3.2.7.3.4">ùë°</ci><ci id="S3.E6.m1.3.3.2.7.3.5.cmml" xref="S3.E6.m1.3.3.2.7.3.5">ùëü</ci><ci id="S3.E6.m1.3.3.2.7.3.6.cmml" xref="S3.E6.m1.3.3.2.7.3.6">ùëñ</ci><ci id="S3.E6.m1.3.3.2.7.3.7.cmml" xref="S3.E6.m1.3.3.2.7.3.7">ùëè</ci><ci id="S3.E6.m1.3.3.2.7.3.8.cmml" xref="S3.E6.m1.3.3.2.7.3.8">ùë¢</ci><ci id="S3.E6.m1.3.3.2.7.3.9.cmml" xref="S3.E6.m1.3.3.2.7.3.9">ùë°</ci><ci id="S3.E6.m1.3.3.2.7.3.10.cmml" xref="S3.E6.m1.3.3.2.7.3.10">ùëí</ci></apply></apply><interval closure="open" id="S3.E6.m1.3.3.2.2.3.cmml" xref="S3.E6.m1.3.3.2.2.2"><apply id="S3.E6.m1.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.2">ùê¥</ci><apply id="S3.E6.m1.2.2.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3"><times id="S3.E6.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.1"></times><ci id="S3.E6.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.2">ùëù</ci><ci id="S3.E6.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.3">ùëü</ci><ci id="S3.E6.m1.2.2.1.1.1.1.3.4.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.4">ùëí</ci></apply></apply><apply id="S3.E6.m1.3.3.2.2.2.2.cmml" xref="S3.E6.m1.3.3.2.2.2.2"><times id="S3.E6.m1.3.3.2.2.2.2.1.cmml" xref="S3.E6.m1.3.3.2.2.2.2.1"></times><ci id="S3.E6.m1.3.3.2.2.2.2.2.cmml" xref="S3.E6.m1.3.3.2.2.2.2.2">ùê∫</ci><ci id="S3.E6.m1.3.3.2.2.2.2.3.cmml" xref="S3.E6.m1.3.3.2.2.2.2.3">ùëü</ci><ci id="S3.E6.m1.3.3.2.2.2.2.4.cmml" xref="S3.E6.m1.3.3.2.2.2.2.4">ùëú</ci><ci id="S3.E6.m1.3.3.2.2.2.2.5.cmml" xref="S3.E6.m1.3.3.2.2.2.2.5">ùë¢</ci><ci id="S3.E6.m1.3.3.2.2.2.2.6.cmml" xref="S3.E6.m1.3.3.2.2.2.2.6">ùëõ</ci><ci id="S3.E6.m1.3.3.2.2.2.2.7.cmml" xref="S3.E6.m1.3.3.2.2.2.2.7">ùëë</ci><ci id="S3.E6.m1.3.3.2.2.2.2.8.cmml" xref="S3.E6.m1.3.3.2.2.2.2.8">ùë°</ci><ci id="S3.E6.m1.3.3.2.2.2.2.9.cmml" xref="S3.E6.m1.3.3.2.2.2.2.9">ùëü</ci><ci id="S3.E6.m1.3.3.2.2.2.2.10.cmml" xref="S3.E6.m1.3.3.2.2.2.2.10">ùë¢</ci><ci id="S3.E6.m1.3.3.2.2.2.2.11.cmml" xref="S3.E6.m1.3.3.2.2.2.2.11">ùë°</ci><ci id="S3.E6.m1.3.3.2.2.2.2.12.cmml" xref="S3.E6.m1.3.3.2.2.2.2.12">‚Ñé</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\displaystyle Loss_{Attribute}(q)=Loss_{Attribute}(A_{pre},Groundtruth)</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.3d">italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_A italic_t italic_t italic_r italic_i italic_b italic_u italic_t italic_e end_POSTSUBSCRIPT ( italic_q ) = italic_L italic_o italic_s italic_s start_POSTSUBSCRIPT italic_A italic_t italic_t italic_r italic_i italic_b italic_u italic_t italic_e end_POSTSUBSCRIPT ( italic_A start_POSTSUBSCRIPT italic_p italic_r italic_e end_POSTSUBSCRIPT , italic_G italic_r italic_o italic_u italic_n italic_d italic_t italic_r italic_u italic_t italic_h )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.7">Here, since we have already acquired knowledge matching the question asked as part of the input through the retrieval method, we do not need to infuse the knowledge into the big model by way of fine-tuning, thus circumventing the inherent shortcomings of inaccurate generation and untraceable sources that may result from acquiring knowledge directly from the big model. Our aim here in using LLM to generate responses is to ensure the diversity<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib21" title="">21</a>]</cite>, specialization, and fluency of the generated responses; in other words, we want to generate responses with a tone style that is closer to that of real researchers, which is the part that fine-tuning techniques excel at, as they can generate responses of similar style with a small amount of manually processed data. Therefore, we first randomly extracted some knowledge from the dataset and constructed it into instances (<math alttext="Prompt_{k}" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m1.1"><semantics id="S3.SS3.p1.5.m1.1a"><mrow id="S3.SS3.p1.5.m1.1.1" xref="S3.SS3.p1.5.m1.1.1.cmml"><mi id="S3.SS3.p1.5.m1.1.1.2" xref="S3.SS3.p1.5.m1.1.1.2.cmml">P</mi><mo id="S3.SS3.p1.5.m1.1.1.1" xref="S3.SS3.p1.5.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.5.m1.1.1.3" xref="S3.SS3.p1.5.m1.1.1.3.cmml">r</mi><mo id="S3.SS3.p1.5.m1.1.1.1a" xref="S3.SS3.p1.5.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.5.m1.1.1.4" xref="S3.SS3.p1.5.m1.1.1.4.cmml">o</mi><mo id="S3.SS3.p1.5.m1.1.1.1b" xref="S3.SS3.p1.5.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.5.m1.1.1.5" xref="S3.SS3.p1.5.m1.1.1.5.cmml">m</mi><mo id="S3.SS3.p1.5.m1.1.1.1c" xref="S3.SS3.p1.5.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS3.p1.5.m1.1.1.6" xref="S3.SS3.p1.5.m1.1.1.6.cmml">p</mi><mo id="S3.SS3.p1.5.m1.1.1.1d" xref="S3.SS3.p1.5.m1.1.1.1.cmml">‚Å¢</mo><msub id="S3.SS3.p1.5.m1.1.1.7" xref="S3.SS3.p1.5.m1.1.1.7.cmml"><mi id="S3.SS3.p1.5.m1.1.1.7.2" xref="S3.SS3.p1.5.m1.1.1.7.2.cmml">t</mi><mi id="S3.SS3.p1.5.m1.1.1.7.3" xref="S3.SS3.p1.5.m1.1.1.7.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m1.1b"><apply id="S3.SS3.p1.5.m1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1"><times id="S3.SS3.p1.5.m1.1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1.1"></times><ci id="S3.SS3.p1.5.m1.1.1.2.cmml" xref="S3.SS3.p1.5.m1.1.1.2">ùëÉ</ci><ci id="S3.SS3.p1.5.m1.1.1.3.cmml" xref="S3.SS3.p1.5.m1.1.1.3">ùëü</ci><ci id="S3.SS3.p1.5.m1.1.1.4.cmml" xref="S3.SS3.p1.5.m1.1.1.4">ùëú</ci><ci id="S3.SS3.p1.5.m1.1.1.5.cmml" xref="S3.SS3.p1.5.m1.1.1.5">ùëö</ci><ci id="S3.SS3.p1.5.m1.1.1.6.cmml" xref="S3.SS3.p1.5.m1.1.1.6">ùëù</ci><apply id="S3.SS3.p1.5.m1.1.1.7.cmml" xref="S3.SS3.p1.5.m1.1.1.7"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m1.1.1.7.1.cmml" xref="S3.SS3.p1.5.m1.1.1.7">subscript</csymbol><ci id="S3.SS3.p1.5.m1.1.1.7.2.cmml" xref="S3.SS3.p1.5.m1.1.1.7.2">ùë°</ci><ci id="S3.SS3.p1.5.m1.1.1.7.3.cmml" xref="S3.SS3.p1.5.m1.1.1.7.3">ùëò</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m1.1c">Prompt_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m1.1d">italic_P italic_r italic_o italic_m italic_p italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="q" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m2.1"><semantics id="S3.SS3.p1.6.m2.1a"><mi id="S3.SS3.p1.6.m2.1.1" xref="S3.SS3.p1.6.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m2.1b"><ci id="S3.SS3.p1.6.m2.1.1.cmml" xref="S3.SS3.p1.6.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m2.1d">italic_q</annotation></semantics></math>, <math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m3.1"><semantics id="S3.SS3.p1.7.m3.1a"><mi id="S3.SS3.p1.7.m3.1.1" xref="S3.SS3.p1.7.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m3.1b"><ci id="S3.SS3.p1.7.m3.1.1.cmml" xref="S3.SS3.p1.7.m3.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m3.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m3.1d">italic_c</annotation></semantics></math>) through a framework, and then generated responses using the OpenAI API<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib1" title="">1</a>]</cite>. We then recruited three annotators with research backgrounds in spectral analysis who manually adjusted the OpenAI-generated responses to more closely resemble the descriptive style of professionals, and we collated all manually processed responses for supervised fine-tuning of the LLM. We used both NLP metrics and AI to evaluate the performance of the fine-tuned model in generating responses and compared it with other baseline models, and the experimental results can be found in Section IV.</p>
</div>
<figure class="ltx_figure" id="S3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S3.F7.g1" src="x10.png" width="667"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Different approaches to two cases whether information of query exist in the labels</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Detail of Implementation</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Our experimental setup aims to effectively evaluate the performance of our proposed method in the field of searching for papers related to spectral detection. All experiments were performed on a single machine equipped with an NVIDIA RTX 4090 GPU and 24GB of memory to ensure efficient execution and minimal processing time. The experiment is mainly divided into three parts. The first step is to use the fine-tuned Llama2-7b model to extract entities from the input question and the second step is to use the TF-IDF cosine similarity retrieval method to retrieve the corresponding literature and knowledge in the paper database based on the extracted entity keywords. At last, the fine-tuned Llama3-8b model was used to generate answers based on the literature knowledge.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">In our experimental setup, we utilized the Low-Rank Adaptation (LoRA) technique to fine-tune both the Llama2-7b and Llama3-8b models, which is a parameter-efficient fine-tuning method that introduces trainable low-rank matrices into each layer of a pre-trained model, significantly reducing the number of trainable parameters and making the fine-tuning process more efficient and less resource-intensive<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib22" title="">22</a>]</cite>. The approach allows for the adaptation of large pre-trained models to specific tasks while preserving their performance. The hyperparameters set in the experiment is shown in Table 1.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Hyperparameters in experiment</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:209.0pt;height:158.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.5pt,-7.2pt) scale(1.1,1.1) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T1.1.1.1.1.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Hyperparameters</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">Values</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.1.2.1.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Batch size</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.1.2.1.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">128</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.3.2.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Max epoch</th>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.3.2.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">15</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.4.3.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Learning rate</th>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.4.3.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">3e-4</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.5.4.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">LoRA rank</th>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.5.4.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">16</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.6.5.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">LoRA alpha</th>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.6.5.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">32</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.1.1.7.6.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">LoRA dropout</th>
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.7.6.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.05</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T1.1.1.8.7.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">LoRA target modules</th>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.1.1.8.7.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">q_proj, v_proj</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">By employing these parameters, we ensured that the LoRA fine-tuning process was both effective and efficient. This enabled the Llama2-7b model to accurately extract entities from input questions and the Llama3-8b model to generate high-quality answers based on the retrieved literature and knowledge. Consequently, we leveraged the strengths of large pre-trained models while maintaining computational feasibility within our hardware constraints, facilitating an effective evaluation of our proposed method in the domain of spectral detection.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Base models and Baseline</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">For entity extraction from the input question, the Llama2-7b model fine-tuned by LoRA is utilized and called LLM1, which is an advanced language model known for its enhanced contextual understanding and language generation capabilities<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib23" title="">23</a>]</cite>. The task of LLM1 is to identify key entities related to spectral detection and focus the retrieval process on the most relevant aspects. The extracted entities include: the research object in the input question, the spectral method mentioned in the input question, and the question type of the input question. After entity extraction, we searched our database using a cosine similarity-based retrieval method which converts the text into TF-IDF feature vectors and calculates the cosine similarity between the extracted entity vectors and the entity vectors present in the research papers<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib24" title="">24</a>]</cite>, allowing us to retrieve the papers with the highest similarity scores and ensuring that our retrieval process is both targeted and relevant.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Two models were used respectively to generate detailed responses: Llama2-13b fine-tuned on LoRA and Llama13-8b fine-tuned on LoRA, collectively referred to as LLM2. Llama3, particularly the Llama13-8b model, represents a further advancement in language modeling, offering superior performance in both understanding and generating natural language<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib25" title="">25</a>]</cite>. During the process, the top five retrieved papers are fed into LLM2, which synthesizes relevant content to provide a comprehensive answer to the input question. This step leverages the advanced language generation capabilities of LLM2 to ensure high-quality and contextually accurate responses.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">The baseline model we used for the experiments is Chat-GPT 3.5 owing to its cost-effectiveness rather than GPT 4.0, which is a mature model known for its powerful language generation capabilities<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib26" title="">26</a>]</cite>. Chat-GPT 3.5 is pre-trained on a diverse dataset and performs well in natural language understanding and generation tasks, allowing us to benchmark the performance of our system in terms of entity extraction, retrieval accuracy, and response generation quality. The comparative analysis between Chat-GPT 3.5 and our Llama2-based model highlights the progress we have made with our focused approach in the area of searching for papers related to spectral detection.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Metrics</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In our experiments, we adopted a comprehensive set of evaluation metrics to evaluate the performance of the models in entity extraction (LLM1) and response generation (LLM2).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">For the entity extraction task using LLM1, the main evaluation metrics include BLEU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib27" title="">27</a>]</cite>, ROUGE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib28" title="">28</a>]</cite>, METEOR<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib29" title="">29</a>]</cite>, BERTScore<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.11557v4#bib.bib30" title="">30</a>]</cite> and accuracy (Acc). BLEU, ROUGE, and METEOR are traditional metrics for evaluating text quality by comparing generated text with reference text. BERTScore leverages BERT‚Äôs contextual embeddings to provide a more nuanced measure of similarity between generated and reference text. Accuracy (Acc) measures the overlap between the entities extracted by the model and the reference entities, providing a direct indicator of the correctness of entity extraction.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">For the response generation task using LLM2, we used similar metrics: BLEU, ROUGE, METEOR, BERTScore, and AI evaluation. BLEU, ROUGE, and METEOR evaluate the generated responses against the reference answers while BERTScore provides a more sophisticated semantic similarity measure. In addition, Chat-GPT4 is used for AI evaluation, which evaluates responses against specific criteria shown in the accompanying Figure 8 .</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="202" id="S4.F8.g1" src="extracted/5920058/AI_evalution.png" width="314"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Detail criteria for AI Evaluation</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Evaluation on LLM for extracting entity</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">The performance of the LLM1 model for extracting question entities was evaluated using several key metrics, including BLEU, ROUGE, METEOR, BERTScore, and accuracy (Acc), for the research object, spectral method, and question type to be extracted in the input question. At the same time, the performance of the Llama2-7b model after Lora fine-tuning and the baseline Chat-GPT model in extracting entities was compared.</p>
</div>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="176" id="S4.F9.g1" src="extracted/5920058/LLM1_represent.png" width="294"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Example for the process of extracting entity</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">LLM1 significantly outperformed the baseline Chat-GPT model in all metrics, and the experimental results are shown in Table 2. For extracting research objects from questions, LLM1 achieved higher scores in BLEU, ROUGE1, METEOR, and BERTScore accuracy. Similarly, for extracting spectral methods mentioned in questions, LLM1 showed excellent performance. LLM1 also had significantly higher accuracy on both tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">In terms of identifying question types, LLM1 consistently provided better results than Chat-GPT, demonstrating its enhanced ability to understand and extract relevant entities in the context of spectral detection.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Evaluation results of LLM1 for extracting entity</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:455.2pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-76.1pt,9.0pt) scale(0.749457322567596,0.749457322567596) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.1.1" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1.1">Models</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T2.1.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.2.1">Bleu</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T2.1.1.1.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.3.1">Rouge1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T2.1.1.1.1.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.4.1">meteor</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T2.1.1.1.1.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.5.1">Bert_score_precision</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S4.T2.1.1.1.1.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.6.1">Acc</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.1.1">Et1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.2.1">Et2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.3.1">Q_type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.4.1">Et1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.5.1">Et2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.6.1">Q_type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.7.1">Et1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.8" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.8.1">Et2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.9" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.9.1">Q_type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.10" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.10.1">Et1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.11" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.11.1">Et2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.12" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.12.1">Q_type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.13" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.13.1">Et2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.2.2.14" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.14.1">Q_type</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.3.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.3.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.3.1.1.1">Llama2-7b</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.087</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.423</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.528</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.871</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.7" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.978</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.8" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.439</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.9" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.831</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.10" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.943</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.11" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.911</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.12" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.972</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.13" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.997</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.14" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.882</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1.15" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.977</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4.2">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T2.1.1.4.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.2.1.1">Chat-GPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.02</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.1</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.093</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.445</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.7" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.711</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.8" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.040</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.9" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.278</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.10" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.681</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.11" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.874</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.12" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.894</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.13" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.956</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.14" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.584</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.2.15" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.534</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Evaluation of the knowledge Retrieve</h3>
<div class="ltx_para ltx_noindent" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">After extracting entities from the input question using LLM1, the retrieval method will retrieve relevant papers based on the entity keywords. The retrieval methods used in the experiment include the Bag of Words model, BM25, and TF-IDF cosine similarity retrieval methods.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">The Bag of Words (BoW) model is a basic and widely used method in text representation, in which each document is represented as an unordered collection of words without considering grammar and word order, but considering the frequency of words. Although the BoW model is simple, it usually lacks contextual understanding, which leads to low accuracy in complex retrieval tasks. BM25 is a ranking function based on a probabilistic retrieval framework that enhances the traditional TF-IDF method by considering word frequency, document length, and inverse document frequency. This method is recognized to be effective in information retrieval tasks. The TF-IDF (Term Frequency-Inverse Document Frequency) cosine similarity retrieval method combines TF-IDF weighting with cosine similarity to measure the angle between document vectors in the vector space model. This method effectively captures the relevance between documents and queries, thereby improving the accuracy of retrieval tasks.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Evaluation results of different knowledge retrieve methods</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:295.4pt;height:79.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(13.4pt,-3.6pt) scale(1.1,1.1) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.1.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Methods</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.1.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">Accuracy(%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.2.1.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Bag-of-Words model</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.2.1.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">46.40</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.3.2.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">BM25</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.3.2.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">80.00</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.1.1.4.3.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">TF-IDF cosine similarity retrieval method</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.1.1.4.3.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">82.80</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">The accuracy of each method is calculated as follows: If the papers retrieved using the entity keyword-based retrieval method match the actual papers corresponding to the keyword, the accuracy is 100%. Then the average accuracy of all queries in the database is calculated as the final accuracy of each method. The experimental results are shown in Table 2.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.1">As can be seen from the table, the TF-IDF cosine similarity retrieval method has the highest accuracy of 82.80%, followed by BM25, which is 80.00%. The Bag-of-Words model has the lowest accuracy of 46.40%. These results demonstrate the superior performance of TF-IDF cosine similarity retrieval in accurately retrieving relevant papers based on the extracted entity keywords.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p5">
<p class="ltx_p" id="S4.SS5.p5.1">By adopting these methods, we are able to compare their retrieval performance and determine that the TF-IDF cosine similarity retrieval method outperforms other methods in terms of accuracy.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Evaluation on LLM for generating response</h3>
<div class="ltx_para ltx_noindent" id="S4.SS6.p1">
<p class="ltx_p" id="S4.SS6.p1.1">The performance of LLM2 models (particularly Llama3-8b and Llama2-13b) was evaluated using several key metrics, including BLEU, ROUGE, METEOR, BERTScore, and AI evaluation, and the experimental results are shown in Table 4. These results are compared with the baseline Chat-GPT model. Both Llama2-13b and Llama3-8b models were fine-tuned using the LoRA technique.</p>
</div>
<figure class="ltx_figure" id="S4.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="251" id="S4.F10.g1" src="extracted/5920058/LLM2_represent.png" width="294"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Example for generating response</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS6.p2">
<p class="ltx_p" id="S4.SS6.p2.1">Llama3-8b achieved the highest scores across most metrics, with a BLEU score of 0.304, ROUGE score of 0.558, METEOR score of 0.503, BERTScore of 0.881, and an AI evaluation score of 4.2. Llama2-13b followed with a BLEU score of 0.158, ROUGE score of 0.385, METEOR score of 0.344, BERTScore of 0.861, and an AI evaluation score of 3.5. The baseline Chat-GPT model scored significantly lower across all metrics, with a BLEU score of 0.001, ROUGE score of 0.065, METEOR score of 0.033, BERTScore of 0.834, and an AI evaluation score of 2.8.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Evaluation results of LLM2 for generating response</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.1" style="width:332.4pt;height:79.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(15.1pt,-3.6pt) scale(1.1,1.1) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Models</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">Bleu</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.3" style="padding-top:1.5pt;padding-bottom:1.5pt;">rouge</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.4" style="padding-top:1.5pt;padding-bottom:1.5pt;">meteor</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.5" style="padding-top:1.5pt;padding-bottom:1.5pt;">Bert_score</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.6" style="padding-top:1.5pt;padding-bottom:1.5pt;">AI evaluate</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.1.2.1.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Llama3-8b</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.1.2.1.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.304</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.1.2.1.3" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.558</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.1.2.1.4" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.503</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.1.2.1.5" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.881</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.1.2.1.6" style="padding-top:1.5pt;padding-bottom:1.5pt;">4.2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.3.2">
<td class="ltx_td ltx_align_left" id="S4.T4.1.1.3.2.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Llama2-13b</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.1.3.2.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.158</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.1.3.2.3" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.385</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.1.3.2.4" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.344</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.1.3.2.5" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.861</td>
<td class="ltx_td ltx_align_left" id="S4.T4.1.1.3.2.6" style="padding-top:1.5pt;padding-bottom:1.5pt;">3.5</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.1.1.4.3.1" style="padding-top:1.5pt;padding-bottom:1.5pt;">Chat-GPT</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.1.1.4.3.2" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.001</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.1.1.4.3.3" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.065</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.1.1.4.3.4" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.033</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.1.1.4.3.5" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.834</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T4.1.1.4.3.6" style="padding-top:1.5pt;padding-bottom:1.5pt;">2.8</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS6.p3">
<p class="ltx_p" id="S4.SS6.p3.1">These results indicate that the Llama3-8b model, fine-tuned with LoRA, performed the best in generating responses, demonstrating superior language generation capabilities and relevance to the spectral detection context compared to both Llama2-13b and the baseline Chat-GPT model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, to enable researchers in the field of spectral detection to retrieve spectral related knowledge faster and more accurately, we designed a fast and reliable spectral detection question answering system based on the SDAAP dataset and a large language model. Considering that professional literature is a valuable treasure trove of advanced knowledge, research results, and engineering methods, we first proposed the Spectral Detection and Analysis Paper (SDAAP) dataset as a basic knowledge source. Subsequently, we developed an automatic question answering framework in related fields based on SDAAP, which uses the Llama2-7b model fine-tuned by LoRA to parse and extract entities and question formats present in the query, and uses the parsed results as query parameters to retrieve relevant spectral detection knowledge through the cosine similarity retrieval method. Finally, the Llama3-8b fine-tuned by LoRA can refer to these retrieved knowledge to generate responses to input queries. Through experiments on the spectral detection knowledge question answering dataset we proposed, the two fine-tuned large language models used to extract entities and generate answers achieved higher accuracy and reliability in generating responses. Both models performed well in commonly used natural language indicator evaluations, with evaluation scores far exceeding Chat-GPT. They can accurately and quickly extract entities and generate answers, respectively, highlighting the domain adaptation potential of LLM in professional fields.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitation</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">‚Ä¢Datasets: A major limitation of this study is the limited number of question-answer pairs and the reliance on a limited amount of literature data, which may inhibit the applicability and validity of the model. On the other hand, the manual cleaning process applied to the data could still be problematic. To address this issue, future research could focus on expanding the task to generate more question-answer pairs; or further structuring the relevant literature database and constructing knowledge graphs to enhance the interconnectivity of the IFT dataset and improve the performance of the model in the vertical domain.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">‚Ä¢Evaluation methodology: In addition to the Type 1 questions, we select metrics such as Bleu and Rouge to measure the similarity between the model output and the golden facts. However, these metrics may not be well suited for model evaluation in verticals, and relying solely on the similarity of the output to the golden facts may not be a valid reflection of the quality of the generated answers. It is worth noting that in the first category of questions, metrics such as Bleu still yield high scores even if the answers are wrong on key spectral species. To address this issue, in the future we will consider introducing entirely new evaluation metrics or using expert evaluation for some of the responses.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Chatgpt.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com" title="">https://chat.openai.com</a>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Teven Le¬†Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Iliƒá, Daniel Hesslow, Roman Castagn√©, Alexandra¬†Sasha Luccioni, Fran√ßois Yvon, Matthias Gall√©, et¬†al.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock">2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Yann Dubois, Chen¬†Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy¬†S Liang, and Tatsunori¬†B Hashimoto.

</span>
<span class="ltx_bibblock">Alpacafarm: A simulation framework for methods that learn from human feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang.

</span>
<span class="ltx_bibblock">Glm: General language model pretraining with autoregressive blank infilling.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2103.10360</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel¬†R Bowman.

</span>
<span class="ltx_bibblock">Glue: A multi-task benchmark and analysis platform for natural language understanding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:1804.07461</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, and Pascale Fung.

</span>
<span class="ltx_bibblock">Towards mitigating llm hallucination via self reflection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 1827‚Äì1843, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu¬†Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et¬†al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Advances in neural information processing systems</span>, 35:27730‚Äì27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Manojit Bhattacharya, Soumen Pal, Srijan Chatterjee, Sang-Soo Lee, and Chiranjib Chakraborty.

</span>
<span class="ltx_bibblock">Large language model (llm) to multimodal large language model (mllm): A journey to shape the biological macromolecules to biological sciences and medicine.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Molecular Therapy-Nucleic Acids</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Arun¬†James Thirunavukarasu, Darren Shu¬†Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting¬†Fang Tan, and Daniel Shu¬†Wei Ting.

</span>
<span class="ltx_bibblock">Large language models in medicine.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Nature medicine</span>, 29(8):1930‚Äì1940, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jiaxiang Li, Siliang Zeng, Hoi-To Wai, Chenliang Li, Alfredo Garcia, and Mingyi Hong.

</span>
<span class="ltx_bibblock">Getting more juice out of the sft data: Reward learning from human demonstration improves sft for llm alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2405.17888</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Yafeng Gu, Yiheng Shen, Xiang Chen, Shaoyu Yang, Yiling Huang, and Zhixiang Cao.

</span>
<span class="ltx_bibblock">Apicom: Automatic api completion via prompt learning and adversarial training-based data augmentation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 14th Asia-Pacific Symposium on Internetware</span>, pages 259‚Äì269, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Romal Thoppilan, Daniel De¬†Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu¬†Du, et¬†al.

</span>
<span class="ltx_bibblock">Lamda: Language models for dialog applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2201.08239</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, and Bin Cui.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for ai-generated content: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2402.19473</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Kamal¬†Raj Kanakarajan, Bhuvana Kundumani, and Malaikannan Sankarasubbu.

</span>
<span class="ltx_bibblock">Bioelectra: pretrained biomedical text encoder using discriminators.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 20th workshop on biomedical language processing</span>, pages 143‚Äì154, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Laila Rasmy, Yang Xiang, Ziqian Xie, Cui Tao, and Degui Zhi.

</span>
<span class="ltx_bibblock">Med-bert: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">NPJ digital medicine</span>, 4(1):86, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Tong Xie, Yuwei Wan, Wei Huang, Zhenyu Yin, Yixuan Liu, Shaozhou Wang, Qingyuan Linghu, Chunyu Kit, Clara Grazian, Wenjie Zhang, et¬†al.

</span>
<span class="ltx_bibblock">Darwin series: Domain specific large language models for natural science.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2308.13565</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting Liu.

</span>
<span class="ltx_bibblock">Huatuo: Tuning llama model with chinese medical knowledge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2304.06975</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Yanrui Du, Sendong Zhao, Yuhan Chen, Rai Bai, Jing Liu, Hua Wu, Haifeng Wang, and Bing Qin.

</span>
<span class="ltx_bibblock">The calla dataset: Probing llms‚Äô interactive knowledge acquisition from chinese medical literature.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2309.04198</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Ammar¬†Ismael Kadhim.

</span>
<span class="ltx_bibblock">Term weighting for feature extraction on twitter: A comparison between bm25 and tf-idf.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">2019 international conference on advanced science and engineering (ICOASE)</span>, pages 124‚Äì128. IEEE, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Yin Zhang, Rong Jin, and Zhi-Hua Zhou.

</span>
<span class="ltx_bibblock">Understanding bag-of-words model: a statistical framework.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">International journal of machine learning and cybernetics</span>, 1:43‚Äì52, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Haochun Wang, Sendong Zhao, Zewen Qiang, Zijian Li, Nuwa Xi, Yanrui Du, MuZhen Cai, Haoqiang Guo, Yuhan Chen, Haoming Xu, et¬†al.

</span>
<span class="ltx_bibblock">Knowledge-tuning large language models with structured medical knowledge bases for reliable response generation in chinese.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2309.04175</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Edward¬†J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu¬†Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2106.09685</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et¬†al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Shahzad Qaiser and Ramsha Ali.

</span>
<span class="ltx_bibblock">Text mining: use of tf-idf to examine the relevance of words to documents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">International Journal of Computer Applications</span>, 181(1):25‚Äì29, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
AI¬†Meta.

</span>
<span class="ltx_bibblock">Introducing meta llama 3: The most capable openly available llm to date.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Meta AI</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Colin¬†G West.

</span>
<span class="ltx_bibblock">Ai and the fci: Can chatgpt project an understanding of introductory physics?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2303.01067</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</span>, pages 311‚Äì318, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">Rouge: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">Text summarization branches out</span>, pages 74‚Äì81, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Satanjeev Banerjee and Alon Lavie.

</span>
<span class="ltx_bibblock">Meteor: An automatic metric for mt evaluation with improved correlation with human judgments.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</span>, pages 65‚Äì72, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian¬†Q Weinberger, and Yoav Artzi.

</span>
<span class="ltx_bibblock">Bertscore: Evaluating text generation with bert.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:1904.09675</span>, 2019.

</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" content="Jiheng Liang, Zujie Xie, Ziru Yu, Xiangyang Yu" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="q-bio.NC, q-bio.QM" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="A Quick, trustworthy spectral knowledge Q&amp;A system leveraging retrieval-augmented generation on LLM" property="dcterms:title"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Oct 11 15:14:43 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
