<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC</title>
<!--Generated on Thu Sep 19 17:42:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.12939v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S1" title="In Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S2" title="In Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>COTS Embedded Processors in Space</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S2.SS1" title="In 2 COTS Embedded Processors in Space ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Field-Programmable Gate Arrays (FPGAs)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S2.SS2" title="In 2 COTS Embedded Processors in Space ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Graphics Processing Units (GPUs)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S2.SS3" title="In 2 COTS Embedded Processors in Space ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Vision Processing Units (VPUs)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S3" title="In Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>The Myriad Vision Processing Unit</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4" title="In Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>AI/CV Acceleration for Lost-In-Space on Myriad X</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.SS1" title="In 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Pre-Processing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.SS2" title="In 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Deep Neural Network for Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.SS3" title="In 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Computer Vision Pipeline for Pose Tracking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5" title="In Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.SS1" title="In 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.SS2" title="In 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Experimental Results on Myriad X VPU</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.SS3" title="In 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Comparison to Embedded Devices</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S6" title="In Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion and Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">Accelerating AI and Computer Vision for
<br class="ltx_break"/>Satellite Pose Estimation on the Intel Myriad X Embedded SoC</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vasileios Leon
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Panagiotis Minaidis
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">George Lentaris
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dimitrios Soudris
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">The challenging deployment of Artificial Intelligence (AI) and Computer Vision (CV) algorithms at the edge pushes the community of embedded computing to examine heterogeneous System-on-Chips (SoCs). Such novel computing platforms provide increased diversity in interfaces, processors and storage, however, the efficient partitioning and mapping of AI/CV workloads still remains an open issue. In this context, the current paper develops a hybrid AI/CV
system on Intel’s Movidius Myriad X, which is an heterogeneous Vision Processing Unit (VPU), for initializing and tracking the satellite’s pose in space missions. The space industry is among the communities examining alternative computing platforms to comply with the tight constraints of on-board data processing, while it is also striving to adopt functionalities from the AI domain. At algorithmic level, we rely on the ResNet-50-based UrsoNet network along with a custom classical CV pipeline. For efficient acceleration, we exploit the SoC’s neural compute engine and 16 vector processors by combining multiple parallelization and low-level optimization techniques. The proposed single-chip, robust-estimation, and real-time solution delivers a throughput of up to 5 FPS for 1-MegaPixel RGB images within a limited power envelope of 2W.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Heterogeneous Computing, Embedded System, System on Chip, Multi-Core Processor, VLIW Processor, Edge Device, Vision Processing Unit, Deep Neural Network, Computer Vision, Vision-Based Navigation, Pose Tracking, Space Avionics, COTS Component, Intel Myriad, OpenVINO, Neural Compute Engine.

</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journal" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span> © 2023. This manuscript version is made available under the CC-BY-NC-ND 4.0 license
<a class="ltx_ref ltx_href" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" style="color:#0000FF;" title="">https://creativecommons.org/licenses/by-nc-nd/4.0/</a></span></span></span>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\affiliation</span>
<p class="ltx_p" id="p1.2">[1]organization=National Technical University of Athens, School of Electrical and Computer Engineering,
country=Greece</p>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\affiliation</span>
<p class="ltx_p" id="p2.2">[2]organization=University of West Attica, Department of Informatics and Computer Engineering,
country=Greece</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The rapid evolution of
powerful Artificial Intelligence (AI) algorithms
and sophisticated Computer Vision (CV) pipelines
marks a new era of computing at the edge.
The worldwide demand for high performance
with a restricted power budget,
especially when considering embedded systems,
challenges the integration of
AI/CV functionalities in novel applications.
Heterogeneous System-on-Chip (SoC) processors
emerge as a promising solution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib1" title="">1</a>]</cite>,
providing increased programming flexibility
and diversity in terms of processors and memories.
A prominent class of heterogeneous SoCs
is the Vision Processing Unit (VPU)
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib4" title="">4</a>]</cite>,
which excels in embedded low-power imaging applications,
covering domains such as robotics, automotive, and space.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Space is one of the communities
seeking alternative processing platforms
to comply with the tight constraints of on-board processing.
Towards this direction,
the enhanced performance of modern edge devices
can efficiently serve tasks for
Earth Observation (EO) and Vision-Based Navigation (VBN).
Satellite Pose Estimation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib8" title="">8</a>]</cite>
constitutes a typical problem in such space applications,
with its increased computing intensity stressing
the conventional processors
to provide
sufficient throughput.
Moreover,
the heterogeneity of devices such as the VPUs,
allows for
improved adaptability to various mission scenarios
and seamless in-flight re-programmability.
To further improve
the Performance and Size-Weight-Power (SWaP),
as well as additional
costs (e.g., development effort),
the space industry is studying
mixed-criticality architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib12" title="">12</a>]</cite>,
i.e., the integration of both
space-grade and Commercial-Off-The-Shelf (COTS) components.
The use of COTS components
in Low Earth Orbit (LEO) missions and CubeSats
relies on
the partial shielding provided by the Earth’s magnetosphere
and/or the short mission lifetime,
which limit the damage or unavailability of electronics
due to radiation.
In this context,
FPGAs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib16" title="">16</a>]</cite>,
GPUs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib21" title="">21</a>]</cite> and
VPUs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib25" title="">25</a>]</cite>
are evaluated as accelerators,
while COTS devices, e.g., Intel’s Myriad 2 VPU,
are subjected to radiation tests <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib26" title="">26</a>]</cite>.
A second challenge for the space industry
is the wider adoption of AI,
which is currently limited to
offline/ground data processing
instead of on-board processing,
mostly due to insufficient computational power
and qualification issues when deployed in orbit
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib26" title="">26</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper,
motivated by the aforementioned challenges
in embedded computing and space avionics,
we develop AI and CV functionalities
for satellite pose estimation
on Intel’s 16-nm Myriad X VPU.
Myriad X is the latest variant of Intel’s VPU family,
supporting custom and automatic AI deployment,
as well as classic CV workloads.
In particular,
we accelerate
a Deep Neural Network (DNN) of ResNet backbone,
namely UrsoNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>,
which estimates the satellite’s pose,
next to
a custom CV pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib6" title="">6</a>]</cite>
tracking the pose.
We select UrsoNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite> and the CV of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib6" title="">6</a>]</cite>
because they are representative of high-performance state-of-the-art algorithms for the pose estimation/tracking problem.
The two algorithmic pipelines are acting complementary
to provide a single-chip solution
to the entire pose estimation problem
(initialization and tracking)
and increase the robustness of the VBN subsystem.
The experimental results show that the proposed
low-level optimization and tuning
improves the speedup
provided by the default core parallelization.
Overall,
we perform pose estimation &amp; tracking
on 1-MegaPixel RGB images
with a throughput of up to 5 FPS,
while the power consumption of the SoC is around 2W.
Moreover,
we directly compare our implementations on the Myriad X VPU
to other competitive embedded devices
(CPUs, embedded GPUs, ARM-based FPGAs).
The contribution of our work lies in two directions:</p>
</div>
<div class="ltx_para" id="S1.p4">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(i)</span>
<div class="ltx_para" id="S1.I1.ix1.p1">
<p class="ltx_p" id="S1.I1.ix1.p1.1"><em class="ltx_emph ltx_font_italic" id="S1.I1.ix1.p1.1.1">Embedded Computing</em>:
We propose a certain hybrid embedded system
combining both AI and classic CV functions, while
we accelerate them
on an heterogeneous SoC
by applying various low-level optimization techniques.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(ii)</span>
<div class="ltx_para" id="S1.I1.ix2.p1">
<p class="ltx_p" id="S1.I1.ix2.p1.1"><em class="ltx_emph ltx_font_italic" id="S1.I1.ix2.p1.1.1">Space Avionics</em>:
We propose a self-contained system
for the entire relative pose estimation problem,
i.e., Lost-In-Space and Tracking.
Our solution is integrated in a single COTS SoC
and provides excellent power consumption and sufficient performance.
We evaluate a candidate device
for on-board acceleration
in mixed-criticality avionics architectures,
while we examine practical AI functionalities for on-board processing
(not widely adopted yet).</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The remainder of this paper is organized as follows.
Section <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S2" title="2 COTS Embedded Processors in Space ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a> provides background in the use of COTS devices in space,
while Section <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S3" title="3 The Myriad Vision Processing Unit ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">3</span></a>
introduces the Myriad VPU family.
Section <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4" title="4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">4</span></a> introduces the proposed embedded AI/CV system, and it also
discusses its mapping onto the Myriad X SoC and low-level implementation details.
Section <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5" title="5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">5</span></a> reports and analyzes the experimental results,
and finally,
Section <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S6" title="6 Conclusion and Future Work ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">6</span></a> draws the conclusions.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>COTS Embedded Processors in Space</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The literature includes a
variety of COTS-based processing architectures
and works evaluating the suitability of COTS devices
for on-board use in future space missions.
In this section,
we report representative works
for each type of COTS processor.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Field-Programmable Gate Arrays (FPGAs)</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">For high-performance solutions,
COTS FPGAs are preferred,
as they outperform both their space-grade counterparts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib27" title="">27</a>]</cite>
and the general-purpose CPUs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib28" title="">28</a>]</cite>.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib13" title="">13</a>]</cite>
propose a runtime reconfigurable SW/HW on-board processor
for VBN,
which provides autonomous adaptation during the mission.
The architecture relies on the RTEMS real-time operating system
to apply reconfiguration and fault mitigation.
The implementation is performed on
Xilinx’s Zynq UltraScale+ MPSoC.
The Zynq-7000 SoC FPGA is used in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite>
to implement compute-intensive CV algorithms for satellite pose tracking.
This architecture is based on a HW/SW co-design methodology
that exploits the full potential of the Zynq structure.
Iturbe <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib15" title="">15</a>]</cite>
propose a HW/SW infrastructure
for instrument data handling and processing,
which is prototyped on Zynq-7000.
They also equip their design with several hardening techniques for fault mitigation (e.g., watchdogs).
The on-board space computer of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib16" title="">16</a>]</cite>,
which is also based on the Zynq FPGA,
integrates several functionalities towards improving in-flight reliability (e.g., memory scrubbing).</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Graphics Processing Units (GPUs)</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">COTS embedded GPUs have also gained the interest of the space community.
The GPU platforms
can provide sufficient performance
with less development effort than FPGAs.
Kosmidis <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.1.1">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib17" title="">17</a>]</cite>
examine the applicability of mobile GPUs in the space domain,
covering both the software and hardware perspectives.
In particular,
they analyze the algorithms and workloads of space applications
to identify their suitability for GPUs,
and they also perform a benchmarking evaluation on GPUs.
In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib18" title="">18</a>]</cite>,
the authors evaluate two graphics-based computing methodologies
(OpenGL 2.0 and Brook Auto)
for safety-critical systems.
Their benchmark is an application modeling a
VBN scenario in which the aircraft performs rendez-vouz
with an object.
Moreover,
the literature includes FPGA-GPU co-processing architectures.
The hybrid FPGA–GPU architecture of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib19" title="">19</a>]</cite>
employs Nvidia’s
Tegra X2/X2i GPU as main accelerator.
The heterogeneous architecture of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib20" title="">20</a>]</cite>
integrates
a SoC FPGA for SpaceWire I/O transcoding,
the AMD SoC (CPU &amp; GPU) for acceleration,
and optionally, a VPU for AI deployment.
The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib29" title="">29</a>]</cite> deploy neural networks for object detection
along with image compression techniques on Nvidia’s Jetson Nano GPU.
More recently,
in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib21" title="">21</a>]</cite>, embedded GPU platforms are evaluated for accelerating
data compression standards for space applications.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Vision Processing Units (VPUs)</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The Intel’s Myriad family of VPUs
is systematically being evaluated
by the space community.
In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib26" title="">26</a>]</cite>,
Furano <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.1">et al.</em> report results from the radiation testing of Myriad 2,
which involves different functional tests
and characterization of all SoC’s memories.
According to their experiments,
Myriad 2 remains fully functional
after exposed to a total ionizing dose of 49 krad(Si).
The same VPU is used
to accelerate CV algorithms for VBN applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite>,
and specifically,
it provides a throughput of up to 5 FPS for pose estimation on 1-MegaPixel images within the power envelope of 1W.
Agarwal <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.2">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib30" title="">30</a>]</cite>
evaluate Myriad 2
for implementing a star identification neural network.
The results show that
Myriad 2 provides sufficient performance,
while consuming around 1W and retaining an accuracy of 99.08%.
Moreover,
Myriad 2 is equipped on-board in the
<math alttext="\mathrm{\Phi}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><mi id="S2.SS3.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS3.p1.1.m1.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\mathrm{\Phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">roman_Φ</annotation></semantics></math>-Sat-1 CubeSat mission of the
European Space Agency
as DNN demonstrator for EO
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib31" title="">31</a>]</cite>.
Myriad 2 is also placed in custom boards for use in space.
In particular,
Ubotica’s CogniSAT CubeSat board <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib32" title="">32</a>]</cite> is an
AI inference and CV engine that exposes the compute of Myriad 2 to the payload developer.
In the same context,
Myriad 2 is integrated as the main accelerator
in the HPCB platform <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib24" title="">24</a>]</cite>,
which is a payload data processor board
for mixed-criticality space avionics.
The results show that
Myriad 2 can provide sufficient AI acceleration
with limited power consumption,
while it sustains remarkable I/O throughput <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib25" title="">25</a>]</cite>.
To increase the reliability of Myriad 2 as part of a mixed-criticality architecture,
the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib33" title="">33</a>]</cite> propose fault-tolerant techniques tailored to this SoC.
Myriad X,
which is the newest VPU and
the successor of Myriad 2,
has received less attention.
In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib34" title="">34</a>]</cite>,
the authors report results for
deploying neural networks classifiers on
Myriad X.
The networks are
trained on Mars imagery from the Reconnaissance Orbiter and Curiosity rover,
and the average inference time is 16-20ms with power lying around 1.8-1.9W.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The Myriad Vision Processing Unit</h2>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="534" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Intel’s Myriad X VPU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib4" title="">4</a>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The Myriad family of VPUs includes multi-core COTS SoCs that
target to
terrestrial mobile and embedded applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib3" title="">3</a>]</cite>.
The SoCs integrate
multiple peripherals for I/O,
hardware filters for low-power image processing,
and
general-purpose &amp; vector processors.
All these components are
connected to a multi-ported high-bandwidth shared memory hierarchy.
The heterogeneity of Myriad VPUs
allows for efficient mapping of AI and CV algorithms
with a power of 1-2W (depending on the VPU variant).
Besides their usage in space,
the Myriad VPUs are employed
for implementing
DNNs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib38" title="">38</a>]</cite>,
machine learning algorithms
(e.g., SVM classifiers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib39" title="">39</a>]</cite>),
and
CV functions (e.g., stereo vision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib40" title="">40</a>]</cite>).</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">In this work,
we employ the Myriad X VPU,
which is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S3.F1" title="Figure 1 ‣ 3 The Myriad Vision Processing Unit ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">1</span></a>.
Contrary to Myriad 2,
this variant
features a dedicated on-chip accelerator,
called Neural Computer Engine (NCE),
for inferencing DNNs.
It also integrates
16 programmable 128-bit VLIW vector cores (called SHAVEs)
for accelerating CV functions,
hardware accelerators for imaging/vision tasks,
and 2 general-purpose LEON4 processors
(called LEON OS and LEON RT).
Regarding the memory hierarchy,
Myriad X provides
on-chip 512MB LPDDR4 DRAM,
2.5MB scratchpad memory (called CMX),
as well caches for LEONs and SHAVEs.
Furthermore,
the SoC offers numerous imaging (MIPI lanes, CIF, LCD)
and general-purpose (e.g., SPI, USB, UART) I/O interfaces.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">The Myriad X SoC is programmed via
the Myriad Development Kit (MDK),
which includes all the necessary tools
(e.g., toolchain for the processors, C/C++ compiler, debugger)
to implement custom CV and DNN algorithms.
To deploy DNNs
of well-known frameworks (e.g., TensorFlow)
on NCE,
the Intel’s OpenVINO toolkit <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib41" title="">41</a>]</cite> is used.
OpenVINO takes the frozen graph as input
and employs tools such as the model optimizer and the Myriad compiler
to generate the programming file.
This binary network file is loaded on NCE via the mvNCI API,
which is also used to feed NCE with input data and receive its outputs in the form of tensors.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>AI/CV Acceleration for Lost-In-Space on Myriad X</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The targeted AI/CV system
for pose estimation &amp; tracking
is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F2" title="Figure 2 ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a>.
The input image is received by the Camera InterFace (CIF) of the VPU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib25" title="">25</a>]</cite>,
it is stored in DRAM,
and then it is subjected to pre-processing.
For the AI pipeline (upper block),
the pre-processing applies resampling
to reduce the image resolution,
and thus
facilitate DNN inferencing at the edge.
Our DNN is a mobile version of the UrsoNet network <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>,
satisfying the real-time processing constraints.
For the CV pipeline (lower block),
the pre-processing converts the image to grayscale,
as required by our 5-stage CV algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The purpose of the current work is to
quantify the costs and benefits of the two complementary algorithmic pipelines (CV and AI),
fine-tune their implementation on Myriad X,
and
evaluate the potential gains of their acceleration on a single low-power SoC.
We note that the final system integration
would also include
a high-level policy mechanism
to coordinate the two pipelines,
e.g.,
(i) decide when to provide an initial pose via AI
and when to continue tracking via CV,
or
(ii) execute both pipelines for the same input
and decide which pose to keep;
the creation of such a policy mechanism
requires additional exploration with test campaigns
and customization to real satellite datasets
(e.g., to identify when the pose is lost).</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="277" id="S4.F2.g1" src="x2.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Cooperation of AI and CV for pose estimation/tracking on Myriad X.</figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Pre-Processing</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.3">To explore different trade-offs between DNN’s performance and accuracy,
we employ three well-established resampling algorithms
with increasing computational complexity.
First, Bilinear Interpolation
inputs 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><times id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">×</annotation></semantics></math>2 pixel regions
with a stride equal to the reciprocal of the scaling factor and calculates
the mean value per region.
Second, Bicubic Interpolation
inputs 4<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mo id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><times id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">×</annotation></semantics></math>4 pixel regions
and applies a cubic polynomial per region.
Finally,
Lanczos Interpolation
reconstructs the pixels through a Lanczos kernel (windowed sinc function),
and then applies interpolation using convolution;
in this work, we consider 8<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mo id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><times id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">×</annotation></semantics></math>8 pixel regions.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">The image resampling algorithms are accelerated on SHAVEs,
while LEON OS monitors the execution
and performs tasks such as
initializing the SHAVEs
and passing the entry points to them.
At system level,
we configure the RTEMS Real-Time Operating System
(RTOS)
for LEON,
define the memory space of DRAM and CMX,
and set the clock of the SoC at the maximum frequency (700MHz).
In terms of high-level design,
the input image is divided into stripes,
i.e., segments of successive image rows,
and LEON OS assigns one stripe to each SHAVE
to enable <em class="ltx_emph ltx_font_italic" id="S4.SS1.p2.1.1">core parallelization</em>.
The input image is stored in DRAM (global memory),
and each SHAVE transfers its own stripe in a dedicated slice
of CMX (scratchpad memory) via the SoC’s DMA engine.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.2">Regarding low-level development details,
the resampling algorithms are implemented in an iterative manner on SHAVEs.
In particular, each SHAVE performs a call to the selected
resampling function per loop iteration,
producing the output rows of its assigned image stripe one by one.
Therefore, the number of image rows
required to be transferred to each SHAVE’s CMX slice per loop iteration
is equal to the height of the
algorithm’s resampling region (e.g., 4 for Bicubic).
Considering a scaling factor of 0.5 (i.e., stride equal to 2),
each loop iteration of Bicubic (4<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mo id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><times id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">×</annotation></semantics></math>4 region) and Lanczos (8<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mo id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><times id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">×</annotation></semantics></math>8 region)
needs to fetch only two new image rows.
To take advantage of this property,
we employ a data structure
that implements
a double-linked list,
where each node contains a row buffer,
and thus,
<em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.2.1">sliding buffer</em> is enabled
by re-arranging the pointers that connect the nodes.
We also exploit the SoC’s support
for numerous data types
(e.g., “u8”, “u16”, and “float16”)
to apply <em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.2.2">variable tuning</em>.
Moreover,
we enable <em class="ltx_emph ltx_font_italic" id="S4.SS1.p3.2.3">SIMD computations</em>
by arranging the data into 128-bit vectors
and calling the corresponding routines
to deploy additions and dot products on SoC’s scalar arithmetic unit.
The compiler is also enabled to
map arithmetic operations onto the vector arithmetic unit.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Deep Neural Network for Pose Estimation</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We employ the UrsoNet DNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>
for estimating the satellite’s pose.
The architecture of UrsoNet,
which is based on the ResNet-50 network,
is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F3" title="Figure 3 ‣ 4.2 Deep Neural Network for Pose Estimation ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">3</span></a>.
In comparison with the original ResNet architecture,
the global average pooling layer and last fully-connected layer
are removed.
In their place,
the designers of UrsoNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite> insert
a bottleneck layer consisting of a 3<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mo id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><times id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">×</annotation></semantics></math>3 convolution with stride 2
as well as two fully-connected layers calculating
the satellite’s location and orientation.
To build our network,
we use the “soyuz_hard” dataset
and follow the training guidelines of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>.
The dataset is split using an 80-10-10 scheme, that is, 4000 images comprise the training set, while the validation and testing set consist of 500 of the remaining images each.
The configuration of UrsoNet for deploying it on Myriad X
is reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.T1" title="Table 1 ‣ 4.2 Deep Neural Network for Pose Estimation ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">1</span></a>.
The initial weights of the backbone are acquired from a Mask R-CNN model pre-trained on the COCO dataset, as suggested in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>. Data augmentation is performed by randomly rotating half of the training images per epoch.
The image resolution is decreased
using the resampling algorithms and zero padding.
All models are trained for 100 epoques on
Nvidia’s Tesla V100 GPU.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="354" id="S4.F3.g1" src="x3.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The architecture of the UrsoNet DNN for pose estimation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">To generate the binary network file and deploy it on the USB NCS2
accelerator of Myriad X,
we follow the typical OpenVINO toolflow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib41" title="">41</a>]</cite>.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F4" title="Figure 4 ‣ 4.2 Deep Neural Network for Pose Estimation ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the mapping of the basic network blocks of our UrsoNet architecture on Myriad X.
Compared to the original ResNet architecture,
the batch normalization blocks are replaced by add operations,
which are accelerated on SHAVEs.
Smaller operations,
e.g., some permutations before the fully-connected layers,
are also executed on SHAVEs.
The convolutions and fully-connected layers
are mapped onto NCE,
while almost all the ReLU activation functions
are optimized out by OpenVINO during the graph transformation stage,
i.e., they are fused with other operations.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The configuration of the UrsoNet DNN for deployment on Myriad X</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.16">
<tr class="ltx_tr" id="S4.T1.16.17">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.16.17.1" style="padding:0.75pt 15.0pt;">Backbone</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.16.17.2" style="padding:0.75pt 15.0pt;">ResNet-50</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_left" id="S4.T1.1.1.2" style="padding:0.75pt 15.0pt;">Bottleneck Width</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.1" style="padding:0.75pt 15.0pt;"><math alttext="128" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mn id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><cn id="S4.T1.1.1.1.m1.1.1.cmml" type="integer" xref="S4.T1.1.1.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">128</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">128</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2">
<td class="ltx_td ltx_align_left" id="S4.T1.2.2.2" style="padding:0.75pt 15.0pt;">Branch Size</td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.2.1" style="padding:0.75pt 15.0pt;"><math alttext="512" class="ltx_Math" display="inline" id="S4.T1.2.2.1.m1.1"><semantics id="S4.T1.2.2.1.m1.1a"><mn id="S4.T1.2.2.1.m1.1.1" xref="S4.T1.2.2.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.1.m1.1b"><cn id="S4.T1.2.2.1.m1.1.1.cmml" type="integer" xref="S4.T1.2.2.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.1.m1.1c">512</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.1.m1.1d">512</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.7.7">
<td class="ltx_td ltx_align_left" id="S4.T1.7.7.6" style="padding:0.75pt 15.0pt;">Input Image</td>
<td class="ltx_td ltx_align_center" id="S4.T1.7.7.5" style="padding:0.75pt 15.0pt;">
<math alttext="1024" class="ltx_Math" display="inline" id="S4.T1.3.3.1.m1.1"><semantics id="S4.T1.3.3.1.m1.1a"><mn id="S4.T1.3.3.1.m1.1.1" xref="S4.T1.3.3.1.m1.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.1.m1.1b"><cn id="S4.T1.3.3.1.m1.1.1.cmml" type="integer" xref="S4.T1.3.3.1.m1.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.1.m1.1c">1024</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.1.m1.1d">1024</annotation></semantics></math><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.4.4.2.m2.1"><semantics id="S4.T1.4.4.2.m2.1a"><mo id="S4.T1.4.4.2.m2.1.1" xref="S4.T1.4.4.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.2.m2.1b"><times id="S4.T1.4.4.2.m2.1.1.cmml" xref="S4.T1.4.4.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.2.m2.1d">×</annotation></semantics></math><math alttext="1024" class="ltx_Math" display="inline" id="S4.T1.5.5.3.m3.1"><semantics id="S4.T1.5.5.3.m3.1a"><mn id="S4.T1.5.5.3.m3.1.1" xref="S4.T1.5.5.3.m3.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.3.m3.1b"><cn id="S4.T1.5.5.3.m3.1.1.cmml" type="integer" xref="S4.T1.5.5.3.m3.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.3.m3.1c">1024</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.3.m3.1d">1024</annotation></semantics></math><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.6.6.4.m4.1"><semantics id="S4.T1.6.6.4.m4.1a"><mo id="S4.T1.6.6.4.m4.1.1" xref="S4.T1.6.6.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.4.m4.1b"><times id="S4.T1.6.6.4.m4.1.1.cmml" xref="S4.T1.6.6.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.6.6.4.m4.1d">×</annotation></semantics></math><math alttext="3" class="ltx_Math" display="inline" id="S4.T1.7.7.5.m5.1"><semantics id="S4.T1.7.7.5.m5.1a"><mn id="S4.T1.7.7.5.m5.1.1" xref="S4.T1.7.7.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.5.m5.1b"><cn id="S4.T1.7.7.5.m5.1.1.cmml" type="integer" xref="S4.T1.7.7.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.5.m5.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.7.5.m5.1d">3</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.16.18">
<td class="ltx_td ltx_align_left" id="S4.T1.16.18.1" style="padding:0.75pt 15.0pt;">Resampling</td>
<td class="ltx_td ltx_align_center" id="S4.T1.16.18.2" style="padding:0.75pt 15.0pt;">Bilinear, Bicubic, Lanczos</td>
</tr>
<tr class="ltx_tr" id="S4.T1.12.12">
<td class="ltx_td ltx_align_left" id="S4.T1.12.12.6" style="padding:0.75pt 15.0pt;">Inference Image</td>
<td class="ltx_td ltx_align_center" id="S4.T1.12.12.5" style="padding:0.75pt 15.0pt;">
<math alttext="512" class="ltx_Math" display="inline" id="S4.T1.8.8.1.m1.1"><semantics id="S4.T1.8.8.1.m1.1a"><mn id="S4.T1.8.8.1.m1.1.1" xref="S4.T1.8.8.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.1.m1.1b"><cn id="S4.T1.8.8.1.m1.1.1.cmml" type="integer" xref="S4.T1.8.8.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.1.m1.1c">512</annotation><annotation encoding="application/x-llamapun" id="S4.T1.8.8.1.m1.1d">512</annotation></semantics></math><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.9.9.2.m2.1"><semantics id="S4.T1.9.9.2.m2.1a"><mo id="S4.T1.9.9.2.m2.1.1" xref="S4.T1.9.9.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.2.m2.1b"><times id="S4.T1.9.9.2.m2.1.1.cmml" xref="S4.T1.9.9.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.9.2.m2.1d">×</annotation></semantics></math><math alttext="512" class="ltx_Math" display="inline" id="S4.T1.10.10.3.m3.1"><semantics id="S4.T1.10.10.3.m3.1a"><mn id="S4.T1.10.10.3.m3.1.1" xref="S4.T1.10.10.3.m3.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.3.m3.1b"><cn id="S4.T1.10.10.3.m3.1.1.cmml" type="integer" xref="S4.T1.10.10.3.m3.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.3.m3.1c">512</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.10.3.m3.1d">512</annotation></semantics></math><math alttext="\times" class="ltx_Math" display="inline" id="S4.T1.11.11.4.m4.1"><semantics id="S4.T1.11.11.4.m4.1a"><mo id="S4.T1.11.11.4.m4.1.1" xref="S4.T1.11.11.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.4.m4.1b"><times id="S4.T1.11.11.4.m4.1.1.cmml" xref="S4.T1.11.11.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T1.11.11.4.m4.1d">×</annotation></semantics></math><math alttext="3" class="ltx_Math" display="inline" id="S4.T1.12.12.5.m5.1"><semantics id="S4.T1.12.12.5.m5.1a"><mn id="S4.T1.12.12.5.m5.1.1" xref="S4.T1.12.12.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.5.m5.1b"><cn id="S4.T1.12.12.5.m5.1.1.cmml" type="integer" xref="S4.T1.12.12.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.5.m5.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.T1.12.12.5.m5.1d">3</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.14">
<td class="ltx_td ltx_align_left" id="S4.T1.14.14.3" style="padding:0.75pt 15.0pt;">Ori./Loc. Resolution</td>
<td class="ltx_td ltx_align_center" id="S4.T1.14.14.2" style="padding:0.75pt 15.0pt;">
<math alttext="16" class="ltx_Math" display="inline" id="S4.T1.13.13.1.m1.1"><semantics id="S4.T1.13.13.1.m1.1a"><mn id="S4.T1.13.13.1.m1.1.1" xref="S4.T1.13.13.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.1.m1.1b"><cn id="S4.T1.13.13.1.m1.1.1.cmml" type="integer" xref="S4.T1.13.13.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.T1.13.13.1.m1.1d">16</annotation></semantics></math>/<math alttext="16" class="ltx_Math" display="inline" id="S4.T1.14.14.2.m2.1"><semantics id="S4.T1.14.14.2.m2.1a"><mn id="S4.T1.14.14.2.m2.1.1" xref="S4.T1.14.14.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.2.m2.1b"><cn id="S4.T1.14.14.2.m2.1.1.cmml" type="integer" xref="S4.T1.14.14.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.2.m2.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.T1.14.14.2.m2.1d">16</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.16.19">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.16.19.1" style="padding:0.75pt 15.0pt;">Pre-Trained Weights</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.16.19.2" style="padding:0.75pt 15.0pt;">COCO</td>
</tr>
<tr class="ltx_tr" id="S4.T1.16.20">
<td class="ltx_td ltx_align_left" id="S4.T1.16.20.1" style="padding:0.75pt 15.0pt;">Dataset</td>
<td class="ltx_td ltx_align_center" id="S4.T1.16.20.2" style="padding:0.75pt 15.0pt;">“soyuz_hard”</td>
</tr>
<tr class="ltx_tr" id="S4.T1.15.15">
<td class="ltx_td ltx_align_left" id="S4.T1.15.15.2" style="padding:0.75pt 15.0pt;">Arithmetic</td>
<td class="ltx_td ltx_align_center" id="S4.T1.15.15.1" style="padding:0.75pt 15.0pt;">
<math alttext="16" class="ltx_Math" display="inline" id="S4.T1.15.15.1.m1.1"><semantics id="S4.T1.15.15.1.m1.1a"><mn id="S4.T1.15.15.1.m1.1.1" xref="S4.T1.15.15.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.1.m1.1b"><cn id="S4.T1.15.15.1.m1.1.1.cmml" type="integer" xref="S4.T1.15.15.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="S4.T1.15.15.1.m1.1d">16</annotation></semantics></math>-bit floating-point</td>
</tr>
<tr class="ltx_tr" id="S4.T1.16.16">
<td class="ltx_td ltx_align_left" id="S4.T1.16.16.2" style="padding:0.75pt 15.0pt;">Epochs</td>
<td class="ltx_td ltx_align_center" id="S4.T1.16.16.1" style="padding:0.75pt 15.0pt;"><math alttext="100" class="ltx_Math" display="inline" id="S4.T1.16.16.1.m1.1"><semantics id="S4.T1.16.16.1.m1.1a"><mn id="S4.T1.16.16.1.m1.1.1" xref="S4.T1.16.16.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.T1.16.16.1.m1.1b"><cn id="S4.T1.16.16.1.m1.1.1.cmml" type="integer" xref="S4.T1.16.16.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.16.1.m1.1c">100</annotation><annotation encoding="application/x-llamapun" id="S4.T1.16.16.1.m1.1d">100</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T1.16.21">
<td class="ltx_td ltx_align_left" id="S4.T1.16.21.1" style="padding:0.75pt 15.0pt;">Image Augmentation</td>
<td class="ltx_td ltx_align_center" id="S4.T1.16.21.2" style="padding:0.75pt 15.0pt;">Yes</td>
</tr>
<tr class="ltx_tr" id="S4.T1.16.22">
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T1.16.22.1" style="padding:0.75pt 15.0pt;">Optimizer</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.16.22.2" style="padding:0.75pt 15.0pt;">SGD</td>
</tr>
</table>
</figure>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="773" id="S4.F4.g1" src="x4.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Mapping of the DNN for pose estimation on Myriad X.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Computer Vision Pipeline for Pose Tracking</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The continuous tracking of the satellite’s pose is performed with a classic CV pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite>,
which is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F5" title="Figure 5 ‣ 4.3 Computer Vision Pipeline for Pose Tracking ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">5</span></a>.
This algorithmic pipeline
involves functions for feature detection, perpendicular matching, image/depth rendering, and linear algebra operations.
In particular,
the pipeline evolves an initial pose
by matching edges
detected on the input image and a depth map (rendered from the satellite’s 3D mesh model).
The matching edges
are then used
to refine the 6D pose
via robust regression calculations.
For the Edge Detection function,
we employ the well-established Canny edge detector <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib42" title="">42</a>]</cite>,
which applies convolutions, non-maximum suppression and hysteresis thresholding.
The Depth Rendering function uses a triangle mesh model
and the 6D pose to generate the depth image,
whose pixels encode the distance
between the camera and the nearest point on
the model’s surface.
The function is based on rasterization
to project the triangles on the image,
and also involves tasks such as bounding box traversal and distance calculation.
Perpendicular Edge Matching
detects the correspondences between the input and the depth image,
and involves image traversal and comparisons.
Finally,
Pose Refinement uses the matching edges and spatial information
to determine the change in satellite’s pose
via linear algebra operations.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Considering that the CV pipeline
is expected to run for multiple successive frames,
we integrate the function for image reception via CIF
in the pipeline.
The heterogeneity of the SoC
facilitates the complex scheduling
presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F6" title="Figure 6 ‣ 4.3 Computer Vision Pipeline for Pose Tracking ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">6</span></a>,
where the reception of the next frame starts
before finishing the processing of the current frame.
The main functions, i.e., Canny Edge Detection, Depth Rendering, and Edge Matching,
are accelerated on SHAVEs,
while LEON RT receives the image via the I/O interface
and LEON OS executes the algebraic-based Pose Refinement
(not mapped onto SHAVEs due to limited BLAS/LAPACK library support).</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="277" id="S4.F5.g1" src="x5.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The block diagram of the CV pipeline for pose tracking <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite>.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="631" id="S4.F6.g1" src="x6.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Scheduling of the CV pipeline for pose tracking on Myriad X.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">For the functions running on SHAVEs,
the processing is performed in image stripes (tiles of pixel rows).
Namely,
LEON OS divides the image into stripes
and assigns them to SHAVEs for parallel processing.
We define the processing of one stripe as one task.
For Edge Detection and Edge Matching,
we apply <em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.1">static task scheduling</em>,
i.e., each SHAVE is assigned a predefined number of stripes to process.
In contrast,
to reduce the idle core time
in the content-dependent Depth Rendering,
we apply <em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.2">dynamic task scheduling</em>,
i.e., each SHAVE is assigned a new stripe to process
upon finishing its previous one.
At lower level,
we apply the optimizations of the resampling algorithms,
i.e., variable tuning and SIMD,
as well as <em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.3">improved buffering</em>
(to allow in-place computations),
<em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.4">loop merging</em>
(to perform calculations within the same loop),
and <em class="ltx_emph ltx_font_italic" id="S4.SS3.p3.1.5">cache optimization</em>
(to improve data accesses).
All these techniques are manually developed in-house.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Evaluation</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental Setup</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The development on Myriad X is performed
with MDK R15.4.
For the DNN implementation,
we use TensorFlow to train and build the model,
and OpenVINO 2021.3 to generate the network binary file.
We consider 1-MegaPixel RGB image as input,
which is scaled to 512<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mo id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><times id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">×</annotation></semantics></math>512 RGB for the DNN inference
and transformed to 1-MegaPixel grayscale for the CV pipeline.
We also employ a power management scheme
(using an API built on-top of the vendor routines)
to deactivate the SoC’s idle components,
i.e., we power off the islands
of unused peripherals and hardware filters.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Experimental results for the pose estimation AI pipeline on Myriad X
(1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.5.m1.1"><semantics id="S5.T2.5.m1.1b"><mo id="S5.T2.5.m1.1.1" xref="S5.T2.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.m1.1c"><times id="S5.T2.5.m1.1.1.cmml" xref="S5.T2.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.m1.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.m1.1e">×</annotation></semantics></math>1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.6.m2.1"><semantics id="S5.T2.6.m2.1b"><mo id="S5.T2.6.m2.1.1" xref="S5.T2.6.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.m2.1c"><times id="S5.T2.6.m2.1.1.cmml" xref="S5.T2.6.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.m2.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.m2.1e">×</annotation></semantics></math>3 input image resampled to 512<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.7.m3.1"><semantics id="S5.T2.7.m3.1b"><mo id="S5.T2.7.m3.1.1" xref="S5.T2.7.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.7.m3.1c"><times id="S5.T2.7.m3.1.1.cmml" xref="S5.T2.7.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.m3.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.m3.1e">×</annotation></semantics></math>512<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.8.m4.1"><semantics id="S5.T2.8.m4.1b"><mo id="S5.T2.8.m4.1.1" xref="S5.T2.8.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.8.m4.1c"><times id="S5.T2.8.m4.1.1.cmml" xref="S5.T2.8.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.m4.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.m4.1e">×</annotation></semantics></math>3 for DNN inference)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S5.T2.20">
<tr class="ltx_tr" id="S5.T2.20.13">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="8" id="S5.T2.20.13.1" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T2.20.13.1.1">Image Resampling</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S5.T2.20.13.2" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T2.20.13.2.1">DNN Inference<sup class="ltx_sup" id="S5.T2.20.13.2.1.1"><span class="ltx_text ltx_font_upright" id="S5.T2.20.13.2.1.1.1">4</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.20.13.3" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T2.20.13.3.1">AI: Pose Estimation</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.20.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.20.14.1" rowspan="2" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.20.14.1.1">Algorithm</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S5.T2.20.14.2" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.20.14.2.1">Performance</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S5.T2.20.14.3" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.20.14.3.1">Power</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.20.14.4" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.20.14.4.1">Performance</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.20.14.5" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.20.14.5.1">Accuracy</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.20.14.6" style="padding:0.75pt 4.3pt;"><span class="ltx_text ltx_font_bold" id="S5.T2.20.14.6.1">Performance</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.20.15">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.1" style="padding:0.75pt 4.3pt;">Latency</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.2" style="padding:0.75pt 4.3pt;">Improv.<sup class="ltx_sup" id="S5.T2.20.15.2.1">1</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.3" style="padding:0.75pt 4.3pt;">Speedup<sup class="ltx_sup" id="S5.T2.20.15.3.1">2</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.4" style="padding:0.75pt 4.3pt;">Core</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.5" style="padding:0.75pt 4.3pt;">DRAM</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.6" style="padding:0.75pt 4.3pt;">Total</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.7" style="padding:0.75pt 4.3pt;">Improv.<sup class="ltx_sup" id="S5.T2.20.15.7.1">3</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.8" style="padding:0.75pt 4.3pt;">Latency</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.9" style="padding:0.75pt 4.3pt;">Speedup<sup class="ltx_sup" id="S5.T2.20.15.9.1">5</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.10" style="padding:0.75pt 4.3pt;">LOCE<sup class="ltx_sup" id="S5.T2.20.15.10.1">6</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.11" style="padding:0.75pt 4.3pt;">ORIE<sup class="ltx_sup" id="S5.T2.20.15.11.1">6</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.12" style="padding:0.75pt 4.3pt;">Latency</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.20.15.13" style="padding:0.75pt 4.3pt;">Throughput</td>
</tr>
<tr class="ltx_tr" id="S5.T2.12.4">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.12.4.5" style="padding:0.75pt 4.3pt;">Bilinear</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.6" style="padding:0.75pt 4.3pt;">1ms</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.9.1.1" style="padding:0.75pt 4.3pt;">141<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.9.1.1.m1.1"><semantics id="S5.T2.9.1.1.m1.1a"><mo id="S5.T2.9.1.1.m1.1.1" xref="S5.T2.9.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.9.1.1.m1.1b"><times id="S5.T2.9.1.1.m1.1.1.cmml" xref="S5.T2.9.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.9.1.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.10.2.2" style="padding:0.75pt 4.3pt;">425<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.10.2.2.m1.1"><semantics id="S5.T2.10.2.2.m1.1a"><mo id="S5.T2.10.2.2.m1.1.1" xref="S5.T2.10.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.10.2.2.m1.1b"><times id="S5.T2.10.2.2.m1.1.1.cmml" xref="S5.T2.10.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.2.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.10.2.2.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.7" style="padding:0.75pt 4.3pt;">1.9W</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.8" style="padding:0.75pt 4.3pt;">0.1W</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.9" style="padding:0.75pt 4.3pt;">2.0W</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.10" style="padding:0.75pt 4.3pt;">10%</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.11" style="padding:0.75pt 4.3pt;">373ms</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.11.3.3" style="padding:0.75pt 4.3pt;">5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.11.3.3.m1.1"><semantics id="S5.T2.11.3.3.m1.1a"><mo id="S5.T2.11.3.3.m1.1.1" xref="S5.T2.11.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.11.3.3.m1.1b"><times id="S5.T2.11.3.3.m1.1.1.cmml" xref="S5.T2.11.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.3.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.11.3.3.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.12" style="padding:0.75pt 4.3pt;">1.18m</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.4" style="padding:0.75pt 4.3pt;">14.76<sup class="ltx_sup" id="S5.T2.12.4.4.1">∘</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.13" style="padding:0.75pt 4.3pt;">374ms</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.12.4.14" style="padding:0.75pt 4.3pt;">2.7 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T2.16.8">
<td class="ltx_td ltx_align_left" id="S5.T2.16.8.5" style="padding:0.75pt 4.3pt;">Bicubic</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.6" style="padding:0.75pt 4.3pt;">6ms</td>
<td class="ltx_td ltx_align_center" id="S5.T2.13.5.1" style="padding:0.75pt 4.3pt;">68<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.13.5.1.m1.1"><semantics id="S5.T2.13.5.1.m1.1a"><mo id="S5.T2.13.5.1.m1.1.1" xref="S5.T2.13.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.13.5.1.m1.1b"><times id="S5.T2.13.5.1.m1.1.1.cmml" xref="S5.T2.13.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.13.5.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.13.5.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.14.6.2" style="padding:0.75pt 4.3pt;">285<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.14.6.2.m1.1"><semantics id="S5.T2.14.6.2.m1.1a"><mo id="S5.T2.14.6.2.m1.1.1" xref="S5.T2.14.6.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.14.6.2.m1.1b"><times id="S5.T2.14.6.2.m1.1.1.cmml" xref="S5.T2.14.6.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.14.6.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.14.6.2.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.7" style="padding:0.75pt 4.3pt;">1.9W</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.8" style="padding:0.75pt 4.3pt;">0.1W</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.9" style="padding:0.75pt 4.3pt;">2.0W</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.10" style="padding:0.75pt 4.3pt;">9%</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.11" style="padding:0.75pt 4.3pt;">373ms</td>
<td class="ltx_td ltx_align_center" id="S5.T2.15.7.3" style="padding:0.75pt 4.3pt;">5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.15.7.3.m1.1"><semantics id="S5.T2.15.7.3.m1.1a"><mo id="S5.T2.15.7.3.m1.1.1" xref="S5.T2.15.7.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.15.7.3.m1.1b"><times id="S5.T2.15.7.3.m1.1.1.cmml" xref="S5.T2.15.7.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.15.7.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.15.7.3.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.12" style="padding:0.75pt 4.3pt;">1.15m</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.4" style="padding:0.75pt 4.3pt;">14.62<sup class="ltx_sup" id="S5.T2.16.8.4.1">∘</sup>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.13" style="padding:0.75pt 4.3pt;">379ms</td>
<td class="ltx_td ltx_align_center" id="S5.T2.16.8.14" style="padding:0.75pt 4.3pt;">2.6 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T2.20.12">
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T2.20.12.5" style="padding:0.75pt 4.3pt;">Lanczos</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.6" style="padding:0.75pt 4.3pt;">19ms</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.17.9.1" style="padding:0.75pt 4.3pt;">55<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.17.9.1.m1.1"><semantics id="S5.T2.17.9.1.m1.1a"><mo id="S5.T2.17.9.1.m1.1.1" xref="S5.T2.17.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.17.9.1.m1.1b"><times id="S5.T2.17.9.1.m1.1.1.cmml" xref="S5.T2.17.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.17.9.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.17.9.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.18.10.2" style="padding:0.75pt 4.3pt;">360<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.18.10.2.m1.1"><semantics id="S5.T2.18.10.2.m1.1a"><mo id="S5.T2.18.10.2.m1.1.1" xref="S5.T2.18.10.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.18.10.2.m1.1b"><times id="S5.T2.18.10.2.m1.1.1.cmml" xref="S5.T2.18.10.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.18.10.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.18.10.2.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.7" style="padding:0.75pt 4.3pt;">2.1W</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.8" style="padding:0.75pt 4.3pt;">0.1W</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.9" style="padding:0.75pt 4.3pt;">2.2W</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.10" style="padding:0.75pt 4.3pt;">9%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.11" style="padding:0.75pt 4.3pt;">373ms</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.19.11.3" style="padding:0.75pt 4.3pt;">5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T2.19.11.3.m1.1"><semantics id="S5.T2.19.11.3.m1.1a"><mo id="S5.T2.19.11.3.m1.1.1" xref="S5.T2.19.11.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.19.11.3.m1.1b"><times id="S5.T2.19.11.3.m1.1.1.cmml" xref="S5.T2.19.11.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.19.11.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T2.19.11.3.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.12" style="padding:0.75pt 4.3pt;">1.15m</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.4" style="padding:0.75pt 4.3pt;">14.57<sup class="ltx_sup" id="S5.T2.20.12.4.1">∘</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.13" style="padding:0.75pt 4.3pt;">392ms</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T2.20.12.14" style="padding:0.75pt 4.3pt;">2.6 FPS</td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S5.I1">
<div class="ltx_block ltx_minipage ltx_align_middle" id="S5.I1.1" style="width:134.4pt;">
<li class="ltx_item" id="S5.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span>
<div class="ltx_para" id="S5.I1.ix1.p1">
<p class="ltx_p" id="S5.I1.ix1.p1.1"><span class="ltx_text" id="S5.I1.ix1.p1.1.1" style="font-size:70%;">improvement vs. straightforward SHAVE parallelization</span>
<span class="ltx_item" id="S5.I1.ix2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2</span>
<span class="ltx_para" id="S5.I1.ix2.p1">
<span class="ltx_p" id="S5.I1.ix2.p1.1"><span class="ltx_text" id="S5.I1.ix2.p1.1.1" style="font-size:70%;">speedup vs. execution on LEON4 CPU</span></span>
</span></span></p>
</div>
</li>
</div>
<div class="ltx_block ltx_minipage ltx_align_middle" id="S5.I1.2" style="width:121.4pt;">
<li class="ltx_item" id="S5.I1.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3</span>
<div class="ltx_para" id="S5.I1.ix3.p1">
<p class="ltx_p" id="S5.I1.ix3.p1.1"><span class="ltx_text" id="S5.I1.ix3.p1.1.1" style="font-size:70%;">improvement vs. default power management</span>
<span class="ltx_item" id="S5.I1.ix4" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">4</span>
<span class="ltx_para" id="S5.I1.ix4.p1">
<span class="ltx_p" id="S5.I1.ix4.p1.1"><span class="ltx_text" id="S5.I1.ix4.p1.1.1" style="font-size:70%;">synchronous inference (throughput = 1/latency)</span></span>
</span></span></p>
</div>
</li>
</div>
<div class="ltx_block ltx_minipage ltx_align_middle" id="S5.I1.3" style="width:173.4pt;">
<li class="ltx_item" id="S5.I1.ix5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5</span>
<div class="ltx_para" id="S5.I1.ix5.p1">
<p class="ltx_p" id="S5.I1.ix5.p1.2"><span class="ltx_text" id="S5.I1.ix5.p1.2.2" style="font-size:70%;">speedup vs. original DNN (1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.I1.ix5.p1.1.1.m1.1"><semantics id="S5.I1.ix5.p1.1.1.m1.1a"><mo id="S5.I1.ix5.p1.1.1.m1.1.1" xref="S5.I1.ix5.p1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.I1.ix5.p1.1.1.m1.1b"><times id="S5.I1.ix5.p1.1.1.m1.1.1.cmml" xref="S5.I1.ix5.p1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.ix5.p1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.I1.ix5.p1.1.1.m1.1d">×</annotation></semantics></math>1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.I1.ix5.p1.2.2.m2.1"><semantics id="S5.I1.ix5.p1.2.2.m2.1a"><mo id="S5.I1.ix5.p1.2.2.m2.1.1" xref="S5.I1.ix5.p1.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.I1.ix5.p1.2.2.m2.1b"><times id="S5.I1.ix5.p1.2.2.m2.1.1.cmml" xref="S5.I1.ix5.p1.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.ix5.p1.2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.I1.ix5.p1.2.2.m2.1d">×</annotation></semantics></math>3 image)</span>
<span class="ltx_item" id="S5.I1.ix6" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">6</span>
<span class="ltx_para" id="S5.I1.ix6.p1">
<span class="ltx_p" id="S5.I1.ix6.p1.1"><span class="ltx_text" id="S5.I1.ix6.p1.1.1" style="font-size:70%;">LOCE=1.3m &amp; ORIE=10.7<sup class="ltx_sup" id="S5.I1.ix6.p1.1.1.1">∘</sup> in original DNN without resampling
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite></span></span>
</span></span></p>
</div>
</li>
</div>
</ul>
</div>
<div class="ltx_flex_break"></div>
</div>
</figure>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Regarding the AI pipeline,
we compare our final implementation of the resampling algorithms on SHAVEs
with the straightforward core parallelization scheme,
which
divides the input image into 16 stripes
and the SHAVEs process one stripe in parallel
without applying any of the proposed optimizations,
and the execution on the LEON4 CPU
(columns 2–4 of Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T2" title="Table 2 ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a>).
Furthermore,
we measure the power consumption
and examine its reduction by our power management scheme (columns 5–8 of Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T2" title="Table 2 ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a>).
Our resampled DNN inference on NCE &amp; SHAVEs
is evaluated by comparing it with
the respective execution on the same processors
for the original 1-MegaPixel image
(columns 9–12 of Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T2" title="Table 2 ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a>).
Finally, we examine the performance of the entire AI pipeline
(columns 13–14 of Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T2" title="Table 2 ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a>).
Regarding the CV pipeline,
we evaluate its acceleration on the SHAVEs of Myriad X
in comparison with
the respective optimized implementation on Myriad 2
and the execution on the LEON4 CPU of Myriad 2
(columns 3–4 of Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T3" title="Table 3 ‣ 5.2 Experimental Results on Myriad X VPU ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental Results on Myriad X VPU</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.10">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T2" title="Table 2 ‣ 5.1 Experimental Setup ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">2</span></a> reports our results per AI pipeline and resampling algorithm.
The focus is on performance (i.e., speed) and power.
The latency of the pre-processing stage is
1–20ms, depending on the algorithm,
which implies 55–141<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mo id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><times id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">×</annotation></semantics></math> performance improvement versus the straightforward parallelization on SHAVEs
without the optimizations (sliding buffer, variable tuning, SIMD) and the use of the scratchpad memory (CMX).
Compared to LEON4,
the speedup is remarkable,
i.e., up to 425<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><mo id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><times id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.1d">×</annotation></semantics></math>.
In terms of power,
our manager improves the consumption by 10%,
delivering around 2W (95% of the total power is consumed by the LEON4 and SHAVE processors).
Moreover,
a single DNN inference (synchronous execution)
on a 512<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><mo id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><times id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">×</annotation></semantics></math>512<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><mo id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><times id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">×</annotation></semantics></math>3 image requires around 373ms,
which is 5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><mo id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><times id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.5.m5.1d">×</annotation></semantics></math> faster than inferencing on the initial
1-MegaPixel image.
At the same time,
the mean Location Error (LOCE) is 1.15–1.18m
and the mean Orientation Error (ORIE) is 14.57<sup class="ltx_sup" id="S5.SS2.p1.10.1">∘</sup>–14.76<sup class="ltx_sup" id="S5.SS2.p1.10.2">∘</sup> for the
“soyuz_hard” dataset,
i.e., both accuracy metrics are in the range of the respective values reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>.
As a result,
like in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>, the accuracy of our DNN is close to that of the
DNN without resampling (LOCE is 1.3m and ORIE is 10.7<sup class="ltx_sup" id="S5.SS2.p1.10.3">∘</sup>).
Furthermore, the network trained with the same configuration on the “soyuz_easy” dataset has a LOCE equal to 0.7m and an ORIE of 8.7<sup class="ltx_sup" id="S5.SS2.p1.10.4">∘</sup>.
These values are sufficiently close to the results reported in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib5" title="">5</a>]</cite>, namely 0.6m LOCE and 8.0<sup class="ltx_sup" id="S5.SS2.p1.10.5">∘</sup> ORIE,
however, once again the average latency is retained at
373ms, indicating that training does not impact the performance.
In all cases,
more fine-grained training
can provide better accuracy results for the same performance on the Myriad X SoC.
Overall,
the entire AI pipeline achieves 2.6–2.7 FPS for synchronous execution (throughput will increase for asynchronous inferencing).</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.6">From the CV pipeline,
Depth Rendering is the most demanding function,
providing a variable latency
as it is highly dependent on the image content.
Our techniques
(dynamic scheduling, SIMD and cache optimization)
improve the latency of this function
by 8<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mo id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><times id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">×</annotation></semantics></math> compared to the straightforward parallelization on SHAVEs.
Similar improvements are also delivered
in the Edge Detection function.
Edge Matching is a memory-intensive function involving comparisons,
thus, it is facilitated by our cache optimizations
to deliver a speedup of 4<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mo id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><times id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">×</annotation></semantics></math> compared to the straightforward SHAVE parallelization.
In Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T3" title="Table 3 ‣ 5.2 Experimental Results on Myriad X VPU ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">3</span></a>, we report the latency results
for the CV pipeline along with the gains compared to the LEON4 and SHAVE processors of Myriad 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite>.
Compared to LEON4,
the speedup is 15–20<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mo id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><times id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">×</annotation></semantics></math>
for the compute-intensive functions
and
100<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.4.m4.1"><semantics id="S5.SS2.p2.4.m4.1a"><mo id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><times id="S5.SS2.p2.4.m4.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.4.m4.1d">×</annotation></semantics></math> for the memory-intensive function.
Furthermore,
compared to the SHAVE implementation on Myriad 2,
we notice a speedup of 1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.5.m5.1"><semantics id="S5.SS2.p2.5.m5.1a"><mo id="S5.SS2.p2.5.m5.1.1" xref="S5.SS2.p2.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.5.m5.1b"><times id="S5.SS2.p2.5.m5.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.5.m5.1d">×</annotation></semantics></math> and 5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.6.m6.1"><semantics id="S5.SS2.p2.6.m6.1a"><mo id="S5.SS2.p2.6.m6.1.1" xref="S5.SS2.p2.6.m6.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.6.m6.1b"><times id="S5.SS2.p2.6.m6.1.1.cmml" xref="S5.SS2.p2.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.6.m6.1d">×</annotation></semantics></math>, respectively,
which mainly comes from the 4 extra SHAVEs
(16 in Myriad X)
and the increased clock frequency (700MHz in Myriad X).
Finally, in terms of accuracy,
the error is below 0.5m
and tracking is lost only in a few frames.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance of the pose tracking CV pipeline on Myriad X</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S5.T3.12">
<tr class="ltx_tr" id="S5.T3.12.13">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.12.13.1" style="padding:0.75pt 6.2pt;">
<span class="ltx_text" id="S5.T3.12.13.1.1"></span> <span class="ltx_text" id="S5.T3.12.13.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T3.12.13.1.2.1">
<span class="ltx_tr" id="S5.T3.12.13.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T3.12.13.1.2.1.1.1" style="padding:0.75pt 6.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.12.13.1.2.1.1.1.1">Function</span></span></span>
</span></span><span class="ltx_text" id="S5.T3.12.13.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.12.13.2" style="padding:0.75pt 6.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.12.13.2.1">Latency</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.12.13.3" style="padding:0.75pt 6.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.12.13.3.1">Speedup<sup class="ltx_sup" id="S5.T3.12.13.3.1.1">1</sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.12.13.4" style="padding:0.75pt 6.2pt;"><span class="ltx_text ltx_font_bold" id="S5.T3.12.13.4.1">Speedup<sup class="ltx_sup" id="S5.T3.12.13.4.1.1">2</sup></span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T3.2.2.3" style="padding:0.75pt 6.2pt;">Intensity Edge Detection</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.2.2.4" style="padding:0.75pt 6.2pt;">24ms</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.1" style="padding:0.75pt 6.2pt;">15<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.m1.1a"><mo id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><times id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.2.2.2" style="padding:0.75pt 6.2pt;">1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.m1.1a"><mo id="S5.T3.2.2.2.m1.1.1" xref="S5.T3.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.m1.1b"><times id="S5.T3.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.m1.1d">×</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.4.4.3" style="padding:0.75pt 6.2pt;">Depth Rendering</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.4" style="padding:0.75pt 6.2pt;">77–170ms</td>
<td class="ltx_td ltx_align_center" id="S5.T3.3.3.1" style="padding:0.75pt 6.2pt;">20<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.3.3.1.m1.1"><semantics id="S5.T3.3.3.1.m1.1a"><mo id="S5.T3.3.3.1.m1.1.1" xref="S5.T3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.1.m1.1b"><times id="S5.T3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.2" style="padding:0.75pt 6.2pt;">1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.4.4.2.m1.1"><semantics id="S5.T3.4.4.2.m1.1a"><mo id="S5.T3.4.4.2.m1.1.1" xref="S5.T3.4.4.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.2.m1.1b"><times id="S5.T3.4.4.2.m1.1.1.cmml" xref="S5.T3.4.4.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.2.m1.1d">×</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.6.6.3" style="padding:0.75pt 6.2pt;">Depth Edge Detection</td>
<td class="ltx_td ltx_align_center" id="S5.T3.6.6.4" style="padding:0.75pt 6.2pt;">26ms</td>
<td class="ltx_td ltx_align_center" id="S5.T3.5.5.1" style="padding:0.75pt 6.2pt;">15<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.5.5.1.m1.1"><semantics id="S5.T3.5.5.1.m1.1a"><mo id="S5.T3.5.5.1.m1.1.1" xref="S5.T3.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.1.m1.1b"><times id="S5.T3.5.5.1.m1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.6.6.2" style="padding:0.75pt 6.2pt;">1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.6.6.2.m1.1"><semantics id="S5.T3.6.6.2.m1.1a"><mo id="S5.T3.6.6.2.m1.1.1" xref="S5.T3.6.6.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.2.m1.1b"><times id="S5.T3.6.6.2.m1.1.1.cmml" xref="S5.T3.6.6.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.6.6.2.m1.1d">×</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.8.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.8.8.3" style="padding:0.75pt 6.2pt;">Edge Matching</td>
<td class="ltx_td ltx_align_center" id="S5.T3.8.8.4" style="padding:0.75pt 6.2pt;">1ms</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.7.1" style="padding:0.75pt 6.2pt;">100<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.7.7.1.m1.1"><semantics id="S5.T3.7.7.1.m1.1a"><mo id="S5.T3.7.7.1.m1.1.1" xref="S5.T3.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.1.m1.1b"><times id="S5.T3.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.7.7.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.8.8.2" style="padding:0.75pt 6.2pt;">5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.8.8.2.m1.1"><semantics id="S5.T3.8.8.2.m1.1a"><mo id="S5.T3.8.8.2.m1.1.1" xref="S5.T3.8.8.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.2.m1.1b"><times id="S5.T3.8.8.2.m1.1.1.cmml" xref="S5.T3.8.8.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.8.8.2.m1.1d">×</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.10.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.10.10.3" style="padding:0.75pt 6.2pt;">Pose Refinement</td>
<td class="ltx_td ltx_align_center" id="S5.T3.10.10.4" style="padding:0.75pt 6.2pt;">90–120ms</td>
<td class="ltx_td ltx_align_center" id="S5.T3.9.9.1" style="padding:0.75pt 6.2pt;">1.1<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.9.9.1.m1.1"><semantics id="S5.T3.9.9.1.m1.1a"><mo id="S5.T3.9.9.1.m1.1.1" xref="S5.T3.9.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.1.m1.1b"><times id="S5.T3.9.9.1.m1.1.1.cmml" xref="S5.T3.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.9.9.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.10.10.2" style="padding:0.75pt 6.2pt;">1.1<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.10.10.2.m1.1"><semantics id="S5.T3.10.10.2.m1.1a"><mo id="S5.T3.10.10.2.m1.1.1" xref="S5.T3.10.10.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.2.m1.1b"><times id="S5.T3.10.10.2.m1.1.1.cmml" xref="S5.T3.10.10.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.10.10.2.m1.1d">×</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.12.12">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.12.12.3" style="padding:0.75pt 6.2pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T3.12.12.3.1">CV: Pose Tracking</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.12.12.4" style="padding:0.75pt 6.2pt;">218–341ms<sup class="ltx_sup" id="S5.T3.12.12.4.1">3</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.11.11.1" style="padding:0.75pt 6.2pt;">13<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.11.11.1.m1.1"><semantics id="S5.T3.11.11.1.m1.1a"><mo id="S5.T3.11.11.1.m1.1.1" xref="S5.T3.11.11.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.11.11.1.m1.1b"><times id="S5.T3.11.11.1.m1.1.1.cmml" xref="S5.T3.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.11.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.11.11.1.m1.1d">×</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S5.T3.12.12.2" style="padding:0.75pt 6.2pt;">1.4<math alttext="\times" class="ltx_Math" display="inline" id="S5.T3.12.12.2.m1.1"><semantics id="S5.T3.12.12.2.m1.1a"><mo id="S5.T3.12.12.2.m1.1.1" xref="S5.T3.12.12.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T3.12.12.2.m1.1b"><times id="S5.T3.12.12.2.m1.1.1.cmml" xref="S5.T3.12.12.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.12.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T3.12.12.2.m1.1d">×</annotation></semantics></math>
</td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S5.I2">
<li class="ltx_item" id="S5.I2.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span>
<div class="ltx_para" id="S5.I2.ix1.p1">
<p class="ltx_p" id="S5.I2.ix1.p1.1"><span class="ltx_text" id="S5.I2.ix1.p1.1.1" style="font-size:70%;">speedup vs. LEON4 @600MHz (Myriad 2)</span></p>
</div>
</li>
<li class="ltx_item" id="S5.I2.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2</span>
<div class="ltx_para" id="S5.I2.ix2.p1">
<p class="ltx_p" id="S5.I2.ix2.p1.1"><span class="ltx_text" id="S5.I2.ix2.p1.1.1" style="font-size:70%;">speedup vs. 12 SHAVEs @600MHz (Myriad 2)</span></p>
</div>
</li>
<li class="ltx_item" id="S5.I2.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3</span>
<div class="ltx_para" id="S5.I2.ix3.p1">
<p class="ltx_p" id="S5.I2.ix3.p1.1"><span class="ltx_text" id="S5.I2.ix3.p1.1.1" style="font-size:70%;">sequential execution (without the scheduling of Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F6" title="Figure 6 ‣ 4.3 Computer Vision Pipeline for Pose Tracking ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">6</span></a>)</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance of Lost-In-Space modules on Myriad X</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S5.T4.8">
<tr class="ltx_tr" id="S5.T4.8.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.8.9.1" style="padding:0.75pt 2.9pt;">
<span class="ltx_text" id="S5.T4.8.9.1.1"></span> <span class="ltx_text" id="S5.T4.8.9.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.8.9.1.2.1">
<span class="ltx_tr" id="S5.T4.8.9.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.8.9.1.2.1.1.1" style="padding:0.75pt 2.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.9.1.2.1.1.1.1">Module</span></span></span>
</span></span><span class="ltx_text" id="S5.T4.8.9.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.9.2" style="padding:0.75pt 2.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.9.2.1">Input Data</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.9.3" style="padding:0.75pt 2.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.9.3.1">Latency</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.8.9.4" style="padding:0.75pt 2.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T4.8.9.4.1">Throughput</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T4.2.2.3" style="padding:0.75pt 2.9pt;">CIF: Image Reception<sup class="ltx_sup" id="S5.T4.2.2.3.1">1</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.2.2" style="padding:0.75pt 2.9pt;">1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.m1.1a"><mo id="S5.T4.1.1.1.m1.1.1" xref="S5.T4.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b"><times id="S5.T4.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.m1.1d">×</annotation></semantics></math>1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.2.2.2.m2.1"><semantics id="S5.T4.2.2.2.m2.1a"><mo id="S5.T4.2.2.2.m2.1.1" xref="S5.T4.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.m2.1b"><times id="S5.T4.2.2.2.m2.1.1.cmml" xref="S5.T4.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.m2.1d">×</annotation></semantics></math>3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.2.4" style="padding:0.75pt 2.9pt;">63ms</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T4.2.2.5" style="padding:0.75pt 2.9pt;">16 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.4.4.3" style="padding:0.75pt 2.9pt;">Pre-Processing</td>
<td class="ltx_td ltx_align_center" id="S5.T4.4.4.2" style="padding:0.75pt 2.9pt;">1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.3.3.1.m1.1"><semantics id="S5.T4.3.3.1.m1.1a"><mo id="S5.T4.3.3.1.m1.1.1" xref="S5.T4.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.1.m1.1b"><times id="S5.T4.3.3.1.m1.1.1.cmml" xref="S5.T4.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.3.1.m1.1d">×</annotation></semantics></math>1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.4.4.2.m2.1"><semantics id="S5.T4.4.4.2.m2.1a"><mo id="S5.T4.4.4.2.m2.1.1" xref="S5.T4.4.4.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.2.m2.1b"><times id="S5.T4.4.4.2.m2.1.1.cmml" xref="S5.T4.4.4.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.4.2.m2.1d">×</annotation></semantics></math>3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.4.4.4" style="padding:0.75pt 2.9pt;">1–19ms</td>
<td class="ltx_td ltx_align_center" id="S5.T4.4.4.5" style="padding:0.75pt 2.9pt;">50–1000 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T4.6.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T4.6.6.3" style="padding:0.75pt 2.9pt;">AI: Pose Estimation</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.6.2" style="padding:0.75pt 2.9pt;">512<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.5.5.1.m1.1"><semantics id="S5.T4.5.5.1.m1.1a"><mo id="S5.T4.5.5.1.m1.1.1" xref="S5.T4.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.1.m1.1b"><times id="S5.T4.5.5.1.m1.1.1.cmml" xref="S5.T4.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.5.1.m1.1d">×</annotation></semantics></math>512<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.6.6.2.m2.1"><semantics id="S5.T4.6.6.2.m2.1a"><mo id="S5.T4.6.6.2.m2.1.1" xref="S5.T4.6.6.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.2.m2.1b"><times id="S5.T4.6.6.2.m2.1.1.cmml" xref="S5.T4.6.6.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.6.2.m2.1d">×</annotation></semantics></math>3</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.6.4" style="padding:0.75pt 2.9pt;">373ms</td>
<td class="ltx_td ltx_align_center" id="S5.T4.6.6.5" style="padding:0.75pt 2.9pt;">2.7 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T4.8.8">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T4.8.8.3" style="padding:0.75pt 2.9pt;">CV: Pose Tracking</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.8.8.2" style="padding:0.75pt 2.9pt;">1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.7.7.1.m1.1"><semantics id="S5.T4.7.7.1.m1.1a"><mo id="S5.T4.7.7.1.m1.1.1" xref="S5.T4.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.7.7.1.m1.1b"><times id="S5.T4.7.7.1.m1.1.1.cmml" xref="S5.T4.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.7.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.7.7.1.m1.1d">×</annotation></semantics></math>1024<math alttext="\times" class="ltx_Math" display="inline" id="S5.T4.8.8.2.m2.1"><semantics id="S5.T4.8.8.2.m2.1a"><mo id="S5.T4.8.8.2.m2.1.1" xref="S5.T4.8.8.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.8.8.2.m2.1b"><times id="S5.T4.8.8.2.m2.1.1.cmml" xref="S5.T4.8.8.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.8.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T4.8.8.2.m2.1d">×</annotation></semantics></math>1</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.8.8.4" style="padding:0.75pt 2.9pt;">218–341ms</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T4.8.8.5" style="padding:0.75pt 2.9pt;">3.1–5.1 FPS<sup class="ltx_sup" id="S5.T4.8.8.5.1">2</sup>
</td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S5.I3">
<li class="ltx_item" id="S5.I3.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span>
<div class="ltx_para" id="S5.I3.ix1.p1">
<p class="ltx_p" id="S5.I3.ix1.p1.1"><span class="ltx_text" id="S5.I3.ix1.p1.1.1" style="font-size:70%;">CIF@50MHz</span></p>
</div>
</li>
<li class="ltx_item" id="S5.I3.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2</span>
<div class="ltx_para" id="S5.I3.ix2.p1">
<p class="ltx_p" id="S5.I3.ix2.p1.1"><span class="ltx_text" id="S5.I3.ix2.p1.1.1" style="font-size:70%;">with function masking for streaming processing (scheduling, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S4.F6" title="Figure 6 ‣ 4.3 Computer Vision Pipeline for Pose Tracking ‣ 4 AI/CV Acceleration for Lost-In-Space on Myriad X ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">6</span></a>)</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of embedded processors for the UrsoNet DNN (TensorFlow, inference on 512<math alttext="\times" class="ltx_Math" display="inline" id="S5.T5.3.m1.1"><semantics id="S5.T5.3.m1.1b"><mo id="S5.T5.3.m1.1.1" xref="S5.T5.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T5.3.m1.1c"><times id="S5.T5.3.m1.1.1.cmml" xref="S5.T5.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.m1.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T5.3.m1.1e">×</annotation></semantics></math>640<math alttext="\times" class="ltx_Math" display="inline" id="S5.T5.4.m2.1"><semantics id="S5.T5.4.m2.1b"><mo id="S5.T5.4.m2.1.1" xref="S5.T5.4.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T5.4.m2.1c"><times id="S5.T5.4.m2.1.1.cmml" xref="S5.T5.4.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.m2.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T5.4.m2.1e">×</annotation></semantics></math>3 image)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S5.T5.5">
<tr class="ltx_tr" id="S5.T5.5.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T5.5.1.1" style="padding:0.75pt 5.7pt;">
<span class="ltx_text" id="S5.T5.5.1.1.1"></span> <span class="ltx_text" id="S5.T5.5.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T5.5.1.1.2.1">
<span class="ltx_tr" id="S5.T5.5.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T5.5.1.1.2.1.1.1" style="padding:0.75pt 5.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.5.1.1.2.1.1.1.1">Device</span></span></span>
</span></span><span class="ltx_text" id="S5.T5.5.1.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T5.5.1.2" style="padding:0.75pt 5.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.5.1.2.1">Processor</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.1.3" style="padding:0.75pt 5.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.5.1.3.1">Latency</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.1.4" style="padding:0.75pt 5.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.5.1.4.1">Throughput</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.1.5" style="padding:0.75pt 5.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.5.1.5.1">Power</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.1.6" style="padding:0.75pt 5.7pt;"><span class="ltx_text ltx_font_bold" id="S5.T5.5.1.6.1">Throughput-per-Watt</span></td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T5.5.2.1" style="padding:0.75pt 5.7pt;">Intel Myriad X VPU (NCS2)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T5.5.2.2" style="padding:0.75pt 5.7pt;">NCE + 16-core SHAVE @700MHz</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.5.2.3" style="padding:0.75pt 5.7pt;">588ms</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.5.2.4" style="padding:0.75pt 5.7pt;">1.7 FPS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.5.2.5" style="padding:0.75pt 5.7pt;">5W<sup class="ltx_sup" id="S5.T5.5.2.5.1">1</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T5.5.2.6" style="padding:0.75pt 5.7pt;">0.34 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.3">
<td class="ltx_td ltx_align_left" id="S5.T5.5.3.1" rowspan="2" style="padding:0.75pt 5.7pt;"><span class="ltx_text" id="S5.T5.5.3.1.1">ARM Cortex-A57 CPU (Jetson Nano)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T5.5.3.2" style="padding:0.75pt 5.7pt;">4-core @1.4GHz</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.3.3" style="padding:0.75pt 5.7pt;">2830ms</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.3.4" style="padding:0.75pt 5.7pt;">0.4 FPS</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.3.5" style="padding:0.75pt 5.7pt;">10W</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.3.6" style="padding:0.75pt 5.7pt;">0.04 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T5.5.4.1" style="padding:0.75pt 5.7pt;">2-core @918MHz</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.4.2" style="padding:0.75pt 5.7pt;">7519ms</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.4.3" style="padding:0.75pt 5.7pt;">0.1 FPS</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.4.4" style="padding:0.75pt 5.7pt;">5W</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.4.5" style="padding:0.75pt 5.7pt;">0.02 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.5">
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T5.5.5.1" rowspan="2" style="padding:0.75pt 5.7pt;"><span class="ltx_text" id="S5.T5.5.5.1.1">Nvidia Maxwell GPU (Jetson Nano)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T5.5.5.2" style="padding:0.75pt 5.7pt;">128-core @921MHz</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.5.3" style="padding:0.75pt 5.7pt;">761ms</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.5.4" style="padding:0.75pt 5.7pt;">1.3 FPS</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.5.5" style="padding:0.75pt 5.7pt;">10W</td>
<td class="ltx_td ltx_align_center" id="S5.T5.5.5.6" style="padding:0.75pt 5.7pt;">0.13 FPS</td>
</tr>
<tr class="ltx_tr" id="S5.T5.5.6">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T5.5.6.1" style="padding:0.75pt 5.7pt;">128-core @614MHz</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.5.6.2" style="padding:0.75pt 5.7pt;">958ms</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.5.6.3" style="padding:0.75pt 5.7pt;">1 FPS</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.5.6.4" style="padding:0.75pt 5.7pt;">5W</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T5.5.6.5" style="padding:0.75pt 5.7pt;">0.2 FPS</td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S5.I4">
<li class="ltx_item" id="S5.I4.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span>
<div class="ltx_para" id="S5.I4.ix1.p1">
<p class="ltx_p" id="S5.I4.ix1.p1.1"><span class="ltx_text" id="S5.I4.ix1.p1.1.1" style="font-size:70%;">NCS2 (2W) hosted on Raspberry Pi 3 (3W).</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T4" title="Table 4 ‣ 5.2 Experimental Results on Myriad X VPU ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes the performance of each module of the targeted AI/CV embedded system.
The image reception via CIF operating at 50MHz lasts 63ms
according to our experiments with an FPGA transmitting data to the VPU
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib25" title="">25</a>]</cite>.
The pre-processing time is negligible compared to the AI/CV execution,
which sustains a throughput of 2.7–5.1 FPS (sufficient for pose estimation on 1-MegaPixel images).
We note that further speedups can be achieved,
e.g.,
inferencing on 192<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.1.m1.1"><semantics id="S5.SS2.p3.1.m1.1a"><mo id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><times id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.1.m1.1d">×</annotation></semantics></math>256<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.2.m2.1"><semantics id="S5.SS2.p3.2.m2.1a"><mo id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><times id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.2.m2.1d">×</annotation></semantics></math>3 image delivers 15 FPS
with reasonable accuracy loss (LOCE is 1.9–2m),
while the throughput of the CV pipeline
can be improved
by rendering a smaller image.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Comparison to Embedded Devices</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">In this section,
we provide comparisons to other embedded devices
that are also considered for space avionics.
In particular,
we compare our implementations on Myriad X with
the execution on
CPUs (LEON, ARM),
GPUs (Jetson Nano, Tegra K1), and
SoC FPGAs (Zynq).</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.13">Starting with UrsoNet,
Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T5" title="Table 5 ‣ 5.2 Experimental Results on Myriad X VPU ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">5</span></a> presents the results
for inferencing on VPU, CPU, and GPU.
For this experiment,
we use input images that are scaled to
512<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mo id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><times id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">×</annotation></semantics></math>640<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><mo id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><times id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.2.m2.1d">×</annotation></semantics></math>3 size.
The CPU is the ARM Cortex-A57
of Nvidia’s Jetson Nano board,
while our GPU is the 128-core Maxwell of the same board.
For Jetson Nano,
we consider its two power modes:
the “low-power” at 5W
and the “high-performance” at 10W.
To make a fair comparison,
we consider the NCS2 VPU
hosted on a single board computer,
i.e., a Raspberry Pi 3,
and thus,
the total power consumption for inferencing is 5W.
In terms of latency,
the 4-core Cortex-A57 operating at 1.4GHZ is relatively slow,
i.e., NCS2 achieves a 6<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.3.m3.1"><semantics id="S5.SS3.p2.3.m3.1a"><mo id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><times id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.3.m3.1d">×</annotation></semantics></math> speedup.
Compared to the GPU,
NCS2 achieves a slight improvement of 1.3<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.4.m4.1"><semantics id="S5.SS3.p2.4.m4.1a"><mo id="S5.SS3.p2.4.m4.1.1" xref="S5.SS3.p2.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.4.m4.1b"><times id="S5.SS3.p2.4.m4.1.1.cmml" xref="S5.SS3.p2.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.4.m4.1d">×</annotation></semantics></math>,
but with
half of the GPU’s power consumption.
When considering both
throughput and power,
NCS2 delivers
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p2.5.m5.1"><semantics id="S5.SS3.p2.5.m5.1a"><mo id="S5.SS3.p2.5.m5.1.1" xref="S5.SS3.p2.5.m5.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.5.m5.1b"><csymbol cd="latexml" id="S5.SS3.p2.5.m5.1.1.cmml" xref="S5.SS3.p2.5.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.5.m5.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.5.m5.1d">∼</annotation></semantics></math>1.7<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.6.m6.1"><semantics id="S5.SS3.p2.6.m6.1a"><mo id="S5.SS3.p2.6.m6.1.1" xref="S5.SS3.p2.6.m6.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.6.m6.1b"><times id="S5.SS3.p2.6.m6.1.1.cmml" xref="S5.SS3.p2.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.6.m6.1d">×</annotation></semantics></math> more FPS per Watt than GPU
and
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p2.7.m7.1"><semantics id="S5.SS3.p2.7.m7.1a"><mo id="S5.SS3.p2.7.m7.1.1" xref="S5.SS3.p2.7.m7.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.7.m7.1b"><csymbol cd="latexml" id="S5.SS3.p2.7.m7.1.1.cmml" xref="S5.SS3.p2.7.m7.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.7.m7.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.7.m7.1d">∼</annotation></semantics></math>8.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.8.m8.1"><semantics id="S5.SS3.p2.8.m8.1a"><mo id="S5.SS3.p2.8.m8.1.1" xref="S5.SS3.p2.8.m8.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.8.m8.1b"><times id="S5.SS3.p2.8.m8.1.1.cmml" xref="S5.SS3.p2.8.m8.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.8.m8.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.8.m8.1d">×</annotation></semantics></math> more FPS per Watt than CPU.
In addition,
we provide comparison results for the original ResNet-50 network
(224<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.9.m9.1"><semantics id="S5.SS3.p2.9.m9.1a"><mo id="S5.SS3.p2.9.m9.1.1" xref="S5.SS3.p2.9.m9.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.9.m9.1b"><times id="S5.SS3.p2.9.m9.1.1.cmml" xref="S5.SS3.p2.9.m9.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.9.m9.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.9.m9.1d">×</annotation></semantics></math>224<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.10.m10.1"><semantics id="S5.SS3.p2.10.m10.1a"><mo id="S5.SS3.p2.10.m10.1.1" xref="S5.SS3.p2.10.m10.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.10.m10.1b"><times id="S5.SS3.p2.10.m10.1.1.cmml" xref="S5.SS3.p2.10.m10.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.10.m10.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.10.m10.1d">×</annotation></semantics></math>3 image),
which is the backbone of UrsoNet.
For this network,
the Jetson Nano GPU
provides increased throughput versus Pi 3 + NCS2,
i.e., 1.3–1.9<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.11.m11.1"><semantics id="S5.SS3.p2.11.m11.1a"><mo id="S5.SS3.p2.11.m11.1.1" xref="S5.SS3.p2.11.m11.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.11.m11.1b"><times id="S5.SS3.p2.11.m11.1.1.cmml" xref="S5.SS3.p2.11.m11.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.11.m11.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.11.m11.1d">×</annotation></semantics></math> more FPS,
however,
when considering FPS-per-Watt,
the VPU inference outperforms the GPU
by 1.1–1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.12.m12.1"><semantics id="S5.SS3.p2.12.m12.1a"><mo id="S5.SS3.p2.12.m12.1.1" xref="S5.SS3.p2.12.m12.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.12.m12.1b"><times id="S5.SS3.p2.12.m12.1.1.cmml" xref="S5.SS3.p2.12.m12.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.12.m12.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.12.m12.1d">×</annotation></semantics></math>.
Finally,
we note that if we use the Myriad X SoC
rather than the pair Pi 3 + NCS2,
the proposed solution provides even better results against the competitor devices.
In this case, the power consumption lies around 2–2.5W,
while the latency does not include the USB communication time (<math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p2.13.m13.1"><semantics id="S5.SS3.p2.13.m13.1a"><mo id="S5.SS3.p2.13.m13.1.1" xref="S5.SS3.p2.13.m13.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.13.m13.1b"><csymbol cd="latexml" id="S5.SS3.p2.13.m13.1.1.cmml" xref="S5.SS3.p2.13.m13.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.13.m13.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.13.m13.1d">∼</annotation></semantics></math>10ms).</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.10">Next,
we evaluate the acceleration of our CV functions
compared to implementations on other embedded devices.
Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#S5.T6" title="Table 6 ‣ 5.3 Comparison to Embedded Devices ‣ 5 Evaluation ‣ Accelerating AI and Computer Vision for Satellite Pose Estimation on the Intel Myriad X Embedded SoC"><span class="ltx_text ltx_ref_tag">6</span></a> summarizes the comparison with other works of the literature implementing the same functions.
As already discussed
in the previous subsection,
Myriad X outperforms its predecessor Myriad 2
by <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p3.1.m1.1"><semantics id="S5.SS3.p3.1.m1.1a"><mo id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><csymbol cd="latexml" id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.1.m1.1d">∼</annotation></semantics></math>1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.2.m2.1"><semantics id="S5.SS3.p3.2.m2.1a"><mo id="S5.SS3.p3.2.m2.1.1" xref="S5.SS3.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.2.m2.1b"><times id="S5.SS3.p3.2.m2.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.2.m2.1d">×</annotation></semantics></math>,
while compared to the general-purpose LEON4 CPU,
it provides acceleration of 15–20<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.3.m3.1"><semantics id="S5.SS3.p3.3.m3.1a"><mo id="S5.SS3.p3.3.m3.1.1" xref="S5.SS3.p3.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.3.m3.1b"><times id="S5.SS3.p3.3.m3.1.1.cmml" xref="S5.SS3.p3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.3.m3.1d">×</annotation></semantics></math>
for the most demanding functions.
Compared to ARM Cortex-A9 of Xilinx’s Zynq <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite>,
we achieve remarkable speedup,
i.e.,
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p3.4.m4.1"><semantics id="S5.SS3.p3.4.m4.1a"><mo id="S5.SS3.p3.4.m4.1.1" xref="S5.SS3.p3.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.4.m4.1b"><csymbol cd="latexml" id="S5.SS3.p3.4.m4.1.1.cmml" xref="S5.SS3.p3.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.4.m4.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.4.m4.1d">∼</annotation></semantics></math>14<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.5.m5.1"><semantics id="S5.SS3.p3.5.m5.1a"><mo id="S5.SS3.p3.5.m5.1.1" xref="S5.SS3.p3.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.5.m5.1b"><times id="S5.SS3.p3.5.m5.1.1.cmml" xref="S5.SS3.p3.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.5.m5.1d">×</annotation></semantics></math> for Canny Edge Detection (326ms on Cortex-A9),
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS3.p3.6.m6.1"><semantics id="S5.SS3.p3.6.m6.1a"><mo id="S5.SS3.p3.6.m6.1.1" xref="S5.SS3.p3.6.m6.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.6.m6.1b"><csymbol cd="latexml" id="S5.SS3.p3.6.m6.1.1.cmml" xref="S5.SS3.p3.6.m6.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.6.m6.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.6.m6.1d">∼</annotation></semantics></math>10<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.7.m7.1"><semantics id="S5.SS3.p3.7.m7.1a"><mo id="S5.SS3.p3.7.m7.1.1" xref="S5.SS3.p3.7.m7.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.7.m7.1b"><times id="S5.SS3.p3.7.m7.1.1.cmml" xref="S5.SS3.p3.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.7.m7.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.7.m7.1d">×</annotation></semantics></math> for Depth Rendering (869ms on Cortex-A9),
and
39<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.8.m8.1"><semantics id="S5.SS3.p3.8.m8.1a"><mo id="S5.SS3.p3.8.m8.1.1" xref="S5.SS3.p3.8.m8.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.8.m8.1b"><times id="S5.SS3.p3.8.m8.1.1.cmml" xref="S5.SS3.p3.8.m8.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.8.m8.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.8.m8.1d">×</annotation></semantics></math> for Edge Matching (39m on Cortex-A9).
Compared to Nvidia’s Tegra K1 GPU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib43" title="">43</a>]</cite>,
Myriad X
provides 2<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.9.m9.1"><semantics id="S5.SS3.p3.9.m9.1a"><mo id="S5.SS3.p3.9.m9.1.1" xref="S5.SS3.p3.9.m9.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.9.m9.1b"><times id="S5.SS3.p3.9.m9.1.1.cmml" xref="S5.SS3.p3.9.m9.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.9.m9.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.9.m9.1d">×</annotation></semantics></math> worse latency
for Canny Edge Detection
(12ms on Tegra K1 for 1-MegaPixel images).
However,
in terms of performance-per-Watt,
Myriad X is 3<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p3.10.m10.1"><semantics id="S5.SS3.p3.10.m10.1a"><mo id="S5.SS3.p3.10.m10.1.1" xref="S5.SS3.p3.10.m10.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.10.m10.1b"><times id="S5.SS3.p3.10.m10.1.1.cmml" xref="S5.SS3.p3.10.m10.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.10.m10.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.10.m10.1d">×</annotation></semantics></math> better
than Tegra K1 consuming 10W.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Improvements by our CV implementations versus literature works</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T6.10">
<tr class="ltx_tr" id="S5.T6.10.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T6.10.11.1" style="padding:0.75pt 2.1pt;">
<span class="ltx_text" id="S5.T6.10.11.1.1"></span> <span class="ltx_text" id="S5.T6.10.11.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T6.10.11.1.2.1">
<span class="ltx_tr" id="S5.T6.10.11.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T6.10.11.1.2.1.1.1" style="padding:0.75pt 2.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.10.11.1.2.1.1.1.1">Design</span></span></span>
</span></span><span class="ltx_text" id="S5.T6.10.11.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.10.11.2" style="padding:0.75pt 2.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.10.11.2.1">Device</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.10.11.3" style="padding:0.75pt 2.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.10.11.3.1">Improvement</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.10.11.4" style="padding:0.75pt 2.1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.10.11.4.1">Ref.</span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.2.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T6.2.2.3" style="padding:0.75pt 2.1pt;">CV Functions</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.2.2.4" style="padding:0.75pt 2.1pt;">Myriad 2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.2.2.2" style="padding:0.75pt 2.1pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.1.1.1.m1.1"><semantics id="S5.T6.1.1.1.m1.1a"><mo id="S5.T6.1.1.1.m1.1.1" xref="S5.T6.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T6.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.1.1.1.m1.1d">∼</annotation></semantics></math>1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.2.2.2.m2.1"><semantics id="S5.T6.2.2.2.m2.1a"><mo id="S5.T6.2.2.2.m2.1.1" xref="S5.T6.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.m2.1b"><times id="S5.T6.2.2.2.m2.1.1.cmml" xref="S5.T6.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.2.2.2.m2.1d">×</annotation></semantics></math> speedup</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.2.2.5" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.4.4">
<td class="ltx_td ltx_align_left" id="S5.T6.4.4.3" style="padding:0.75pt 2.1pt;">CV Functions</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.4.4" style="padding:0.75pt 2.1pt;">LEON4</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.4.2" style="padding:0.75pt 2.1pt;">
<math alttext="\sim" class="ltx_Math" display="inline" id="S5.T6.3.3.1.m1.1"><semantics id="S5.T6.3.3.1.m1.1a"><mo id="S5.T6.3.3.1.m1.1.1" xref="S5.T6.3.3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.T6.3.3.1.m1.1b"><csymbol cd="latexml" id="S5.T6.3.3.1.m1.1.1.cmml" xref="S5.T6.3.3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.3.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S5.T6.3.3.1.m1.1d">∼</annotation></semantics></math>15–20<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.4.4.2.m2.1"><semantics id="S5.T6.4.4.2.m2.1a"><mo id="S5.T6.4.4.2.m2.1.1" xref="S5.T6.4.4.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.4.4.2.m2.1b"><times id="S5.T6.4.4.2.m2.1.1.cmml" xref="S5.T6.4.4.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.4.4.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.4.4.2.m2.1d">×</annotation></semantics></math> speedup</td>
<td class="ltx_td ltx_align_center" id="S5.T6.4.4.5" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib22" title="">22</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5">
<td class="ltx_td ltx_align_left" id="S5.T6.5.5.2" style="padding:0.75pt 2.1pt;">Edge Detection</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.3" style="padding:0.75pt 2.1pt;">ARM Cortex-A9</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.1" style="padding:0.75pt 2.1pt;">14<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.5.5.1.m1.1"><semantics id="S5.T6.5.5.1.m1.1a"><mo id="S5.T6.5.5.1.m1.1.1" xref="S5.T6.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.5.5.1.m1.1b"><times id="S5.T6.5.5.1.m1.1.1.cmml" xref="S5.T6.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.5.5.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.5.5.1.m1.1d">×</annotation></semantics></math> speedup</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.4" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.6.6">
<td class="ltx_td ltx_align_left" id="S5.T6.6.6.2" style="padding:0.75pt 2.1pt;">Depth Rendering</td>
<td class="ltx_td ltx_align_center" id="S5.T6.6.6.3" style="padding:0.75pt 2.1pt;">ARM Cortex-A9</td>
<td class="ltx_td ltx_align_center" id="S5.T6.6.6.1" style="padding:0.75pt 2.1pt;">10<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.6.6.1.m1.1"><semantics id="S5.T6.6.6.1.m1.1a"><mo id="S5.T6.6.6.1.m1.1.1" xref="S5.T6.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.6.6.1.m1.1b"><times id="S5.T6.6.6.1.m1.1.1.cmml" xref="S5.T6.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.6.6.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.6.6.1.m1.1d">×</annotation></semantics></math> speedup</td>
<td class="ltx_td ltx_align_center" id="S5.T6.6.6.4" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.7.7">
<td class="ltx_td ltx_align_left" id="S5.T6.7.7.2" style="padding:0.75pt 2.1pt;">Edge Matching</td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.7.3" style="padding:0.75pt 2.1pt;">ARM Cortex-A9</td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.7.1" style="padding:0.75pt 2.1pt;">39<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.7.7.1.m1.1"><semantics id="S5.T6.7.7.1.m1.1a"><mo id="S5.T6.7.7.1.m1.1.1" xref="S5.T6.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.7.7.1.m1.1b"><times id="S5.T6.7.7.1.m1.1.1.cmml" xref="S5.T6.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.7.7.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.7.7.1.m1.1d">×</annotation></semantics></math> speedup</td>
<td class="ltx_td ltx_align_center" id="S5.T6.7.7.4" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.8.8">
<td class="ltx_td ltx_align_left" id="S5.T6.8.8.2" style="padding:0.75pt 2.1pt;">Edge Detection</td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.8.3" style="padding:0.75pt 2.1pt;">Tegra K1</td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.8.1" style="padding:0.75pt 2.1pt;">3<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.8.8.1.m1.1"><semantics id="S5.T6.8.8.1.m1.1a"><mo id="S5.T6.8.8.1.m1.1.1" xref="S5.T6.8.8.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.8.8.1.m1.1b"><times id="S5.T6.8.8.1.m1.1.1.cmml" xref="S5.T6.8.8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.8.8.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.8.8.1.m1.1d">×</annotation></semantics></math> performance-per-Watt</td>
<td class="ltx_td ltx_align_center" id="S5.T6.8.8.4" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib43" title="">43</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.9.9">
<td class="ltx_td ltx_align_left" id="S5.T6.9.9.2" style="padding:0.75pt 2.1pt;">CV Pipeline</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.9.3" style="padding:0.75pt 2.1pt;">Zynq-7000</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.9.1" style="padding:0.75pt 2.1pt;">3.5–4<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.9.9.1.m1.1"><semantics id="S5.T6.9.9.1.m1.1a"><mo id="S5.T6.9.9.1.m1.1.1" xref="S5.T6.9.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.9.9.1.m1.1b"><times id="S5.T6.9.9.1.m1.1.1.cmml" xref="S5.T6.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.9.9.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.9.9.1.m1.1d">×</annotation></semantics></math> better power</td>
<td class="ltx_td ltx_align_center" id="S5.T6.9.9.4" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite></td>
</tr>
<tr class="ltx_tr" id="S5.T6.10.10">
<td class="ltx_td ltx_align_left ltx_border_b" id="S5.T6.10.10.2" style="padding:0.75pt 2.1pt;">CV Pipeline</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.10.10.3" style="padding:0.75pt 2.1pt;">Zynq-7000</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.10.10.1" style="padding:0.75pt 2.1pt;">1.4<math alttext="\times" class="ltx_Math" display="inline" id="S5.T6.10.10.1.m1.1"><semantics id="S5.T6.10.10.1.m1.1a"><mo id="S5.T6.10.10.1.m1.1.1" xref="S5.T6.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.10.10.1.m1.1b"><times id="S5.T6.10.10.1.m1.1.1.cmml" xref="S5.T6.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.10.10.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.T6.10.10.1.m1.1d">×</annotation></semantics></math> performance-per-Watt</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T6.10.10.4" style="padding:0.75pt 2.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.2">Finally,
we compare our CV implementation
on Myriad X
to that on the programmable logic of Zynq-7000 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite>.
The results show
that Myriad X trades off speed for power,
i.e.,
it is 2.5–3<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p4.1.m1.1"><semantics id="S5.SS3.p4.1.m1.1a"><mo id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><times id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.1.m1.1d">×</annotation></semantics></math> slower than the FPGA
(considering the entire CV pipeline),
however,
it is 3.5–4<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p4.2.m2.1"><semantics id="S5.SS3.p4.2.m2.1a"><mo id="S5.SS3.p4.2.m2.1.1" xref="S5.SS3.p4.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.2.m2.1b"><times id="S5.SS3.p4.2.m2.1.1.cmml" xref="S5.SS3.p4.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.2.m2.1d">×</annotation></semantics></math> better
in terms of mean power consumption.
Furthermore,
it exhibits stable power consumption (2W)
compared to the FPGA, which has a variation
between 2W and 9W.
Besides better power
and performance per Watt,
the Myriad X provides
additional benefits versus the FPGA.
First,
the large DDR memory of Myriad X
can facilitate in-flight programmability in space avionics,
i.e., store different algorithms/applications that can be seamlessly programmed.
On the other hand,
the FPGA requires the development of
dynamic re-configuration techniques,
which also add timing penalties.
Second, to support AI acceleration
and fast DNN deployment on
Zynq,
the developer has to build Xilinx’s Deep Learning Processor Unit (DPU).
Therefore,
considering the resources required for the DPU,
a device like Zynq-7000
is stressed
to implement the entire system
(UrsoNet DNN + CV pipeline),
as the CV kernel already
utilizes increased resources,
i.e., 36% LUTs, 48% DSPs, and 77% RAMBs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.12939v1#bib.bib14" title="">14</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The paper
showed that heterogeneous embedded SoCs
integrating diverse processors
(general-purpose, vector, neural)
can provide promising AI/CV solutions
in challenging problems for space,
such as pose estimation in
lost-in-space and satellite tracking scenarios.
We combined low-level optimizations,
evaluated the capabilities of Myriad X,
and quantified the total costs of
each algorithm in the targeted AI/CV system.
The results showed that the Myriad X
VPU
directly competes with other state-of-the-art processors,
widely considered for space applications,
offering promising throughput
and significantly lower power consumption.
Our future work includes
improving the cooperation between
the AI and CV pipelines by
customizing on certain datasets/sequences
and fine-tuning the high-level SW mechanism
to switch between pipelines in real time.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The authors would like to thank
M. Lourakis &amp; X. Zabulis
for providing the initial software of the CV pipeline,
and
P. Proença &amp; Y. Gao
for providing the UrsoNet code in GitHub.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. Mittal, J. S. Vetter, A survey of CPU-GPU heterogeneous computing
techniques, ACM Computing Surveys 47 (4) (2015) 1–35.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1145/2788396" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1145/2788396</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. Barry, C. Brick, F. Connor, D. Donohoe, D. Moloney, R. Richmond,
M. O’Riordan, V. Toma, Always-on vision processing unit for mobile
applications, IEEE Micro 35 (2) (2015) 56–66.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/MM.2015.10" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/MM.2015.10</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
D. Moloney, B. Barry, R. Richmond, F. Connor, C. Brick, D. Donohoe, Myriad 2:
Eye of the computational vision storm, in: IEEE Hot Chips Symposium (HCS),
2014, pp. 1–18.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/HOTCHIPS.2014.7478823" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/HOTCHIPS.2014.7478823</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
E. Petrongonas, V. Leon, G. Lentaris, D. Soudris, ParalOS: A scheduling &amp;
memory management framework for heterogeneous VPUs, in: Euromicro
Conference on Digital System Design (DSD), 2021, pp. 221–228.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/DSD53832.2021.00043" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/DSD53832.2021.00043</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
P. F. Proença, Y. Gao, Deep learning for spacecraft pose estimation from
photorealistic rendering, in: IEEE International Conference on Robotics and
Automation (ICRA), 2020, pp. 6007–6013.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/ICRA40945.2020.9197244" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ICRA40945.2020.9197244</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. Lourakis, X. Zabulis, Model-based visual tracking of orbiting satellites
using edges, in: IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS), 2017, pp. 3791–3796.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/IROS.2017.8206228" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/IROS.2017.8206228</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
P. Carcagni, M. Leo, P. Spagnolo, P. L. Mazzeo, C. Distante, A lightweight
model for satellite pose estimation, in: International Conference on Image
Analysis and Processing (ICIAP), 2022, p. 3–14.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1007/978-3-031-06427-2_1" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1007/978-3-031-06427-2\_1</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Hu, S. Speierer, W. Jakob, P. Fua, M. Salzmann, Wide-depth-range 6D object
pose estimation in space, in: IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), 2021, pp. 15865–15874.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/CVPR46437.2021.01561" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/CVPR46437.2021.01561</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A. D. George, C. M. Wilson, Onboard processing with hybrid and reconfigurable
computing on small satellites, Proceedings of the IEEE 106 (3) (2018)
458–470.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/JPROC.2018.2802438" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JPROC.2018.2802438</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Crespo, A. Alonso, M. Marcos, J. A. de la Puente, P. Balbastre, Mixed
criticality in control systems, IFAC Proceedings Volumes 47 (3) (2014)
12261–12271.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.3182/20140824-6-ZA-1003.02004" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3182/20140824-6-ZA-1003.02004</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Esposito, M. Violante, System-level architecture for mixed criticality
applications on MPSoC: A space application, in: IEEE International
Workshop on Metrology for AeroSpace (MetroAeroSpace), 2017, pp. 479–483.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/MetroAeroSpace.2017.7999621" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/MetroAeroSpace.2017.7999621</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
V. Leon, G. Lentaris, D. Soudris, S. Vellas, M. Bernou, Towards employing
FPGA and ASIP acceleration to enable onboard AI/ML in space
applications, in: IFIP/IEEE International Conference on Very Large Scale
Integration (VLSI-SoC), 2022, pp. 1–4.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/VLSI-SoC54400.2022.9939566" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/VLSI-SoC54400.2022.9939566</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
A. Pérez, A. Rodríguez, A. Otero, D. González-Arjona, A. Jiménez-Peralo,
M. A. Verdugo, E. De La Torre, Run-time reconfigurable MPSoC-based
on-board processor for vision-based space navigation, IEEE Access 8 (2020)
59891–59905.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/ACCESS.2020.2983308" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ACCESS.2020.2983308</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G. Lentaris, I. Stratakos, I. Stamoulias, D. Soudris, M. Lourakis, X. Zabulis,
High-performance vision-based navigation on SoC FPGA for spacecraft
proximity operations, IEEE Transactions on Circuits and Systems for Video
Technology 30 (4) (2020) 1188–1202.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/TCSVT.2019.2900802" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TCSVT.2019.2900802</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X. Iturbe, D. Keymeulen, E. Ozer, P. Yiu, D. Berisford, K. Hand, R. Carlson, An
integrated SoC for science data processing in next-generation space
flight instruments avionics, in: IFIP/IEEE International Conference on Very
Large Scale Integration (VLSI-SoC), 2015, pp. 134–141.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/VLSI-SoC.2015.7314405" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/VLSI-SoC.2015.7314405</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
D. Rudolph, C. M. Wilson, J. Stewart, P. Gauvin, A. D. George, H. Lam, G. Crum,
M. J. Wirthlin, A. Wilson, A. Stoddard, CSP: A multifaceted hybrid
architecture for space computing, in: AIAA/USU Conference on Small
Satellites, 2014, pp. 1–7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
L. Kosmidis, I. Rodriguez, Álvaro Jover, S. Alcaide, J. Lachaize, J. Abella,
O. Notebaert, F. J. Cazorla, D. Steenari, GPU4S: Embedded GPUs in space -
latest project updates, Elsevier Microprocessors and Microsystems 77 (2020)
1–10.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1016/j.micpro.2020.103143" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1016/j.micpro.2020.103143</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Benito, M. M. Trompouki, L. Kosmidis, J. D. Garcia, S. Carretero, K. Wenger,
Comparison of GPU computing methodologies for safety-critical systems: An
avionics case study, in: Design, Automation &amp; Test in Europe (DATE), 2021,
pp. 717–718.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.23919/DATE51398.2021.9474060" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.23919/DATE51398.2021.9474060</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
C. Adams, A. Spain, J. Parker, M. Hevert, J. Roach, D. Cotten, Towards an
integrated GPU accelerated SoC as a flight computer for small
satellites, in: IEEE Aerospace Conference, 2019, pp. 1–7.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/AERO.2019.8741765" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/AERO.2019.8741765</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
F. C. Bruhn, N. Tsog, F. Kunkel, O. Flordal, I. Troxel, Enabling radiation
tolerant heterogeneous GPU-based onboard data processing in space, CEAS
Space Journal 12 (2020) 551–564.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1007/s12567-020-00321-9" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1007/s12567-020-00321-9</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A. Jover-Alvarez, I. Rodriguez, L. Kosmidis, D. Steenari, Space compression
algorithms acceleration on embedded multi-core and GPU platforms, ACM
SIGAda Ada Letters 42 (1) (2022) 100–104.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1145/3577949.3577969" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1145/3577949.3577969</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
V. Leon, G. Lentaris, E. Petrongonas, D. Soudris, G. Furano, A. Tavoularis,
D. Moloney, Improving performance-power-programmability in space avionics
with edge devices: VBN on Myriad2 SoC, ACM Transactions on Embedded
Computing Systems 20 (3) (2021) 1–23.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1145/3440885" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1145/3440885</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
G. Giuffrida, L. Fanucci, G. Meoni, M. Batič, L. Buckley, A. Dunne,
C. Van Dijk, M. Esposito, J. Hefele, N. Vercruyssen, G. Furano, M. Pastena,
J. Aschbacher, The <math alttext="\mathrm{\Phi}" class="ltx_Math" display="inline" id="bib.bib23.1.m1.1"><semantics id="bib.bib23.1.m1.1a"><mi id="bib.bib23.1.m1.1.1" mathvariant="normal" xref="bib.bib23.1.m1.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="bib.bib23.1.m1.1b"><ci id="bib.bib23.1.m1.1.1.cmml" xref="bib.bib23.1.m1.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib23.1.m1.1c">\mathrm{\Phi}</annotation><annotation encoding="application/x-llamapun" id="bib.bib23.1.m1.1d">roman_Φ</annotation></semantics></math>-Sat-1 mission: the first on-board deep
neural network demonstrator for satellite earth observation, IEEE
Transactions on Geoscience and Remote Sensing 60 (2022) 1–14.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/TGRS.2021.3125567" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TGRS.2021.3125567</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J. E. Navarro, A. Samuelsson, H. Gingsjö, J. Barendt, A. Dunne, L. Buckley,
D. Reisis, A. Kyriakos, E.-A. Papatheofanous, C. Bezaitis, P. Matthijs, J. P.
Ramos, D. Steenari, High-performance compute board – a fault-tolerant module
for on-board vision processing, in: European Workshop on On-Board Data
Processing (OBDP), 2021, pp. 1–7.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.5281/zenodo.5521624" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.5281/zenodo.5521624</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
V. Leon, C. Bezaitis, G. Lentaris, D. Soudris, D. Reisis, E.-A. Papatheofanous,
A. Kyriakos, A. Dunne, A. Samuelsson, D. Steenari, FPGA &amp; VPU
co-processing in space applications: Development and testing with DSP/AI
benchmarks, in: IEEE International Conference on Electronics, Circuits and
Systems (ICECS), 2021, pp. 1–5.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/ICECS53924.2021.9665462" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ICECS53924.2021.9665462</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
G. Furano, G. Meoni, A. Dunne, D. Moloney, V. Ferlet-Cavrois, A. Tavoularis,
J. Byrne, L. Buckley, M. Psarakis, K.-O. Voss, L. Fanucci, Towards the use of
Artificial Intelligence on the edge in space systems: Challenges and
opportunities, IEEE Aerospace and Electronic Systems Magazine 35 (12) (2020)
44–56.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/MAES.2020.3008468" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/MAES.2020.3008468</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
V. Leon, I. Stamoulias, G. Lentaris, D. Soudris, D. Gonzalez-Arjona,
R. Domingo, D. M. Codinachs, I. Conway, Development and testing on the
European space-grade BRAVE FPGAs: Evaluation of NG-Large using
high-performance dsp benchmarks, IEEE Access 9 (2021) 131877–131892.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/ACCESS.2021.3114502" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ACCESS.2021.3114502</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
G. Lentaris, K. Maragos, I. Stratakos, L. Papadopoulos, O. Papanikolaou,
D. Soudris, M. Lourakis, X. Zabulis, D. Gonzalez-Arjona, G. Furano,
High-performance embedded computing in space: Evaluation of platforms for
vision-based navigation, Journal of Aerospace Information Systems 15 (4)
(2018) 178–192.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.2514/1.I010555" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.2514/1.I010555</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
M. Lofqvist, J. Cano, Accelerating deep learning applications in space, in:
AIAA/USU Conference on Small Satellites, 2020, pp. 1–19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
S. Agarwal, E. Hervas-Martin, J. Byrne, A. Dunne, J. Luis Espinosa-Aranda,
D. Rijlaarsdam, An evaluation of low-cost vision processors for efficient
star identification, MDPI Sensors 20 (21) (2020) 1–14.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.3390/s20216250" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.3390/s20216250</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
L. Buckley, A. Dunne, G. Furano, M. Tali, Radiation test and in orbit
performance of MPSoC AI accelerator, in: IEEE Aerospace Conference
(AERO), 2022, pp. 1–9.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/AERO53065.2022.9843440" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/AERO53065.2022.9843440</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
A. Dunne, UB0100 AI &amp; CV compute engine, in: ESA Workshop on Avionics, Data,
Control and Software Systems (ADCSS), 2020, pp. 1–17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
V. Leon, E. A. Papatheofanous, G. Lentaris, C. Bezaitis, N. Mastorakis,
G. Bampilis, D. Reisis, D. Soudris, Combining fault tolerance techniques and
COTS SoC accelerators for payload processing in space, in: IFIP/IEEE
International Conference on Very Large Scale Integration (VLSI-SoC), 2022,
pp. 1–6.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/VLSI-SoC54400.2022.9939621" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/VLSI-SoC54400.2022.9939621</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
E. Dunkel, J. L. Espinosa-Aranda, J. Romero-Canas, L. Buckley, Z. Towfic,
F. Mirza, J. Swope, D. Russell, J. Sauvaeau, D. Sheldon, S. Chien,
M. Fernandez, C. Knox, K. Wagstaff, S. Lu, M. Denbina, D. Atha, M. Swan,
M. Ono, Benchmarking machine learning on the Myriad X processor onboard
the ISS, in: International Space Station Research and Development
Conference, 2021, pp. 1–24.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
A. Xygkis, L. Papadopoulos, D. Moloney, D. Soudris, S. Yous, Efficient
Winograd-based convolution kernel implementation on edge devices, in:
ACM/ESDA/IEEE Design Automation Conference (DAC), 2018, pp. 1–6.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1145/3195970.3196041" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1145/3195970.3196041</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
F. Tsimpourlas, L. Papadopoulos, A. Bartsokas, D. Soudris, A design space
exploration framework for convolutional neural networks implemented on edge
devices, IEEE Transactions on Computer-Aided Design of Integrated Circuits
and Systems 37 (11) (2018) 2212–2221.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/TCAD.2018.2857280" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TCAD.2018.2857280</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
X. Xu, J. Amaro, S. Caulfield, A. Forembski, G. Falcao, D. Moloney,
Convolutional neural network on neural compute stick for voxelized
point-clouds classification, in: International Congress on Image and Signal
Processing, BioMedical Engineering and Informatics (CISP-BMEI), 2017, pp.
1–7.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/CISP-BMEI.2017.8302078" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/CISP-BMEI.2017.8302078</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
J. Hochstetler, R. Padidela, Q. Chen, Q. Yang, S. Fu, Embedded deep
learning for vehicular edge computing, in: IEEE/ACM Symposium on Edge
Computing (SEC), 2018, pp. 341–343.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/SEC.2018.00038" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/SEC.2018.00038</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
C. Marantos, N. Karavalakis, V. Leon, V. Tsoutsouras, K. Pekmestzi,
D. Soudris, Efficient support vector machines implementation on
Intel/Movidius Myriad 2, in: International Conference on Modern
Circuits and Systems Technologies (MOCAST), 2018, pp. 1–4.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/MOCAST.2018.8376630" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/MOCAST.2018.8376630</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
L. Puglia, M. Ionică, G. Raiconi, D. Moloney, Passive dense stereo vision on
the Myriad2 VPU, in: IEEE Hot Chips Symposium (HCS), 2016, pp. 1–5.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/HOTCHIPS.2016.7936240" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/HOTCHIPS.2016.7936240</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Intel Corporation,
<a class="ltx_ref ltx_href" href="https://docs.openvino.ai/2021.2/index.html" title="">OpenVINO Toolkit
Overview</a> (2021).

<br class="ltx_break"/>URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://docs.openvino.ai/2021.2/index.html" title="">https://docs.openvino.ai/2021.2/index.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
J. Canny, A computational approach to edge detection, IEEE Transactions on
Pattern Analysis and Machine Intelligence PAMI-8 (6) (1986) 679–698.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/TPAMI.1986.4767851" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TPAMI.1986.4767851</span></a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y. Huang, Y. Bai, R. Li, X. Huang, Research of Canny edge detection algorithm
on embedded CPU and GPU heterogeneous systems, in: International
Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery
(ICNC-FSKD), 2016, pp. 647–651.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://dx.doi.org/10.1109/FSKD.2016.7603250" title=""><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/FSKD.2016.7603250</span></a>.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 19 17:42:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
