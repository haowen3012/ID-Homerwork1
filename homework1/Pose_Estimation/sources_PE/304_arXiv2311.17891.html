<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Graph-Based Approach for Category-Agnostic Pose Estimation</title>
<!--Generated on Thu Jul 11 12:49:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Class-Agnostic Pose Estimation,  Few-Shot Learning" lang="en" name="keywords"/>
<base href="/html/2311.17891v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S1" title="In A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S2" title="In A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S2.SS1" title="In 2 Related Works ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Detection Transformer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S2.SS2" title="In 2 Related Works ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Category-Agnostic Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S2.SS3" title="In 2 Related Works ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Graph Neural Networks in Computer Vision</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3" title="In A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.SS1" title="In 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>A Graph-Based Approach</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.SS2" title="In 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Training Scheme</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.SS3" title="In 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Encoding Structure: Positional Encoding VS Graph Network</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4" title="In A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS0.SSS1" title="In 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.1 </span>CapeFormer-T.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS1" title="In 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS2" title="In 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Qualitative Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS3" title="In 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Quantitative Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS4" title="In 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS4.SSS1" title="In 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.1 </span>Out-of-Distribution Performance.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS4.SSS2" title="In 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.2 </span>The Contribution of Graph Structure.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS4.SSS3" title="In 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.3 </span>Masking Support/Query Images.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.SS4.SSS4" title="In 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.4 </span>Cross-Category Correspondence.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S5" title="In A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S5.SS0.SSS1" title="In 5 Conclusion ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.0.1 </span>Acknowledgement.</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Tel-Aviv University 
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>orhirschorn@mail.tau.ac.il</span></span></span> ¬†and¬† <span class="ltx_note ltx_role_email" id="id1.2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>avidan@eng.tau.ac.il</span></span></span>
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://orhir.github.io/pose-anything/" title="">https://orhir.github.io/pose-anything/</a></span></span></span>
<h1 class="ltx_title ltx_title_document">A Graph-Based Approach for Category-Agnostic Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Or Hirschorn 
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shai Avidan
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Traditional 2D pose estimation models are limited by their category-specific design, making them suitable only for predefined object categories. This restriction becomes particularly challenging when dealing with novel objects due to the lack of relevant training data.
To address this limitation, category-agnostic pose estimation (CAPE) was introduced. CAPE aims to enable keypoint localization for arbitrary object categories using a few-shot single model, requiring minimal support images with annotated keypoints.</p>
<p class="ltx_p" id="id2.id2">We present a significant departure from conventional CAPE techniques, which treat keypoints as isolated entities, by treating the input pose data as a graph. We leverage the inherent geometrical relations between keypoints through a graph-based network to break symmetry, preserve structure, and better handle occlusions.
We validate our approach on the MP-100 benchmark, a comprehensive dataset comprising over 20,000 images spanning over 100 categories. Our solution boosts performance by 0.98% under a 1-shot setting, achieving a new state-of-the-art for CAPE. Additionally, we enhance the dataset with skeleton annotations.
Our code and data are publicly available.

</p>
<div class="ltx_logical-block" id="id3.id3">
<figure class="ltx_figure ltx_align_center" id="S0.F1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S0.F1.10">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S0.F1.2.2">
<td class="ltx_td ltx_nopad_l ltx_align_center" colspan="2" id="S0.F1.1.1.1" style="padding:-1pt 0.8pt;">
<span class="ltx_text ltx_font_bold" id="S0.F1.1.1.1.1" style="color:#BF0040;">Support</span> <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S0.F1.1.1.1.m1.1"><semantics id="S0.F1.1.1.1.m1.1a"><mo id="S0.F1.1.1.1.m1.1.1" stretchy="false" xref="S0.F1.1.1.1.m1.1.1.cmml">‚Üí</mo><annotation-xml encoding="MathML-Content" id="S0.F1.1.1.1.m1.1b"><ci id="S0.F1.1.1.1.m1.1.1.cmml" xref="S0.F1.1.1.1.m1.1.1">‚Üí</ci></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S0.F1.1.1.1.m1.1d">‚Üí</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S0.F1.1.1.1.2" style="color:#00E000;">Query</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" colspan="2" id="S0.F1.2.2.2" style="padding:-1pt 0.8pt;">
<span class="ltx_text ltx_font_bold" id="S0.F1.2.2.2.1" style="color:#BF0040;">Support</span> <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S0.F1.2.2.2.m1.1"><semantics id="S0.F1.2.2.2.m1.1a"><mo id="S0.F1.2.2.2.m1.1.1" stretchy="false" xref="S0.F1.2.2.2.m1.1.1.cmml">‚Üí</mo><annotation-xml encoding="MathML-Content" id="S0.F1.2.2.2.m1.1b"><ci id="S0.F1.2.2.2.m1.1.1.cmml" xref="S0.F1.2.2.2.m1.1.1">‚Üí</ci></annotation-xml><annotation encoding="application/x-tex" id="S0.F1.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S0.F1.2.2.2.m1.1d">‚Üí</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S0.F1.2.2.2.2" style="color:#00E000;">Query</span>
</td>
</tr>
<tr class="ltx_tr" id="S0.F1.6.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.3.3.1" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.3.3.1.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.3.3.1.1.g1" src="extracted/5725098/Figures/1_teaser/29_0.png" width="132"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.4.4.2" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.4.4.2.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.4.4.2.1.g1" src="extracted/5725098/Figures/1_teaser/29_1.png" width="132"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.5.5.3" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.5.5.3.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.5.5.3.1.g1" src="extracted/5725098/Figures/1_teaser/59_0.png" width="132"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.6.6.4" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.6.6.4.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.6.6.4.1.g1" src="extracted/5725098/Figures/1_teaser/59_1.png" width="132"/></span></td>
</tr>
<tr class="ltx_tr" id="S0.F1.10.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.7.7.1" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.7.7.1.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.7.7.1.1.g1" src="extracted/5725098/Figures/1_teaser/24_0.png" width="132"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.8.8.2" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.8.8.2.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.8.8.2.1.g1" src="extracted/5725098/Figures/1_teaser/24_1.png" width="132"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.9.9.3" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.9.9.3.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.9.9.3.1.g1" src="extracted/5725098/Figures/1_teaser/14_0.png" width="132"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S0.F1.10.10.4" style="padding:-1pt 0.8pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S0.F1.10.10.4.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="132" id="S0.F1.10.10.4.1.g1" src="extracted/5725098/Figures/1_teaser/14_1.png" width="132"/></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.14.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S0.F1.15.2" style="font-size:90%;">Given a support image and skeleton from any category (<span class="ltx_text" id="S0.F1.15.2.1" style="color:#BF0040;">purple</span>) our model localizes the skeleton on a query image (<span class="ltx_text" id="S0.F1.15.2.2" style="color:#00E000;">green</span>). Our graph-oriented method integrates structural information to improve keypoint localization.
</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Class-Agnostic Pose Estimation, Few-Shot Learning
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">2D pose estimation, also known as keypoint localization, has recently gained significant prominence in computer vision research, finding diverse applications in both academic and industrial domains. This task involves predicting specific semantic parts‚Äô locations within an object depicted in an image. Notably, it plays a crucial role in areas such as human pose estimation for video understanding or virtual reality, animal pose estimation in zoology, and vehicle pose estimation for autonomous driving.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, a fundamental limitation of conventional pose estimation models is their inherent category specificity. These models are typically designed to work exclusively within a predefined object category, restricting their use to the domain they were trained on. Consequently, their adaptability to real-world situations involving novel objects is impeded due to the absence of relevant training data.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address this challenge, category-agnostic pose estimation (CAPE) was proposed¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>. CAPE seeks to perform keypoint localization for arbitrary object categories, using a single model, by utilizing just one or a few support images with keypoint annotations, referred to as support keypoints.
This approach enables the generation of an object‚Äôs pose based on arbitrary keypoint definitions. Significantly, it substantially reduces the extensive costs associated with data collection, model training, and parameter tuning for each novel class. This paves the way for more versatile and adaptable applications in the field of pose estimation.
Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S0.F1" title="Figure 1 ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a> shows some results of our work.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">CAPE methods match support keypoints with their corresponding counterparts in the query image. The matching is done in latent space to facilitate the localization of keypoints.
Previous CAPE methods treat keypoints as individual, disconnected points. However, inherent geometrical relations between keypoints serve as a robust prior that can enhance the accuracy of keypoint localization by breaking symmetry and handling occlusions.
In contrast to these approaches, we recognize this significant geometrical structure and leverage it by treating the input keypoints as a graph.
Building upon this realization, we introduce GraphCape, a graph-based model, purposefully designed to capture and incorporate this crucial structural information. By doing so, we exploit the inherent relationships and dependencies between keypoints.
We explored various design choices, detailed in the supplementary, and ultimately chose to incorporate this prior into the model architecture.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We evaluate our method on the category-agnostic pose estimation benchmark MP-100¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>.
This dataset contains over <math alttext="20k" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml"><mn id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml">20</mn><mo id="S1.p5.1.m1.1.1.1" xref="S1.p5.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S1.p5.1.m1.1.1.3" xref="S1.p5.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1"><times id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1.1"></times><cn id="S1.p5.1.m1.1.1.2.cmml" type="integer" xref="S1.p5.1.m1.1.1.2">20</cn><ci id="S1.p5.1.m1.1.1.3.cmml" xref="S1.p5.1.m1.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">20k</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">20 italic_k</annotation></semantics></math> images from over 100 categories, including animals, vehicles, furniture, and clothes. It is composed of samples collected from existing category-specific pose estimation datasets. As some of the skeleton data was missing, we collected skeleton annotations from the original datasets and annotated several categories with missing skeleton definitions.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">It is important to note that the required additional keypoints connectivity input is shared among instances of the same category. Thus, the additional graph annotations required equals the number of categories. For example, when using our method for fine-tuning or inference on a specific category, the annotation process requires adding only one skeletal definition, which is quite simple.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">We compare our method to previous CAPE methods, as well as an updated version of the previous state-of-the-art which we call CapeFormer-T. Our method improves over this updated version, boosting performance under a 1-shot setting by 0.98%, achieving a new state-of-the-art.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">To summarize, we propose three key contributions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose to treat the input keypoints as connected nodes of a graph, instead of independent entities. Furthermore, to leverage the graph connectivity we introduce a new graph-based model design.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We provide an updated version of the MP-100 dataset with skeleton annotations for all categories.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We achieve state-of-the-art performance on the MP-100 benchmark.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Detection Transformer</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">A compelling connection emerges between detection problems, focused on bounding box estimation and localization, and pose estimation, which centers on keypoint localization. Recognizing this connection, we incorporate several advancements from object detection models into the latest category-agnostic pose estimation method¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite>, thus improving its performance.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The DEtection TRansformer (DETR)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib2" title="">2</a>]</cite> was the first transformer-based network for object detection, replacing conventional spatial anchors with learnable object queries in a transformer decoder. Its simplicity and universally applicable approach require minimal domain-specific knowledge, avoiding customized label assignments or non-maximum suppression. However, the original DETR design faced challenges such as slow convergence rates and reduced detection accuracy. In response, numerous studies<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib20" title="">20</a>]</cite> have emerged to improve the DETR paradigm. These works have led to the development of top-tier object detectors, leveraging innovations like the reintroduction of multi-scale features and local cross-attention computations¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib34" title="">34</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Category-Agnostic Pose Estimation</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The primary goal of pose estimation is to localize the semantic keypoints of objects or instances accurately. Traditionally, pose estimation methods have predominantly been tailored to specific categories, such as humans¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib41" title="">41</a>]</cite>, animals¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib43" title="">43</a>]</cite>, or vehicles¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib27" title="">27</a>]</cite>.
Existing research focused mainly on designing convolutional neural networks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib15" title="">15</a>]</cite> or transformer-based architectures¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib38" title="">38</a>]</cite>. However, these methods are limited to categories encountered during training.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">A relatively unexplored area is category-agnostic pose estimation (CAPE), introduced by Xu¬†<em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.1.1">et al</em>.<span class="ltx_text" id="S2.SS2.p2.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>. This approach predicts keypoints by comparing support keypoints with query images in the embedding space, handling unseen object categories during training. This shifts pose estimation into few-shot learning, which utilizes prototype, meta-learning, and fine-tuning.
ProtoNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib30" title="">30</a>]</cite> learns a prototype for each class in the support data and classifies query data based on the nearest prototype. MAML¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib9" title="">9</a>]</cite> is a meta-learning-based approach that finds optimal initialization weights for rapid generalization to novel tasks with minimal fine-tuning. Another few-shot approach is fine-tuning¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib25" title="">25</a>]</cite>, where the model is pre-trained on all base categories and fine-tuned on support images of novel categories during testing.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Specifically designed for CAPE, POMNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite> employs a transformer to encode query images and support keypoints, with a regression head predicting similarity directly from the concatenation of support keypoint and query image features.
CapeFormer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite> extends the matching paradigm to a two-stage framework, rectifying unreliable matching outcomes to enhance prediction precision.
We first update CapeFormer, enhancing their methodology. Then, we focus on the importance of geometrical structure, integrating it into our model design.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Graph Neural Networks in Computer Vision</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Originally designed for graph data like social networks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib11" title="">11</a>]</cite>, citation networks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib28" title="">28</a>]</cite>, and biochemical graphs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib32" title="">32</a>]</cite>, GCNs have become pivotal in computer vision tasks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib14" title="">14</a>]</cite>, finding applications in scene graph generation, point cloud classification, and action recognition.
Scene graph generation parses images into graphs representing objects and their relations, often combined with object detection¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib40" title="">40</a>]</cite>.
Point clouds from LiDAR scans are effectively classified and segmented using GCNs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib35" title="">35</a>]</cite>.
Additionally, GCNs process human joints‚Äô graphs for activity recognition¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib22" title="">22</a>]</cite>. Recent work even suggests using GNNs as backbone feature extractors for visual tasks, representing images as graphs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib12" title="">12</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Graph-driven models have also been proposed for 6D pose estimation to better infuse structure information¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib47" title="">47</a>]</cite>. They utilize orientation-aware autoencoders with 3D graph convolutions, which are robust to point shift and object size variations and construct k-NN graphs, extracting geometry-aware inter-modality correlations. Lian¬†<em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.1.1">et al</em>.<span class="ltx_text" id="S2.SS3.p2.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib18" title="">18</a>]</cite> adopts GNNs to model interactions among 3D keypoints, aiming for 2D correspondences in input images.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">Inspired by these approaches, we integrate GCNs into the decoder‚Äôs architecture to enhance semantic connections between keypoints and share information among structurally close ones.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="217" id="S3.F2.g1" src="x1.png" width="814"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.3.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F2.4.2" style="font-size:90%;">Architecture Overview.<span class="ltx_text ltx_font_medium" id="S3.F2.4.2.1"> Our approach utilizes a pre-trained backbone to extract image features, followed by a transformer encoder that refines these features through self-attention. A similarity proposal generator is employed alongside a graph transformer decoder, enhancing keypoint localization accuracy with a focus on graph-oriented decoding.</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In the following section, we describe our graph-based approach that takes advantage of the strong graph structure available in the data. The complete architecture of our method is illustrated in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.F2" title="Figure 2 ‚Ä£ 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>.
Our approach utilizes a pre-trained backbone to extract support keypoints and query image features, followed by a transformer encoder that refines these features through self-attention. A similarity proposal generator is employed for initial coordinates localization. Finally, a transformer decoder predicts the keypoints‚Äô locations. More details on the different components are in the supplementary.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>A Graph-Based Approach</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The core idea of our work is in treating the input keypoints as a graph, to take advantage of the geometrical structure encoded in the graph connectivity.
Our key insight is in recognizing that self-attention, a mechanism that helps models focus on relevant information, can be thought of as a GCN with an input-dependent learnable adjacency matrix. When we are dealing with pose estimation for a single category, this mechanism is sufficient for learning the relationships between keypoints and integrating a learned structure into the model.
However, for the new task of CAPE, where the model needs to work with object categories it has never seen before, it is beneficial to explicitly consider the semantic connections between keypoints.
As GNN promotes information sharing between connected keypoints, location data is shared among structurally connected keypoints, which are typically close. Thus, the graph design aids in structure preservation and occlusion handling.
Moreover, we believe that utilizing the graph structure during training helps in breaking feature symmetry, as it enforces similar features based on structure (e.g., right/left) rather than solely on semantics.
Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.F3" title="Figure 3 ‚Ä£ 3.1 A Graph-Based Approach ‚Ä£ 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates this hypothesis qualitatively. Notably, our graph-based method, despite being trained on multiple categories, exhibits similar attention patterns to models trained on single categories.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.F3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.F3.3.3">
<td class="ltx_td ltx_align_center" id="S3.F3.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S3.F3.1.1.1.g1" src="extracted/5725098/Figures/3_self_attn/base.png" width="138"/></td>
<td class="ltx_td ltx_align_center" id="S3.F3.2.2.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S3.F3.2.2.2.g1" src="extracted/5725098/Figures/3_self_attn/one_cat.png" width="138"/></td>
<td class="ltx_td ltx_align_center" id="S3.F3.3.3.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S3.F3.3.3.3.g1" src="extracted/5725098/Figures/3_self_attn/graph.png" width="138"/></td>
</tr>
<tr class="ltx_tr" id="S3.F3.3.4.1">
<td class="ltx_td ltx_align_center" id="S3.F3.3.4.1.1">Multi-Category</td>
<td class="ltx_td ltx_align_center" id="S3.F3.3.4.1.2">Single-Category</td>
<td class="ltx_td ltx_align_center" id="S3.F3.3.4.1.3">Multi-Category</td>
</tr>
<tr class="ltx_tr" id="S3.F3.3.5.2">
<td class="ltx_td ltx_align_center" id="S3.F3.3.5.2.1">Base Model</td>
<td class="ltx_td ltx_align_center" id="S3.F3.3.5.2.2">Base Model</td>
<td class="ltx_td ltx_align_center" id="S3.F3.3.5.2.3">Graph Model</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.6.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F3.7.2" style="font-size:90%;">Self-Attention Map Visualization<span class="ltx_text ltx_font_medium" id="S3.F3.7.2.1">. Comparing self-attention in decoders of three models: (a) CapeFormer-T trained on various object categories, (b) CapeFormer-T trained only on furniture objects, and (c) GraphCape trained on various object categories using a graph structure. Observe the edges between the legs and base of the chair. Notably, our graph-based method, despite being trained on multiple categories, exhibits similar attention patterns to models trained on single categories.
</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We implemented this prior into the transformer decoder. Specifically, our design is based on CapeFormer, changing the decoder‚Äôs feed-forward network from a simple MLP to a GCN-based module. To address the potential problem of excessive smoothing often observed in deep GCNs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib26" title="">26</a>]</cite>, which can lead to a reduction in the distinctiveness of node characteristics and consequently a decline in performance, we introduce a linear layer for each node following the GCN layer. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.F4" title="Figure 4 ‚Ä£ 3.1 A Graph-Based Approach ‚Ä£ 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates our new design.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="353" id="S3.F4.g1" src="x2.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.6.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F4.7.2" style="font-size:90%;">Graph FFN.<span class="ltx_text ltx_font_medium" id="S3.F4.7.2.1"> The Transformer decoder is based on the original CapeFormer design, changing the feed-forward network from a simple MLP to a graph-based network.
</span>(a)<span class="ltx_text ltx_font_medium" id="S3.F4.7.2.2"> A scheme of the transformer decoder which includes self-attention, cross-attention, and a feed-forward network. Self-attention encourages adaptive interactions among support keypoints, while cross-attention extracts localization information.
</span>(b)<span class="ltx_text ltx_font_medium" id="S3.F4.7.2.3"> Previous FFN consisted of an MLP with 2 layers.
</span>(c)<span class="ltx_text ltx_font_medium" id="S3.F4.7.2.4"> Our graph FFN includes a GCN layer and subsequent linear layers that enhance keypoint features and promote information exchange among known connected keypoints.
</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.6">The decoder has three main components: self-attention, cross-attention, and a feed-forward network.
Self-attention allows for adaptive interactions among support keypoints, transforming the input feature <math alttext="F_{s}^{l}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msubsup id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p3.1.m1.1.1.2.3" xref="S3.SS1.p3.1.m1.1.1.2.3.cmml">s</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">superscript</csymbol><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2">ùêπ</ci><ci id="S3.SS1.p3.1.m1.1.1.2.3.cmml" xref="S3.SS1.p3.1.m1.1.1.2.3">ùë†</ci></apply><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">F_{s}^{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> into <math alttext="F_{s}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><msubsup id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">s</mi><mo id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2">ùêπ</ci><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">ùë†</ci></apply><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">F_{s}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>.
Cross-attention augments support keypoints‚Äô representation by extracting localization information from query feature patches, enhancing attention at proposed locations. This involves concatenating the keypoint localization embedding with keypoint features. Cross-attention inputs are <math alttext="F_{s}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><msubsup id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2.2" xref="S3.SS1.p3.3.m3.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p3.3.m3.1.1.2.3" xref="S3.SS1.p3.3.m3.1.1.2.3.cmml">s</mi><mo id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2.2">ùêπ</ci><ci id="S3.SS1.p3.3.m3.1.1.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.2.3">ùë†</ci></apply><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">F_{s}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> (with the localization embedding) as queries, patch features <math alttext="F_{q}" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><msub id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml">F</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2">ùêπ</ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ùëû</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">F_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_F start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> (with positional encoding) as keys, and <math alttext="F_{q}" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">F</mi><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">ùêπ</ci><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">ùëû</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">F_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">italic_F start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> as values, resulting in transformed features <math alttext="F_{s}^{\prime\prime}" class="ltx_Math" display="inline" id="S3.SS1.p3.6.m6.1"><semantics id="S3.SS1.p3.6.m6.1a"><msubsup id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml"><mi id="S3.SS1.p3.6.m6.1.1.2.2" xref="S3.SS1.p3.6.m6.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p3.6.m6.1.1.2.3" xref="S3.SS1.p3.6.m6.1.1.2.3.cmml">s</mi><mo id="S3.SS1.p3.6.m6.1.1.3" xref="S3.SS1.p3.6.m6.1.1.3.cmml">‚Ä≤‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><apply id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.1.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">superscript</csymbol><apply id="S3.SS1.p3.6.m6.1.1.2.cmml" xref="S3.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.1.1.2.1.cmml" xref="S3.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p3.6.m6.1.1.2.2.cmml" xref="S3.SS1.p3.6.m6.1.1.2.2">ùêπ</ci><ci id="S3.SS1.p3.6.m6.1.1.2.3.cmml" xref="S3.SS1.p3.6.m6.1.1.2.3">ùë†</ci></apply><ci id="S3.SS1.p3.6.m6.1.1.3.cmml" xref="S3.SS1.p3.6.m6.1.1.3">‚Ä≤‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">F_{s}^{\prime\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.6.m6.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>.
Lastly, we employ a graph-based feed-forward network to process the output keypoint features as a graph. This layer further concentrates the keypoint features, facilitating the exchange of information between neighboring keypoints in the graph.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">The output value for an input <math alttext="F_{s}^{\prime\prime}\in\mathbb{R}^{C_{in}\times K}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mrow id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><msubsup id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2.2.2" xref="S3.SS1.p4.1.m1.1.1.2.2.2.cmml">F</mi><mi id="S3.SS1.p4.1.m1.1.1.2.2.3" xref="S3.SS1.p4.1.m1.1.1.2.2.3.cmml">s</mi><mo id="S3.SS1.p4.1.m1.1.1.2.3" xref="S3.SS1.p4.1.m1.1.1.2.3.cmml">‚Ä≤‚Ä≤</mo></msubsup><mo id="S3.SS1.p4.1.m1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.2" xref="S3.SS1.p4.1.m1.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS1.p4.1.m1.1.1.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.cmml"><msub id="S3.SS1.p4.1.m1.1.1.3.3.2" xref="S3.SS1.p4.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.3.2.2" xref="S3.SS1.p4.1.m1.1.1.3.3.2.2.cmml">C</mi><mrow id="S3.SS1.p4.1.m1.1.1.3.3.2.3" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.3.2.3.2" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.2.cmml">i</mi><mo id="S3.SS1.p4.1.m1.1.1.3.3.2.3.1" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.1.m1.1.1.3.3.2.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.3.cmml">n</mi></mrow></msub><mo id="S3.SS1.p4.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p4.1.m1.1.1.3.3.1.cmml">√ó</mo><mi id="S3.SS1.p4.1.m1.1.1.3.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><in id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1"></in><apply id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.2.1.cmml" xref="S3.SS1.p4.1.m1.1.1.2">superscript</csymbol><apply id="S3.SS1.p4.1.m1.1.1.2.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.2.2.1.cmml" xref="S3.SS1.p4.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.2.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2.2.2">ùêπ</ci><ci id="S3.SS1.p4.1.m1.1.1.2.2.3.cmml" xref="S3.SS1.p4.1.m1.1.1.2.2.3">ùë†</ci></apply><ci id="S3.SS1.p4.1.m1.1.1.2.3.cmml" xref="S3.SS1.p4.1.m1.1.1.2.3">‚Ä≤‚Ä≤</ci></apply><apply id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.2">‚Ñù</ci><apply id="S3.SS1.p4.1.m1.1.1.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3"><times id="S3.SS1.p4.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.1"></times><apply id="S3.SS1.p4.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2.2">ùê∂</ci><apply id="S3.SS1.p4.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3"><times id="S3.SS1.p4.1.m1.1.1.3.3.2.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.1"></times><ci id="S3.SS1.p4.1.m1.1.1.3.3.2.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.2">ùëñ</ci><ci id="S3.SS1.p4.1.m1.1.1.3.3.2.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.2.3.3">ùëõ</ci></apply></apply><ci id="S3.SS1.p4.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3.3">ùêæ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">F_{s}^{\prime\prime}\in\mathbb{R}^{C_{in}\times K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT ‚àà blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT √ó italic_K end_POSTSUPERSCRIPT</annotation></semantics></math> can be written as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\widetilde{F_{s}^{\prime\prime}}=\sigma_{act}(W_{adj}F_{s}^{\prime\prime}%
\widetilde{A}+W_{self}F_{s}^{\prime\prime})" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mover accent="true" id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><msubsup id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2.2" xref="S3.E1.m1.1.1.3.2.2.2.cmml">F</mi><mi id="S3.E1.m1.1.1.3.2.2.3" xref="S3.E1.m1.1.1.3.2.2.3.cmml">s</mi><mo id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml">‚Ä≤‚Ä≤</mo></msubsup><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">~</mo></mover><mo id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.3.2.cmml">œÉ</mi><mrow id="S3.E1.m1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.3.3.2.cmml">a</mi><mo id="S3.E1.m1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.3.3.3.cmml">c</mi><mo id="S3.E1.m1.1.1.1.3.3.1a" xref="S3.E1.m1.1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.3.3.4" xref="S3.E1.m1.1.1.1.3.3.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml">W</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.2.cmml">a</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.2.3.1" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.3.cmml">d</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.2.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.3.4" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.4.cmml">j</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.1.1.2.1" xref="S3.E1.m1.1.1.1.1.1.1.2.1.cmml">‚Å¢</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.2.cmml">F</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.3.cmml">s</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3.cmml">‚Ä≤‚Ä≤</mo></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.2.1a" xref="S3.E1.m1.1.1.1.1.1.1.2.1.cmml">‚Å¢</mo><mover accent="true" id="S3.E1.m1.1.1.1.1.1.1.2.4" xref="S3.E1.m1.1.1.1.1.1.1.2.4.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.4.2" xref="S3.E1.m1.1.1.1.1.1.1.2.4.2.cmml">A</mi><mo id="S3.E1.m1.1.1.1.1.1.1.2.4.1" xref="S3.E1.m1.1.1.1.1.1.1.2.4.1.cmml">~</mo></mover></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml">W</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.2.cmml">s</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.2.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.3.cmml">e</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.2.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.3.4" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.4.cmml">l</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.2.3.1b" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.3.5" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.5.cmml">f</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.1.cmml">‚Å¢</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.2.cmml">F</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.3.cmml">s</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml">‚Ä≤‚Ä≤</mo></msubsup></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"></eq><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><ci id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1">~</ci><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2">superscript</csymbol><apply id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.2.1.cmml" xref="S3.E1.m1.1.1.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2.2">ùêπ</ci><ci id="S3.E1.m1.1.1.3.2.2.3.cmml" xref="S3.E1.m1.1.1.3.2.2.3">ùë†</ci></apply><ci id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3">‚Ä≤‚Ä≤</ci></apply></apply><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><apply id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.3.2">ùúé</ci><apply id="S3.E1.m1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.3.3.2">ùëé</ci><ci id="S3.E1.m1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.3.3.3">ùëê</ci><ci id="S3.E1.m1.1.1.1.3.3.4.cmml" xref="S3.E1.m1.1.1.1.3.3.4">ùë°</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><times id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.1"></times><apply id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2">ùëä</ci><apply id="S3.E1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3"><times id="S3.E1.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.2">ùëé</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.3">ùëë</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.4">ùëó</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.2">ùêπ</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.2.3">ùë†</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3.3">‚Ä≤‚Ä≤</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.2.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.4"><ci id="S3.E1.m1.1.1.1.1.1.1.2.4.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.4.1">~</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.4.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.4.2">ùê¥</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.1"></times><apply id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2">ùëä</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3"><times id="S3.E1.m1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.2">ùë†</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.3">ùëí</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.4">ùëô</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.3.5.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.5">ùëì</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.2">ùêπ</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.3">ùë†</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3">‚Ä≤‚Ä≤</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\widetilde{F_{s}^{\prime\prime}}=\sigma_{act}(W_{adj}F_{s}^{\prime\prime}%
\widetilde{A}+W_{self}F_{s}^{\prime\prime})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">over~ start_ARG italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT end_ARG = italic_œÉ start_POSTSUBSCRIPT italic_a italic_c italic_t end_POSTSUBSCRIPT ( italic_W start_POSTSUBSCRIPT italic_a italic_d italic_j end_POSTSUBSCRIPT italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT over~ start_ARG italic_A end_ARG + italic_W start_POSTSUBSCRIPT italic_s italic_e italic_l italic_f end_POSTSUBSCRIPT italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="F_{s}^{l+1}=F_{s}^{\prime\prime}+W_{linear}\widetilde{F_{s}^{\prime\prime}}" class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msubsup id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2.2" xref="S3.E2.m1.1.1.2.2.2.cmml">F</mi><mi id="S3.E2.m1.1.1.2.2.3" xref="S3.E2.m1.1.1.2.2.3.cmml">s</mi><mrow id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.2.3.2" xref="S3.E2.m1.1.1.2.3.2.cmml">l</mi><mo id="S3.E2.m1.1.1.2.3.1" xref="S3.E2.m1.1.1.2.3.1.cmml">+</mo><mn id="S3.E2.m1.1.1.2.3.3" xref="S3.E2.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><msubsup id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.3.2.2.2.cmml">F</mi><mi id="S3.E2.m1.1.1.3.2.2.3" xref="S3.E2.m1.1.1.3.2.2.3.cmml">s</mi><mo id="S3.E2.m1.1.1.3.2.3" xref="S3.E2.m1.1.1.3.2.3.cmml">‚Ä≤‚Ä≤</mo></msubsup><mo id="S3.E2.m1.1.1.3.1" xref="S3.E2.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml"><msub id="S3.E2.m1.1.1.3.3.2" xref="S3.E2.m1.1.1.3.3.2.cmml"><mi id="S3.E2.m1.1.1.3.3.2.2" xref="S3.E2.m1.1.1.3.3.2.2.cmml">W</mi><mrow id="S3.E2.m1.1.1.3.3.2.3" xref="S3.E2.m1.1.1.3.3.2.3.cmml"><mi id="S3.E2.m1.1.1.3.3.2.3.2" xref="S3.E2.m1.1.1.3.3.2.3.2.cmml">l</mi><mo id="S3.E2.m1.1.1.3.3.2.3.1" xref="S3.E2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.3.3.2.3.3" xref="S3.E2.m1.1.1.3.3.2.3.3.cmml">i</mi><mo id="S3.E2.m1.1.1.3.3.2.3.1a" xref="S3.E2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.3.3.2.3.4" xref="S3.E2.m1.1.1.3.3.2.3.4.cmml">n</mi><mo id="S3.E2.m1.1.1.3.3.2.3.1b" xref="S3.E2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.3.3.2.3.5" xref="S3.E2.m1.1.1.3.3.2.3.5.cmml">e</mi><mo id="S3.E2.m1.1.1.3.3.2.3.1c" xref="S3.E2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.3.3.2.3.6" xref="S3.E2.m1.1.1.3.3.2.3.6.cmml">a</mi><mo id="S3.E2.m1.1.1.3.3.2.3.1d" xref="S3.E2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.1.1.3.3.2.3.7" xref="S3.E2.m1.1.1.3.3.2.3.7.cmml">r</mi></mrow></msub><mo id="S3.E2.m1.1.1.3.3.1" xref="S3.E2.m1.1.1.3.3.1.cmml">‚Å¢</mo><mover accent="true" id="S3.E2.m1.1.1.3.3.3" xref="S3.E2.m1.1.1.3.3.3.cmml"><msubsup id="S3.E2.m1.1.1.3.3.3.2" xref="S3.E2.m1.1.1.3.3.3.2.cmml"><mi id="S3.E2.m1.1.1.3.3.3.2.2.2" xref="S3.E2.m1.1.1.3.3.3.2.2.2.cmml">F</mi><mi id="S3.E2.m1.1.1.3.3.3.2.2.3" xref="S3.E2.m1.1.1.3.3.3.2.2.3.cmml">s</mi><mo id="S3.E2.m1.1.1.3.3.3.2.3" xref="S3.E2.m1.1.1.3.3.3.2.3.cmml">‚Ä≤‚Ä≤</mo></msubsup><mo id="S3.E2.m1.1.1.3.3.3.1" xref="S3.E2.m1.1.1.3.3.3.1.cmml">~</mo></mover></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"></eq><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.2.2.2">ùêπ</ci><ci id="S3.E2.m1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.2.2.3">ùë†</ci></apply><apply id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3"><plus id="S3.E2.m1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.2.3.1"></plus><ci id="S3.E2.m1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.2.3.2">ùëô</ci><cn id="S3.E2.m1.1.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><plus id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3.1"></plus><apply id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.3.2">superscript</csymbol><apply id="S3.E2.m1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2.2">ùêπ</ci><ci id="S3.E2.m1.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.3.2.2.3">ùë†</ci></apply><ci id="S3.E2.m1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.3.2.3">‚Ä≤‚Ä≤</ci></apply><apply id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3"><times id="S3.E2.m1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.1"></times><apply id="S3.E2.m1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.3.2.1.cmml" xref="S3.E2.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.1.1.3.3.2.2">ùëä</ci><apply id="S3.E2.m1.1.1.3.3.2.3.cmml" xref="S3.E2.m1.1.1.3.3.2.3"><times id="S3.E2.m1.1.1.3.3.2.3.1.cmml" xref="S3.E2.m1.1.1.3.3.2.3.1"></times><ci id="S3.E2.m1.1.1.3.3.2.3.2.cmml" xref="S3.E2.m1.1.1.3.3.2.3.2">ùëô</ci><ci id="S3.E2.m1.1.1.3.3.2.3.3.cmml" xref="S3.E2.m1.1.1.3.3.2.3.3">ùëñ</ci><ci id="S3.E2.m1.1.1.3.3.2.3.4.cmml" xref="S3.E2.m1.1.1.3.3.2.3.4">ùëõ</ci><ci id="S3.E2.m1.1.1.3.3.2.3.5.cmml" xref="S3.E2.m1.1.1.3.3.2.3.5">ùëí</ci><ci id="S3.E2.m1.1.1.3.3.2.3.6.cmml" xref="S3.E2.m1.1.1.3.3.2.3.6">ùëé</ci><ci id="S3.E2.m1.1.1.3.3.2.3.7.cmml" xref="S3.E2.m1.1.1.3.3.2.3.7">ùëü</ci></apply></apply><apply id="S3.E2.m1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3"><ci id="S3.E2.m1.1.1.3.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.3.1">~</ci><apply id="S3.E2.m1.1.1.3.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.3.3.2.1.cmml" xref="S3.E2.m1.1.1.3.3.3.2">superscript</csymbol><apply id="S3.E2.m1.1.1.3.3.3.2.2.cmml" xref="S3.E2.m1.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.3.3.2.2.1.cmml" xref="S3.E2.m1.1.1.3.3.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.3.3.2.2.2.cmml" xref="S3.E2.m1.1.1.3.3.3.2.2.2">ùêπ</ci><ci id="S3.E2.m1.1.1.3.3.3.2.2.3.cmml" xref="S3.E2.m1.1.1.3.3.3.2.2.3">ùë†</ci></apply><ci id="S3.E2.m1.1.1.3.3.3.2.3.cmml" xref="S3.E2.m1.1.1.3.3.3.2.3">‚Ä≤‚Ä≤</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">F_{s}^{l+1}=F_{s}^{\prime\prime}+W_{linear}\widetilde{F_{s}^{\prime\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT = italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT + italic_W start_POSTSUBSCRIPT italic_l italic_i italic_n italic_e italic_a italic_r end_POSTSUBSCRIPT over~ start_ARG italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ‚Ä≤ ‚Ä≤ end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p4.10">Where <math alttext="W_{i}\in\mathbb{R}^{C_{out}\times C_{in}}" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m1.1"><semantics id="S3.SS1.p4.2.m1.1a"><mrow id="S3.SS1.p4.2.m1.1.1" xref="S3.SS1.p4.2.m1.1.1.cmml"><msub id="S3.SS1.p4.2.m1.1.1.2" xref="S3.SS1.p4.2.m1.1.1.2.cmml"><mi id="S3.SS1.p4.2.m1.1.1.2.2" xref="S3.SS1.p4.2.m1.1.1.2.2.cmml">W</mi><mi id="S3.SS1.p4.2.m1.1.1.2.3" xref="S3.SS1.p4.2.m1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.p4.2.m1.1.1.1" xref="S3.SS1.p4.2.m1.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p4.2.m1.1.1.3" xref="S3.SS1.p4.2.m1.1.1.3.cmml"><mi id="S3.SS1.p4.2.m1.1.1.3.2" xref="S3.SS1.p4.2.m1.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS1.p4.2.m1.1.1.3.3" xref="S3.SS1.p4.2.m1.1.1.3.3.cmml"><msub id="S3.SS1.p4.2.m1.1.1.3.3.2" xref="S3.SS1.p4.2.m1.1.1.3.3.2.cmml"><mi id="S3.SS1.p4.2.m1.1.1.3.3.2.2" xref="S3.SS1.p4.2.m1.1.1.3.3.2.2.cmml">C</mi><mrow id="S3.SS1.p4.2.m1.1.1.3.3.2.3" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.cmml"><mi id="S3.SS1.p4.2.m1.1.1.3.3.2.3.2" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.2.cmml">o</mi><mo id="S3.SS1.p4.2.m1.1.1.3.3.2.3.1" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.2.m1.1.1.3.3.2.3.3" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.3.cmml">u</mi><mo id="S3.SS1.p4.2.m1.1.1.3.3.2.3.1a" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.2.m1.1.1.3.3.2.3.4" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS1.p4.2.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p4.2.m1.1.1.3.3.1.cmml">√ó</mo><msub id="S3.SS1.p4.2.m1.1.1.3.3.3" xref="S3.SS1.p4.2.m1.1.1.3.3.3.cmml"><mi id="S3.SS1.p4.2.m1.1.1.3.3.3.2" xref="S3.SS1.p4.2.m1.1.1.3.3.3.2.cmml">C</mi><mrow id="S3.SS1.p4.2.m1.1.1.3.3.3.3" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.cmml"><mi id="S3.SS1.p4.2.m1.1.1.3.3.3.3.2" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S3.SS1.p4.2.m1.1.1.3.3.3.3.1" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.2.m1.1.1.3.3.3.3.3" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.3.cmml">n</mi></mrow></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m1.1b"><apply id="S3.SS1.p4.2.m1.1.1.cmml" xref="S3.SS1.p4.2.m1.1.1"><in id="S3.SS1.p4.2.m1.1.1.1.cmml" xref="S3.SS1.p4.2.m1.1.1.1"></in><apply id="S3.SS1.p4.2.m1.1.1.2.cmml" xref="S3.SS1.p4.2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m1.1.1.2.1.cmml" xref="S3.SS1.p4.2.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.2.m1.1.1.2.2.cmml" xref="S3.SS1.p4.2.m1.1.1.2.2">ùëä</ci><ci id="S3.SS1.p4.2.m1.1.1.2.3.cmml" xref="S3.SS1.p4.2.m1.1.1.2.3">ùëñ</ci></apply><apply id="S3.SS1.p4.2.m1.1.1.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m1.1.1.3.1.cmml" xref="S3.SS1.p4.2.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.2.m1.1.1.3.2.cmml" xref="S3.SS1.p4.2.m1.1.1.3.2">‚Ñù</ci><apply id="S3.SS1.p4.2.m1.1.1.3.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3"><times id="S3.SS1.p4.2.m1.1.1.3.3.1.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.1"></times><apply id="S3.SS1.p4.2.m1.1.1.3.3.2.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m1.1.1.3.3.2.1.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p4.2.m1.1.1.3.3.2.2.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2.2">ùê∂</ci><apply id="S3.SS1.p4.2.m1.1.1.3.3.2.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3"><times id="S3.SS1.p4.2.m1.1.1.3.3.2.3.1.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.1"></times><ci id="S3.SS1.p4.2.m1.1.1.3.3.2.3.2.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.2">ùëú</ci><ci id="S3.SS1.p4.2.m1.1.1.3.3.2.3.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.3">ùë¢</ci><ci id="S3.SS1.p4.2.m1.1.1.3.3.2.3.4.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.2.3.4">ùë°</ci></apply></apply><apply id="S3.SS1.p4.2.m1.1.1.3.3.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m1.1.1.3.3.3.1.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p4.2.m1.1.1.3.3.3.2.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3.2">ùê∂</ci><apply id="S3.SS1.p4.2.m1.1.1.3.3.3.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3"><times id="S3.SS1.p4.2.m1.1.1.3.3.3.3.1.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.1"></times><ci id="S3.SS1.p4.2.m1.1.1.3.3.3.3.2.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.2">ùëñ</ci><ci id="S3.SS1.p4.2.m1.1.1.3.3.3.3.3.cmml" xref="S3.SS1.p4.2.m1.1.1.3.3.3.3.3">ùëõ</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m1.1c">W_{i}\in\mathbb{R}^{C_{out}\times C_{in}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m1.1d">italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚àà blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT √ó italic_C start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math> is a learnable parameter matrix, <math alttext="\sigma_{act}" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m2.1"><semantics id="S3.SS1.p4.3.m2.1a"><msub id="S3.SS1.p4.3.m2.1.1" xref="S3.SS1.p4.3.m2.1.1.cmml"><mi id="S3.SS1.p4.3.m2.1.1.2" xref="S3.SS1.p4.3.m2.1.1.2.cmml">œÉ</mi><mrow id="S3.SS1.p4.3.m2.1.1.3" xref="S3.SS1.p4.3.m2.1.1.3.cmml"><mi id="S3.SS1.p4.3.m2.1.1.3.2" xref="S3.SS1.p4.3.m2.1.1.3.2.cmml">a</mi><mo id="S3.SS1.p4.3.m2.1.1.3.1" xref="S3.SS1.p4.3.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.3.m2.1.1.3.3" xref="S3.SS1.p4.3.m2.1.1.3.3.cmml">c</mi><mo id="S3.SS1.p4.3.m2.1.1.3.1a" xref="S3.SS1.p4.3.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.3.m2.1.1.3.4" xref="S3.SS1.p4.3.m2.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m2.1b"><apply id="S3.SS1.p4.3.m2.1.1.cmml" xref="S3.SS1.p4.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m2.1.1.1.cmml" xref="S3.SS1.p4.3.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.3.m2.1.1.2.cmml" xref="S3.SS1.p4.3.m2.1.1.2">ùúé</ci><apply id="S3.SS1.p4.3.m2.1.1.3.cmml" xref="S3.SS1.p4.3.m2.1.1.3"><times id="S3.SS1.p4.3.m2.1.1.3.1.cmml" xref="S3.SS1.p4.3.m2.1.1.3.1"></times><ci id="S3.SS1.p4.3.m2.1.1.3.2.cmml" xref="S3.SS1.p4.3.m2.1.1.3.2">ùëé</ci><ci id="S3.SS1.p4.3.m2.1.1.3.3.cmml" xref="S3.SS1.p4.3.m2.1.1.3.3">ùëê</ci><ci id="S3.SS1.p4.3.m2.1.1.3.4.cmml" xref="S3.SS1.p4.3.m2.1.1.3.4">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m2.1c">\sigma_{act}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m2.1d">italic_œÉ start_POSTSUBSCRIPT italic_a italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is an activation function (ReLU), and <math alttext="\widetilde{A}\in\mathbb{R}^{K\times K}" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m3.1"><semantics id="S3.SS1.p4.4.m3.1a"><mrow id="S3.SS1.p4.4.m3.1.1" xref="S3.SS1.p4.4.m3.1.1.cmml"><mover accent="true" id="S3.SS1.p4.4.m3.1.1.2" xref="S3.SS1.p4.4.m3.1.1.2.cmml"><mi id="S3.SS1.p4.4.m3.1.1.2.2" xref="S3.SS1.p4.4.m3.1.1.2.2.cmml">A</mi><mo id="S3.SS1.p4.4.m3.1.1.2.1" xref="S3.SS1.p4.4.m3.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS1.p4.4.m3.1.1.1" xref="S3.SS1.p4.4.m3.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p4.4.m3.1.1.3" xref="S3.SS1.p4.4.m3.1.1.3.cmml"><mi id="S3.SS1.p4.4.m3.1.1.3.2" xref="S3.SS1.p4.4.m3.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS1.p4.4.m3.1.1.3.3" xref="S3.SS1.p4.4.m3.1.1.3.3.cmml"><mi id="S3.SS1.p4.4.m3.1.1.3.3.2" xref="S3.SS1.p4.4.m3.1.1.3.3.2.cmml">K</mi><mo id="S3.SS1.p4.4.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p4.4.m3.1.1.3.3.1.cmml">√ó</mo><mi id="S3.SS1.p4.4.m3.1.1.3.3.3" xref="S3.SS1.p4.4.m3.1.1.3.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m3.1b"><apply id="S3.SS1.p4.4.m3.1.1.cmml" xref="S3.SS1.p4.4.m3.1.1"><in id="S3.SS1.p4.4.m3.1.1.1.cmml" xref="S3.SS1.p4.4.m3.1.1.1"></in><apply id="S3.SS1.p4.4.m3.1.1.2.cmml" xref="S3.SS1.p4.4.m3.1.1.2"><ci id="S3.SS1.p4.4.m3.1.1.2.1.cmml" xref="S3.SS1.p4.4.m3.1.1.2.1">~</ci><ci id="S3.SS1.p4.4.m3.1.1.2.2.cmml" xref="S3.SS1.p4.4.m3.1.1.2.2">ùê¥</ci></apply><apply id="S3.SS1.p4.4.m3.1.1.3.cmml" xref="S3.SS1.p4.4.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m3.1.1.3.1.cmml" xref="S3.SS1.p4.4.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.4.m3.1.1.3.2.cmml" xref="S3.SS1.p4.4.m3.1.1.3.2">‚Ñù</ci><apply id="S3.SS1.p4.4.m3.1.1.3.3.cmml" xref="S3.SS1.p4.4.m3.1.1.3.3"><times id="S3.SS1.p4.4.m3.1.1.3.3.1.cmml" xref="S3.SS1.p4.4.m3.1.1.3.3.1"></times><ci id="S3.SS1.p4.4.m3.1.1.3.3.2.cmml" xref="S3.SS1.p4.4.m3.1.1.3.3.2">ùêæ</ci><ci id="S3.SS1.p4.4.m3.1.1.3.3.3.cmml" xref="S3.SS1.p4.4.m3.1.1.3.3.3">ùêæ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m3.1c">\widetilde{A}\in\mathbb{R}^{K\times K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m3.1d">over~ start_ARG italic_A end_ARG ‚àà blackboard_R start_POSTSUPERSCRIPT italic_K √ó italic_K end_POSTSUPERSCRIPT</annotation></semantics></math> is the symmetrically normalized form of the adjacency matrix <math alttext="A\in[0,1]^{K\times K}" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m4.2"><semantics id="S3.SS1.p4.5.m4.2a"><mrow id="S3.SS1.p4.5.m4.2.3" xref="S3.SS1.p4.5.m4.2.3.cmml"><mi id="S3.SS1.p4.5.m4.2.3.2" xref="S3.SS1.p4.5.m4.2.3.2.cmml">A</mi><mo id="S3.SS1.p4.5.m4.2.3.1" xref="S3.SS1.p4.5.m4.2.3.1.cmml">‚àà</mo><msup id="S3.SS1.p4.5.m4.2.3.3" xref="S3.SS1.p4.5.m4.2.3.3.cmml"><mrow id="S3.SS1.p4.5.m4.2.3.3.2.2" xref="S3.SS1.p4.5.m4.2.3.3.2.1.cmml"><mo id="S3.SS1.p4.5.m4.2.3.3.2.2.1" stretchy="false" xref="S3.SS1.p4.5.m4.2.3.3.2.1.cmml">[</mo><mn id="S3.SS1.p4.5.m4.1.1" xref="S3.SS1.p4.5.m4.1.1.cmml">0</mn><mo id="S3.SS1.p4.5.m4.2.3.3.2.2.2" xref="S3.SS1.p4.5.m4.2.3.3.2.1.cmml">,</mo><mn id="S3.SS1.p4.5.m4.2.2" xref="S3.SS1.p4.5.m4.2.2.cmml">1</mn><mo id="S3.SS1.p4.5.m4.2.3.3.2.2.3" stretchy="false" xref="S3.SS1.p4.5.m4.2.3.3.2.1.cmml">]</mo></mrow><mrow id="S3.SS1.p4.5.m4.2.3.3.3" xref="S3.SS1.p4.5.m4.2.3.3.3.cmml"><mi id="S3.SS1.p4.5.m4.2.3.3.3.2" xref="S3.SS1.p4.5.m4.2.3.3.3.2.cmml">K</mi><mo id="S3.SS1.p4.5.m4.2.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p4.5.m4.2.3.3.3.1.cmml">√ó</mo><mi id="S3.SS1.p4.5.m4.2.3.3.3.3" xref="S3.SS1.p4.5.m4.2.3.3.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m4.2b"><apply id="S3.SS1.p4.5.m4.2.3.cmml" xref="S3.SS1.p4.5.m4.2.3"><in id="S3.SS1.p4.5.m4.2.3.1.cmml" xref="S3.SS1.p4.5.m4.2.3.1"></in><ci id="S3.SS1.p4.5.m4.2.3.2.cmml" xref="S3.SS1.p4.5.m4.2.3.2">ùê¥</ci><apply id="S3.SS1.p4.5.m4.2.3.3.cmml" xref="S3.SS1.p4.5.m4.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m4.2.3.3.1.cmml" xref="S3.SS1.p4.5.m4.2.3.3">superscript</csymbol><interval closure="closed" id="S3.SS1.p4.5.m4.2.3.3.2.1.cmml" xref="S3.SS1.p4.5.m4.2.3.3.2.2"><cn id="S3.SS1.p4.5.m4.1.1.cmml" type="integer" xref="S3.SS1.p4.5.m4.1.1">0</cn><cn id="S3.SS1.p4.5.m4.2.2.cmml" type="integer" xref="S3.SS1.p4.5.m4.2.2">1</cn></interval><apply id="S3.SS1.p4.5.m4.2.3.3.3.cmml" xref="S3.SS1.p4.5.m4.2.3.3.3"><times id="S3.SS1.p4.5.m4.2.3.3.3.1.cmml" xref="S3.SS1.p4.5.m4.2.3.3.3.1"></times><ci id="S3.SS1.p4.5.m4.2.3.3.3.2.cmml" xref="S3.SS1.p4.5.m4.2.3.3.3.2">ùêæ</ci><ci id="S3.SS1.p4.5.m4.2.3.3.3.3.cmml" xref="S3.SS1.p4.5.m4.2.3.3.3.3">ùêæ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m4.2c">A\in[0,1]^{K\times K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m4.2d">italic_A ‚àà [ 0 , 1 ] start_POSTSUPERSCRIPT italic_K √ó italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>. <math alttext="A" class="ltx_Math" display="inline" id="S3.SS1.p4.6.m5.1"><semantics id="S3.SS1.p4.6.m5.1a"><mi id="S3.SS1.p4.6.m5.1.1" xref="S3.SS1.p4.6.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m5.1b"><ci id="S3.SS1.p4.6.m5.1.1.cmml" xref="S3.SS1.p4.6.m5.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m5.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.6.m5.1d">italic_A</annotation></semantics></math> is a binary matrix, defined as <math alttext="a_{ij}=1" class="ltx_Math" display="inline" id="S3.SS1.p4.7.m6.1"><semantics id="S3.SS1.p4.7.m6.1a"><mrow id="S3.SS1.p4.7.m6.1.1" xref="S3.SS1.p4.7.m6.1.1.cmml"><msub id="S3.SS1.p4.7.m6.1.1.2" xref="S3.SS1.p4.7.m6.1.1.2.cmml"><mi id="S3.SS1.p4.7.m6.1.1.2.2" xref="S3.SS1.p4.7.m6.1.1.2.2.cmml">a</mi><mrow id="S3.SS1.p4.7.m6.1.1.2.3" xref="S3.SS1.p4.7.m6.1.1.2.3.cmml"><mi id="S3.SS1.p4.7.m6.1.1.2.3.2" xref="S3.SS1.p4.7.m6.1.1.2.3.2.cmml">i</mi><mo id="S3.SS1.p4.7.m6.1.1.2.3.1" xref="S3.SS1.p4.7.m6.1.1.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS1.p4.7.m6.1.1.2.3.3" xref="S3.SS1.p4.7.m6.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.SS1.p4.7.m6.1.1.1" xref="S3.SS1.p4.7.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p4.7.m6.1.1.3" xref="S3.SS1.p4.7.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m6.1b"><apply id="S3.SS1.p4.7.m6.1.1.cmml" xref="S3.SS1.p4.7.m6.1.1"><eq id="S3.SS1.p4.7.m6.1.1.1.cmml" xref="S3.SS1.p4.7.m6.1.1.1"></eq><apply id="S3.SS1.p4.7.m6.1.1.2.cmml" xref="S3.SS1.p4.7.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m6.1.1.2.1.cmml" xref="S3.SS1.p4.7.m6.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.7.m6.1.1.2.2.cmml" xref="S3.SS1.p4.7.m6.1.1.2.2">ùëé</ci><apply id="S3.SS1.p4.7.m6.1.1.2.3.cmml" xref="S3.SS1.p4.7.m6.1.1.2.3"><times id="S3.SS1.p4.7.m6.1.1.2.3.1.cmml" xref="S3.SS1.p4.7.m6.1.1.2.3.1"></times><ci id="S3.SS1.p4.7.m6.1.1.2.3.2.cmml" xref="S3.SS1.p4.7.m6.1.1.2.3.2">ùëñ</ci><ci id="S3.SS1.p4.7.m6.1.1.2.3.3.cmml" xref="S3.SS1.p4.7.m6.1.1.2.3.3">ùëó</ci></apply></apply><cn id="S3.SS1.p4.7.m6.1.1.3.cmml" type="integer" xref="S3.SS1.p4.7.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m6.1c">a_{ij}=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.7.m6.1d">italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 1</annotation></semantics></math> for node <math alttext="v_{j}" class="ltx_Math" display="inline" id="S3.SS1.p4.8.m7.1"><semantics id="S3.SS1.p4.8.m7.1a"><msub id="S3.SS1.p4.8.m7.1.1" xref="S3.SS1.p4.8.m7.1.1.cmml"><mi id="S3.SS1.p4.8.m7.1.1.2" xref="S3.SS1.p4.8.m7.1.1.2.cmml">v</mi><mi id="S3.SS1.p4.8.m7.1.1.3" xref="S3.SS1.p4.8.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m7.1b"><apply id="S3.SS1.p4.8.m7.1.1.cmml" xref="S3.SS1.p4.8.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.8.m7.1.1.1.cmml" xref="S3.SS1.p4.8.m7.1.1">subscript</csymbol><ci id="S3.SS1.p4.8.m7.1.1.2.cmml" xref="S3.SS1.p4.8.m7.1.1.2">ùë£</ci><ci id="S3.SS1.p4.8.m7.1.1.3.cmml" xref="S3.SS1.p4.8.m7.1.1.3">ùëó</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m7.1c">v_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.8.m7.1d">italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> that is connected to node <math alttext="v_{i}" class="ltx_Math" display="inline" id="S3.SS1.p4.9.m8.1"><semantics id="S3.SS1.p4.9.m8.1a"><msub id="S3.SS1.p4.9.m8.1.1" xref="S3.SS1.p4.9.m8.1.1.cmml"><mi id="S3.SS1.p4.9.m8.1.1.2" xref="S3.SS1.p4.9.m8.1.1.2.cmml">v</mi><mi id="S3.SS1.p4.9.m8.1.1.3" xref="S3.SS1.p4.9.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.9.m8.1b"><apply id="S3.SS1.p4.9.m8.1.1.cmml" xref="S3.SS1.p4.9.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.9.m8.1.1.1.cmml" xref="S3.SS1.p4.9.m8.1.1">subscript</csymbol><ci id="S3.SS1.p4.9.m8.1.1.2.cmml" xref="S3.SS1.p4.9.m8.1.1.2">ùë£</ci><ci id="S3.SS1.p4.9.m8.1.1.3.cmml" xref="S3.SS1.p4.9.m8.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.9.m8.1c">v_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.9.m8.1d">italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="0" class="ltx_Math" display="inline" id="S3.SS1.p4.10.m9.1"><semantics id="S3.SS1.p4.10.m9.1a"><mn id="S3.SS1.p4.10.m9.1.1" xref="S3.SS1.p4.10.m9.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.10.m9.1b"><cn id="S3.SS1.p4.10.m9.1.1.cmml" type="integer" xref="S3.SS1.p4.10.m9.1.1">0</cn></annotation-xml></semantics></math> elsewhere.
While the adjacency matrix is fixed for each category, during training some nodes may not be visible in the support image. Thus, we also mask the adjacency matrix before normalization, to make sure only meaningful information is propagated between nodes.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.3">The output features <math alttext="F_{s}^{l+1}" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><msubsup id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><mi id="S3.SS1.p5.1.m1.1.1.2.2" xref="S3.SS1.p5.1.m1.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p5.1.m1.1.1.2.3" xref="S3.SS1.p5.1.m1.1.1.2.3.cmml">s</mi><mrow id="S3.SS1.p5.1.m1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.3.cmml"><mi id="S3.SS1.p5.1.m1.1.1.3.2" xref="S3.SS1.p5.1.m1.1.1.3.2.cmml">l</mi><mo id="S3.SS1.p5.1.m1.1.1.3.1" xref="S3.SS1.p5.1.m1.1.1.3.1.cmml">+</mo><mn id="S3.SS1.p5.1.m1.1.1.3.3" xref="S3.SS1.p5.1.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">superscript</csymbol><apply id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.2.1.cmml" xref="S3.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.2.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2.2">ùêπ</ci><ci id="S3.SS1.p5.1.m1.1.1.2.3.cmml" xref="S3.SS1.p5.1.m1.1.1.2.3">ùë†</ci></apply><apply id="S3.SS1.p5.1.m1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3"><plus id="S3.SS1.p5.1.m1.1.1.3.1.cmml" xref="S3.SS1.p5.1.m1.1.1.3.1"></plus><ci id="S3.SS1.p5.1.m1.1.1.3.2.cmml" xref="S3.SS1.p5.1.m1.1.1.3.2">ùëô</ci><cn id="S3.SS1.p5.1.m1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p5.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">F_{s}^{l+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT</annotation></semantics></math> are used to update the normalized keypoints locations from <math alttext="P^{l}" class="ltx_Math" display="inline" id="S3.SS1.p5.2.m2.1"><semantics id="S3.SS1.p5.2.m2.1a"><msup id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml"><mi id="S3.SS1.p5.2.m2.1.1.2" xref="S3.SS1.p5.2.m2.1.1.2.cmml">P</mi><mi id="S3.SS1.p5.2.m2.1.1.3" xref="S3.SS1.p5.2.m2.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><apply id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2">ùëÉ</ci><ci id="S3.SS1.p5.2.m2.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3">ùëô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">P^{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.2.m2.1d">italic_P start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> to <math alttext="P^{l+1}" class="ltx_Math" display="inline" id="S3.SS1.p5.3.m3.1"><semantics id="S3.SS1.p5.3.m3.1a"><msup id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mi id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">P</mi><mrow id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml"><mi id="S3.SS1.p5.3.m3.1.1.3.2" xref="S3.SS1.p5.3.m3.1.1.3.2.cmml">l</mi><mo id="S3.SS1.p5.3.m3.1.1.3.1" xref="S3.SS1.p5.3.m3.1.1.3.1.cmml">+</mo><mn id="S3.SS1.p5.3.m3.1.1.3.3" xref="S3.SS1.p5.3.m3.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2">ùëÉ</ci><apply id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3"><plus id="S3.SS1.p5.3.m3.1.1.3.1.cmml" xref="S3.SS1.p5.3.m3.1.1.3.1"></plus><ci id="S3.SS1.p5.3.m3.1.1.3.2.cmml" xref="S3.SS1.p5.3.m3.1.1.3.2">ùëô</ci><cn id="S3.SS1.p5.3.m3.1.1.3.3.cmml" type="integer" xref="S3.SS1.p5.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">P^{l+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.3.m3.1d">italic_P start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT</annotation></semantics></math>. We follow¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite> and use the following update function:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P^{l+1}=\sigma(\sigma^{-1}(P^{l})+MLP(F_{s}^{l+1}))" class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><msup id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.3.2" xref="S3.E3.m1.1.1.3.2.cmml">P</mi><mrow id="S3.E3.m1.1.1.3.3" xref="S3.E3.m1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.3.3.2" xref="S3.E3.m1.1.1.3.3.2.cmml">l</mi><mo id="S3.E3.m1.1.1.3.3.1" xref="S3.E3.m1.1.1.3.3.1.cmml">+</mo><mn id="S3.E3.m1.1.1.3.3.3" xref="S3.E3.m1.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml">œÉ</mi><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><msup id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.2.cmml">œÉ</mi><mrow id="S3.E3.m1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.3.3a" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3.cmml">‚àí</mo><mn id="S3.E3.m1.1.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3.2.cmml">1</mn></mrow></msup><mo id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">P</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">l</mi></msup><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.2.3.cmml">M</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.2.2.cmml">‚Å¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.2.4" xref="S3.E3.m1.1.1.1.1.1.1.2.4.cmml">L</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.2a" xref="S3.E3.m1.1.1.1.1.1.1.2.2.cmml">‚Å¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.2.5" xref="S3.E3.m1.1.1.1.1.1.1.2.5.cmml">P</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.2b" xref="S3.E3.m1.1.1.1.1.1.1.2.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.2.1.1" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.2.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msubsup id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2.cmml">F</mi><mi id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3.cmml">s</mi><mrow id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.2.cmml">l</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.1.cmml">+</mo><mn id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.3.cmml">1</mn></mrow></msubsup><mo id="S3.E3.m1.1.1.1.1.1.1.2.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"></eq><apply id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.3.2">ùëÉ</ci><apply id="S3.E3.m1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.3.3"><plus id="S3.E3.m1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3.1"></plus><ci id="S3.E3.m1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.2">ùëô</ci><cn id="S3.E3.m1.1.1.3.3.3.cmml" type="integer" xref="S3.E3.m1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3">ùúé</ci><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3"></plus><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.2">ùúé</ci><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3"><minus id="S3.E3.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3"></minus><cn id="S3.E3.m1.1.1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.1.1.1.3.3.2">1</cn></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2">ùëÉ</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3">ùëô</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.2"></times><ci id="S3.E3.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.3">ùëÄ</ci><ci id="S3.E3.m1.1.1.1.1.1.1.2.4.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.4">ùêø</ci><ci id="S3.E3.m1.1.1.1.1.1.1.2.5.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.5">ùëÉ</ci><apply id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.2">ùêπ</ci><ci id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.3">ùë†</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3"><plus id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.1"></plus><ci id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.2">ùëô</ci><cn id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.3.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">P^{l+1}=\sigma(\sigma^{-1}(P^{l})+MLP(F_{s}^{l+1}))</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">italic_P start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT = italic_œÉ ( italic_œÉ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_P start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT ) + italic_M italic_L italic_P ( italic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p5.5">where <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS1.p5.4.m1.1"><semantics id="S3.SS1.p5.4.m1.1a"><mi id="S3.SS1.p5.4.m1.1.1" xref="S3.SS1.p5.4.m1.1.1.cmml">œÉ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m1.1b"><ci id="S3.SS1.p5.4.m1.1.1.cmml" xref="S3.SS1.p5.4.m1.1.1">ùúé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.4.m1.1d">italic_œÉ</annotation></semantics></math> and <math alttext="\sigma^{-1}" class="ltx_Math" display="inline" id="S3.SS1.p5.5.m2.1"><semantics id="S3.SS1.p5.5.m2.1a"><msup id="S3.SS1.p5.5.m2.1.1" xref="S3.SS1.p5.5.m2.1.1.cmml"><mi id="S3.SS1.p5.5.m2.1.1.2" xref="S3.SS1.p5.5.m2.1.1.2.cmml">œÉ</mi><mrow id="S3.SS1.p5.5.m2.1.1.3" xref="S3.SS1.p5.5.m2.1.1.3.cmml"><mo id="S3.SS1.p5.5.m2.1.1.3a" xref="S3.SS1.p5.5.m2.1.1.3.cmml">‚àí</mo><mn id="S3.SS1.p5.5.m2.1.1.3.2" xref="S3.SS1.p5.5.m2.1.1.3.2.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.5.m2.1b"><apply id="S3.SS1.p5.5.m2.1.1.cmml" xref="S3.SS1.p5.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.5.m2.1.1.1.cmml" xref="S3.SS1.p5.5.m2.1.1">superscript</csymbol><ci id="S3.SS1.p5.5.m2.1.1.2.cmml" xref="S3.SS1.p5.5.m2.1.1.2">ùúé</ci><apply id="S3.SS1.p5.5.m2.1.1.3.cmml" xref="S3.SS1.p5.5.m2.1.1.3"><minus id="S3.SS1.p5.5.m2.1.1.3.1.cmml" xref="S3.SS1.p5.5.m2.1.1.3"></minus><cn id="S3.SS1.p5.5.m2.1.1.3.2.cmml" type="integer" xref="S3.SS1.p5.5.m2.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m2.1c">\sigma^{-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.5.m2.1d">italic_œÉ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT</annotation></semantics></math> are the sigmoid and its inverse function.
The keypoints‚Äô positions from the last decoder layer are used as the final keypoints prediction.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training Scheme</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.6">Following CapeFormer, we use two supervision signals: a heatmap loss and an offset loss. The heatmap loss supervises the proposal generator, constraining the shape of the similarity maps, and facilitating the learning of meaningful representations, while the offset loss supervises the localization output:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{heatmap}=\frac{1}{K\cdot H\cdot W}\sum_{i=1}^{K}\lVert\sigma(M_{i%
})-H_{i}\rVert" class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml">‚Ñí</mi><mrow id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.3.3.2" xref="S3.E4.m1.1.1.3.3.2.cmml">h</mi><mo id="S3.E4.m1.1.1.3.3.1" xref="S3.E4.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.1.1.3.3.3" xref="S3.E4.m1.1.1.3.3.3.cmml">e</mi><mo id="S3.E4.m1.1.1.3.3.1a" xref="S3.E4.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.1.1.3.3.4" xref="S3.E4.m1.1.1.3.3.4.cmml">a</mi><mo id="S3.E4.m1.1.1.3.3.1b" xref="S3.E4.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.1.1.3.3.5" xref="S3.E4.m1.1.1.3.3.5.cmml">t</mi><mo id="S3.E4.m1.1.1.3.3.1c" xref="S3.E4.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.1.1.3.3.6" xref="S3.E4.m1.1.1.3.3.6.cmml">m</mi><mo id="S3.E4.m1.1.1.3.3.1d" xref="S3.E4.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.1.1.3.3.7" xref="S3.E4.m1.1.1.3.3.7.cmml">a</mi><mo id="S3.E4.m1.1.1.3.3.1e" xref="S3.E4.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.1.1.3.3.8" xref="S3.E4.m1.1.1.3.3.8.cmml">p</mi></mrow></msub><mo id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mfrac id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml"><mn id="S3.E4.m1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.3.2.cmml">1</mn><mrow id="S3.E4.m1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.1.3.3.2.cmml">K</mi><mo id="S3.E4.m1.1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.1.1.1.3.3.1.cmml">‚ãÖ</mo><mi id="S3.E4.m1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.3.3.3.cmml">H</mi><mo id="S3.E4.m1.1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.1.1.1.3.3.1.cmml">‚ãÖ</mo><mi id="S3.E4.m1.1.1.1.3.3.4" xref="S3.E4.m1.1.1.1.3.3.4.cmml">W</mi></mrow></mfrac><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><munderover id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.1.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E4.m1.1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E4.m1.1.1.1.1.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2.3.2" xref="S3.E4.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E4.m1.1.1.1.1.2.2.3.1" xref="S3.E4.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.1.1.1.1.2.2.3.3" xref="S3.E4.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.2.3.cmml">K</mi></munderover><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.2.cmml"><mo fence="true" id="S3.E4.m1.1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S3.E4.m1.1.1.1.1.1.2.1.cmml">‚à•</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml">œÉ</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">M</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">‚àí</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.3.2.cmml">H</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo fence="true" id="S3.E4.m1.1.1.1.1.1.1.3" lspace="0em" xref="S3.E4.m1.1.1.1.1.1.2.1.cmml">‚à•</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"></eq><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2">‚Ñí</ci><apply id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3"><times id="S3.E4.m1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3.1"></times><ci id="S3.E4.m1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.2">‚Ñé</ci><ci id="S3.E4.m1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3">ùëí</ci><ci id="S3.E4.m1.1.1.3.3.4.cmml" xref="S3.E4.m1.1.1.3.3.4">ùëé</ci><ci id="S3.E4.m1.1.1.3.3.5.cmml" xref="S3.E4.m1.1.1.3.3.5">ùë°</ci><ci id="S3.E4.m1.1.1.3.3.6.cmml" xref="S3.E4.m1.1.1.3.3.6">ùëö</ci><ci id="S3.E4.m1.1.1.3.3.7.cmml" xref="S3.E4.m1.1.1.3.3.7">ùëé</ci><ci id="S3.E4.m1.1.1.3.3.8.cmml" xref="S3.E4.m1.1.1.3.3.8">ùëù</ci></apply></apply><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><times id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3"><divide id="S3.E4.m1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.3"></divide><cn id="S3.E4.m1.1.1.1.3.2.cmml" type="integer" xref="S3.E4.m1.1.1.1.3.2">1</cn><apply id="S3.E4.m1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.3.3"><ci id="S3.E4.m1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.3.3.1">‚ãÖ</ci><ci id="S3.E4.m1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.3.3.2">ùêæ</ci><ci id="S3.E4.m1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.3.3.3">ùêª</ci><ci id="S3.E4.m1.1.1.1.3.3.4.cmml" xref="S3.E4.m1.1.1.1.3.3.4">ùëä</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1"><apply id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E4.m1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E4.m1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.3"><eq id="S3.E4.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.3.2">ùëñ</ci><cn id="S3.E4.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E4.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3">ùêæ</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">delimited-‚à•‚à•</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><minus id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">ùúé</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2">ùëÄ</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3">ùëñ</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3.2">ùêª</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3.3">ùëñ</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathcal{L}_{heatmap}=\frac{1}{K\cdot H\cdot W}\sum_{i=1}^{K}\lVert\sigma(M_{i%
})-H_{i}\rVert</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_h italic_e italic_a italic_t italic_m italic_a italic_p end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_K ‚ãÖ italic_H ‚ãÖ italic_W end_ARG ‚àë start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT ‚à• italic_œÉ ( italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ‚à•</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{offset}=\frac{1}{L}\sum_{i=1}^{L}\sum_{i=1}^{K}|P_{i}^{l}-\hat{P_%
{i}}|" class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml">‚Ñí</mi><mrow id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.3.3.2" xref="S3.E5.m1.1.1.3.3.2.cmml">o</mi><mo id="S3.E5.m1.1.1.3.3.1" xref="S3.E5.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.1.1.3.3.3" xref="S3.E5.m1.1.1.3.3.3.cmml">f</mi><mo id="S3.E5.m1.1.1.3.3.1a" xref="S3.E5.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.1.1.3.3.4" xref="S3.E5.m1.1.1.3.3.4.cmml">f</mi><mo id="S3.E5.m1.1.1.3.3.1b" xref="S3.E5.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.1.1.3.3.5" xref="S3.E5.m1.1.1.3.3.5.cmml">s</mi><mo id="S3.E5.m1.1.1.3.3.1c" xref="S3.E5.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.1.1.3.3.6" xref="S3.E5.m1.1.1.3.3.6.cmml">e</mi><mo id="S3.E5.m1.1.1.3.3.1d" xref="S3.E5.m1.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E5.m1.1.1.3.3.7" xref="S3.E5.m1.1.1.3.3.7.cmml">t</mi></mrow></msub><mo id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><mfrac id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3.cmml"><mn id="S3.E5.m1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.3.2.cmml">1</mn><mi id="S3.E5.m1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.3.3.cmml">L</mi></mfrac><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><munderover id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><mo id="S3.E5.m1.1.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E5.m1.1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E5.m1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2.3.2" xref="S3.E5.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.1.1.2.2.3.1" xref="S3.E5.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E5.m1.1.1.1.1.2.2.3.3" xref="S3.E5.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml">L</mi></munderover><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><munderover id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.2.cmml"><mo id="S3.E5.m1.1.1.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E5.m1.1.1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E5.m1.1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.2.2.3.2" xref="S3.E5.m1.1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.1.1.1.2.2.3.1" xref="S3.E5.m1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E5.m1.1.1.1.1.1.2.2.3.3" xref="S3.E5.m1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E5.m1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.2.3.cmml">K</mi></munderover><mrow id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E5.m1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">P</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml">l</mi></msubsup><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mover accent="true" id="S3.E5.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">P</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"></eq><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2">‚Ñí</ci><apply id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3"><times id="S3.E5.m1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.1"></times><ci id="S3.E5.m1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2">ùëú</ci><ci id="S3.E5.m1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3">ùëì</ci><ci id="S3.E5.m1.1.1.3.3.4.cmml" xref="S3.E5.m1.1.1.3.3.4">ùëì</ci><ci id="S3.E5.m1.1.1.3.3.5.cmml" xref="S3.E5.m1.1.1.3.3.5">ùë†</ci><ci id="S3.E5.m1.1.1.3.3.6.cmml" xref="S3.E5.m1.1.1.3.3.6">ùëí</ci><ci id="S3.E5.m1.1.1.3.3.7.cmml" xref="S3.E5.m1.1.1.3.3.7">ùë°</ci></apply></apply><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><times id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2"></times><apply id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3"><divide id="S3.E5.m1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.3"></divide><cn id="S3.E5.m1.1.1.1.3.2.cmml" type="integer" xref="S3.E5.m1.1.1.1.3.2">1</cn><ci id="S3.E5.m1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.3.3">ùêø</ci></apply><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1"><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E5.m1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E5.m1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.2.3"><eq id="S3.E5.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E5.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2.3.2">ùëñ</ci><cn id="S3.E5.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3">ùêø</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><apply id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E5.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2.2.2"></sum><apply id="S3.E5.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.2.2.3"><eq id="S3.E5.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E5.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2.2.3.2">ùëñ</ci><cn id="S3.E5.m1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.2.3">ùêæ</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><abs id="S3.E5.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.2"></abs><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1"><minus id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.2">ùëÉ</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.3">ùëñ</ci></apply><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3">ùëô</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3"><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.1">^</ci><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.2">ùëÉ</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.3">ùëñ</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\mathcal{L}_{offset}=\frac{1}{L}\sum_{i=1}^{L}\sum_{i=1}^{K}|P_{i}^{l}-\hat{P_%
{i}}|</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_o italic_f italic_f italic_s italic_e italic_t end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_L end_ARG ‚àë start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT ‚àë start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT | italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT - over^ start_ARG italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.5">where <math alttext="M_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ùëÄ</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">M_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes the output similarity heatmap from the proposal generator, <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">œÉ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ùúé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_œÉ</annotation></semantics></math> is the sigmoid function, <math alttext="H_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">H</mi><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ùêª</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">H_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> the ground-truth heatmap, <math alttext="P_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">P</mi><mi id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">ùëÉ</ci><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">P_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> the output location from the each layer and <math alttext="\hat{P_{i}}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><mover accent="true" id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><msub id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2.2" xref="S3.SS2.p1.5.m5.1.1.2.2.cmml">P</mi><mi id="S3.SS2.p1.5.m5.1.1.2.3" xref="S3.SS2.p1.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p1.5.m5.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><ci id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1">^</ci><apply id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.2.1.cmml" xref="S3.SS2.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2.2">ùëÉ</ci><ci id="S3.SS2.p1.5.m5.1.1.2.3.cmml" xref="S3.SS2.p1.5.m5.1.1.2.3">ùëñ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\hat{P_{i}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">over^ start_ARG italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> the ground-truth location.
The overall loss term is:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=\lambda_{heatmap}\cdot\mathcal{L}_{heatmap}+\mathcal{L}_{offset}" class="ltx_Math" display="block" id="S3.E6.m1.1"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml">‚Ñí</mi><mo id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><mrow id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml"><msub id="S3.E6.m1.1.1.3.2.2" xref="S3.E6.m1.1.1.3.2.2.cmml"><mi id="S3.E6.m1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.3.2.2.2.cmml">Œª</mi><mrow id="S3.E6.m1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.3.2.2.3.cmml"><mi id="S3.E6.m1.1.1.3.2.2.3.2" xref="S3.E6.m1.1.1.3.2.2.3.2.cmml">h</mi><mo id="S3.E6.m1.1.1.3.2.2.3.1" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.2.3.3" xref="S3.E6.m1.1.1.3.2.2.3.3.cmml">e</mi><mo id="S3.E6.m1.1.1.3.2.2.3.1a" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.2.3.4" xref="S3.E6.m1.1.1.3.2.2.3.4.cmml">a</mi><mo id="S3.E6.m1.1.1.3.2.2.3.1b" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.2.3.5" xref="S3.E6.m1.1.1.3.2.2.3.5.cmml">t</mi><mo id="S3.E6.m1.1.1.3.2.2.3.1c" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.2.3.6" xref="S3.E6.m1.1.1.3.2.2.3.6.cmml">m</mi><mo id="S3.E6.m1.1.1.3.2.2.3.1d" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.2.3.7" xref="S3.E6.m1.1.1.3.2.2.3.7.cmml">a</mi><mo id="S3.E6.m1.1.1.3.2.2.3.1e" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.2.3.8" xref="S3.E6.m1.1.1.3.2.2.3.8.cmml">p</mi></mrow></msub><mo id="S3.E6.m1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E6.m1.1.1.3.2.1.cmml">‚ãÖ</mo><msub id="S3.E6.m1.1.1.3.2.3" xref="S3.E6.m1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.3.2.3.2.cmml">‚Ñí</mi><mrow id="S3.E6.m1.1.1.3.2.3.3" xref="S3.E6.m1.1.1.3.2.3.3.cmml"><mi id="S3.E6.m1.1.1.3.2.3.3.2" xref="S3.E6.m1.1.1.3.2.3.3.2.cmml">h</mi><mo id="S3.E6.m1.1.1.3.2.3.3.1" xref="S3.E6.m1.1.1.3.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.3.3.3" xref="S3.E6.m1.1.1.3.2.3.3.3.cmml">e</mi><mo id="S3.E6.m1.1.1.3.2.3.3.1a" xref="S3.E6.m1.1.1.3.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.3.3.4" xref="S3.E6.m1.1.1.3.2.3.3.4.cmml">a</mi><mo id="S3.E6.m1.1.1.3.2.3.3.1b" xref="S3.E6.m1.1.1.3.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.3.3.5" xref="S3.E6.m1.1.1.3.2.3.3.5.cmml">t</mi><mo id="S3.E6.m1.1.1.3.2.3.3.1c" xref="S3.E6.m1.1.1.3.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.3.3.6" xref="S3.E6.m1.1.1.3.2.3.3.6.cmml">m</mi><mo id="S3.E6.m1.1.1.3.2.3.3.1d" xref="S3.E6.m1.1.1.3.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.3.3.7" xref="S3.E6.m1.1.1.3.2.3.3.7.cmml">a</mi><mo id="S3.E6.m1.1.1.3.2.3.3.1e" xref="S3.E6.m1.1.1.3.2.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.2.3.3.8" xref="S3.E6.m1.1.1.3.2.3.3.8.cmml">p</mi></mrow></msub></mrow><mo id="S3.E6.m1.1.1.3.1" xref="S3.E6.m1.1.1.3.1.cmml">+</mo><msub id="S3.E6.m1.1.1.3.3" xref="S3.E6.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.3.3.2" xref="S3.E6.m1.1.1.3.3.2.cmml">‚Ñí</mi><mrow id="S3.E6.m1.1.1.3.3.3" xref="S3.E6.m1.1.1.3.3.3.cmml"><mi id="S3.E6.m1.1.1.3.3.3.2" xref="S3.E6.m1.1.1.3.3.3.2.cmml">o</mi><mo id="S3.E6.m1.1.1.3.3.3.1" xref="S3.E6.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.3.3.3" xref="S3.E6.m1.1.1.3.3.3.3.cmml">f</mi><mo id="S3.E6.m1.1.1.3.3.3.1a" xref="S3.E6.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.3.3.4" xref="S3.E6.m1.1.1.3.3.3.4.cmml">f</mi><mo id="S3.E6.m1.1.1.3.3.3.1b" xref="S3.E6.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.3.3.5" xref="S3.E6.m1.1.1.3.3.3.5.cmml">s</mi><mo id="S3.E6.m1.1.1.3.3.3.1c" xref="S3.E6.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.3.3.6" xref="S3.E6.m1.1.1.3.3.3.6.cmml">e</mi><mo id="S3.E6.m1.1.1.3.3.3.1d" xref="S3.E6.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S3.E6.m1.1.1.3.3.3.7" xref="S3.E6.m1.1.1.3.3.3.7.cmml">t</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"></eq><ci id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2">‚Ñí</ci><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><plus id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3.1"></plus><apply id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2"><ci id="S3.E6.m1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.3.2.1">‚ãÖ</ci><apply id="S3.E6.m1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2.2">ùúÜ</ci><apply id="S3.E6.m1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.3.2.2.3"><times id="S3.E6.m1.1.1.3.2.2.3.1.cmml" xref="S3.E6.m1.1.1.3.2.2.3.1"></times><ci id="S3.E6.m1.1.1.3.2.2.3.2.cmml" xref="S3.E6.m1.1.1.3.2.2.3.2">‚Ñé</ci><ci id="S3.E6.m1.1.1.3.2.2.3.3.cmml" xref="S3.E6.m1.1.1.3.2.2.3.3">ùëí</ci><ci id="S3.E6.m1.1.1.3.2.2.3.4.cmml" xref="S3.E6.m1.1.1.3.2.2.3.4">ùëé</ci><ci id="S3.E6.m1.1.1.3.2.2.3.5.cmml" xref="S3.E6.m1.1.1.3.2.2.3.5">ùë°</ci><ci id="S3.E6.m1.1.1.3.2.2.3.6.cmml" xref="S3.E6.m1.1.1.3.2.2.3.6">ùëö</ci><ci id="S3.E6.m1.1.1.3.2.2.3.7.cmml" xref="S3.E6.m1.1.1.3.2.2.3.7">ùëé</ci><ci id="S3.E6.m1.1.1.3.2.2.3.8.cmml" xref="S3.E6.m1.1.1.3.2.2.3.8">ùëù</ci></apply></apply><apply id="S3.E6.m1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.3.2.3.2">‚Ñí</ci><apply id="S3.E6.m1.1.1.3.2.3.3.cmml" xref="S3.E6.m1.1.1.3.2.3.3"><times id="S3.E6.m1.1.1.3.2.3.3.1.cmml" xref="S3.E6.m1.1.1.3.2.3.3.1"></times><ci id="S3.E6.m1.1.1.3.2.3.3.2.cmml" xref="S3.E6.m1.1.1.3.2.3.3.2">‚Ñé</ci><ci id="S3.E6.m1.1.1.3.2.3.3.3.cmml" xref="S3.E6.m1.1.1.3.2.3.3.3">ùëí</ci><ci id="S3.E6.m1.1.1.3.2.3.3.4.cmml" xref="S3.E6.m1.1.1.3.2.3.3.4">ùëé</ci><ci id="S3.E6.m1.1.1.3.2.3.3.5.cmml" xref="S3.E6.m1.1.1.3.2.3.3.5">ùë°</ci><ci id="S3.E6.m1.1.1.3.2.3.3.6.cmml" xref="S3.E6.m1.1.1.3.2.3.3.6">ùëö</ci><ci id="S3.E6.m1.1.1.3.2.3.3.7.cmml" xref="S3.E6.m1.1.1.3.2.3.3.7">ùëé</ci><ci id="S3.E6.m1.1.1.3.2.3.3.8.cmml" xref="S3.E6.m1.1.1.3.2.3.3.8">ùëù</ci></apply></apply></apply><apply id="S3.E6.m1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.3.3">subscript</csymbol><ci id="S3.E6.m1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.3.3.2">‚Ñí</ci><apply id="S3.E6.m1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.3.3.3"><times id="S3.E6.m1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.1.1.3.3.3.1"></times><ci id="S3.E6.m1.1.1.3.3.3.2.cmml" xref="S3.E6.m1.1.1.3.3.3.2">ùëú</ci><ci id="S3.E6.m1.1.1.3.3.3.3.cmml" xref="S3.E6.m1.1.1.3.3.3.3">ùëì</ci><ci id="S3.E6.m1.1.1.3.3.3.4.cmml" xref="S3.E6.m1.1.1.3.3.3.4">ùëì</ci><ci id="S3.E6.m1.1.1.3.3.3.5.cmml" xref="S3.E6.m1.1.1.3.3.3.5">ùë†</ci><ci id="S3.E6.m1.1.1.3.3.3.6.cmml" xref="S3.E6.m1.1.1.3.3.3.6">ùëí</ci><ci id="S3.E6.m1.1.1.3.3.3.7.cmml" xref="S3.E6.m1.1.1.3.3.3.7">ùë°</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathcal{L}=\lambda_{heatmap}\cdot\mathcal{L}_{heatmap}+\mathcal{L}_{offset}</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.1d">caligraphic_L = italic_Œª start_POSTSUBSCRIPT italic_h italic_e italic_a italic_t italic_m italic_a italic_p end_POSTSUBSCRIPT ‚ãÖ caligraphic_L start_POSTSUBSCRIPT italic_h italic_e italic_a italic_t italic_m italic_a italic_p end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT italic_o italic_f italic_f italic_s italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Encoding Structure: Positional Encoding VS Graph Network</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text ltx_font_bold" id="S3.T1.4.2" style="font-size:90%;">Keypoint Positional Encoding:<span class="ltx_text ltx_font_medium" id="S3.T1.4.2.1"> Comparison of results using CapeFormer with the original dataset and using permuted keypoints. Keypoint Positional Encoding (PE) adds an implicit structure bias according to the fixed order of keypoints in the dataset. Graph-FFN adds an explicit structure prior of any object‚Äôs shape.</span></span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.5.1.1">
<td class="ltx_td ltx_border_tt" id="S3.T1.5.1.1.1"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.5.1.1.2">Original Data</th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S3.T1.5.1.1.3"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.5.1.1.4">Shuffled Keypoints</th>
</tr>
<tr class="ltx_tr" id="S3.T1.5.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.2.2.1">With PE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.2.2.2">89.26</td>
<td class="ltx_td ltx_border_t" id="S3.T1.5.2.2.3"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.5.2.2.4">64.20 <span class="ltx_text ltx_font_bold" id="S3.T1.5.2.2.4.1">(-25.06%)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.3.3">
<td class="ltx_td ltx_align_center" id="S3.T1.5.3.3.1">Without PE</td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.3.3.2">85.24</td>
<td class="ltx_td" id="S3.T1.5.3.3.3"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.3.3.4">85.24 <span class="ltx_text ltx_font_bold" id="S3.T1.5.3.3.4.1">(0%)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.4.4">
<td class="ltx_td ltx_align_center" id="S3.T1.5.4.4.1">Without PE + Graph-FFN</td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.4.4.2">87.71</td>
<td class="ltx_td" id="S3.T1.5.4.4.3"></td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.4.4.4">87.71 <span class="ltx_text ltx_font_bold" id="S3.T1.5.4.4.4.1">(0%)</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">CapeFormer introduced a keypoint positional encoding (PE), termed the "Support Keypoint Identifier". This encoding is generated via sinusoidal encoding of the keypoints‚Äô order.
We analyzed this feature thoroughly and present the results in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S3.T1" title="Table 1 ‚Ä£ 3.3 Encoding Structure: Positional Encoding VS Graph Network ‚Ä£ 3 Method ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a>.
As shown, this encoding improves performance by a significant 4% PCK (defined later), at the cost of introducing a dependency on the order of keypoints.
This became evident when we evaluated a model trained with this positional encoding on data of keypoints in permuted order. Using PE and shuffling the keypoints results in a notable decrease of approximately 25% in PCK, indicating that the model had become highly specialized for a specific keypoint format. This sharp decrease is not present when the positional encoding is not used.
Although the dataset contains diverse object categories, some of them share a common keypoint ordering.
This indicates that using this PE adds structure information, learned from known categories in the training set.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">As we require invariance to keypoint permutations, graph structure is an obvious choice. Our graph-based approach serves as an alternative, boosting performance while being agnostic to permutations in the order of nodes.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Following previous CAPE works, we use the MP-100 dataset¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite> for training and evaluation, comprising samples drawn from existing category-specific pose estimation datasets.
The MP-100 dataset encompasses a collection of over 20,000 images, spanning 100 distinct categories, with varying keypoint numbers up to 68 across different categories.
To ensure categories used for evaluation remain unseen during the training process, the samples are divided into five different mutually exclusive splits.
The dataset includes partial skeleton annotations in various formats, including differences in the indexing of keypoints (some start from zero while others from one). We adopted a unified format with comprehensive skeleton definitions for all categories (skeleton annotations are shared among categories). This process involved cross-referencing the original datasets and, where necessary, conducting manual annotations.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">To quantify our model‚Äôs performance, we employ the Probability of Correct Keypoint (PCK) metric¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib42" title="">42</a>]</cite>, with a PCK threshold set at 0.2, following previous conventions¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite>.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.1 </span>CapeFormer-T.</h4>
<div class="ltx_para" id="S4.SS0.SSS1.p1">
<p class="ltx_p" id="S4.SS0.SSS1.p1.1">In the following sections, we compare our model to previous works along with an updated version of the previous state-of-the-art method which we call CapeFormer-T.
For this baseline, we replaced the original ResNet-50¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib13" title="">13</a>]</cite> backbone with a stronger transformer-based SwinV2-T¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib21" title="">21</a>]</cite>. After testing various configurations, including multi-scale and single-scale feature maps, we found that applying bilinear upsampling on the final feature layer achieved comparable results while maintaining simplicity. To capitalize on the improved feature quality we extract keypoint features using a Gaussian kernel mask with lower variance.
We believe that CAPE should not enforce a specific keypoint order. Therefore, following the discussion in the previous section, we removed keypoint positional encoding.
These simple adjustments led to an improvement of 0.94% over the original CapeFormer. We provide a short description of the different components of CapeFormer in the supplementary.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS1.p2">
<p class="ltx_p" id="S4.SS0.SSS1.p2.1">It is important to note that the difference between CapeFormer-T and our method GraphCape, is the graph-based decoder design, which utilizes the graph structure during training and inference. Thus any performance difference between these models is a result of using our graph-oriented architecture.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implementation Details</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.3">For a fair comparison, network parameters, training parameters, data augmentations and data pre-processing are kept the same as CapeFormer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite>:
Both the encoder and decoder have three layers and <math alttext="\lambda_{heatmap}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">Œª</mi><mrow id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">h</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">e</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1a" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.4" xref="S4.SS1.p1.1.m1.1.1.3.4.cmml">a</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1b" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.5" xref="S4.SS1.p1.1.m1.1.1.3.5.cmml">t</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1c" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.6" xref="S4.SS1.p1.1.m1.1.1.3.6.cmml">m</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1d" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.7" xref="S4.SS1.p1.1.m1.1.1.3.7.cmml">a</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1e" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.8" xref="S4.SS1.p1.1.m1.1.1.3.8.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ùúÜ</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><times id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">‚Ñé</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">ùëí</ci><ci id="S4.SS1.p1.1.m1.1.1.3.4.cmml" xref="S4.SS1.p1.1.m1.1.1.3.4">ùëé</ci><ci id="S4.SS1.p1.1.m1.1.1.3.5.cmml" xref="S4.SS1.p1.1.m1.1.1.3.5">ùë°</ci><ci id="S4.SS1.p1.1.m1.1.1.3.6.cmml" xref="S4.SS1.p1.1.m1.1.1.3.6">ùëö</ci><ci id="S4.SS1.p1.1.m1.1.1.3.7.cmml" xref="S4.SS1.p1.1.m1.1.1.3.7">ùëé</ci><ci id="S4.SS1.p1.1.m1.1.1.3.8.cmml" xref="S4.SS1.p1.1.m1.1.1.3.8">ùëù</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\lambda_{heatmap}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_Œª start_POSTSUBSCRIPT italic_h italic_e italic_a italic_t italic_m italic_a italic_p end_POSTSUBSCRIPT</annotation></semantics></math> is set to <math alttext="2.0" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">2.0</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn id="S4.SS1.p1.2.m2.1.1.cmml" type="float" xref="S4.SS1.p1.2.m2.1.1">2.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">2.0</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">2.0</annotation></semantics></math>.
The model is built upon MMPose framework¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib5" title="">5</a>]</cite>, trained using Adam optimizer for 200 epochs with a batch size of 16, the learning rate is <math alttext="10^{-5}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><msup id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mn id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">10</mn><mrow id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml"><mo id="S4.SS1.p1.3.m3.1.1.3a" xref="S4.SS1.p1.3.m3.1.1.3.cmml">‚àí</mo><mn id="S4.SS1.p1.3.m3.1.1.3.2" xref="S4.SS1.p1.3.m3.1.1.3.2.cmml">5</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">superscript</csymbol><cn id="S4.SS1.p1.3.m3.1.1.2.cmml" type="integer" xref="S4.SS1.p1.3.m3.1.1.2">10</cn><apply id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><minus id="S4.SS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3"></minus><cn id="S4.SS1.p1.3.m3.1.1.3.2.cmml" type="integer" xref="S4.SS1.p1.3.m3.1.1.3.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>, and decays by 10√ó on the 160th and 180th epoch. More design choices and evaluations are in the supplementary.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Qualitative Results</h3>
<figure class="ltx_figure" id="S4.F5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F5.18">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F5.18.19.1">
<td class="ltx_td ltx_align_center" id="S4.F5.18.19.1.1"><span class="ltx_text" id="S4.F5.18.19.1.1.1" style="font-size:70%;">Support</span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.18.19.1.2"><span class="ltx_text" id="S4.F5.18.19.1.2.1" style="font-size:70%;">GT</span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.18.19.1.3"><span class="ltx_text" id="S4.F5.18.19.1.3.1" style="font-size:70%;">POMNet</span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.18.19.1.4"><span class="ltx_text" id="S4.F5.18.19.1.4.1" style="font-size:70%;">CapeFromer</span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.18.19.1.5"><span class="ltx_text" id="S4.F5.18.19.1.5.1" style="font-size:70%;">CapeFormer-T</span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.18.19.1.6"><span class="ltx_text ltx_font_bold" id="S4.F5.18.19.1.6.1" style="font-size:70%;">GraphCape</span></td>
</tr>
<tr class="ltx_tr" id="S4.F5.6.6">
<td class="ltx_td ltx_align_center" id="S4.F5.1.1.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.1.1.1.1" style="font-size:70%;border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.1.1.1.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/23_0.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.2.2.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.2.2.2.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.2.2.2.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/23_1_GT.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.3.3.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.3.3.3.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.3.3.3.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/5_1.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.4.4.4"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.4.4.4.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.4.4.4.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/3_1.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.5.5.5"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.5.5.5.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.5.5.5.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/23_1_BASE.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.6.6.6"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.6.6.6.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.6.6.6.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/23_1.png" width="90"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F5.12.12">
<td class="ltx_td ltx_align_center" id="S4.F5.7.7.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.7.7.1.1" style="font-size:70%;border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.7.7.1.1.g1" src="extracted/5725098/Figures/4_qualitative/70_0.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.8.8.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.8.8.2.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.8.8.2.1.g1" src="extracted/5725098/Figures/4_qualitative/70_1_gt.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.9.9.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.9.9.3.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.9.9.3.1.g1" src="extracted/5725098/Figures/4_qualitative/pam_52_1.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.10.10.4"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.10.10.4.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.10.10.4.1.g1" src="extracted/5725098/Figures/4_qualitative/c50_1.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.11.11.5"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.11.11.5.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.11.11.5.1.g1" src="extracted/5725098/Figures/4_qualitative/base_70_1.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.12.12.6"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.12.12.6.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.12.12.6.1.g1" src="extracted/5725098/Figures/4_qualitative/70_1.png" width="90"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F5.18.18">
<td class="ltx_td ltx_align_center" id="S4.F5.13.13.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.13.13.1.1" style="font-size:70%;border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.13.13.1.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/27_0.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.14.14.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.14.14.2.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.14.14.2.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/81_1_GTV2.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.15.15.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.15.15.3.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.15.15.3.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/63_1V2.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.16.16.4"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.16.16.4.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.16.16.4.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/61_1V2.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.17.17.5"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.17.17.5.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.17.17.5.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/81_1_BASEV2.png" width="90"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F5.18.18.6"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F5.18.18.6.1" style="font-size:70%;border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="90" id="S4.F5.18.18.6.1.g1" src="extracted/5725098/Figures/4_qualitative/split2/27_1.png" width="90"/></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.23.1.1" style="font-size:129%;">Figure 5</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F5.24.2" style="font-size:129%;">Qualitative Results.<span class="ltx_text ltx_font_medium" id="S4.F5.24.2.1"> We visualize the keypoint predictions under a 1-shot setting. The left column denotes the support image with its corresponding skeleton. The second column is the ground-truth query keypoints. The following columns are results from POMNet, CapeFormer, CapeFormer-T, and our method.
</span></span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We show a qualitative comparison between our method, CapeFormer-T, and previous CAPE methods: CapeFormer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite> and POMNet<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We used POMNet official code to train and visualize results, as they don‚Äôt provide pre-trained models. Quantitative results are taken from the published paper.</span></span></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite> in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.F5" title="Figure 5 ‚Ä£ 4.2 Qualitative Results ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">5</span></a>.
As can be seen, the structure information incorporated in our method serves as a strong prior for localizing keypoints, helping in breaking symmetry and creating structure consistency between the keypoints. The first row of the figure shows an example of symmetry that confuses prior methods but not ours, while the third row shows our method‚Äôs superiority in preserving structure consistency across keypoints. More examples are in the supplementary.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Quantitative Results</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.3.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.4.2" style="font-size:90%;">
<span class="ltx_text ltx_font_bold" id="S4.T2.4.2.1">MP-100 Results.</span> PCK performance under 1-shot and 5-shot settings. In both settings, our approach consistently outperforms other methods, across all splits.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.5.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T2.5.1.1.1"></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T2.5.1.1.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.5.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.1.3.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.1.4">Split 1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.1.5">Split 2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.1.6">Split 3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.1.7">Split 4</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.1.1.8">Split 5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.5.1.1.9">Avg</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T2.5.2.2.1" rowspan="7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.2.2.1.1">1-Shot</span></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.5.2.2.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.2.2.3">ProtoNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib30" title="">30</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.2.4">46.05</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.2.5">40.84</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.2.6">49.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.2.7">43.34</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.2.2.8">44.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.2.2.9">44.78</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.3.3.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.3.3.2">MAML¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib9" title="">9</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.3.3.3">68.14</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.3.3.4">54.72</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.3.3.5">64.19</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.3.3.6">63.24</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.3.3.7">57.20</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.3.3.8">61.50</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.4.4">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.4.4.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.4.4.2">Fine-tuned¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib25" title="">25</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.4.3">70.60</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.4.4">57.04</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.4.5">66.06</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.4.6">65.00</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.4.4.7">59.20</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.4.4.8">63.58</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5.5">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.5.5.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.5.5.2">POMNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5.3">84.23</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5.4">78.25</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5.5">78.17</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5.6">78.68</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.5.5.7">79.17</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.5.5.8">79.70</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.6.6">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.6.6.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.6.6.2">CapeFormer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.6.3">89.45</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.6.4">84.88</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.6.5">83.59</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.6.6">83.53</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.6.6.7">85.09</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.6.6.8">85.31</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.7.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.5.7.7.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.7.7.2">CapeFormer-T</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.7.7.3">89.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.7.7.4">86.69</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.7.7.5">85.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.7.7.6">84.79</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.7.7.7">84.97</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.7.7.8">86.25</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.8.8">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.8.8.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.8.8.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.2.1">GraphCape</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.8.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.3.1">91.19</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.8.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.4.1">87.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.5.1">85.68</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.8.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.6.1">85.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.8.8.7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.7.1">85.61</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.8.8"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.8.8.1">87.23</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T2.5.9.9.1" rowspan="7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.9.9.1.1">5-Shot</span></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.5.9.9.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.9.9.3">ProtoNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib30" title="">30</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.9.9.4">60.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.9.9.5">53.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.9.9.6">61.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.9.9.7">58.44</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.9.9.8">58.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.9.9.9">58.56</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.10.10">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.10.10.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.10.10.2">MAML¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib9" title="">9</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.10.3">70.03</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.10.4">55.98</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.10.5">63.21</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.10.6">64.79</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.10.10.7">58.47</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.10.8">62.50</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.11.11">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.11.11.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.11.11.2">Fine-tuned¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib25" title="">25</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.11.3">71.67</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.11.4">57.84</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.11.5">66.76</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.11.6">66.53</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.11.11.7">60.24</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.11.8">64.61</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.12.12">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.12.12.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.12.12.2">POMNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.12.3">84.72</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.12.4">79.61</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.12.5">78.00</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.12.6">80.38</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.12.12.7">80.85</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.12.8">80.71</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.13.13">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.5.13.13.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.13.13.2">CapeFormer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.13.3">91.94</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.13.4">88.92</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.13.5">89.40</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.13.6">88.01</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.13.13.7">88.25</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.13.8">89.30</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.14.14">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.5.14.14.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.14.14.2">CapeFormer-T</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.14.14.3">94.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.14.14.4">91.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.14.14.5">89.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.14.14.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.14.14.6.1">90.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.14.14.7">89.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.14.14.8">90.90</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.15.15">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="S4.T2.5.15.15.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T2.5.15.15.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.15.15.2.1">GraphCape</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.15.15.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.15.15.3.1">94.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.15.15.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.15.15.4.1">91.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.15.15.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.15.15.5.1">90.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.15.15.6">90.37</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.5.15.15.7"><span class="ltx_text ltx_font_bold" id="S4.T2.5.15.15.7.1">89.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.5.15.15.8"><span class="ltx_text ltx_font_bold" id="S4.T2.5.15.15.8.1">91.16</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We compare our method with CapeFormer-T, previous CAPE methods CapeFormer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>]</cite> and POMNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>, and three baselines:
ProtoNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib30" title="">30</a>]</cite>, MAML¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib9" title="">9</a>]</cite>, and Fine-tuned¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib25" title="">25</a>]</cite>. Further details on these model‚Äôs evaluation can be found in¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>.
We report results on the MP-100 dataset under 1-shot and 5-shot settings in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.T2" title="Table 2 ‚Ä£ 4.3 Quantitative Results ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>. As can be seen, our graph-based method consistently improves performance over CapeFormer-T on the different dataset splits, on average by 0.98% under the 1-shot setting and 0.26% under the 5-shot setting, achieving new state-of-the-art results for both settings.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">In the supplementary, we also show better scalability of our design. Similar to DETR-based models, employing a larger backbone improves performance and our graph-based design also enhances performance using larger backbones. Furthermore, we show that our graph model scales better with the number of decoder layers compared to CapeFormer-T.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We conducted several ablation studies on the MP-100 dataset.
We first show quantitative examples using out-of-distribution images. Then, we display the contribution of the geometrical structure prior by evaluating our model using different skeleton relations. Then, we demonstrate the advantages of using graph structure in handling occlusions by evaluating the performance using masked inputs. Lastly, we test our model‚Äôs performance under a cross-category setting.
We perform all ablation experiments on the test set of MP-100 split1 under the 1-shot setting following¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib37" title="">37</a>]</cite>.
In the supplementary, we also show our model‚Äôs performance with various pre-trained backbones, aligning with DETER-based results¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#bib.bib19" title="">19</a>]</cite> regarding the preferred backbone.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Out-of-Distribution Performance.</h4>
<div class="ltx_para" id="S4.SS4.SSS1.p1">
<p class="ltx_p" id="S4.SS4.SSS1.p1.1">To assess the robustness of our model, we evaluate our network using images from different domains. Results are shown in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.F6" title="Figure 6 ‚Ä£ 4.4.1 Out-of-Distribution Performance. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">6</span></a>. Our model, which was trained on real images only, demonstrates its adaptability and effectiveness across varying data sources such as cartoons and imaginary animals, created using a text-to-image diffusion model.
Furthermore, our model performs satisfactorily even when the support and query images are from different domains.
However, when the images are from vastly different categories from the ones seen during training, the performance degrades.
Yet, this is common to all CAPE methods and doesn‚Äôt relate to using graphs.</p>
</div>
<figure class="ltx_figure" id="S4.F6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F6.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F6.4.4">
<td class="ltx_td ltx_align_center" id="S4.F6.1.1.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.1.1.1.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.1.1.1.1.g1" src="extracted/5725098/Figures/4_OOD/0_0.png" width="120"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F6.2.2.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.2.2.2.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.2.2.2.1.g1" src="extracted/5725098/Figures/4_OOD/2_0.png" width="120"/></span></td>
<td class="ltx_td" id="S4.F6.4.4.5"></td>
<td class="ltx_td ltx_align_center" id="S4.F6.3.3.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.3.3.3.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.3.3.3.1.g1" src="extracted/5725098/Figures/4_OOD/9_0.png" width="120"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F6.4.4.4"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.4.4.4.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.4.4.4.1.g1" src="extracted/5725098/Figures/4_OOD/11_0.png" width="120"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F6.8.8">
<td class="ltx_td ltx_align_center" id="S4.F6.5.5.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.5.5.1.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.5.5.1.1.g1" src="extracted/5725098/Figures/4_OOD/0_1.png" width="120"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F6.6.6.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.6.6.2.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.6.6.2.1.g1" src="extracted/5725098/Figures/4_OOD/2_1.png" width="120"/></span></td>
<td class="ltx_td" id="S4.F6.8.8.5"></td>
<td class="ltx_td ltx_align_center" id="S4.F6.7.7.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.7.7.3.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.7.7.3.1.g1" src="extracted/5725098/Figures/4_OOD/9_1.png" width="120"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F6.8.8.4"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F6.8.8.4.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="120" id="S4.F6.8.8.4.1.g1" src="extracted/5725098/Figures/4_OOD/11_1.png" width="120"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F6.8.9.1">
<td class="ltx_td ltx_align_center" colspan="2" id="S4.F6.8.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.F6.8.9.1.1.1">(a)</span></td>
<td class="ltx_td" id="S4.F6.8.9.1.2"></td>
<td class="ltx_td ltx_align_center" colspan="2" id="S4.F6.8.9.1.3"><span class="ltx_text ltx_font_bold" id="S4.F6.8.9.1.3.1">(b)</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.15.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F6.16.2" style="font-size:90%;">Out-of-Distribution.<span class="ltx_text ltx_font_medium" id="S4.F6.16.2.1"> Qualitative results using OOD samples, <span class="ltx_text" id="S4.F6.16.2.1.1" style="color:#BF0040;">top</span> is the support image and <span class="ltx_text" id="S4.F6.16.2.1.2" style="color:#00E000;">bottom</span> the query. </span>(a)<span class="ltx_text ltx_font_medium" id="S4.F6.16.2.2">: Support and query are from the same OOD domain. </span>(b)<span class="ltx_text ltx_font_medium" id="S4.F6.16.2.3">: Support and query images are from different domains.
</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>The Contribution of Graph Structure.</h4>
<div class="ltx_para" id="S4.SS4.SSS2.p1">
<p class="ltx_p" id="S4.SS4.SSS2.p1.1">To assess the contribution of the graph structure prior, we evaluate our method using different graph inputs. Results are shown in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.T3" title="Table 3 ‚Ä£ 4.4.2 The Contribution of Graph Structure. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a>.
Training and evaluating the graph model without node‚Äôs connectivity, the model is equivalent to CapeFormer-T, thus performing the same.
Moreover, training the model on fully-connected graphs results in a similar performance to CapeFormer-T as mathematically it is equivalent to adding a bias vector to all nodes, which is normalized and canceled. And again, performance is similar to CapeFormer-T (intuitively, as all graph inputs are the same, no new information is provided).
When providing random graphs the model‚Äôs performance degrades as wrong connectivity involves inferior semantic features for localization.
This shows a limitation of using graphs, as the wrong skeleton data may impair performance.
Lastly, we show in the supplementary that different graph definitions may result in different performances. However, we noticed empirically that most straightforward skeletal definitions produce similar results. Furthermore, as we didn‚Äôt optimize the dataset skeletons, we believe that further quantitative improvements can be made using optimal skeletal relations. Thus, we defer the exploration of the optimal skeletons to future research.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.4.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.5.2" style="font-size:90%;">
<span class="ltx_text ltx_font_bold" id="S4.T3.5.2.1">Different Graph Connectivity:</span> We evaluate our graph-oriented network, training and evaluating with different types of graph definitions.
</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.2"><span class="ltx_text" id="S4.T3.1.1.2.1" style="font-size:90%;">Graph Structure</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1">
<span class="ltx_text" id="S4.T3.1.1.1.1" style="font-size:90%;">PCK</span><sub class="ltx_sub" id="S4.T3.1.1.1.2"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.1.2.1" style="font-size:90%;">0.2</span></sub>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.2.1.1"><span class="ltx_text" id="S4.T3.1.2.1.1.1" style="font-size:90%;">No Connectivity</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.2.1.2"><span class="ltx_text" id="S4.T3.1.2.1.2.1" style="font-size:90%;">89.48</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T3.1.3.2.1"><span class="ltx_text" id="S4.T3.1.3.2.1.1" style="font-size:90%;">Fully Connected</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.3.2.2"><span class="ltx_text" id="S4.T3.1.3.2.2.1" style="font-size:90%;">89.35</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.3.1"><span class="ltx_text" id="S4.T3.1.4.3.1.1" style="font-size:90%;">Random Graphs (each instance)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.3.2"><span class="ltx_text" id="S4.T3.1.4.3.2.1" style="font-size:90%;">81.49</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.4.1"><span class="ltx_text" id="S4.T3.1.5.4.1.1" style="font-size:90%;">Random Graphs (each category)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.4.2"><span class="ltx_text" id="S4.T3.1.5.4.2.1" style="font-size:90%;">88.10</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.5.1"><span class="ltx_text" id="S4.T3.1.6.5.1.1" style="font-size:90%;">Pose Graph</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.5.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.2.1" style="font-size:90%;">91.19</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.3 </span>Masking Support/Query Images.</h4>
<div class="ltx_para" id="S4.SS4.SSS3.p1">
<p class="ltx_p" id="S4.SS4.SSS3.p1.1">To highlight the contribution of graph information in handling occlusions, we applied partial masking to the support/query image before executing our algorithm. It is important to note that the difference between the two compared models is our suggested graph-based decoder.
Quantitative analysis in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.F7.sf1" title="Figure 7(a) ‚Ä£ Figure 7 ‚Ä£ 4.4.3 Masking Support/Query Images. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">7(a)</span></a> shows our method consistently outperforming CapeFormer-T. The dashed horizontal line represents the identity operation which outputs the support keypoint‚Äôs locations, preserving structure.
Notably, our model can predict keypoints even when a significant portion of the support image is masked. This suggests that the model has learned which keypoints are relevant and matches them based on structure.
For instance, in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.F7.sf2" title="Figure 7(b) ‚Ä£ Figure 7 ‚Ä£ 4.4.3 Masking Support/Query Images. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">7(b)</span></a> (top), the model accurately predicts most keypoints. In comparison, CapeFormer-T is confused by symmetry, breaking the structure of the sofa.
However, when large portions of the query image are masked, the model‚Äôs performance rapidly declines, although it retains structure, as evident in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.F7.sf2" title="Figure 7(b) ‚Ä£ Figure 7 ‚Ä£ 4.4.3 Masking Support/Query Images. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">7(b)</span></a> (bottom).
This experiment suggests that our model better handles occlusions, which is crucial for real-world applications.
More examples are in the supplementary.
</p>
</div>
<figure class="ltx_figure" id="S4.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="394" id="S4.F7.sf1.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F7.sf2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.F7.sf2.8">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F7.sf2.4.4">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F7.sf2.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.1.1.1.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.1.1.1.1.g1" src="extracted/5725098/supp_figs/mask/support/84_0.png" width="138"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r" id="S4.F7.sf2.4.4.5" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.2.2.2.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.2.2.2.1.g1" src="extracted/5725098/supp_figs/mask/support/gt_84_1.png" width="138"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.3.3.3.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.3.3.3.1.g1" src="extracted/5725098/supp_figs/mask/support/base_84_1.png" width="138"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.4.4.4.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.4.4.4.1.g1" src="extracted/5725098/supp_figs/mask/support/84_1.png" width="138"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F7.sf2.8.8">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F7.sf2.5.5.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.5.5.1.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.5.5.1.1.g1" src="extracted/5725098/supp_figs/mask/query/73_0.png" width="138"/></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row" id="S4.F7.sf2.8.8.5" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.6.6.2" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.6.6.2.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.6.6.2.1.g1" src="extracted/5725098/supp_figs/mask/query/gt_73_1.png" width="138"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.7.7.3" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.7.7.3.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.7.7.3.1.g1" src="extracted/5725098/supp_figs/mask/query/base_73_1.png" width="138"/></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.8.8.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F7.sf2.8.8.4.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S4.F7.sf2.8.8.4.1.g1" src="extracted/5725098/supp_figs/mask/query/73_1.png" width="138"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F7.sf2.8.9.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F7.sf2.8.9.1.1" style="padding-left:1.0pt;padding-right:1.0pt;">Support</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r" id="S4.F7.sf2.8.9.1.2" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.8.9.1.3" style="padding-left:1.0pt;padding-right:1.0pt;">GT</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.8.9.1.4" style="padding-left:1.0pt;padding-right:1.0pt;">CapeFormer-T</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F7.sf2.8.9.1.5" style="padding-left:1.0pt;padding-right:1.0pt;">GraphCape</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.sf2.10.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.7.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F7.8.2" style="font-size:90%;">Masking.<span class="ltx_text ltx_font_medium" id="S4.F7.8.2.1">
</span>(a)<span class="ltx_text ltx_font_medium" id="S4.F7.8.2.2"> Quantitative results when masking the support/query images.
Our method consistently surpasses CapeFormer-T, leveraging cues provided by the graph structure to overcome information gaps in the support/query images.
</span>(b)<span class="ltx_text ltx_font_medium" id="S4.F7.8.2.3"> Qualitative results when masking the support (</span>top<span class="ltx_text ltx_font_medium" id="S4.F7.8.2.4">) and query (</span>bottom<span class="ltx_text ltx_font_medium" id="S4.F7.8.2.5">) image using CapeFormer-T and our graph-based model. Our model better handles occlusions by preserving structure and breaking symmetry.
</span></span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.4 </span>Cross-Category Correspondence.</h4>
<div class="ltx_para" id="S4.SS4.SSS4.p1">
<p class="ltx_p" id="S4.SS4.SSS4.p1.1">We test our model‚Äôs performance when the support and query images are from vastly different categories. Results can be seen in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2311.17891v2#S4.F8" title="Figure 8 ‚Ä£ 4.4.4 Cross-Category Correspondence. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experiments ‚Ä£ A Graph-Based Approach for Category-Agnostic Pose Estimation"><span class="ltx_text ltx_ref_tag">8</span></a>. CapeFormer-T correctly finds correspondence between the legs of the chair and of the horse. However, it mistakenly matches keypoints according to their location in the image and not according to the orientation of the objects. Our model breaks the symmetry between the leg keypoints and correctly matches keypoints with the correct 3D orientation.</p>
</div>
<figure class="ltx_figure" id="S4.F8">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F8.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F8.3.3">
<td class="ltx_td ltx_align_center" id="S4.F8.1.1.1"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F8.1.1.1.1" style="border-color: #BF0040;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="168" id="S4.F8.1.1.1.1.g1" src="extracted/5725098/Figures/4_cross/chair.png" width="168"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F8.2.2.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F8.2.2.2.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="168" id="S4.F8.2.2.2.1.g1" src="extracted/5725098/Figures/4_cross/horse_base.png" width="168"/></span></td>
<td class="ltx_td ltx_align_center" id="S4.F8.3.3.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.F8.3.3.3.1" style="border-color: #00E000;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="168" id="S4.F8.3.3.3.1.g1" src="extracted/5725098/Figures/4_cross/horse_ours.png" width="168"/></span></td>
</tr>
<tr class="ltx_tr" id="S4.F8.3.4.1">
<td class="ltx_td ltx_align_center" id="S4.F8.3.4.1.1">Support</td>
<td class="ltx_td ltx_align_center" id="S4.F8.3.4.1.2">Capefromer-T</td>
<td class="ltx_td ltx_align_center" id="S4.F8.3.4.1.3">GraphCape</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.6.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text ltx_font_bold" id="S4.F8.7.2" style="font-size:90%;">Cross-Category Correspondence<span class="ltx_text ltx_font_medium" id="S4.F8.7.2.1">. We test our model‚Äôs performance when the support and query images are from vastly different categories.
The difference lies in matching keypoints. CapeFormer-T matches keypoints naively, based on their location in the image.
In contrast, our model breaks the symmetry between the legs and correctly matches keypoints with the correct object 3D orientation.
</span></span></figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We present a novel approach for category-agnostic pose estimation (CAPE) by treating input keypoints as graphs, recognizing the importance of underlying geometrical structures within objects.
We implement this prior using a Graph-FFN, which captures and incorporates structural information by exploiting the relationships and dependencies between keypoints. This change significantly enhances the accuracy of keypoint localization.
In addition, we provide an updated version of the MP-100 dataset, which now includes skeleton annotations for all categories, further promoting research in CAPE.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Our experimental results demonstrate the superiority of our method over our updated version of the previous state-of-the-art approach, CapeFormer-T.
With improvements under both 1-shot and 5-shot settings, our method opens the door to more versatile and adaptable applications in computer vision.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.0.1 </span>Acknowledgement.</h4>
<div class="ltx_para" id="S5.SS0.SSS1.p1">
<p class="ltx_p" id="S5.SS0.SSS1.p1.1">Part of this research was supported by the Weinstein Institute and ISF grant 2132/23.</p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Cao, Z., Hidalgo Martinez, G., Simon, T., Wei, S., Sheikh, Y.A.: Openpose: Realtime multi-person 2d pose estimation using part affinity fields. IEEE Transactions on Pattern Analysis and Machine Intelligence (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-to-end object detection with transformers. In: European conference on computer vision. pp. 213‚Äì229. Springer (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Chen, W., Jia, X., Chang, H.J., Duan, J., Shen, L., Leonardis, A.: Fs-net: Fast shape-based network for category-level 6d object pose estimation with decoupled rotation mechanism. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 1581‚Äì1590 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Cheng, K., Zhang, Y., He, X., Chen, W., Cheng, J., Lu, H.: Skeleton-based action recognition with shift graph convolutional network. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 183‚Äì192 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Contributors, M.: Openmmlab pose estimation toolbox and benchmark. <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/open-mmlab/mmpose" title="">https://github.com/open-mmlab/mmpose</a> (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Dai, X., Chen, Y., Yang, J., Zhang, P., Yuan, L., Zhang, L.: Dynamic detr: End-to-end object detection with dynamic attention. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 2988‚Äì2997 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Fang, H.S., Li, J., Tang, H., Xu, C., Zhu, H., Xiu, Y., Li, Y.L., Lu, C.: Alphapose: Whole-body regional multi-person pose estimation and tracking in real-time. IEEE Transactions on Pattern Analysis and Machine Intelligence (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Fang, Y., Wang, W., Xie, B., Sun, Q., Wu, L., Wang, X., Huang, T., Wang, X., Cao, Y.: Eva: Exploring the limits of masked visual representation learning at scale. arXiv preprint arXiv:2211.07636 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Finn, C., Abbeel, P., Levine, S.: Model-agnostic meta-learning for fast adaptation of deep networks (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Gao, P., Zheng, M., Wang, X., Dai, J., Li, H.: Fast convergence of detr with spatially modulated co-attention. In: ICCV. pp. 3621‚Äì3630 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Hamilton, W.L., Ying, R., Leskovec, J.: Inductive representation learning on large graphs. In: NIPS. pp. 1025‚Äì1035 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Han, K., Wang, Y., Guo, J., Tang, Y., Wu, E.: Vision gnn: An image is worth graph of nodes. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib12.1.1">35</span>, 8291‚Äì8303 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770‚Äì778 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Jing, Y., Mao, Y., Yang, Y., Zhan, Y., Song, M., Wang, X., Tao, D.: Learning graph neural networks for image style transfer. In: ECCV (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Kreiss, S., Bertoni, L., Alahi, A.: Openpifpaf: Composite fields for semantic keypoint detection and spatio-temporal association. IEEE Transactions on Intelligent Transportation Systems <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">23</span>(8), 13498‚Äì13511 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Landrieu, L., Simonovsky, M.: Large-scale point cloud semantic segmentation with superpoint graphs. In: CVPR. pp. 4558‚Äì4567 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Li, Q., Han, Z., Wu, X.M.: Deeper insights into graph convolutional networks for semi-supervised learning. In: Proceedings of the AAAI conference on artificial intelligence. vol.¬†32 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Lian, R., Ling, H.: Checkerpose: Progressive dense keypoint localization for object pose estimation with graph neural network. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 14022‚Äì14033 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Lin, Y., Yuan, Y., Zhang, Z., Li, C., Zheng, N., Hu, H.: Detr does not need multi-scale or locality design. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 6545‚Äì6554 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Liu, S., Li, F., Zhang, H., Yang, X., Qi, X., Su, H., Zhu, J., Zhang, L.: Dab-detr: Dynamic anchor boxes are better queries for detr. arXiv preprint arXiv:2201.12329 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Liu, Z., Hu, H., Lin, Y., Yao, Z., Xie, Z., Wei, Y., Ning, J., Cao, Y., Zhang, Z., Dong, L., et¬†al.: Swin transformer v2: Scaling up capacity and resolution. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 12009‚Äì12019 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Liu, Z., Zhang, H., Chen, Z., Wang, Z., Ouyang, W.: Disentangling and unifying graph convolutions for skeleton-based action recognition. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 143‚Äì152 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Mao, W., Ge, Y., Shen, C., Tian, Z., Wang, X., Wang, Z.: Tfpose: Direct human pose estimation with transformers. arXiv preprint arXiv:2103.15320 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Meng, D., Chen, X., Fan, Z., Zeng, G., Li, H., Yuan, Y., Sun, L., Wang, J.: Conditional detr for fast training convergence. In: Proceedings of the IEEE International Conference on Computer Vision (ICCV) (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Nakamura, A., Harada, T.: Revisiting fine-tuning for few-shot learning. arXiv preprint arXiv:1910.00216 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Oono, K., Suzuki, T.: Graph neural networks exponentially lose expressive power for node classification. arXiv preprint arXiv:1905.10947 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Reddy, N.D., Vo, M., Narasimhan, S.G.: Carfusion: Combining point tracking and part detection for dynamic 3d reconstruction of vehicles. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 1906‚Äì1915 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., Eliassi-Rad, T.: Collective classification in network data. AI magazine <span class="ltx_text ltx_font_bold" id="bib.bib28.1.1">29</span>(3), 93‚Äì93 (2008)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Shi, M., Huang, Z., Ma, X., Hu, X., Cao, Z.: Matching is not enough: A two-stage framework for category-agnostic pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 7308‚Äì7317 (June 2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Snell, J., Swersky, K., Zemel, R.: Prototypical networks for few-shot learning. NeurIPS (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Song, X., Wang, P., Zhou, D., Zhu, R., Guan, C., Dai, Y., Su, H., Li, H., Yang, R.: Apollocar3d: A large 3d car instance understanding benchmark for autonomous driving. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 5452‚Äì5462 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Wale, N., Watson, I.A., Karypis, G.: Comparison of descriptor spaces for chemical compound retrieval and classification. Knowledge and Information Systems <span class="ltx_text ltx_font_bold" id="bib.bib32.1.1">14</span>(3), 347‚Äì375 (2008)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Wang, R., Yan, J., Yang, X.: Learning combinatorial embedding networks for deep graph matching. In: ICCV. pp. 3056‚Äì3065 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Wang, W., Dai, J., Chen, Z., Huang, Z., Li, Z., Zhu, X., Hu, X., Lu, T., Lu, L., Li, H., et¬†al.: Internimage: Exploring large-scale vision foundation models with deformable convolutions. arXiv preprint arXiv:2211.05778 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Wang, Y., Sun, Y., Liu, Z., Sarma, S.E., Bronstein, M.M., Solomon, J.M.: Dynamic graph cnn for learning on point clouds. Acm Transactions On Graphics (tog) <span class="ltx_text ltx_font_bold" id="bib.bib35.1.1">38</span>(5), 1‚Äì12 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Xu, D., Zhu, Y., Choy, C.B., Fei-Fei, L.: Scene graph generation by iterative message passing. In: CVPR. pp. 5410‚Äì5419 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Xu, L., Jin, S., Zeng, W., Liu, W., Qian, C., Ouyang, W., Luo, P., Wang, X.: Pose for everything: Towards category-agnostic pose estimation. In: European Conference on Computer Vision. pp. 398‚Äì416. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Xu, Y., Zhang, J., Zhang, Q., Tao, D.: Vitpose: Simple vision transformer baselines for human pose estimation. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib38.1.1">35</span>, 38571‚Äì38584 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Yan, S., Xiong, Y., Lin, D.: Spatial temporal graph convolutional networks for skeleton-based action recognition. In: AAAI (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Yang, J., Lu, J., Lee, S., Batra, D., Parikh, D.: Graph r-cnn for scene graph generation. In: ECCV. pp. 670‚Äì685 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Yang, S., Quan, Z., Nie, M., Yang, W.: Transpose: Keypoint localization via transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 11802‚Äì11812 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Yang, Y., Ramanan, D.: Articulated human detection with flexible mixtures of parts. IEEE transactions on pattern analysis and machine intelligence <span class="ltx_text ltx_font_bold" id="bib.bib42.1.1">35</span>(12), 2878‚Äì2890 (2012)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Yang, Y., Yang, J., Xu, Y., Zhang, J., Lan, L., Tao, D.: Apt-36k: A large-scale benchmark for animal pose estimation and tracking. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib43.1.1">35</span>, 17301‚Äì17313 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Yu, H., Xu, Y., Zhang, J., Zhao, W., Guan, Z., Tao, D.: Ap-10k: A benchmark for animal pose estimation in the wild. In: Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2) (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Zhang, H., Li, F., Liu, S., Zhang, L., Su, H., Zhu, J., Ni, L.M., Shum, H.Y.: Dino: Detr with improved denoising anchor boxes for end-to-end object detection. arXiv preprint arXiv:2203.03605 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Zhang, S., Zhao, W., Guan, Z., Peng, X., Peng, J.: Keypoint-graph-driven learning framework for object pose estimation. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 1065‚Äì1073 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Zhou, G., Wang, H., Chen, J., Huang, D.: Pr-gcn: A deep graph convolutional network with point refinement for 6d pose estimation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 2793‚Äì2802 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J.: Deformable detr: Deformable transformers for end-to-end object detection. arXiv preprint arXiv:2010.04159 (2020)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jul 11 12:49:57 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
