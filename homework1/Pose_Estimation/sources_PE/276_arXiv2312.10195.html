<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation</title>
<!--Generated on Fri Dec 15 20:42:44 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.10195v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1 Introduction ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S2" title="2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>RELATED WORK</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S2.SS1" title="2.1 3D human pose Estimation of Videos ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>3D human pose Estimation of Videos</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S2.SS1.SSS1" title="2.1.1 Many-to-One Models ‣ 2.1 3D human pose Estimation of Videos ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>Many-to-One Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S2.SS1.SSS2" title="2.1.2 Two-stage 3D Human Pose Estimation Methods ‣ 2.1 3D human pose Estimation of Videos ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Two-stage 3D Human Pose Estimation Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S2.SS1.SSS3" title="2.1.3 Heatmap Representations of Pose Estimation ‣ 2.1 3D human pose Estimation of Videos ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.3 </span>Heatmap Representations of Pose Estimation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S2.SS2" title="2.2 Dataset Constraints ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Dataset Constraints</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S2.SS2.SSS1" title="2.2.1 3D Human Pose Estimation Datasets ‣ 2.2 Dataset Constraints ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>3D Human Pose Estimation Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S2.SS2.SSS2" title="2.2.2 Existing Dataset Limitations ‣ 2.2 Dataset Constraints ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Existing Dataset Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S2.SS2.SSS3" title="2.2.3 Data Augmentation Methodologies ‣ 2.2 Dataset Constraints ‣ 2 RELATED WORK ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.3 </span>Data Augmentation Methodologies</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S3" title="3 3D AugMotion Toolkit: Dataset Augmentation Methodology ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>3D AugMotion Toolkit: Dataset Augmentation Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS1" title="3.1 Key Frames ‣ 3 3D AugMotion Toolkit: Dataset Augmentation Methodology ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Key Frames</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS2" title="3.2 Methodology for Defining a Universal Coordinate System ‣ 3 3D AugMotion Toolkit: Dataset Augmentation Methodology ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Methodology for Defining a Universal Coordinate System</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S3.SS3" title="3.3 Kabsch Algorithm ‣ 3 3D AugMotion Toolkit: Dataset Augmentation Methodology ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Kabsch Algorithm</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S4" title="4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>SoloPose: One-shot 3D human pose estimation network</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S4.SS1" title="4.1 Spatio-temporal transformer ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Spatio-temporal transformer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S4.SS2" title="4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>HeatPose: 3D Gaussian heatmap</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S5" title="5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments and results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S5.SS1" title="5.1 Datasets ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S5.SS2" title="5.2 Evaluation Metrics ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S5.SS3" title="5.3 Comparison with the State-of-the-art ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Comparison with the State-of-the-art</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S5.SS4" title="5.4 Ablation Study ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S5.SS4.SSS1" title="5.4.1 Analysis without 3D Gaussian Heatmap ‣ 5.4 Ablation Study ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.1 </span>Analysis without 3D Gaussian Heatmap</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="#S5.SS4.SSS2" title="5.4.2 Analysis without Data Augmentation ‣ 5.4 Ablation Study ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4.2 </span>Analysis without Data Augmentation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S6" title="6 CONCLUSION ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>CONCLUSION</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div aria-label="”Conversion" been="" class="package-alerts ltx_document" errors="" found”="" have="" role="“status”">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: epic</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of <a href="https://corpora.mathweb.org/corpus/arxmliv/tex_to_html/info/loaded_file" target="_blank">supported packages</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2312.10195v1 [cs.CV] 15 Dec 2023</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">David C. Jeong, Hongji Liu, Saunder Salazar, Jessie Jiang, Christopher A. Kitts 
<br class="ltx_break"/>Santa Clara University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1" style="font-size:90%;">dcjeong@scu.edu, hliu4@scu.edu, ssalazar@scu.edu jjiang3@scu.edu, ckitts@scu.edu</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">While recent two-stage many-to-one deep learning models have demonstrated great success in 3D human pose estimation, such models are inefficient ways to detect 3D key points in a sequential video relative to one-shot and many-to-many models. Another key drawback of two-stage and many-to-one models is that errors in the first stage will be passed onto the second stage. In this paper, we introduce SoloPose, a novel one-shot, many-to-many spatio-temporal transformer model for kinematic 3D human pose estimation of video. SoloPose is further fortified by HeatPose, a 3D heatmap based on Gaussian Mixture Model distributions that factors target key points as well as kinematically adjacent key points. Finally, we address data diversity constraints with the 3D AugMotion Toolkit, a methodology to augment existing 3D human pose datasets, specifically by projecting four top public 3D human pose datasets (Humans3.6M, MADS, AIST Dance++, MPI INF 3DHP) into a novel dataset (Humans7.1M) with a universal coordinate system. Extensive experiments are conducted on Human3.6M as well as the augmented Humans7.1M dataset, and SoloPose demonstrates superior results relative to the state-of-the-art approaches.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Monocular pose estimation takes 2D images or videos as input, and generates 2D or 3D coordinates of skeletal key points. This task has a variety of applications such as action recognition, sports analysis, medical rehabilitation, and collaborative robotics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>, <a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>.
Models to generate 2D skeleton key points have been greatly improved in recent years <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>, but there is still room for improvement for 3D human pose estimators due to the following.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">First, there is a lack of high-quality 3D datasets for pose estimation. Many pose estimation models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite> are trained on Human3.6M <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>, which is limited in image resolution and data diversity (e.g., limited actors, actions) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>]</cite>. The disproportionate use of the Human3.6M dataset constrains the accuracy and efficiency of existing 3D human pose estimation models. The natural solution to such data diversity issues is to train on alternative datsets, such as MADS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>, AIST Dance++<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> and MPI INF 3DHP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>. Of course, each additional dataset requires respective training
due their unique marker format, data distribution, and ground truth. Ultimately, addressing data diversity issues with alternative datasets presents added costs in training time and performance accuracy on data in-the-wild, thus severely constraining downstream applications.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Second, most 3D human pose estimators are two-stage models  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite> that are a) highly dependent on the accuracy of 2D estimators, and b) solely take 2D skeletal keypoints as input, thus omitting valuable contextual information needed for computational efficiency during 3D human pose estimation.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Finally, recent pose estimators utilize transformers as the deep learning network<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>. Most video-based models process frames in a time-consuming many-to-one approach<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>, which take multiple frames as input but select solely the middle frame to estimate coordinates, neglecting frames at the beginning and end of videos.</p>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Complexity Hierarchy in 3D Human Pose Estimation</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S1.T1.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.4.1.1">
<td class="ltx_td ltx_border_tt" id="S1.T1.4.1.1.1"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.2"><span class="ltx_text" id="S1.T1.4.1.1.2.1" style="font-size:90%;">single person</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.3"><span class="ltx_text" id="S1.T1.4.1.1.3.1" style="font-size:90%;">3D human pose</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.4"><span class="ltx_text" id="S1.T1.4.1.1.4.1" style="font-size:90%;">video input</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.5"><span class="ltx_text" id="S1.T1.4.1.1.5.1" style="font-size:90%;">single stage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.6"><span class="ltx_text" id="S1.T1.4.1.1.6.1" style="font-size:90%;">many-to-many</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.7"><span class="ltx_text" id="S1.T1.4.1.1.7.1" style="font-size:90%;">data augmentation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.8"><span class="ltx_text" id="S1.T1.4.1.1.8.1" style="font-size:90%;">heatmap</span></th>
</tr>
<tr class="ltx_tr" id="S1.T1.4.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.1">
<span class="ltx_text" id="S1.T1.4.2.2.1.1" style="font-size:90%;">STCFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.2.2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib22" title="">22</a><span class="ltx_text" id="S1.T1.4.2.2.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.2"><span class="ltx_text" id="S1.T1.4.2.2.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.3"><span class="ltx_text" id="S1.T1.4.2.2.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.4"><span class="ltx_text" id="S1.T1.4.2.2.4.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.5"><span class="ltx_text ltx_font_bold" id="S1.T1.4.2.2.5.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.2.2.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.2.2.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.2.2.8"><span class="ltx_text ltx_font_bold" id="S1.T1.4.2.2.8.1" style="font-size:90%;color:#FF0000;">×</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.3.3">
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.1">
<span class="ltx_text" id="S1.T1.4.3.3.1.1" style="font-size:90%;">P-STMO </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.3.3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib20" title="">20</a><span class="ltx_text" id="S1.T1.4.3.3.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.2"><span class="ltx_text" id="S1.T1.4.3.3.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.3"><span class="ltx_text" id="S1.T1.4.3.3.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.4"><span class="ltx_text" id="S1.T1.4.3.3.4.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.5"><span class="ltx_text ltx_font_bold" id="S1.T1.4.3.3.5.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.3.3.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.3.3.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.3.3.8"><span class="ltx_text ltx_font_bold" id="S1.T1.4.3.3.8.1" style="font-size:90%;color:#FF0000;">×</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.4.4">
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.1">
<span class="ltx_text" id="S1.T1.4.4.4.1.1" style="font-size:90%;">MHFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.4.4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib8" title="">8</a><span class="ltx_text" id="S1.T1.4.4.4.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.2"><span class="ltx_text" id="S1.T1.4.4.4.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.3"><span class="ltx_text" id="S1.T1.4.4.4.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.4"><span class="ltx_text" id="S1.T1.4.4.4.4.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.5"><span class="ltx_text ltx_font_bold" id="S1.T1.4.4.4.5.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.4.4.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.4.4.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.4.4.8"><span class="ltx_text ltx_font_bold" id="S1.T1.4.4.4.8.1" style="font-size:90%;color:#FF0000;">×</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.5.5">
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.1">
<span class="ltx_text" id="S1.T1.4.5.5.1.1" style="font-size:90%;">PoseFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.5.5.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib27" title="">27</a><span class="ltx_text" id="S1.T1.4.5.5.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.2"><span class="ltx_text" id="S1.T1.4.5.5.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.3"><span class="ltx_text" id="S1.T1.4.5.5.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.4"><span class="ltx_text" id="S1.T1.4.5.5.4.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.5"><span class="ltx_text ltx_font_bold" id="S1.T1.4.5.5.5.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.5.5.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.5.5.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.5.5.8"><span class="ltx_text ltx_font_bold" id="S1.T1.4.5.5.8.1" style="font-size:90%;color:#FF0000;">×</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.6.6">
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.1">
<span class="ltx_text" id="S1.T1.4.6.6.1.1" style="font-size:90%;">Coarse-to-fine </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.6.6.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib13" title="">13</a><span class="ltx_text" id="S1.T1.4.6.6.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.2"><span class="ltx_text" id="S1.T1.4.6.6.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.3"><span class="ltx_text" id="S1.T1.4.6.6.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.4"><span class="ltx_text ltx_font_bold" id="S1.T1.4.6.6.4.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.5"><span class="ltx_text" id="S1.T1.4.6.6.5.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.6.6.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.6.6.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.6.6.8"><span class="ltx_text" id="S1.T1.4.6.6.8.1" style="font-size:90%;color:#00FF00;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.7.7">
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.1">
<span class="ltx_text" id="S1.T1.4.7.7.1.1" style="font-size:90%;">Geometry-Aware </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.7.7.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib18" title="">18</a><span class="ltx_text" id="S1.T1.4.7.7.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.2"><span class="ltx_text" id="S1.T1.4.7.7.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.3"><span class="ltx_text" id="S1.T1.4.7.7.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.4"><span class="ltx_text ltx_font_bold" id="S1.T1.4.7.7.4.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.5"><span class="ltx_text" id="S1.T1.4.7.7.5.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.7.7.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.7"><span class="ltx_text" id="S1.T1.4.7.7.7.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.7.7.8"><span class="ltx_text ltx_font_bold" id="S1.T1.4.7.7.8.1" style="font-size:90%;color:#FF0000;">×</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.8.8">
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.1">
<span class="ltx_text" id="S1.T1.4.8.8.1.1" style="font-size:90%;">MeTRAbs </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.8.8.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib19" title="">19</a><span class="ltx_text" id="S1.T1.4.8.8.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.2"><span class="ltx_text" id="S1.T1.4.8.8.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.3"><span class="ltx_text" id="S1.T1.4.8.8.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.4"><span class="ltx_text ltx_font_bold" id="S1.T1.4.8.8.4.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.5"><span class="ltx_text" id="S1.T1.4.8.8.5.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.8.8.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.8.8.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.8.8.8"><span class="ltx_text ltx_font_bold" id="S1.T1.4.8.8.8.1" style="font-size:90%;color:#FF0000;">×</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.9.9">
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.1">
<span class="ltx_text" id="S1.T1.4.9.9.1.1" style="font-size:90%;">HEMlets </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.T1.4.9.9.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="#bib.bib28" title="">28</a><span class="ltx_text" id="S1.T1.4.9.9.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.2"><span class="ltx_text" id="S1.T1.4.9.9.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.3"><span class="ltx_text" id="S1.T1.4.9.9.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.4"><span class="ltx_text ltx_font_bold" id="S1.T1.4.9.9.4.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.5"><span class="ltx_text" id="S1.T1.4.9.9.5.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.6"><span class="ltx_text ltx_font_bold" id="S1.T1.4.9.9.6.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.7"><span class="ltx_text ltx_font_bold" id="S1.T1.4.9.9.7.1" style="font-size:90%;color:#FF0000;">×</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.4.9.9.8"><span class="ltx_text" id="S1.T1.4.9.9.8.1" style="font-size:90%;color:#00FF00;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.4.10.10">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.1"><span class="ltx_text" id="S1.T1.4.10.10.1.1" style="font-size:90%;">Our SoloPose</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.2"><span class="ltx_text" id="S1.T1.4.10.10.2.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.3"><span class="ltx_text" id="S1.T1.4.10.10.3.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.4"><span class="ltx_text" id="S1.T1.4.10.10.4.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.5"><span class="ltx_text" id="S1.T1.4.10.10.5.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.6"><span class="ltx_text" id="S1.T1.4.10.10.6.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.7"><span class="ltx_text" id="S1.T1.4.10.10.7.1" style="font-size:90%;color:#00FF00;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.4.10.10.8"><span class="ltx_text" id="S1.T1.4.10.10.8.1" style="font-size:90%;color:#00FF00;">✓</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In sum, 3D human pose estimators are constrained by limitations in 1) 3D human pose datasets, 2) two-stage models, and 3) many-to-one approaches. To address these challenges, we propose the following contributions:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We introduce <span class="ltx_text ltx_font_italic" id="S1.I1.i1.p1.1.1">SoloPose<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote1.1.1.1">1</span></span><span class="ltx_text ltx_font_upright" id="footnote1.9">All relevant code and documentation may be found on GitHub: http://tinyurl.com/3m488z83</span></span></span></span></span>, a cost-efficient one-shot, many-to-many spatio-temporal transformer model of 3D human pose estimation that takes frame sequences of monocular 2D video as input to directly estimate 3D key point coordinates.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose the <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">3D AugMotion Toolkit </span>to augment existing datasets (e.g., Humans3.6M, MADS, AIST Dance++, MPI INF 3DHP) by increasing diversity and reducing noise, yielding an augmented dataset that we refer to as <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.2">Humans7.1M</span>.
</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Finally, we introduce <span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.1">HeatPose</span>, a 3D heatmap based on GMM, which represents kinematically adjacent information of each given target key point, including key point labels, distance, and direction. We utilize cross entropy as a loss function in SoloPose instead of MSE loss to improve the accuracy of 3D coordinates.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">We structure the current work as follows. First, we discuss related work of the current state-of-the-art in monocular 3D human pose estimation as well as prevailing 3D human pose video datasets. Second, we introduce the 3D Augmotion Toolkit, a methodology to augment 3D human pose datasets using universal coordinate systems, which we leverage to generate our Humans7.1M dataset. Third, we introduce SoloPose, a one-shot, many-to-many spatio-temporal transformer for 3D human pose estimation, which is fortified by our 3D GMM-based heatmap (HeatPose). Next, we demonstrate SoloPose’s performance by comparing SOTA methods, as well as comparing existing Humans3.6M and our Humans7.1M datasets. Finally, we conduct ablation studies to test our contributions, namely HeatPose (i.e., 3D Gaussian heatmap) and AugMotion (i.e., 3D human pose data augmentation).</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>RELATED WORK</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In the following, we present the constraints and limitations in existing a) 3D human pose estimation model methodologies, namely an observed prevalence of many-to-one video frame approaches, two-stage, and key point regression methodologies, and b) 3D human pose datasets.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>3D human pose Estimation of Videos</h3>
<section class="ltx_subsubsection" id="S2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Many-to-One Models</h4>
<div class="ltx_para" id="S2.SS1.SSS1.p1">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">While single-image pose estimation performance is well-established<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib21" title="">21</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>, pose estimation of sequences of multiple frames (i.e., videos) is the focus of recent research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>. Pose estimation of sequential frames leverages temporal information to address occlusion issues. That being said, most video-based pose estimation models take a many-to-one approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>, which estimates key points for a solitary middle frame among the input frames within a fixed sequence of frames, thus impacting model complexity and learning efficiency.
</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Two-stage 3D Human Pose Estimation Methods</h4>
<div class="ltx_para" id="S2.SS1.SSS2.p1">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">While previous work<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib21" title="">21</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite> propose one-shot methodologies to boost efficiency and accuracy, these models have thus far solely utilized is a single image inputs, preventing effective detection of temporal information.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS2.p2">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1">Alternatively, video-based 3D human pose estimation largely utilize two-stage methods of lifting 3D coordinates after generating 2D coordinates with off-the-shelf 2D pose estimators, offering compatibility with any 2D pose estimation method. For instance, Skeletal graph neural networks (SGNN)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite> use off-the-shelf 2D key point detectors<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite> to obtain the 2D poses needed to derive 3D human poses. Despite improved performance over previous models, SGNN yet lacks spatial depth perception of objects in a scene, which is addressed by PoseFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite> using a spatial-temporal transformer structure. That said, PoseFormer is constrained in learning 2D-to-3D spatial and temporal correlations, and requires more training data than CNNs.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS2.p3">
<p class="ltx_p" id="S2.SS1.SSS2.p3.1">MHFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite> addresses the optimization constraints of PoseFormer
by synthesizing an ultimate pose from learning spatio-temporal representations multiple plausible pose hypotheses. However, MHFormer requires a large high-quality data to maintain high performance, which P-STMO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite> addresses with a self-supervised pre-training method, but is ultimately constrained by the quadratic growth of its computational cost as the number of video sequences increases, given its many-to-one methodology. Most recently, STCFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite> presents a state-of-the-art spatio-temporal criss-cross attention (STC) block by decomposing correlation learning across space and time to increase processing speed. Nonetheless, STCFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite> is limited by the quality of 2D pose estimators, as it is a two-stage method.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>Heatmap Representations of Pose Estimation</h4>
<div class="ltx_para" id="S2.SS1.SSS3.p1">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1">A recent development in pose estimation has been to configure models to learn heatmap estimation as an alternative to key point regression <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite>. Coarse-to-fine <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite> builds 3D Gaussian distributions centered around the ground truth position to solve non-linear problem of direct 3D coordinate regression. Based on coarse-to-fine <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite> , HEMlets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite> incorporate the kinematic information of a parent joint and a child joint (Part-Centric Heatmap Triplets) to improve accuracy of 3D key points estimation. However, both Coarse-to-fine and HEMlets use MSE as loss functions, leading to non-convex problems.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p2">
<p class="ltx_p" id="S2.SS1.SSS3.p2.1">RLE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite> replaces the MSE loss function with likelihood loss function, resulting in an elevated time complexity. Thus, keypoint transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite> utilizes the cross-entropy loss of 3D heatmap instead of likelihood loss. However, this 3D heatmap did not consider adjacent joints’ kinematic connections, which prevents the model from distinguishing between different key points. Though HEMlets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite> considers adjacent key points, its triplet structure at most include three key points, missing connections where more than three key points are kinematically connected.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Dataset Constraints</h3>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>3D Human Pose Estimation Datasets</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">3D datasets for pose estimation are difficult to generate, as motion capture systems must be used to generate accurate 3D coordinates as ground truth. However, mocap-generated datasets ultimately cannot contain data in the wild. Recent developments have seen novel approaches to estimate ground truth data using algorithms, which made 3D human pose datasets easier to make, but ground truth of such datasets tend to be less accurate, posing new problems for training.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS1.p2">
<p class="ltx_p" id="S2.SS2.SSS1.p2.1">Human3.6M <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite> is the first ever large-scale dataset that uses motion capture equipment to track accurate 3D coordinates while a number of actors performing different daily life movements. MADS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>, developed by City University of Hong Kong, uses the same approach as Human3.6M in a smaller scale and includes movements in martial arts, dancing and sports. AIST Dance++ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> is a recent dataset with high-definition recording of dancing of multiple genres. Its difference from the first two datasets is that it is marker-free, meaning algorithms are used for ground truth. MPI INF 3DHP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite> is a 3D marker-based dataset as an extension of the classic 2D dataset MPII.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Existing Dataset Limitations</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">Existing 3D human pose datasets are lacking in scale and diversity.
First, the performance of the vision transformers may be constrained by the limited number of frames in the datasets. For instance, AIST Dance ++ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> is 2.4 times larger than Human3.6M <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>, but it only has 12760 videos.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p2">
<p class="ltx_p" id="S2.SS2.SSS2.p2.1">Apart from a data size limitations, existing 3D human pose datasets are in lacking in diversity, negatively impacting in-the-wild applications. Most existing 3D human pose datasets are shot in a studio with fixed lighting, background, and the same set of actors. For instance, AIST Dance++ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> has 10 dance genres and 30 dancers.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Data Augmentation Methodologies</h4>
<div class="ltx_para" id="S2.SS2.SSS3.p1">
<p class="ltx_p" id="S2.SS2.SSS3.p1.1">Recent work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>, <a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> has developed novel data augmentation methodologies to address data diversity limitations of existing 3D human pose estimation datasets, namely by scaling dataset size by standardizing different datasets to feed into one training process.  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>, <a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite>.
</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS3.p2">
<p class="ltx_p" id="S2.SS2.SSS3.p2.1">Three such data augmentation precedents are observed. The first involves using handcrafted rules in skeletal joints to manually harmonize differences between datasets (HumanEva-I, Human3.6M, and Panoptic Studio) into one combined dataset<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite>. However, handcrafted rules are susceptible to errors and similar manual configurations are required to apply such a methodology onto other datasets. A second approach <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite> is to standardize reference systems based on the relative rotation between camera viewing direction and the orientation of the torso. However, this approach is vulnerable to errors during conversion from camera to global coordinate systems. A third method of dataset augmentation merges dozens of datasets into one training process with a latent key point set serving as ground truth<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>. Such a learned latent key point set, however, leads to data imbalance and is further constrained in performance by the complexity of a given task.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>3D AugMotion Toolkit: Dataset Augmentation Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Acknowledging the lack of diversity and in-the-wild data in existing 3D human pose datasets, we introduce the 3D AugMotion Toolkit, a data augmentation methodology to merge existing 3D human pose datasets into a single dataset with the highest number of frames and diversity to date. The current work applies the augmentation methodology on four frequently utilized datasets, namely Human3.6M<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>, MADS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>, AIST Dance++<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> and MPI INF 3DHP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>. That said, the 3D AugMotion Toolkit is applicable to any 3D human pose estimation dataset.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">It is essential for all datasets to be projected onto a universal coordinate system to be properly used by models as ground truth data. Naturally, the model would be unable to minimize loss if a single key point could have multiple coordinates. Therefore, the first challenge is to address discrepancies between datasets’ reference systems
as each dataset maintains its own coordinate system. That is, ground truth data of each dataset comes with unique camera-configured coordinates and global coordinates, respectively.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">As 3D human pose datasets are typically captured with multi-camera studio set-ups, the perspective and configurations of each camera dictate its coordinate system. Naturally, each camera maintains its own unique camera-specific coordinate system. Most datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib26" title="">26</a>, <a class="ltx_ref" href="#bib.bib23" title="">23</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite> compute translation and rotation matrix to standardize the coordinates of each camera within the multi-camera setup onto a global coordinate system. However, global coordinate systems of 3D human pose datasets are not consistent with each other, meaning they require standardization to locate the same key point with the same coordinates.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">Global reference systems within the same dataset, however, are also susceptible to errors. For instance, coordinates for the same frame of movement within the Humans3.6M dataset are taken from different camera perspectives that yield misaligned and non-overlapping key point representations of a subject when converted to global coordinates. The four key point skeletons in Fig. <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ 3 3D AugMotion Toolkit: Dataset Augmentation Methodology ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">1</span></a> represent the same pose from the same subject taken from multiple perspectives, but each are clearly misaligned when converted to global 3D coordinate systems.The lack of overlapping alignment suggests a need for a standard to universalize all camera reference systems with key frames.
</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F1.1"><span class="ltx_text" id="S3.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="298" id="S3.F1.1.1.g1" src="extracted/5298414/Fig/humans36.png" width="598"/></span></p>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S3.F1.4.2" style="font-size:90%;">This example from the Human3.6M dataset (A) shows how the conversions to global coordinate systems from unique camera parameters are susceptible to errors. The four key point skeletons (B) represent the same pose from the same subject taken from multiple perspectives, but each are misaligned when converted to global 3D coordinate systems. </span></figcaption>
</figure>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1">To address the coordinate system problems above, the proposed methodology is to 1) select key frames serving as benchmark, 2) use key frames and the proposed approach to establish a universal coordinate system, and 3) utilize the Kabsch Algorithm to project all other frames onto the established universal coordinate system.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Key Frames</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The proposed universal coordinate system defines the upward direction as perpendicular to the ground as the positive direction of the z-axis. We select as key frames where the upper body of the pose is perpendicular to the ground. We utilize <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">k</span>-means clustering to find qualified key frames with 3 clusters and select the cluster center frame of the largest cluster as the key frame for each video.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Methodology for Defining a Universal Coordinate System</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Unique coordinate systems are defined by origin, as well as positive orientation of the <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">x</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">y</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.3">z</span> axis. In the proposed methodology, we further define the <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.4">origin</span> as the midpoint between left shoulders and right shoulders, the <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.5">y-axis positive orientation</span> as left-shoulder-to-right-shoulder vectors, the <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.6"> z-axis positive orientation</span> as origin-to-pubis vectors, and the <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.7">x-axis positive orientation</span> as face directions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We further select left shoulders, right shoulders, and pubises as <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.1">reference key points</span> as shown in red in Fig. <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.1 Spatio-temporal transformer ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">3</span></a>. Based on the definitions above, the left shoulder key point and the right should key point would be on the y-z plane symmetric to each other while the pubis key point is on the z axis. Before determining coordinates of the reference key points to define unit length and used for the Kabsch algorithm, we compute the ratio of the shoulder to shoulder distance (i.e., width) to the distance from the shoulder to shoulder midpoint to the pubis to properly represent poses in the coordinate system. Refer to Equation (1) for further detail.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F2.1"><span class="ltx_text" id="S3.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="337" id="S3.F2.1.1.g1" src="extracted/5298414/Fig/skeleton.png" width="299"/></span></p>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.3.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.4.2" style="font-size:90%;">Red points represent 3D reference key points, namely left shoulder, right shoulder, and pubis.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.2">After taking the average of all datasets to compute the ratio of the distance <math alttext="d\left(p_{sl}^{i},p_{sr}^{i}\right)" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.2"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.4" xref="S3.SS2.p3.1.m1.2.2.4.cmml">d</mi><mo id="S3.SS2.p3.1.m1.2.2.3" xref="S3.SS2.p3.1.m1.2.2.3.cmml">⁢</mo><mrow id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml"><mo id="S3.SS2.p3.1.m1.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">(</mo><msubsup id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.2.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.2.cmml">p</mi><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.2.cmml">s</mi><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.3.cmml">l</mi></mrow><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.1.m1.2.2.2.2.4" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">,</mo><msubsup id="S3.SS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.2.cmml">p</mi><mrow id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.2.cmml">s</mi><mo id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.1" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.3" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.3.cmml">r</mi></mrow><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.1.m1.2.2.2.2.5" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><apply id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2"><times id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.3"></times><ci id="S3.SS2.p3.1.m1.2.2.4.cmml" xref="S3.SS2.p3.1.m1.2.2.4">𝑑</ci><interval closure="open" id="S3.SS2.p3.1.m1.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.2">𝑝</ci><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3"><times id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.2">𝑠</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.3.3">𝑙</ci></apply></apply><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p3.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.2">𝑝</ci><apply id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3"><times id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.1"></times><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.2">𝑠</ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.3.3">𝑟</ci></apply></apply><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">d\left(p_{sl}^{i},p_{sr}^{i}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.2d">italic_d ( italic_p start_POSTSUBSCRIPT italic_s italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_p start_POSTSUBSCRIPT italic_s italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math> to the distance <math alttext="d\left(p_{ms}^{i},p_{p}^{i}\right)" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.2"><semantics id="S3.SS2.p3.2.m2.2a"><mrow id="S3.SS2.p3.2.m2.2.2" xref="S3.SS2.p3.2.m2.2.2.cmml"><mi id="S3.SS2.p3.2.m2.2.2.4" xref="S3.SS2.p3.2.m2.2.2.4.cmml">d</mi><mo id="S3.SS2.p3.2.m2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.3.cmml">⁢</mo><mrow id="S3.SS2.p3.2.m2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml"><mo id="S3.SS2.p3.2.m2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">(</mo><msubsup id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.2.cmml">p</mi><mrow id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.2.cmml">m</mi><mo id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.3.cmml">s</mi></mrow><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.2.m2.2.2.2.2.4" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">,</mo><msubsup id="S3.SS2.p3.2.m2.2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.2.m2.2.2.2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2.2.cmml">p</mi><mi id="S3.SS2.p3.2.m2.2.2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2.3.cmml">p</mi><mi id="S3.SS2.p3.2.m2.2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS2.p3.2.m2.2.2.2.2.5" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.2b"><apply id="S3.SS2.p3.2.m2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2"><times id="S3.SS2.p3.2.m2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.3"></times><ci id="S3.SS2.p3.2.m2.2.2.4.cmml" xref="S3.SS2.p3.2.m2.2.2.4">𝑑</ci><interval closure="open" id="S3.SS2.p3.2.m2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2"><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.2">𝑝</ci><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3"><times id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.2">𝑚</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.3.3">𝑠</ci></apply></apply><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p3.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2.2">𝑝</ci><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2.3">𝑝</ci></apply><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.2c">d\left(p_{ms}^{i},p_{p}^{i}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.2d">italic_d ( italic_p start_POSTSUBSCRIPT italic_m italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_p start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math>, we then define the left shoulder at (-1,0,3), the right shoulder at (1,0,3), and the pubis at (0,0,0.5) to establish the universal coordinate system.</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E1">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E1X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle M_{s}=\frac{1}{N}\sum_{i=1}^{N}d\left(p_{sl}^{i},p_{sr}^{i}\right)" class="ltx_Math" display="inline" id="S3.E1X.2.1.1.m1.2"><semantics id="S3.E1X.2.1.1.m1.2a"><mrow id="S3.E1X.2.1.1.m1.2.2" xref="S3.E1X.2.1.1.m1.2.2.cmml"><msub id="S3.E1X.2.1.1.m1.2.2.4" xref="S3.E1X.2.1.1.m1.2.2.4.cmml"><mi id="S3.E1X.2.1.1.m1.2.2.4.2" xref="S3.E1X.2.1.1.m1.2.2.4.2.cmml">M</mi><mi id="S3.E1X.2.1.1.m1.2.2.4.3" xref="S3.E1X.2.1.1.m1.2.2.4.3.cmml">s</mi></msub><mo id="S3.E1X.2.1.1.m1.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E1X.2.1.1.m1.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1X.2.1.1.m1.2.2.2.4" xref="S3.E1X.2.1.1.m1.2.2.2.4.cmml"><mfrac id="S3.E1X.2.1.1.m1.2.2.2.4a" xref="S3.E1X.2.1.1.m1.2.2.2.4.cmml"><mn id="S3.E1X.2.1.1.m1.2.2.2.4.2" xref="S3.E1X.2.1.1.m1.2.2.2.4.2.cmml">1</mn><mi id="S3.E1X.2.1.1.m1.2.2.2.4.3" xref="S3.E1X.2.1.1.m1.2.2.2.4.3.cmml">N</mi></mfrac></mstyle><mo id="S3.E1X.2.1.1.m1.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.3.cmml">⁢</mo><mrow id="S3.E1X.2.1.1.m1.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1X.2.1.1.m1.2.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.cmml"><munderover id="S3.E1X.2.1.1.m1.2.2.2.2.3a" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.cmml"><mo id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.2" movablelimits="false" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.cmml"><mi id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.1" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E1X.2.1.1.m1.2.2.2.2.3.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.3.cmml">N</mi></munderover></mstyle><mrow id="S3.E1X.2.1.1.m1.2.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.cmml"><mi id="S3.E1X.2.1.1.m1.2.2.2.2.2.4" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.4.cmml">d</mi><mo id="S3.E1X.2.1.1.m1.2.2.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.3.cmml"><mo id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.3.cmml">(</mo><msubsup id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml">p</mi><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">s</mi><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">l</mi></mrow><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.4" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.2.cmml">p</mi><mrow id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.cmml"><mi id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.2" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.2.cmml">s</mi><mo id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.1" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.3.cmml">r</mi></mrow><mi id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.3" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.5" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.2.1.1.m1.2b"><apply id="S3.E1X.2.1.1.m1.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2"><eq id="S3.E1X.2.1.1.m1.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.3"></eq><apply id="S3.E1X.2.1.1.m1.2.2.4.cmml" xref="S3.E1X.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.2.2.4.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.4">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.2.2.4.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.4.2">𝑀</ci><ci id="S3.E1X.2.1.1.m1.2.2.4.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.4.3">𝑠</ci></apply><apply id="S3.E1X.2.1.1.m1.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2"><times id="S3.E1X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.3"></times><apply id="S3.E1X.2.1.1.m1.2.2.2.4.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.4"><divide id="S3.E1X.2.1.1.m1.2.2.2.4.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.4"></divide><cn id="S3.E1X.2.1.1.m1.2.2.2.4.2.cmml" type="integer" xref="S3.E1X.2.1.1.m1.2.2.2.4.2">1</cn><ci id="S3.E1X.2.1.1.m1.2.2.2.4.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.4.3">𝑁</ci></apply><apply id="S3.E1X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2"><apply id="S3.E1X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.2.2.2.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3">superscript</csymbol><apply id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3">subscript</csymbol><sum id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.2"></sum><apply id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3"><eq id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.1"></eq><ci id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.2">𝑖</ci><cn id="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.3.cmml" type="integer" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E1X.2.1.1.m1.2.2.2.2.3.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.3.3">𝑁</ci></apply><apply id="S3.E1X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2"><times id="S3.E1X.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.3"></times><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.4.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.4">𝑑</ci><interval closure="open" id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2"><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2">𝑝</ci><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3"><times id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2">𝑠</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3">𝑙</ci></apply></apply><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.2">𝑝</ci><apply id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3"><times id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.1"></times><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.2.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.2">𝑠</ci><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.3">𝑟</ci></apply></apply><ci id="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.2.1.1.m1.2c">\displaystyle M_{s}=\frac{1}{N}\sum_{i=1}^{N}d\left(p_{sl}^{i},p_{sr}^{i}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E1X.2.1.1.m1.2d">italic_M start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_d ( italic_p start_POSTSUBSCRIPT italic_s italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_p start_POSTSUBSCRIPT italic_s italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="2"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E1Xa">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle M_{sp}=\frac{1}{N}\sum_{i=1}^{N}d\left(p_{ms}^{i},p_{p}^{i}\right)" class="ltx_Math" display="inline" id="S3.E1Xa.2.1.1.m1.2"><semantics id="S3.E1Xa.2.1.1.m1.2a"><mrow id="S3.E1Xa.2.1.1.m1.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.cmml"><msub id="S3.E1Xa.2.1.1.m1.2.2.4" xref="S3.E1Xa.2.1.1.m1.2.2.4.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.4.2" xref="S3.E1Xa.2.1.1.m1.2.2.4.2.cmml">M</mi><mrow id="S3.E1Xa.2.1.1.m1.2.2.4.3" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.4.3.2" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.2.cmml">s</mi><mo id="S3.E1Xa.2.1.1.m1.2.2.4.3.1" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.1.cmml">⁢</mo><mi id="S3.E1Xa.2.1.1.m1.2.2.4.3.3" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.3.cmml">p</mi></mrow></msub><mo id="S3.E1Xa.2.1.1.m1.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E1Xa.2.1.1.m1.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1Xa.2.1.1.m1.2.2.2.4" xref="S3.E1Xa.2.1.1.m1.2.2.2.4.cmml"><mfrac id="S3.E1Xa.2.1.1.m1.2.2.2.4a" xref="S3.E1Xa.2.1.1.m1.2.2.2.4.cmml"><mn id="S3.E1Xa.2.1.1.m1.2.2.2.4.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.4.2.cmml">1</mn><mi id="S3.E1Xa.2.1.1.m1.2.2.2.4.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.4.3.cmml">N</mi></mfrac></mstyle><mo id="S3.E1Xa.2.1.1.m1.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.3.cmml">⁢</mo><mrow id="S3.E1Xa.2.1.1.m1.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1Xa.2.1.1.m1.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.cmml"><munderover id="S3.E1Xa.2.1.1.m1.2.2.2.2.3a" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.cmml"><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.2" movablelimits="false" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.1" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.3.cmml">N</mi></munderover></mstyle><mrow id="S3.E1Xa.2.1.1.m1.2.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.4" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.4.cmml">d</mi><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.3.cmml"><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.3.cmml">(</mo><msubsup id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml">p</mi><mrow id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">m</mi><mo id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">s</mi></mrow><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.4" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.2.cmml">p</mi><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.cmml">p</mi><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.5" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1Xa.2.1.1.m1.2b"><apply id="S3.E1Xa.2.1.1.m1.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2"><eq id="S3.E1Xa.2.1.1.m1.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.3"></eq><apply id="S3.E1Xa.2.1.1.m1.2.2.4.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.4.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.2.2.4.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.2">𝑀</ci><apply id="S3.E1Xa.2.1.1.m1.2.2.4.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.3"><times id="S3.E1Xa.2.1.1.m1.2.2.4.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.1"></times><ci id="S3.E1Xa.2.1.1.m1.2.2.4.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.2">𝑠</ci><ci id="S3.E1Xa.2.1.1.m1.2.2.4.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.3">𝑝</ci></apply></apply><apply id="S3.E1Xa.2.1.1.m1.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2"><times id="S3.E1Xa.2.1.1.m1.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.3"></times><apply id="S3.E1Xa.2.1.1.m1.2.2.2.4.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.4"><divide id="S3.E1Xa.2.1.1.m1.2.2.2.4.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.4"></divide><cn id="S3.E1Xa.2.1.1.m1.2.2.2.4.2.cmml" type="integer" xref="S3.E1Xa.2.1.1.m1.2.2.2.4.2">1</cn><ci id="S3.E1Xa.2.1.1.m1.2.2.2.4.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.4.3">𝑁</ci></apply><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2"><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3">superscript</csymbol><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3">subscript</csymbol><sum id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.2"></sum><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3"><eq id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.1"></eq><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.2">𝑖</ci><cn id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.3.cmml" type="integer" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3.3">𝑁</ci></apply><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2"><times id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3"></times><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.4.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.4">𝑑</ci><interval closure="open" id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2"><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.2">𝑝</ci><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3"><times id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2">𝑚</ci><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3">𝑠</ci></apply></apply><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.2">𝑝</ci><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.2.3">𝑝</ci></apply><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xa.2.1.1.m1.2c">\displaystyle M_{sp}=\frac{1}{N}\sum_{i=1}^{N}d\left(p_{ms}^{i},p_{p}^{i}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E1Xa.2.1.1.m1.2d">italic_M start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_d ( italic_p start_POSTSUBSCRIPT italic_m italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_p start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.10">Where <math alttext="M_{s}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m1.1"><semantics id="S3.SS2.p3.3.m1.1a"><msub id="S3.SS2.p3.3.m1.1.1" xref="S3.SS2.p3.3.m1.1.1.cmml"><mi id="S3.SS2.p3.3.m1.1.1.2" xref="S3.SS2.p3.3.m1.1.1.2.cmml">M</mi><mi id="S3.SS2.p3.3.m1.1.1.3" xref="S3.SS2.p3.3.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m1.1b"><apply id="S3.SS2.p3.3.m1.1.1.cmml" xref="S3.SS2.p3.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m1.1.1.1.cmml" xref="S3.SS2.p3.3.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m1.1.1.2.cmml" xref="S3.SS2.p3.3.m1.1.1.2">𝑀</ci><ci id="S3.SS2.p3.3.m1.1.1.3.cmml" xref="S3.SS2.p3.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m1.1c">M_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m1.1d">italic_M start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> is the average distance from left shoulder to right shoulder; <math alttext="M_{sp}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m2.1"><semantics id="S3.SS2.p3.4.m2.1a"><msub id="S3.SS2.p3.4.m2.1.1" xref="S3.SS2.p3.4.m2.1.1.cmml"><mi id="S3.SS2.p3.4.m2.1.1.2" xref="S3.SS2.p3.4.m2.1.1.2.cmml">M</mi><mrow id="S3.SS2.p3.4.m2.1.1.3" xref="S3.SS2.p3.4.m2.1.1.3.cmml"><mi id="S3.SS2.p3.4.m2.1.1.3.2" xref="S3.SS2.p3.4.m2.1.1.3.2.cmml">s</mi><mo id="S3.SS2.p3.4.m2.1.1.3.1" xref="S3.SS2.p3.4.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.4.m2.1.1.3.3" xref="S3.SS2.p3.4.m2.1.1.3.3.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m2.1b"><apply id="S3.SS2.p3.4.m2.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m2.1.1.1.cmml" xref="S3.SS2.p3.4.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m2.1.1.2.cmml" xref="S3.SS2.p3.4.m2.1.1.2">𝑀</ci><apply id="S3.SS2.p3.4.m2.1.1.3.cmml" xref="S3.SS2.p3.4.m2.1.1.3"><times id="S3.SS2.p3.4.m2.1.1.3.1.cmml" xref="S3.SS2.p3.4.m2.1.1.3.1"></times><ci id="S3.SS2.p3.4.m2.1.1.3.2.cmml" xref="S3.SS2.p3.4.m2.1.1.3.2">𝑠</ci><ci id="S3.SS2.p3.4.m2.1.1.3.3.cmml" xref="S3.SS2.p3.4.m2.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m2.1c">M_{sp}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m2.1d">italic_M start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT</annotation></semantics></math> is the average distance from the middle of two shoulders to pubis; <math alttext="d()" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m3.1"><semantics id="S3.SS2.p3.5.m3.1a"><mrow id="S3.SS2.p3.5.m3.1.1" xref="S3.SS2.p3.5.m3.1.1.cmml"><mi id="S3.SS2.p3.5.m3.1.1.2" xref="S3.SS2.p3.5.m3.1.1.2.cmml">d</mi><mo id="S3.SS2.p3.5.m3.1.1.1" xref="S3.SS2.p3.5.m3.1.1.1.cmml">⁢</mo><mrow id="S3.SS2.p3.5.m3.1.1.3.2" xref="S3.SS2.p3.5.m3.1.1.cmml"><mo id="S3.SS2.p3.5.m3.1.1.3.2.1" stretchy="false" xref="S3.SS2.p3.5.m3.1.1.3.1.cmml">(</mo><mo id="S3.SS2.p3.5.m3.1.1.3.2.2" stretchy="false" xref="S3.SS2.p3.5.m3.1.1.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m3.1b"><apply id="S3.SS2.p3.5.m3.1.1.cmml" xref="S3.SS2.p3.5.m3.1.1"><times id="S3.SS2.p3.5.m3.1.1.1.cmml" xref="S3.SS2.p3.5.m3.1.1.1"></times><ci id="S3.SS2.p3.5.m3.1.1.2.cmml" xref="S3.SS2.p3.5.m3.1.1.2">𝑑</ci><list id="S3.SS2.p3.5.m3.1.1.3.1.cmml" xref="S3.SS2.p3.5.m3.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m3.1c">d()</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m3.1d">italic_d ( )</annotation></semantics></math> is the distance function; <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m4.1"><semantics id="S3.SS2.p3.6.m4.1a"><mi id="S3.SS2.p3.6.m4.1.1" xref="S3.SS2.p3.6.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m4.1b"><ci id="S3.SS2.p3.6.m4.1.1.cmml" xref="S3.SS2.p3.6.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m4.1d">italic_N</annotation></semantics></math> is the number of frames in all datasets; <math alttext="p_{sl}" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m5.1"><semantics id="S3.SS2.p3.7.m5.1a"><msub id="S3.SS2.p3.7.m5.1.1" xref="S3.SS2.p3.7.m5.1.1.cmml"><mi id="S3.SS2.p3.7.m5.1.1.2" xref="S3.SS2.p3.7.m5.1.1.2.cmml">p</mi><mrow id="S3.SS2.p3.7.m5.1.1.3" xref="S3.SS2.p3.7.m5.1.1.3.cmml"><mi id="S3.SS2.p3.7.m5.1.1.3.2" xref="S3.SS2.p3.7.m5.1.1.3.2.cmml">s</mi><mo id="S3.SS2.p3.7.m5.1.1.3.1" xref="S3.SS2.p3.7.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.7.m5.1.1.3.3" xref="S3.SS2.p3.7.m5.1.1.3.3.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m5.1b"><apply id="S3.SS2.p3.7.m5.1.1.cmml" xref="S3.SS2.p3.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m5.1.1.1.cmml" xref="S3.SS2.p3.7.m5.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m5.1.1.2.cmml" xref="S3.SS2.p3.7.m5.1.1.2">𝑝</ci><apply id="S3.SS2.p3.7.m5.1.1.3.cmml" xref="S3.SS2.p3.7.m5.1.1.3"><times id="S3.SS2.p3.7.m5.1.1.3.1.cmml" xref="S3.SS2.p3.7.m5.1.1.3.1"></times><ci id="S3.SS2.p3.7.m5.1.1.3.2.cmml" xref="S3.SS2.p3.7.m5.1.1.3.2">𝑠</ci><ci id="S3.SS2.p3.7.m5.1.1.3.3.cmml" xref="S3.SS2.p3.7.m5.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m5.1c">p_{sl}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m5.1d">italic_p start_POSTSUBSCRIPT italic_s italic_l end_POSTSUBSCRIPT</annotation></semantics></math> is the left shoulder key point; <math alttext="p_{sr}" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m6.1"><semantics id="S3.SS2.p3.8.m6.1a"><msub id="S3.SS2.p3.8.m6.1.1" xref="S3.SS2.p3.8.m6.1.1.cmml"><mi id="S3.SS2.p3.8.m6.1.1.2" xref="S3.SS2.p3.8.m6.1.1.2.cmml">p</mi><mrow id="S3.SS2.p3.8.m6.1.1.3" xref="S3.SS2.p3.8.m6.1.1.3.cmml"><mi id="S3.SS2.p3.8.m6.1.1.3.2" xref="S3.SS2.p3.8.m6.1.1.3.2.cmml">s</mi><mo id="S3.SS2.p3.8.m6.1.1.3.1" xref="S3.SS2.p3.8.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.8.m6.1.1.3.3" xref="S3.SS2.p3.8.m6.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m6.1b"><apply id="S3.SS2.p3.8.m6.1.1.cmml" xref="S3.SS2.p3.8.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m6.1.1.1.cmml" xref="S3.SS2.p3.8.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.8.m6.1.1.2.cmml" xref="S3.SS2.p3.8.m6.1.1.2">𝑝</ci><apply id="S3.SS2.p3.8.m6.1.1.3.cmml" xref="S3.SS2.p3.8.m6.1.1.3"><times id="S3.SS2.p3.8.m6.1.1.3.1.cmml" xref="S3.SS2.p3.8.m6.1.1.3.1"></times><ci id="S3.SS2.p3.8.m6.1.1.3.2.cmml" xref="S3.SS2.p3.8.m6.1.1.3.2">𝑠</ci><ci id="S3.SS2.p3.8.m6.1.1.3.3.cmml" xref="S3.SS2.p3.8.m6.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m6.1c">p_{sr}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m6.1d">italic_p start_POSTSUBSCRIPT italic_s italic_r end_POSTSUBSCRIPT</annotation></semantics></math> is the left shoulder key point; <math alttext="p_{ms}" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m7.1"><semantics id="S3.SS2.p3.9.m7.1a"><msub id="S3.SS2.p3.9.m7.1.1" xref="S3.SS2.p3.9.m7.1.1.cmml"><mi id="S3.SS2.p3.9.m7.1.1.2" xref="S3.SS2.p3.9.m7.1.1.2.cmml">p</mi><mrow id="S3.SS2.p3.9.m7.1.1.3" xref="S3.SS2.p3.9.m7.1.1.3.cmml"><mi id="S3.SS2.p3.9.m7.1.1.3.2" xref="S3.SS2.p3.9.m7.1.1.3.2.cmml">m</mi><mo id="S3.SS2.p3.9.m7.1.1.3.1" xref="S3.SS2.p3.9.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.9.m7.1.1.3.3" xref="S3.SS2.p3.9.m7.1.1.3.3.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m7.1b"><apply id="S3.SS2.p3.9.m7.1.1.cmml" xref="S3.SS2.p3.9.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m7.1.1.1.cmml" xref="S3.SS2.p3.9.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.9.m7.1.1.2.cmml" xref="S3.SS2.p3.9.m7.1.1.2">𝑝</ci><apply id="S3.SS2.p3.9.m7.1.1.3.cmml" xref="S3.SS2.p3.9.m7.1.1.3"><times id="S3.SS2.p3.9.m7.1.1.3.1.cmml" xref="S3.SS2.p3.9.m7.1.1.3.1"></times><ci id="S3.SS2.p3.9.m7.1.1.3.2.cmml" xref="S3.SS2.p3.9.m7.1.1.3.2">𝑚</ci><ci id="S3.SS2.p3.9.m7.1.1.3.3.cmml" xref="S3.SS2.p3.9.m7.1.1.3.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m7.1c">p_{ms}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m7.1d">italic_p start_POSTSUBSCRIPT italic_m italic_s end_POSTSUBSCRIPT</annotation></semantics></math> is the midpoint between two shoulders; <math alttext="p_{p}" class="ltx_Math" display="inline" id="S3.SS2.p3.10.m8.1"><semantics id="S3.SS2.p3.10.m8.1a"><msub id="S3.SS2.p3.10.m8.1.1" xref="S3.SS2.p3.10.m8.1.1.cmml"><mi id="S3.SS2.p3.10.m8.1.1.2" xref="S3.SS2.p3.10.m8.1.1.2.cmml">p</mi><mi id="S3.SS2.p3.10.m8.1.1.3" xref="S3.SS2.p3.10.m8.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m8.1b"><apply id="S3.SS2.p3.10.m8.1.1.cmml" xref="S3.SS2.p3.10.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.10.m8.1.1.1.cmml" xref="S3.SS2.p3.10.m8.1.1">subscript</csymbol><ci id="S3.SS2.p3.10.m8.1.1.2.cmml" xref="S3.SS2.p3.10.m8.1.1.2">𝑝</ci><ci id="S3.SS2.p3.10.m8.1.1.3.cmml" xref="S3.SS2.p3.10.m8.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m8.1c">p_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.10.m8.1d">italic_p start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> is the pubis key point.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Kabsch Algorithm</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.4">The last step of our dataset augmentation methodology is to use the Kabsch Algorithm (KA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite> to compute the rotation matrix and translation matrix for projection. KA finds the optimal rotation and translation of two sets of points in N-dimensional space with linear and vector algebra to minimize root-mean-square deviation (RMSD) between them. KA does translation, computation of a covariance matrix, and computation of the optimal rotation matrix sequentially. The translation matrix <math alttext="T" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_T</annotation></semantics></math> is computed by subtracting point coordinates from the point coordinates of the respective centroid. The second step consists of calculating a cross-covariance matrix <math alttext="H" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_H</annotation></semantics></math> when <math alttext="P" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_P</annotation></semantics></math> and <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_Q</annotation></semantics></math> are seen as data matrices using the following summation notation:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="H_{ij}=\sum_{k=1}^{N}P_{ki}Q_{kj}," class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.2.cmml">H</mi><mrow id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.3.2" xref="S3.E2.m1.1.1.1.1.2.3.2.cmml">i</mi><mo id="S3.E2.m1.1.1.1.1.2.3.1" xref="S3.E2.m1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.2.3.3" xref="S3.E2.m1.1.1.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.1" rspace="0.111em" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><munderover id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml"><mo id="S3.E2.m1.1.1.1.1.3.1.2.2" movablelimits="false" xref="S3.E2.m1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.1.1.1.1.3.1.2.3" xref="S3.E2.m1.1.1.1.1.3.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.1.2.3.2" xref="S3.E2.m1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S3.E2.m1.1.1.1.1.3.1.2.3.1" xref="S3.E2.m1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.1.1.1.1.3.1.2.3.3" xref="S3.E2.m1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.1.1.1.1.3.1.3" xref="S3.E2.m1.1.1.1.1.3.1.3.cmml">N</mi></munderover><mrow id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml"><msub id="S3.E2.m1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.2.cmml">P</mi><mrow id="S3.E2.m1.1.1.1.1.3.2.2.3" xref="S3.E2.m1.1.1.1.1.3.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2.3.2" xref="S3.E2.m1.1.1.1.1.3.2.2.3.2.cmml">k</mi><mo id="S3.E2.m1.1.1.1.1.3.2.2.3.1" xref="S3.E2.m1.1.1.1.1.3.2.2.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.3.2.2.3.3" xref="S3.E2.m1.1.1.1.1.3.2.2.3.3.cmml">i</mi></mrow></msub><mo id="S3.E2.m1.1.1.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.3.2.1.cmml">⁢</mo><msub id="S3.E2.m1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.3.2" xref="S3.E2.m1.1.1.1.1.3.2.3.2.cmml">Q</mi><mrow id="S3.E2.m1.1.1.1.1.3.2.3.3" xref="S3.E2.m1.1.1.1.1.3.2.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.3.3.2" xref="S3.E2.m1.1.1.1.1.3.2.3.3.2.cmml">k</mi><mo id="S3.E2.m1.1.1.1.1.3.2.3.3.1" xref="S3.E2.m1.1.1.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.3.2.3.3.3" xref="S3.E2.m1.1.1.1.1.3.2.3.3.3.cmml">j</mi></mrow></msub></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2">𝐻</ci><apply id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3"><times id="S3.E2.m1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.3.1"></times><ci id="S3.E2.m1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.3.2">𝑖</ci><ci id="S3.E2.m1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><apply id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E2.m1.1.1.1.1.3.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.1.2.2"></sum><apply id="S3.E2.m1.1.1.1.1.3.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.1.2.3"><eq id="S3.E2.m1.1.1.1.1.3.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1.2.3.1"></eq><ci id="S3.E2.m1.1.1.1.1.3.1.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.1.2.3.2">𝑘</ci><cn id="S3.E2.m1.1.1.1.1.3.1.2.3.3.cmml" type="integer" xref="S3.E2.m1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.1.1.1.1.3.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3.1.3">𝑁</ci></apply><apply id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2"><times id="S3.E2.m1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.1"></times><apply id="S3.E2.m1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2.2">𝑃</ci><apply id="S3.E2.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2.3"><times id="S3.E2.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2.3.1"></times><ci id="S3.E2.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2.3.2">𝑘</ci><ci id="S3.E2.m1.1.1.1.1.3.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2.3.3">𝑖</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3.2">𝑄</ci><apply id="S3.E2.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3.3"><times id="S3.E2.m1.1.1.1.1.3.2.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3.3.1"></times><ci id="S3.E2.m1.1.1.1.1.3.2.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3.3.2">𝑘</ci><ci id="S3.E2.m1.1.1.1.1.3.2.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">H_{ij}=\sum_{k=1}^{N}P_{ki}Q_{kj},</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">italic_H start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_P start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT italic_k italic_j end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.5">The last step is to calculate the optimal rotation <math alttext="\mathrm{R}" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m1.1"><semantics id="S3.SS3.p1.5.m1.1a"><mi id="S3.SS3.p1.5.m1.1.1" mathvariant="normal" xref="S3.SS3.p1.5.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m1.1b"><ci id="S3.SS3.p1.5.m1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m1.1c">\mathrm{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m1.1d">roman_R</annotation></semantics></math> by using singular value decomposition (SVD):</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{gathered}H=U\Sigma V^{\top}\\
d=\operatorname{sign}\left(\operatorname{det}\left(VU^{\top}\right)\right)\\
R=V\left(\begin{array}[]{lll}1&amp;0&amp;0\\
0&amp;1&amp;0\\
0&amp;0&amp;d\end{array}\right)U^{\top}\end{gathered}" class="ltx_Math" display="block" id="S3.E3.m1.27"><semantics id="S3.E3.m1.27a"><mtable displaystyle="true" id="S3.E3.m1.27.27.2" rowspacing="0pt" xref="S3.E3.m1.26.26.1.cmml"><mtr id="S3.E3.m1.27.27.2a" xref="S3.E3.m1.26.26.1.cmml"><mtd id="S3.E3.m1.27.27.2b" xref="S3.E3.m1.26.26.1.cmml"><mrow id="S3.E3.m1.6.6.6.6.6" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml">H</mi><mo id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml">=</mo><mrow id="S3.E3.m1.6.6.6.6.6.7" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.3.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.3.3.cmml">U</mi><mo id="S3.E3.m1.6.6.6.6.6.7.1" xref="S3.E3.m1.26.26.1a.cmml">⁢</mo><mi id="S3.E3.m1.4.4.4.4.4.4" mathvariant="normal" xref="S3.E3.m1.4.4.4.4.4.4.cmml">Σ</mi><mo id="S3.E3.m1.6.6.6.6.6.7.1a" xref="S3.E3.m1.26.26.1a.cmml">⁢</mo><msup id="S3.E3.m1.6.6.6.6.6.7.2" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.5.5.5.5.5.5" xref="S3.E3.m1.5.5.5.5.5.5.cmml">V</mi><mo id="S3.E3.m1.6.6.6.6.6.6.1" xref="S3.E3.m1.6.6.6.6.6.6.1.cmml">⊤</mo></msup></mrow></mrow></mtd></mtr><mtr id="S3.E3.m1.27.27.2c" xref="S3.E3.m1.26.26.1.cmml"><mtd id="S3.E3.m1.27.27.2d" xref="S3.E3.m1.26.26.1.cmml"><mrow id="S3.E3.m1.27.27.2.26.12.12" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.7.7.7.1.1.1" xref="S3.E3.m1.7.7.7.1.1.1.cmml">d</mi><mo id="S3.E3.m1.8.8.8.2.2.2" xref="S3.E3.m1.8.8.8.2.2.2.cmml">=</mo><mrow id="S3.E3.m1.27.27.2.26.12.12.12.1" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.9.9.9.3.3.3" xref="S3.E3.m1.9.9.9.3.3.3.cmml">sign</mi><mo id="S3.E3.m1.27.27.2.26.12.12.12.1a" xref="S3.E3.m1.26.26.1a.cmml">⁡</mo><mrow id="S3.E3.m1.27.27.2.26.12.12.12.1.1" xref="S3.E3.m1.26.26.1.cmml"><mo id="S3.E3.m1.10.10.10.4.4.4" xref="S3.E3.m1.26.26.1a.cmml">(</mo><mrow id="S3.E3.m1.27.27.2.26.12.12.12.1.1.1" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.11.11.11.5.5.5" xref="S3.E3.m1.11.11.11.5.5.5.cmml">det</mi><mo id="S3.E3.m1.27.27.2.26.12.12.12.1.1.1a" xref="S3.E3.m1.26.26.1a.cmml">⁡</mo><mrow id="S3.E3.m1.27.27.2.26.12.12.12.1.1.1.1.1" xref="S3.E3.m1.26.26.1.cmml"><mo id="S3.E3.m1.12.12.12.6.6.6" xref="S3.E3.m1.26.26.1a.cmml">(</mo><mrow id="S3.E3.m1.27.27.2.26.12.12.12.1.1.1.1.1.1" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.13.13.13.7.7.7" xref="S3.E3.m1.13.13.13.7.7.7.cmml">V</mi><mo id="S3.E3.m1.27.27.2.26.12.12.12.1.1.1.1.1.1.1" xref="S3.E3.m1.26.26.1a.cmml">⁢</mo><msup id="S3.E3.m1.27.27.2.26.12.12.12.1.1.1.1.1.1.2" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.14.14.14.8.8.8" xref="S3.E3.m1.14.14.14.8.8.8.cmml">U</mi><mo id="S3.E3.m1.15.15.15.9.9.9.1" xref="S3.E3.m1.15.15.15.9.9.9.1.cmml">⊤</mo></msup></mrow><mo id="S3.E3.m1.16.16.16.10.10.10" xref="S3.E3.m1.26.26.1a.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.17.17.17.11.11.11" xref="S3.E3.m1.26.26.1a.cmml">)</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E3.m1.27.27.2e" xref="S3.E3.m1.26.26.1.cmml"><mtd id="S3.E3.m1.27.27.2f" xref="S3.E3.m1.26.26.1.cmml"><mrow id="S3.E3.m1.25.25.25.8.8" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.18.18.18.1.1.1" xref="S3.E3.m1.18.18.18.1.1.1.cmml">R</mi><mo id="S3.E3.m1.19.19.19.2.2.2" xref="S3.E3.m1.19.19.19.2.2.2.cmml">=</mo><mrow id="S3.E3.m1.25.25.25.8.8.9" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.20.20.20.3.3.3" xref="S3.E3.m1.20.20.20.3.3.3.cmml">V</mi><mo id="S3.E3.m1.25.25.25.8.8.9.1" xref="S3.E3.m1.26.26.1a.cmml">⁢</mo><mrow id="S3.E3.m1.25.25.25.8.8.9.2" xref="S3.E3.m1.26.26.1.cmml"><mo id="S3.E3.m1.21.21.21.4.4.4" xref="S3.E3.m1.26.26.1a.cmml">(</mo><mtable columnspacing="5pt" displaystyle="true" id="S3.E3.m1.22.22.22.5.5.5" rowspacing="0pt" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mtr id="S3.E3.m1.22.22.22.5.5.5a" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5b" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.1.1.1" xref="S3.E3.m1.22.22.22.5.5.5.1.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5c" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.1.2.1" xref="S3.E3.m1.22.22.22.5.5.5.1.2.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5d" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.1.3.1" xref="S3.E3.m1.22.22.22.5.5.5.1.3.1.cmml">0</mn></mtd></mtr><mtr id="S3.E3.m1.22.22.22.5.5.5e" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5f" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.2.1.1" xref="S3.E3.m1.22.22.22.5.5.5.2.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5g" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.2.2.1" xref="S3.E3.m1.22.22.22.5.5.5.2.2.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5h" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.2.3.1" xref="S3.E3.m1.22.22.22.5.5.5.2.3.1.cmml">0</mn></mtd></mtr><mtr id="S3.E3.m1.22.22.22.5.5.5i" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5j" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.3.1.1" xref="S3.E3.m1.22.22.22.5.5.5.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5k" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mn id="S3.E3.m1.22.22.22.5.5.5.3.2.1" xref="S3.E3.m1.22.22.22.5.5.5.3.2.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E3.m1.22.22.22.5.5.5l" xref="S3.E3.m1.22.22.22.5.5.5.cmml"><mi id="S3.E3.m1.22.22.22.5.5.5.3.3.1" xref="S3.E3.m1.22.22.22.5.5.5.3.3.1.cmml">d</mi></mtd></mtr></mtable><mo id="S3.E3.m1.23.23.23.6.6.6" xref="S3.E3.m1.26.26.1a.cmml">)</mo></mrow><mo id="S3.E3.m1.25.25.25.8.8.9.1a" xref="S3.E3.m1.26.26.1a.cmml">⁢</mo><msup id="S3.E3.m1.25.25.25.8.8.9.3" xref="S3.E3.m1.26.26.1.cmml"><mi id="S3.E3.m1.24.24.24.7.7.7" xref="S3.E3.m1.24.24.24.7.7.7.cmml">U</mi><mo id="S3.E3.m1.25.25.25.8.8.8.1" xref="S3.E3.m1.25.25.25.8.8.8.1.cmml">⊤</mo></msup></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E3.m1.27b"><apply id="S3.E3.m1.26.26.1.cmml" xref="S3.E3.m1.27.27.2"><and id="S3.E3.m1.26.26.1a.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1"></and><apply id="S3.E3.m1.26.26.1b.cmml" xref="S3.E3.m1.27.27.2"><eq id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"></eq><ci id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">𝐻</ci><apply id="S3.E3.m1.26.26.1.5.cmml" xref="S3.E3.m1.27.27.2"><times id="S3.E3.m1.26.26.1.5.1.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1"></times><ci id="S3.E3.m1.3.3.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3.3.3">𝑈</ci><ci id="S3.E3.m1.4.4.4.4.4.4.cmml" xref="S3.E3.m1.4.4.4.4.4.4">Σ</ci><apply id="S3.E3.m1.26.26.1.5.4.cmml" xref="S3.E3.m1.27.27.2"><csymbol cd="ambiguous" id="S3.E3.m1.26.26.1.5.4.1.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1">superscript</csymbol><ci id="S3.E3.m1.5.5.5.5.5.5.cmml" xref="S3.E3.m1.5.5.5.5.5.5">𝑉</ci><csymbol cd="latexml" id="S3.E3.m1.6.6.6.6.6.6.1.cmml" xref="S3.E3.m1.6.6.6.6.6.6.1">top</csymbol></apply><ci id="S3.E3.m1.7.7.7.1.1.1.cmml" xref="S3.E3.m1.7.7.7.1.1.1">𝑑</ci></apply></apply><apply id="S3.E3.m1.26.26.1c.cmml" xref="S3.E3.m1.27.27.2"><eq id="S3.E3.m1.8.8.8.2.2.2.cmml" xref="S3.E3.m1.8.8.8.2.2.2"></eq><share href="#S3.E3.m1.26.26.1.5.cmml" id="S3.E3.m1.26.26.1d.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1"></share><apply id="S3.E3.m1.26.26.1.1.cmml" xref="S3.E3.m1.27.27.2"><times id="S3.E3.m1.26.26.1.1.2.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1"></times><apply id="S3.E3.m1.26.26.1.1.1.2.cmml" xref="S3.E3.m1.27.27.2"><ci id="S3.E3.m1.9.9.9.3.3.3.cmml" xref="S3.E3.m1.9.9.9.3.3.3">sign</ci><apply id="S3.E3.m1.26.26.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.27.27.2"><ci id="S3.E3.m1.11.11.11.5.5.5.cmml" xref="S3.E3.m1.11.11.11.5.5.5">det</ci><apply id="S3.E3.m1.26.26.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.27.27.2"><times id="S3.E3.m1.26.26.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.27.27.2"></times><ci id="S3.E3.m1.13.13.13.7.7.7.cmml" xref="S3.E3.m1.13.13.13.7.7.7">𝑉</ci><apply id="S3.E3.m1.26.26.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.27.27.2"><csymbol cd="ambiguous" id="S3.E3.m1.26.26.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.27.27.2">superscript</csymbol><ci id="S3.E3.m1.14.14.14.8.8.8.cmml" xref="S3.E3.m1.14.14.14.8.8.8">𝑈</ci><csymbol cd="latexml" id="S3.E3.m1.15.15.15.9.9.9.1.cmml" xref="S3.E3.m1.15.15.15.9.9.9.1">top</csymbol></apply></apply></apply></apply><ci id="S3.E3.m1.18.18.18.1.1.1.cmml" xref="S3.E3.m1.18.18.18.1.1.1">𝑅</ci></apply></apply><apply id="S3.E3.m1.26.26.1e.cmml" xref="S3.E3.m1.27.27.2"><eq id="S3.E3.m1.19.19.19.2.2.2.cmml" xref="S3.E3.m1.19.19.19.2.2.2"></eq><share href="#S3.E3.m1.26.26.1.1.cmml" id="S3.E3.m1.26.26.1f.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1"></share><apply id="S3.E3.m1.26.26.1.8.cmml" xref="S3.E3.m1.27.27.2"><times id="S3.E3.m1.26.26.1.8.1.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1"></times><ci id="S3.E3.m1.20.20.20.3.3.3.cmml" xref="S3.E3.m1.20.20.20.3.3.3">𝑉</ci><matrix id="S3.E3.m1.22.22.22.5.5.5.cmml" xref="S3.E3.m1.22.22.22.5.5.5"><matrixrow id="S3.E3.m1.22.22.22.5.5.5a.cmml" xref="S3.E3.m1.22.22.22.5.5.5"><cn id="S3.E3.m1.22.22.22.5.5.5.1.1.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.1.1.1">1</cn><cn id="S3.E3.m1.22.22.22.5.5.5.1.2.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.1.2.1">0</cn><cn id="S3.E3.m1.22.22.22.5.5.5.1.3.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.1.3.1">0</cn></matrixrow><matrixrow id="S3.E3.m1.22.22.22.5.5.5b.cmml" xref="S3.E3.m1.22.22.22.5.5.5"><cn id="S3.E3.m1.22.22.22.5.5.5.2.1.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.2.1.1">0</cn><cn id="S3.E3.m1.22.22.22.5.5.5.2.2.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.2.2.1">1</cn><cn id="S3.E3.m1.22.22.22.5.5.5.2.3.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.2.3.1">0</cn></matrixrow><matrixrow id="S3.E3.m1.22.22.22.5.5.5c.cmml" xref="S3.E3.m1.22.22.22.5.5.5"><cn id="S3.E3.m1.22.22.22.5.5.5.3.1.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.3.1.1">0</cn><cn id="S3.E3.m1.22.22.22.5.5.5.3.2.1.cmml" type="integer" xref="S3.E3.m1.22.22.22.5.5.5.3.2.1">0</cn><ci id="S3.E3.m1.22.22.22.5.5.5.3.3.1.cmml" xref="S3.E3.m1.22.22.22.5.5.5.3.3.1">𝑑</ci></matrixrow></matrix><apply id="S3.E3.m1.26.26.1.8.4.cmml" xref="S3.E3.m1.27.27.2"><csymbol cd="ambiguous" id="S3.E3.m1.26.26.1.8.4.1.cmml" xref="S3.E3.m1.6.6.6.6.6.7.1">superscript</csymbol><ci id="S3.E3.m1.24.24.24.7.7.7.cmml" xref="S3.E3.m1.24.24.24.7.7.7">𝑈</ci><csymbol cd="latexml" id="S3.E3.m1.25.25.25.8.8.8.1.cmml" xref="S3.E3.m1.25.25.25.8.8.8.1">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.27c">\begin{gathered}H=U\Sigma V^{\top}\\
d=\operatorname{sign}\left(\operatorname{det}\left(VU^{\top}\right)\right)\\
R=V\left(\begin{array}[]{lll}1&amp;0&amp;0\\
0&amp;1&amp;0\\
0&amp;0&amp;d\end{array}\right)U^{\top}\end{gathered}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.27d">start_ROW start_CELL italic_H = italic_U roman_Σ italic_V start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT end_CELL end_ROW start_ROW start_CELL italic_d = roman_sign ( roman_det ( italic_V italic_U start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ) ) end_CELL end_ROW start_ROW start_CELL italic_R = italic_V ( start_ARRAY start_ROW start_CELL 1 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL italic_d end_CELL end_ROW end_ARRAY ) italic_U start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.7">Now that we have the translation matrix <math alttext="\mathrm{T}" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m1.1"><semantics id="S3.SS3.p1.6.m1.1a"><mi id="S3.SS3.p1.6.m1.1.1" mathvariant="normal" xref="S3.SS3.p1.6.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m1.1b"><ci id="S3.SS3.p1.6.m1.1.1.cmml" xref="S3.SS3.p1.6.m1.1.1">T</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m1.1c">\mathrm{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m1.1d">roman_T</annotation></semantics></math> and the optimal rotation <math alttext="\mathrm{R}" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m2.1"><semantics id="S3.SS3.p1.7.m2.1a"><mi id="S3.SS3.p1.7.m2.1.1" mathvariant="normal" xref="S3.SS3.p1.7.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m2.1b"><ci id="S3.SS3.p1.7.m2.1.1.cmml" xref="S3.SS3.p1.7.m2.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m2.1c">\mathrm{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m2.1d">roman_R</annotation></semantics></math> to project the key frame into the global standard:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R\times A+t=B" class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mrow id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml"><mrow id="S3.E4.m1.1.1.2.2" xref="S3.E4.m1.1.1.2.2.cmml"><mi id="S3.E4.m1.1.1.2.2.2" xref="S3.E4.m1.1.1.2.2.2.cmml">R</mi><mo id="S3.E4.m1.1.1.2.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.1.1.2.2.1.cmml">×</mo><mi id="S3.E4.m1.1.1.2.2.3" xref="S3.E4.m1.1.1.2.2.3.cmml">A</mi></mrow><mo id="S3.E4.m1.1.1.2.1" xref="S3.E4.m1.1.1.2.1.cmml">+</mo><mi id="S3.E4.m1.1.1.2.3" xref="S3.E4.m1.1.1.2.3.cmml">t</mi></mrow><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mi id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><apply id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"><plus id="S3.E4.m1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.2.1"></plus><apply id="S3.E4.m1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.2.2"><times id="S3.E4.m1.1.1.2.2.1.cmml" xref="S3.E4.m1.1.1.2.2.1"></times><ci id="S3.E4.m1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.2.2.2">𝑅</ci><ci id="S3.E4.m1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.2.2.3">𝐴</ci></apply><ci id="S3.E4.m1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.2.3">𝑡</ci></apply><ci id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">R\times A+t=B</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">italic_R × italic_A + italic_t = italic_B</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.9">Where <math alttext="A" class="ltx_Math" display="inline" id="S3.SS3.p1.8.m1.1"><semantics id="S3.SS3.p1.8.m1.1a"><mi id="S3.SS3.p1.8.m1.1.1" xref="S3.SS3.p1.8.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m1.1b"><ci id="S3.SS3.p1.8.m1.1.1.cmml" xref="S3.SS3.p1.8.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.8.m1.1d">italic_A</annotation></semantics></math> represents the original coordinates of the key frame’s key points; <math alttext="B" class="ltx_Math" display="inline" id="S3.SS3.p1.9.m2.1"><semantics id="S3.SS3.p1.9.m2.1a"><mi id="S3.SS3.p1.9.m2.1.1" xref="S3.SS3.p1.9.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m2.1b"><ci id="S3.SS3.p1.9.m2.1.1.cmml" xref="S3.SS3.p1.9.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.9.m2.1d">italic_B</annotation></semantics></math> represents the projected coordinates of the key frame’s key points.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>SoloPose: One-shot 3D human pose estimation network</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Spatio-temporal transformer</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We propose a one-shot many-to-many transformer-based method to extract feature maps from spatial and temporal data, as shown in Fig. <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.1 Spatio-temporal transformer ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">3</span></a>. Spatial information is represented by intra-frame content within respective frames, whereas temporal information is represented by inter-frame content between multiple frames along a time-series.</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<p class="ltx_p ltx_align_center ltx_align_center" id="S4.F3.1"><span class="ltx_text" id="S4.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="196" id="S4.F3.1.1.g1" src="extracted/5298414/Fig/pose.png" width="343"/></span></p>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.4.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.5.2" style="font-size:90%;">The framework of our proposed network, <span class="ltx_text ltx_font_italic" id="S4.F3.5.2.1">SoloPose</span> spatio-temporal transformer.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We first utilize the spatial transformer for each input frame to extract the spatial feature maps of each input frame. Then we utilize the temporal transformer with the spatial feature maps as the input to extract the temporal feature maps. Finally, we propose a heatmap task head (i.e., layer extraction) to convert temporal feature maps into our proposed 3D heatmap, which we discuss later.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.3">For the spatial transformer, we apply the pre-trained model, CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>, which has been pre-trained on an extensive dataset containing images and their corresponding text descriptions. Each frame goes through the spatial transformer to obtain spatial feature maps, whose size is <math alttext="1\times 200\times 192" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mn id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">1</mn><mo id="S4.SS1.p3.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p3.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">200</mn><mo id="S4.SS1.p3.1.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p3.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p3.1.m1.1.1.4" xref="S4.SS1.p3.1.m1.1.1.4.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><times id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1"></times><cn id="S4.SS1.p3.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.1.2">1</cn><cn id="S4.SS1.p3.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.1.3">200</cn><cn id="S4.SS1.p3.1.m1.1.1.4.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.1.4">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">1\times 200\times 192</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">1 × 200 × 192</annotation></semantics></math>. Then, we concatenate all the spatial feature maps along the channel dimension resulting in an output size that is <math alttext="n\times 200\times 192" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">n</mi><mo id="S4.SS1.p3.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p3.2.m2.1.1.1.cmml">×</mo><mn id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml">200</mn><mo id="S4.SS1.p3.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p3.2.m2.1.1.1.cmml">×</mo><mn id="S4.SS1.p3.2.m2.1.1.4" xref="S4.SS1.p3.2.m2.1.1.4.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><times id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1"></times><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝑛</ci><cn id="S4.SS1.p3.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.p3.2.m2.1.1.3">200</cn><cn id="S4.SS1.p3.2.m2.1.1.4.cmml" type="integer" xref="S4.SS1.p3.2.m2.1.1.4">192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">n\times 200\times 192</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">italic_n × 200 × 192</annotation></semantics></math>, where <math alttext="n" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mi id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">italic_n</annotation></semantics></math> is the number of frames in one clip.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.2">For the temporal transformer, we apply a linear embedding layer to flatten the spatial feature maps into 2D tokens. Our temporal transformer is mostly based on Swin transformer blocks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite> with an update to 3D relative position embedding. We calculate 3D relative distances between any two input tokens, as the position index to obtain the value of <math alttext="\mathbf{B}" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">𝐁</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">𝐁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">\mathbf{B}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">bold_B</annotation></semantics></math> from the 3D bias matrix <math alttext="\widehat{B}" class="ltx_Math" display="inline" id="S4.SS1.p4.2.m2.1"><semantics id="S4.SS1.p4.2.m2.1a"><mover accent="true" id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mi id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">B</mi><mo id="S4.SS1.p4.2.m2.1.1.1" xref="S4.SS1.p4.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><ci id="S4.SS1.p4.2.m2.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1.1">^</ci><ci id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">\widehat{B}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.2.m2.1d">over^ start_ARG italic_B end_ARG</annotation></semantics></math>, which contains relative weights that will be updated during the training process:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\operatorname{A}(\mathbf{Q},\mathbf{K},\mathbf{V})=\operatorname{Softmax}\left%
(\mathbf{Q}\mathbf{K}^{T}/\sqrt{d}+\mathbf{B}\right)\times\mathbf{V}," class="ltx_Math" display="block" id="S4.E5.m1.6"><semantics id="S4.E5.m1.6a"><mrow id="S4.E5.m1.6.6.1" xref="S4.E5.m1.6.6.1.1.cmml"><mrow id="S4.E5.m1.6.6.1.1" xref="S4.E5.m1.6.6.1.1.cmml"><mrow id="S4.E5.m1.6.6.1.1.3.2" xref="S4.E5.m1.6.6.1.1.3.1.cmml"><mi id="S4.E5.m1.1.1" mathvariant="normal" xref="S4.E5.m1.1.1.cmml">A</mi><mo id="S4.E5.m1.6.6.1.1.3.2a" xref="S4.E5.m1.6.6.1.1.3.1.cmml">⁡</mo><mrow id="S4.E5.m1.6.6.1.1.3.2.1" xref="S4.E5.m1.6.6.1.1.3.1.cmml"><mo id="S4.E5.m1.6.6.1.1.3.2.1.1" stretchy="false" xref="S4.E5.m1.6.6.1.1.3.1.cmml">(</mo><mi id="S4.E5.m1.2.2" xref="S4.E5.m1.2.2.cmml">𝐐</mi><mo id="S4.E5.m1.6.6.1.1.3.2.1.2" xref="S4.E5.m1.6.6.1.1.3.1.cmml">,</mo><mi id="S4.E5.m1.3.3" xref="S4.E5.m1.3.3.cmml">𝐊</mi><mo id="S4.E5.m1.6.6.1.1.3.2.1.3" xref="S4.E5.m1.6.6.1.1.3.1.cmml">,</mo><mi id="S4.E5.m1.4.4" xref="S4.E5.m1.4.4.cmml">𝐕</mi><mo id="S4.E5.m1.6.6.1.1.3.2.1.4" stretchy="false" xref="S4.E5.m1.6.6.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.6.6.1.1.2" xref="S4.E5.m1.6.6.1.1.2.cmml">=</mo><mrow id="S4.E5.m1.6.6.1.1.1" xref="S4.E5.m1.6.6.1.1.1.cmml"><mrow id="S4.E5.m1.6.6.1.1.1.1.1" xref="S4.E5.m1.6.6.1.1.1.1.2.cmml"><mi id="S4.E5.m1.5.5" xref="S4.E5.m1.5.5.cmml">Softmax</mi><mo id="S4.E5.m1.6.6.1.1.1.1.1a" xref="S4.E5.m1.6.6.1.1.1.1.2.cmml">⁡</mo><mrow id="S4.E5.m1.6.6.1.1.1.1.1.1" xref="S4.E5.m1.6.6.1.1.1.1.2.cmml"><mo id="S4.E5.m1.6.6.1.1.1.1.1.1.2" xref="S4.E5.m1.6.6.1.1.1.1.2.cmml">(</mo><mrow id="S4.E5.m1.6.6.1.1.1.1.1.1.1" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.cmml"><mrow id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.cmml"><msup id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.2" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml">𝐐𝐊</mi><mi id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.3" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml">T</mi></msup><mo id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.1" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">/</mo><msqrt id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3.cmml"><mi id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3.2" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml">d</mi></msqrt></mrow><mo id="S4.E5.m1.6.6.1.1.1.1.1.1.1.1" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S4.E5.m1.6.6.1.1.1.1.1.1.1.3" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.3.cmml">𝐁</mi></mrow><mo id="S4.E5.m1.6.6.1.1.1.1.1.1.3" rspace="0.055em" xref="S4.E5.m1.6.6.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.6.6.1.1.1.2" rspace="0.222em" xref="S4.E5.m1.6.6.1.1.1.2.cmml">×</mo><mi id="S4.E5.m1.6.6.1.1.1.3" xref="S4.E5.m1.6.6.1.1.1.3.cmml">𝐕</mi></mrow></mrow><mo id="S4.E5.m1.6.6.1.2" xref="S4.E5.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.6b"><apply id="S4.E5.m1.6.6.1.1.cmml" xref="S4.E5.m1.6.6.1"><eq id="S4.E5.m1.6.6.1.1.2.cmml" xref="S4.E5.m1.6.6.1.1.2"></eq><apply id="S4.E5.m1.6.6.1.1.3.1.cmml" xref="S4.E5.m1.6.6.1.1.3.2"><ci id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1">A</ci><ci id="S4.E5.m1.2.2.cmml" xref="S4.E5.m1.2.2">𝐐</ci><ci id="S4.E5.m1.3.3.cmml" xref="S4.E5.m1.3.3">𝐊</ci><ci id="S4.E5.m1.4.4.cmml" xref="S4.E5.m1.4.4">𝐕</ci></apply><apply id="S4.E5.m1.6.6.1.1.1.cmml" xref="S4.E5.m1.6.6.1.1.1"><times id="S4.E5.m1.6.6.1.1.1.2.cmml" xref="S4.E5.m1.6.6.1.1.1.2"></times><apply id="S4.E5.m1.6.6.1.1.1.1.2.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1"><ci id="S4.E5.m1.5.5.cmml" xref="S4.E5.m1.5.5">Softmax</ci><apply id="S4.E5.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1"><plus id="S4.E5.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.1"></plus><apply id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2"><divide id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.1"></divide><apply id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.2">𝐐𝐊</ci><ci id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.2.3">𝑇</ci></apply><apply id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3"><root id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3a.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3"></root><ci id="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.2.3.2">𝑑</ci></apply></apply><ci id="S4.E5.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.6.6.1.1.1.1.1.1.1.3">𝐁</ci></apply></apply><ci id="S4.E5.m1.6.6.1.1.1.3.cmml" xref="S4.E5.m1.6.6.1.1.1.3">𝐕</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.6c">\operatorname{A}(\mathbf{Q},\mathbf{K},\mathbf{V})=\operatorname{Softmax}\left%
(\mathbf{Q}\mathbf{K}^{T}/\sqrt{d}+\mathbf{B}\right)\times\mathbf{V},</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.6d">roman_A ( bold_Q , bold_K , bold_V ) = roman_Softmax ( bold_QK start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT / square-root start_ARG italic_d end_ARG + bold_B ) × bold_V ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p4.3">where <math alttext="\mathbf{Q},\mathbf{K},\mathbf{V}" class="ltx_Math" display="inline" id="S4.SS1.p4.3.m1.3"><semantics id="S4.SS1.p4.3.m1.3a"><mrow id="S4.SS1.p4.3.m1.3.4.2" xref="S4.SS1.p4.3.m1.3.4.1.cmml"><mi id="S4.SS1.p4.3.m1.1.1" xref="S4.SS1.p4.3.m1.1.1.cmml">𝐐</mi><mo id="S4.SS1.p4.3.m1.3.4.2.1" xref="S4.SS1.p4.3.m1.3.4.1.cmml">,</mo><mi id="S4.SS1.p4.3.m1.2.2" xref="S4.SS1.p4.3.m1.2.2.cmml">𝐊</mi><mo id="S4.SS1.p4.3.m1.3.4.2.2" xref="S4.SS1.p4.3.m1.3.4.1.cmml">,</mo><mi id="S4.SS1.p4.3.m1.3.3" xref="S4.SS1.p4.3.m1.3.3.cmml">𝐕</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m1.3b"><list id="S4.SS1.p4.3.m1.3.4.1.cmml" xref="S4.SS1.p4.3.m1.3.4.2"><ci id="S4.SS1.p4.3.m1.1.1.cmml" xref="S4.SS1.p4.3.m1.1.1">𝐐</ci><ci id="S4.SS1.p4.3.m1.2.2.cmml" xref="S4.SS1.p4.3.m1.2.2">𝐊</ci><ci id="S4.SS1.p4.3.m1.3.3.cmml" xref="S4.SS1.p4.3.m1.3.3">𝐕</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m1.3c">\mathbf{Q},\mathbf{K},\mathbf{V}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.3.m1.3d">bold_Q , bold_K , bold_V</annotation></semantics></math> are the query, key and value matrices.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">In the last layer, we apply a heatmap task head by 3 convolutional neural networks to reshape the temporal feature maps into our proposed 3D heatmap, which is a probability result introduced in the next section.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>HeatPose: 3D Gaussian heatmap</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We propose a <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.1">HeatPose</span>, a 3D heatmap based on Gaussian mixture model (GMM)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>. Although conventional GMMs do not factor weights into its various Gaussian distributions, we adapted GMM in HeatPose to represent varying degrees of probabilistic proximity to the ground truth of a given target key point across different weights of Gaussian distributions. In other words, we generated Gaussian distributions for each key point, each of which are evaluated for closeness to the ground truth. The maximum value of a given Gaussian distribution would be the actual ground truth positioning of its corresponding target key point. We refer to this target-based distribution as the main 3D Gaussian Distribution, and it is the primary mechanism of HeatPose.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">However, HeatPose is also supplemented by factoring information regarding key points that are kinematically adjacent from a given target key point (e.g., direction, distance), which we represent with a finite number of target-adjacent distributions that we refer to as the side 3D Gaussian Distributions.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Side 3D Gaussian distribution may be understood by hypothetically considering the neck key point as a given target key point, as seen in <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ 4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">5</span></a> (A). In this example, the neck key point is kinematically adjacent to the key points of the shoulder, head, and pubis Fig. <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ 4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">5</span></a> (A). The application of kinematically adjacent key points in HeatPose serves to reflect closer-to-reality distributions as the probability of a key point is affected by key points nearby. As seen in Fig. <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">4</span></a>, we present a comparison of conventional 3D heatmaps without kinematic information (left) and HeatPose with application of kinematically adjacent keypoints (right). The distinction between the application of kinematically adjacent key points and conventional 3D heatmaps without such kinematic information is illustrated in Fig. <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">4</span></a></p>
</div>
<figure class="ltx_figure" id="S4.F4">
<p class="ltx_p ltx_align_center ltx_align_center" id="S4.F4.1"><span class="ltx_text" id="S4.F4.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="250" id="S4.F4.1.1.g1" src="extracted/5298414/Fig/heatMap.png" width="598"/></span></p>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.3.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.4.2" style="font-size:90%;">The left figure (A) is the 3D heatmap of human key points <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>. The right figure (B) is our proposed heatmap, HeatPose. Each sphere in the right figure represents a key point with discrete points with unique probability distributions represented with different colors, with red signifying close to 1 probability as a key point, and purple signifying close to 0 probability. </span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.5">For each target key point’s main 3D Gaussian distribution, we set coordinates of the target key point as <math alttext="\mu_{main}" class="ltx_Math" display="inline" id="S4.SS2.p4.1.m1.1"><semantics id="S4.SS2.p4.1.m1.1a"><msub id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml">μ</mi><mrow id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml"><mi id="S4.SS2.p4.1.m1.1.1.3.2" xref="S4.SS2.p4.1.m1.1.1.3.2.cmml">m</mi><mo id="S4.SS2.p4.1.m1.1.1.3.1" xref="S4.SS2.p4.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.1.m1.1.1.3.3" xref="S4.SS2.p4.1.m1.1.1.3.3.cmml">a</mi><mo id="S4.SS2.p4.1.m1.1.1.3.1a" xref="S4.SS2.p4.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.1.m1.1.1.3.4" xref="S4.SS2.p4.1.m1.1.1.3.4.cmml">i</mi><mo id="S4.SS2.p4.1.m1.1.1.3.1b" xref="S4.SS2.p4.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.1.m1.1.1.3.5" xref="S4.SS2.p4.1.m1.1.1.3.5.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">𝜇</ci><apply id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3"><times id="S4.SS2.p4.1.m1.1.1.3.1.cmml" xref="S4.SS2.p4.1.m1.1.1.3.1"></times><ci id="S4.SS2.p4.1.m1.1.1.3.2.cmml" xref="S4.SS2.p4.1.m1.1.1.3.2">𝑚</ci><ci id="S4.SS2.p4.1.m1.1.1.3.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3.3">𝑎</ci><ci id="S4.SS2.p4.1.m1.1.1.3.4.cmml" xref="S4.SS2.p4.1.m1.1.1.3.4">𝑖</ci><ci id="S4.SS2.p4.1.m1.1.1.3.5.cmml" xref="S4.SS2.p4.1.m1.1.1.3.5">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">\mu_{main}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">italic_μ start_POSTSUBSCRIPT italic_m italic_a italic_i italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, and a specified covariance matrix as <math alttext="\sigma_{main}" class="ltx_Math" display="inline" id="S4.SS2.p4.2.m2.1"><semantics id="S4.SS2.p4.2.m2.1a"><msub id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">σ</mi><mrow id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml"><mi id="S4.SS2.p4.2.m2.1.1.3.2" xref="S4.SS2.p4.2.m2.1.1.3.2.cmml">m</mi><mo id="S4.SS2.p4.2.m2.1.1.3.1" xref="S4.SS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.2.m2.1.1.3.3" xref="S4.SS2.p4.2.m2.1.1.3.3.cmml">a</mi><mo id="S4.SS2.p4.2.m2.1.1.3.1a" xref="S4.SS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.2.m2.1.1.3.4" xref="S4.SS2.p4.2.m2.1.1.3.4.cmml">i</mi><mo id="S4.SS2.p4.2.m2.1.1.3.1b" xref="S4.SS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.2.m2.1.1.3.5" xref="S4.SS2.p4.2.m2.1.1.3.5.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">𝜎</ci><apply id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3"><times id="S4.SS2.p4.2.m2.1.1.3.1.cmml" xref="S4.SS2.p4.2.m2.1.1.3.1"></times><ci id="S4.SS2.p4.2.m2.1.1.3.2.cmml" xref="S4.SS2.p4.2.m2.1.1.3.2">𝑚</ci><ci id="S4.SS2.p4.2.m2.1.1.3.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3.3">𝑎</ci><ci id="S4.SS2.p4.2.m2.1.1.3.4.cmml" xref="S4.SS2.p4.2.m2.1.1.3.4">𝑖</ci><ci id="S4.SS2.p4.2.m2.1.1.3.5.cmml" xref="S4.SS2.p4.2.m2.1.1.3.5">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">\sigma_{main}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.2.m2.1d">italic_σ start_POSTSUBSCRIPT italic_m italic_a italic_i italic_n end_POSTSUBSCRIPT</annotation></semantics></math> to represent the ground truth of a given target key point. To decide each target key point’s side 3D Gaussian distribution, we compute the number <math alttext="N_{side}" class="ltx_Math" display="inline" id="S4.SS2.p4.3.m3.1"><semantics id="S4.SS2.p4.3.m3.1a"><msub id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mi id="S4.SS2.p4.3.m3.1.1.2" xref="S4.SS2.p4.3.m3.1.1.2.cmml">N</mi><mrow id="S4.SS2.p4.3.m3.1.1.3" xref="S4.SS2.p4.3.m3.1.1.3.cmml"><mi id="S4.SS2.p4.3.m3.1.1.3.2" xref="S4.SS2.p4.3.m3.1.1.3.2.cmml">s</mi><mo id="S4.SS2.p4.3.m3.1.1.3.1" xref="S4.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.3.m3.1.1.3.3" xref="S4.SS2.p4.3.m3.1.1.3.3.cmml">i</mi><mo id="S4.SS2.p4.3.m3.1.1.3.1a" xref="S4.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.3.m3.1.1.3.4" xref="S4.SS2.p4.3.m3.1.1.3.4.cmml">d</mi><mo id="S4.SS2.p4.3.m3.1.1.3.1b" xref="S4.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p4.3.m3.1.1.3.5" xref="S4.SS2.p4.3.m3.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2">𝑁</ci><apply id="S4.SS2.p4.3.m3.1.1.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3"><times id="S4.SS2.p4.3.m3.1.1.3.1.cmml" xref="S4.SS2.p4.3.m3.1.1.3.1"></times><ci id="S4.SS2.p4.3.m3.1.1.3.2.cmml" xref="S4.SS2.p4.3.m3.1.1.3.2">𝑠</ci><ci id="S4.SS2.p4.3.m3.1.1.3.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3.3">𝑖</ci><ci id="S4.SS2.p4.3.m3.1.1.3.4.cmml" xref="S4.SS2.p4.3.m3.1.1.3.4">𝑑</ci><ci id="S4.SS2.p4.3.m3.1.1.3.5.cmml" xref="S4.SS2.p4.3.m3.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">N_{side}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.3.m3.1d">italic_N start_POSTSUBSCRIPT italic_s italic_i italic_d italic_e end_POSTSUBSCRIPT</annotation></semantics></math> of side Gaussian distributions in advance to represent the distance <math alttext="D\left(P_{t},P_{a}\right)" class="ltx_Math" display="inline" id="S4.SS2.p4.4.m4.2"><semantics id="S4.SS2.p4.4.m4.2a"><mrow id="S4.SS2.p4.4.m4.2.2" xref="S4.SS2.p4.4.m4.2.2.cmml"><mi id="S4.SS2.p4.4.m4.2.2.4" xref="S4.SS2.p4.4.m4.2.2.4.cmml">D</mi><mo id="S4.SS2.p4.4.m4.2.2.3" xref="S4.SS2.p4.4.m4.2.2.3.cmml">⁢</mo><mrow id="S4.SS2.p4.4.m4.2.2.2.2" xref="S4.SS2.p4.4.m4.2.2.2.3.cmml"><mo id="S4.SS2.p4.4.m4.2.2.2.2.3" xref="S4.SS2.p4.4.m4.2.2.2.3.cmml">(</mo><msub id="S4.SS2.p4.4.m4.1.1.1.1.1" xref="S4.SS2.p4.4.m4.1.1.1.1.1.cmml"><mi id="S4.SS2.p4.4.m4.1.1.1.1.1.2" xref="S4.SS2.p4.4.m4.1.1.1.1.1.2.cmml">P</mi><mi id="S4.SS2.p4.4.m4.1.1.1.1.1.3" xref="S4.SS2.p4.4.m4.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.SS2.p4.4.m4.2.2.2.2.4" xref="S4.SS2.p4.4.m4.2.2.2.3.cmml">,</mo><msub id="S4.SS2.p4.4.m4.2.2.2.2.2" xref="S4.SS2.p4.4.m4.2.2.2.2.2.cmml"><mi id="S4.SS2.p4.4.m4.2.2.2.2.2.2" xref="S4.SS2.p4.4.m4.2.2.2.2.2.2.cmml">P</mi><mi id="S4.SS2.p4.4.m4.2.2.2.2.2.3" xref="S4.SS2.p4.4.m4.2.2.2.2.2.3.cmml">a</mi></msub><mo id="S4.SS2.p4.4.m4.2.2.2.2.5" xref="S4.SS2.p4.4.m4.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.2b"><apply id="S4.SS2.p4.4.m4.2.2.cmml" xref="S4.SS2.p4.4.m4.2.2"><times id="S4.SS2.p4.4.m4.2.2.3.cmml" xref="S4.SS2.p4.4.m4.2.2.3"></times><ci id="S4.SS2.p4.4.m4.2.2.4.cmml" xref="S4.SS2.p4.4.m4.2.2.4">𝐷</ci><interval closure="open" id="S4.SS2.p4.4.m4.2.2.2.3.cmml" xref="S4.SS2.p4.4.m4.2.2.2.2"><apply id="S4.SS2.p4.4.m4.1.1.1.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.4.m4.1.1.1.1.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p4.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS2.p4.4.m4.1.1.1.1.1.2">𝑃</ci><ci id="S4.SS2.p4.4.m4.1.1.1.1.1.3.cmml" xref="S4.SS2.p4.4.m4.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.SS2.p4.4.m4.2.2.2.2.2.cmml" xref="S4.SS2.p4.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p4.4.m4.2.2.2.2.2.1.cmml" xref="S4.SS2.p4.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p4.4.m4.2.2.2.2.2.2.cmml" xref="S4.SS2.p4.4.m4.2.2.2.2.2.2">𝑃</ci><ci id="S4.SS2.p4.4.m4.2.2.2.2.2.3.cmml" xref="S4.SS2.p4.4.m4.2.2.2.2.2.3">𝑎</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.2c">D\left(P_{t},P_{a}\right)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.4.m4.2d">italic_D ( italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT )</annotation></semantics></math> between a given target key point and a kinematically adjacent key point following the Equation 6, where <math alttext="c" class="ltx_Math" display="inline" id="S4.SS2.p4.5.m5.1"><semantics id="S4.SS2.p4.5.m5.1a"><mi id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><ci id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.5.m5.1d">italic_c</annotation></semantics></math> is a constant. Thus, the longer the distance between two adjacent key points, the more side Gaussian distributions there will be to represent kinematic information, so that each key point is unique represented by a different distribution:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="N_{s}=\frac{D\left(P_{t},P_{a}\right)}{c}" class="ltx_Math" display="block" id="S4.E6.m1.2"><semantics id="S4.E6.m1.2a"><mrow id="S4.E6.m1.2.3" xref="S4.E6.m1.2.3.cmml"><msub id="S4.E6.m1.2.3.2" xref="S4.E6.m1.2.3.2.cmml"><mi id="S4.E6.m1.2.3.2.2" xref="S4.E6.m1.2.3.2.2.cmml">N</mi><mi id="S4.E6.m1.2.3.2.3" xref="S4.E6.m1.2.3.2.3.cmml">s</mi></msub><mo id="S4.E6.m1.2.3.1" xref="S4.E6.m1.2.3.1.cmml">=</mo><mfrac id="S4.E6.m1.2.2" xref="S4.E6.m1.2.2.cmml"><mrow id="S4.E6.m1.2.2.2" xref="S4.E6.m1.2.2.2.cmml"><mi id="S4.E6.m1.2.2.2.4" xref="S4.E6.m1.2.2.2.4.cmml">D</mi><mo id="S4.E6.m1.2.2.2.3" xref="S4.E6.m1.2.2.2.3.cmml">⁢</mo><mrow id="S4.E6.m1.2.2.2.2.2" xref="S4.E6.m1.2.2.2.2.3.cmml"><mo id="S4.E6.m1.2.2.2.2.2.3" xref="S4.E6.m1.2.2.2.2.3.cmml">(</mo><msub id="S4.E6.m1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.cmml"><mi id="S4.E6.m1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.2.cmml">P</mi><mi id="S4.E6.m1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E6.m1.2.2.2.2.2.4" xref="S4.E6.m1.2.2.2.2.3.cmml">,</mo><msub id="S4.E6.m1.2.2.2.2.2.2" xref="S4.E6.m1.2.2.2.2.2.2.cmml"><mi id="S4.E6.m1.2.2.2.2.2.2.2" xref="S4.E6.m1.2.2.2.2.2.2.2.cmml">P</mi><mi id="S4.E6.m1.2.2.2.2.2.2.3" xref="S4.E6.m1.2.2.2.2.2.2.3.cmml">a</mi></msub><mo id="S4.E6.m1.2.2.2.2.2.5" xref="S4.E6.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mi id="S4.E6.m1.2.2.4" xref="S4.E6.m1.2.2.4.cmml">c</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.2b"><apply id="S4.E6.m1.2.3.cmml" xref="S4.E6.m1.2.3"><eq id="S4.E6.m1.2.3.1.cmml" xref="S4.E6.m1.2.3.1"></eq><apply id="S4.E6.m1.2.3.2.cmml" xref="S4.E6.m1.2.3.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.3.2.1.cmml" xref="S4.E6.m1.2.3.2">subscript</csymbol><ci id="S4.E6.m1.2.3.2.2.cmml" xref="S4.E6.m1.2.3.2.2">𝑁</ci><ci id="S4.E6.m1.2.3.2.3.cmml" xref="S4.E6.m1.2.3.2.3">𝑠</ci></apply><apply id="S4.E6.m1.2.2.cmml" xref="S4.E6.m1.2.2"><divide id="S4.E6.m1.2.2.3.cmml" xref="S4.E6.m1.2.2"></divide><apply id="S4.E6.m1.2.2.2.cmml" xref="S4.E6.m1.2.2.2"><times id="S4.E6.m1.2.2.2.3.cmml" xref="S4.E6.m1.2.2.2.3"></times><ci id="S4.E6.m1.2.2.2.4.cmml" xref="S4.E6.m1.2.2.2.4">𝐷</ci><interval closure="open" id="S4.E6.m1.2.2.2.2.3.cmml" xref="S4.E6.m1.2.2.2.2.2"><apply id="S4.E6.m1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2">𝑃</ci><ci id="S4.E6.m1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.E6.m1.2.2.2.2.2.2.cmml" xref="S4.E6.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.2.2.2.2.1.cmml" xref="S4.E6.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.E6.m1.2.2.2.2.2.2.2.cmml" xref="S4.E6.m1.2.2.2.2.2.2.2">𝑃</ci><ci id="S4.E6.m1.2.2.2.2.2.2.3.cmml" xref="S4.E6.m1.2.2.2.2.2.2.3">𝑎</ci></apply></interval></apply><ci id="S4.E6.m1.2.2.4.cmml" xref="S4.E6.m1.2.2.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.2c">N_{s}=\frac{D\left(P_{t},P_{a}\right)}{c}</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.2d">italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT = divide start_ARG italic_D ( italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ) end_ARG start_ARG italic_c end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<figure class="ltx_figure" id="S4.F5">
<p class="ltx_p ltx_align_center ltx_align_center" id="S4.F5.1"><span class="ltx_text" id="S4.F5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="731" id="S4.F5.1.1.g1" src="extracted/5298414/Fig/heat_example.png" width="598"/></span></p>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.3.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.4.2" style="font-size:90%;">HeatPose visual summary. The upper figure (A) demonstrates the kinematically adjacent key points if we hypothetically considered the neck key point as the target key point. Adjacent key points are green and transitional points are gray. The lower figure (B) is an example of key points with two adjacent points, with the final results of the Gaussian Mixture Model distribution (GMM) of target points represented by the green line. The red line is the main 3D Gaussian distribution in GMM. And the 3 black lines are the side 3D Gaussian distributions in GMM.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.10">Once we determine a finite number <math alttext="N_{side}" class="ltx_Math" display="inline" id="S4.SS2.p5.1.m1.1"><semantics id="S4.SS2.p5.1.m1.1a"><msub id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml"><mi id="S4.SS2.p5.1.m1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.2.cmml">N</mi><mrow id="S4.SS2.p5.1.m1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.3.cmml"><mi id="S4.SS2.p5.1.m1.1.1.3.2" xref="S4.SS2.p5.1.m1.1.1.3.2.cmml">s</mi><mo id="S4.SS2.p5.1.m1.1.1.3.1" xref="S4.SS2.p5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.1.m1.1.1.3.3" xref="S4.SS2.p5.1.m1.1.1.3.3.cmml">i</mi><mo id="S4.SS2.p5.1.m1.1.1.3.1a" xref="S4.SS2.p5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.1.m1.1.1.3.4" xref="S4.SS2.p5.1.m1.1.1.3.4.cmml">d</mi><mo id="S4.SS2.p5.1.m1.1.1.3.1b" xref="S4.SS2.p5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.1.m1.1.1.3.5" xref="S4.SS2.p5.1.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p5.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.2">𝑁</ci><apply id="S4.SS2.p5.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3"><times id="S4.SS2.p5.1.m1.1.1.3.1.cmml" xref="S4.SS2.p5.1.m1.1.1.3.1"></times><ci id="S4.SS2.p5.1.m1.1.1.3.2.cmml" xref="S4.SS2.p5.1.m1.1.1.3.2">𝑠</ci><ci id="S4.SS2.p5.1.m1.1.1.3.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3.3">𝑖</ci><ci id="S4.SS2.p5.1.m1.1.1.3.4.cmml" xref="S4.SS2.p5.1.m1.1.1.3.4">𝑑</ci><ci id="S4.SS2.p5.1.m1.1.1.3.5.cmml" xref="S4.SS2.p5.1.m1.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">N_{side}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.1.m1.1d">italic_N start_POSTSUBSCRIPT italic_s italic_i italic_d italic_e end_POSTSUBSCRIPT</annotation></semantics></math> of side 3D Gaussian distributions for each adjacent key point, we compute coordinates of <math alttext="N_{p}" class="ltx_Math" display="inline" id="S4.SS2.p5.2.m2.1"><semantics id="S4.SS2.p5.2.m2.1a"><msub id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml"><mi id="S4.SS2.p5.2.m2.1.1.2" xref="S4.SS2.p5.2.m2.1.1.2.cmml">N</mi><mi id="S4.SS2.p5.2.m2.1.1.3" xref="S4.SS2.p5.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><apply id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.2.m2.1.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p5.2.m2.1.1.2.cmml" xref="S4.SS2.p5.2.m2.1.1.2">𝑁</ci><ci id="S4.SS2.p5.2.m2.1.1.3.cmml" xref="S4.SS2.p5.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">N_{p}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.2.m2.1d">italic_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> transitional points located between the target key point and an adjacent key point. As shown in Fig. <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ 4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">5</span></a>, the first transitional point in <math alttext="N_{s}" class="ltx_Math" display="inline" id="S4.SS2.p5.3.m3.1"><semantics id="S4.SS2.p5.3.m3.1a"><msub id="S4.SS2.p5.3.m3.1.1" xref="S4.SS2.p5.3.m3.1.1.cmml"><mi id="S4.SS2.p5.3.m3.1.1.2" xref="S4.SS2.p5.3.m3.1.1.2.cmml">N</mi><mi id="S4.SS2.p5.3.m3.1.1.3" xref="S4.SS2.p5.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.3.m3.1b"><apply id="S4.SS2.p5.3.m3.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.3.m3.1.1.1.cmml" xref="S4.SS2.p5.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p5.3.m3.1.1.2.cmml" xref="S4.SS2.p5.3.m3.1.1.2">𝑁</ci><ci id="S4.SS2.p5.3.m3.1.1.3.cmml" xref="S4.SS2.p5.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.3.m3.1c">N_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.3.m3.1d">italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> number of transitional points is <math alttext="c" class="ltx_Math" display="inline" id="S4.SS2.p5.4.m4.1"><semantics id="S4.SS2.p5.4.m4.1a"><mi id="S4.SS2.p5.4.m4.1.1" xref="S4.SS2.p5.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.4.m4.1b"><ci id="S4.SS2.p5.4.m4.1.1.cmml" xref="S4.SS2.p5.4.m4.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.4.m4.1d">italic_c</annotation></semantics></math> euclidean distance away from a given target key point. Each subsequent transitional point is <math alttext="c" class="ltx_Math" display="inline" id="S4.SS2.p5.5.m5.1"><semantics id="S4.SS2.p5.5.m5.1a"><mi id="S4.SS2.p5.5.m5.1.1" xref="S4.SS2.p5.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.5.m5.1b"><ci id="S4.SS2.p5.5.m5.1.1.cmml" xref="S4.SS2.p5.5.m5.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.5.m5.1c">c</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.5.m5.1d">italic_c</annotation></semantics></math> distance away from the previous transitional point. For the <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p5.6.m6.1"><semantics id="S4.SS2.p5.6.m6.1a"><mi id="S4.SS2.p5.6.m6.1.1" xref="S4.SS2.p5.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.6.m6.1b"><ci id="S4.SS2.p5.6.m6.1.1.cmml" xref="S4.SS2.p5.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.6.m6.1d">italic_i</annotation></semantics></math>th side 3D Gaussian distributions, we set the coordinates of <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p5.7.m7.1"><semantics id="S4.SS2.p5.7.m7.1a"><mi id="S4.SS2.p5.7.m7.1.1" xref="S4.SS2.p5.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.7.m7.1b"><ci id="S4.SS2.p5.7.m7.1.1.cmml" xref="S4.SS2.p5.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.7.m7.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.7.m7.1d">italic_i</annotation></semantics></math>th middle points as <math alttext="\mu_{side}^{i}" class="ltx_Math" display="inline" id="S4.SS2.p5.8.m8.1"><semantics id="S4.SS2.p5.8.m8.1a"><msubsup id="S4.SS2.p5.8.m8.1.1" xref="S4.SS2.p5.8.m8.1.1.cmml"><mi id="S4.SS2.p5.8.m8.1.1.2.2" xref="S4.SS2.p5.8.m8.1.1.2.2.cmml">μ</mi><mrow id="S4.SS2.p5.8.m8.1.1.2.3" xref="S4.SS2.p5.8.m8.1.1.2.3.cmml"><mi id="S4.SS2.p5.8.m8.1.1.2.3.2" xref="S4.SS2.p5.8.m8.1.1.2.3.2.cmml">s</mi><mo id="S4.SS2.p5.8.m8.1.1.2.3.1" xref="S4.SS2.p5.8.m8.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.8.m8.1.1.2.3.3" xref="S4.SS2.p5.8.m8.1.1.2.3.3.cmml">i</mi><mo id="S4.SS2.p5.8.m8.1.1.2.3.1a" xref="S4.SS2.p5.8.m8.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.8.m8.1.1.2.3.4" xref="S4.SS2.p5.8.m8.1.1.2.3.4.cmml">d</mi><mo id="S4.SS2.p5.8.m8.1.1.2.3.1b" xref="S4.SS2.p5.8.m8.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.8.m8.1.1.2.3.5" xref="S4.SS2.p5.8.m8.1.1.2.3.5.cmml">e</mi></mrow><mi id="S4.SS2.p5.8.m8.1.1.3" xref="S4.SS2.p5.8.m8.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.8.m8.1b"><apply id="S4.SS2.p5.8.m8.1.1.cmml" xref="S4.SS2.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.8.m8.1.1.1.cmml" xref="S4.SS2.p5.8.m8.1.1">superscript</csymbol><apply id="S4.SS2.p5.8.m8.1.1.2.cmml" xref="S4.SS2.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.8.m8.1.1.2.1.cmml" xref="S4.SS2.p5.8.m8.1.1">subscript</csymbol><ci id="S4.SS2.p5.8.m8.1.1.2.2.cmml" xref="S4.SS2.p5.8.m8.1.1.2.2">𝜇</ci><apply id="S4.SS2.p5.8.m8.1.1.2.3.cmml" xref="S4.SS2.p5.8.m8.1.1.2.3"><times id="S4.SS2.p5.8.m8.1.1.2.3.1.cmml" xref="S4.SS2.p5.8.m8.1.1.2.3.1"></times><ci id="S4.SS2.p5.8.m8.1.1.2.3.2.cmml" xref="S4.SS2.p5.8.m8.1.1.2.3.2">𝑠</ci><ci id="S4.SS2.p5.8.m8.1.1.2.3.3.cmml" xref="S4.SS2.p5.8.m8.1.1.2.3.3">𝑖</ci><ci id="S4.SS2.p5.8.m8.1.1.2.3.4.cmml" xref="S4.SS2.p5.8.m8.1.1.2.3.4">𝑑</ci><ci id="S4.SS2.p5.8.m8.1.1.2.3.5.cmml" xref="S4.SS2.p5.8.m8.1.1.2.3.5">𝑒</ci></apply></apply><ci id="S4.SS2.p5.8.m8.1.1.3.cmml" xref="S4.SS2.p5.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.8.m8.1c">\mu_{side}^{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.8.m8.1d">italic_μ start_POSTSUBSCRIPT italic_s italic_i italic_d italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> and set <math alttext="\sigma_{side}^{i}" class="ltx_Math" display="inline" id="S4.SS2.p5.9.m9.1"><semantics id="S4.SS2.p5.9.m9.1a"><msubsup id="S4.SS2.p5.9.m9.1.1" xref="S4.SS2.p5.9.m9.1.1.cmml"><mi id="S4.SS2.p5.9.m9.1.1.2.2" xref="S4.SS2.p5.9.m9.1.1.2.2.cmml">σ</mi><mrow id="S4.SS2.p5.9.m9.1.1.2.3" xref="S4.SS2.p5.9.m9.1.1.2.3.cmml"><mi id="S4.SS2.p5.9.m9.1.1.2.3.2" xref="S4.SS2.p5.9.m9.1.1.2.3.2.cmml">s</mi><mo id="S4.SS2.p5.9.m9.1.1.2.3.1" xref="S4.SS2.p5.9.m9.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.9.m9.1.1.2.3.3" xref="S4.SS2.p5.9.m9.1.1.2.3.3.cmml">i</mi><mo id="S4.SS2.p5.9.m9.1.1.2.3.1a" xref="S4.SS2.p5.9.m9.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.9.m9.1.1.2.3.4" xref="S4.SS2.p5.9.m9.1.1.2.3.4.cmml">d</mi><mo id="S4.SS2.p5.9.m9.1.1.2.3.1b" xref="S4.SS2.p5.9.m9.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS2.p5.9.m9.1.1.2.3.5" xref="S4.SS2.p5.9.m9.1.1.2.3.5.cmml">e</mi></mrow><mi id="S4.SS2.p5.9.m9.1.1.3" xref="S4.SS2.p5.9.m9.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.9.m9.1b"><apply id="S4.SS2.p5.9.m9.1.1.cmml" xref="S4.SS2.p5.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.9.m9.1.1.1.cmml" xref="S4.SS2.p5.9.m9.1.1">superscript</csymbol><apply id="S4.SS2.p5.9.m9.1.1.2.cmml" xref="S4.SS2.p5.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.9.m9.1.1.2.1.cmml" xref="S4.SS2.p5.9.m9.1.1">subscript</csymbol><ci id="S4.SS2.p5.9.m9.1.1.2.2.cmml" xref="S4.SS2.p5.9.m9.1.1.2.2">𝜎</ci><apply id="S4.SS2.p5.9.m9.1.1.2.3.cmml" xref="S4.SS2.p5.9.m9.1.1.2.3"><times id="S4.SS2.p5.9.m9.1.1.2.3.1.cmml" xref="S4.SS2.p5.9.m9.1.1.2.3.1"></times><ci id="S4.SS2.p5.9.m9.1.1.2.3.2.cmml" xref="S4.SS2.p5.9.m9.1.1.2.3.2">𝑠</ci><ci id="S4.SS2.p5.9.m9.1.1.2.3.3.cmml" xref="S4.SS2.p5.9.m9.1.1.2.3.3">𝑖</ci><ci id="S4.SS2.p5.9.m9.1.1.2.3.4.cmml" xref="S4.SS2.p5.9.m9.1.1.2.3.4">𝑑</ci><ci id="S4.SS2.p5.9.m9.1.1.2.3.5.cmml" xref="S4.SS2.p5.9.m9.1.1.2.3.5">𝑒</ci></apply></apply><ci id="S4.SS2.p5.9.m9.1.1.3.cmml" xref="S4.SS2.p5.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.9.m9.1c">\sigma_{side}^{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.9.m9.1d">italic_σ start_POSTSUBSCRIPT italic_s italic_i italic_d italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> by Equation 7, where <math alttext="i=1,2,\ldots,N_{s}" class="ltx_Math" display="inline" id="S4.SS2.p5.10.m10.4"><semantics id="S4.SS2.p5.10.m10.4a"><mrow id="S4.SS2.p5.10.m10.4.4" xref="S4.SS2.p5.10.m10.4.4.cmml"><mi id="S4.SS2.p5.10.m10.4.4.3" xref="S4.SS2.p5.10.m10.4.4.3.cmml">i</mi><mo id="S4.SS2.p5.10.m10.4.4.2" xref="S4.SS2.p5.10.m10.4.4.2.cmml">=</mo><mrow id="S4.SS2.p5.10.m10.4.4.1.1" xref="S4.SS2.p5.10.m10.4.4.1.2.cmml"><mn id="S4.SS2.p5.10.m10.1.1" xref="S4.SS2.p5.10.m10.1.1.cmml">1</mn><mo id="S4.SS2.p5.10.m10.4.4.1.1.2" xref="S4.SS2.p5.10.m10.4.4.1.2.cmml">,</mo><mn id="S4.SS2.p5.10.m10.2.2" xref="S4.SS2.p5.10.m10.2.2.cmml">2</mn><mo id="S4.SS2.p5.10.m10.4.4.1.1.3" xref="S4.SS2.p5.10.m10.4.4.1.2.cmml">,</mo><mi id="S4.SS2.p5.10.m10.3.3" mathvariant="normal" xref="S4.SS2.p5.10.m10.3.3.cmml">…</mi><mo id="S4.SS2.p5.10.m10.4.4.1.1.4" xref="S4.SS2.p5.10.m10.4.4.1.2.cmml">,</mo><msub id="S4.SS2.p5.10.m10.4.4.1.1.1" xref="S4.SS2.p5.10.m10.4.4.1.1.1.cmml"><mi id="S4.SS2.p5.10.m10.4.4.1.1.1.2" xref="S4.SS2.p5.10.m10.4.4.1.1.1.2.cmml">N</mi><mi id="S4.SS2.p5.10.m10.4.4.1.1.1.3" xref="S4.SS2.p5.10.m10.4.4.1.1.1.3.cmml">s</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.10.m10.4b"><apply id="S4.SS2.p5.10.m10.4.4.cmml" xref="S4.SS2.p5.10.m10.4.4"><eq id="S4.SS2.p5.10.m10.4.4.2.cmml" xref="S4.SS2.p5.10.m10.4.4.2"></eq><ci id="S4.SS2.p5.10.m10.4.4.3.cmml" xref="S4.SS2.p5.10.m10.4.4.3">𝑖</ci><list id="S4.SS2.p5.10.m10.4.4.1.2.cmml" xref="S4.SS2.p5.10.m10.4.4.1.1"><cn id="S4.SS2.p5.10.m10.1.1.cmml" type="integer" xref="S4.SS2.p5.10.m10.1.1">1</cn><cn id="S4.SS2.p5.10.m10.2.2.cmml" type="integer" xref="S4.SS2.p5.10.m10.2.2">2</cn><ci id="S4.SS2.p5.10.m10.3.3.cmml" xref="S4.SS2.p5.10.m10.3.3">…</ci><apply id="S4.SS2.p5.10.m10.4.4.1.1.1.cmml" xref="S4.SS2.p5.10.m10.4.4.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.10.m10.4.4.1.1.1.1.cmml" xref="S4.SS2.p5.10.m10.4.4.1.1.1">subscript</csymbol><ci id="S4.SS2.p5.10.m10.4.4.1.1.1.2.cmml" xref="S4.SS2.p5.10.m10.4.4.1.1.1.2">𝑁</ci><ci id="S4.SS2.p5.10.m10.4.4.1.1.1.3.cmml" xref="S4.SS2.p5.10.m10.4.4.1.1.1.3">𝑠</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.10.m10.4c">i=1,2,\ldots,N_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.10.m10.4d">italic_i = 1 , 2 , … , italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<table class="ltx_equation ltx_eqn_table" id="S4.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\delta_{\text{side}}^{i}=i^{2}\cdot\delta_{\text{main}}" class="ltx_Math" display="block" id="S4.E7.m1.1"><semantics id="S4.E7.m1.1a"><mrow id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml"><msubsup id="S4.E7.m1.1.1.2" xref="S4.E7.m1.1.1.2.cmml"><mi id="S4.E7.m1.1.1.2.2.2" xref="S4.E7.m1.1.1.2.2.2.cmml">δ</mi><mtext id="S4.E7.m1.1.1.2.2.3" xref="S4.E7.m1.1.1.2.2.3a.cmml">side</mtext><mi id="S4.E7.m1.1.1.2.3" xref="S4.E7.m1.1.1.2.3.cmml">i</mi></msubsup><mo id="S4.E7.m1.1.1.1" xref="S4.E7.m1.1.1.1.cmml">=</mo><mrow id="S4.E7.m1.1.1.3" xref="S4.E7.m1.1.1.3.cmml"><msup id="S4.E7.m1.1.1.3.2" xref="S4.E7.m1.1.1.3.2.cmml"><mi id="S4.E7.m1.1.1.3.2.2" xref="S4.E7.m1.1.1.3.2.2.cmml">i</mi><mn id="S4.E7.m1.1.1.3.2.3" xref="S4.E7.m1.1.1.3.2.3.cmml">2</mn></msup><mo id="S4.E7.m1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S4.E7.m1.1.1.3.1.cmml">⋅</mo><msub id="S4.E7.m1.1.1.3.3" xref="S4.E7.m1.1.1.3.3.cmml"><mi id="S4.E7.m1.1.1.3.3.2" xref="S4.E7.m1.1.1.3.3.2.cmml">δ</mi><mtext id="S4.E7.m1.1.1.3.3.3" xref="S4.E7.m1.1.1.3.3.3a.cmml">main</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.1b"><apply id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1"><eq id="S4.E7.m1.1.1.1.cmml" xref="S4.E7.m1.1.1.1"></eq><apply id="S4.E7.m1.1.1.2.cmml" xref="S4.E7.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.2.1.cmml" xref="S4.E7.m1.1.1.2">superscript</csymbol><apply id="S4.E7.m1.1.1.2.2.cmml" xref="S4.E7.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.2.2.1.cmml" xref="S4.E7.m1.1.1.2">subscript</csymbol><ci id="S4.E7.m1.1.1.2.2.2.cmml" xref="S4.E7.m1.1.1.2.2.2">𝛿</ci><ci id="S4.E7.m1.1.1.2.2.3a.cmml" xref="S4.E7.m1.1.1.2.2.3"><mtext id="S4.E7.m1.1.1.2.2.3.cmml" mathsize="70%" xref="S4.E7.m1.1.1.2.2.3">side</mtext></ci></apply><ci id="S4.E7.m1.1.1.2.3.cmml" xref="S4.E7.m1.1.1.2.3">𝑖</ci></apply><apply id="S4.E7.m1.1.1.3.cmml" xref="S4.E7.m1.1.1.3"><ci id="S4.E7.m1.1.1.3.1.cmml" xref="S4.E7.m1.1.1.3.1">⋅</ci><apply id="S4.E7.m1.1.1.3.2.cmml" xref="S4.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.3.2.1.cmml" xref="S4.E7.m1.1.1.3.2">superscript</csymbol><ci id="S4.E7.m1.1.1.3.2.2.cmml" xref="S4.E7.m1.1.1.3.2.2">𝑖</ci><cn id="S4.E7.m1.1.1.3.2.3.cmml" type="integer" xref="S4.E7.m1.1.1.3.2.3">2</cn></apply><apply id="S4.E7.m1.1.1.3.3.cmml" xref="S4.E7.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.3.3.1.cmml" xref="S4.E7.m1.1.1.3.3">subscript</csymbol><ci id="S4.E7.m1.1.1.3.3.2.cmml" xref="S4.E7.m1.1.1.3.3.2">𝛿</ci><ci id="S4.E7.m1.1.1.3.3.3a.cmml" xref="S4.E7.m1.1.1.3.3.3"><mtext id="S4.E7.m1.1.1.3.3.3.cmml" mathsize="70%" xref="S4.E7.m1.1.1.3.3.3">main</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.1c">\delta_{\text{side}}^{i}=i^{2}\cdot\delta_{\text{main}}</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m1.1d">italic_δ start_POSTSUBSCRIPT side end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_i start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⋅ italic_δ start_POSTSUBSCRIPT main end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.1">A larger <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p7.1.m1.1"><semantics id="S4.SS2.p7.1.m1.1a"><mi id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><ci id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p7.1.m1.1d">italic_i</annotation></semantics></math> value represents greater distance from the target key point, thus representing a less influence of the side Gaussian distribution on the target key point.</p>
</div>
<div class="ltx_para" id="S4.SS2.p8">
<p class="ltx_p" id="S4.SS2.p8.1">Once we build a Gaussian mixture model (GMM), we generate volumetric size <math alttext="w\times h\times d" class="ltx_Math" display="inline" id="S4.SS2.p8.1.m1.1"><semantics id="S4.SS2.p8.1.m1.1a"><mrow id="S4.SS2.p8.1.m1.1.1" xref="S4.SS2.p8.1.m1.1.1.cmml"><mi id="S4.SS2.p8.1.m1.1.1.2" xref="S4.SS2.p8.1.m1.1.1.2.cmml">w</mi><mo id="S4.SS2.p8.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p8.1.m1.1.1.1.cmml">×</mo><mi id="S4.SS2.p8.1.m1.1.1.3" xref="S4.SS2.p8.1.m1.1.1.3.cmml">h</mi><mo id="S4.SS2.p8.1.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p8.1.m1.1.1.1.cmml">×</mo><mi id="S4.SS2.p8.1.m1.1.1.4" xref="S4.SS2.p8.1.m1.1.1.4.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p8.1.m1.1b"><apply id="S4.SS2.p8.1.m1.1.1.cmml" xref="S4.SS2.p8.1.m1.1.1"><times id="S4.SS2.p8.1.m1.1.1.1.cmml" xref="S4.SS2.p8.1.m1.1.1.1"></times><ci id="S4.SS2.p8.1.m1.1.1.2.cmml" xref="S4.SS2.p8.1.m1.1.1.2">𝑤</ci><ci id="S4.SS2.p8.1.m1.1.1.3.cmml" xref="S4.SS2.p8.1.m1.1.1.3">ℎ</ci><ci id="S4.SS2.p8.1.m1.1.1.4.cmml" xref="S4.SS2.p8.1.m1.1.1.4">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p8.1.m1.1c">w\times h\times d</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p8.1.m1.1d">italic_w × italic_h × italic_d</annotation></semantics></math>, which is discretized uniformly across each dimension. While conventional 3D heatmaps build a volume for each key point, HeatPose computes the probability of voxels of all key points into one volumetric representation, as seen in Equation 8:</p>
</div>
<div class="ltx_para" id="S4.SS2.p9">
<table class="ltx_equation ltx_eqn_table" id="S4.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(x)=\frac{\mathcal{N}\left(x\mid\mu_{\text{main }},{\delta_{\text{main }}^{2}%
}\right)+\sum_{i=1}^{N_{s}}\mathcal{N}\left(x\mid\mu_{side}^{i},{\delta_{side}%
^{i}}^{2}\right)}{MAX}" class="ltx_Math" display="block" id="S4.E8.m1.3"><semantics id="S4.E8.m1.3a"><mrow id="S4.E8.m1.3.4" xref="S4.E8.m1.3.4.cmml"><mrow id="S4.E8.m1.3.4.2" xref="S4.E8.m1.3.4.2.cmml"><mi id="S4.E8.m1.3.4.2.2" xref="S4.E8.m1.3.4.2.2.cmml">P</mi><mo id="S4.E8.m1.3.4.2.1" xref="S4.E8.m1.3.4.2.1.cmml">⁢</mo><mrow id="S4.E8.m1.3.4.2.3.2" xref="S4.E8.m1.3.4.2.cmml"><mo id="S4.E8.m1.3.4.2.3.2.1" stretchy="false" xref="S4.E8.m1.3.4.2.cmml">(</mo><mi id="S4.E8.m1.3.3" xref="S4.E8.m1.3.3.cmml">x</mi><mo id="S4.E8.m1.3.4.2.3.2.2" stretchy="false" xref="S4.E8.m1.3.4.2.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.3.4.1" xref="S4.E8.m1.3.4.1.cmml">=</mo><mfrac id="S4.E8.m1.2.2" xref="S4.E8.m1.2.2.cmml"><mrow id="S4.E8.m1.2.2.2" xref="S4.E8.m1.2.2.2.cmml"><mrow id="S4.E8.m1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.3.cmml">𝒩</mi><mo id="S4.E8.m1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E8.m1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml"><mo id="S4.E8.m1.1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E8.m1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E8.m1.1.1.1.1.1.1.1.4" xref="S4.E8.m1.1.1.1.1.1.1.1.4.cmml">x</mi><mo id="S4.E8.m1.1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.3.cmml">∣</mo><mrow id="S4.E8.m1.1.1.1.1.1.1.1.2.2" xref="S4.E8.m1.1.1.1.1.1.1.1.2.3.cmml"><msub id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">μ</mi><mtext id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.3a.cmml">main </mtext></msub><mo id="S4.E8.m1.1.1.1.1.1.1.1.2.2.3" xref="S4.E8.m1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msubsup id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">δ</mi><mtext id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.3a.cmml">main </mtext><mn id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">2</mn></msubsup></mrow></mrow><mo id="S4.E8.m1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E8.m1.2.2.2.3" rspace="0.055em" xref="S4.E8.m1.2.2.2.3.cmml">+</mo><mrow id="S4.E8.m1.2.2.2.2" xref="S4.E8.m1.2.2.2.2.cmml"><msubsup id="S4.E8.m1.2.2.2.2.2" xref="S4.E8.m1.2.2.2.2.2.cmml"><mo id="S4.E8.m1.2.2.2.2.2.2.2" xref="S4.E8.m1.2.2.2.2.2.2.2.cmml">∑</mo><mrow id="S4.E8.m1.2.2.2.2.2.2.3" xref="S4.E8.m1.2.2.2.2.2.2.3.cmml"><mi id="S4.E8.m1.2.2.2.2.2.2.3.2" xref="S4.E8.m1.2.2.2.2.2.2.3.2.cmml">i</mi><mo id="S4.E8.m1.2.2.2.2.2.2.3.1" xref="S4.E8.m1.2.2.2.2.2.2.3.1.cmml">=</mo><mn id="S4.E8.m1.2.2.2.2.2.2.3.3" xref="S4.E8.m1.2.2.2.2.2.2.3.3.cmml">1</mn></mrow><msub id="S4.E8.m1.2.2.2.2.2.3" xref="S4.E8.m1.2.2.2.2.2.3.cmml"><mi id="S4.E8.m1.2.2.2.2.2.3.2" xref="S4.E8.m1.2.2.2.2.2.3.2.cmml">N</mi><mi id="S4.E8.m1.2.2.2.2.2.3.3" xref="S4.E8.m1.2.2.2.2.2.3.3.cmml">s</mi></msub></msubsup><mrow id="S4.E8.m1.2.2.2.2.1" xref="S4.E8.m1.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E8.m1.2.2.2.2.1.3" xref="S4.E8.m1.2.2.2.2.1.3.cmml">𝒩</mi><mo id="S4.E8.m1.2.2.2.2.1.2" xref="S4.E8.m1.2.2.2.2.1.2.cmml">⁢</mo><mrow id="S4.E8.m1.2.2.2.2.1.1.1" xref="S4.E8.m1.2.2.2.2.1.1.1.1.cmml"><mo id="S4.E8.m1.2.2.2.2.1.1.1.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E8.m1.2.2.2.2.1.1.1.1" xref="S4.E8.m1.2.2.2.2.1.1.1.1.cmml"><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.4" xref="S4.E8.m1.2.2.2.2.1.1.1.1.4.cmml">x</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.3.cmml">∣</mo><mrow id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.3.cmml"><msubsup id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.2.cmml">μ</mi><mrow id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.cmml"><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.2.cmml">s</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.3.cmml">i</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1a" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.4" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.4.cmml">d</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1b" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.5" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.5.cmml">e</mi></mrow><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.3.cmml">,</mo><mmultiscripts id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.cmml"><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.2.cmml">δ</mi><mrow id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.cmml"><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.2" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.2.cmml">s</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.3.cmml">i</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1a" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.4" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.4.cmml">d</mi><mo id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1b" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.5" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.5.cmml">e</mi></mrow><mi id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.3.cmml">i</mi><mrow id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2a" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.cmml"></mrow><mn id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.3.cmml">2</mn></mmultiscripts></mrow></mrow><mo id="S4.E8.m1.2.2.2.2.1.1.1.3" xref="S4.E8.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mrow id="S4.E8.m1.2.2.4" xref="S4.E8.m1.2.2.4.cmml"><mi id="S4.E8.m1.2.2.4.2" xref="S4.E8.m1.2.2.4.2.cmml">M</mi><mo id="S4.E8.m1.2.2.4.1" xref="S4.E8.m1.2.2.4.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.4.3" xref="S4.E8.m1.2.2.4.3.cmml">A</mi><mo id="S4.E8.m1.2.2.4.1a" xref="S4.E8.m1.2.2.4.1.cmml">⁢</mo><mi id="S4.E8.m1.2.2.4.4" xref="S4.E8.m1.2.2.4.4.cmml">X</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m1.3b"><apply id="S4.E8.m1.3.4.cmml" xref="S4.E8.m1.3.4"><eq id="S4.E8.m1.3.4.1.cmml" xref="S4.E8.m1.3.4.1"></eq><apply id="S4.E8.m1.3.4.2.cmml" xref="S4.E8.m1.3.4.2"><times id="S4.E8.m1.3.4.2.1.cmml" xref="S4.E8.m1.3.4.2.1"></times><ci id="S4.E8.m1.3.4.2.2.cmml" xref="S4.E8.m1.3.4.2.2">𝑃</ci><ci id="S4.E8.m1.3.3.cmml" xref="S4.E8.m1.3.3">𝑥</ci></apply><apply id="S4.E8.m1.2.2.cmml" xref="S4.E8.m1.2.2"><divide id="S4.E8.m1.2.2.3.cmml" xref="S4.E8.m1.2.2"></divide><apply id="S4.E8.m1.2.2.2.cmml" xref="S4.E8.m1.2.2.2"><plus id="S4.E8.m1.2.2.2.3.cmml" xref="S4.E8.m1.2.2.2.3"></plus><apply id="S4.E8.m1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1"><times id="S4.E8.m1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.2"></times><ci id="S4.E8.m1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.3">𝒩</ci><apply id="S4.E8.m1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E8.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.3">conditional</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.4.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.4">𝑥</ci><list id="S4.E8.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2"><apply id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.2">𝜇</ci><ci id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S4.E8.m1.1.1.1.1.1.1.1.1.1.1.3">main </mtext></ci></apply><apply id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.2">𝛿</ci><ci id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.3a.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.3"><mtext id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" mathsize="70%" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.2.3">main </mtext></ci></apply><cn id="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" type="integer" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.2.3">2</cn></apply></list></apply></apply><apply id="S4.E8.m1.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2"><apply id="S4.E8.m1.2.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.2.1.cmml" xref="S4.E8.m1.2.2.2.2.2">superscript</csymbol><apply id="S4.E8.m1.2.2.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.2.2.1.cmml" xref="S4.E8.m1.2.2.2.2.2">subscript</csymbol><sum id="S4.E8.m1.2.2.2.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.2.2.2"></sum><apply id="S4.E8.m1.2.2.2.2.2.2.3.cmml" xref="S4.E8.m1.2.2.2.2.2.2.3"><eq id="S4.E8.m1.2.2.2.2.2.2.3.1.cmml" xref="S4.E8.m1.2.2.2.2.2.2.3.1"></eq><ci id="S4.E8.m1.2.2.2.2.2.2.3.2.cmml" xref="S4.E8.m1.2.2.2.2.2.2.3.2">𝑖</ci><cn id="S4.E8.m1.2.2.2.2.2.2.3.3.cmml" type="integer" xref="S4.E8.m1.2.2.2.2.2.2.3.3">1</cn></apply></apply><apply id="S4.E8.m1.2.2.2.2.2.3.cmml" xref="S4.E8.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.2.3.1.cmml" xref="S4.E8.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S4.E8.m1.2.2.2.2.2.3.2.cmml" xref="S4.E8.m1.2.2.2.2.2.3.2">𝑁</ci><ci id="S4.E8.m1.2.2.2.2.2.3.3.cmml" xref="S4.E8.m1.2.2.2.2.2.3.3">𝑠</ci></apply></apply><apply id="S4.E8.m1.2.2.2.2.1.cmml" xref="S4.E8.m1.2.2.2.2.1"><times id="S4.E8.m1.2.2.2.2.1.2.cmml" xref="S4.E8.m1.2.2.2.2.1.2"></times><ci id="S4.E8.m1.2.2.2.2.1.3.cmml" xref="S4.E8.m1.2.2.2.2.1.3">𝒩</ci><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1"><csymbol cd="latexml" id="S4.E8.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.3">conditional</csymbol><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.4.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.4">𝑥</ci><list id="S4.E8.m1.2.2.2.2.1.1.1.1.2.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2"><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.2">𝜇</ci><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3"><times id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.1"></times><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.2">𝑠</ci><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.3">𝑖</ci><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.4.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.4">𝑑</ci><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.5.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2.3.5">𝑒</ci></apply></apply><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2">superscript</csymbol><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2">superscript</csymbol><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.2">𝛿</ci><apply id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3"><times id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.1"></times><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.2.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.2">𝑠</ci><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.3">𝑖</ci><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.4.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.4">𝑑</ci><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.5.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.2.3.5">𝑒</ci></apply></apply><ci id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.3.cmml" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.2.3">𝑖</ci></apply><cn id="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.3.cmml" type="integer" xref="S4.E8.m1.2.2.2.2.1.1.1.1.2.2.2.3">2</cn></apply></list></apply></apply></apply></apply><apply id="S4.E8.m1.2.2.4.cmml" xref="S4.E8.m1.2.2.4"><times id="S4.E8.m1.2.2.4.1.cmml" xref="S4.E8.m1.2.2.4.1"></times><ci id="S4.E8.m1.2.2.4.2.cmml" xref="S4.E8.m1.2.2.4.2">𝑀</ci><ci id="S4.E8.m1.2.2.4.3.cmml" xref="S4.E8.m1.2.2.4.3">𝐴</ci><ci id="S4.E8.m1.2.2.4.4.cmml" xref="S4.E8.m1.2.2.4.4">𝑋</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.3c">P(x)=\frac{\mathcal{N}\left(x\mid\mu_{\text{main }},{\delta_{\text{main }}^{2}%
}\right)+\sum_{i=1}^{N_{s}}\mathcal{N}\left(x\mid\mu_{side}^{i},{\delta_{side}%
^{i}}^{2}\right)}{MAX}</annotation><annotation encoding="application/x-llamapun" id="S4.E8.m1.3d">italic_P ( italic_x ) = divide start_ARG caligraphic_N ( italic_x ∣ italic_μ start_POSTSUBSCRIPT main end_POSTSUBSCRIPT , italic_δ start_POSTSUBSCRIPT main end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) + ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_POSTSUPERSCRIPT caligraphic_N ( italic_x ∣ italic_μ start_POSTSUBSCRIPT italic_s italic_i italic_d italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_δ start_POSTSUBSCRIPT italic_s italic_i italic_d italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) end_ARG start_ARG italic_M italic_A italic_X end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.p9.2">where <math alttext="\mathcal{N}" class="ltx_Math" display="inline" id="S4.SS2.p9.1.m1.1"><semantics id="S4.SS2.p9.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p9.1.m1.1.1" xref="S4.SS2.p9.1.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p9.1.m1.1b"><ci id="S4.SS2.p9.1.m1.1.1.cmml" xref="S4.SS2.p9.1.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p9.1.m1.1c">\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p9.1.m1.1d">caligraphic_N</annotation></semantics></math> is Gaussian distribution, <math alttext="MAX" class="ltx_Math" display="inline" id="S4.SS2.p9.2.m2.1"><semantics id="S4.SS2.p9.2.m2.1a"><mrow id="S4.SS2.p9.2.m2.1.1" xref="S4.SS2.p9.2.m2.1.1.cmml"><mi id="S4.SS2.p9.2.m2.1.1.2" xref="S4.SS2.p9.2.m2.1.1.2.cmml">M</mi><mo id="S4.SS2.p9.2.m2.1.1.1" xref="S4.SS2.p9.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p9.2.m2.1.1.3" xref="S4.SS2.p9.2.m2.1.1.3.cmml">A</mi><mo id="S4.SS2.p9.2.m2.1.1.1a" xref="S4.SS2.p9.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p9.2.m2.1.1.4" xref="S4.SS2.p9.2.m2.1.1.4.cmml">X</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p9.2.m2.1b"><apply id="S4.SS2.p9.2.m2.1.1.cmml" xref="S4.SS2.p9.2.m2.1.1"><times id="S4.SS2.p9.2.m2.1.1.1.cmml" xref="S4.SS2.p9.2.m2.1.1.1"></times><ci id="S4.SS2.p9.2.m2.1.1.2.cmml" xref="S4.SS2.p9.2.m2.1.1.2">𝑀</ci><ci id="S4.SS2.p9.2.m2.1.1.3.cmml" xref="S4.SS2.p9.2.m2.1.1.3">𝐴</ci><ci id="S4.SS2.p9.2.m2.1.1.4.cmml" xref="S4.SS2.p9.2.m2.1.1.4">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p9.2.m2.1c">MAX</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p9.2.m2.1d">italic_M italic_A italic_X</annotation></semantics></math> stands for the maximum probability of voxels in the volume.</p>
</div>
<div class="ltx_para" id="S4.SS2.p10">
<p class="ltx_p" id="S4.SS2.p10.1">Based on Equation 8, we compute the cross-entropy between the output of our SoloPose and HeatPose, converted from the ground truth as our model’s loss function. Departing from existing 3D heatmaps that use MSE loss functions, using a cross-entropy loss function methodology avoids non-convex problems. That is, such cross-entropy models can easily converge because targeting the distribution of each key point affords the handling of noise in ground truth. HeatPose’s application of GMM as opposed to the single Gaussian distribution used conventional 3D heatmaps leads to more accurate representations and coordinate estimates.</p>
</div>
<div class="ltx_para" id="S4.SS2.p11">
<p class="ltx_p" id="S4.SS2.p11.1">As we set up increasingly larger <math alttext="\sigma" class="ltx_Math" display="inline" id="S4.SS2.p11.1.m1.1"><semantics id="S4.SS2.p11.1.m1.1a"><mi id="S4.SS2.p11.1.m1.1.1" xref="S4.SS2.p11.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p11.1.m1.1b"><ci id="S4.SS2.p11.1.m1.1.1.cmml" xref="S4.SS2.p11.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p11.1.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p11.1.m1.1d">italic_σ</annotation></semantics></math> for the side Gaussian distributions with regard to the corresponding main Gaussian distribution, we can easily find the maximum of voxels’ probability shown in Fig. <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ 4.2 HeatPose: 3D Gaussian heatmap ‣ 4 SoloPose: One-shot 3D human pose estimation network ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">5</span></a> (B) to convert our HeatPose back to the 3D keypoints’ original coordinates.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">With the AugMotion dataset augmentation method, we merge four datasets: Human3.6M<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>, MADS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>, AIST Dance++<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> and MPI INF 3DHP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite> as shown in Fig <a class="ltx_ref" href="#S5.F6" title="Figure 6 ‣ 5.1 Datasets ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">6</span></a>. Notably, we set the Human3.6M Testing Dataset as one of the independent testing datasets for a fair evaluation with SOTA models, which is not merged into our Humans7.1M dataset. The number of Human3.6M, MADS, AIST Dance++ and MPI INF 3DHP shown in Fig <a class="ltx_ref" href="#S5.F6" title="Figure 6 ‣ 5.1 Datasets ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">6</span></a>, is the number of final clips as input data of our SoloPose for training in each dataset, which is pre-processed by a sliding window with a step size of 16. From the rest of the four datasets collectively, we randomly choose 331,875 clips as the training dataset, 94,821 clips as the validation dataset, and 47,412 clips as our Humans7.1M testing dataset.</p>
</div>
<figure class="ltx_figure" id="S5.F6">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F6.1"><span class="ltx_text" id="S5.F6.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="527" id="S5.F6.1.1.g1" src="extracted/5298414/Fig/data.png" width="598"/></span></p>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.3.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S5.F6.4.2" style="font-size:90%;">3D human pose Dataset and our training, validation, and testing dataset with number of unique video clips. 7.1M is the number of frames in our augmented dataset.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation Metrics</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We use the mean per joint position error (MPJPE) and Procrustes MPJPE (P-MPJPE) to evaluate two SOTA models and our SoloPose.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.2.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.3.2" style="font-size:90%;">Results on different testing datasets</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T2.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S5.T2.4.1.1.1">Method</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T2.4.1.1.2">Our Humans7.1M testing dataset</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T2.4.1.1.3">Human3.6M testing dataset</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S5.T2.4.2.2.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.2.2.2">MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.2.2.3">P-MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.2.2.4">MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.2.2.5">P–MPJPE</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.3.3.1">P-STMO w/ CPN<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.3.3.2">53.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.3.3.3">46.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.3.3.4">42.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.3.3.5">34.4</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T2.4.4.4.1">STCFormer w/ CPN<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.4.2">48.3</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.4.3">40.3</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.4.4">40.5</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.4.4.5">31.8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T2.4.5.5.1">P-STMO w/ GT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.5.5.2">36.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.5.5.3">18.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.5.5.4">29.3</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.5.5.5">12.9</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T2.4.6.6.1">STCFormer w/ GT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.6.2">30.5</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.6.3">13.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.6.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.6.6.4.1">21.3</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.6.6.5"><span class="ltx_text ltx_font_bold" id="S5.T2.4.6.6.5.1">5.8</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S5.T2.4.7.7.1">Our SoloPose</th>
<td class="ltx_td ltx_align_center" id="S5.T2.4.7.7.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.7.7.2.1">22.7</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.7.7.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.7.7.3.1">6.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.7.7.4">26.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.4.7.7.5">11.5</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.8.8.1">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.4.8.8.1.1">
<tr class="ltx_tr" id="S5.T2.4.8.8.1.1.1">
<td class="ltx_td ltx_align_center" id="S5.T2.4.8.8.1.1.1.1">Our SoloPose w/o</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.8.8.1.1.2">
<td class="ltx_td ltx_align_center" id="S5.T2.4.8.8.1.1.2.1">HeatPose</td>
</tr>
</table>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.8.8.2">25.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.8.8.3">11.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.8.8.4">30.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.8.8.5">15.8</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S5.T2.4.9.9.1">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.4.9.9.1.1">
<tr class="ltx_tr" id="S5.T2.4.9.9.1.1.1">
<td class="ltx_td ltx_align_center" id="S5.T2.4.9.9.1.1.1.1">Our SoloPose only trained</td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.9.9.1.1.2">
<td class="ltx_td ltx_align_center" id="S5.T2.4.9.9.1.1.2.1">on Human3.6M</td>
</tr>
</table>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.9.9.2">47.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.9.9.3">38.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.9.9.4">38.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.9.9.5">29.9</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Comparison with the State-of-the-art</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We compare the proposed model with the best-performing SOTA methods, P-STMO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite> and STCFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>, which are pre-trained on the Human3.6M training dataset. We test all methods on our Humans7.1M testing dataset as well as on the Human3.6M Testing dataset, which do not overlap. Both P-STMO and STCFormer are two-stage methods that choose CPN (Cascaded Pyramid Network)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite> to generate 2D coordinates as second-stage input, and 2D ground truth as input to test model’s performance. We evaluate these two models with CPN-generated 2D estimates or 2D ground truth as input, respectively. Notably, 2D ground truth as input gives the comparative models an unfair advantage because it provides additional information unavailable to the proposed one-shot method. Besides, it is impossible for any pose estimation model to obtain 2D ground truth when applied on real-world in-the-wild data. As such, we mainly compare our model against performance with CPN estimates as input but we still include GT performance for reference.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">As shown in Table <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Evaluation Metrics ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">2</span></a>, our SoloPose achieves the highest performance of MPJPE and P-MPJPE on the Humans7.1M testing dataset. Even when compared to SOTA methods with ground truth, our results of MPJPE and P-MPJPE are still 25.5% and 47.3% lower than the best-performing STCFormer. When evaluated on the Human3.6M testing dataset, our results of MPJPE and P-MPJPE are 35.8% and 63.8% lower than STCFormer with CPN as input, and only lower than STCFormer with ground truth as input.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Ablation Study</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We designed two ablation studies to test the contributions of the proposed 3D kinematically adjacent heatmap (HeatPose) and data augmentation methodology (AugMotion) to our SoloPose performance.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.1 </span>Analysis without 3D Gaussian Heatmap</h4>
<div class="ltx_para" id="S5.SS4.SSS1.p1">
<p class="ltx_p" id="S5.SS4.SSS1.p1.1">The first ablation study removes HeatPose and utilizes the traditional MSE loss function to train our proposed model. As shown in the second section of Table <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.2 Evaluation Metrics ‣ 5 Experiments and results ‣ SoloPose: One-Shot Kinematic 3D Human Pose Estimation with Video Data Augmentation"><span class="ltx_text ltx_ref_tag">2</span></a>, the results of MPJPE and P-MPJPE on Human3.6M testing dataset are 15.3% and 27.2% higher than that of our SoloPose with HeatPose respectively, but it is 24.2% and 50.3% lower than STCformer with CPN.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.4.2 </span>Analysis without Data Augmentation</h4>
<div class="ltx_para" id="S5.SS4.SSS2.p1">
<p class="ltx_p" id="S5.SS4.SSS2.p1.1">The second ablation study trains the model only on Human3.6M, in the mold of P-STMO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite> and STCFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>. Our results of MPJPE and P-MPJPE are still 3.9% and 5.9%lower than the two SOTA methods on the Human3.6M testing dataset, which demonstrates that our SoloPose model is more effective than current SOTA methods. When tested on the Human3.6M testing dataset, the second ablation study’s MPJPE result increases by 12.9 as opposed to the increase of 4.7 observed with the first ablation study, thus demonstrating that our proposed data augmentation methodology (AugMotion) improves 3D human pose estimation performance by efficiently enhancing data quality and diversity.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>CONCLUSION</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduced SoloPose, a one-shot, many-to-many spatio-temporal transformer network for video-based 3D human pose estimation. To address limitations of high-quality 3D human pose estimation datasets, we proposed the 3D AugMotion ToolKit, a novel dataset augmentation methodology by projecting existing datasets onto a universal coordinate system. Further, we proposed HeatPose, a 3D kinematically adjacent heatmap that provide greater probabilistic key point information compared with conventional 3D heatmaps. As a result, we demonstrate our SoloPose model’s improved performance over existing SOTA models for 3D human pose estimation in both experimental evaluation and ablation. In future work, we intend to extend the model onto 3D multi-person pose estimation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
Sérgio Agostinho, Aljoša Ošep, Alessio Del Bue, and Laura Leal-Taixé.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.2.1" style="font-size:90%;">(just) a spoonful of refinements helps the registration error go down.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib1.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span class="ltx_text" id="bib.bib1.5.3" style="font-size:90%;">, pages 6108–6117, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
Yilun Chen, Zhicheng Wang, Yuxiang Peng, Zhiqiang Zhang, Gang Yu, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.2.1" style="font-size:90%;">Cascaded pyramid network for multi-person pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib2.4.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib2.5.3" style="font-size:90%;">, pages 7103–7112, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
Zhiqiang Gong, Ping Zhong, and Weidong Hu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.2.1" style="font-size:90%;">Diversity in machine learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.3.1" style="font-size:90%;">Ieee Access</span><span class="ltx_text" id="bib.bib3.4.2" style="font-size:90%;">, 7:64323–64350, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
Shreyas Hampali, Sayan Deb Sarkar, Mahdi Rad, and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.2.1" style="font-size:90%;">Keypoint transformer: Solving joint identification in challenging hands and object interactions for accurate 3d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib4.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib4.5.3" style="font-size:90%;">, pages 11090–11100, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
Catalin Ionescu, Dragos Papava, Vlad Olaru, and Cristian Sminchisescu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.2.1" style="font-size:90%;">Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.3.1" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span class="ltx_text" id="bib.bib5.4.2" style="font-size:90%;">, 36(7):1325–1339, jul 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
Lei Jin, Chenyang Xu, Xiaojuan Wang, Yabo Xiao, Yandong Guo, Xuecheng Nie, and Jian Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.2.1" style="font-size:90%;">Single-stage is enough: Multi-person absolute 3d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib6.5.3" style="font-size:90%;">, pages 13086–13095, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
Jiefeng Li, Siyuan Bian, Ailing Zeng, Can Wang, Bo Pang, Wentao Liu, and Cewu Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.2.1" style="font-size:90%;">Human pose regression with residual log-likelihood estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib7.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span class="ltx_text" id="bib.bib7.5.3" style="font-size:90%;">, pages 11025–11034, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Wenhao Li, Hong Liu, Hao Tang, Pichao Wang, and Luc Van Gool.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.2.1" style="font-size:90%;">Mhformer: Multi-hypothesis transformer for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib8.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib8.5.3" style="font-size:90%;">, pages 13147–13156, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.2.1" style="font-size:90%;">Swin transformer: Hierarchical vision transformer using shifted windows.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib9.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span class="ltx_text" id="bib.bib9.5.3" style="font-size:90%;">, pages 10012–10022, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
Geoffrey J McLachlan and Suren Rathnayake.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.2.1" style="font-size:90%;">On the number of components in a gaussian mixture model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.3.1" style="font-size:90%;">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</span><span class="ltx_text" id="bib.bib10.4.2" style="font-size:90%;">, 4(5):341–355, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksandr Sotnychenko, Weipeng Xu, and Christian Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.2.1" style="font-size:90%;">Monocular 3d human pose estimation in the wild using improved cnn supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib11.4.2" style="font-size:90%;">3D Vision (3DV), 2017 Fifth International Conference on</span><span class="ltx_text" id="bib.bib11.5.3" style="font-size:90%;">. IEEE, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
Alejandro Newell, Kaiyu Yang, and Jia Deng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.2.1" style="font-size:90%;">Stacked hourglass networks for human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.4.2" style="font-size:90%;">Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VIII 14</span><span class="ltx_text" id="bib.bib12.5.3" style="font-size:90%;">, pages 483–499. Springer, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.2.1" style="font-size:90%;">Coarse-to-fine volumetric prediction for single-image 3d human pose.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib13.4.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib13.5.3" style="font-size:90%;">, pages 7025–7034, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.2.1" style="font-size:90%;">Learning transferable visual models from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib14.4.2" style="font-size:90%;">International conference on machine learning</span><span class="ltx_text" id="bib.bib14.5.3" style="font-size:90%;">, pages 8748–8763. PMLR, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
Michał Rapczyński, Philipp Werner, Sebastian Handrich, and Ayoub Al-Hamadi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.2.1" style="font-size:90%;">A baseline for cross-database 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.3.1" style="font-size:90%;">Sensors</span><span class="ltx_text" id="bib.bib15.4.2" style="font-size:90%;">, 21(11), 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
Edoardo Remelli, Shangchen Han, Sina Honari, Pascal Fua, and Robert Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.2.1" style="font-size:90%;">Lightweight multi-view 3d pose estimation through camera-disentangled representation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib16.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span class="ltx_text" id="bib.bib16.5.3" style="font-size:90%;">, pages 6040–6049, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
Yu Rong, Takaaki Shiratori, and Hanbyul Joo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.2.1" style="font-size:90%;">Frankmocap: A monocular 3d whole-body pose estimation system via regression and integration.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib17.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span class="ltx_text" id="bib.bib17.5.3" style="font-size:90%;">, pages 1749–1759, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
István Sárándi, Alexander Hermans, and Bastian Leibe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.2.1" style="font-size:90%;">Learning 3d human pose estimation from dozens of datasets using a geometry-aware autoencoder to bridge between skeleton formats.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib18.4.2" style="font-size:90%;">IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2023, Waikoloa, HI, USA, January 2-7, 2023</span><span class="ltx_text" id="bib.bib18.5.3" style="font-size:90%;">, pages 2955–2965. IEEE, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
István Sárándi, Timm Linder, Kai Oliver Arras, and Bastian Leibe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.2.1" style="font-size:90%;">Metrabs: metric-scale truncation-robust heatmaps for absolute 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.3.1" style="font-size:90%;">IEEE Transactions on Biometrics, Behavior, and Identity Science</span><span class="ltx_text" id="bib.bib19.4.2" style="font-size:90%;">, 3(1):16–30, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
Wenkang Shan, Zhenhua Liu, Xinfeng Zhang, Shanshe Wang, Siwei Ma, and Wen Gao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.2.1" style="font-size:90%;">P-stmo: Pre-trained spatial temporal many-to-one model for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib20.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib20.5.3" style="font-size:90%;">, pages 461–478. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
Xiao Sun, Bin Xiao, Fangyin Wei, Shuang Liang, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.2.1" style="font-size:90%;">Integral human pose regression.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib21.4.2" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</span><span class="ltx_text" id="bib.bib21.5.3" style="font-size:90%;">, pages 529–545, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
Zhenhua Tang, Zhaofan Qiu, Yanbin Hao, Richang Hong, and Ting Yao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.2.1" style="font-size:90%;">3d human pose estimation with spatio-temporal criss-cross attention.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib22.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib22.5.3" style="font-size:90%;">, pages 4790–4799, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
Shuhei Tsuchida, Satoru Fukayama, Masahiro Hamasaki, and Masataka Goto.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.2.1" style="font-size:90%;">Aist dance video database: Multi-genre, multi-dancer, and multi-camera database for dance information processing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib23.4.2" style="font-size:90%;">Proceedings of the 20th International Society for Music Information Retrieval Conference, ISMIR 2019</span><span class="ltx_text" id="bib.bib23.5.3" style="font-size:90%;">, Delft, Netherlands, Nov. 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
Zhe Wang, Daeyun Shin, and Charless C Fowlkes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.2.1" style="font-size:90%;">Predicting camera viewpoint improves cross-dataset generalization for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib24.4.2" style="font-size:90%;">Computer Vision–ECCV 2020 Workshops: Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16</span><span class="ltx_text" id="bib.bib24.5.3" style="font-size:90%;">, pages 523–540. Springer, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
Ailing Zeng, Xiao Sun, Lei Yang, Nanxuan Zhao, Minhao Liu, and Qiang Xu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.2.1" style="font-size:90%;">Learning skeletal graph neural networks for hard 3d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib25.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span class="ltx_text" id="bib.bib25.5.3" style="font-size:90%;">, pages 11436–11445, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
Weichen Zhang, Zhiguang Liu, Liuyang Zhou, Howard Leung, and Antoni B Chan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.2.1" style="font-size:90%;">Martial arts, dancing and sports dataset: A challenging stereo and multi-view dataset for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.3.1" style="font-size:90%;">Image and Vision Computing</span><span class="ltx_text" id="bib.bib26.4.2" style="font-size:90%;">, 61:22–39, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
Ce Zheng, Sijie Zhu, Matias Mendieta, Taojiannan Yang, Chen Chen, and Zhengming Ding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.2.1" style="font-size:90%;">3d human pose estimation with spatial and temporal transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib27.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span class="ltx_text" id="bib.bib27.5.3" style="font-size:90%;">, pages 11656–11665, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
Kun Zhou, Xiaoguang Han, Nianjuan Jiang, Kui Jia, and Jiangbo Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.2.1" style="font-size:90%;">Hemlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib28.4.2" style="font-size:90%;">2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul, Korea (South), October 27 - November 2, 2019</span><span class="ltx_text" id="bib.bib28.5.3" style="font-size:90%;">, pages 2344–2353. IEEE, 2019.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Dec 15 20:42:44 2023 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
