<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors</title>
<!--Generated on Tue May 14 16:09:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2405.03545v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S1" title="In Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S2" title="In Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S3" title="In Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S4" title="In Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S5" title="In Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S6" title="In Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Amit Moryossef 
<br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="sign.mt" title="">sign.mt</a>
<br class="ltx_break"/>University of Zurich 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">amit@sign.mt</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">This paper addresses a critical flaw in MediaPipe Holistic’s hand Region of Interest (ROI) prediction, which struggles with non-ideal hand orientations, affecting sign language recognition accuracy. We propose a data-driven approach to enhance ROI estimation, leveraging an enriched feature set including additional hand keypoints and the z-dimension. Our results demonstrate better estimates, with higher Intersection-over-Union compared to the current method.
Our code and optimizations are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sign-language-processing/mediapipe-hand-crop-fix" title="">https://github.com/sign-language-processing/mediapipe-hand-crop-fix</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In recent years, pose estimation <cite class="ltx_cite ltx_citemacro_cite">Pishchulin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib7" title="">2012</a>); Cao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib2" title="">2019</a>); Güler et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib4" title="">2018</a>)</cite> has emerged as a fundamental component for various applications ranging from action recognition and interactive gaming to the more nuanced field of sign language processing. Among the tools at the forefront of this technological revolution, MediaPipe Holistic <cite class="ltx_cite ltx_citemacro_cite">Grishchenko and Bazarevsky (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib3" title="">2020</a>)</cite> distinguishes itself by offering real-time processing capabilities across a diverse array of devices, coupled with its adaptability in different runtime environments. This flexibility has facilitated its adoption across both research and practical applications.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, the MediaPipe Holistic approach exhibits a significant flaw. The heuristic they use<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/google/mediapipe/blob/master/mediapipe/modules/holistic_landmark/hand_landmarks_from_pose_to_recrop_roi.pbtxt" title="">https://github.com/google/mediapipe/blob/master/mediapipe/modules/holistic_landmark/hand_landmarks_from_pose_to_recrop_roi.pbtxt</a></span></span></span> for determining the region of interest (ROI) for hands was designed for scenarios where the hand’s plane is parallel to the camera—–a design choice that does not hold in numerous practical situations. This limitation can lead to inaccuracies in hand ROI prediction, which subsequently affect the detection of hand keypoints, and compromises the overall accuracy of the full-body pose estimation <cite class="ltx_cite ltx_citemacro_cite">Moryossef et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib6" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The naiveté of the existing hand ROI prediction method in MediaPipe Holistic typically manifests when dealing with non-ideal hand orientations. Given the applications of MediaPipe Holistic in domains such as sign language recognition, enhancing the robustness of hand ROI prediction is needed for accurate downstream solutions.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Concretely, their approach (Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#algorithm1" title="Algorithm 1 ‣ 1 Introduction ‣ Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_tag">1</span></a>) extracts the body pose using BlazePose <cite class="ltx_cite ltx_citemacro_cite">Bazarevsky et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib1" title="">2020</a>)</cite>, which includes four hand keypoints per hand - the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">Wrist</em>, the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">Index MCP</em>, the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.3">Pinky MCP</em>, and the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.4">Thumb</em>.
Then, a rough ROI crop estimate is calculated from the first three points by estimating the position of the center of the hand from the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.5">Index MCP</em> and <em class="ltx_emph ltx_font_italic" id="S1.p4.1.6">Pinky MCP</em>, and calculating the hand size as double the distance from the center to the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.7">Wrist</em>. The center is then shifted, and a bounding box around it is estimated by scaling the hand size using hard-coded values.
The 2D hand orientation is then estimated from the angle between the wrist and the center, and a rough crop is produced. This rough crop is fed to a re-cropping model which refines the bounding box, to create the hand crop. The hand crop is fed to the hand landmark model, predicting the keypoints for each hand independently.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S1.F1.g1" src="extracted/2405.03545v2/piepline.jpeg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>MediaPipe Holistic Pipeline Overview <cite class="ltx_cite ltx_citemacro_cite">Grishchenko and Bazarevsky (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib3" title="">2020</a>)</cite>.</figcaption>
</figure>
<figure class="ltx_table" id="S1.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S1.T1.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S1.T1.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.5.6.1.1"><span class="ltx_text ltx_font_bold" id="S1.T1.5.6.1.1.1">Worst</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S1.T1.5.6.1.2.1">Bad</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.5.6.1.3"><span class="ltx_text ltx_font_bold" id="S1.T1.5.6.1.3.1">OKish</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.5.6.1.4"><span class="ltx_text ltx_font_bold" id="S1.T1.5.6.1.4.1">Good</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.5.6.1.5"><span class="ltx_text ltx_font_bold" id="S1.T1.5.6.1.5.1">Best</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.5.5">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="108" id="S1.T1.1.1.1.g1" src="extracted/2405.03545v2/cropped/worst.jpg" width="108"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="108" id="S1.T1.2.2.2.g1" src="extracted/2405.03545v2/cropped/bad.jpg" width="108"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.3.3.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="108" id="S1.T1.3.3.3.g1" src="extracted/2405.03545v2/cropped/ok.jpg" width="108"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.4.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="108" id="S1.T1.4.4.4.g1" src="extracted/2405.03545v2/cropped/good.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.5.5.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="108" id="S1.T1.5.5.5.g1" src="extracted/2405.03545v2/cropped/best.jpg" width="108"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Selected examples of hand keypoint detections with different ROI coverages. Each image shows hand keypoints in green lines, and two bounding boxes: green for the gold ROI and red for the predicted ROI. A blue line indicates the orientation of the bounding box on the bottom edge.</figcaption>
</figure>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="algorithm1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.2.1.1">Algorithm 1</span> </span> Hand Landmarks from Pose to ROI</figcaption>
<div class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_listing" id="algorithm1.3">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGNhbGNfaGFuZF9yb2kod3Jpc3QsIGluZGV4LCBwaW5reSk6CiAgICAjIEVzdGltYXRlIG1pZGRsZSBmaW5nZXIgcG9zaXRpb24KICAgIGNlbnRlciA9ICgyICogaW5kZXggKyBwaW5reSkgLyAzCiAgICAjIEVzdGltYXRlIGhhbmQgc2l6ZQogICAgc2l6ZSA9IDIgKiBkaXN0YW5jZShjZW50ZXIsIHdyaXN0KQogICAgIyBFc3RpbWF0ZSBoYW5kIDJEIHJvdGF0aW9uCiAgICByb3RhdGlvbiA9IGFuZ2xlKHdyaXN0LCBjZW50ZXIpICsgOTAKICAgICMgU2hpZnQgY2VudGVyIFkgcG9zaXRpb24KICAgIGNlbnRlciA9IHNoaWZ0KGNlbnRlciwgcm90YXRpb24sCiAgICAgICAgICAgICAgICAgICAgYnk9KDAsIC0wLjEgKiBzaXplKSkKICAgICMgU2NhbGUgcHJlZGljdGlvbgogICAgc2l6ZSA9IDIuNyAqIHNpemUKICAgIHJldHVybiBjZW50ZXIsIHNpemUsIHJvdGF0aW9u">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_tag ltx_tag_listingline">1</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx1.1" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.2"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.3">calc_hand_roi</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.4">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.5">wrist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.6">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.7"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.8">index</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.11">pinky</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.12">):</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_tag ltx_tag_listingline">2</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx2.2" style="color:#808080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx2.2.1"> </span>Estimate<span class="ltx_text ltx_lst_space" id="lstnumberx2.2.2"> </span>middle<span class="ltx_text ltx_lst_space" id="lstnumberx2.2.3"> </span>finger<span class="ltx_text ltx_lst_space" id="lstnumberx2.2.4"> </span>position</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_tag ltx_tag_listingline">3</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.2">center</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.6">(2</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.7"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.8">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.10">index</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.11"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.12">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.13"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.14">pinky</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.15">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.16"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.17">/</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.18"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.19">3</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_tag ltx_tag_listingline">4</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx4.2" style="color:#808080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.1"> </span>Estimate<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.2"> </span>hand<span class="ltx_text ltx_lst_space" id="lstnumberx4.2.3"> </span>size</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_tag ltx_tag_listingline">5</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.2">size</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.6">2</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.7"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.8">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.10">distance</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.11">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.12">center</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.13">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.14"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.15">wrist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.16">)</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_tag ltx_tag_listingline">6</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx6.2" style="color:#808080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx6.2.1"> </span>Estimate<span class="ltx_text ltx_lst_space" id="lstnumberx6.2.2"> </span>hand<span class="ltx_text ltx_lst_space" id="lstnumberx6.2.3"> </span>2D<span class="ltx_text ltx_lst_space" id="lstnumberx6.2.4"> </span>rotation</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_tag ltx_tag_listingline">7</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.2">rotation</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.6">angle</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.7">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.8">wrist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.11">center</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.12">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.13"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.14">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.15"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.16">90</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_tag ltx_tag_listingline">8</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx8.2" style="color:#808080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx8.2.1"> </span>Shift<span class="ltx_text ltx_lst_space" id="lstnumberx8.2.2"> </span>center<span class="ltx_text ltx_lst_space" id="lstnumberx8.2.3"> </span>Y<span class="ltx_text ltx_lst_space" id="lstnumberx8.2.4"> </span>position</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_tag ltx_tag_listingline">9</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.2">center</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.5"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.6">shift</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.7">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.8">center</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.9">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.10"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.11">rotation</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.12">,</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_tag ltx_tag_listingline">10</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.2">by</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.3">=(0,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.4"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.5">-0.1</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.6"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.7">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.8"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.9">size</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.10">))</span>
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_tag ltx_tag_listingline">11</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1"> </span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx11.2" style="color:#808080;">#<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.1"> </span>Scale<span class="ltx_text ltx_lst_space" id="lstnumberx11.2.2"> </span>prediction</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_tag ltx_tag_listingline">12</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.1"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.2">size</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.3"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.4">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.5"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.6">2.7</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.7"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.8">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.10">size</span>
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_tag ltx_tag_listingline">13</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.1"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx13.2" style="color:#0000FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.3"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.4">center</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.5">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.6"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.7">size</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.8">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.9"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.10">rotation</span>
</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Dataset</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We utilize the Panoptic Hand DB dataset <cite class="ltx_cite ltx_citemacro_cite">Simon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib8" title="">2017</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://domedb.perception.cs.cmu.edu/" title="">https://domedb.perception.cs.cmu.edu/</a></span></span></span>, which contains manually annotated 2D hand poses, with 1912 annotations in the training set and 846 in the testing set. Annotations encompass both <em class="ltx_emph ltx_font_italic" id="S2.p1.1.1">right</em> and <em class="ltx_emph ltx_font_italic" id="S2.p1.1.2">left</em> hand data, providing a comprehensive basis for analysis.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">To estimate the quality of MediaPipe’s ROI estimation, we first adopt the MediaPipe framework to define an ROI from the hand keypoints. This process involves bounding all keypoints and adjusting the bounding box by scaling and rotating it based on the angle between the wrist and middle finger. Then, MediaPipe Holistic is employed to predict the body keypoints. We extract the keypoints for the specific hand being analyzed (shoulder, elbow, wrist, thumb, index finger, and pinky), and for consistency, left-hand keypoints are mirrored to simulate right-handed orientation. The ROI is then determined using Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#algorithm1" title="Algorithm 1 ‣ 1 Introduction ‣ Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates selected instances from the dataset with varying levels of success in ROI coverage. The ‘Worst’ and ‘Best’ examples were automatically identified based on their coverage percentages, at <math alttext="0.8" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><cn id="S2.p3.1.m1.1.1.cmml" type="float" xref="S2.p3.1.m1.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">0.8</annotation><annotation encoding="application/x-llamapun" id="S2.p3.1.m1.1d">0.8</annotation></semantics></math>% and <math alttext="93.7" class="ltx_Math" display="inline" id="S2.p3.2.m2.1"><semantics id="S2.p3.2.m2.1a"><mn id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">93.7</mn><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><cn id="S2.p3.2.m2.1.1.cmml" type="float" xref="S2.p3.2.m2.1.1">93.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">93.7</annotation><annotation encoding="application/x-llamapun" id="S2.p3.2.m2.1d">93.7</annotation></semantics></math>% respectively, whereas other samples were selected manually.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.3">We explore an enhancement to the hand ROI calculation mechanism within the MediaPipe Holistic framework.
We recognize that the current solution only uses three hand points (<em class="ltx_emph ltx_font_italic" id="S3.p1.3.1">wrist</em>, <em class="ltx_emph ltx_font_italic" id="S3.p1.3.2">index</em>, and <em class="ltx_emph ltx_font_italic" id="S3.p1.3.3">pinky</em>) and ignores the <em class="ltx_emph ltx_font_italic" id="S3.p1.3.4">shoulder</em>, <em class="ltx_emph ltx_font_italic" id="S3.p1.3.5">elbow</em>, and <em class="ltx_emph ltx_font_italic" id="S3.p1.3.6">thumb</em> which can also be indicative of the hand region. Furthermore, the current solution only uses the <math alttext="(x,y)" class="ltx_Math" display="inline" id="S3.p1.1.m1.2"><semantics id="S3.p1.1.m1.2a"><mrow id="S3.p1.1.m1.2.3.2" xref="S3.p1.1.m1.2.3.1.cmml"><mo id="S3.p1.1.m1.2.3.2.1" stretchy="false" xref="S3.p1.1.m1.2.3.1.cmml">(</mo><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">x</mi><mo id="S3.p1.1.m1.2.3.2.2" xref="S3.p1.1.m1.2.3.1.cmml">,</mo><mi id="S3.p1.1.m1.2.2" xref="S3.p1.1.m1.2.2.cmml">y</mi><mo id="S3.p1.1.m1.2.3.2.3" stretchy="false" xref="S3.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.2b"><interval closure="open" id="S3.p1.1.m1.2.3.1.cmml" xref="S3.p1.1.m1.2.3.2"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑥</ci><ci id="S3.p1.1.m1.2.2.cmml" xref="S3.p1.1.m1.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.2c">(x,y)</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.2d">( italic_x , italic_y )</annotation></semantics></math> coordinates, and ignores the predicted <math alttext="z" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_z</annotation></semantics></math>. As we note that the model seems to perform badly when the hand is perpendicular to the camera, the <math alttext="z" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_z</annotation></semantics></math> dimension can be particularly useful. As history has repeatedly shown, adopting a data-driven solution is almost always a better choice <cite class="ltx_cite ltx_citemacro_cite">Sutton (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib9" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">We also understand that a good solution to this problem must be very performant, and ideally as interpretable as the current solution. Since we are not members of the MediaPipe project, a complex pull-request with an additional model with obscure weights may not be accepted.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Therefore ideally, we would like to formulate a Kolmogorov-Arnold Network (KAN) <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#bib.bib5" title="">2024</a>)</cite>, as they are suitable for applications where high accuracy and interpretability are needed. Such a KAN could be formulated to use all six normalized body right-hand keypoints, alongside the image aspect-ratio (<math alttext="\rho" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><mi id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="S3.p3.1.m1.1d">italic_ρ</annotation></semantics></math>), and predict the ROI parameters - <em class="ltx_emph ltx_font_italic" id="S3.p3.1.1">center</em>, <em class="ltx_emph ltx_font_italic" id="S3.p3.1.2">size</em>, and <em class="ltx_emph ltx_font_italic" id="S3.p3.1.3">angle</em>.
After pruning, a KAN can be represented as simple mathematics, allowing us to deliver a solution in code, without loading additional models.
We would start the solution by manifesting a KAN from the current mathematical solution. For example, the current <em class="ltx_emph ltx_font_italic" id="S3.p3.1.4">size</em> estimation as described in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#algorithm1" title="Algorithm 1 ‣ 1 Introduction ‣ Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_tag">1</span></a> is mathematically equivalent to the following equation for the <em class="ltx_emph ltx_font_italic" id="S3.p3.1.5">wrist</em>, <em class="ltx_emph ltx_font_italic" id="S3.p3.1.6">index</em> and <em class="ltx_emph ltx_font_italic" id="S3.p3.1.7">pinky</em>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="5.4\sqrt{\rho^{2}(x_{1}-\frac{2x_{2}+x_{3}}{3})^{2}+(y_{1}-\frac{2y_{2}+y_{3}}%
{3})^{2}}" class="ltx_Math" display="block" id="S3.Ex1.m1.2"><semantics id="S3.Ex1.m1.2a"><mrow id="S3.Ex1.m1.2.3" xref="S3.Ex1.m1.2.3.cmml"><mn id="S3.Ex1.m1.2.3.2" xref="S3.Ex1.m1.2.3.2.cmml">5.4</mn><mo id="S3.Ex1.m1.2.3.1" xref="S3.Ex1.m1.2.3.1.cmml">⁢</mo><msqrt id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml"><mrow id="S3.Ex1.m1.2.2.2" xref="S3.Ex1.m1.2.2.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml"><msup id="S3.Ex1.m1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.1.3.2.cmml">ρ</mi><mn id="S3.Ex1.m1.1.1.1.1.3.3" xref="S3.Ex1.m1.1.1.1.1.3.3.cmml">2</mn></msup><mo id="S3.Ex1.m1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.2.cmml">⁢</mo><msup id="S3.Ex1.m1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mfrac id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.cmml"><mn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.2.cmml">2</mn><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.1.cmml">⁢</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml">x</mi><mn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml">2</mn></msub></mrow><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.1.cmml">+</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml">x</mi><mn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml">3</mn></msub></mrow><mn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.cmml">3</mn></mfrac></mrow><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S3.Ex1.m1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.Ex1.m1.2.2.2.3" xref="S3.Ex1.m1.2.2.2.3.cmml">+</mo><msup id="S3.Ex1.m1.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.1.1" xref="S3.Ex1.m1.2.2.2.2.1.1.1.cmml"><mo id="S3.Ex1.m1.2.2.2.2.1.1.2" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.2.2.1.1.1" xref="S3.Ex1.m1.2.2.2.2.1.1.1.cmml"><msub id="S3.Ex1.m1.2.2.2.2.1.1.1.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2.cmml"><mi id="S3.Ex1.m1.2.2.2.2.1.1.1.2.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2.2.cmml">y</mi><mn id="S3.Ex1.m1.2.2.2.2.1.1.1.2.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.Ex1.m1.2.2.2.2.1.1.1.1" xref="S3.Ex1.m1.2.2.2.2.1.1.1.1.cmml">−</mo><mfrac id="S3.Ex1.m1.2.2.2.2.1.1.1.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.cmml"><mn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.2.cmml">2</mn><mo id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.1" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.1.cmml">⁢</mo><msub id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.cmml"><mi id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.2.cmml">y</mi><mn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.3.cmml">2</mn></msub></mrow><mo id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.1" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.1.cmml">+</mo><msub id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.cmml"><mi id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.2" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.2.cmml">y</mi><mn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.3.cmml">3</mn></msub></mrow><mn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.3" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.3.cmml">3</mn></mfrac></mrow><mo id="S3.Ex1.m1.2.2.2.2.1.1.3" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow><mn id="S3.Ex1.m1.2.2.2.2.3" xref="S3.Ex1.m1.2.2.2.2.3.cmml">2</mn></msup></mrow></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.2b"><apply id="S3.Ex1.m1.2.3.cmml" xref="S3.Ex1.m1.2.3"><times id="S3.Ex1.m1.2.3.1.cmml" xref="S3.Ex1.m1.2.3.1"></times><cn id="S3.Ex1.m1.2.3.2.cmml" type="float" xref="S3.Ex1.m1.2.3.2">5.4</cn><apply id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2"><root id="S3.Ex1.m1.2.2a.cmml" xref="S3.Ex1.m1.2.2"></root><apply id="S3.Ex1.m1.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2"><plus id="S3.Ex1.m1.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.3"></plus><apply id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1"><times id="S3.Ex1.m1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.2"></times><apply id="S3.Ex1.m1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.3.2">𝜌</ci><cn id="S3.Ex1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.3.3">2</cn></apply><apply id="S3.Ex1.m1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1"><minus id="S3.Ex1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><cn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.2.3">1</cn></apply><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3"><divide id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3"></divide><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2"><plus id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.1"></plus><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2"><times id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.1"></times><cn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.2.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.2">2</cn><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.2">𝑥</ci><cn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.2.3.3">2</cn></apply></apply><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.2">𝑥</ci><cn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.2.3.3">3</cn></apply></apply><cn id="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.3.3">3</cn></apply></apply><cn id="S3.Ex1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.3">2</cn></apply></apply><apply id="S3.Ex1.m1.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2">superscript</csymbol><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1"><minus id="S3.Ex1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.1"></minus><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.1.1.1.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.1.1.1.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2.2">𝑦</ci><cn id="S3.Ex1.m1.2.2.2.2.1.1.1.2.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.1.1.1.2.3">1</cn></apply><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3"><divide id="S3.Ex1.m1.2.2.2.2.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3"></divide><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2"><plus id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.1"></plus><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2"><times id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.1"></times><cn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.2">2</cn><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3">subscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.2">𝑦</ci><cn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.2.3.3">2</cn></apply></apply><apply id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.1.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3">subscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.2.cmml" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.2">𝑦</ci><cn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.2.3.3">3</cn></apply></apply><cn id="S3.Ex1.m1.2.2.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.1.1.1.3.3">3</cn></apply></apply><cn id="S3.Ex1.m1.2.2.2.2.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.2c">5.4\sqrt{\rho^{2}(x_{1}-\frac{2x_{2}+x_{3}}{3})^{2}+(y_{1}-\frac{2y_{2}+y_{3}}%
{3})^{2}}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.2d">5.4 square-root start_ARG italic_ρ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - divide start_ARG 2 italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 3 end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - divide start_ARG 2 italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_y start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 3 end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">However, due to instability in the <em class="ltx_emph ltx_font_italic" id="S3.p4.1.1">pykan</em> framework, we instead use a standard MLP with two hidden layers of size of 10, to predict each of the ROI parameters separately. This delivers a fast solution of three MLPs with 332 parameters each but lacks the interpretability of a KAN.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To evaluate the effectiveness of our proposed methodology, we measure the improvement in hand ROI predictions. We use the following metrics:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Center Error</span> - in percentage based on the image dimensions, how distance is the predicted center from the gold center.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Scale Error</span> - the absolute difference between the two scales, divided by the gold scale.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Rotation Error</span> - the absolute difference between the predicted and gold angles, circularly around 360 degrees.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">IoU</span> - intersection-over-union of the predicted and actual hand ROIs.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We anticipate that the model will refine ROI predictions leading to higher precision in hand keypoint detection across a variety of hand orientations and movements. This should be reflected by a higher IoU.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We train three separate MLPs on the train set to predict the <em class="ltx_emph ltx_font_italic" id="S5.p1.1.1">center</em>, <em class="ltx_emph ltx_font_italic" id="S5.p1.1.2">size</em>, and <em class="ltx_emph ltx_font_italic" id="S5.p1.1.3">angle</em>.
Table <a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S5.T2" title="Table 2 ‣ 5 Results ‣ Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of both the original and our new method on the test set. It shows that the MLP manages to better predict the <em class="ltx_emph ltx_font_italic" id="S5.p1.1.4">center</em> and <em class="ltx_emph ltx_font_italic" id="S5.p1.1.5">size</em> of the ROI, but fails to better predict the rotation. We believe that this is due to the simplicity of our network, containing only linear layers with <em class="ltx_emph ltx_font_italic" id="S5.p1.1.6">relu</em> activations.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.4" style="width:433.6pt;height:100.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(100.3pt,-23.2pt) scale(1.86036152958602,1.86036152958602) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T2.4.4.4.5">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.1.1.1.1">IoU <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T2.1.1.1.1.m1.1"><semantics id="S5.T2.1.1.1.1.m1.1a"><mo id="S5.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.2.2.2.2">Center <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.2.2.2.2.m1.1"><semantics id="S5.T2.2.2.2.2.m1.1a"><mo id="S5.T2.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.2.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.3.3.3.3">Scale <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.3.3.3.3.m1.1"><semantics id="S5.T2.3.3.3.3.m1.1a"><mo id="S5.T2.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T2.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T2.4.4.4.4">Rotation <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.4.4.4.4.m1.1"><semantics id="S5.T2.4.4.4.4.m1.1a"><mo id="S5.T2.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T2.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.m1.1b"><ci id="S5.T2.4.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.4.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.4.4.5.1.1">Original</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.5.1.2">57%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.5.1.3">2.51%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.4.4.5.1.4">30.37%</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S5.T2.4.4.5.1.5"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.5.1.5.1">32.08</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.4.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.4.4.6.2.1">MLP</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.6.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.2.1">63%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.6.2.3"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.3.1">2.15%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.4.4.6.2.4"><span class="ltx_text ltx_font_bold" id="S5.T2.4.4.6.2.4.1">17.91%</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S5.T2.4.4.6.2.5">56.96</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of our method to the original.</figcaption>
</figure>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Importantly, on the test set, we find that while the minimum IoU using the original method is 3%, our new method archives a minimum of 16%, indicating that it might work better for edge cases.
Comparing the IoU per image, the MLP wins against the original method 63% of the time. Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.03545v2#S5.F2" title="Figure 2 ‣ 5 Results ‣ Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors"><span class="ltx_text ltx_ref_tag">2</span></a> shows the distribution of scores per method.</p>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S5.F2.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Histogram of IoU scores per method.</figcaption>
</figure>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Therefore, unless further optimized, we believe the final solution should use the MLP to predict the <em class="ltx_emph ltx_font_italic" id="S5.p3.1.1">center</em> and <em class="ltx_emph ltx_font_italic" id="S5.p3.1.2">scale</em>, and use the heuristic to calculate the rotation.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The issues we encountered with <em class="ltx_emph ltx_font_italic" id="S6.p1.1.1">pykan</em> prevented us from delivering an interpretable solution, which could prove to be better, and more easily accepted by the library maintainers.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">While being an improvement on the current methodology, our solution should not be the final one. Users of MediaPipe with more time on their hands could explore additional solutions and validate them on larger amounts of data.
Our code is available to ease these future optimizations <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sign-language-processing/mediapipe-hand-crop-fix" title="">https://github.com/sign-language-processing/mediapipe-hand-crop-fix</a>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bazarevsky et al. (2020)</span>
<span class="ltx_bibblock">
Valentin Bazarevsky, Ivan Grishchenko, Karthik Raveendran, Tyler Zhu, Fan Zhang, and Matthias Grundmann. 2020.

</span>
<span class="ltx_bibblock">Blazepose: On-device real-time body pose tracking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2006.10204</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. (2019)</span>
<span class="ltx_bibblock">
Z. Cao, G. Hidalgo Martinez, T. Simon, S. Wei, and Y. A. Sheikh. 2019.

</span>
<span class="ltx_bibblock">OpenPose: Realtime multi-person 2D pose estimation using part affinity fields.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grishchenko and Bazarevsky (2020)</span>
<span class="ltx_bibblock">
Ivan Grishchenko and Valentin Bazarevsky. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://google.github.io/mediapipe/solutions/holistic.html" title="">Mediapipe holistic</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Güler et al. (2018)</span>
<span class="ltx_bibblock">
Rıza Alp Güler, Natalia Neverova, and Iasonas Kokkinos. 2018.

</span>
<span class="ltx_bibblock">Densepose: Dense human pose estimation in the wild.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, pages 7297–7306.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y. Hou, and Max Tegmark. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2404.19756" title="">Kan: Kolmogorov-arnold networks</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moryossef et al. (2021)</span>
<span class="ltx_bibblock">
Amit Moryossef, Ioannis Tsochantaridis, Joe Dinn, Necati Cihan Camgoz, Richard Bowden, Tao Jiang, Annette Rios, Mathias Müller, and Sarah Ebling. 2021.

</span>
<span class="ltx_bibblock">Evaluating the immediate applicability of pose estimation for sign language recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 3434–3440.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pishchulin et al. (2012)</span>
<span class="ltx_bibblock">
Leonid Pishchulin, Arjun Jain, Mykhaylo Andriluka, Thorsten Thorm ä hlen, and Bernt Schiele. 2012.

</span>
<span class="ltx_bibblock">Articulated people detection and pose estimation: Reshaping the future.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">2012 IEEE Conference on Computer Vision and Pattern Recognition</em>, pages 3178–3185. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simon et al. (2017)</span>
<span class="ltx_bibblock">
Tomas Simon, Hanbyul Joo, Iain Matthews, and Yaser Sheikh. 2017.

</span>
<span class="ltx_bibblock">Hand keypoint detection in single images using multiview bootstrapping.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</em>, pages 1145–1153.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutton (2019)</span>
<span class="ltx_bibblock">
Richard S. Sutton. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" title="">The bitter lesson</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-07.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue May 14 16:09:50 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
