<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation</title>
<!--Generated on Wed Sep 18 09:07:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Machine learning,  Computer vision,  Robotics,  Artificial,  augmented,  and virtual realities
" lang="en" name="keywords"/>
<base href="/html/2409.11819v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S1" title="In End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2" title="In End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.SS1" title="In II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Direct Regression 6D Object Pose Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.SS2" title="In II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Perspective-<math alttext="n" class="ltx_Math" display="inline"><semantics><mi>n</mi><annotation-xml encoding="MathML-Content"><ci>𝑛</ci></annotation-xml><annotation encoding="application/x-tex">n</annotation><annotation encoding="application/x-llamapun">italic_n</annotation></semantics></math>-Point</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.SS2.SSS1" title="In II-B Perspective-n-Point ‣ II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span>1 </span>P<math alttext="n" class="ltx_Math" display="inline"><semantics><mi>n</mi><annotation-xml encoding="MathML-Content"><ci>𝑛</ci></annotation-xml><annotation encoding="application/x-tex">n</annotation><annotation encoding="application/x-llamapun">italic_n</annotation></semantics></math>P-based Pose Estimators</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.SS2.SSS2" title="In II-B Perspective-n-Point ‣ II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span>2 </span>P<math alttext="n" class="ltx_Math" display="inline"><semantics><mi>n</mi><annotation-xml encoding="MathML-Content"><ci>𝑛</ci></annotation-xml><annotation encoding="application/x-tex">n</annotation><annotation encoding="application/x-llamapun">italic_n</annotation></semantics></math>P Algorithms</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.SS3" title="In II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">Template Matching</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.SS4" title="In II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-D</span> </span><span class="ltx_text ltx_font_italic">Pose Refinement</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3" title="In End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Proposed Method</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.SS1" title="In III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Algorithm Selection</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.SS2" title="In III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Implementation Details</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.SS3" title="In III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Training Details</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4" title="In End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.SS1" title="In IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Quantitative Results</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.SS2" title="In IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Discussion</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S5" title="In End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Thomas Pöllabauer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id1.1.id1">Virtual &amp; Augmented Reality (VRAR)</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id2.2.id2">Fraunhofer IGD &amp; TU Darmstadt
<br class="ltx_break"/></span>Darmstadt, Germany 
<br class="ltx_break"/>0000-0003-0075-1181
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiayin Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id3.1.id1">VRAR</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id4.2.id2">Fraunhofer IGD
<br class="ltx_break"/></span>Darmstadt, Germany 
<br class="ltx_break"/>0009-0008-7843-6054
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Volker Knauthe
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id5.1.id1">Interactive Graphics Systems Group</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id6.2.id2">TU Darmstadt
<br class="ltx_break"/></span>Darmstadt, Germany 
<br class="ltx_break"/>0000-0001-6993-5099
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sarah Berkei
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id7.1.id1">VRAR</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id8.2.id2">Fraunhofer IGD
<br class="ltx_break"/></span>Darmstadt, Germany 
<br class="ltx_break"/>0000-0002-7986-1414
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arjan Kuijper
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id9.1.id1">Interactive Graphics Systems Group</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id10.2.id2">TU Darmstadt
<br class="ltx_break"/></span>Darmstadt, Germany 
<br class="ltx_break"/>0000-0002-6413-0061
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.id1">6D object pose estimation is the problem of identifying the position and orientation of an object relative to a chosen coordinate system, which is a core technology for modern XR applications.
State-of-the-art 6D object pose estimators directly predict an object pose given an object observation. Due to the ill-posed nature of the pose estimation problem, where multiple different poses can correspond to a single observation, generating additional plausible estimates per observation can be valuable.
To address this, we reformulate the state-of-the-art algorithm GDRNPP and introduce EPRO-GDR (End-to-End Probabilistic Geometry-Guided Regression). Instead of predicting a single pose per detection, we estimate a probability density distribution of the pose.
Using the evaluation procedure defined by the BOP (Benchmark for 6D Object Pose Estimation) Challenge, we test our approach on four of its core datasets and demonstrate superior quantitative results for EPRO-GDR on LM-O, YCB-V, and ITODD. Our probabilistic solution shows that predicting a pose distribution instead of a single pose can improve state-of-the-art single-view pose estimation while providing the additional benefit of being able to sample multiple meaningful pose candidates.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Machine learning, Computer vision, Robotics, Artificial, augmented, and virtual realities

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Detecting objects in 3D space, relative to a camera, is an essential problem for robotics and XR applications. Current state-of-the-art object pose estimators achieve good results predicting a single pose, given a novel object observation. At the same time, the pose estimation task is an ill-posed one, as scene characteristics such as occlusion can drastically reduce estimation accuracy. An even more serious problem is the pose ambiguity problem, where multiple poses may explain a certain observation. We argue that the pose ambiguity problem can be mitigated by predicting a probability density function (pdf) instead of discrete poses.
Towards this end, we enhance and reformulate the state-of-the-art algorithm GDRNPP and introduce EPRO-GDR. Given a single observation, EPRO-GDR is capable of sampling multiple meaningful poses together with an expressive representation of the uncertainty of any sampled pose. While this approach is particularly useful for scene-level optimization, where the poses of all objects in a scene are optimized together, it also enhances the accuracy of individual object pose estimates, as we demonstrate. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Our contribution consists of improving the state-of-the-art single-view pose estimator GDRNPP to predict a pdf per detected object and image, instead of directly regressing pose. EPRO-GDR allows sampling multiple relevant pose candidates together with a meaningful measure of uncertainty, which we argue is useful for multi-view scene-level pose optimization. At the same time, it outperforms the baseline GDRNPP on 3 out of 4 BOP core datasets.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">6D object pose estimation methods can be divided into traditional methods and methods based on deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib2" title="">2</a>]</cite>. Recently the state-of-the-art has been dominated by machine learning-based approaches, as can be seen in the results of the representative BOP challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib4" title="">4</a>]</cite>. In our discussion we will focus on these ML-based algorithms.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">Direct Regression 6D Object Pose Estimation</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">A first group of algorithms uses regression, directly predicting the object pose based on a given image <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib2" title="">2</a>]</cite>. Methods of this kind are SSD-6D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib5" title="">5</a>]</cite>, PoseCNN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib6" title="">6</a>]</cite>, BB8 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib7" title="">7</a>]</cite>, and RDPN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib8" title="">8</a>]</cite>.
SSD-6D follows a similar idea as the predating SSD detector: approaching the detection task by classifying dense candidate boxes and regressing their locations. However, it extends this idea by discretizing the rotation space and transforming the regression problem into a classification task.
PoseCNN leverages convolutional neural networks (CNN) to extract features from RGB images and predicts the semantic labels, rotation, and translation. The paper notably introduces the widely used YCB-Video (YCB-V) dataset, which serves as a core dataset within the BOP challenge.
BB8 predicts the 6D poses using a CNN, represented as 2D projections of the corners of their 6D bounding boxes. To deal with rotational symmetric objects PoseCNN restricts the range of poses used for training and introduces a classifier to identify the pose range at runtime before estimating it. Additionally, an optional refinement step is employed to improve the accuracy of the predicted poses.
RDPN predicts dense correspondences, specifically the object coordinates per visible pixel. Using conventional object detection they crop objects from the image and adjust the camera intrinsic per crop to fit the observation. Next, RDPN extracts relevant features to obtain an object mask and object coordinates. In a third step, dense correspondences are established and used in the pose predictor for pose estimation. RDPN requires RGB-D input.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.6.2.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.1.1">Perspective-<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.1.1.m1.1"><semantics id="S2.SS2.1.1.m1.1b"><mi id="S2.SS2.1.1.m1.1.1" xref="S2.SS2.1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.1.1.m1.1c"><ci id="S2.SS2.1.1.m1.1.1.cmml" xref="S2.SS2.1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.1.1.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.1.1.m1.1e">italic_n</annotation></semantics></math>-Point</span>
</h3>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S2.SS2.SSS1.6.1.1">II-B</span>1 </span>P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.1.m1.1"><semantics id="S2.SS2.SSS1.1.m1.1b"><mi id="S2.SS2.SSS1.1.m1.1.1" xref="S2.SS2.SSS1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.1.m1.1c"><ci id="S2.SS2.SSS1.1.m1.1.1.cmml" xref="S2.SS2.SSS1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.1.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.1.m1.1e">italic_n</annotation></semantics></math>P-based Pose Estimators</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.10">Another group of algorithms predicts various kinds of keypoints and key image features and solves for the pose using perspective-<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.1.m1.1"><semantics id="S2.SS2.SSS1.p1.1.m1.1a"><mi id="S2.SS2.SSS1.p1.1.m1.1.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.1.m1.1b"><ci id="S2.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.1.m1.1d">italic_n</annotation></semantics></math>-point algorithm (P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.2.m2.1"><semantics id="S2.SS2.SSS1.p1.2.m2.1a"><mi id="S2.SS2.SSS1.p1.2.m2.1.1" xref="S2.SS2.SSS1.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.2.m2.1b"><ci id="S2.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.2.m2.1d">italic_n</annotation></semantics></math>P). Among these are SingleShotPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib9" title="">9</a>]</cite>, PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib10" title="">10</a>]</cite>, HybridPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib11" title="">11</a>]</cite>, CDPN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib12" title="">12</a>]</cite>, EPOS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib13" title="">13</a>]</cite>, SurfEmb <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib14" title="">14</a>]</cite>, ZebraPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib15" title="">15</a>]</cite>, GDR-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib16" title="">16</a>]</cite>, and its improved version GDRNPP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib17" title="">17</a>]</cite>.
SingleShotPose extends a YOLO detector to predict the 8 axis-aligned 6D bounding box corners and uses P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.3.m3.1"><semantics id="S2.SS2.SSS1.p1.3.m3.1a"><mi id="S2.SS2.SSS1.p1.3.m3.1.1" xref="S2.SS2.SSS1.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.3.m3.1b"><ci id="S2.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.3.m3.1d">italic_n</annotation></semantics></math>P to solve for the pose.
PVNet generates a voting vector for each pixel in the input images. These voting vectors are then aggregated, resulting in the final prediction of key points. Additionally, a mask is predicted to filter out irrelevant pixels, thereby enhancing accuracy.
HybridPose employs a hybrid intermediate representation to capture various geometric information present in the input image, such as keypoints, edge vectors, and symmetry correspondences. These different intermediate representations can all be predicted using a single neural network. Additionally, a robust regression module is utilized to filter out outliers in the predicted intermediate representations.
CDPN employs a disentangled approach to predict rotation and translation separately for pose estimation. It utilizes a CNN to predict a dense map of 3D coordinates and a mask. The rotation is obtained by solving P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.4.m4.1"><semantics id="S2.SS2.SSS1.p1.4.m4.1a"><mi id="S2.SS2.SSS1.p1.4.m4.1.1" xref="S2.SS2.SSS1.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.4.m4.1b"><ci id="S2.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.4.m4.1d">italic_n</annotation></semantics></math>P/RANSAC using the predicted coordinates, while the translation is estimated directly from the image. In EPOS, objects are represented by compact surface segments. A network with an encoder-decoder architecture is employed to predict the correspondence between densely sampled pixels and these segments. The pose is subsequently determined using a modified P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.5.m5.1"><semantics id="S2.SS2.SSS1.p1.5.m5.1a"><mi id="S2.SS2.SSS1.p1.5.m5.1.1" xref="S2.SS2.SSS1.p1.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.5.m5.1b"><ci id="S2.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS1.p1.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.5.m5.1d">italic_n</annotation></semantics></math>P/RANSAC method called graph-cut RANSAC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib18" title="">18</a>]</cite>.
SurfEmb learns pixel-wise surface distributions and a mask to establish a correspondence distribution. For each individual point on the object in a 2D image, there is a corresponding area on the surface of the 3D models. The pose hypotheses are obtained using P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.6.m6.1"><semantics id="S2.SS2.SSS1.p1.6.m6.1a"><mi id="S2.SS2.SSS1.p1.6.m6.1.1" xref="S2.SS2.SSS1.p1.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.6.m6.1b"><ci id="S2.SS2.SSS1.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS1.p1.6.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.6.m6.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.6.m6.1d">italic_n</annotation></semantics></math>P/RANSAC and are later evaluated using the surface distributions and masks. The pose hypothesis with the highest score is then refined and optimized based on the 2D-3D correspondence distributions.
ZebraPose employs a discrete descriptor that provides dense representation of the object surface instead of relying on learning dense maps. This descriptor utilizes a hierarchical binary surface encoding as an intermediate representation for 3D coordinates, offering increased robustness against occlusion. The final pose estimation is achieved by solving the P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.7.m7.1"><semantics id="S2.SS2.SSS1.p1.7.m7.1a"><mi id="S2.SS2.SSS1.p1.7.m7.1.1" xref="S2.SS2.SSS1.p1.7.m7.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.7.m7.1b"><ci id="S2.SS2.SSS1.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS1.p1.7.m7.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.7.m7.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.7.m7.1d">italic_n</annotation></semantics></math>P problem using the Progressive-X method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib19" title="">19</a>]</cite>.
GDR-Net predicts intermediate geometric features, including dense correspondences and surface region attention. Subsequently, the Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.8.m8.1"><semantics id="S2.SS2.SSS1.p1.8.m8.1a"><mi id="S2.SS2.SSS1.p1.8.m8.1.1" xref="S2.SS2.SSS1.p1.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.8.m8.1b"><ci id="S2.SS2.SSS1.p1.8.m8.1.1.cmml" xref="S2.SS2.SSS1.p1.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.8.m8.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.8.m8.1d">italic_n</annotation></semantics></math>P algorithm directly regresses the 6D object pose. This approach makes GDR-Net differentiable, distinguishing it from traditional two-stage pipelines that establish 2D-3D correspondences and then utilize a variant of the P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.9.m9.1"><semantics id="S2.SS2.SSS1.p1.9.m9.1a"><mi id="S2.SS2.SSS1.p1.9.m9.1.1" xref="S2.SS2.SSS1.p1.9.m9.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.9.m9.1b"><ci id="S2.SS2.SSS1.p1.9.m9.1.1.cmml" xref="S2.SS2.SSS1.p1.9.m9.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.9.m9.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.9.m9.1d">italic_n</annotation></semantics></math>P/RANSAC algorithm. The differentiable nature of Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.10.m10.1"><semantics id="S2.SS2.SSS1.p1.10.m10.1a"><mi id="S2.SS2.SSS1.p1.10.m10.1.1" xref="S2.SS2.SSS1.p1.10.m10.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.10.m10.1b"><ci id="S2.SS2.SSS1.p1.10.m10.1.1.cmml" xref="S2.SS2.SSS1.p1.10.m10.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.10.m10.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.10.m10.1d">italic_n</annotation></semantics></math>P (it is a neural network) makes it particularly suitable for tasks that necessitate differentiable poses.
GDRNPP is an enhanced version of GDR-Net (Geometry-Guided Direct Regression Network) that incorporates stronger domain randomization operations for augmentation. Additionally, ResNet-34 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib20" title="">20</a>]</cite> is replaced with ConvNeXt <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib21" title="">21</a>]</cite> and instead of only predicting the visible mask, it predicts the amodal mask as well.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S2.SS2.SSS2.6.1.1">II-B</span>2 </span>P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.1.m1.1"><semantics id="S2.SS2.SSS2.1.m1.1b"><mi id="S2.SS2.SSS2.1.m1.1.1" xref="S2.SS2.SSS2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.1.m1.1c"><ci id="S2.SS2.SSS2.1.m1.1.1.cmml" xref="S2.SS2.SSS2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.1.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.1.m1.1e">italic_n</annotation></semantics></math>P Algorithms</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.10">There are many different algorithms to solve the P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.1.m1.1"><semantics id="S2.SS2.SSS2.p1.1.m1.1a"><mi id="S2.SS2.SSS2.p1.1.m1.1.1" xref="S2.SS2.SSS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.1.m1.1b"><ci id="S2.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.1.m1.1d">italic_n</annotation></semantics></math>P problem, among them are Iterative P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.2.m2.1"><semantics id="S2.SS2.SSS2.p1.2.m2.1a"><mi id="S2.SS2.SSS2.p1.2.m2.1.1" xref="S2.SS2.SSS2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.2.m2.1b"><ci id="S2.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.2.m2.1d">italic_n</annotation></semantics></math>P, Efficient P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.3.m3.1"><semantics id="S2.SS2.SSS2.p1.3.m3.1a"><mi id="S2.SS2.SSS2.p1.3.m3.1.1" xref="S2.SS2.SSS2.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.3.m3.1b"><ci id="S2.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS2.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.3.m3.1d">italic_n</annotation></semantics></math>P (EP<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.4.m4.1"><semantics id="S2.SS2.SSS2.p1.4.m4.1a"><mi id="S2.SS2.SSS2.p1.4.m4.1.1" xref="S2.SS2.SSS2.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.4.m4.1b"><ci id="S2.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS2.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.4.m4.1d">italic_n</annotation></semantics></math>P) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib22" title="">22</a>]</cite>, Generalized End-to-End Probabilistic P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.5.m5.1"><semantics id="S2.SS2.SSS2.p1.5.m5.1a"><mi id="S2.SS2.SSS2.p1.5.m5.1.1" xref="S2.SS2.SSS2.p1.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.5.m5.1b"><ci id="S2.SS2.SSS2.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS2.p1.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.5.m5.1d">italic_n</annotation></semantics></math>P (EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.6.m6.1"><semantics id="S2.SS2.SSS2.p1.6.m6.1a"><mi id="S2.SS2.SSS2.p1.6.m6.1.1" xref="S2.SS2.SSS2.p1.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.6.m6.1b"><ci id="S2.SS2.SSS2.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS2.p1.6.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.6.m6.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.6.m6.1d">italic_n</annotation></semantics></math>P) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib23" title="">23</a>]</cite>, Progressive-X (Prog-X) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib19" title="">19</a>]</cite>, and Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.7.m7.1"><semantics id="S2.SS2.SSS2.p1.7.m7.1a"><mi id="S2.SS2.SSS2.p1.7.m7.1.1" xref="S2.SS2.SSS2.p1.7.m7.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.7.m7.1b"><ci id="S2.SS2.SSS2.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS2.p1.7.m7.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.7.m7.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.7.m7.1d">italic_n</annotation></semantics></math>P <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib16" title="">16</a>]</cite>.
Iterative P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.8.m8.1"><semantics id="S2.SS2.SSS2.p1.8.m8.1a"><mi id="S2.SS2.SSS2.p1.8.m8.1.1" xref="S2.SS2.SSS2.p1.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.8.m8.1b"><ci id="S2.SS2.SSS2.p1.8.m8.1.1.cmml" xref="S2.SS2.SSS2.p1.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.8.m8.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.8.m8.1d">italic_n</annotation></semantics></math>P refines an initial estimate by minimizing the re-projection error until it falls below a certain threshold.
EP<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.9.m9.1"><semantics id="S2.SS2.SSS2.p1.9.m9.1a"><mi id="S2.SS2.SSS2.p1.9.m9.1.1" xref="S2.SS2.SSS2.p1.9.m9.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.9.m9.1b"><ci id="S2.SS2.SSS2.p1.9.m9.1.1.cmml" xref="S2.SS2.SSS2.p1.9.m9.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.9.m9.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.9.m9.1d">italic_n</annotation></semantics></math>P achieves its efficiency by expressing pose as a function of four virtual control points, thereby reducing the number of unknowns to be solved.
EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p1.10.m10.1"><semantics id="S2.SS2.SSS2.p1.10.m10.1a"><mi id="S2.SS2.SSS2.p1.10.m10.1.1" xref="S2.SS2.SSS2.p1.10.m10.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.10.m10.1b"><ci id="S2.SS2.SSS2.p1.10.m10.1.1.cmml" xref="S2.SS2.SSS2.p1.10.m10.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.10.m10.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p1.10.m10.1d">italic_n</annotation></semantics></math>P is a probabilistic approach and differentiable. It minimizes the Kullback-Leibler divergence between prediction and target pose distribution to learn the intermediate variables: 2D-3D coordinates and corresponding 2D weights.
Prog-X progessively grows the set of points considered to find a solution, allowing to incrementally improve upon the current solution.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.5.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.6.2">Template Matching</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.2">Template matching tries to solve for object pose by generating templates (often renderings based on 3D meshes) and matching them with the object appearances found in the target view. This often involves finding key points in both the template and the image and looking for similarities. One of the most prominent methods following this idea is the non-ML algorithm Linemod <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib24" title="">24</a>]</cite>.
But the idea is also found in more modern algorithms, such as the zero-shot methods MegaPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib25" title="">25</a>]</cite> and GigaPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib26" title="">26</a>]</cite>. PFA-Pose (Prspective Flow Aggregation) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib27" title="">27</a>]</cite>, after estimating an initial pose using a first network, continues to match this pose with offline-generated templates. However, for the BOP challenge, the rendering is done online, resulting in improved accuracy compared to offline rendering as mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib28" title="">28</a>]</cite>. Comparison between retrieved template and target view in the 2D image is done by computing the displacement field between both. This field represents the distance and direction that each pixel needs to move from the example image to the target image. Displacement field results are combined and transformed into a set of 3D-2D correspondences. The final result is obtained by solving the P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><mi id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">italic_n</annotation></semantics></math>P problem using RANSAC/P<math alttext="n" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">italic_n</annotation></semantics></math>P. As a result, this method consists of two stages and cannot be trained end-to-end, which we think is a major drawback and important reason to choose to extend GDRNPP over PFA.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="222" id="S2.F1.g1" src="extracted/5862760/figures/EPRO-GDRv2_ICPR.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.10.5.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.8.4" style="font-size:90%;">Proposed method with both training phases. We start by training GDRNPP as described in the author’s description of their entry to the BOP challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib17" title="">17</a>]</cite>, predicting 3D coordinate maps, masks, and surface region attention and solving directly for pose using Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S2.F1.5.1.m1.1"><semantics id="S2.F1.5.1.m1.1b"><mi id="S2.F1.5.1.m1.1.1" xref="S2.F1.5.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.F1.5.1.m1.1c"><ci id="S2.F1.5.1.m1.1.1.cmml" xref="S2.F1.5.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.5.1.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.F1.5.1.m1.1e">italic_n</annotation></semantics></math>P (Phase 1, white arrows). Phase 2 / black arrows: After convergence we replace Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S2.F1.6.2.m2.1"><semantics id="S2.F1.6.2.m2.1b"><mi id="S2.F1.6.2.m2.1.1" xref="S2.F1.6.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.F1.6.2.m2.1c"><ci id="S2.F1.6.2.m2.1.1.cmml" xref="S2.F1.6.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.6.2.m2.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.F1.6.2.m2.1e">italic_n</annotation></semantics></math>P with EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S2.F1.7.3.m3.1"><semantics id="S2.F1.7.3.m3.1b"><mi id="S2.F1.7.3.m3.1.1" xref="S2.F1.7.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.F1.7.3.m3.1c"><ci id="S2.F1.7.3.m3.1.1.cmml" xref="S2.F1.7.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.7.3.m3.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.F1.7.3.m3.1e">italic_n</annotation></semantics></math>P and modify the loss functions (details in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.SS2" title="III-B Implementation Details ‣ III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>), also predict the 2D weights required by EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S2.F1.8.4.m4.1"><semantics id="S2.F1.8.4.m4.1b"><mi id="S2.F1.8.4.m4.1.1" xref="S2.F1.8.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.F1.8.4.m4.1c"><ci id="S2.F1.8.4.m4.1.1.cmml" xref="S2.F1.8.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.8.4.m4.1d">n</annotation><annotation encoding="application/x-llamapun" id="S2.F1.8.4.m4.1e">italic_n</annotation></semantics></math>P, and continue training. After convergence, our model is fully trained. At inference, we predict a distribution instead of a single pose. The data flow is the same as with Phase 2, our second training phase. </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS4.5.1.1">II-D</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS4.6.2">Pose Refinement</span>
</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Pose refinement is the process of starting with a coarse initial pose estimate and using additional (often iterative) steps to (step-wise) increase the final prediction accuracy.
DeepIM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib29" title="">29</a>]</cite> builds upon PoseCNN and introduces an iterative optimization process to enhance pose estimation accuracy. This process involves iteratively matching between images rendered from the 3D model. The refined pose from each iteration serves as the input for the next iteration. This iterative matching continues until the process converges or reaches the maximum number of steps. CosyPose, as described in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib30" title="">30</a>]</cite>, combines the DeepIM approach with scene-level refinement. This approach improves both pose estimation and correspondences simultaneously. RePose, introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib31" title="">31</a>]</cite>, achieves faster runtime by replacing repeated forward passes of CNN-based optimization with a fast renderer and a learned 3D texture.
Another important refinement method, Iterative closest point (ICP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib32" title="">32</a>]</cite>, is commonly used for aligning 3D models. Given two point clouds, the algorithm iteratively adjusts the transformation parameters, including rotation and translation, to minimize the distance between corresponding points in the two point clouds.
Coupled-iterative refinement (CIR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib33" title="">33</a>]</cite> involves estimating the flow between an input image and a collection of rendered images of a known 3D object. This estimation process generates 2D-3D correspondences, which are subsequently utilized to solve for pose estimation. What sets CIR apart is its coupled iterative approach, where the flow and object pose are updated in a mutually dependent manner. Specifically, the update of the flow is conditioned on the current pose and vice versa.
GDRNPP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib17" title="">17</a>]</cite> propose a depth refinement step to improve the accuracy of the translation estimate. This refinement is achieved by comparing the rendered object depth and the observed depth. The depth refinement value is computed as the median of the differences between these depth values for corresponding pixels. The updated translation vector is then obtained by adding a translation adjustment, calculated based on the depth difference and the inverse of the camera intrinsic matrix, to the initial translation estimate.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Proposed Method</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We discuss the algorithm selection for probabilistic pose estimation, discuss our modifications, and overall approach, before detailing our implementation and training details.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Algorithm Selection</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We can draw some conclusions from previous work: First, P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_n</annotation></semantics></math>P-based methods tend to be more likely to achieve SotA performance. Second, refinement plays a critical role to lift a good result to one of the best. For instance CIR increases average recall of GDRNPP-PBR-RGB-MModel by approximately 0.1, as shown in the BOP challenge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib4" title="">4</a>]</cite>. Finally, probability-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib34" title="">34</a>]</cite> modeling pose distributions show the potential to increase robustness. In our opinion, the ability to sample multiple plausible pose candidates per detection, along with their associated probabilities as an indicator of quality, makes them an excellent choice for scene-level optimization.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Top 10 entries in the leaderboard of the BOP challenge for the task localization of seen objects <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib35" title="">35</a>]</cite>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.7.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.1.1.1"><span class="ltx_text" id="S3.T1.7.1.1.1.1" style="font-size:90%;">Rank</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.1.1.2"><span class="ltx_text" id="S3.T1.7.1.1.2.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.7.1.1.3"><span class="ltx_text" id="S3.T1.7.1.1.3.1" style="font-size:90%;">AR</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S3.T1.7.1.1.4"><span class="ltx_text" id="S3.T1.7.1.1.4.1" style="font-size:90%;">Time</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.7.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.2.1.1"><span class="ltx_text" id="S3.T1.7.2.1.1.1" style="font-size:90%;">1</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.2.1.2"><span class="ltx_text" id="S3.T1.7.2.1.2.1" style="font-size:90%;">GPose2023</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.2.1.3"><span class="ltx_text" id="S3.T1.7.2.1.3.1" style="font-size:90%;">85.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.2.1.4"><span class="ltx_text" id="S3.T1.7.2.1.4.1" style="font-size:90%;">2.670</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.3.2.1"><span class="ltx_text" id="S3.T1.7.3.2.1.1" style="font-size:90%;">2</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.3.2.2"><span class="ltx_text" id="S3.T1.7.3.2.2.1" style="font-size:90%;">GPose2023-OfficialDetection</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.3.2.3"><span class="ltx_text" id="S3.T1.7.3.2.3.1" style="font-size:90%;">85.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.3.2.4"><span class="ltx_text" id="S3.T1.7.3.2.4.1" style="font-size:90%;">4.575</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.4.3.1"><span class="ltx_text" id="S3.T1.7.4.3.1.1" style="font-size:90%;">3</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.4.3.2"><span class="ltx_text" id="S3.T1.7.4.3.2.1" style="font-size:90%;">GPose2023-PBR</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.4.3.3"><span class="ltx_text" id="S3.T1.7.4.3.3.1" style="font-size:90%;">84.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.4.3.4"><span class="ltx_text" id="S3.T1.7.4.3.4.1" style="font-size:90%;">2.686</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.5.4.1"><span class="ltx_text" id="S3.T1.7.5.4.1.1" style="font-size:90%;">4</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.5.4.2"><span class="ltx_text" id="S3.T1.7.5.4.2.1" style="font-size:90%;">GDRNPP-PBRReal-RGBD</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.5.4.3"><span class="ltx_text" id="S3.T1.7.5.4.3.1" style="font-size:90%;">83.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.5.4.4"><span class="ltx_text" id="S3.T1.7.5.4.4.1" style="font-size:90%;">6.263</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.6.5.1"><span class="ltx_text" id="S3.T1.7.6.5.1.1" style="font-size:90%;">5</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.6.5.2"><span class="ltx_text" id="S3.T1.7.6.5.2.1" style="font-size:90%;">GDRNPP-PBR-RGBD</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.6.5.3"><span class="ltx_text" id="S3.T1.7.6.5.3.1" style="font-size:90%;">82.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.6.5.4"><span class="ltx_text" id="S3.T1.7.6.5.4.1" style="font-size:90%;">6.264</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.7.6.1"><span class="ltx_text" id="S3.T1.7.7.6.1.1" style="font-size:90%;">6</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.7.6.2"><span class="ltx_text" id="S3.T1.7.7.6.2.1" style="font-size:90%;">ZebraPose-EffnetB4-refined</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.6.3"><span class="ltx_text" id="S3.T1.7.7.6.3.1" style="font-size:90%;">81.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.7.6.4"><span class="ltx_text" id="S3.T1.7.7.6.4.1" style="font-size:90%;">2.577</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.8.7.1"><span class="ltx_text" id="S3.T1.7.8.7.1.1" style="font-size:90%;">7</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.8.7.2"><span class="ltx_text" id="S3.T1.7.8.7.2.1" style="font-size:90%;">GDRNPP-PBRReal-RGBD-Fast</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.8.7.3"><span class="ltx_text" id="S3.T1.7.8.7.3.1" style="font-size:90%;">80.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.8.7.4"><span class="ltx_text" id="S3.T1.7.8.7.4.1" style="font-size:90%;">0.228</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.9.8.1"><span class="ltx_text" id="S3.T1.7.9.8.1.1" style="font-size:90%;">8</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.9.8.2"><span class="ltx_text" id="S3.T1.7.9.8.2.1" style="font-size:90%;">PFA-Mixpbr-RGBD</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.9.8.3"><span class="ltx_text" id="S3.T1.7.9.8.3.1" style="font-size:90%;">80.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.9.8.4"><span class="ltx_text" id="S3.T1.7.9.8.4.1" style="font-size:90%;">1.193</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.10.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.10.9.1"><span class="ltx_text" id="S3.T1.7.10.9.1.1" style="font-size:90%;">9</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.7.10.9.2"><span class="ltx_text" id="S3.T1.7.10.9.2.1" style="font-size:90%;">RDPN</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.10.9.3"><span class="ltx_text" id="S3.T1.7.10.9.3.1" style="font-size:90%;">79.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.7.10.9.4"><span class="ltx_text" id="S3.T1.7.10.9.4.1" style="font-size:90%;">2.429</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.11.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.7.11.10.1"><span class="ltx_text" id="S3.T1.7.11.10.1.1" style="font-size:90%;">10</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.7.11.10.2"><span class="ltx_text" id="S3.T1.7.11.10.2.1" style="font-size:90%;">GDRNPP-PBRReal-RGBD-OfficialDet.</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.7.11.10.3"><span class="ltx_text" id="S3.T1.7.11.10.3.1" style="font-size:90%;">79.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.7.11.10.4"><span class="ltx_text" id="S3.T1.7.11.10.4.1" style="font-size:90%;">6.406</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.6">To select a suitable pose estimation algorithm to extend we take a look at the BOP leaderboard presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.T1" title="TABLE I ‣ III-A Algorithm Selection ‣ III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">I</span></a>. We find five different algorithms among the top 10 positions: GPose, GDRNPP, ZebraPose, PFA, and RDPN. GPose is an extension to GDRNPP, though there is no paper nor an implementation published. GDRNPP, ZebraPose, PFA, and RDPN were discussed above in Seciton <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2" title="II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">II</span></a>. Based on our algorithm discussion and their ranking in the BOP leaderboard, we choose to extend the SotA method GDRNPP for several reasongs: first, for its simple design and high performance in the BOP Challenge. The simple encoder-decoder architecture and the realization of P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_n</annotation></semantics></math>P in form of a neural network are appealing. Most importantly, because of this design, GDRNPP can be trained in an end-to-end (and fully differentiable) manner and it is possible to directly concatenate any features that may facilitate the resolution of the P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_n</annotation></semantics></math>P problem and input them into the implicit P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_n</annotation></semantics></math>P solver, as has been shown in a straightforward stereo vision extension <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib36" title="">36</a>]</cite>. Also, GPose as the overall best performing algorithm being based on GDRNPP shows there is still potential in improving the architecture. GDRNPP’s design and use of Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_n</annotation></semantics></math>P also makes it a natural candidate to incorporate a probabilistic method for pose distribution prediction, which we argue can benefit (multi-view) scene-level optimization. Based on our research, EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_n</annotation></semantics></math>P seems to be a natural fit for our purpose and we decide to integrate EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_n</annotation></semantics></math>P into GDRNPP and call our modified algorithm EPRO-GDR.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Implementation Details</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">We propose to replace GDRNPPs Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_n</annotation></semantics></math>P algorithm with EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_n</annotation></semantics></math>P <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib23" title="">23</a>]</cite> to easily sample multiple pose candidates per image and object detection. We continue by presenting EPRO-GDR in detail.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.6">GDRNPP runs a detector (YOLOX <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib37" title="">37</a>]</cite> in case of the BOP challenge) to detect objects within the 2D image grid, crops the object and feeds the image patch (RoI) to the backbone network ConvNeXt. Inspired by CDPN the extracted feature maps are used to predict 3 different features: visible and amodal object masks <math alttext="M_{vis}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">M</mi><mrow id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">v</mi><mo id="S3.SS2.p2.1.m1.1.1.3.1" xref="S3.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml">i</mi><mo id="S3.SS2.p2.1.m1.1.1.3.1a" xref="S3.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.1.m1.1.1.3.4" xref="S3.SS2.p2.1.m1.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝑀</ci><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><times id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.1"></times><ci id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">𝑣</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3">𝑖</ci><ci id="S3.SS2.p2.1.m1.1.1.3.4.cmml" xref="S3.SS2.p2.1.m1.1.1.3.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">M_{vis}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_M start_POSTSUBSCRIPT italic_v italic_i italic_s end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="M_{amodal}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">M</mi><mrow id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.3" xref="S3.SS2.p2.2.m2.1.1.3.3.cmml">m</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1a" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.4" xref="S3.SS2.p2.2.m2.1.1.3.4.cmml">o</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1b" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.5" xref="S3.SS2.p2.2.m2.1.1.3.5.cmml">d</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1c" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.6" xref="S3.SS2.p2.2.m2.1.1.3.6.cmml">a</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1d" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.7" xref="S3.SS2.p2.2.m2.1.1.3.7.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑀</ci><apply id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3"><times id="S3.SS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3.1"></times><ci id="S3.SS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.2">𝑎</ci><ci id="S3.SS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3">𝑚</ci><ci id="S3.SS2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS2.p2.2.m2.1.1.3.4">𝑜</ci><ci id="S3.SS2.p2.2.m2.1.1.3.5.cmml" xref="S3.SS2.p2.2.m2.1.1.3.5">𝑑</ci><ci id="S3.SS2.p2.2.m2.1.1.3.6.cmml" xref="S3.SS2.p2.2.m2.1.1.3.6">𝑎</ci><ci id="S3.SS2.p2.2.m2.1.1.3.7.cmml" xref="S3.SS2.p2.2.m2.1.1.3.7">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">M_{amodal}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_M start_POSTSUBSCRIPT italic_a italic_m italic_o italic_d italic_a italic_l end_POSTSUBSCRIPT</annotation></semantics></math>, 3D coordinate maps <math alttext="x^{3D}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><msup id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">x</mi><mrow id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml"><mn id="S3.SS2.p2.3.m3.1.1.3.2" xref="S3.SS2.p2.3.m3.1.1.3.2.cmml">3</mn><mo id="S3.SS2.p2.3.m3.1.1.3.1" xref="S3.SS2.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.3.m3.1.1.3.3" xref="S3.SS2.p2.3.m3.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">𝑥</ci><apply id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3"><times id="S3.SS2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS2.p2.3.m3.1.1.3.1"></times><cn id="S3.SS2.p2.3.m3.1.1.3.2.cmml" type="integer" xref="S3.SS2.p2.3.m3.1.1.3.2">3</cn><ci id="S3.SS2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">x^{3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_x start_POSTSUPERSCRIPT 3 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> transformed into dense correspondence maps <math alttext="M_{2D-3D}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">M</mi><mrow id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mrow id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml"><mn id="S3.SS2.p2.4.m4.1.1.3.2.2" xref="S3.SS2.p2.4.m4.1.1.3.2.2.cmml">2</mn><mo id="S3.SS2.p2.4.m4.1.1.3.2.1" xref="S3.SS2.p2.4.m4.1.1.3.2.1.cmml">⁢</mo><mi id="S3.SS2.p2.4.m4.1.1.3.2.3" xref="S3.SS2.p2.4.m4.1.1.3.2.3.cmml">D</mi></mrow><mo id="S3.SS2.p2.4.m4.1.1.3.1" xref="S3.SS2.p2.4.m4.1.1.3.1.cmml">−</mo><mrow id="S3.SS2.p2.4.m4.1.1.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.cmml"><mn id="S3.SS2.p2.4.m4.1.1.3.3.2" xref="S3.SS2.p2.4.m4.1.1.3.3.2.cmml">3</mn><mo id="S3.SS2.p2.4.m4.1.1.3.3.1" xref="S3.SS2.p2.4.m4.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.4.m4.1.1.3.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.3.cmml">D</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">𝑀</ci><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><minus id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.1"></minus><apply id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2"><times id="S3.SS2.p2.4.m4.1.1.3.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2.1"></times><cn id="S3.SS2.p2.4.m4.1.1.3.2.2.cmml" type="integer" xref="S3.SS2.p2.4.m4.1.1.3.2.2">2</cn><ci id="S3.SS2.p2.4.m4.1.1.3.2.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2.3">𝐷</ci></apply><apply id="S3.SS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3"><times id="S3.SS2.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.1"></times><cn id="S3.SS2.p2.4.m4.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.p2.4.m4.1.1.3.3.2">3</cn><ci id="S3.SS2.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">M_{2D-3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_M start_POSTSUBSCRIPT 2 italic_D - 3 italic_D end_POSTSUBSCRIPT</annotation></semantics></math>, and surface region attention maps <math alttext="M_{SRA}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">M</mi><mrow id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">S</mi><mo id="S3.SS2.p2.5.m5.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml">R</mi><mo id="S3.SS2.p2.5.m5.1.1.3.1a" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.5.m5.1.1.3.4" xref="S3.SS2.p2.5.m5.1.1.3.4.cmml">A</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">𝑀</ci><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><times id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.1"></times><ci id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2">𝑆</ci><ci id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3">𝑅</ci><ci id="S3.SS2.p2.5.m5.1.1.3.4.cmml" xref="S3.SS2.p2.5.m5.1.1.3.4">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">M_{SRA}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_M start_POSTSUBSCRIPT italic_S italic_R italic_A end_POSTSUBSCRIPT</annotation></semantics></math>. Compared to CDPN the translation head is removed. The extracted features get handed to the Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_n</annotation></semantics></math>P solver consisting of a small CNN with 3 layers leading into 2-layer MLP.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.4">EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_n</annotation></semantics></math>P extracts 3D coordinate maps and 2D-3D correspondence maps to solve the P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_n</annotation></semantics></math>P problem. Based on the architecture of CDPN, EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_n</annotation></semantics></math>P proposes to view the P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_n</annotation></semantics></math>P problem as a non-linear least squares problem written in equation <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.E1" title="In III-B Implementation Details ‣ III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib23" title="">23</a>]</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\underset{y}{\operatorname{arg\ min}}\frac{1}{2}\sum_{i=1}^{N}\|\underbrace{w_%
{i}^{2\mathrm{D}}\circ\left(\pi\left(Rx_{i}^{3\mathrm{D}}+t\right)-x_{i}^{2%
\mathrm{D}}\right)}_{f_{i}(y)\in\mathbb{R}^{2}}\|^{2}" class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><munder accentunder="true" id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mrow id="S3.E1.m1.3.3.3.2" xref="S3.E1.m1.3.3.3.2.cmml"><mi id="S3.E1.m1.3.3.3.2.2" xref="S3.E1.m1.3.3.3.2.2.cmml">arg</mi><mo id="S3.E1.m1.3.3.3.2.1" lspace="0.500em" xref="S3.E1.m1.3.3.3.2.1.cmml">⁢</mo><mi id="S3.E1.m1.3.3.3.2.3" xref="S3.E1.m1.3.3.3.2.3.cmml">min</mi></mrow><mo id="S3.E1.m1.3.3.3.1" xref="S3.E1.m1.3.3.3.1.cmml">𝑦</mo></munder><mo id="S3.E1.m1.3.3.2" lspace="0.167em" xref="S3.E1.m1.3.3.2.cmml">⁢</mo><mfrac id="S3.E1.m1.3.3.4" xref="S3.E1.m1.3.3.4.cmml"><mn id="S3.E1.m1.3.3.4.2" xref="S3.E1.m1.3.3.4.2.cmml">1</mn><mn id="S3.E1.m1.3.3.4.3" xref="S3.E1.m1.3.3.4.3.cmml">2</mn></mfrac><mo id="S3.E1.m1.3.3.2a" xref="S3.E1.m1.3.3.2.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.cmml"><munderover id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.2.cmml"><mo id="S3.E1.m1.3.3.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E1.m1.3.3.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.3.3.1.2.2.3" xref="S3.E1.m1.3.3.1.2.2.3.cmml"><mi id="S3.E1.m1.3.3.1.2.2.3.2" xref="S3.E1.m1.3.3.1.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.3.3.1.2.2.3.1" xref="S3.E1.m1.3.3.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.3.3.1.2.2.3.3" xref="S3.E1.m1.3.3.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.3.3.1.2.3" xref="S3.E1.m1.3.3.1.2.3.cmml">N</mi></munderover><msup id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.2.cmml"><mo id="S3.E1.m1.3.3.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.2.1.cmml">‖</mo><munder id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml"><munder accentunder="true" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><msubsup id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.3.2.2.cmml">w</mi><mi id="S3.E1.m1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.3.2.3.cmml">i</mi><mrow id="S3.E1.m1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.3.3.cmml"><mn id="S3.E1.m1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.3.3.2.cmml">2</mn><mo id="S3.E1.m1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.3.3.3" mathvariant="normal" xref="S3.E1.m1.1.1.1.3.3.3.cmml">D</mi></mrow></msubsup><mo id="S3.E1.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.1.2.cmml">∘</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">π</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.3.cmml">i</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml"><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.2.cmml">3</mn><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.3" mathvariant="normal" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.3.cmml">D</mi></mrow></msubsup></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">−</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml"><mn id="S3.E1.m1.1.1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml">2</mn><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3" mathvariant="normal" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml">D</mi></mrow></msubsup></mrow><mo id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">⏟</mo></munder><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><mrow id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml"><msub id="S3.E1.m1.2.2.1.3.2" xref="S3.E1.m1.2.2.1.3.2.cmml"><mi id="S3.E1.m1.2.2.1.3.2.2" xref="S3.E1.m1.2.2.1.3.2.2.cmml">f</mi><mi id="S3.E1.m1.2.2.1.3.2.3" xref="S3.E1.m1.2.2.1.3.2.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.3.1" xref="S3.E1.m1.2.2.1.3.1.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.1.3.3.2" xref="S3.E1.m1.2.2.1.3.cmml"><mo id="S3.E1.m1.2.2.1.3.3.2.1" stretchy="false" xref="S3.E1.m1.2.2.1.3.cmml">(</mo><mi id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml">y</mi><mo id="S3.E1.m1.2.2.1.3.3.2.2" stretchy="false" xref="S3.E1.m1.2.2.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.2.cmml">∈</mo><msup id="S3.E1.m1.2.2.1.4" xref="S3.E1.m1.2.2.1.4.cmml"><mi id="S3.E1.m1.2.2.1.4.2" xref="S3.E1.m1.2.2.1.4.2.cmml">ℝ</mi><mn id="S3.E1.m1.2.2.1.4.3" xref="S3.E1.m1.2.2.1.4.3.cmml">2</mn></msup></mrow></munder><mo id="S3.E1.m1.3.3.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><times id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"></times><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><ci id="S3.E1.m1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.3.1">𝑦</ci><apply id="S3.E1.m1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.2"><times id="S3.E1.m1.3.3.3.2.1.cmml" xref="S3.E1.m1.3.3.3.2.1"></times><ci id="S3.E1.m1.3.3.3.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2">arg</ci><ci id="S3.E1.m1.3.3.3.2.3.cmml" xref="S3.E1.m1.3.3.3.2.3">min</ci></apply></apply><apply id="S3.E1.m1.3.3.4.cmml" xref="S3.E1.m1.3.3.4"><divide id="S3.E1.m1.3.3.4.1.cmml" xref="S3.E1.m1.3.3.4"></divide><cn id="S3.E1.m1.3.3.4.2.cmml" type="integer" xref="S3.E1.m1.3.3.4.2">1</cn><cn id="S3.E1.m1.3.3.4.3.cmml" type="integer" xref="S3.E1.m1.3.3.4.3">2</cn></apply><apply id="S3.E1.m1.3.3.1.cmml" xref="S3.E1.m1.3.3.1"><apply id="S3.E1.m1.3.3.1.2.cmml" xref="S3.E1.m1.3.3.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.2.1.cmml" xref="S3.E1.m1.3.3.1.2">superscript</csymbol><apply id="S3.E1.m1.3.3.1.2.2.cmml" xref="S3.E1.m1.3.3.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.2.2.1.cmml" xref="S3.E1.m1.3.3.1.2">subscript</csymbol><sum id="S3.E1.m1.3.3.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.2.2.2"></sum><apply id="S3.E1.m1.3.3.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.2.2.3"><eq id="S3.E1.m1.3.3.1.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.2.2.3.1"></eq><ci id="S3.E1.m1.3.3.1.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.2.2.3.2">𝑖</ci><cn id="S3.E1.m1.3.3.1.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.3.3.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.3.3.1.2.3.cmml" xref="S3.E1.m1.3.3.1.2.3">𝑁</ci></apply><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1">superscript</csymbol><apply id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><ci id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">⏟</ci><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><compose id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></compose><apply id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.3.2.2">𝑤</ci><ci id="S3.E1.m1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S3.E1.m1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.3.3.1"></times><cn id="S3.E1.m1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.3.3.2">2</cn><ci id="S3.E1.m1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.3.3.3">D</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"></minus><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">𝜋</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2">𝑅</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.2">𝑥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.2.3">𝑖</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3"><times id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.1"></times><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.2">3</cn><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.3.3">D</ci></apply></apply></apply><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2">𝑥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.1"></times><cn id="S3.E1.m1.1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.3.3.2">2</cn><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3.3">D</ci></apply></apply></apply></apply></apply><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><in id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.2"></in><apply id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3"><times id="S3.E1.m1.2.2.1.3.1.cmml" xref="S3.E1.m1.2.2.1.3.1"></times><apply id="S3.E1.m1.2.2.1.3.2.cmml" xref="S3.E1.m1.2.2.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.3.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.3.2.2">𝑓</ci><ci id="S3.E1.m1.2.2.1.3.2.3.cmml" xref="S3.E1.m1.2.2.1.3.2.3">𝑖</ci></apply><ci id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1">𝑦</ci></apply><apply id="S3.E1.m1.2.2.1.4.cmml" xref="S3.E1.m1.2.2.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.4.1.cmml" xref="S3.E1.m1.2.2.1.4">superscript</csymbol><ci id="S3.E1.m1.2.2.1.4.2.cmml" xref="S3.E1.m1.2.2.1.4.2">ℝ</ci><cn id="S3.E1.m1.2.2.1.4.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.4.3">2</cn></apply></apply></apply></apply><cn id="S3.E1.m1.3.3.1.1.3.cmml" type="integer" xref="S3.E1.m1.3.3.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\underset{y}{\operatorname{arg\ min}}\frac{1}{2}\sum_{i=1}^{N}\|\underbrace{w_%
{i}^{2\mathrm{D}}\circ\left(\pi\left(Rx_{i}^{3\mathrm{D}}+t\right)-x_{i}^{2%
\mathrm{D}}\right)}_{f_{i}(y)\in\mathbb{R}^{2}}\|^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">underitalic_y start_ARG roman_arg roman_min end_ARG divide start_ARG 1 end_ARG start_ARG 2 end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ∥ under⏟ start_ARG italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 roman_D end_POSTSUPERSCRIPT ∘ ( italic_π ( italic_R italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 roman_D end_POSTSUPERSCRIPT + italic_t ) - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 roman_D end_POSTSUPERSCRIPT ) end_ARG start_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y ) ∈ blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.14">The objective is to estimate a target pose <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m1.1"><semantics id="S3.SS2.p3.5.m1.1a"><mi id="S3.SS2.p3.5.m1.1.1" xref="S3.SS2.p3.5.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m1.1b"><ci id="S3.SS2.p3.5.m1.1.1.cmml" xref="S3.SS2.p3.5.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m1.1d">italic_y</annotation></semantics></math> minimizing the cumulative squared weighted re-projection error. Using the projection function <math alttext="\pi(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m2.1"><semantics id="S3.SS2.p3.6.m2.1a"><mrow id="S3.SS2.p3.6.m2.1.2" xref="S3.SS2.p3.6.m2.1.2.cmml"><mi id="S3.SS2.p3.6.m2.1.2.2" xref="S3.SS2.p3.6.m2.1.2.2.cmml">π</mi><mo id="S3.SS2.p3.6.m2.1.2.1" xref="S3.SS2.p3.6.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.p3.6.m2.1.2.3.2" xref="S3.SS2.p3.6.m2.1.2.cmml"><mo id="S3.SS2.p3.6.m2.1.2.3.2.1" stretchy="false" xref="S3.SS2.p3.6.m2.1.2.cmml">(</mo><mo id="S3.SS2.p3.6.m2.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p3.6.m2.1.1.cmml">⋅</mo><mo id="S3.SS2.p3.6.m2.1.2.3.2.2" stretchy="false" xref="S3.SS2.p3.6.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m2.1b"><apply id="S3.SS2.p3.6.m2.1.2.cmml" xref="S3.SS2.p3.6.m2.1.2"><times id="S3.SS2.p3.6.m2.1.2.1.cmml" xref="S3.SS2.p3.6.m2.1.2.1"></times><ci id="S3.SS2.p3.6.m2.1.2.2.cmml" xref="S3.SS2.p3.6.m2.1.2.2">𝜋</ci><ci id="S3.SS2.p3.6.m2.1.1.cmml" xref="S3.SS2.p3.6.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m2.1c">\pi(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m2.1d">italic_π ( ⋅ )</annotation></semantics></math>, along with an element-wise product denoted by <math alttext="\circ" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m3.1"><semantics id="S3.SS2.p3.7.m3.1a"><mo id="S3.SS2.p3.7.m3.1.1" xref="S3.SS2.p3.7.m3.1.1.cmml">∘</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m3.1b"><compose id="S3.SS2.p3.7.m3.1.1.cmml" xref="S3.SS2.p3.7.m3.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m3.1c">\circ</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m3.1d">∘</annotation></semantics></math>, the 2D points in the image are computed based on the predicted pose and the intrinsic properties of the camera and 3D points. Subsequently, the differences between these computed 2D points and the ground truth 2D points are calculated. These differences are then multiplied by the predicted weights of the correspondences, denoted as <math alttext="f_{i}(y)" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m4.1"><semantics id="S3.SS2.p3.8.m4.1a"><mrow id="S3.SS2.p3.8.m4.1.2" xref="S3.SS2.p3.8.m4.1.2.cmml"><msub id="S3.SS2.p3.8.m4.1.2.2" xref="S3.SS2.p3.8.m4.1.2.2.cmml"><mi id="S3.SS2.p3.8.m4.1.2.2.2" xref="S3.SS2.p3.8.m4.1.2.2.2.cmml">f</mi><mi id="S3.SS2.p3.8.m4.1.2.2.3" xref="S3.SS2.p3.8.m4.1.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p3.8.m4.1.2.1" xref="S3.SS2.p3.8.m4.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.p3.8.m4.1.2.3.2" xref="S3.SS2.p3.8.m4.1.2.cmml"><mo id="S3.SS2.p3.8.m4.1.2.3.2.1" stretchy="false" xref="S3.SS2.p3.8.m4.1.2.cmml">(</mo><mi id="S3.SS2.p3.8.m4.1.1" xref="S3.SS2.p3.8.m4.1.1.cmml">y</mi><mo id="S3.SS2.p3.8.m4.1.2.3.2.2" stretchy="false" xref="S3.SS2.p3.8.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m4.1b"><apply id="S3.SS2.p3.8.m4.1.2.cmml" xref="S3.SS2.p3.8.m4.1.2"><times id="S3.SS2.p3.8.m4.1.2.1.cmml" xref="S3.SS2.p3.8.m4.1.2.1"></times><apply id="S3.SS2.p3.8.m4.1.2.2.cmml" xref="S3.SS2.p3.8.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m4.1.2.2.1.cmml" xref="S3.SS2.p3.8.m4.1.2.2">subscript</csymbol><ci id="S3.SS2.p3.8.m4.1.2.2.2.cmml" xref="S3.SS2.p3.8.m4.1.2.2.2">𝑓</ci><ci id="S3.SS2.p3.8.m4.1.2.2.3.cmml" xref="S3.SS2.p3.8.m4.1.2.2.3">𝑖</ci></apply><ci id="S3.SS2.p3.8.m4.1.1.cmml" xref="S3.SS2.p3.8.m4.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m4.1c">f_{i}(y)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m4.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y )</annotation></semantics></math>. Instead of solving only for a singular solution EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m5.1"><semantics id="S3.SS2.p3.9.m5.1a"><mi id="S3.SS2.p3.9.m5.1.1" xref="S3.SS2.p3.9.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m5.1b"><ci id="S3.SS2.p3.9.m5.1.1.cmml" xref="S3.SS2.p3.9.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m5.1d">italic_n</annotation></semantics></math>P suggests to model the prediction as a distribution, accommodating the fact that there are many non-distinguishable solutions of the non-linear least squares problem. Please refer to the base paper <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib23" title="">23</a>]</cite> for details on the inner workings of EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.10.m6.1"><semantics id="S3.SS2.p3.10.m6.1a"><mi id="S3.SS2.p3.10.m6.1.1" xref="S3.SS2.p3.10.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m6.1b"><ci id="S3.SS2.p3.10.m6.1.1.cmml" xref="S3.SS2.p3.10.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m6.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.10.m6.1d">italic_n</annotation></semantics></math>P.
Just like GDRNPP, EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.11.m7.1"><semantics id="S3.SS2.p3.11.m7.1a"><mi id="S3.SS2.p3.11.m7.1.1" xref="S3.SS2.p3.11.m7.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m7.1b"><ci id="S3.SS2.p3.11.m7.1.1.cmml" xref="S3.SS2.p3.11.m7.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m7.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.11.m7.1d">italic_n</annotation></semantics></math>P borrows heavily from the design of CDPN and only adds slight modifications to the outputs. Most importantly the translation head is, again, removed. EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p3.12.m8.1"><semantics id="S3.SS2.p3.12.m8.1a"><mi id="S3.SS2.p3.12.m8.1.1" xref="S3.SS2.p3.12.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m8.1b"><ci id="S3.SS2.p3.12.m8.1.1.cmml" xref="S3.SS2.p3.12.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m8.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.12.m8.1d">italic_n</annotation></semantics></math>P, just like GDRNPP, predicts 3D coordinate maps <math alttext="x^{3D}" class="ltx_Math" display="inline" id="S3.SS2.p3.13.m9.1"><semantics id="S3.SS2.p3.13.m9.1a"><msup id="S3.SS2.p3.13.m9.1.1" xref="S3.SS2.p3.13.m9.1.1.cmml"><mi id="S3.SS2.p3.13.m9.1.1.2" xref="S3.SS2.p3.13.m9.1.1.2.cmml">x</mi><mrow id="S3.SS2.p3.13.m9.1.1.3" xref="S3.SS2.p3.13.m9.1.1.3.cmml"><mn id="S3.SS2.p3.13.m9.1.1.3.2" xref="S3.SS2.p3.13.m9.1.1.3.2.cmml">3</mn><mo id="S3.SS2.p3.13.m9.1.1.3.1" xref="S3.SS2.p3.13.m9.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.13.m9.1.1.3.3" xref="S3.SS2.p3.13.m9.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m9.1b"><apply id="S3.SS2.p3.13.m9.1.1.cmml" xref="S3.SS2.p3.13.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m9.1.1.1.cmml" xref="S3.SS2.p3.13.m9.1.1">superscript</csymbol><ci id="S3.SS2.p3.13.m9.1.1.2.cmml" xref="S3.SS2.p3.13.m9.1.1.2">𝑥</ci><apply id="S3.SS2.p3.13.m9.1.1.3.cmml" xref="S3.SS2.p3.13.m9.1.1.3"><times id="S3.SS2.p3.13.m9.1.1.3.1.cmml" xref="S3.SS2.p3.13.m9.1.1.3.1"></times><cn id="S3.SS2.p3.13.m9.1.1.3.2.cmml" type="integer" xref="S3.SS2.p3.13.m9.1.1.3.2">3</cn><ci id="S3.SS2.p3.13.m9.1.1.3.3.cmml" xref="S3.SS2.p3.13.m9.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m9.1c">x^{3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.13.m9.1d">italic_x start_POSTSUPERSCRIPT 3 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>, and additional 2D XY weight maps <math alttext="w^{2D}" class="ltx_Math" display="inline" id="S3.SS2.p3.14.m10.1"><semantics id="S3.SS2.p3.14.m10.1a"><msup id="S3.SS2.p3.14.m10.1.1" xref="S3.SS2.p3.14.m10.1.1.cmml"><mi id="S3.SS2.p3.14.m10.1.1.2" xref="S3.SS2.p3.14.m10.1.1.2.cmml">w</mi><mrow id="S3.SS2.p3.14.m10.1.1.3" xref="S3.SS2.p3.14.m10.1.1.3.cmml"><mn id="S3.SS2.p3.14.m10.1.1.3.2" xref="S3.SS2.p3.14.m10.1.1.3.2.cmml">2</mn><mo id="S3.SS2.p3.14.m10.1.1.3.1" xref="S3.SS2.p3.14.m10.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.14.m10.1.1.3.3" xref="S3.SS2.p3.14.m10.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m10.1b"><apply id="S3.SS2.p3.14.m10.1.1.cmml" xref="S3.SS2.p3.14.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m10.1.1.1.cmml" xref="S3.SS2.p3.14.m10.1.1">superscript</csymbol><ci id="S3.SS2.p3.14.m10.1.1.2.cmml" xref="S3.SS2.p3.14.m10.1.1.2">𝑤</ci><apply id="S3.SS2.p3.14.m10.1.1.3.cmml" xref="S3.SS2.p3.14.m10.1.1.3"><times id="S3.SS2.p3.14.m10.1.1.3.1.cmml" xref="S3.SS2.p3.14.m10.1.1.3.1"></times><cn id="S3.SS2.p3.14.m10.1.1.3.2.cmml" type="integer" xref="S3.SS2.p3.14.m10.1.1.3.2">2</cn><ci id="S3.SS2.p3.14.m10.1.1.3.3.cmml" xref="S3.SS2.p3.14.m10.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m10.1c">w^{2D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.14.m10.1d">italic_w start_POSTSUPERSCRIPT 2 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>, taken from CDPN, but extending it with spatial Softmax and global scaling.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.20">Based on these two algorithms we develop our approach:
First, while EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">italic_n</annotation></semantics></math>P originally utilizes a ResNet-34 backbone, we instead decide to re-use GDRNPPs ConvNeXt, saving computation time by sharing the common feature representation among all 4 prediction heads. We predict all 3 features found in GDRNPP, visible and amodal object masks <math alttext="M_{vis}" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><msub id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2" xref="S3.SS2.p4.2.m2.1.1.3.2.cmml">v</mi><mo id="S3.SS2.p4.2.m2.1.1.3.1" xref="S3.SS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.cmml">i</mi><mo id="S3.SS2.p4.2.m2.1.1.3.1a" xref="S3.SS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.2.m2.1.1.3.4" xref="S3.SS2.p4.2.m2.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝑀</ci><apply id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><times id="S3.SS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3.1"></times><ci id="S3.SS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2">𝑣</ci><ci id="S3.SS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3">𝑖</ci><ci id="S3.SS2.p4.2.m2.1.1.3.4.cmml" xref="S3.SS2.p4.2.m2.1.1.3.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">M_{vis}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_M start_POSTSUBSCRIPT italic_v italic_i italic_s end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="M_{amodal}" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><msub id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml"><mi id="S3.SS2.p4.3.m3.1.1.3.2" xref="S3.SS2.p4.3.m3.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p4.3.m3.1.1.3.1" xref="S3.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.3.m3.1.1.3.3" xref="S3.SS2.p4.3.m3.1.1.3.3.cmml">m</mi><mo id="S3.SS2.p4.3.m3.1.1.3.1a" xref="S3.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.3.m3.1.1.3.4" xref="S3.SS2.p4.3.m3.1.1.3.4.cmml">o</mi><mo id="S3.SS2.p4.3.m3.1.1.3.1b" xref="S3.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.3.m3.1.1.3.5" xref="S3.SS2.p4.3.m3.1.1.3.5.cmml">d</mi><mo id="S3.SS2.p4.3.m3.1.1.3.1c" xref="S3.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.3.m3.1.1.3.6" xref="S3.SS2.p4.3.m3.1.1.3.6.cmml">a</mi><mo id="S3.SS2.p4.3.m3.1.1.3.1d" xref="S3.SS2.p4.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.3.m3.1.1.3.7" xref="S3.SS2.p4.3.m3.1.1.3.7.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">𝑀</ci><apply id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3"><times id="S3.SS2.p4.3.m3.1.1.3.1.cmml" xref="S3.SS2.p4.3.m3.1.1.3.1"></times><ci id="S3.SS2.p4.3.m3.1.1.3.2.cmml" xref="S3.SS2.p4.3.m3.1.1.3.2">𝑎</ci><ci id="S3.SS2.p4.3.m3.1.1.3.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3.3">𝑚</ci><ci id="S3.SS2.p4.3.m3.1.1.3.4.cmml" xref="S3.SS2.p4.3.m3.1.1.3.4">𝑜</ci><ci id="S3.SS2.p4.3.m3.1.1.3.5.cmml" xref="S3.SS2.p4.3.m3.1.1.3.5">𝑑</ci><ci id="S3.SS2.p4.3.m3.1.1.3.6.cmml" xref="S3.SS2.p4.3.m3.1.1.3.6">𝑎</ci><ci id="S3.SS2.p4.3.m3.1.1.3.7.cmml" xref="S3.SS2.p4.3.m3.1.1.3.7">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">M_{amodal}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_M start_POSTSUBSCRIPT italic_a italic_m italic_o italic_d italic_a italic_l end_POSTSUBSCRIPT</annotation></semantics></math>, 3D coordinate maps <math alttext="x^{3D}" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><msup id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml">x</mi><mrow id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml"><mn id="S3.SS2.p4.4.m4.1.1.3.2" xref="S3.SS2.p4.4.m4.1.1.3.2.cmml">3</mn><mo id="S3.SS2.p4.4.m4.1.1.3.1" xref="S3.SS2.p4.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.4.m4.1.1.3.3" xref="S3.SS2.p4.4.m4.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2">𝑥</ci><apply id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3"><times id="S3.SS2.p4.4.m4.1.1.3.1.cmml" xref="S3.SS2.p4.4.m4.1.1.3.1"></times><cn id="S3.SS2.p4.4.m4.1.1.3.2.cmml" type="integer" xref="S3.SS2.p4.4.m4.1.1.3.2">3</cn><ci id="S3.SS2.p4.4.m4.1.1.3.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">x^{3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">italic_x start_POSTSUPERSCRIPT 3 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> transformed into dense correspondence maps <math alttext="M_{2D-3D}" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m5.1"><semantics id="S3.SS2.p4.5.m5.1a"><msub id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml"><mrow id="S3.SS2.p4.5.m5.1.1.3.2" xref="S3.SS2.p4.5.m5.1.1.3.2.cmml"><mn id="S3.SS2.p4.5.m5.1.1.3.2.2" xref="S3.SS2.p4.5.m5.1.1.3.2.2.cmml">2</mn><mo id="S3.SS2.p4.5.m5.1.1.3.2.1" xref="S3.SS2.p4.5.m5.1.1.3.2.1.cmml">⁢</mo><mi id="S3.SS2.p4.5.m5.1.1.3.2.3" xref="S3.SS2.p4.5.m5.1.1.3.2.3.cmml">D</mi></mrow><mo id="S3.SS2.p4.5.m5.1.1.3.1" xref="S3.SS2.p4.5.m5.1.1.3.1.cmml">−</mo><mrow id="S3.SS2.p4.5.m5.1.1.3.3" xref="S3.SS2.p4.5.m5.1.1.3.3.cmml"><mn id="S3.SS2.p4.5.m5.1.1.3.3.2" xref="S3.SS2.p4.5.m5.1.1.3.3.2.cmml">3</mn><mo id="S3.SS2.p4.5.m5.1.1.3.3.1" xref="S3.SS2.p4.5.m5.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.5.m5.1.1.3.3.3" xref="S3.SS2.p4.5.m5.1.1.3.3.3.cmml">D</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2">𝑀</ci><apply id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3"><minus id="S3.SS2.p4.5.m5.1.1.3.1.cmml" xref="S3.SS2.p4.5.m5.1.1.3.1"></minus><apply id="S3.SS2.p4.5.m5.1.1.3.2.cmml" xref="S3.SS2.p4.5.m5.1.1.3.2"><times id="S3.SS2.p4.5.m5.1.1.3.2.1.cmml" xref="S3.SS2.p4.5.m5.1.1.3.2.1"></times><cn id="S3.SS2.p4.5.m5.1.1.3.2.2.cmml" type="integer" xref="S3.SS2.p4.5.m5.1.1.3.2.2">2</cn><ci id="S3.SS2.p4.5.m5.1.1.3.2.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3.2.3">𝐷</ci></apply><apply id="S3.SS2.p4.5.m5.1.1.3.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3"><times id="S3.SS2.p4.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3.1"></times><cn id="S3.SS2.p4.5.m5.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.p4.5.m5.1.1.3.3.2">3</cn><ci id="S3.SS2.p4.5.m5.1.1.3.3.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">M_{2D-3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m5.1d">italic_M start_POSTSUBSCRIPT 2 italic_D - 3 italic_D end_POSTSUBSCRIPT</annotation></semantics></math>, and surface region attention maps <math alttext="M_{SRA}" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m6.1"><semantics id="S3.SS2.p4.6.m6.1a"><msub id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mi id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml"><mi id="S3.SS2.p4.6.m6.1.1.3.2" xref="S3.SS2.p4.6.m6.1.1.3.2.cmml">S</mi><mo id="S3.SS2.p4.6.m6.1.1.3.1" xref="S3.SS2.p4.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.6.m6.1.1.3.3" xref="S3.SS2.p4.6.m6.1.1.3.3.cmml">R</mi><mo id="S3.SS2.p4.6.m6.1.1.3.1a" xref="S3.SS2.p4.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.6.m6.1.1.3.4" xref="S3.SS2.p4.6.m6.1.1.3.4.cmml">A</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2">𝑀</ci><apply id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3"><times id="S3.SS2.p4.6.m6.1.1.3.1.cmml" xref="S3.SS2.p4.6.m6.1.1.3.1"></times><ci id="S3.SS2.p4.6.m6.1.1.3.2.cmml" xref="S3.SS2.p4.6.m6.1.1.3.2">𝑆</ci><ci id="S3.SS2.p4.6.m6.1.1.3.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3.3">𝑅</ci><ci id="S3.SS2.p4.6.m6.1.1.3.4.cmml" xref="S3.SS2.p4.6.m6.1.1.3.4">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">M_{SRA}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m6.1d">italic_M start_POSTSUBSCRIPT italic_S italic_R italic_A end_POSTSUBSCRIPT</annotation></semantics></math> and additionally predict the 2D XY weights <math alttext="w^{2D}" class="ltx_Math" display="inline" id="S3.SS2.p4.7.m7.1"><semantics id="S3.SS2.p4.7.m7.1a"><msup id="S3.SS2.p4.7.m7.1.1" xref="S3.SS2.p4.7.m7.1.1.cmml"><mi id="S3.SS2.p4.7.m7.1.1.2" xref="S3.SS2.p4.7.m7.1.1.2.cmml">w</mi><mrow id="S3.SS2.p4.7.m7.1.1.3" xref="S3.SS2.p4.7.m7.1.1.3.cmml"><mn id="S3.SS2.p4.7.m7.1.1.3.2" xref="S3.SS2.p4.7.m7.1.1.3.2.cmml">2</mn><mo id="S3.SS2.p4.7.m7.1.1.3.1" xref="S3.SS2.p4.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.7.m7.1.1.3.3" xref="S3.SS2.p4.7.m7.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m7.1b"><apply id="S3.SS2.p4.7.m7.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p4.7.m7.1.1.2.cmml" xref="S3.SS2.p4.7.m7.1.1.2">𝑤</ci><apply id="S3.SS2.p4.7.m7.1.1.3.cmml" xref="S3.SS2.p4.7.m7.1.1.3"><times id="S3.SS2.p4.7.m7.1.1.3.1.cmml" xref="S3.SS2.p4.7.m7.1.1.3.1"></times><cn id="S3.SS2.p4.7.m7.1.1.3.2.cmml" type="integer" xref="S3.SS2.p4.7.m7.1.1.3.2">2</cn><ci id="S3.SS2.p4.7.m7.1.1.3.3.cmml" xref="S3.SS2.p4.7.m7.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m7.1c">w^{2D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.7.m7.1d">italic_w start_POSTSUPERSCRIPT 2 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> proposed by CDPN and modified by EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.8.m8.1"><semantics id="S3.SS2.p4.8.m8.1a"><mi id="S3.SS2.p4.8.m8.1.1" xref="S3.SS2.p4.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.8.m8.1b"><ci id="S3.SS2.p4.8.m8.1.1.cmml" xref="S3.SS2.p4.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.8.m8.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.8.m8.1d">italic_n</annotation></semantics></math>P.
Second, we find that EPRO-GDR benefits from good initialization and decide to split the training in 2 phases: We utilize the Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.9.m9.1"><semantics id="S3.SS2.p4.9.m9.1a"><mi id="S3.SS2.p4.9.m9.1.1" xref="S3.SS2.p4.9.m9.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.9.m9.1b"><ci id="S3.SS2.p4.9.m9.1.1.cmml" xref="S3.SS2.p4.9.m9.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.9.m9.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.9.m9.1d">italic_n</annotation></semantics></math>P solver and train till convergence, only predicting <math alttext="M_{vis}" class="ltx_Math" display="inline" id="S3.SS2.p4.10.m10.1"><semantics id="S3.SS2.p4.10.m10.1a"><msub id="S3.SS2.p4.10.m10.1.1" xref="S3.SS2.p4.10.m10.1.1.cmml"><mi id="S3.SS2.p4.10.m10.1.1.2" xref="S3.SS2.p4.10.m10.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.10.m10.1.1.3" xref="S3.SS2.p4.10.m10.1.1.3.cmml"><mi id="S3.SS2.p4.10.m10.1.1.3.2" xref="S3.SS2.p4.10.m10.1.1.3.2.cmml">v</mi><mo id="S3.SS2.p4.10.m10.1.1.3.1" xref="S3.SS2.p4.10.m10.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.10.m10.1.1.3.3" xref="S3.SS2.p4.10.m10.1.1.3.3.cmml">i</mi><mo id="S3.SS2.p4.10.m10.1.1.3.1a" xref="S3.SS2.p4.10.m10.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.10.m10.1.1.3.4" xref="S3.SS2.p4.10.m10.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.10.m10.1b"><apply id="S3.SS2.p4.10.m10.1.1.cmml" xref="S3.SS2.p4.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.10.m10.1.1.1.cmml" xref="S3.SS2.p4.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.p4.10.m10.1.1.2.cmml" xref="S3.SS2.p4.10.m10.1.1.2">𝑀</ci><apply id="S3.SS2.p4.10.m10.1.1.3.cmml" xref="S3.SS2.p4.10.m10.1.1.3"><times id="S3.SS2.p4.10.m10.1.1.3.1.cmml" xref="S3.SS2.p4.10.m10.1.1.3.1"></times><ci id="S3.SS2.p4.10.m10.1.1.3.2.cmml" xref="S3.SS2.p4.10.m10.1.1.3.2">𝑣</ci><ci id="S3.SS2.p4.10.m10.1.1.3.3.cmml" xref="S3.SS2.p4.10.m10.1.1.3.3">𝑖</ci><ci id="S3.SS2.p4.10.m10.1.1.3.4.cmml" xref="S3.SS2.p4.10.m10.1.1.3.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.10.m10.1c">M_{vis}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.10.m10.1d">italic_M start_POSTSUBSCRIPT italic_v italic_i italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="M_{amodal}" class="ltx_Math" display="inline" id="S3.SS2.p4.11.m11.1"><semantics id="S3.SS2.p4.11.m11.1a"><msub id="S3.SS2.p4.11.m11.1.1" xref="S3.SS2.p4.11.m11.1.1.cmml"><mi id="S3.SS2.p4.11.m11.1.1.2" xref="S3.SS2.p4.11.m11.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.11.m11.1.1.3" xref="S3.SS2.p4.11.m11.1.1.3.cmml"><mi id="S3.SS2.p4.11.m11.1.1.3.2" xref="S3.SS2.p4.11.m11.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p4.11.m11.1.1.3.1" xref="S3.SS2.p4.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.11.m11.1.1.3.3" xref="S3.SS2.p4.11.m11.1.1.3.3.cmml">m</mi><mo id="S3.SS2.p4.11.m11.1.1.3.1a" xref="S3.SS2.p4.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.11.m11.1.1.3.4" xref="S3.SS2.p4.11.m11.1.1.3.4.cmml">o</mi><mo id="S3.SS2.p4.11.m11.1.1.3.1b" xref="S3.SS2.p4.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.11.m11.1.1.3.5" xref="S3.SS2.p4.11.m11.1.1.3.5.cmml">d</mi><mo id="S3.SS2.p4.11.m11.1.1.3.1c" xref="S3.SS2.p4.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.11.m11.1.1.3.6" xref="S3.SS2.p4.11.m11.1.1.3.6.cmml">a</mi><mo id="S3.SS2.p4.11.m11.1.1.3.1d" xref="S3.SS2.p4.11.m11.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.11.m11.1.1.3.7" xref="S3.SS2.p4.11.m11.1.1.3.7.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.11.m11.1b"><apply id="S3.SS2.p4.11.m11.1.1.cmml" xref="S3.SS2.p4.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.11.m11.1.1.1.cmml" xref="S3.SS2.p4.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p4.11.m11.1.1.2.cmml" xref="S3.SS2.p4.11.m11.1.1.2">𝑀</ci><apply id="S3.SS2.p4.11.m11.1.1.3.cmml" xref="S3.SS2.p4.11.m11.1.1.3"><times id="S3.SS2.p4.11.m11.1.1.3.1.cmml" xref="S3.SS2.p4.11.m11.1.1.3.1"></times><ci id="S3.SS2.p4.11.m11.1.1.3.2.cmml" xref="S3.SS2.p4.11.m11.1.1.3.2">𝑎</ci><ci id="S3.SS2.p4.11.m11.1.1.3.3.cmml" xref="S3.SS2.p4.11.m11.1.1.3.3">𝑚</ci><ci id="S3.SS2.p4.11.m11.1.1.3.4.cmml" xref="S3.SS2.p4.11.m11.1.1.3.4">𝑜</ci><ci id="S3.SS2.p4.11.m11.1.1.3.5.cmml" xref="S3.SS2.p4.11.m11.1.1.3.5">𝑑</ci><ci id="S3.SS2.p4.11.m11.1.1.3.6.cmml" xref="S3.SS2.p4.11.m11.1.1.3.6">𝑎</ci><ci id="S3.SS2.p4.11.m11.1.1.3.7.cmml" xref="S3.SS2.p4.11.m11.1.1.3.7">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.11.m11.1c">M_{amodal}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.11.m11.1d">italic_M start_POSTSUBSCRIPT italic_a italic_m italic_o italic_d italic_a italic_l end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="x^{3D}" class="ltx_Math" display="inline" id="S3.SS2.p4.12.m12.1"><semantics id="S3.SS2.p4.12.m12.1a"><msup id="S3.SS2.p4.12.m12.1.1" xref="S3.SS2.p4.12.m12.1.1.cmml"><mi id="S3.SS2.p4.12.m12.1.1.2" xref="S3.SS2.p4.12.m12.1.1.2.cmml">x</mi><mrow id="S3.SS2.p4.12.m12.1.1.3" xref="S3.SS2.p4.12.m12.1.1.3.cmml"><mn id="S3.SS2.p4.12.m12.1.1.3.2" xref="S3.SS2.p4.12.m12.1.1.3.2.cmml">3</mn><mo id="S3.SS2.p4.12.m12.1.1.3.1" xref="S3.SS2.p4.12.m12.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.12.m12.1.1.3.3" xref="S3.SS2.p4.12.m12.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.12.m12.1b"><apply id="S3.SS2.p4.12.m12.1.1.cmml" xref="S3.SS2.p4.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.12.m12.1.1.1.cmml" xref="S3.SS2.p4.12.m12.1.1">superscript</csymbol><ci id="S3.SS2.p4.12.m12.1.1.2.cmml" xref="S3.SS2.p4.12.m12.1.1.2">𝑥</ci><apply id="S3.SS2.p4.12.m12.1.1.3.cmml" xref="S3.SS2.p4.12.m12.1.1.3"><times id="S3.SS2.p4.12.m12.1.1.3.1.cmml" xref="S3.SS2.p4.12.m12.1.1.3.1"></times><cn id="S3.SS2.p4.12.m12.1.1.3.2.cmml" type="integer" xref="S3.SS2.p4.12.m12.1.1.3.2">3</cn><ci id="S3.SS2.p4.12.m12.1.1.3.3.cmml" xref="S3.SS2.p4.12.m12.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.12.m12.1c">x^{3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.12.m12.1d">italic_x start_POSTSUPERSCRIPT 3 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>/<math alttext="M_{2D-3D}" class="ltx_Math" display="inline" id="S3.SS2.p4.13.m13.1"><semantics id="S3.SS2.p4.13.m13.1a"><msub id="S3.SS2.p4.13.m13.1.1" xref="S3.SS2.p4.13.m13.1.1.cmml"><mi id="S3.SS2.p4.13.m13.1.1.2" xref="S3.SS2.p4.13.m13.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.13.m13.1.1.3" xref="S3.SS2.p4.13.m13.1.1.3.cmml"><mrow id="S3.SS2.p4.13.m13.1.1.3.2" xref="S3.SS2.p4.13.m13.1.1.3.2.cmml"><mn id="S3.SS2.p4.13.m13.1.1.3.2.2" xref="S3.SS2.p4.13.m13.1.1.3.2.2.cmml">2</mn><mo id="S3.SS2.p4.13.m13.1.1.3.2.1" xref="S3.SS2.p4.13.m13.1.1.3.2.1.cmml">⁢</mo><mi id="S3.SS2.p4.13.m13.1.1.3.2.3" xref="S3.SS2.p4.13.m13.1.1.3.2.3.cmml">D</mi></mrow><mo id="S3.SS2.p4.13.m13.1.1.3.1" xref="S3.SS2.p4.13.m13.1.1.3.1.cmml">−</mo><mrow id="S3.SS2.p4.13.m13.1.1.3.3" xref="S3.SS2.p4.13.m13.1.1.3.3.cmml"><mn id="S3.SS2.p4.13.m13.1.1.3.3.2" xref="S3.SS2.p4.13.m13.1.1.3.3.2.cmml">3</mn><mo id="S3.SS2.p4.13.m13.1.1.3.3.1" xref="S3.SS2.p4.13.m13.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.13.m13.1.1.3.3.3" xref="S3.SS2.p4.13.m13.1.1.3.3.3.cmml">D</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.13.m13.1b"><apply id="S3.SS2.p4.13.m13.1.1.cmml" xref="S3.SS2.p4.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.13.m13.1.1.1.cmml" xref="S3.SS2.p4.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.p4.13.m13.1.1.2.cmml" xref="S3.SS2.p4.13.m13.1.1.2">𝑀</ci><apply id="S3.SS2.p4.13.m13.1.1.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3"><minus id="S3.SS2.p4.13.m13.1.1.3.1.cmml" xref="S3.SS2.p4.13.m13.1.1.3.1"></minus><apply id="S3.SS2.p4.13.m13.1.1.3.2.cmml" xref="S3.SS2.p4.13.m13.1.1.3.2"><times id="S3.SS2.p4.13.m13.1.1.3.2.1.cmml" xref="S3.SS2.p4.13.m13.1.1.3.2.1"></times><cn id="S3.SS2.p4.13.m13.1.1.3.2.2.cmml" type="integer" xref="S3.SS2.p4.13.m13.1.1.3.2.2">2</cn><ci id="S3.SS2.p4.13.m13.1.1.3.2.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3.2.3">𝐷</ci></apply><apply id="S3.SS2.p4.13.m13.1.1.3.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3"><times id="S3.SS2.p4.13.m13.1.1.3.3.1.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3.1"></times><cn id="S3.SS2.p4.13.m13.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.p4.13.m13.1.1.3.3.2">3</cn><ci id="S3.SS2.p4.13.m13.1.1.3.3.3.cmml" xref="S3.SS2.p4.13.m13.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.13.m13.1c">M_{2D-3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.13.m13.1d">italic_M start_POSTSUBSCRIPT 2 italic_D - 3 italic_D end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="M_{SRA}" class="ltx_Math" display="inline" id="S3.SS2.p4.14.m14.1"><semantics id="S3.SS2.p4.14.m14.1a"><msub id="S3.SS2.p4.14.m14.1.1" xref="S3.SS2.p4.14.m14.1.1.cmml"><mi id="S3.SS2.p4.14.m14.1.1.2" xref="S3.SS2.p4.14.m14.1.1.2.cmml">M</mi><mrow id="S3.SS2.p4.14.m14.1.1.3" xref="S3.SS2.p4.14.m14.1.1.3.cmml"><mi id="S3.SS2.p4.14.m14.1.1.3.2" xref="S3.SS2.p4.14.m14.1.1.3.2.cmml">S</mi><mo id="S3.SS2.p4.14.m14.1.1.3.1" xref="S3.SS2.p4.14.m14.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.14.m14.1.1.3.3" xref="S3.SS2.p4.14.m14.1.1.3.3.cmml">R</mi><mo id="S3.SS2.p4.14.m14.1.1.3.1a" xref="S3.SS2.p4.14.m14.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.14.m14.1.1.3.4" xref="S3.SS2.p4.14.m14.1.1.3.4.cmml">A</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.14.m14.1b"><apply id="S3.SS2.p4.14.m14.1.1.cmml" xref="S3.SS2.p4.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.14.m14.1.1.1.cmml" xref="S3.SS2.p4.14.m14.1.1">subscript</csymbol><ci id="S3.SS2.p4.14.m14.1.1.2.cmml" xref="S3.SS2.p4.14.m14.1.1.2">𝑀</ci><apply id="S3.SS2.p4.14.m14.1.1.3.cmml" xref="S3.SS2.p4.14.m14.1.1.3"><times id="S3.SS2.p4.14.m14.1.1.3.1.cmml" xref="S3.SS2.p4.14.m14.1.1.3.1"></times><ci id="S3.SS2.p4.14.m14.1.1.3.2.cmml" xref="S3.SS2.p4.14.m14.1.1.3.2">𝑆</ci><ci id="S3.SS2.p4.14.m14.1.1.3.3.cmml" xref="S3.SS2.p4.14.m14.1.1.3.3">𝑅</ci><ci id="S3.SS2.p4.14.m14.1.1.3.4.cmml" xref="S3.SS2.p4.14.m14.1.1.3.4">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.14.m14.1c">M_{SRA}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.14.m14.1d">italic_M start_POSTSUBSCRIPT italic_S italic_R italic_A end_POSTSUBSCRIPT</annotation></semantics></math>, as depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S2.F1" title="Figure 1 ‣ II-C Template Matching ‣ II Related Work ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a>. We then replace Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.15.m15.1"><semantics id="S3.SS2.p4.15.m15.1a"><mi id="S3.SS2.p4.15.m15.1.1" xref="S3.SS2.p4.15.m15.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.15.m15.1b"><ci id="S3.SS2.p4.15.m15.1.1.cmml" xref="S3.SS2.p4.15.m15.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.15.m15.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.15.m15.1d">italic_n</annotation></semantics></math>P with EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.16.m16.1"><semantics id="S3.SS2.p4.16.m16.1a"><mi id="S3.SS2.p4.16.m16.1.1" xref="S3.SS2.p4.16.m16.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.16.m16.1b"><ci id="S3.SS2.p4.16.m16.1.1.cmml" xref="S3.SS2.p4.16.m16.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.16.m16.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.16.m16.1d">italic_n</annotation></semantics></math>P and continue training, now only using 3D coordinate maps <math alttext="x^{3D}" class="ltx_Math" display="inline" id="S3.SS2.p4.17.m17.1"><semantics id="S3.SS2.p4.17.m17.1a"><msup id="S3.SS2.p4.17.m17.1.1" xref="S3.SS2.p4.17.m17.1.1.cmml"><mi id="S3.SS2.p4.17.m17.1.1.2" xref="S3.SS2.p4.17.m17.1.1.2.cmml">x</mi><mrow id="S3.SS2.p4.17.m17.1.1.3" xref="S3.SS2.p4.17.m17.1.1.3.cmml"><mn id="S3.SS2.p4.17.m17.1.1.3.2" xref="S3.SS2.p4.17.m17.1.1.3.2.cmml">3</mn><mo id="S3.SS2.p4.17.m17.1.1.3.1" xref="S3.SS2.p4.17.m17.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.17.m17.1.1.3.3" xref="S3.SS2.p4.17.m17.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.17.m17.1b"><apply id="S3.SS2.p4.17.m17.1.1.cmml" xref="S3.SS2.p4.17.m17.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.17.m17.1.1.1.cmml" xref="S3.SS2.p4.17.m17.1.1">superscript</csymbol><ci id="S3.SS2.p4.17.m17.1.1.2.cmml" xref="S3.SS2.p4.17.m17.1.1.2">𝑥</ci><apply id="S3.SS2.p4.17.m17.1.1.3.cmml" xref="S3.SS2.p4.17.m17.1.1.3"><times id="S3.SS2.p4.17.m17.1.1.3.1.cmml" xref="S3.SS2.p4.17.m17.1.1.3.1"></times><cn id="S3.SS2.p4.17.m17.1.1.3.2.cmml" type="integer" xref="S3.SS2.p4.17.m17.1.1.3.2">3</cn><ci id="S3.SS2.p4.17.m17.1.1.3.3.cmml" xref="S3.SS2.p4.17.m17.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.17.m17.1c">x^{3D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.17.m17.1d">italic_x start_POSTSUPERSCRIPT 3 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>, as well as our newly introduced head, predicting 2D weights <math alttext="w^{2D}" class="ltx_Math" display="inline" id="S3.SS2.p4.18.m18.1"><semantics id="S3.SS2.p4.18.m18.1a"><msup id="S3.SS2.p4.18.m18.1.1" xref="S3.SS2.p4.18.m18.1.1.cmml"><mi id="S3.SS2.p4.18.m18.1.1.2" xref="S3.SS2.p4.18.m18.1.1.2.cmml">w</mi><mrow id="S3.SS2.p4.18.m18.1.1.3" xref="S3.SS2.p4.18.m18.1.1.3.cmml"><mn id="S3.SS2.p4.18.m18.1.1.3.2" xref="S3.SS2.p4.18.m18.1.1.3.2.cmml">2</mn><mo id="S3.SS2.p4.18.m18.1.1.3.1" xref="S3.SS2.p4.18.m18.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p4.18.m18.1.1.3.3" xref="S3.SS2.p4.18.m18.1.1.3.3.cmml">D</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.18.m18.1b"><apply id="S3.SS2.p4.18.m18.1.1.cmml" xref="S3.SS2.p4.18.m18.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.18.m18.1.1.1.cmml" xref="S3.SS2.p4.18.m18.1.1">superscript</csymbol><ci id="S3.SS2.p4.18.m18.1.1.2.cmml" xref="S3.SS2.p4.18.m18.1.1.2">𝑤</ci><apply id="S3.SS2.p4.18.m18.1.1.3.cmml" xref="S3.SS2.p4.18.m18.1.1.3"><times id="S3.SS2.p4.18.m18.1.1.3.1.cmml" xref="S3.SS2.p4.18.m18.1.1.3.1"></times><cn id="S3.SS2.p4.18.m18.1.1.3.2.cmml" type="integer" xref="S3.SS2.p4.18.m18.1.1.3.2">2</cn><ci id="S3.SS2.p4.18.m18.1.1.3.3.cmml" xref="S3.SS2.p4.18.m18.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.18.m18.1c">w^{2D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.18.m18.1d">italic_w start_POSTSUPERSCRIPT 2 italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>.
Third, we modify the loss functions in phase 2: Most importantly, we add a new term from EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.19.m19.1"><semantics id="S3.SS2.p4.19.m19.1a"><mi id="S3.SS2.p4.19.m19.1.1" xref="S3.SS2.p4.19.m19.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.19.m19.1b"><ci id="S3.SS2.p4.19.m19.1.1.cmml" xref="S3.SS2.p4.19.m19.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.19.m19.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.19.m19.1d">italic_n</annotation></semantics></math>P, namely Kullback-Leibler loss (KL), measuring the divergence between predicted and target pose distributions. Since we do not require surface region attention for EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p4.20.m20.1"><semantics id="S3.SS2.p4.20.m20.1a"><mi id="S3.SS2.p4.20.m20.1.1" xref="S3.SS2.p4.20.m20.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.20.m20.1b"><ci id="S3.SS2.p4.20.m20.1.1.cmml" xref="S3.SS2.p4.20.m20.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.20.m20.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.20.m20.1d">italic_n</annotation></semantics></math>P, in phase 2 of our training, we reduce its weight from 1.0 in phase 1 to 0.005. In our experiments this made it behave like regularization, while not interfering with our newly introduced KL loss, which we weight with 0.2. Also, we activate the rotation loss term found in GDRNPP. They set it to 0.0 in their <a class="ltx_ref ltx_href" href="https://github.com/shanice-l/gdrnpp_bop2022/blob/8c6c34b1705008c6798f921dc5609f1e77f045e2/configs/_base_/gdrn_base.py#L138" title="">config file</a> and do not use it in their <a class="ltx_ref ltx_href" href="https://github.com/shanice-l/gdrnpp_bop2022/blob/8c6c34b1705008c6798f921dc5609f1e77f045e2/configs/gdrn/lmo_pbr/convnext_a6_AugCosyAAEGray_BG05_mlL1_DMask_amodalClipBox_classAware_lmo.py" title="">training config</a> . It is defined as</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L_{\text{rot.}}=\frac{1}{2}\left(1-\frac{\text{trace}(\text{m}_{1}\cdot\text{m%
}_{2}^{T})-1}{2}\right)" class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><msub id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml"><mi id="S3.E2.m1.2.2.3.2" xref="S3.E2.m1.2.2.3.2.cmml">L</mi><mtext id="S3.E2.m1.2.2.3.3" xref="S3.E2.m1.2.2.3.3a.cmml">rot.</mtext></msub><mo id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.cmml"><mfrac id="S3.E2.m1.2.2.1.3" xref="S3.E2.m1.2.2.1.3.cmml"><mn id="S3.E2.m1.2.2.1.3.2" xref="S3.E2.m1.2.2.1.3.2.cmml">1</mn><mn id="S3.E2.m1.2.2.1.3.3" xref="S3.E2.m1.2.2.1.3.3.cmml">2</mn></mfrac><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mo id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mn id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml">−</mo><mfrac id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mtext id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3a.cmml">trace</mtext><mo id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml"><mtext id="S3.E2.m1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2a.cmml">m</mtext><mn id="S3.E2.m1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">⋅</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml"><mtext id="S3.E2.m1.1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.2a.cmml">m</mtext><mn id="S3.E2.m1.1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.3.cmml">2</mn><mi id="S3.E2.m1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.cmml">T</mi></msubsup></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">−</mo><mn id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">1</mn></mrow><mn id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">2</mn></mfrac></mrow><mo id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"></eq><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.3">subscript</csymbol><ci id="S3.E2.m1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.3.2">𝐿</ci><ci id="S3.E2.m1.2.2.3.3a.cmml" xref="S3.E2.m1.2.2.3.3"><mtext id="S3.E2.m1.2.2.3.3.cmml" mathsize="70%" xref="S3.E2.m1.2.2.3.3">rot.</mtext></ci></apply><apply id="S3.E2.m1.2.2.1.cmml" xref="S3.E2.m1.2.2.1"><times id="S3.E2.m1.2.2.1.2.cmml" xref="S3.E2.m1.2.2.1.2"></times><apply id="S3.E2.m1.2.2.1.3.cmml" xref="S3.E2.m1.2.2.1.3"><divide id="S3.E2.m1.2.2.1.3.1.cmml" xref="S3.E2.m1.2.2.1.3"></divide><cn id="S3.E2.m1.2.2.1.3.2.cmml" type="integer" xref="S3.E2.m1.2.2.1.3.2">1</cn><cn id="S3.E2.m1.2.2.1.3.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.3.3">2</cn></apply><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"></minus><cn id="S3.E2.m1.2.2.1.1.1.1.2.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.1.2">1</cn><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><divide id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1"></divide><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><minus id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></minus><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.3"><mtext id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3">trace</mtext></ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">⋅</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.2a.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2"><mtext id="S3.E2.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2">m</mtext></ci><cn id="S3.E2.m1.1.1.1.1.1.1.1.2.3.cmml" type="integer" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3">1</cn></apply><apply id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.2.2a.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.2"><mtext id="S3.E2.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.2">m</mtext></ci><cn id="S3.E2.m1.1.1.1.1.1.1.1.3.2.3.cmml" type="integer" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.3">2</cn></apply><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3">𝑇</ci></apply></apply></apply><cn id="S3.E2.m1.1.1.1.3.cmml" type="integer" xref="S3.E2.m1.1.1.1.3">1</cn></apply><cn id="S3.E2.m1.1.1.3.cmml" type="integer" xref="S3.E2.m1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">L_{\text{rot.}}=\frac{1}{2}\left(1-\frac{\text{trace}(\text{m}_{1}\cdot\text{m%
}_{2}^{T})-1}{2}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_L start_POSTSUBSCRIPT rot. end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( 1 - divide start_ARG trace ( m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⋅ m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) - 1 end_ARG start_ARG 2 end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.24">with <math alttext="m_{1}" class="ltx_Math" display="inline" id="S3.SS2.p4.21.m1.1"><semantics id="S3.SS2.p4.21.m1.1a"><msub id="S3.SS2.p4.21.m1.1.1" xref="S3.SS2.p4.21.m1.1.1.cmml"><mi id="S3.SS2.p4.21.m1.1.1.2" xref="S3.SS2.p4.21.m1.1.1.2.cmml">m</mi><mn id="S3.SS2.p4.21.m1.1.1.3" xref="S3.SS2.p4.21.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.21.m1.1b"><apply id="S3.SS2.p4.21.m1.1.1.cmml" xref="S3.SS2.p4.21.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.21.m1.1.1.1.cmml" xref="S3.SS2.p4.21.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.21.m1.1.1.2.cmml" xref="S3.SS2.p4.21.m1.1.1.2">𝑚</ci><cn id="S3.SS2.p4.21.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p4.21.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.21.m1.1c">m_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.21.m1.1d">italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="m_{2}" class="ltx_Math" display="inline" id="S3.SS2.p4.22.m2.1"><semantics id="S3.SS2.p4.22.m2.1a"><msub id="S3.SS2.p4.22.m2.1.1" xref="S3.SS2.p4.22.m2.1.1.cmml"><mi id="S3.SS2.p4.22.m2.1.1.2" xref="S3.SS2.p4.22.m2.1.1.2.cmml">m</mi><mn id="S3.SS2.p4.22.m2.1.1.3" xref="S3.SS2.p4.22.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.22.m2.1b"><apply id="S3.SS2.p4.22.m2.1.1.cmml" xref="S3.SS2.p4.22.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.22.m2.1.1.1.cmml" xref="S3.SS2.p4.22.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.22.m2.1.1.2.cmml" xref="S3.SS2.p4.22.m2.1.1.2">𝑚</ci><cn id="S3.SS2.p4.22.m2.1.1.3.cmml" type="integer" xref="S3.SS2.p4.22.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.22.m2.1c">m_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.22.m2.1d">italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> being rotation matrices and <math alttext="m_{2}^{T}" class="ltx_Math" display="inline" id="S3.SS2.p4.23.m3.1"><semantics id="S3.SS2.p4.23.m3.1a"><msubsup id="S3.SS2.p4.23.m3.1.1" xref="S3.SS2.p4.23.m3.1.1.cmml"><mi id="S3.SS2.p4.23.m3.1.1.2.2" xref="S3.SS2.p4.23.m3.1.1.2.2.cmml">m</mi><mn id="S3.SS2.p4.23.m3.1.1.2.3" xref="S3.SS2.p4.23.m3.1.1.2.3.cmml">2</mn><mi id="S3.SS2.p4.23.m3.1.1.3" xref="S3.SS2.p4.23.m3.1.1.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.23.m3.1b"><apply id="S3.SS2.p4.23.m3.1.1.cmml" xref="S3.SS2.p4.23.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.23.m3.1.1.1.cmml" xref="S3.SS2.p4.23.m3.1.1">superscript</csymbol><apply id="S3.SS2.p4.23.m3.1.1.2.cmml" xref="S3.SS2.p4.23.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.23.m3.1.1.2.1.cmml" xref="S3.SS2.p4.23.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.23.m3.1.1.2.2.cmml" xref="S3.SS2.p4.23.m3.1.1.2.2">𝑚</ci><cn id="S3.SS2.p4.23.m3.1.1.2.3.cmml" type="integer" xref="S3.SS2.p4.23.m3.1.1.2.3">2</cn></apply><ci id="S3.SS2.p4.23.m3.1.1.3.cmml" xref="S3.SS2.p4.23.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.23.m3.1c">m_{2}^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.23.m3.1d">italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math> the transpose of <math alttext="m_{2}" class="ltx_Math" display="inline" id="S3.SS2.p4.24.m4.1"><semantics id="S3.SS2.p4.24.m4.1a"><msub id="S3.SS2.p4.24.m4.1.1" xref="S3.SS2.p4.24.m4.1.1.cmml"><mi id="S3.SS2.p4.24.m4.1.1.2" xref="S3.SS2.p4.24.m4.1.1.2.cmml">m</mi><mn id="S3.SS2.p4.24.m4.1.1.3" xref="S3.SS2.p4.24.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.24.m4.1b"><apply id="S3.SS2.p4.24.m4.1.1.cmml" xref="S3.SS2.p4.24.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.24.m4.1.1.1.cmml" xref="S3.SS2.p4.24.m4.1.1">subscript</csymbol><ci id="S3.SS2.p4.24.m4.1.1.2.cmml" xref="S3.SS2.p4.24.m4.1.1.2">𝑚</ci><cn id="S3.SS2.p4.24.m4.1.1.3.cmml" type="integer" xref="S3.SS2.p4.24.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.24.m4.1c">m_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.24.m4.1d">italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>. The equation calculates the angular distance between the predicted and the ground truth rotation, that is, the smallest angle required to align both rotations. We found angular distance loss helpful and set its weight to 1.0. Following this training regimen we achieve the performance as presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4" title="IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">IV</span></a>. Training details are to be found in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S3.SS3" title="III-C Training Details ‣ III Proposed Method ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>. 
<br class="ltx_break"/>At inference, we can predict a pose distribution given only an RGB image. We start by filtering low confidence 2D-3D correspondences to compute the initial pose before refining the pose relying on Levenberg-Marquardt algorithm to converge to our final best pose estimate. If available, we use the additional channel of an RGB-D input to refine our translation vector further using depth refinement, following the methodology of GDRNPP.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Training Details</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.4">We train one model per dataset and only use BlenderProc-generated <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib38" title="">38</a>]</cite> PBR images as provided by the BOP challenge. As mentioned above, the training consists of two phases: In phase 1 we rely on Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_n</annotation></semantics></math>P to solve for our target pose and rely on the default parameterization of GDRNPP as used in the BOP challenge, while in phase 2 we replace Patch-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_n</annotation></semantics></math>P with EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_n</annotation></semantics></math>P and continue training using our modified loss function. We base our code on GDRNPP and use all of its augmentation such as strong randomization and dynamic zoom-in on the object crops (also used by CDPN and EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_n</annotation></semantics></math>P). For phase 2 we increase the batch size from 48 to 72, do 400 iterations warm-up to gently introduce the modified loss function and re-weighted loss terms, then keep the learning rate stable before ending the training with cosine annealing. As proposed with GDRNPP we rely on the Ranger optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib39" title="">39</a>]</cite> and choose a learning rate of 0.0008. Weight decay is set to 0.01 and we train for 40 epochs, using early stopping based on our disjoint validation set.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Evaluation</span>
</h2>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Single-View Results on LM-O, YCB-V, ITODD, and T-LESS. Each algorithm is trained per dataset (single model, multiple objects). <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.T2.2.m1.1"><semantics id="S4.T2.2.m1.1b"><mrow id="S4.T2.2.m1.1.1" xref="S4.T2.2.m1.1.1.cmml"><mi id="S4.T2.2.m1.1.1.2" xref="S4.T2.2.m1.1.1.2.cmml">A</mi><mo id="S4.T2.2.m1.1.1.1" xref="S4.T2.2.m1.1.1.1.cmml">⁢</mo><msub id="S4.T2.2.m1.1.1.3" xref="S4.T2.2.m1.1.1.3.cmml"><mi id="S4.T2.2.m1.1.1.3.2" xref="S4.T2.2.m1.1.1.3.2.cmml">R</mi><mrow id="S4.T2.2.m1.1.1.3.3" xref="S4.T2.2.m1.1.1.3.3.cmml"><mi id="S4.T2.2.m1.1.1.3.3.2" xref="S4.T2.2.m1.1.1.3.3.2.cmml">B</mi><mo id="S4.T2.2.m1.1.1.3.3.1" xref="S4.T2.2.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.T2.2.m1.1.1.3.3.3" xref="S4.T2.2.m1.1.1.3.3.3.cmml">O</mi><mo id="S4.T2.2.m1.1.1.3.3.1b" xref="S4.T2.2.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.T2.2.m1.1.1.3.3.4" xref="S4.T2.2.m1.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.m1.1c"><apply id="S4.T2.2.m1.1.1.cmml" xref="S4.T2.2.m1.1.1"><times id="S4.T2.2.m1.1.1.1.cmml" xref="S4.T2.2.m1.1.1.1"></times><ci id="S4.T2.2.m1.1.1.2.cmml" xref="S4.T2.2.m1.1.1.2">𝐴</ci><apply id="S4.T2.2.m1.1.1.3.cmml" xref="S4.T2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T2.2.m1.1.1.3.1.cmml" xref="S4.T2.2.m1.1.1.3">subscript</csymbol><ci id="S4.T2.2.m1.1.1.3.2.cmml" xref="S4.T2.2.m1.1.1.3.2">𝑅</ci><apply id="S4.T2.2.m1.1.1.3.3.cmml" xref="S4.T2.2.m1.1.1.3.3"><times id="S4.T2.2.m1.1.1.3.3.1.cmml" xref="S4.T2.2.m1.1.1.3.3.1"></times><ci id="S4.T2.2.m1.1.1.3.3.2.cmml" xref="S4.T2.2.m1.1.1.3.3.2">𝐵</ci><ci id="S4.T2.2.m1.1.1.3.3.3.cmml" xref="S4.T2.2.m1.1.1.3.3.3">𝑂</ci><ci id="S4.T2.2.m1.1.1.3.3.4.cmml" xref="S4.T2.2.m1.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.m1.1d">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.m1.1e">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> metric following the official BOP approach, higher is better. The best result between GDRNPP and EPRO-GDR in <span class="ltx_text ltx_font_bold" id="S4.T2.9.1">bold font</span>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.10.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T2.10.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="4" id="S4.T2.10.1.1.2"><span class="ltx_text" id="S4.T2.10.1.1.2.1" style="font-size:90%;">LM-O</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="4" id="S4.T2.10.1.1.3"><span class="ltx_text" id="S4.T2.10.1.1.3.1" style="font-size:90%;">YCB-V</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="4" id="S4.T2.10.1.1.4"><span class="ltx_text" id="S4.T2.10.1.1.4.1" style="font-size:90%;">ITODD</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="4" id="S4.T2.10.1.1.5"><span class="ltx_text" id="S4.T2.10.1.1.5.1" style="font-size:90%;">T-LESS</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.10.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T2.10.2.2.1"></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.2.1">
<span class="ltx_p" id="S4.T2.10.2.2.2.1.1"><span class="ltx_text" id="S4.T2.10.2.2.2.1.1.1" style="font-size:90%;">MSPD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.3.1">
<span class="ltx_p" id="S4.T2.10.2.2.3.1.1"><span class="ltx_text" id="S4.T2.10.2.2.3.1.1.1" style="font-size:90%;">MSSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.4.1">
<span class="ltx_p" id="S4.T2.10.2.2.4.1.1"><span class="ltx_text" id="S4.T2.10.2.2.4.1.1.1" style="font-size:90%;">VSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r" id="S4.T2.10.2.2.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.5.1">
<span class="ltx_p" id="S4.T2.10.2.2.5.1.1"><span class="ltx_text" id="S4.T2.10.2.2.5.1.1.1" style="font-size:90%;">Mean</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.6.1">
<span class="ltx_p" id="S4.T2.10.2.2.6.1.1"><span class="ltx_text" id="S4.T2.10.2.2.6.1.1.1" style="font-size:90%;">MSPD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.7.1">
<span class="ltx_p" id="S4.T2.10.2.2.7.1.1"><span class="ltx_text" id="S4.T2.10.2.2.7.1.1.1" style="font-size:90%;">MSSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.8.1">
<span class="ltx_p" id="S4.T2.10.2.2.8.1.1"><span class="ltx_text" id="S4.T2.10.2.2.8.1.1.1" style="font-size:90%;">VSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r" id="S4.T2.10.2.2.9">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.9.1">
<span class="ltx_p" id="S4.T2.10.2.2.9.1.1"><span class="ltx_text" id="S4.T2.10.2.2.9.1.1.1" style="font-size:90%;">Mean</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.10">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.10.1">
<span class="ltx_p" id="S4.T2.10.2.2.10.1.1"><span class="ltx_text" id="S4.T2.10.2.2.10.1.1.1" style="font-size:90%;">MSPD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.11">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.11.1">
<span class="ltx_p" id="S4.T2.10.2.2.11.1.1"><span class="ltx_text" id="S4.T2.10.2.2.11.1.1.1" style="font-size:90%;">MSSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.12">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.12.1">
<span class="ltx_p" id="S4.T2.10.2.2.12.1.1"><span class="ltx_text" id="S4.T2.10.2.2.12.1.1.1" style="font-size:90%;">VSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r" id="S4.T2.10.2.2.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.13.1">
<span class="ltx_p" id="S4.T2.10.2.2.13.1.1"><span class="ltx_text" id="S4.T2.10.2.2.13.1.1.1" style="font-size:90%;">Mean</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.14">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.14.1">
<span class="ltx_p" id="S4.T2.10.2.2.14.1.1"><span class="ltx_text" id="S4.T2.10.2.2.14.1.1.1" style="font-size:90%;">MSPD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.15">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.15.1">
<span class="ltx_p" id="S4.T2.10.2.2.15.1.1"><span class="ltx_text" id="S4.T2.10.2.2.15.1.1.1" style="font-size:90%;">MSSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.16">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.16.1">
<span class="ltx_p" id="S4.T2.10.2.2.16.1.1"><span class="ltx_text" id="S4.T2.10.2.2.16.1.1.1" style="font-size:90%;">VSD</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column" id="S4.T2.10.2.2.17">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.2.2.17.1">
<span class="ltx_p" id="S4.T2.10.2.2.17.1.1"><span class="ltx_text" id="S4.T2.10.2.2.17.1.1.1" style="font-size:90%;">Mean</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.10.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.10.3.1.1">
<span class="ltx_text" id="S4.T2.10.3.1.1.1" style="font-size:90%;">SurfEmb </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.10.3.1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib40" title="">40</a><span class="ltx_text" id="S4.T2.10.3.1.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.2.1">
<span class="ltx_p" id="S4.T2.10.3.1.2.1.1"><span class="ltx_text" id="S4.T2.10.3.1.2.1.1.1" style="font-size:90%;">0.856</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.3.1">
<span class="ltx_p" id="S4.T2.10.3.1.3.1.1"><span class="ltx_text" id="S4.T2.10.3.1.3.1.1.1" style="font-size:90%;">0.809</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.4.1">
<span class="ltx_p" id="S4.T2.10.3.1.4.1.1"><span class="ltx_text" id="S4.T2.10.3.1.4.1.1.1" style="font-size:90%;">0.615</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S4.T2.10.3.1.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.5.1">
<span class="ltx_p" id="S4.T2.10.3.1.5.1.1"><span class="ltx_text" id="S4.T2.10.3.1.5.1.1.1" style="font-size:90%;">0.760</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.6.1">
<span class="ltx_p" id="S4.T2.10.3.1.6.1.1"><span class="ltx_text" id="S4.T2.10.3.1.6.1.1.1" style="font-size:90%;">0.792</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.7.1">
<span class="ltx_p" id="S4.T2.10.3.1.7.1.1"><span class="ltx_text" id="S4.T2.10.3.1.7.1.1.1" style="font-size:90%;">0.849</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.8.1">
<span class="ltx_p" id="S4.T2.10.3.1.8.1.1"><span class="ltx_text" id="S4.T2.10.3.1.8.1.1.1" style="font-size:90%;">0.757</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S4.T2.10.3.1.9">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.9.1">
<span class="ltx_p" id="S4.T2.10.3.1.9.1.1"><span class="ltx_text" id="S4.T2.10.3.1.9.1.1.1" style="font-size:90%;">0.757</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.10">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.10.1">
<span class="ltx_p" id="S4.T2.10.3.1.10.1.1"><span class="ltx_text" id="S4.T2.10.3.1.10.1.1.1" style="font-size:90%;">0.560</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.11">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.11.1">
<span class="ltx_p" id="S4.T2.10.3.1.11.1.1"><span class="ltx_text" id="S4.T2.10.3.1.11.1.1.1" style="font-size:90%;">0.558</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.12">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.12.1">
<span class="ltx_p" id="S4.T2.10.3.1.12.1.1"><span class="ltx_text" id="S4.T2.10.3.1.12.1.1.1" style="font-size:90%;">0.497</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S4.T2.10.3.1.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.13.1">
<span class="ltx_p" id="S4.T2.10.3.1.13.1.1"><span class="ltx_text" id="S4.T2.10.3.1.13.1.1.1" style="font-size:90%;">0.538</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.14">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.14.1">
<span class="ltx_p" id="S4.T2.10.3.1.14.1.1"><span class="ltx_text" id="S4.T2.10.3.1.14.1.1.1" style="font-size:90%;">0.859</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.15">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.15.1">
<span class="ltx_p" id="S4.T2.10.3.1.15.1.1"><span class="ltx_text" id="S4.T2.10.3.1.15.1.1.1" style="font-size:90%;">0.829</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.16">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.16.1">
<span class="ltx_p" id="S4.T2.10.3.1.16.1.1"><span class="ltx_text" id="S4.T2.10.3.1.16.1.1.1" style="font-size:90%;">0.797</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.10.3.1.17">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.3.1.17.1">
<span class="ltx_p" id="S4.T2.10.3.1.17.1.1"><span class="ltx_text" id="S4.T2.10.3.1.17.1.1.1" style="font-size:90%;">0.828</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.4.2.1">
<span class="ltx_text" id="S4.T2.10.4.2.1.1" style="font-size:90%;">PFA </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.10.4.2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib28" title="">28</a><span class="ltx_text" id="S4.T2.10.4.2.1.3.2" style="font-size:90%;">]</span></cite>
</th>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.2.1">
<span class="ltx_p" id="S4.T2.10.4.2.2.1.1"><span class="ltx_text" id="S4.T2.10.4.2.2.1.1.1" style="font-size:90%;">0.890</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.3.1">
<span class="ltx_p" id="S4.T2.10.4.2.3.1.1"><span class="ltx_text" id="S4.T2.10.4.2.3.1.1.1" style="font-size:90%;">0.843</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.4.1">
<span class="ltx_p" id="S4.T2.10.4.2.4.1.1"><span class="ltx_text" id="S4.T2.10.4.2.4.1.1.1" style="font-size:90%;">0.658</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.4.2.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.5.1">
<span class="ltx_p" id="S4.T2.10.4.2.5.1.1"><span class="ltx_text" id="S4.T2.10.4.2.5.1.1.1" style="font-size:90%;">0.797</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.6.1">
<span class="ltx_p" id="S4.T2.10.4.2.6.1.1"><span class="ltx_text" id="S4.T2.10.4.2.6.1.1.1" style="font-size:90%;">0.881</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.7.1">
<span class="ltx_p" id="S4.T2.10.4.2.7.1.1"><span class="ltx_text" id="S4.T2.10.4.2.7.1.1.1" style="font-size:90%;">0.920</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.8.1">
<span class="ltx_p" id="S4.T2.10.4.2.8.1.1"><span class="ltx_text" id="S4.T2.10.4.2.8.1.1.1" style="font-size:90%;">0.863</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.4.2.9">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.9.1">
<span class="ltx_p" id="S4.T2.10.4.2.9.1.1"><span class="ltx_text" id="S4.T2.10.4.2.9.1.1.1" style="font-size:90%;">0.888</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.10">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.10.1">
<span class="ltx_p" id="S4.T2.10.4.2.10.1.1"><span class="ltx_text" id="S4.T2.10.4.2.10.1.1.1" style="font-size:90%;">0.498</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.11">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.11.1">
<span class="ltx_p" id="S4.T2.10.4.2.11.1.1"><span class="ltx_text" id="S4.T2.10.4.2.11.1.1.1" style="font-size:90%;">0.495</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.12">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.12.1">
<span class="ltx_p" id="S4.T2.10.4.2.12.1.1"><span class="ltx_text" id="S4.T2.10.4.2.12.1.1.1" style="font-size:90%;">0.413</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.4.2.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.13.1">
<span class="ltx_p" id="S4.T2.10.4.2.13.1.1"><span class="ltx_text" id="S4.T2.10.4.2.13.1.1.1" style="font-size:90%;">0.469</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.14">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.14.1">
<span class="ltx_p" id="S4.T2.10.4.2.14.1.1"><span class="ltx_text" id="S4.T2.10.4.2.14.1.1.1" style="font-size:90%;">0.825</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.15">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.15.1">
<span class="ltx_p" id="S4.T2.10.4.2.15.1.1"><span class="ltx_text" id="S4.T2.10.4.2.15.1.1.1" style="font-size:90%;">0.795</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.16">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.16.1">
<span class="ltx_p" id="S4.T2.10.4.2.16.1.1"><span class="ltx_text" id="S4.T2.10.4.2.16.1.1.1" style="font-size:90%;">0.718</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.4.2.17">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.4.2.17.1">
<span class="ltx_p" id="S4.T2.10.4.2.17.1.1"><span class="ltx_text" id="S4.T2.10.4.2.17.1.1.1" style="font-size:90%;">0.779</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.5.3" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.5.3.1"><span class="ltx_text" id="S4.T2.10.5.3.1.1" style="font-size:90%;background-color:#E6E6E6;">GDRNPP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib41" title="">41</a>]</cite></span></th>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.2.1.1"><span class="ltx_text" id="S4.T2.10.5.3.2.1.1.1" style="font-size:90%;">0.849</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.3.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.3.1.1"><span class="ltx_text" id="S4.T2.10.5.3.3.1.1.1" style="font-size:90%;">0.803</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.4.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.4.1.1"><span class="ltx_text" id="S4.T2.10.5.3.4.1.1.1" style="font-size:90%;">0.619</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.5.3.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.5.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.5.1.1"><span class="ltx_text" id="S4.T2.10.5.3.5.1.1.1" style="font-size:90%;">0.757</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.6.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.6.1.1"><span class="ltx_text" id="S4.T2.10.5.3.6.1.1.1" style="font-size:90%;">0.814</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.7.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.7.1.1"><span class="ltx_text" id="S4.T2.10.5.3.7.1.1.1" style="font-size:90%;">0.876</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.8.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.8.1.1"><span class="ltx_text" id="S4.T2.10.5.3.8.1.1.1" style="font-size:90%;">0.761</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.5.3.9">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.9.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.9.1.1"><span class="ltx_text" id="S4.T2.10.5.3.9.1.1.1" style="font-size:90%;">0.817</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.10">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.10.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.10.1.1"><span class="ltx_text" id="S4.T2.10.5.3.10.1.1.1" style="font-size:90%;">0.370</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.11">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.11.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.11.1.1"><span class="ltx_text" id="S4.T2.10.5.3.11.1.1.1" style="font-size:90%;">0.397</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.12">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.12.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.12.1.1"><span class="ltx_text" id="S4.T2.10.5.3.12.1.1.1" style="font-size:90%;">0.302</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.5.3.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.13.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.13.1.1"><span class="ltx_text" id="S4.T2.10.5.3.13.1.1.1" style="font-size:90%;">0.356</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.14">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.14.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.14.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.5.3.14.1.1.1" style="font-size:90%;">0.903</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.15">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.15.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.15.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.5.3.15.1.1.1" style="font-size:90%;">0.871</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.16">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.16.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.16.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.5.3.16.1.1.1" style="font-size:90%;">0.793</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.5.3.17">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.5.3.17.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.5.3.17.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.5.3.17.1.1.1" style="font-size:90%;">0.856</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.6.4" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.6.4.1"><span class="ltx_text" id="S4.T2.10.6.4.1.1" style="font-size:90%;background-color:#E6E6E6;">EPRO-GDR (Ours)</span></th>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.2.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.2.1.1.1" style="font-size:90%;">0.879</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.3.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.3.1.1.1" style="font-size:90%;">0.835</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.4">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.4.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.4.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.4.1.1.1" style="font-size:90%;">0.645</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.6.4.5">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.5.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.5.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.5.1.1.1" style="font-size:90%;">0.786</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.6">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.6.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.6.1.1.1" style="font-size:90%;">0.832</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.7">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.7.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.7.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.7.1.1.1" style="font-size:90%;">0.894</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.8">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.8.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.8.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.8.1.1.1" style="font-size:90%;">0.807</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.6.4.9">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.9.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.9.1.1.1" style="font-size:90%;">0.844</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.10">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.10.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.10.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.10.1.1.1" style="font-size:90%;">0.447</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.11">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.11.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.11.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.11.1.1.1" style="font-size:90%;">0.433</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.12">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.12.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.12.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.12.1.1.1" style="font-size:90%;">0.358</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S4.T2.10.6.4.13">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.13.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.13.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.6.4.13.1.1.1" style="font-size:90%;">0.412</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.14">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.14.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.14.1.1"><span class="ltx_text" id="S4.T2.10.6.4.14.1.1.1" style="font-size:90%;">0.811</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.15">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.15.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.15.1.1"><span class="ltx_text" id="S4.T2.10.6.4.15.1.1.1" style="font-size:90%;">0.769</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.16">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.16.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.16.1.1"><span class="ltx_text" id="S4.T2.10.6.4.16.1.1.1" style="font-size:90%;">0.715</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S4.T2.10.6.4.17">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.10.6.4.17.1" style="background-color:#E6E6E6;">
<span class="ltx_p" id="S4.T2.10.6.4.17.1.1"><span class="ltx_text" id="S4.T2.10.6.4.17.1.1.1" style="font-size:90%;">0.765</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">For our quantitative analysis, the standardized tasks and tests in the BOP challenge allow for a fair comparison with the wide landscape of pose estimation algorithms and we comply with their evaluation methods using the BOP toolkit. In addition to our base algorithm GDRNPP and for comparison with pose estimators following different paradigms, we utilize two additional algorithms, probability-based SurfEmb <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib14" title="">14</a>]</cite> and template-based PFA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib27" title="">27</a>]</cite> as comparison. Both perform at the top of the class in their respective paradigm as shown in the BOP leaderboard. We evaluate on a representative subset of the 7 BOP core datasets, namely LM-O <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib42" title="">42</a>]</cite>, YCB-V <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib6" title="">6</a>]</cite>, T-Less <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib43" title="">43</a>]</cite>, and ITODD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib44" title="">44</a>]</cite>. LM-O presents 8 objects under heavy occlusion, placed in cluttered scenes and varying lighting conditions. Among the objects are some with very little texture. YCB-Video has 21 household and food items, such as cracker boxes, and cans and is mostly strongly textured. ITODD has gray scale recordings featuring 28 real-world objects found in industrial use cases including objects with metallic surfaces. Finally, T-Less comprises 30 objects found in the context of electric installations. The real-world objects have little texture and the test images feature heavy occlusions, a high number of object instances per image, and varying lighting conditions. We report results per dataset in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.T2" title="TABLE II ‣ IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">II</span></a> showing the 3 metrics used in the BOP challenge, maximum symmetry-aware projection distance (MSPD), maximum symmetry-aware surface distance (MSSD), and visible surface discrepancy (VSD). VSD quantifies the difference between the visible surfaces of two 3D objects, while MSSD measures the maximum distance between corresponding points on surfaces, taking into account the inherent symmetry of the models. MSPD calculates the maximum distance between corresponding points using the projection, measuring the perceivable deviation. A pose is considered correct if the deviation according to the metric falls below a given threshold. The overall score in the BOP challenge is defined as the average of these 3 metrics. In addition, we report the widely used ADD-S 0.1 metric, though we find a strong correlation with the BOP metrics and think them more meaningful when trying to evaluate the expected performance for a given use case and use <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mi id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">A</mi><mo id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml"><mi id="S4.p1.1.m1.1.1.3.2" xref="S4.p1.1.m1.1.1.3.2.cmml">R</mi><mrow id="S4.p1.1.m1.1.1.3.3" xref="S4.p1.1.m1.1.1.3.3.cmml"><mi id="S4.p1.1.m1.1.1.3.3.2" xref="S4.p1.1.m1.1.1.3.3.2.cmml">B</mi><mo id="S4.p1.1.m1.1.1.3.3.1" xref="S4.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.p1.1.m1.1.1.3.3.3" xref="S4.p1.1.m1.1.1.3.3.3.cmml">O</mi><mo id="S4.p1.1.m1.1.1.3.3.1a" xref="S4.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.p1.1.m1.1.1.3.3.4" xref="S4.p1.1.m1.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><times id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></times><ci id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">𝐴</ci><apply id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.3.1.cmml" xref="S4.p1.1.m1.1.1.3">subscript</csymbol><ci id="S4.p1.1.m1.1.1.3.2.cmml" xref="S4.p1.1.m1.1.1.3.2">𝑅</ci><apply id="S4.p1.1.m1.1.1.3.3.cmml" xref="S4.p1.1.m1.1.1.3.3"><times id="S4.p1.1.m1.1.1.3.3.1.cmml" xref="S4.p1.1.m1.1.1.3.3.1"></times><ci id="S4.p1.1.m1.1.1.3.3.2.cmml" xref="S4.p1.1.m1.1.1.3.3.2">𝐵</ci><ci id="S4.p1.1.m1.1.1.3.3.3.cmml" xref="S4.p1.1.m1.1.1.3.3.3">𝑂</ci><ci id="S4.p1.1.m1.1.1.3.3.4.cmml" xref="S4.p1.1.m1.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> for discussing performance on the troublesome T-Less dataset. The ADD metric measures the average distance between model points transformed by the estimated pose and those transformed by the ground truth pose. Recall is determined by a correctness threshold, typically set at 10% of the object’s diameter (ADD 0.1). To account for object symmetries (ADD-S), evaluation can compute the distance between each transformed model point and the nearest point on the ground truth model, thus accommodating equivalent transformations to yield identical scores.
To discuss the effect of our method on individual objects in T-Less, we show per object results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.T5" title="TABLE V ‣ IV-A Quantitative Results ‣ IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">V</span></a> using the <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mrow id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mi id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">A</mi><mo id="S4.p1.2.m2.1.1.1" xref="S4.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml"><mi id="S4.p1.2.m2.1.1.3.2" xref="S4.p1.2.m2.1.1.3.2.cmml">R</mi><mrow id="S4.p1.2.m2.1.1.3.3" xref="S4.p1.2.m2.1.1.3.3.cmml"><mi id="S4.p1.2.m2.1.1.3.3.2" xref="S4.p1.2.m2.1.1.3.3.2.cmml">B</mi><mo id="S4.p1.2.m2.1.1.3.3.1" xref="S4.p1.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.p1.2.m2.1.1.3.3.3" xref="S4.p1.2.m2.1.1.3.3.3.cmml">O</mi><mo id="S4.p1.2.m2.1.1.3.3.1a" xref="S4.p1.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.p1.2.m2.1.1.3.3.4" xref="S4.p1.2.m2.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><times id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1"></times><ci id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2">𝐴</ci><apply id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.p1.2.m2.1.1.3.1.cmml" xref="S4.p1.2.m2.1.1.3">subscript</csymbol><ci id="S4.p1.2.m2.1.1.3.2.cmml" xref="S4.p1.2.m2.1.1.3.2">𝑅</ci><apply id="S4.p1.2.m2.1.1.3.3.cmml" xref="S4.p1.2.m2.1.1.3.3"><times id="S4.p1.2.m2.1.1.3.3.1.cmml" xref="S4.p1.2.m2.1.1.3.3.1"></times><ci id="S4.p1.2.m2.1.1.3.3.2.cmml" xref="S4.p1.2.m2.1.1.3.3.2">𝐵</ci><ci id="S4.p1.2.m2.1.1.3.3.3.cmml" xref="S4.p1.2.m2.1.1.3.3.3">𝑂</ci><ci id="S4.p1.2.m2.1.1.3.3.4.cmml" xref="S4.p1.2.m2.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> metrics.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Quantitative Results</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.3">We can see a noticeable outperformance on 3 out of 4 sets, LM-O, YCB-V, and ITODD and perform especially well on the notoriously difficult ITODD dataset with an increase of more than 10% in the <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">A</mi><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">R</mi><mrow id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.3.2" xref="S4.SS1.p1.1.m1.1.1.3.3.2.cmml">B</mi><mo id="S4.SS1.p1.1.m1.1.1.3.3.1" xref="S4.SS1.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.3.cmml">O</mi><mo id="S4.SS1.p1.1.m1.1.1.3.3.1a" xref="S4.SS1.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.3.4" xref="S4.SS1.p1.1.m1.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">𝑅</ci><apply id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3"><times id="S4.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.3">𝑂</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.4.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> metrics. We will now take a closer look at the per-dataset results. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.3.1">LM-O.</span> With LM-O we increase the <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">A</mi><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.2" xref="S4.SS1.p1.2.m2.1.1.3.2.cmml">R</mi><mrow id="S4.SS1.p1.2.m2.1.1.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.3.2" xref="S4.SS1.p1.2.m2.1.1.3.3.2.cmml">B</mi><mo id="S4.SS1.p1.2.m2.1.1.3.3.1" xref="S4.SS1.p1.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.3.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.3.cmml">O</mi><mo id="S4.SS1.p1.2.m2.1.1.3.3.1a" xref="S4.SS1.p1.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.3.3.4" xref="S4.SS1.p1.2.m2.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></times><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝐴</ci><apply id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.2">𝑅</ci><apply id="S4.SS1.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3"><times id="S4.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.1"></times><ci id="S4.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.3">𝑂</ci><ci id="S4.SS1.p1.2.m2.1.1.3.3.4.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> score by 2.9%, from 0.757 to 0.786, and the ADD-S 0.1 score from 85.72 to 88.65 as presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.T3" title="TABLE III ‣ IV-A Quantitative Results ‣ IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">III</span></a>. Considering the <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">A</mi><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.2" xref="S4.SS1.p1.3.m3.1.1.3.2.cmml">R</mi><mrow id="S4.SS1.p1.3.m3.1.1.3.3" xref="S4.SS1.p1.3.m3.1.1.3.3.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.3.2" xref="S4.SS1.p1.3.m3.1.1.3.3.2.cmml">B</mi><mo id="S4.SS1.p1.3.m3.1.1.3.3.1" xref="S4.SS1.p1.3.m3.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.3.3.3" xref="S4.SS1.p1.3.m3.1.1.3.3.3.cmml">O</mi><mo id="S4.SS1.p1.3.m3.1.1.3.3.1a" xref="S4.SS1.p1.3.m3.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.3.3.4" xref="S4.SS1.p1.3.m3.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><times id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></times><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝐴</ci><apply id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2">𝑅</ci><apply id="S4.SS1.p1.3.m3.1.1.3.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3"><times id="S4.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.1"></times><ci id="S4.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.3">𝑂</ci><ci id="S4.SS1.p1.3.m3.1.1.3.3.4.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> scores, we outperform GDRNPP on 8 out of 8 objects. The biggest (relative as well as absolute) gain is to be found on the symmetric object eggbox, followed by the texture-less cat. Like stated above, LM-O shows heavily occluded objects with little texture in a cluttered environment under high variation in lighting, and EPRO-GDR shows a clear outperformance compared to its predecessor GDRNPP.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.3.1.1" style="font-size:90%;">TABLE III</span>: </span><span class="ltx_text" id="S4.T3.4.2" style="font-size:90%;">Results with per object results on LM-O. ADD-S 0.1 metric, higher is better. The best results in <span class="ltx_text ltx_font_bold" id="S4.T3.4.2.1">bold font</span>. EPRO-GDR achieves the best overall performance among all methods.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.5.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.5.1.1.1"><span class="ltx_text" id="S4.T3.5.1.1.1.1">Objects</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.5.1.1.2">SurfEmb<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib40" title="">40</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.5.1.1.3">PFA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib28" title="">28</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.5.1.1.4">GDRNPP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib41" title="">41</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.5.1.1.5">Ours</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.5.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.5.2.1.1">ape</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.2.1.2">70.86</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.2.1.3">75.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.5.2.1.4.1">77.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.2.1.5">76.57</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.3.2.1">can</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.3.2.2">95.98</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.3.2.3.1">98.99</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.3.2.4">97.49</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.3.2.5">98.49</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.4.3.1">cat</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.4.3.2">76.02</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.4.3.3">86.55</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.4.3.4">84.21</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.4.3.5.1">88.89</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.5.4.1">driller</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.4.2">95.50</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.4.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.4.3.1">96.50</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.4.4">95.50</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.4.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.4.5.1">96.50</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.6.5.1">duck</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.6.5.2">79.44</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.6.5.3">81.11</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.6.5.4">80.56</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.6.5.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.6.5.5.1">82.78</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.7.6.1">eggbox</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.7.6.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.7.6.2.1">80.56</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.7.6.3">72.78</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.7.6.4">60.56</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.7.6.5">74.44</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.8.7.1">glue</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.8.7.2">92.86</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.8.7.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.8.7.3.1">95.71</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.8.7.4"><span class="ltx_text ltx_font_bold" id="S4.T3.5.8.7.4.1">95.71</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.8.7.5">95.00</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.5.9.8.1">holepuncher</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.9.8.2">93.50</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.9.8.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.9.8.3.1">98.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.9.8.4">94.00</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.9.8.5">96.50</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.5.10.9.1">Mean</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.5.10.9.2">85.59</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.5.10.9.3">88.13</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.5.10.9.4">85.72</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.5.10.9.5"><span class="ltx_text ltx_font_bold" id="S4.T3.5.10.9.5.1">88.65</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.6.1.1" style="font-size:129%;">TABLE IV</span>: </span><span class="ltx_text" id="S4.T4.7.2" style="font-size:129%;">Results with per object results on YCB-V. ADD-S 0.1 metric, higher is better. The best results in <span class="ltx_text ltx_font_bold" id="S4.T4.7.2.1">bold font</span>. EPRO-GDR achieves the best overall performance.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.8.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T4.8.1.1.1"><span class="ltx_text" id="S4.T4.8.1.1.1.1" style="font-size:70%;">Objects</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.8.1.1.2">
<span class="ltx_text" id="S4.T4.8.1.1.2.1" style="font-size:70%;">SurfEmb</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.8.1.1.2.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib40" title="">40</a><span class="ltx_text" id="S4.T4.8.1.1.2.3.2" style="font-size:70%;">]</span></cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.8.1.1.3">
<span class="ltx_text" id="S4.T4.8.1.1.3.1" style="font-size:70%;">PFA</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.8.1.1.3.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib28" title="">28</a><span class="ltx_text" id="S4.T4.8.1.1.3.3.2" style="font-size:70%;">]</span></cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.8.1.1.4">
<span class="ltx_text" id="S4.T4.8.1.1.4.1" style="font-size:70%;">GDRNPP</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.8.1.1.4.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib41" title="">41</a><span class="ltx_text" id="S4.T4.8.1.1.4.3.2" style="font-size:70%;">]</span></cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.8.1.1.5"><span class="ltx_text" id="S4.T4.8.1.1.5.1" style="font-size:70%;">Ours</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.8.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.8.2.1.1"><span class="ltx_text" id="S4.T4.8.2.1.1.1" style="font-size:70%;">002_master_chef_can</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.2.1.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.2.1.3"><span class="ltx_text" id="S4.T4.8.2.1.3.1" style="font-size:70%;">96.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.2.1.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.8.2.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.2.1.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.3.2.1"><span class="ltx_text" id="S4.T4.8.3.2.1.1" style="font-size:70%;">003_cracker_box</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.3.2.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.3.2.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.3.2.3"><span class="ltx_text" id="S4.T4.8.3.2.3.1" style="font-size:70%;">92.89</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.3.2.4"><span class="ltx_text" id="S4.T4.8.3.2.4.1" style="font-size:70%;">60.44</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.3.2.5"><span class="ltx_text" id="S4.T4.8.3.2.5.1" style="font-size:70%;">73.33</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.4.3.1"><span class="ltx_text" id="S4.T4.8.4.3.1.1" style="font-size:70%;">004_sugar_box</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.4.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.4.3.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.4.3.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.4.3.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.4.3.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.5.4.1"><span class="ltx_text" id="S4.T4.8.5.4.1.1" style="font-size:70%;">005_tomato_soup_can</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.5.4.2"><span class="ltx_text" id="S4.T4.8.5.4.2.1" style="font-size:70%;">94.87</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.5.4.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.5.4.3.1" style="font-size:70%;">95.31</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.5.4.4"><span class="ltx_text" id="S4.T4.8.5.4.4.1" style="font-size:70%;">94.87</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.5.4.5"><span class="ltx_text" id="S4.T4.8.5.4.5.1" style="font-size:70%;">95.09</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.6.5.1"><span class="ltx_text" id="S4.T4.8.6.5.1.1" style="font-size:70%;">006_mustard_bottle</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.6.5.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.6.5.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.6.5.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.6.5.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.6.5.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.6.5.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.6.5.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.6.5.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.7.6.1"><span class="ltx_text" id="S4.T4.8.7.6.1.1" style="font-size:70%;">007_tuna_fish_can</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.7.6.2"><span class="ltx_text" id="S4.T4.8.7.6.2.1" style="font-size:70%;">99.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.7.6.3"><span class="ltx_text" id="S4.T4.8.7.6.3.1" style="font-size:70%;">99.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.7.6.4"><span class="ltx_text" id="S4.T4.8.7.6.4.1" style="font-size:70%;">93.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.7.6.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.7.6.5.1" style="font-size:70%;">99.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.8.7.1"><span class="ltx_text" id="S4.T4.8.8.7.1.1" style="font-size:70%;">008_pudding_box</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.8.7.2"><span class="ltx_text" id="S4.T4.8.8.7.2.1" style="font-size:70%;">98.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.8.7.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.7.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.8.7.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.7.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.8.7.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.8.7.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.9.8.1"><span class="ltx_text" id="S4.T4.8.9.8.1.1" style="font-size:70%;">009_gelatin_box</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.9.8.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.9.8.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.9.8.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.9.8.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.9.8.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.9.8.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.9.8.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.9.8.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.10.9.1"><span class="ltx_text" id="S4.T4.8.10.9.1.1" style="font-size:70%;">010_potted_meat_can</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.10.9.2"><span class="ltx_text" id="S4.T4.8.10.9.2.1" style="font-size:70%;">77.78</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.10.9.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.10.9.3.1" style="font-size:70%;">81.78</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.10.9.4"><span class="ltx_text" id="S4.T4.8.10.9.4.1" style="font-size:70%;">77.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.10.9.5"><span class="ltx_text" id="S4.T4.8.10.9.5.1" style="font-size:70%;">81.33</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.11.10.1"><span class="ltx_text" id="S4.T4.8.11.10.1.1" style="font-size:70%;">011_banana</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.11.10.2"><span class="ltx_text" id="S4.T4.8.11.10.2.1" style="font-size:70%;">96.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.11.10.3"><span class="ltx_text" id="S4.T4.8.11.10.3.1" style="font-size:70%;">87.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.11.10.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.11.10.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.11.10.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.11.10.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.12.11.1"><span class="ltx_text" id="S4.T4.8.12.11.1.1" style="font-size:70%;">019_pitcher_base</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.12.11.2"><span class="ltx_text" id="S4.T4.8.12.11.2.1" style="font-size:70%;">60.89</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.12.11.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.12.11.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.12.11.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.12.11.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.12.11.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.12.11.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.13.12.1"><span class="ltx_text" id="S4.T4.8.13.12.1.1" style="font-size:70%;">021_bleach_cleanser</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.13.12.2"><span class="ltx_text" id="S4.T4.8.13.12.2.1" style="font-size:70%;">90.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.13.12.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.13.12.3.1" style="font-size:70%;">94.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.13.12.4"><span class="ltx_text" id="S4.T4.8.13.12.4.1" style="font-size:70%;">92.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.13.12.5"><span class="ltx_text" id="S4.T4.8.13.12.5.1" style="font-size:70%;">90.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.14.13.1"><span class="ltx_text" id="S4.T4.8.14.13.1.1" style="font-size:70%;">024_bowl</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.14.13.2"><span class="ltx_text" id="S4.T4.8.14.13.2.1" style="font-size:70%;">17.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.14.13.3"><span class="ltx_text" id="S4.T4.8.14.13.3.1" style="font-size:70%;">50.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.14.13.4"><span class="ltx_text" id="S4.T4.8.14.13.4.1" style="font-size:70%;">66.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.14.13.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.14.13.5.1" style="font-size:70%;">82.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.15.14.1"><span class="ltx_text" id="S4.T4.8.15.14.1.1" style="font-size:70%;">025_mug</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.15.14.2"><span class="ltx_text" id="S4.T4.8.15.14.2.1" style="font-size:70%;">91.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.15.14.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.15.14.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.15.14.4"><span class="ltx_text" id="S4.T4.8.15.14.4.1" style="font-size:70%;">97.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.15.14.5"><span class="ltx_text" id="S4.T4.8.15.14.5.1" style="font-size:70%;">98.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.16.15.1"><span class="ltx_text" id="S4.T4.8.16.15.1.1" style="font-size:70%;">035_power_drill</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.16.15.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.16.15.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.16.15.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.16.15.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.16.15.4"><span class="ltx_text" id="S4.T4.8.16.15.4.1" style="font-size:70%;">97.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.16.15.5"><span class="ltx_text" id="S4.T4.8.16.15.5.1" style="font-size:70%;">99.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.17.16.1"><span class="ltx_text" id="S4.T4.8.17.16.1.1" style="font-size:70%;">036_wood_block</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.17.16.2"><span class="ltx_text" id="S4.T4.8.17.16.2.1" style="font-size:70%;">69.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.17.16.3"><span class="ltx_text" id="S4.T4.8.17.16.3.1" style="font-size:70%;">81.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.17.16.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.17.16.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.17.16.5"><span class="ltx_text" id="S4.T4.8.17.16.5.1" style="font-size:70%;">93.33</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.18.17.1"><span class="ltx_text" id="S4.T4.8.18.17.1.1" style="font-size:70%;">037_scissors</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.18.17.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.18.17.2.1" style="font-size:70%;">98.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.18.17.3"><span class="ltx_text" id="S4.T4.8.18.17.3.1" style="font-size:70%;">93.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.18.17.4"><span class="ltx_text" id="S4.T4.8.18.17.4.1" style="font-size:70%;">46.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.18.17.5"><span class="ltx_text" id="S4.T4.8.18.17.5.1" style="font-size:70%;">42.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.19.18.1"><span class="ltx_text" id="S4.T4.8.19.18.1.1" style="font-size:70%;">040_large_marker</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.19.18.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.19.18.2.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.19.18.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.19.18.3.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.19.18.4"><span class="ltx_text" id="S4.T4.8.19.18.4.1" style="font-size:70%;">99.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.19.18.5"><span class="ltx_text" id="S4.T4.8.19.18.5.1" style="font-size:70%;">98.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.20.19.1"><span class="ltx_text" id="S4.T4.8.20.19.1.1" style="font-size:70%;">051_large_clamp</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.20.19.2"><span class="ltx_text ltx_font_bold" id="S4.T4.8.20.19.2.1" style="font-size:70%;">99.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.20.19.3"><span class="ltx_text ltx_font_bold" id="S4.T4.8.20.19.3.1" style="font-size:70%;">99.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.20.19.4"><span class="ltx_text" id="S4.T4.8.20.19.4.1" style="font-size:70%;">86.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.20.19.5"><span class="ltx_text" id="S4.T4.8.20.19.5.1" style="font-size:70%;">98.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.21.20.1"><span class="ltx_text" id="S4.T4.8.21.20.1.1" style="font-size:70%;">052_extra_large_clamp</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.21.20.2"><span class="ltx_text" id="S4.T4.8.21.20.2.1" style="font-size:70%;">78.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.21.20.3"><span class="ltx_text" id="S4.T4.8.21.20.3.1" style="font-size:70%;">75.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.21.20.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.21.20.4.1" style="font-size:70%;">99.33</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.21.20.5"><span class="ltx_text" id="S4.T4.8.21.20.5.1" style="font-size:70%;">91.33</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.8.22.21.1"><span class="ltx_text" id="S4.T4.8.22.21.1.1" style="font-size:70%;">061_foam_brick</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.8.22.21.2"><span class="ltx_text" id="S4.T4.8.22.21.2.1" style="font-size:70%;">96.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.22.21.3"><span class="ltx_text" id="S4.T4.8.22.21.3.1" style="font-size:70%;">94.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.22.21.4"><span class="ltx_text ltx_font_bold" id="S4.T4.8.22.21.4.1" style="font-size:70%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.22.21.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.22.21.5.1" style="font-size:70%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.8.23.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T4.8.23.22.1"><span class="ltx_text" id="S4.T4.8.23.22.1.1" style="font-size:70%;">Mean</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.8.23.22.2"><span class="ltx_text" id="S4.T4.8.23.22.2.1" style="font-size:70%;">88.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.8.23.22.3"><span class="ltx_text" id="S4.T4.8.23.22.3.1" style="font-size:70%;">92.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.8.23.22.4"><span class="ltx_text" id="S4.T4.8.23.22.4.1" style="font-size:70%;">90.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.8.23.22.5"><span class="ltx_text ltx_font_bold" id="S4.T4.8.23.22.5.1" style="font-size:70%;">92.56</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">YCB-V.</span>
On YCB-V we increase the <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">A</mi><mo id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.3.2.cmml">R</mi><mrow id="S4.SS1.p2.1.m1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.3.3.2" xref="S4.SS1.p2.1.m1.1.1.3.3.2.cmml">B</mi><mo id="S4.SS1.p2.1.m1.1.1.3.3.1" xref="S4.SS1.p2.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.1.1.3.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.3.cmml">O</mi><mo id="S4.SS1.p2.1.m1.1.1.3.3.1a" xref="S4.SS1.p2.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.SS1.p2.1.m1.1.1.3.3.4" xref="S4.SS1.p2.1.m1.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝐴</ci><apply id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2">𝑅</ci><apply id="S4.SS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3"><times id="S4.SS1.p2.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.1"></times><ci id="S4.SS1.p2.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.2">𝐵</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.3">𝑂</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.4.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> metric from 0.816 to 0.844 and the ADD-S 0.1 from 90.98 to 92.56 as listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.T4" title="TABLE IV ‣ IV-A Quantitative Results ‣ IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">IV</span></a>. Again, focusing on the BOP metrics, out of 8 symmetric objects, we beat our baseline on 4, not supporting the notion, that we learn a better understanding of symmetry. Instead we outperform on most of the texture-rich as well as texture-less objects, suggesting that EPRO-GDR can use, but does not rely on strong textures.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">ITODD.</span> ITODD consists of industrial, metallic shapes and is the most difficult out of the 7 core datasets. We achieve an improvement of the metric result from 0.356 to 0.412. Since the ground truth of ITODD is not available we cannot compare object-level performance and can only report the 3 individual metrics, MSPD, MSSD, and VSD, all of which seem to improve to a similar degree, with MSPD benefiting slightly more than the other two. Since MSPD only compares visible discrepancies it is considered the most important for XR applications. A high score on this metric indicates a good fit. The great improvement on ITODD indicate that EPRO-GDR can deal better with metallic industrial shapes. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.2">T-Less.</span> Our method has some problems with the T-Less dataset. We still tend to achieve a high quality with many objects, outperforming GDRNPP on objects 10, 11, 21, and 26, for instance, but we face challenges with a few individual objects, reducing our average score. The offending objects are 14, 16, 27, 28, and 30. Please consider Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.T5" title="TABLE V ‣ IV-A Quantitative Results ‣ IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">V</span></a> for detailed, per object results. Template-based PFA also shows reduced performance with these texture-less objects, while SurfEmb still achieves high scores.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.6.2.1" style="font-size:90%;">TABLE V</span>: </span><span class="ltx_text" id="S4.T5.2.1" style="font-size:90%;">Results with per object results on T-LESS. <math alttext="AR_{BOP}" class="ltx_Math" display="inline" id="S4.T5.2.1.m1.1"><semantics id="S4.T5.2.1.m1.1b"><mrow id="S4.T5.2.1.m1.1.1" xref="S4.T5.2.1.m1.1.1.cmml"><mi id="S4.T5.2.1.m1.1.1.2" xref="S4.T5.2.1.m1.1.1.2.cmml">A</mi><mo id="S4.T5.2.1.m1.1.1.1" xref="S4.T5.2.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.2.1.m1.1.1.3" xref="S4.T5.2.1.m1.1.1.3.cmml"><mi id="S4.T5.2.1.m1.1.1.3.2" xref="S4.T5.2.1.m1.1.1.3.2.cmml">R</mi><mrow id="S4.T5.2.1.m1.1.1.3.3" xref="S4.T5.2.1.m1.1.1.3.3.cmml"><mi id="S4.T5.2.1.m1.1.1.3.3.2" xref="S4.T5.2.1.m1.1.1.3.3.2.cmml">B</mi><mo id="S4.T5.2.1.m1.1.1.3.3.1" xref="S4.T5.2.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.T5.2.1.m1.1.1.3.3.3" xref="S4.T5.2.1.m1.1.1.3.3.3.cmml">O</mi><mo id="S4.T5.2.1.m1.1.1.3.3.1b" xref="S4.T5.2.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.T5.2.1.m1.1.1.3.3.4" xref="S4.T5.2.1.m1.1.1.3.3.4.cmml">P</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.2.1.m1.1c"><apply id="S4.T5.2.1.m1.1.1.cmml" xref="S4.T5.2.1.m1.1.1"><times id="S4.T5.2.1.m1.1.1.1.cmml" xref="S4.T5.2.1.m1.1.1.1"></times><ci id="S4.T5.2.1.m1.1.1.2.cmml" xref="S4.T5.2.1.m1.1.1.2">𝐴</ci><apply id="S4.T5.2.1.m1.1.1.3.cmml" xref="S4.T5.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.2.1.m1.1.1.3.1.cmml" xref="S4.T5.2.1.m1.1.1.3">subscript</csymbol><ci id="S4.T5.2.1.m1.1.1.3.2.cmml" xref="S4.T5.2.1.m1.1.1.3.2">𝑅</ci><apply id="S4.T5.2.1.m1.1.1.3.3.cmml" xref="S4.T5.2.1.m1.1.1.3.3"><times id="S4.T5.2.1.m1.1.1.3.3.1.cmml" xref="S4.T5.2.1.m1.1.1.3.3.1"></times><ci id="S4.T5.2.1.m1.1.1.3.3.2.cmml" xref="S4.T5.2.1.m1.1.1.3.3.2">𝐵</ci><ci id="S4.T5.2.1.m1.1.1.3.3.3.cmml" xref="S4.T5.2.1.m1.1.1.3.3.3">𝑂</ci><ci id="S4.T5.2.1.m1.1.1.3.3.4.cmml" xref="S4.T5.2.1.m1.1.1.3.3.4">𝑃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.1.m1.1d">AR_{BOP}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.1.m1.1e">italic_A italic_R start_POSTSUBSCRIPT italic_B italic_O italic_P end_POSTSUBSCRIPT</annotation></semantics></math> metric, higher is better. Symmetric objects in <span class="ltx_text ltx_font_italic" id="S4.T5.2.1.1">italics</span>. The best result between GDRNPP and EPRO-GDR in <span class="ltx_text ltx_font_bold" id="S4.T5.2.1.2">bold font</span>. </span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.7.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T5.7.1.1.1"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.7.1.1.2">SurfEmb <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib40" title="">40</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.7.1.1.3">PFA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib28" title="">28</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.7.1.1.4">GDRNPP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#bib.bib41" title="">41</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.7.1.1.5">Ours</th>
</tr>
<tr class="ltx_tr" id="S4.T5.7.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.7.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.2.2.1.1">Obj. 1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.7.2.2.2">0.726</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.7.2.2.3">0.656</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.7.2.2.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.2.2.4.1" style="background-color:#E6E6E6;">0.837</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.7.2.2.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.2.2.5.1" style="background-color:#E6E6E6;">0.766</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.3.3">
<td class="ltx_td ltx_align_center" id="S4.T5.7.3.3.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.3.3.1.1">Obj. 2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.3.3.2">0.668</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.3.3.3">0.704</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.3.3.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.3.3.4.1" style="background-color:#E6E6E6;">0.818</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.3.3.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.3.3.5.1" style="background-color:#E6E6E6;">0.741</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.4.4">
<td class="ltx_td ltx_align_center" id="S4.T5.7.4.4.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.4.4.1.1">Obj. 3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.4.4.2">0.900</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.4.4.3">0.758</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.4.4.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.4.4.4.1" style="background-color:#E6E6E6;">0.887</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.4.4.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.4.4.5.1" style="background-color:#E6E6E6;">0.854</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.5.5">
<td class="ltx_td ltx_align_center" id="S4.T5.7.5.5.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.5.5.1.1">Obj. 4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.5.5.2">0.605</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.5.5.3">0.638</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.5.5.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.5.5.4.1" style="background-color:#E6E6E6;">0.849</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.5.5.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.5.5.5.1" style="background-color:#E6E6E6;">0.804</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.6.6">
<td class="ltx_td ltx_align_center" id="S4.T5.7.6.6.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.6.6.1.1">Obj. 5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.6.6.2">0.941</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.6.6.3">0.926</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.6.6.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.6.6.4.1" style="background-color:#E6E6E6;">0.946</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.6.6.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.6.6.5.1" style="background-color:#E6E6E6;">0.948</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.7.7">
<td class="ltx_td ltx_align_center" id="S4.T5.7.7.7.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.7.7.1.1">Obj. 6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.7.7.2">0.963</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.7.7.3">0.874</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.7.7.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.7.7.4.1" style="background-color:#E6E6E6;">0.930</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.7.7.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.7.7.5.1" style="background-color:#E6E6E6;">0.946</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.8.8">
<td class="ltx_td ltx_align_center" id="S4.T5.7.8.8.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.8.8.1.1">Obj. 7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.8.8.2">0.893</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.8.8.3">0.851</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.8.8.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.8.8.4.1" style="background-color:#E6E6E6;">0.876</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.8.8.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.8.8.5.1" style="background-color:#E6E6E6;">0.895</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.9.9">
<td class="ltx_td ltx_align_center" id="S4.T5.7.9.9.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.9.9.1.1">Obj. 8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.9.9.2">0.950</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.9.9.3">0.901</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.9.9.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.9.9.4.1" style="background-color:#E6E6E6;">0.903</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.9.9.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.9.9.5.1" style="background-color:#E6E6E6;">0.900</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.10.10">
<td class="ltx_td ltx_align_center" id="S4.T5.7.10.10.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.10.10.1.1">Obj. 9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.10.10.2">0.950</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.10.10.3">0.927</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.10.10.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.10.10.4.1" style="background-color:#E6E6E6;">0.905</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.10.10.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.10.10.5.1" style="background-color:#E6E6E6;">0.906</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.11.11">
<td class="ltx_td ltx_align_center" id="S4.T5.7.11.11.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.11.11.1.1">Obj. 10</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.11.11.2">0.934</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.11.11.3">0.901</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.11.11.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.11.11.4.1" style="background-color:#E6E6E6;">0.894</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.11.11.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.11.11.5.1" style="background-color:#E6E6E6;">0.925</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.12.12">
<td class="ltx_td ltx_align_center" id="S4.T5.7.12.12.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.12.12.1.1">Obj. 11</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.12.12.2">0.912</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.12.12.3">0.828</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.12.12.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.12.12.4.1" style="background-color:#E6E6E6;">0.865</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.12.12.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.12.12.5.1" style="background-color:#E6E6E6;">0.924</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.13.13">
<td class="ltx_td ltx_align_center" id="S4.T5.7.13.13.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.13.13.1.1">Obj. 12</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.13.13.2">0.921</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.13.13.3">0.855</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.13.13.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.13.13.4.1" style="background-color:#E6E6E6;">0.878</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.13.13.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.13.13.5.1" style="background-color:#E6E6E6;">0.910</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.14.14">
<td class="ltx_td ltx_align_center" id="S4.T5.7.14.14.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.14.14.1.1">Obj. 13</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.14.14.2">0.817</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.14.14.3">0.647</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.14.14.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.14.14.4.1" style="background-color:#E6E6E6;">0.855</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.14.14.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.14.14.5.1" style="background-color:#E6E6E6;">0.854</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.15.15">
<td class="ltx_td ltx_align_center" id="S4.T5.7.15.15.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.15.15.1.1">Obj. 14</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.15.15.2">0.812</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.15.15.3">0.810</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.15.15.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.15.15.4.1" style="background-color:#E6E6E6;">0.865</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.15.15.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.15.15.5.1" style="background-color:#E6E6E6;">0.183</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.16.16">
<td class="ltx_td ltx_align_center" id="S4.T5.7.16.16.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.16.16.1.1">Obj. 15</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.16.16.2">0.769</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.16.16.3">0.770</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.16.16.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.16.16.4.1" style="background-color:#E6E6E6;">0.838</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.16.16.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.16.16.5.1" style="background-color:#E6E6E6;">0.558</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.17.17">
<td class="ltx_td ltx_align_center" id="S4.T5.7.17.17.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.17.17.1.1">Obj. 16</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.17.17.2">0.894</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.17.17.3">0.821</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.17.17.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.17.17.4.1" style="background-color:#E6E6E6;">0.920</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.17.17.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.17.17.5.1" style="background-color:#E6E6E6;">0.448</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.18.18">
<td class="ltx_td ltx_align_center" id="S4.T5.7.18.18.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.18.18.1.1">Obj. 17</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.18.18.2">0.956</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.18.18.3">0.935</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.18.18.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.18.18.4.1" style="background-color:#E6E6E6;">0.939</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.18.18.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.18.18.5.1" style="background-color:#E6E6E6;">0.927</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.19.19">
<td class="ltx_td ltx_align_center" id="S4.T5.7.19.19.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.19.19.1.1">Obj. 18</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.19.19.2">0.918</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.19.19.3">0.911</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.19.19.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.19.19.4.1" style="background-color:#E6E6E6;">0.856</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.19.19.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.19.19.5.1" style="background-color:#E6E6E6;">0.914</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.20.20">
<td class="ltx_td ltx_align_center" id="S4.T5.7.20.20.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.20.20.1.1">Obj. 19</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.20.20.2">0.863</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.20.20.3">0.772</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.20.20.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.20.20.4.1" style="background-color:#E6E6E6;">0.807</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.20.20.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.20.20.5.1" style="background-color:#E6E6E6;">0.698</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.21.21">
<td class="ltx_td ltx_align_center" id="S4.T5.7.21.21.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.21.21.1.1">Obj. 20</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.21.21.2">0.815</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.21.21.3">0.764</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.21.21.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.21.21.4.1" style="background-color:#E6E6E6;">0.777</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.21.21.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.21.21.5.1" style="background-color:#E6E6E6;">0.653</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.22.22">
<td class="ltx_td ltx_align_center" id="S4.T5.7.22.22.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.22.22.1.1">Obj. 21</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.22.22.2">0.798</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.22.22.3">0.733</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.22.22.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.22.22.4.1" style="background-color:#E6E6E6;">0.792</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.22.22.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.22.22.5.1" style="background-color:#E6E6E6;">0.820</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.23.23">
<td class="ltx_td ltx_align_center" id="S4.T5.7.23.23.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.23.23.1.1">Obj. 22</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.23.23.2">0.749</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.23.23.3">0.719</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.23.23.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.23.23.4.1" style="background-color:#E6E6E6;">0.683</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.23.23.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.23.23.5.1" style="background-color:#E6E6E6;">0.758</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.24.24">
<td class="ltx_td ltx_align_center" id="S4.T5.7.24.24.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.24.24.1.1">Obj. 23</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.24.24.2">0.930</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.24.24.3">0.874</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.24.24.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.24.24.4.1" style="background-color:#E6E6E6;">0.857</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.24.24.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.24.24.5.1" style="background-color:#E6E6E6;">0.867</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.25.25">
<td class="ltx_td ltx_align_center" id="S4.T5.7.25.25.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.25.25.1.1">Obj. 24</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.25.25.2">0.948</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.25.25.3">0.784</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.25.25.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.25.25.4.1" style="background-color:#E6E6E6;">0.886</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.25.25.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.25.25.5.1" style="background-color:#E6E6E6;">0.905</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.26.26">
<td class="ltx_td ltx_align_center" id="S4.T5.7.26.26.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.26.26.1.1">Obj. 25</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.26.26.2">0.831</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.26.26.3">0.783</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.26.26.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.26.26.4.1" style="background-color:#E6E6E6;">0.823</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.26.26.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.26.26.5.1" style="background-color:#E6E6E6;">0.924</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.27.27">
<td class="ltx_td ltx_align_center" id="S4.T5.7.27.27.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.27.27.1.1">Obj. 26</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.27.27.2">0.937</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.27.27.3">0.822</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.27.27.4" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.27.27.4.1" style="background-color:#E6E6E6;">0.849</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.27.27.5" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.27.27.5.1" style="background-color:#E6E6E6;">0.947</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.28.28">
<td class="ltx_td ltx_align_center" id="S4.T5.7.28.28.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.28.28.1.1">Obj. 27</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.28.28.2">0.906</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.28.28.3">0.842</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.28.28.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.28.28.4.1" style="background-color:#E6E6E6;">0.843</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.28.28.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.28.28.5.1" style="background-color:#E6E6E6;">0.125</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.29.29">
<td class="ltx_td ltx_align_center" id="S4.T5.7.29.29.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.29.29.1.1">Obj. 28</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.29.29.2">0.929</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.29.29.3">0.841</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.29.29.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.29.29.4.1" style="background-color:#E6E6E6;">0.848</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.29.29.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.29.29.5.1" style="background-color:#E6E6E6;">0.417</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.30.30">
<td class="ltx_td ltx_align_center" id="S4.T5.7.30.30.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.30.30.1.1">Obj. 29</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.30.30.2">0.948</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.30.30.3">0.862</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.30.30.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.30.30.4.1" style="background-color:#E6E6E6;">0.936</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.30.30.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.30.30.5.1" style="background-color:#E6E6E6;">0.929</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.31.31">
<td class="ltx_td ltx_align_center" id="S4.T5.7.31.31.1"><span class="ltx_text ltx_font_italic" id="S4.T5.7.31.31.1.1">Obj. 30</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.31.31.2">0.794</td>
<td class="ltx_td ltx_align_left" id="S4.T5.7.31.31.3">0.765</td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.31.31.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.31.31.4.1" style="background-color:#E6E6E6;">0.858</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.7.31.31.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.31.31.5.1" style="background-color:#E6E6E6;">0.195</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.7.32.32">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.7.32.32.1">Mean</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.7.32.32.2">0.828</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T5.7.32.32.3">0.779</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.7.32.32.4" style="background-color:#E6E6E6;"><span class="ltx_text ltx_font_bold" id="S4.T5.7.32.32.4.1" style="background-color:#E6E6E6;">0.855</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.7.32.32.5" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T5.7.32.32.5.1" style="background-color:#E6E6E6;">0.765</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.9.10.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.9.10.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.9.10.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.9.10.1.2.1">Sample 1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.9.10.1.3"><span class="ltx_text ltx_font_bold" id="S4.T6.9.10.1.3.1">Sample 2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T6.9.10.1.4"><span class="ltx_text ltx_font_bold" id="S4.T6.9.10.1.4.1">Sample 3</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.3.3.4">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T6.3.3.4.1" style="width:8.8pt;height:48.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:48.7pt;transform:translate(-19.95pt,-18.98pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T6.3.3.4.1.1">RGB input</p>
</span></div>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="S4.T6.1.1.1.g1" src="extracted/5862760/img/tless_x1.png" width="110"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="S4.T6.2.2.2.g1" src="extracted/5862760/img/tless_x2.png" width="110"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.3.3.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="111" id="S4.T6.3.3.3.g1" src="extracted/5862760/img/tless_x3-2.png" width="110"/></td>
</tr>
<tr class="ltx_tr" id="S4.T6.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.6.6.4">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T6.6.6.4.1" style="width:8.9pt;height:70.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:70.6pt;transform:translate(-30.88pt,-29.9pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T6.6.6.4.1.1">predicted points</p>
</span></div>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.4.4.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="103" id="S4.T6.4.4.1.g1" src="extracted/5862760/img/tless_x1_ori.png" width="110"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.5.5.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="106" id="S4.T6.5.5.2.g1" src="extracted/5862760/img/tless_x2_ori-2.png" width="110"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.6.6.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="103" id="S4.T6.6.6.3.g1" src="extracted/5862760/img/tless_x3_crop-2.png" width="110"/></td>
</tr>
<tr class="ltx_tr" id="S4.T6.9.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T6.9.9.4">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T6.9.9.4.1" style="width:8.8pt;height:45.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:45.1pt;transform:translate(-18.17pt,-17.2pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.T6.9.9.4.1.1">GT points</p>
</span></div>
</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.7.7.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="105" id="S4.T6.7.7.1.g1" src="extracted/5862760/img/tless_x1_crop.png" width="110"/></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.8.8.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="105" id="S4.T6.8.8.2.g1" src="extracted/5862760/img/tless_x2_crop.png" width="110"/></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T6.9.9.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="103" id="S4.T6.9.9.3.g1" src="extracted/5862760/img/tless_x3_ori-2.png" width="110"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.11.1.1" style="font-size:90%;">TABLE VI</span>: </span><span class="ltx_text" id="S4.T6.12.2" style="font-size:90%;">Single model training for T-Less object 27 (first two samples). Given an input sample, we show the 3D points as predicted by the model versus the ground truth. We find that the model has problems estimating the correct shape. For comparison we present object 26 (trained in a multiple objects, single model case) in column three. The shape is well understood as already indicated by the very high score of 0.947 for EPRO-GDR compared to only 0.849 for GDNRPP. </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Discussion</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">EPRO-GDR outperforms GDRNPP on 3 out of 4 datasets. To indentify the challenges lie with T-Less, we delve deeper to find the source of our problem: Though there are some <a class="ltx_ref ltx_href" href="https://github.com/ylabbe/cosypose/issues/7#issuecomment-689017593" title="">misalignment issues</a> between depth and RGB sensors in the T-Less dataset, we don’t think this is the sole reason for the poor results on some objects. For further investigation, we pick out object 27, which has its score drop from 0.843 with GDRNPP to a mere 0.125 using EPRO-GDR, and we train a model solely on this single object. Since GDRNPP tends to perform significantly better in the single model per single object use case, we anticipated achieving much higher performance. While we did see improvements, we still did not reach the performance levels of GDRNPP. Our model tops out at 0.615, suggesting some deeper problem with specific geometric features. We show 3 samples with predicted 3D points and ground truth in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.11819v1#S4.T6" title="TABLE VI ‣ IV-A Quantitative Results ‣ IV Evaluation ‣ End-to-End Probabilistic Geometry-Guided Regression for 6DoF Object Pose Estimation"><span class="ltx_text ltx_ref_tag">VI</span></a>. For the poorly performing object 27, we note a discrepancy between the predicted 3D points at the bottom of the object and the corresponding ground truth. Specifically, the object is not as concave as the predicted points suggest. This inconsistency affects the calculation of re-projection error and the learning of the overall shape. On a closer look at the dataset, one reason for this is that there is not enough training data showing the bottom of the object. This issue may be less severe in single-object training but becomes more serious in multi-object training (as proved by the much improved performance of 0.615 vs. 0.125). Another possible reason is that the structure on the bottom makes it challenging to accurately determine the 3D points from the RGB information, as they create the illusion of a more concave bottom than is actually present. Indeed, the disorganized nature of the predicted 3D points suggests that the model does not fully comprehend the entire shape of the object. For comparison, we include a sample from the extremely well performing object 26, on which we drastically outperform GDRNPP, in column 3. Our method is capable of learning even the challenging, under-represented details of the texture-less T-Less objects, as demonstrated by our single-model training. To address outliers, we suggest increasing the number of training samples for problematic object views, giving them a higher weight during optimization. 
<br class="ltx_break"/>All in all, EPRO-GDR outperforms its baseline on most objects, with T-Less containing a few very bad outliers. That being said, even on T-Less EPRO-GDR outperforms GDRNPP on 14 out of 30 objects making EPRO-GDR the overall better performing algorithm and placing it in line with the succession of incremental improvements starting with CDPN, GDR-Net, EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_n</annotation></semantics></math>P, and GDRNPP. Considering the suitability for scene-level optimization, we deem EPRO-GDR to stand out among these choices, not only because of improved single-view accuracy, but by bringing the virtues of EPro-P<math alttext="n" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_n</annotation></semantics></math>P’s probability-based pose prediction to GDRNPP’s design and by changing the prediction output from discrete poses to a probability distribution. The formulation as a pdf allows to sample multiple meaningful poses, the benefit of which is easy to see once one considers the often occurring possibility of visually non-distinguishable views. Also, typically ML algorithms are designed to also predict a score, representing how confident they are in their prediction. The probability of a pose sample is a meaningful representation for confidence. Future work might look into directly incorporating the pdfs provided by EPRO-GDR for scene-level optimization.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we argue that a probabilistic formulation of the single-view 6D pose estimation problem is useful, because it allows to sample multiple likely pose candidates, and we show that it can improve the accuracy of pose estimates. To this end, we reformulated the state-of-the-art GDRNPP algorithm into our novel EPRO-GDR algorithm, which estimates a probability density distribution of poses. EPRO-GDR’s ability to sample multiple pose estimates with a meaningful measure of uncertainty is a notable advancement over traditional single-view estimators for use cases that can incorporate the information of multiple estimates, such as scene-level optimization. Even when sampling just a single pose candidate (i.e. the mode of the distribution), EPRO-GDR shows superior quantitative results in pose estimation across three widely-used reference datasets.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Chen, “Texture optimization for 6 dof pose
estimation,” Master Thesis, ETH Zurich, Zurich, 2022-11.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Y. Zhu, M. Li, W. Yao, and C. Chen, “A review of 6d object pose estimation,”
in <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">2022 IEEE 10th Joint International Information Technology and
Artificial Intelligence Conference (ITAIC)</em>, vol. 10, 2022, pp. 1647–1655.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
T. Hodan, M. Sundermeyer, Y. Labbe, V. N. Nguyen, G. Wang, E. Brachmann,
B. Drost, V. Lepetit, C. Rother, and J. Matas, “Bop challenge 2023 on
detection, segmentation and pose estimation of seen and unseen rigid
objects,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2403.09799</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Sundermeyer, T. Hodan, Y. Labbé, G. Wang, E. Brachmann, B. Drost,
C. Rother, and J. E. S. Matas, “Bop challenge 2022 on detection,
segmentation and pose estimation of specific rigid objects,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">2023
IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops
(CVPRW)</em>, pp. 2785–2794, 2023. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:257220212" title="">https://api.semanticscholar.org/CorpusID:257220212</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
W. Kehl, F. Manhardt, F. Tombari, S. Ilic, and N. Navab, “Ssd-6d: Making
rgb-based 3d detection and 6d pose estimation great again,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">2017 IEEE
International Conference on Computer Vision (ICCV)</em>, pp. 1530–1538, 2017.
[Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:10655945" title="">https://api.semanticscholar.org/CorpusID:10655945</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Xiang, T. Schmidt, V. Narayanan, and D. Fox, “Posecnn: A convolutional
neural network for 6d object pose estimation in cluttered scenes,”
<em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">ArXiv</em>, vol. abs/1711.00199, 2017. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:3440950" title="">https://api.semanticscholar.org/CorpusID:3440950</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Rad and V. Lepetit, “Bb8: A scalable, accurate, robust to partial occlusion
method for predicting the 3d poses of challenging objects without using
depth,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the IEEE international conference on
computer vision</em>, 2017, pp. 3828–3836.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Z.-W. Hong, Y.-Y. Hung, and C.-S. Chen, “Rdpn6d: Residual-based dense
point-wise network for 6dof object pose estimation based on rgb-d images,”
in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR) Workshops</em>, June 2024, pp. 5251–5260.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
B. Tekin, S. N. Sinha, and P. Fua, “Real-time seamless single shot 6d object
pose prediction,” in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the IEEE conference on computer
vision and pattern recognition</em>, 2018, pp. 292–301.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
S. Peng, Y. Liu, Q.-X. Huang, H. Bao, and X. Zhou, “Pvnet: Pixel-wise voting
network for 6dof pose estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">2019 IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, pp. 4556–4565, 2018.
[Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:57189382" title="">https://api.semanticscholar.org/CorpusID:57189382</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C. Song, J. Song, and Q. Huang, “Hybridpose: 6d object pose estimation under
hybrid representations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the IEEE/CVF conference on
computer vision and pattern recognition</em>, 2020, pp. 431–440.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Z. Li, G. Wang, and X. Ji, “Cdpn: Coordinates-based disentangled pose network
for real-time rgb-based 6-dof object pose estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">2019 IEEE/CVF
International Conference on Computer Vision (ICCV)</em>, pp. 7677–7686, 2019.
[Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:204962112" title="">https://api.semanticscholar.org/CorpusID:204962112</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. Hodan, D. Baráth, and J. Matas, “Epos: Estimating 6d pose of objects
with symmetries,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2020 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp. 11 700–11 709, 2020. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:214743136" title="">https://api.semanticscholar.org/CorpusID:214743136</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
R. L. Haugaard and A. G. Buch, “Surfemb: Dense and continuous correspondence
distributions for object pose estimation with learnt surface embeddings,”
<em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR)</em>, pp. 6739–6748, 2021. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:244708985" title="">https://api.semanticscholar.org/CorpusID:244708985</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Su, M. Saleh, T. Fetzer, J. R. Rambach, N. Navab, B. Busam, D. Stricker, and
F. Tombari, “Zebrapose: Coarse to fine surface encoding for 6dof object pose
estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, pp. 6728–6738, 2022. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:247518862" title="">https://api.semanticscholar.org/CorpusID:247518862</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
G. Wang, F. Manhardt, F. Tombari, and X. Ji, “Gdr-net: Geometry-guided direct
regression network for monocular 6d object pose estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">2021
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.
16 606–16 616, 2021. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:232035418" title="">https://api.semanticscholar.org/CorpusID:232035418</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
X. Liu, R. Zhang, C. Zhang, B. Fu, J. Tang, X. Liang, J. Tang, X. Cheng,
Y. Zhang, G. Wang, and X. Ji, “Gdrnpp,”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/shanice-l/gdrnpp_bop2022" title="">https://github.com/shanice-l/gdrnpp_bop2022</a>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
D. Barath and J. Matas, “Graph-cut ransac,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the IEEE
conference on computer vision and pattern recognition</em>, 2018, pp. 6733–6741.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
D. Baráth and J. Matas, “Progressive-x: Efficient, anytime, multi-model
fitting algorithm,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">2019 IEEE/CVF International Conference on Computer
Vision (ICCV)</em>, pp. 3779–3787, 2019. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:174802993" title="">https://api.semanticscholar.org/CorpusID:174802993</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the IEEE conference on computer vision
and pattern recognition</em>, 2016, pp. 770–778.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Z. Liu, H. Mao, C.-Y. Wu, C. Feichtenhofer, T. Darrell, and S. Xie, “A convnet
for the 2020s,” in <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition</em>, 2022, pp. 11 976–11 986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
V. Lepetit, F. Moreno-Noguer, and P. Fua, “Epnp: An accurate o(n) solution to
the pnp problem,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Journal of Computer Vision</em>, vol. 81,
no. 2, pp. 155–166, 2009. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s11263-008-0152-6" title="">https://doi.org/10.1007/s11263-008-0152-6</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. Chen, P. Wang, F. Wang, W. Tian, L. Xiong, and H. Li, “Epro-pnp:
Generalized end-to-end probabilistic perspective-n-points for monocular
object pose estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">2022 IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em>, pp. 2771–2780, 2022. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:247628136" title="">https://api.semanticscholar.org/CorpusID:247628136</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
S. Hinterstoisser, V. Lepetit, S. Ilic, S. Holzer, G. Bradski, K. Konolige, and
N. Navab, “Model based training, detection and pose estimation of
texture-less 3d objects in heavily cluttered scenes,” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Computer
Vision–ACCV 2012: 11th Asian Conference on Computer Vision, Daejeon, Korea,
November 5-9, 2012, Revised Selected Papers, Part I 11</em>.   Springer, 2013, pp. 548–562.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y. Labbé, L. Manuelli, A. Mousavian, S. Tyree, S. Birchfield, J. Tremblay,
J. Carpentier, M. Aubry, D. Fox, and J. Sivic, “Megapose: 6d pose estimation
of novel objects via render &amp; compare,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint
arXiv:2212.06870</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
V. N. Nguyen, T. Groueix, M. Salzmann, and V. Lepetit, “Gigapose: Fast and
robust novel object pose estimation via one correspondence,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv
preprint arXiv:2311.14155</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Y. Hu, P. Fua, and M. Salzmann, “Perspective flow aggregation for data-limited
6d object pose estimation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">European Conference on Computer
Vision</em>, 2022. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:247595249" title="">https://api.semanticscholar.org/CorpusID:247595249</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
BOP: Benchmark for 6D Object Pose Estimation, “PFA BOP results,”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bop.felk.cvut.cz/method_info/278/" title="">https://bop.felk.cvut.cz/method_info/278/</a>, accessed on 27.06.2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Y. Li, G. Wang, X. Ji, Y. Xiang, and D. Fox, “DeepIM: Deep iterative
matching for 6d pose estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">International Journal of Computer
Vision</em>, vol. 128, no. 3, pp. 657–678, nov 2019. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007%2Fs11263-019-01250-9" title="">https://doi.org/10.1007%2Fs11263-019-01250-9</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Y. Labb’e, J. Carpentier, M. Aubry, and J. Sivic, “Cosypose: Consistent
multi-view multi-object 6d pose estimation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">European Conference on
Computer Vision</em>, 2020. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:221172989" title="">https://api.semanticscholar.org/CorpusID:221172989</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
S. Iwase, X. Liu, R. Khirodkar, R. Yokota, and K. M. Kitani, “Repose: Fast 6d
object pose refinement via deep texture rendering,” in <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of
the IEEE/CVF International Conference on Computer Vision</em>, 2021, pp.
3303–3312.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
P. Besl and N. D. McKay, “A method for registration of 3-d shapes,”
<em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,
vol. 14, no. 2, pp. 239–256, 1992.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
L. Lipson, Z. Teed, A. Goyal, and J. Deng, “Coupled iterative refinement for
6d multi-object pose estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">2022 IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, pp. 6718–6727, 2022. [Online].
Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:248406199" title="">https://api.semanticscholar.org/CorpusID:248406199</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
R. L. Haugaard, F. Hagelskjær, and T. M. Iversen, “Spyropose: Se(3)
pyramids for object pose distribution estimation,” <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">2023 IEEE/CVF
International Conference on Computer Vision Workshops (ICCVW)</em>, pp.
2074–2083, 2023. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:266555253" title="">https://api.semanticscholar.org/CorpusID:266555253</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
“Leaderboards: Model-based 6D localization of seen objects –
BOP-Classic-Core,”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bop.felk.cvut.cz/leaderboards/pose-estimation-bop19/bop-classic-core/" title="">https://bop.felk.cvut.cz/leaderboards/pose-estimation-bop19/bop-classic-core/</a>,
BOP: Benchmark for 6D Object Pose Estimation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
T. Pöllabauer, J. Emrich, V. Knauthe, and A. Kuijper, “Extending 6d object
pose estimators for stereo vision,” <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2402.05610</em>,
2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Z. Ge, S. Liu, F. Wang, Z. Li, and J. Sun, “Yolox: Exceeding yolo series in
2021,” <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">ArXiv</em>, vol. abs/2107.08430, 2021. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:236088010" title="">https://api.semanticscholar.org/CorpusID:236088010</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
M. Denninger, M. Sundermeyer, D. Winkelbauer, D. Olefir, T. Hodan, Y. Zidan,
M. Elbadrawy, M. Knauer, H. Katam, and A. Lodhi, “Blenderproc: Reducing the
reality gap with photorealistic rendering,” in <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">International
Conference on Robotics: Sciene and Systems, RSS 2020</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
L. Wright, “Ranger - a synergistic optimizer.”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer" title="">https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer</a>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
BOP: Benchmark for 6D Object Pose Estimation, “SurfEmb BOP results,”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bop.felk.cvut.cz/method_info/180/" title="">https://bop.felk.cvut.cz/method_info/180/</a>, accessed on 2023-12-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
——, “GDRNPP BOP results,”
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bop.felk.cvut.cz/method_info/286/" title="">https://bop.felk.cvut.cz/method_info/286/</a>, accessed on 2023-12-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
E. Brachmann, A. Krull, F. Michel, S. Gumhold, J. Shotton, and C. Rother,
“Learning 6d object pose estimation using 3d object coordinates,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Computer Vision–ECCV 2014: 13th European Conference, Zurich,
Switzerland, September 6-12, 2014, Proceedings, Part II 13</em>.   Springer, 2014, pp. 536–551.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
T. Hodaň, P. Haluza, Š. Obdržálek, J. Matas, M. Lourakis,
and X. Zabulis, “T-LESS: An RGB-D dataset for 6D pose estimation of
texture-less objects,” <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">IEEE Winter Conference on Applications of
Computer Vision (WACV)</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
B. Drost, M. Ulrich, P. Bergmann, P. Härtinger, and C. Steger, “Introducing
mvtec itodd — a dataset for 3d object recognition in industry,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">2017 IEEE International Conference on Computer Vision Workshops
(ICCVW)</em>, 2017, pp. 2200–2208.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 18 09:07:57 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
