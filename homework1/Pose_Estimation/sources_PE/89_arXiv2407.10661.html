<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs</title>
<!--Generated on Wed Sep 25 07:53:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.10661v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S1" title="In Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S2" title="In Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S2.SS1" title="In II Related Work â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Visual 6D Robot Pose Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S2.SS2" title="In II Related Work â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Self Supervised Learning for Visual Pose Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S2.SS3" title="In II Related Work â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">Weakly Supervised Learning in Computer Vision</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S3" title="In Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Method</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S3.SS1" title="In III Method â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Losses</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4" title="In Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Setup</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4.SS1" title="In IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4.SS2" title="In IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Training Strategies</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4.SS3" title="In IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Neural Network Training</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4.SS4" title="In IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic">Evaluation Metrics</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5" title="In Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS1" title="In V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">LED Pretext Task Learns Robot Detection Without Labels</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS2" title="In V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">LED Pretext Task Transfers Well to Pose Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS3" title="In V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">LED Pretext Task Captures Robot Heading</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS4" title="In V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">LED Pretext Task is Robust to Images Without Robots</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS5" title="In V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span> </span><span class="ltx_text ltx_font_italic">LED Pretext Task Generalizes to Unseen Environments</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S6" title="In Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusions</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">Learning to Estimate the Pose of a Peer Robot in a Camera Image
<br class="ltx_break"/>by Predicting the States of its LEDs
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nicholas Carlotti<sup class="ltx_sup" id="id5.5.id1"><span class="ltx_text ltx_font_italic" id="id5.5.id1.1">1</span></sup>, Mirko Nava<sup class="ltx_sup" id="id6.6.id2"><span class="ltx_text ltx_font_italic" id="id6.6.id2.1">1</span></sup>, and Alessandro Giusti<sup class="ltx_sup" id="id7.7.id3"><span class="ltx_text ltx_font_italic" id="id7.7.id3.1">1</span></sup>
</span><span class="ltx_author_notes"><sup class="ltx_sup" id="id8.8.id1"><span class="ltx_text ltx_font_italic" id="id8.8.id1.1">1</span></sup>All authors are with the Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, 6962, Switzerland <span class="ltx_text ltx_font_typewriter" id="id9.9.id2">nicholas.carlotti@idsia.ch</span>This work is supported by the Swiss National Science Foundation, grant number 213074.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id10.id1">We consider the problem of training a fully convolutional network to estimate the relative 6D pose of a robot given a camera image, when the robot is equipped with independent controllable LEDs placed in different parts of its body. The training data is composed by few (or zero) images labeled with a ground truth relative pose and many images labeled only with the true state (<span class="ltx_text ltx_font_smallcaps" id="id10.id1.1">on</span> or <span class="ltx_text ltx_font_smallcaps" id="id10.id1.2">off</span>) of each of the peer LEDs. The former data is expensive to acquire, requiring external infrastructure for tracking the two robots; the latter is cheap as it can be acquired by two unsupervised robots moving randomly and toggling their LEDs while sharing the true LED states via radio.
Training with the latter dataset on estimating the LEDsâ€™ state of the peer robot (<em class="ltx_emph ltx_font_italic" id="id10.id1.3">pretext task</em>) promotes learning the relative localization task (<em class="ltx_emph ltx_font_italic" id="id10.id1.4">end task</em>).
Experiments on real-world data acquired by two autonomous wheeled robots show that a model trained only on the pretext task successfully learns to localize a peer robot on the image plane; fine-tuning such model on the end task with few labeled images yields statistically significant improvements in 6D relative pose estimation with respect to baselines that do not use pretext-task pre-training, and alternative approaches.
Estimating the state of multiple independent LEDs promotes learning to estimate relative heading.
The approach works even when a large fraction of training images do not include the peer robot and generalizes well to unseen environments.</p>
</div>
<div class="ltx_para" id="p1">
<svg class="ltx_picture" height="66.72" id="p1.pic1" overflow="visible" version="1.1" width="604.52"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,66.72) matrix(1 0 0 -1 0 0) translate(-122.74,0) translate(0,-14.11) matrix(1.0 0.0 0.0 1.0 127.35 42.63)"><foreignobject height="57.5" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="595.3"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="p1.pic1.1.1.1.1" style="border-color: #000000;">
<span class="ltx_inline-block ltx_parbox ltx_align_middle" id="p1.pic1.1.1.1.1.1" style="width:430.2pt;">
<span class="ltx_p" id="p1.pic1.1.1.1.1.1.1"><span class="ltx_text" id="p1.pic1.1.1.1.1.1.1.1" style="font-size:80%;">Â©2024 IEEE. Personal use of this material is permitted.
Permission from IEEE must be obtained for all other uses, in any current or future
media, including reprinting/republishing this material for advertising or promotional
purposes, creating new collective works, for resale or redistribution to servers or
lists, or reuse of any copyrighted component of this work in other works.</span></span>
</span></span></foreignobject></g></svg>
</div>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Supplementary Material</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Videos, dataset and code of the proposed approach are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/idsia-robotics/ssl-pretext-multi-led" style="font-size:90%;" title="">https://github.com/idsia-robotics/ssl-pretext-multi-led</a><span class="ltx_text" id="Sx1.p1.1.1" style="font-size:90%;">.</span></p>
</div>
</section>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><span class="ltx_text" id="S1.p1.1.1" style="font-size:90%;">Estimating the relative pose of a peer robot is a key capability for multi-robot systemsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib1" title="">1</a><span class="ltx_text" id="S1.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.4" style="font-size:90%;">, with wide-ranging applications spanning surveillanceÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib3" title="">3</a><span class="ltx_text" id="S1.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.7" style="font-size:90%;">, surveying or explorationÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib5" title="">5</a><span class="ltx_text" id="S1.p1.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.10" style="font-size:90%;">, acrobatic and light showsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.11.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib8" title="">8</a><span class="ltx_text" id="S1.p1.1.12.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.13" style="font-size:90%;">.
Solving the problem using visual inputs typically involves training a convolutional neural network with images and associated ground truth labels, representing the true relative pose of the peer robot. Collecting such a dataset can be expensive: generating ground truth labels requires specialized tracking hardware, e.g., often a fixed infrastructure; at the same time, generalizing to different environments and conditions requires training with a dataset that is large and varied.
To minimize the need for expensive labeled training data for the pose estimation task, i.e., our </span><em class="ltx_emph ltx_font_italic" id="S1.p1.1.14" style="font-size:90%;">end task</em><span class="ltx_text" id="S1.p1.1.15" style="font-size:90%;">, one can train the model to solve an auxiliary </span><em class="ltx_emph ltx_font_italic" id="S1.p1.1.16" style="font-size:90%;">pretext task</em><span class="ltx_text" id="S1.p1.1.17" style="font-size:90%;">Â </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.18.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib9" title="">9</a><span class="ltx_text" id="S1.p1.1.19.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.20" style="font-size:90%;">. A good pretext task has two distinctive characteristics: it promotes learning visual features that are relevant to the end task and uses ground truth labels that are easy to collect.</span></p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1"><span class="ltx_text" id="S1.p2.1.1" style="font-size:90%;">In previous work </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib10" title="">10</a><span class="ltx_text" id="S1.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p2.1.4" style="font-size:90%;">, we have shown that learning to estimate the shared boolean state of the LEDs on the peer robot (being either all turned on, or all off) is an effective pretext task to learn the end task of 2D localization of the peer robot in the image plane, also called detection in the literature.
This pretext task entails a powerful idea: predicting whether the peer robotâ€™s LEDs are on or off given an image requires understanding where the peer robot is in the image.
The task can be trained using images labeled only with the true state of the peer robotâ€™s LEDs; this data is easy to get from a collaborative peer, e.g., via radio, and large datasets can be collected autonomously by the pair of robots in any environment, without the need for external infrastructure or supervision.</span></p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="694" id="S1.F1.g1" src="x1.png" width="1196"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A DJI RoboMaster S1 visually estimating the relative pose of a peer robot, using a model trained on an autonomously-collected dataset in which the four LED states of its peer robot are known for all images; instead, the true relative pose of its peer is known in few, or even zero images.</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text" id="S1.p3.1.1" style="font-size:90%;">This paper extends our previous work </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib10" title="">10</a><span class="ltx_text" id="S1.p3.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.4" style="font-size:90%;"> in multiple directions.
We show that the pretext task alone, </span><em class="ltx_emph ltx_font_italic" id="S1.p3.1.5" style="font-size:90%;">without any labels for the end task</em><span class="ltx_text" id="S1.p3.1.6" style="font-size:90%;">, leads to the model learning to localize the peer robot on the image plane. This is due to the inductive bias induced by our fully convolutional networkÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.7.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib11" title="">11</a><span class="ltx_text" id="S1.p3.1.8.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.9" style="font-size:90%;"> architecture. It predicts the state of an LED as the weighted average of an output LED state map while the weights are given by an output robot position map. This weighting can be seen as an attention mechanism exploited for localization, similar to weakly supervised learning for object localizationÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.10.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib12" title="">12</a><span class="ltx_text" id="S1.p3.1.11.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.12" style="font-size:90%;">, but using autonomously-collected LED state labels instead of semantic labels.
Instead of a single state shared by all of the peerâ€™s LEDs, our pretext task estimates </span><em class="ltx_emph ltx_font_italic" id="S1.p3.1.13" style="font-size:90%;">four independent states</em><span class="ltx_text" id="S1.p3.1.14" style="font-size:90%;">, one for each LED placed on a different side of the peer robot, as shown in FigureÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S1.F1" style="font-size:90%;" title="Figure 1 â€£ I Introduction â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S1.p3.1.15" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text" id="S1.p4.1.1" style="font-size:90%;">Solving the pretext task requires not only help to localize the peer in the image but also to understand its relative orientation, as shown in FigureÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S1.F2" style="font-size:90%;" title="Figure 2 â€£ I Introduction â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S1.p4.1.2" style="font-size:90%;">.
Experiments confirm that the proposed pretext task helps to learn to estimate the peerâ€™s relative orientation.
Further, previous workÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p4.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib10" title="">10</a><span class="ltx_text" id="S1.p4.1.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p4.1.5" style="font-size:90%;"> only considered the position of the peer robot in the image and assumed it to be always visible in images used to train the pretext task; here, we estimate the 6D relative pose of the peer and also consider the two robots autonomously collecting training data while roaming a confined environment: less than a quarter of the resulting images have the peer robot visible at all, with each LED being visible only for 8% of images.
We show that the pretext task is effective in this challenging but realistic case.</span></p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text" id="S1.p5.1.1" style="font-size:90%;">Our </span><span class="ltx_text ltx_font_bold" id="S1.p5.1.2" style="font-size:90%;">main</span><span class="ltx_text" id="S1.p5.1.3" style="font-size:90%;"> contribution is the improved methodology for an LED-based pretext task, presented in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S3" style="font-size:90%;" title="III Method â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">III</span></a><span class="ltx_text" id="S1.p5.1.4" style="font-size:90%;">. We extensively validate our approach on real-world data on the task of estimating the pose of a wheeled ground robot from the feed of an RGB monocular camera in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4" style="font-size:90%;" title="IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">IV</span></a><span class="ltx_text" id="S1.p5.1.5" style="font-size:90%;">.
Results, reported in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5" style="font-size:90%;" title="V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">V</span></a><span class="ltx_text" id="S1.p5.1.6" style="font-size:90%;">, show the ability of the robot to localize its peer without training on ground truth pose labels, and significant improvements when the model trained on the pretext task is fine-tuned for the end task on 10, 100 or 1000 labeled images; compared to a baseline that does not use the pretext task, and to a baseline trained on CLIPÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p5.1.7.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib13" title="">13</a><span class="ltx_text" id="S1.p5.1.8.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p5.1.9" style="font-size:90%;"> features, our approach significantly improves performance on 2D image localization, relative orientation estimation, and 3D pose estimation. As a </span><span class="ltx_text ltx_font_bold" id="S1.p5.1.10" style="font-size:90%;">secondary</span><span class="ltx_text" id="S1.p5.1.11" style="font-size:90%;"> contribution, we release the code and real-world dataset used for our experiments. Finally, we conclude the article and describe future work directions in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S6" style="font-size:90%;" title="VI Conclusions â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">VI</span></a><span class="ltx_text" id="S1.p5.1.12" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="337" id="S1.F2.g1" src="extracted/5878331/fig/fcn.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Our fully convolutional network model takes an image as input and predicts maps for the robotâ€™s image space position <math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S1.F2.11.m1.1"><semantics id="S1.F2.11.m1.1b"><mover accent="true" id="S1.F2.11.m1.1.1" xref="S1.F2.11.m1.1.1.cmml"><mi id="S1.F2.11.m1.1.1.2" xref="S1.F2.11.m1.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S1.F2.11.m1.1.1.1" mathvariant="bold" xref="S1.F2.11.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.11.m1.1c"><apply id="S1.F2.11.m1.1.1.cmml" xref="S1.F2.11.m1.1.1"><ci id="S1.F2.11.m1.1.1.1.cmml" xref="S1.F2.11.m1.1.1.1">bold-^</ci><ci id="S1.F2.11.m1.1.1.2.cmml" xref="S1.F2.11.m1.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.11.m1.1d">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.11.m1.1e">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math>, distance <math alttext="\bm{\hat{D}}" class="ltx_Math" display="inline" id="S1.F2.12.m2.1"><semantics id="S1.F2.12.m2.1b"><mover accent="true" id="S1.F2.12.m2.1.1" xref="S1.F2.12.m2.1.1.cmml"><mi id="S1.F2.12.m2.1.1.2" xref="S1.F2.12.m2.1.1.2.cmml">ğ‘«</mi><mo class="ltx_mathvariant_bold" id="S1.F2.12.m2.1.1.1" mathvariant="bold" xref="S1.F2.12.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.12.m2.1c"><apply id="S1.F2.12.m2.1.1.cmml" xref="S1.F2.12.m2.1.1"><ci id="S1.F2.12.m2.1.1.1.cmml" xref="S1.F2.12.m2.1.1.1">bold-^</ci><ci id="S1.F2.12.m2.1.1.2.cmml" xref="S1.F2.12.m2.1.1.2">ğ‘«</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.12.m2.1d">\bm{\hat{D}}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.12.m2.1e">overbold_^ start_ARG bold_italic_D end_ARG</annotation></semantics></math>, orientation <math alttext="\bm{\hat{O}}" class="ltx_Math" display="inline" id="S1.F2.13.m3.1"><semantics id="S1.F2.13.m3.1b"><mover accent="true" id="S1.F2.13.m3.1.1" xref="S1.F2.13.m3.1.1.cmml"><mi id="S1.F2.13.m3.1.1.2" xref="S1.F2.13.m3.1.1.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S1.F2.13.m3.1.1.1" mathvariant="bold" xref="S1.F2.13.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.13.m3.1c"><apply id="S1.F2.13.m3.1.1.cmml" xref="S1.F2.13.m3.1.1"><ci id="S1.F2.13.m3.1.1.1.cmml" xref="S1.F2.13.m3.1.1.1">bold-^</ci><ci id="S1.F2.13.m3.1.1.2.cmml" xref="S1.F2.13.m3.1.1.2">ğ‘¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.13.m3.1d">\bm{\hat{O}}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.13.m3.1e">overbold_^ start_ARG bold_italic_O end_ARG</annotation></semantics></math> and state of the LEDs <math alttext="\bm{\hat{L}}_{i}" class="ltx_Math" display="inline" id="S1.F2.14.m4.1"><semantics id="S1.F2.14.m4.1b"><msub id="S1.F2.14.m4.1.1" xref="S1.F2.14.m4.1.1.cmml"><mover accent="true" id="S1.F2.14.m4.1.1.2" xref="S1.F2.14.m4.1.1.2.cmml"><mi id="S1.F2.14.m4.1.1.2.2" xref="S1.F2.14.m4.1.1.2.2.cmml">ğ‘³</mi><mo class="ltx_mathvariant_bold" id="S1.F2.14.m4.1.1.2.1" mathvariant="bold" xref="S1.F2.14.m4.1.1.2.1.cmml">^</mo></mover><mi id="S1.F2.14.m4.1.1.3" xref="S1.F2.14.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F2.14.m4.1c"><apply id="S1.F2.14.m4.1.1.cmml" xref="S1.F2.14.m4.1.1"><csymbol cd="ambiguous" id="S1.F2.14.m4.1.1.1.cmml" xref="S1.F2.14.m4.1.1">subscript</csymbol><apply id="S1.F2.14.m4.1.1.2.cmml" xref="S1.F2.14.m4.1.1.2"><ci id="S1.F2.14.m4.1.1.2.1.cmml" xref="S1.F2.14.m4.1.1.2.1">bold-^</ci><ci id="S1.F2.14.m4.1.1.2.2.cmml" xref="S1.F2.14.m4.1.1.2.2">ğ‘³</ci></apply><ci id="S1.F2.14.m4.1.1.3.cmml" xref="S1.F2.14.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.14.m4.1d">\bm{\hat{L}}_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.14.m4.1e">overbold_^ start_ARG bold_italic_L end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. We obtain scalar values from the maps by element-wise multiplication (denoted as <math alttext="\circ" class="ltx_Math" display="inline" id="S1.F2.15.m5.1"><semantics id="S1.F2.15.m5.1b"><mo id="S1.F2.15.m5.1.1" xref="S1.F2.15.m5.1.1.cmml">âˆ˜</mo><annotation-xml encoding="MathML-Content" id="S1.F2.15.m5.1c"><compose id="S1.F2.15.m5.1.1.cmml" xref="S1.F2.15.m5.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.15.m5.1d">\circ</annotation><annotation encoding="application/x-llamapun" id="S1.F2.15.m5.1e">âˆ˜</annotation></semantics></math>) with <math alttext="norm(\bm{\hat{P}})" class="ltx_Math" display="inline" id="S1.F2.16.m6.1"><semantics id="S1.F2.16.m6.1b"><mrow id="S1.F2.16.m6.1.2" xref="S1.F2.16.m6.1.2.cmml"><mi id="S1.F2.16.m6.1.2.2" xref="S1.F2.16.m6.1.2.2.cmml">n</mi><mo id="S1.F2.16.m6.1.2.1" xref="S1.F2.16.m6.1.2.1.cmml">â¢</mo><mi id="S1.F2.16.m6.1.2.3" xref="S1.F2.16.m6.1.2.3.cmml">o</mi><mo id="S1.F2.16.m6.1.2.1b" xref="S1.F2.16.m6.1.2.1.cmml">â¢</mo><mi id="S1.F2.16.m6.1.2.4" xref="S1.F2.16.m6.1.2.4.cmml">r</mi><mo id="S1.F2.16.m6.1.2.1c" xref="S1.F2.16.m6.1.2.1.cmml">â¢</mo><mi id="S1.F2.16.m6.1.2.5" xref="S1.F2.16.m6.1.2.5.cmml">m</mi><mo id="S1.F2.16.m6.1.2.1d" xref="S1.F2.16.m6.1.2.1.cmml">â¢</mo><mrow id="S1.F2.16.m6.1.2.6.2" xref="S1.F2.16.m6.1.1.cmml"><mo id="S1.F2.16.m6.1.2.6.2.1" stretchy="false" xref="S1.F2.16.m6.1.1.cmml">(</mo><mover accent="true" id="S1.F2.16.m6.1.1" xref="S1.F2.16.m6.1.1.cmml"><mi id="S1.F2.16.m6.1.1.2" xref="S1.F2.16.m6.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S1.F2.16.m6.1.1.1" mathvariant="bold" xref="S1.F2.16.m6.1.1.1.cmml">^</mo></mover><mo id="S1.F2.16.m6.1.2.6.2.2" stretchy="false" xref="S1.F2.16.m6.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F2.16.m6.1c"><apply id="S1.F2.16.m6.1.2.cmml" xref="S1.F2.16.m6.1.2"><times id="S1.F2.16.m6.1.2.1.cmml" xref="S1.F2.16.m6.1.2.1"></times><ci id="S1.F2.16.m6.1.2.2.cmml" xref="S1.F2.16.m6.1.2.2">ğ‘›</ci><ci id="S1.F2.16.m6.1.2.3.cmml" xref="S1.F2.16.m6.1.2.3">ğ‘œ</ci><ci id="S1.F2.16.m6.1.2.4.cmml" xref="S1.F2.16.m6.1.2.4">ğ‘Ÿ</ci><ci id="S1.F2.16.m6.1.2.5.cmml" xref="S1.F2.16.m6.1.2.5">ğ‘š</ci><apply id="S1.F2.16.m6.1.1.cmml" xref="S1.F2.16.m6.1.2.6.2"><ci id="S1.F2.16.m6.1.1.1.cmml" xref="S1.F2.16.m6.1.1.1">bold-^</ci><ci id="S1.F2.16.m6.1.1.2.cmml" xref="S1.F2.16.m6.1.1.2">ğ‘·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.16.m6.1d">norm(\bm{\hat{P}})</annotation><annotation encoding="application/x-llamapun" id="S1.F2.16.m6.1e">italic_n italic_o italic_r italic_m ( overbold_^ start_ARG bold_italic_P end_ARG )</annotation></semantics></math>, acting as an attention mechanism. By optimizing <math alttext="\hat{l}_{i}" class="ltx_Math" display="inline" id="S1.F2.17.m7.1"><semantics id="S1.F2.17.m7.1b"><msub id="S1.F2.17.m7.1.1" xref="S1.F2.17.m7.1.1.cmml"><mover accent="true" id="S1.F2.17.m7.1.1.2" xref="S1.F2.17.m7.1.1.2.cmml"><mi id="S1.F2.17.m7.1.1.2.2" xref="S1.F2.17.m7.1.1.2.2.cmml">l</mi><mo id="S1.F2.17.m7.1.1.2.1" xref="S1.F2.17.m7.1.1.2.1.cmml">^</mo></mover><mi id="S1.F2.17.m7.1.1.3" xref="S1.F2.17.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F2.17.m7.1c"><apply id="S1.F2.17.m7.1.1.cmml" xref="S1.F2.17.m7.1.1"><csymbol cd="ambiguous" id="S1.F2.17.m7.1.1.1.cmml" xref="S1.F2.17.m7.1.1">subscript</csymbol><apply id="S1.F2.17.m7.1.1.2.cmml" xref="S1.F2.17.m7.1.1.2"><ci id="S1.F2.17.m7.1.1.2.1.cmml" xref="S1.F2.17.m7.1.1.2.1">^</ci><ci id="S1.F2.17.m7.1.1.2.2.cmml" xref="S1.F2.17.m7.1.1.2.2">ğ‘™</ci></apply><ci id="S1.F2.17.m7.1.1.3.cmml" xref="S1.F2.17.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.17.m7.1d">\hat{l}_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.17.m7.1e">over^ start_ARG italic_l end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, the model learns to estimate the robotâ€™s LED state and position in the image; gradients for <math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S1.F2.18.m8.1"><semantics id="S1.F2.18.m8.1b"><mover accent="true" id="S1.F2.18.m8.1.1" xref="S1.F2.18.m8.1.1.cmml"><mi id="S1.F2.18.m8.1.1.2" xref="S1.F2.18.m8.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S1.F2.18.m8.1.1.1" mathvariant="bold" xref="S1.F2.18.m8.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.18.m8.1c"><apply id="S1.F2.18.m8.1.1.cmml" xref="S1.F2.18.m8.1.1"><ci id="S1.F2.18.m8.1.1.1.cmml" xref="S1.F2.18.m8.1.1.1">bold-^</ci><ci id="S1.F2.18.m8.1.1.2.cmml" xref="S1.F2.18.m8.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.18.m8.1d">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.18.m8.1e">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math> resulting from the optimization of <math alttext="\hat{d}" class="ltx_Math" display="inline" id="S1.F2.19.m9.1"><semantics id="S1.F2.19.m9.1b"><mover accent="true" id="S1.F2.19.m9.1.1" xref="S1.F2.19.m9.1.1.cmml"><mi id="S1.F2.19.m9.1.1.2" xref="S1.F2.19.m9.1.1.2.cmml">d</mi><mo id="S1.F2.19.m9.1.1.1" xref="S1.F2.19.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.19.m9.1c"><apply id="S1.F2.19.m9.1.1.cmml" xref="S1.F2.19.m9.1.1"><ci id="S1.F2.19.m9.1.1.1.cmml" xref="S1.F2.19.m9.1.1.1">^</ci><ci id="S1.F2.19.m9.1.1.2.cmml" xref="S1.F2.19.m9.1.1.2">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.19.m9.1d">\hat{d}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.19.m9.1e">over^ start_ARG italic_d end_ARG</annotation></semantics></math> and <math alttext="\hat{\psi}" class="ltx_Math" display="inline" id="S1.F2.20.m10.1"><semantics id="S1.F2.20.m10.1b"><mover accent="true" id="S1.F2.20.m10.1.1" xref="S1.F2.20.m10.1.1.cmml"><mi id="S1.F2.20.m10.1.1.2" xref="S1.F2.20.m10.1.1.2.cmml">Ïˆ</mi><mo id="S1.F2.20.m10.1.1.1" xref="S1.F2.20.m10.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S1.F2.20.m10.1c"><apply id="S1.F2.20.m10.1.1.cmml" xref="S1.F2.20.m10.1.1"><ci id="S1.F2.20.m10.1.1.1.cmml" xref="S1.F2.20.m10.1.1.1">^</ci><ci id="S1.F2.20.m10.1.1.2.cmml" xref="S1.F2.20.m10.1.1.2">ğœ“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.20.m10.1d">\hat{\psi}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.20.m10.1e">over^ start_ARG italic_Ïˆ end_ARG</annotation></semantics></math> are blocked (see Section <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S3.SS1" title="III-A Losses â€£ III Method â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a> for details).</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">Visual 6D Robot Pose Estimation</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text" id="S2.SS1.p1.1.1" style="font-size:90%;">Visual robot pose estimation problems are solved using hand-craftedÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib15" title="">15</a><span class="ltx_text" id="S2.SS1.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.4" style="font-size:90%;"> or learnedÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib17" title="">17</a><span class="ltx_text" id="S2.SS1.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.7" style="font-size:90%;"> features.
Hand-crafted approaches propose algorithms to extract geometrical features of either paper-printed patterns </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib14" title="">14</a><span class="ltx_text" id="S2.SS1.p1.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.10" style="font-size:90%;"> or fiducial markers </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.11.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib6" title="">6</a><span class="ltx_text" id="S2.SS1.p1.1.12.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.13" style="font-size:90%;"> and process them to reconstruct the pose of the robot relative to the camera.
In the absence of markers or patterns, Yu et al.Â </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.14.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib15" title="">15</a><span class="ltx_text" id="S2.SS1.p1.1.15.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.16" style="font-size:90%;"> leverage dense information from an RGB-D camera to extract features and then localize the robot.
However, these techniques do not generalize to environmental settings not conceived at design time.
To address this limitation, practitioners resort to deep neural networks; these models are used for pose estimation of a robot armâ€™s joints by predicting keypointsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.17.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib16" title="">16</a><span class="ltx_text" id="S2.SS1.p1.1.18.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.19" style="font-size:90%;">, and further optimize the keypoint placementÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.20.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib17" title="">17</a><span class="ltx_text" id="S2.SS1.p1.1.21.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.22" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text" id="S2.SS1.p2.1.1" style="font-size:90%;">Our approach uses a self-supervised pretext task to train a deep neural network model, learning relevant visual features and enabling relative pose estimation of a peer robot given a single image.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.5.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.6.2">Self Supervised Learning for Visual Pose Estimation</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text" id="S2.SS2.p1.1.1" style="font-size:90%;">Training neural networks to solve complex visual tasks requires a large amount of labeled data.
Labeling this data is often expensive and time-consuming, involving specialized tracking hardware or tedious hand-labeling.
This issue is tackled by self-supervised learning techniques, where an autonomous robot collects its own training dataÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib20" title="">20</a><span class="ltx_text" id="S2.SS2.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.4" style="font-size:90%;"> and uses it to train on a pretext task, learning features that are useful for solving perception problemsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib22" title="">22</a><span class="ltx_text" id="S2.SS2.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.7" style="font-size:90%;">.
Automated data collection with a robot arm involves recording interactions with objects and the view of the scene, later used to learn object featuresÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib18" title="">18</a><span class="ltx_text" id="S2.SS2.p1.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.10" style="font-size:90%;"> or its pose, starting from models pre-trained in simulation and fine-tuned on real dataÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.11.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib19" title="">19</a><span class="ltx_text" id="S2.SS2.p1.1.12.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.13" style="font-size:90%;">.
Nano-droneâ€™s poses are estimated from monocular cameras, training on labels generated from ultra-wide band sensorsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.14.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib20" title="">20</a><span class="ltx_text" id="S2.SS2.p1.1.15.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.16" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text" id="S2.SS2.p2.1.1" style="font-size:90%;">Approaches that rely on a pretext task in robotics use masked autoencoders to learn object pose estimation and manipulationÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib21" title="">21</a><span class="ltx_text" id="S2.SS2.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p2.1.4" style="font-size:90%;">;
improve the detection of a drone by solving the pretext task of estimating the sound produced by its rotorsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p2.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib22" title="">22</a><span class="ltx_text" id="S2.SS2.p2.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p2.1.7" style="font-size:90%;">;
or the shared state of the droneâ€™s LEDsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p2.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib10" title="">10</a><span class="ltx_text" id="S2.SS2.p2.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p2.1.10" style="font-size:90%;">, which are assumed to be either all on or off.
In contrast, the present work estimates the independent state of multiple robot-mounted LEDs: which of these are actually visible depends on the robot relative orientation. This defines a more complex pretext task; learning to solve it leads to learning features that are informative not only for image-space localization, but also for estimating the relative orientation of the peer robot.</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text" id="S2.SS2.p3.1.1" style="font-size:90%;">Additionally, we demonstrate that our approach is robust to training with images that depict the robot infrequently, as it commonly occurs with a robot autonomously collecting data.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.5.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.6.2">Weakly Supervised Learning in Computer Vision</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1"><span class="ltx_text" id="S2.SS3.p1.1.1" style="font-size:90%;">In computer vision, weakly supervised learning focuses on reducing the need for lots of labeled examples for solving object localizationÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib12" title="">12</a><span class="ltx_text" id="S2.SS3.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p1.1.4" style="font-size:90%;"> and segmentationÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib23" title="">23</a><span class="ltx_text" id="S2.SS3.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p1.1.7" style="font-size:90%;"> tasks.
The general framework consists in training classification models using coarse image labels, e.g., the textual description of the subject of a picture;
by training on these labels, models learn to extract finer information, such as image segmentations, by analyzing neural network activations </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p1.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib25" title="">25</a><span class="ltx_text" id="S2.SS3.p1.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p1.1.10" style="font-size:90%;"> or employing feature clustering mechanisms </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p1.1.11.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib26" title="">26</a><span class="ltx_text" id="S2.SS3.p1.1.12.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p1.1.13" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text" id="S2.SS3.p2.1.1" style="font-size:90%;">The most notable approach that analyzes the networkâ€™s hidden state for segmentation is Class Activation Mapping (CAM)Â </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib27" title="">27</a><span class="ltx_text" id="S2.SS3.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.4" style="font-size:90%;">, and more recently Ablation-CAMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib28" title="">28</a><span class="ltx_text" id="S2.SS3.p2.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.7" style="font-size:90%;">.
These approaches use a trained image classifier to detect discriminative areas of the input image, i.e., those responsible for making the model predict the image class.
For Ablation-CAMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib28" title="">28</a><span class="ltx_text" id="S2.SS3.p2.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.10" style="font-size:90%;">, the activation maps are extracted with a gradient-free method, disabling feature maps and measuring its impact on the modelâ€™s output.
Another proposed solution modifies a pre-trained classifier to predict a class for a set of regions partitioning the input imageÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.11.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib29" title="">29</a><span class="ltx_text" id="S2.SS3.p2.1.12.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.13" style="font-size:90%;">.
The individual scores for every region are then combined to allow for the detection of objects of interest in the input image.
Semantic segmentation is achieved by training a fully convolutional network to predict image labels using a weak supervision lossÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.14.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib30" title="">30</a><span class="ltx_text" id="S2.SS3.p2.1.15.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.16" style="font-size:90%;">.
The loss enforces soft constraints based on the number of classes and number of elements within the class to improve segmentation results.
The introduction of attention mechanisms to visual modelsÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.17.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib25" title="">25</a><span class="ltx_text" id="S2.SS3.p2.1.18.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.19" style="font-size:90%;"> paved the way for novel weakly supervised segmentation approaches:
attention mechanism for convolutional neural networks have been proposed for segmenting images through the learning of classification tasksÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.20.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib32" title="">32</a><span class="ltx_text" id="S2.SS3.p2.1.21.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.22" style="font-size:90%;">;
while vision transformers segment images using a novel patch-based attention dropout layerÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p2.1.23.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib33" title="">33</a><span class="ltx_text" id="S2.SS3.p2.1.24.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p2.1.25" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text" id="S2.SS3.p3.1.1" style="font-size:90%;">The discussed approaches learn to detect objects in images by training on semantic class labels.
Here, instead, we employ the state of a robotâ€™s on-board LEDs as multi-class labels; this information can be easily collected by letting the robot broadcast the LEDsâ€™ state, enabling the automated collection of training data.
Further, our deep neural network model employs a soft attention mechanism:
it designates one feature map as a mask applied to the other feature maps to predict the LEDsâ€™ state. After training, this map is used to locate the robot in the image.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Method</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.10"><span class="ltx_text" id="S3.p1.10.1" style="font-size:90%;">We focus on relative visual robot localization tasks where the goal is to estimate the relative pose of a target robot w.r.t. the frame of a peer robot, called observer, using as input the feed of a monocular camera.
To this end, we train a deep learning model using collected data, consisting of samples </span><math alttext="\{\langle\bm{i}_{j},\bm{p}_{j},\bm{l}_{j}\rangle\}_{j=1}^{N}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><msubsup id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mrow id="S3.p1.1.m1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.1.1.2.cmml"><mo id="S3.p1.1.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.p1.1.m1.1.1.1.1.2.cmml">{</mo><mrow id="S3.p1.1.m1.1.1.1.1.1.1.3" xref="S3.p1.1.m1.1.1.1.1.1.1.4.cmml"><mo id="S3.p1.1.m1.1.1.1.1.1.1.3.4" maxsize="90%" minsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.4.cmml">âŸ¨</mo><msub id="S3.p1.1.m1.1.1.1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1.2.cmml">ğ’Š</mi><mi id="S3.p1.1.m1.1.1.1.1.1.1.1.1.3" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.p1.1.m1.1.1.1.1.1.1.3.5" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S3.p1.1.m1.1.1.1.1.1.1.2.2" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.p1.1.m1.1.1.1.1.1.1.2.2.2" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2.2.cmml">ğ’‘</mi><mi id="S3.p1.1.m1.1.1.1.1.1.1.2.2.3" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2.3.cmml">j</mi></msub><mo id="S3.p1.1.m1.1.1.1.1.1.1.3.6" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S3.p1.1.m1.1.1.1.1.1.1.3.3" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.p1.1.m1.1.1.1.1.1.1.3.3.2" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3.2.cmml">ğ’</mi><mi id="S3.p1.1.m1.1.1.1.1.1.1.3.3.3" mathsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3.3.cmml">j</mi></msub><mo id="S3.p1.1.m1.1.1.1.1.1.1.3.7" maxsize="90%" minsize="90%" xref="S3.p1.1.m1.1.1.1.1.1.1.4.cmml">âŸ©</mo></mrow><mo id="S3.p1.1.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.p1.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p1.1.m1.1.1.1.3" xref="S3.p1.1.m1.1.1.1.3.cmml"><mi id="S3.p1.1.m1.1.1.1.3.2" mathsize="90%" xref="S3.p1.1.m1.1.1.1.3.2.cmml">j</mi><mo id="S3.p1.1.m1.1.1.1.3.1" mathsize="90%" xref="S3.p1.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S3.p1.1.m1.1.1.1.3.3" mathsize="90%" xref="S3.p1.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p1.1.m1.1.1.3" mathsize="90%" xref="S3.p1.1.m1.1.1.3.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1">superscript</csymbol><apply id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1">subscript</csymbol><set id="S3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1"><list id="S3.p1.1.m1.1.1.1.1.1.1.4.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.3"><apply id="S3.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1.2">ğ’Š</ci><ci id="S3.p1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.p1.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.p1.1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2.2">ğ’‘</ci><ci id="S3.p1.1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.2.2.3">ğ‘—</ci></apply><apply id="S3.p1.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.p1.1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3.2">ğ’</ci><ci id="S3.p1.1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.3.3.3">ğ‘—</ci></apply></list></set><apply id="S3.p1.1.m1.1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.1.3"><eq id="S3.p1.1.m1.1.1.1.3.1.cmml" xref="S3.p1.1.m1.1.1.1.3.1"></eq><ci id="S3.p1.1.m1.1.1.1.3.2.cmml" xref="S3.p1.1.m1.1.1.1.3.2">ğ‘—</ci><cn id="S3.p1.1.m1.1.1.1.3.3.cmml" type="integer" xref="S3.p1.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\{\langle\bm{i}_{j},\bm{p}_{j},\bm{l}_{j}\rangle\}_{j=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">{ âŸ¨ bold_italic_i start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , bold_italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , bold_italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT âŸ© } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.2" style="font-size:90%;"> where </span><math alttext="\bm{i}\in\mathbb{R}^{whc}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" mathsize="90%" xref="S3.p1.2.m2.1.1.2.cmml">ğ’Š</mi><mo id="S3.p1.2.m2.1.1.1" mathsize="90%" xref="S3.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.3.2" mathsize="90%" xref="S3.p1.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml"><mi id="S3.p1.2.m2.1.1.3.3.2" mathsize="90%" xref="S3.p1.2.m2.1.1.3.3.2.cmml">w</mi><mo id="S3.p1.2.m2.1.1.3.3.1" xref="S3.p1.2.m2.1.1.3.3.1.cmml">â¢</mo><mi id="S3.p1.2.m2.1.1.3.3.3" mathsize="90%" xref="S3.p1.2.m2.1.1.3.3.3.cmml">h</mi><mo id="S3.p1.2.m2.1.1.3.3.1a" xref="S3.p1.2.m2.1.1.3.3.1.cmml">â¢</mo><mi id="S3.p1.2.m2.1.1.3.3.4" mathsize="90%" xref="S3.p1.2.m2.1.1.3.3.4.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><in id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></in><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ğ’Š</ci><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3"><times id="S3.p1.2.m2.1.1.3.3.1.cmml" xref="S3.p1.2.m2.1.1.3.3.1"></times><ci id="S3.p1.2.m2.1.1.3.3.2.cmml" xref="S3.p1.2.m2.1.1.3.3.2">ğ‘¤</ci><ci id="S3.p1.2.m2.1.1.3.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3.3">â„</ci><ci id="S3.p1.2.m2.1.1.3.3.4.cmml" xref="S3.p1.2.m2.1.1.3.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\bm{i}\in\mathbb{R}^{whc}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">bold_italic_i âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_w italic_h italic_c end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.3" style="font-size:90%;"> is the image of </span><math alttext="w\times h" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mrow id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" mathsize="90%" xref="S3.p1.3.m3.1.1.2.cmml">w</mi><mo id="S3.p1.3.m3.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.p1.3.m3.1.1.1.cmml">Ã—</mo><mi id="S3.p1.3.m3.1.1.3" mathsize="90%" xref="S3.p1.3.m3.1.1.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><times id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1"></times><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">ğ‘¤</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">w\times h</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_w Ã— italic_h</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.4" style="font-size:90%;"> pixels and </span><math alttext="c" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" mathsize="90%" xref="S3.p1.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">italic_c</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.5" style="font-size:90%;"> channels, </span><math alttext="\bm{p}\in SE(3)" class="ltx_Math" display="inline" id="S3.p1.5.m5.1"><semantics id="S3.p1.5.m5.1a"><mrow id="S3.p1.5.m5.1.2" xref="S3.p1.5.m5.1.2.cmml"><mi id="S3.p1.5.m5.1.2.2" mathsize="90%" xref="S3.p1.5.m5.1.2.2.cmml">ğ’‘</mi><mo id="S3.p1.5.m5.1.2.1" mathsize="90%" xref="S3.p1.5.m5.1.2.1.cmml">âˆˆ</mo><mrow id="S3.p1.5.m5.1.2.3" xref="S3.p1.5.m5.1.2.3.cmml"><mi id="S3.p1.5.m5.1.2.3.2" mathsize="90%" xref="S3.p1.5.m5.1.2.3.2.cmml">S</mi><mo id="S3.p1.5.m5.1.2.3.1" xref="S3.p1.5.m5.1.2.3.1.cmml">â¢</mo><mi id="S3.p1.5.m5.1.2.3.3" mathsize="90%" xref="S3.p1.5.m5.1.2.3.3.cmml">E</mi><mo id="S3.p1.5.m5.1.2.3.1a" xref="S3.p1.5.m5.1.2.3.1.cmml">â¢</mo><mrow id="S3.p1.5.m5.1.2.3.4.2" xref="S3.p1.5.m5.1.2.3.cmml"><mo id="S3.p1.5.m5.1.2.3.4.2.1" maxsize="90%" minsize="90%" xref="S3.p1.5.m5.1.2.3.cmml">(</mo><mn id="S3.p1.5.m5.1.1" mathsize="90%" xref="S3.p1.5.m5.1.1.cmml">3</mn><mo id="S3.p1.5.m5.1.2.3.4.2.2" maxsize="90%" minsize="90%" xref="S3.p1.5.m5.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><apply id="S3.p1.5.m5.1.2.cmml" xref="S3.p1.5.m5.1.2"><in id="S3.p1.5.m5.1.2.1.cmml" xref="S3.p1.5.m5.1.2.1"></in><ci id="S3.p1.5.m5.1.2.2.cmml" xref="S3.p1.5.m5.1.2.2">ğ’‘</ci><apply id="S3.p1.5.m5.1.2.3.cmml" xref="S3.p1.5.m5.1.2.3"><times id="S3.p1.5.m5.1.2.3.1.cmml" xref="S3.p1.5.m5.1.2.3.1"></times><ci id="S3.p1.5.m5.1.2.3.2.cmml" xref="S3.p1.5.m5.1.2.3.2">ğ‘†</ci><ci id="S3.p1.5.m5.1.2.3.3.cmml" xref="S3.p1.5.m5.1.2.3.3">ğ¸</ci><cn id="S3.p1.5.m5.1.1.cmml" type="integer" xref="S3.p1.5.m5.1.1">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">\bm{p}\in SE(3)</annotation><annotation encoding="application/x-llamapun" id="S3.p1.5.m5.1d">bold_italic_p âˆˆ italic_S italic_E ( 3 )</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.6" style="font-size:90%;"> is the 6D relative pose of the target robot consisting of </span><math alttext="\langle x,y,z,\varphi,\theta,\psi\rangle" class="ltx_Math" display="inline" id="S3.p1.6.m6.6"><semantics id="S3.p1.6.m6.6a"><mrow id="S3.p1.6.m6.6.7.2" xref="S3.p1.6.m6.6.7.1.cmml"><mo id="S3.p1.6.m6.6.7.2.1" maxsize="90%" minsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">âŸ¨</mo><mi id="S3.p1.6.m6.1.1" mathsize="90%" xref="S3.p1.6.m6.1.1.cmml">x</mi><mo id="S3.p1.6.m6.6.7.2.2" mathsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">,</mo><mi id="S3.p1.6.m6.2.2" mathsize="90%" xref="S3.p1.6.m6.2.2.cmml">y</mi><mo id="S3.p1.6.m6.6.7.2.3" mathsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">,</mo><mi id="S3.p1.6.m6.3.3" mathsize="90%" xref="S3.p1.6.m6.3.3.cmml">z</mi><mo id="S3.p1.6.m6.6.7.2.4" mathsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">,</mo><mi id="S3.p1.6.m6.4.4" mathsize="90%" xref="S3.p1.6.m6.4.4.cmml">Ï†</mi><mo id="S3.p1.6.m6.6.7.2.5" mathsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">,</mo><mi id="S3.p1.6.m6.5.5" mathsize="90%" xref="S3.p1.6.m6.5.5.cmml">Î¸</mi><mo id="S3.p1.6.m6.6.7.2.6" mathsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">,</mo><mi id="S3.p1.6.m6.6.6" mathsize="90%" xref="S3.p1.6.m6.6.6.cmml">Ïˆ</mi><mo id="S3.p1.6.m6.6.7.2.7" maxsize="90%" minsize="90%" xref="S3.p1.6.m6.6.7.1.cmml">âŸ©</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.6b"><list id="S3.p1.6.m6.6.7.1.cmml" xref="S3.p1.6.m6.6.7.2"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">ğ‘¥</ci><ci id="S3.p1.6.m6.2.2.cmml" xref="S3.p1.6.m6.2.2">ğ‘¦</ci><ci id="S3.p1.6.m6.3.3.cmml" xref="S3.p1.6.m6.3.3">ğ‘§</ci><ci id="S3.p1.6.m6.4.4.cmml" xref="S3.p1.6.m6.4.4">ğœ‘</ci><ci id="S3.p1.6.m6.5.5.cmml" xref="S3.p1.6.m6.5.5">ğœƒ</ci><ci id="S3.p1.6.m6.6.6.cmml" xref="S3.p1.6.m6.6.6">ğœ“</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.6c">\langle x,y,z,\varphi,\theta,\psi\rangle</annotation><annotation encoding="application/x-llamapun" id="S3.p1.6.m6.6d">âŸ¨ italic_x , italic_y , italic_z , italic_Ï† , italic_Î¸ , italic_Ïˆ âŸ©</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.7" style="font-size:90%;">, and </span><math alttext="\bm{l}\in\{\textsc{off},\textsc{on}\}^{k}" class="ltx_Math" display="inline" id="S3.p1.7.m7.2"><semantics id="S3.p1.7.m7.2a"><mrow id="S3.p1.7.m7.2.3" xref="S3.p1.7.m7.2.3.cmml"><mi id="S3.p1.7.m7.2.3.2" mathsize="90%" xref="S3.p1.7.m7.2.3.2.cmml">ğ’</mi><mo id="S3.p1.7.m7.2.3.1" mathsize="90%" xref="S3.p1.7.m7.2.3.1.cmml">âˆˆ</mo><msup id="S3.p1.7.m7.2.3.3" xref="S3.p1.7.m7.2.3.3.cmml"><mrow id="S3.p1.7.m7.2.3.3.2.2" xref="S3.p1.7.m7.2.3.3.2.1.cmml"><mo id="S3.p1.7.m7.2.3.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.p1.7.m7.2.3.3.2.1.cmml">{</mo><mtext class="ltx_font_smallcaps" id="S3.p1.7.m7.1.1" mathsize="90%" xref="S3.p1.7.m7.1.1a.cmml">off</mtext><mo id="S3.p1.7.m7.2.3.3.2.2.2" mathsize="90%" xref="S3.p1.7.m7.2.3.3.2.1.cmml">,</mo><mtext class="ltx_font_smallcaps" id="S3.p1.7.m7.2.2" mathsize="90%" xref="S3.p1.7.m7.2.2a.cmml">on</mtext><mo id="S3.p1.7.m7.2.3.3.2.2.3" maxsize="90%" minsize="90%" xref="S3.p1.7.m7.2.3.3.2.1.cmml">}</mo></mrow><mi id="S3.p1.7.m7.2.3.3.3" mathsize="90%" xref="S3.p1.7.m7.2.3.3.3.cmml">k</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.2b"><apply id="S3.p1.7.m7.2.3.cmml" xref="S3.p1.7.m7.2.3"><in id="S3.p1.7.m7.2.3.1.cmml" xref="S3.p1.7.m7.2.3.1"></in><ci id="S3.p1.7.m7.2.3.2.cmml" xref="S3.p1.7.m7.2.3.2">ğ’</ci><apply id="S3.p1.7.m7.2.3.3.cmml" xref="S3.p1.7.m7.2.3.3"><csymbol cd="ambiguous" id="S3.p1.7.m7.2.3.3.1.cmml" xref="S3.p1.7.m7.2.3.3">superscript</csymbol><set id="S3.p1.7.m7.2.3.3.2.1.cmml" xref="S3.p1.7.m7.2.3.3.2.2"><ci id="S3.p1.7.m7.1.1a.cmml" xref="S3.p1.7.m7.1.1"><mtext class="ltx_font_smallcaps" id="S3.p1.7.m7.1.1.cmml" mathsize="90%" xref="S3.p1.7.m7.1.1">off</mtext></ci><ci id="S3.p1.7.m7.2.2a.cmml" xref="S3.p1.7.m7.2.2"><mtext class="ltx_font_smallcaps" id="S3.p1.7.m7.2.2.cmml" mathsize="90%" xref="S3.p1.7.m7.2.2">on</mtext></ci></set><ci id="S3.p1.7.m7.2.3.3.3.cmml" xref="S3.p1.7.m7.2.3.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.2c">\bm{l}\in\{\textsc{off},\textsc{on}\}^{k}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.7.m7.2d">bold_italic_l âˆˆ { off , on } start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.8" style="font-size:90%;"> is the state of the robotâ€™s fitted LEDs consisting of </span><math alttext="\langle l_{1},\dots,l_{k}\rangle" class="ltx_Math" display="inline" id="S3.p1.8.m8.3"><semantics id="S3.p1.8.m8.3a"><mrow id="S3.p1.8.m8.3.3.2" xref="S3.p1.8.m8.3.3.3.cmml"><mo id="S3.p1.8.m8.3.3.2.3" maxsize="90%" minsize="90%" xref="S3.p1.8.m8.3.3.3.cmml">âŸ¨</mo><msub id="S3.p1.8.m8.2.2.1.1" xref="S3.p1.8.m8.2.2.1.1.cmml"><mi id="S3.p1.8.m8.2.2.1.1.2" mathsize="90%" xref="S3.p1.8.m8.2.2.1.1.2.cmml">l</mi><mn id="S3.p1.8.m8.2.2.1.1.3" mathsize="90%" xref="S3.p1.8.m8.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.p1.8.m8.3.3.2.4" mathsize="90%" xref="S3.p1.8.m8.3.3.3.cmml">,</mo><mi id="S3.p1.8.m8.1.1" mathsize="90%" mathvariant="normal" xref="S3.p1.8.m8.1.1.cmml">â€¦</mi><mo id="S3.p1.8.m8.3.3.2.5" mathsize="90%" xref="S3.p1.8.m8.3.3.3.cmml">,</mo><msub id="S3.p1.8.m8.3.3.2.2" xref="S3.p1.8.m8.3.3.2.2.cmml"><mi id="S3.p1.8.m8.3.3.2.2.2" mathsize="90%" xref="S3.p1.8.m8.3.3.2.2.2.cmml">l</mi><mi id="S3.p1.8.m8.3.3.2.2.3" mathsize="90%" xref="S3.p1.8.m8.3.3.2.2.3.cmml">k</mi></msub><mo id="S3.p1.8.m8.3.3.2.6" maxsize="90%" minsize="90%" xref="S3.p1.8.m8.3.3.3.cmml">âŸ©</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.3b"><list id="S3.p1.8.m8.3.3.3.cmml" xref="S3.p1.8.m8.3.3.2"><apply id="S3.p1.8.m8.2.2.1.1.cmml" xref="S3.p1.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.1.1.1.cmml" xref="S3.p1.8.m8.2.2.1.1">subscript</csymbol><ci id="S3.p1.8.m8.2.2.1.1.2.cmml" xref="S3.p1.8.m8.2.2.1.1.2">ğ‘™</ci><cn id="S3.p1.8.m8.2.2.1.1.3.cmml" type="integer" xref="S3.p1.8.m8.2.2.1.1.3">1</cn></apply><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">â€¦</ci><apply id="S3.p1.8.m8.3.3.2.2.cmml" xref="S3.p1.8.m8.3.3.2.2"><csymbol cd="ambiguous" id="S3.p1.8.m8.3.3.2.2.1.cmml" xref="S3.p1.8.m8.3.3.2.2">subscript</csymbol><ci id="S3.p1.8.m8.3.3.2.2.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2">ğ‘™</ci><ci id="S3.p1.8.m8.3.3.2.2.3.cmml" xref="S3.p1.8.m8.3.3.2.2.3">ğ‘˜</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.3c">\langle l_{1},\dots,l_{k}\rangle</annotation><annotation encoding="application/x-llamapun" id="S3.p1.8.m8.3d">âŸ¨ italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT âŸ©</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.9" style="font-size:90%;">.
Since our application involves a ground robot, </span><math alttext="\phi" class="ltx_Math" display="inline" id="S3.p1.9.m9.1"><semantics id="S3.p1.9.m9.1a"><mi id="S3.p1.9.m9.1.1" mathsize="90%" xref="S3.p1.9.m9.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.p1.9.m9.1d">italic_Ï•</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.10" style="font-size:90%;"> and </span><math alttext="\theta" class="ltx_Math" display="inline" id="S3.p1.10.m10.1"><semantics id="S3.p1.10.m10.1a"><mi id="S3.p1.10.m10.1.1" mathsize="90%" xref="S3.p1.10.m10.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><ci id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.p1.10.m10.1d">italic_Î¸</annotation></semantics></math><span class="ltx_text" id="S3.p1.10.11" style="font-size:90%;"> are assumed to be always zero.</span></p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.5"><span class="ltx_text" id="S3.p2.5.1" style="font-size:90%;">We consider scenarios where the ground truth labels for the relative robot pose might only be measurable in dedicated lab environments with specialized hardware, e.g., tracking systems, while in other environments, this information in unknown and collected images might not feature a visible robot.
As such, the collected samples are said to be labeled if they feature known relative robot poses or unlabeled otherwise.
Based on this notion, we define three disjoint sets: the labeled training set </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><msub id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.1.m1.1.1.2" mathsize="90%" xref="S3.p2.1.m1.1.1.2.cmml">ğ’¯</mi><mi id="S3.p2.1.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S3.p2.1.m1.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">ğ’¯</ci><ci id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p2.5.2" style="font-size:90%;"> containing a limited amount of labeled samples, the unlabeled training set </span><math alttext="\mathcal{T}_{u}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.2.m2.1.1.2" mathsize="90%" xref="S3.p2.2.m2.1.1.2.cmml">ğ’¯</mi><mi id="S3.p2.2.m2.1.1.3" mathsize="90%" xref="S3.p2.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ’¯</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">\mathcal{T}_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p2.5.3" style="font-size:90%;"> containing unlabeled samples, and the testing set </span><math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S3.p2.3.m3.1"><semantics id="S3.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p2.3.m3.1.1" mathsize="90%" xref="S3.p2.3.m3.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.1d">caligraphic_Q</annotation></semantics></math><span class="ltx_text" id="S3.p2.5.4" style="font-size:90%;"> containing labeled samples.
For our experiments, we additionally consider the subset of the unlabeled testing set having samples with the robot visible, named </span><math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S3.p2.4.m4.1"><semantics id="S3.p2.4.m4.1a"><msubsup id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.4.m4.1.1.2.2" mathsize="90%" xref="S3.p2.4.m4.1.1.2.2.cmml">ğ’¯</mi><mi id="S3.p2.4.m4.1.1.2.3" mathsize="90%" xref="S3.p2.4.m4.1.1.2.3.cmml">u</mi><mi id="S3.p2.4.m4.1.1.3" mathsize="90%" xref="S3.p2.4.m4.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1">superscript</csymbol><apply id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.2.1.cmml" xref="S3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.2.cmml" xref="S3.p2.4.m4.1.1.2.2">ğ’¯</ci><ci id="S3.p2.4.m4.1.1.2.3.cmml" xref="S3.p2.4.m4.1.1.2.3">ğ‘¢</ci></apply><ci id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p2.5.5" style="font-size:90%;">, and denote the full unlabeled set as </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S3.p2.5.m5.1"><semantics id="S3.p2.5.m5.1a"><msubsup id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.5.m5.1.1.2.2" mathsize="90%" xref="S3.p2.5.m5.1.1.2.2.cmml">ğ’¯</mi><mi id="S3.p2.5.m5.1.1.2.3" mathsize="90%" xref="S3.p2.5.m5.1.1.2.3.cmml">u</mi><mi id="S3.p2.5.m5.1.1.3" mathsize="90%" xref="S3.p2.5.m5.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1">superscript</csymbol><apply id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.2.1.cmml" xref="S3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.2.2.cmml" xref="S3.p2.5.m5.1.1.2.2">ğ’¯</ci><ci id="S3.p2.5.m5.1.1.2.3.cmml" xref="S3.p2.5.m5.1.1.2.3">ğ‘¢</ci></apply><ci id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p2.5.6" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.13"><span class="ltx_text" id="S3.p3.13.1" style="font-size:90%;">Using these samples, we learn a convolutional neural network </span><math alttext="\bm{m_{\theta}}(\bm{i})" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><mrow id="S3.p3.1.m1.1.2" xref="S3.p3.1.m1.1.2.cmml"><msub id="S3.p3.1.m1.1.2.2" xref="S3.p3.1.m1.1.2.2.cmml"><mi id="S3.p3.1.m1.1.2.2.2" mathsize="90%" xref="S3.p3.1.m1.1.2.2.2.cmml">ğ’</mi><mi id="S3.p3.1.m1.1.2.2.3" mathsize="90%" xref="S3.p3.1.m1.1.2.2.3.cmml">ğœ½</mi></msub><mo id="S3.p3.1.m1.1.2.1" xref="S3.p3.1.m1.1.2.1.cmml">â¢</mo><mrow id="S3.p3.1.m1.1.2.3.2" xref="S3.p3.1.m1.1.2.cmml"><mo id="S3.p3.1.m1.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.p3.1.m1.1.2.cmml">(</mo><mi id="S3.p3.1.m1.1.1" mathsize="90%" xref="S3.p3.1.m1.1.1.cmml">ğ’Š</mi><mo id="S3.p3.1.m1.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.2.cmml" xref="S3.p3.1.m1.1.2"><times id="S3.p3.1.m1.1.2.1.cmml" xref="S3.p3.1.m1.1.2.1"></times><apply id="S3.p3.1.m1.1.2.2.cmml" xref="S3.p3.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.2.2.1.cmml" xref="S3.p3.1.m1.1.2.2">subscript</csymbol><ci id="S3.p3.1.m1.1.2.2.2.cmml" xref="S3.p3.1.m1.1.2.2.2">ğ’</ci><ci id="S3.p3.1.m1.1.2.2.3.cmml" xref="S3.p3.1.m1.1.2.2.3">ğœ½</ci></apply><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">ğ’Š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\bm{m_{\theta}}(\bm{i})</annotation><annotation encoding="application/x-llamapun" id="S3.p3.1.m1.1d">bold_italic_m start_POSTSUBSCRIPT bold_italic_Î¸ end_POSTSUBSCRIPT ( bold_italic_i )</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.2" style="font-size:90%;"> parametrized by </span><math alttext="\bm{\theta}" class="ltx_Math" display="inline" id="S3.p3.2.m2.1"><semantics id="S3.p3.2.m2.1a"><mi id="S3.p3.2.m2.1.1" mathsize="90%" xref="S3.p3.2.m2.1.1.cmml">ğœ½</mi><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><ci id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">ğœ½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">\bm{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.2.m2.1d">bold_italic_Î¸</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.3" style="font-size:90%;"> and whose input is the image </span><math alttext="\bm{i}" class="ltx_Math" display="inline" id="S3.p3.3.m3.1"><semantics id="S3.p3.3.m3.1a"><mi id="S3.p3.3.m3.1.1" mathsize="90%" xref="S3.p3.3.m3.1.1.cmml">ğ’Š</mi><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><ci id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1">ğ’Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">\bm{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.3.m3.1d">bold_italic_i</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.4" style="font-size:90%;">.
The model learns to predict the image-space position of the robot on the horizontal </span><math alttext="u" class="ltx_Math" display="inline" id="S3.p3.4.m4.1"><semantics id="S3.p3.4.m4.1a"><mi id="S3.p3.4.m4.1.1" mathsize="90%" xref="S3.p3.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.1b"><ci id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.p3.4.m4.1d">italic_u</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.5" style="font-size:90%;"> and vertical </span><math alttext="v" class="ltx_Math" display="inline" id="S3.p3.5.m5.1"><semantics id="S3.p3.5.m5.1a"><mi id="S3.p3.5.m5.1.1" mathsize="90%" xref="S3.p3.5.m5.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.1b"><ci id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.p3.5.m5.1d">italic_v</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.6" style="font-size:90%;"> axes, also called 2D detection in the literature, the distance of the robot </span><math alttext="d" class="ltx_Math" display="inline" id="S3.p3.6.m6.1"><semantics id="S3.p3.6.m6.1a"><mi id="S3.p3.6.m6.1.1" mathsize="90%" xref="S3.p3.6.m6.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.p3.6.m6.1b"><ci id="S3.p3.6.m6.1.1.cmml" xref="S3.p3.6.m6.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.6.m6.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.p3.6.m6.1d">italic_d</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.7" style="font-size:90%;"> and its roll </span><math alttext="\varphi" class="ltx_Math" display="inline" id="S3.p3.7.m7.1"><semantics id="S3.p3.7.m7.1a"><mi id="S3.p3.7.m7.1.1" mathsize="90%" xref="S3.p3.7.m7.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.p3.7.m7.1b"><ci id="S3.p3.7.m7.1.1.cmml" xref="S3.p3.7.m7.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.7.m7.1c">\varphi</annotation><annotation encoding="application/x-llamapun" id="S3.p3.7.m7.1d">italic_Ï†</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.8" style="font-size:90%;">, pitch </span><math alttext="\theta" class="ltx_Math" display="inline" id="S3.p3.8.m8.1"><semantics id="S3.p3.8.m8.1a"><mi id="S3.p3.8.m8.1.1" mathsize="90%" xref="S3.p3.8.m8.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p3.8.m8.1b"><ci id="S3.p3.8.m8.1.1.cmml" xref="S3.p3.8.m8.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.8.m8.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.p3.8.m8.1d">italic_Î¸</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.9" style="font-size:90%;">, and yaw </span><math alttext="\psi" class="ltx_Math" display="inline" id="S3.p3.9.m9.1"><semantics id="S3.p3.9.m9.1a"><mi id="S3.p3.9.m9.1.1" mathsize="90%" xref="S3.p3.9.m9.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S3.p3.9.m9.1b"><ci id="S3.p3.9.m9.1.1.cmml" xref="S3.p3.9.m9.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.9.m9.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S3.p3.9.m9.1d">italic_Ïˆ</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.10" style="font-size:90%;"> rotation.
Given the camera intrinsics, we reconstruct the 3D position </span><math alttext="xyz" class="ltx_Math" display="inline" id="S3.p3.10.m10.1"><semantics id="S3.p3.10.m10.1a"><mrow id="S3.p3.10.m10.1.1" xref="S3.p3.10.m10.1.1.cmml"><mi id="S3.p3.10.m10.1.1.2" mathsize="90%" xref="S3.p3.10.m10.1.1.2.cmml">x</mi><mo id="S3.p3.10.m10.1.1.1" xref="S3.p3.10.m10.1.1.1.cmml">â¢</mo><mi id="S3.p3.10.m10.1.1.3" mathsize="90%" xref="S3.p3.10.m10.1.1.3.cmml">y</mi><mo id="S3.p3.10.m10.1.1.1a" xref="S3.p3.10.m10.1.1.1.cmml">â¢</mo><mi id="S3.p3.10.m10.1.1.4" mathsize="90%" xref="S3.p3.10.m10.1.1.4.cmml">z</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.10.m10.1b"><apply id="S3.p3.10.m10.1.1.cmml" xref="S3.p3.10.m10.1.1"><times id="S3.p3.10.m10.1.1.1.cmml" xref="S3.p3.10.m10.1.1.1"></times><ci id="S3.p3.10.m10.1.1.2.cmml" xref="S3.p3.10.m10.1.1.2">ğ‘¥</ci><ci id="S3.p3.10.m10.1.1.3.cmml" xref="S3.p3.10.m10.1.1.3">ğ‘¦</ci><ci id="S3.p3.10.m10.1.1.4.cmml" xref="S3.p3.10.m10.1.1.4">ğ‘§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.10.m10.1c">xyz</annotation><annotation encoding="application/x-llamapun" id="S3.p3.10.m10.1d">italic_x italic_y italic_z</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.11" style="font-size:90%;"> of the robot by projecting a ray passing through the </span><math alttext="uv" class="ltx_Math" display="inline" id="S3.p3.11.m11.1"><semantics id="S3.p3.11.m11.1a"><mrow id="S3.p3.11.m11.1.1" xref="S3.p3.11.m11.1.1.cmml"><mi id="S3.p3.11.m11.1.1.2" mathsize="90%" xref="S3.p3.11.m11.1.1.2.cmml">u</mi><mo id="S3.p3.11.m11.1.1.1" xref="S3.p3.11.m11.1.1.1.cmml">â¢</mo><mi id="S3.p3.11.m11.1.1.3" mathsize="90%" xref="S3.p3.11.m11.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.11.m11.1b"><apply id="S3.p3.11.m11.1.1.cmml" xref="S3.p3.11.m11.1.1"><times id="S3.p3.11.m11.1.1.1.cmml" xref="S3.p3.11.m11.1.1.1"></times><ci id="S3.p3.11.m11.1.1.2.cmml" xref="S3.p3.11.m11.1.1.2">ğ‘¢</ci><ci id="S3.p3.11.m11.1.1.3.cmml" xref="S3.p3.11.m11.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.11.m11.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S3.p3.11.m11.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.12" style="font-size:90%;"> pixel and selecting the point lying at distance </span><math alttext="d" class="ltx_Math" display="inline" id="S3.p3.12.m12.1"><semantics id="S3.p3.12.m12.1a"><mi id="S3.p3.12.m12.1.1" mathsize="90%" xref="S3.p3.12.m12.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.p3.12.m12.1b"><ci id="S3.p3.12.m12.1.1.cmml" xref="S3.p3.12.m12.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.12.m12.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.p3.12.m12.1d">italic_d</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.13" style="font-size:90%;"> from the camera.
As the architecture of choice, we propose a fully convolutional network (FCN) architectureÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.p3.13.14.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib11" title="">11</a><span class="ltx_text" id="S3.p3.13.15.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S3.p3.13.16" style="font-size:90%;">, being composed solely of convolution and pooling layers and producing maps of </span><math alttext="w^{\prime}\times h^{\prime}" class="ltx_Math" display="inline" id="S3.p3.13.m13.1"><semantics id="S3.p3.13.m13.1a"><mrow id="S3.p3.13.m13.1.1" xref="S3.p3.13.m13.1.1.cmml"><msup id="S3.p3.13.m13.1.1.2" xref="S3.p3.13.m13.1.1.2.cmml"><mi id="S3.p3.13.m13.1.1.2.2" mathsize="90%" xref="S3.p3.13.m13.1.1.2.2.cmml">w</mi><mo id="S3.p3.13.m13.1.1.2.3" mathsize="90%" xref="S3.p3.13.m13.1.1.2.3.cmml">â€²</mo></msup><mo id="S3.p3.13.m13.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.p3.13.m13.1.1.1.cmml">Ã—</mo><msup id="S3.p3.13.m13.1.1.3" xref="S3.p3.13.m13.1.1.3.cmml"><mi id="S3.p3.13.m13.1.1.3.2" mathsize="90%" xref="S3.p3.13.m13.1.1.3.2.cmml">h</mi><mo id="S3.p3.13.m13.1.1.3.3" mathsize="90%" xref="S3.p3.13.m13.1.1.3.3.cmml">â€²</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.13.m13.1b"><apply id="S3.p3.13.m13.1.1.cmml" xref="S3.p3.13.m13.1.1"><times id="S3.p3.13.m13.1.1.1.cmml" xref="S3.p3.13.m13.1.1.1"></times><apply id="S3.p3.13.m13.1.1.2.cmml" xref="S3.p3.13.m13.1.1.2"><csymbol cd="ambiguous" id="S3.p3.13.m13.1.1.2.1.cmml" xref="S3.p3.13.m13.1.1.2">superscript</csymbol><ci id="S3.p3.13.m13.1.1.2.2.cmml" xref="S3.p3.13.m13.1.1.2.2">ğ‘¤</ci><ci id="S3.p3.13.m13.1.1.2.3.cmml" xref="S3.p3.13.m13.1.1.2.3">â€²</ci></apply><apply id="S3.p3.13.m13.1.1.3.cmml" xref="S3.p3.13.m13.1.1.3"><csymbol cd="ambiguous" id="S3.p3.13.m13.1.1.3.1.cmml" xref="S3.p3.13.m13.1.1.3">superscript</csymbol><ci id="S3.p3.13.m13.1.1.3.2.cmml" xref="S3.p3.13.m13.1.1.3.2">â„</ci><ci id="S3.p3.13.m13.1.1.3.3.cmml" xref="S3.p3.13.m13.1.1.3.3">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.13.m13.1c">w^{\prime}\times h^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.13.m13.1d">italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT Ã— italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p3.13.17" style="font-size:90%;"> cells as the output.
We take full advantage of the inductive bias of FCNs, namely that a cellâ€™s value depends only on a portion of the input image based on the modelâ€™s receptive field, and that the weight-sharing of convolutions forces the model to recognize local patterns regardless of its location within the image.
Indeed, this helps the model to focus more on the robotâ€™s appearance and less on the background, and is a desirable property due to our expectation that the robot occupies a small portion of the field of view.</span></p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.14"><span class="ltx_text" id="S3.p4.14.1" style="font-size:90%;">The model produces estimates for the position map </span><math alttext="\bm{\hat{P}}\in[0,1]^{w^{\prime}h^{\prime}}" class="ltx_Math" display="inline" id="S3.p4.1.m1.2"><semantics id="S3.p4.1.m1.2a"><mrow id="S3.p4.1.m1.2.3" xref="S3.p4.1.m1.2.3.cmml"><mover accent="true" id="S3.p4.1.m1.2.3.2" xref="S3.p4.1.m1.2.3.2.cmml"><mi id="S3.p4.1.m1.2.3.2.2" mathsize="90%" xref="S3.p4.1.m1.2.3.2.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.p4.1.m1.2.3.2.1" mathsize="90%" mathvariant="bold" xref="S3.p4.1.m1.2.3.2.1.cmml">^</mo></mover><mo id="S3.p4.1.m1.2.3.1" mathsize="90%" xref="S3.p4.1.m1.2.3.1.cmml">âˆˆ</mo><msup id="S3.p4.1.m1.2.3.3" xref="S3.p4.1.m1.2.3.3.cmml"><mrow id="S3.p4.1.m1.2.3.3.2.2" xref="S3.p4.1.m1.2.3.3.2.1.cmml"><mo id="S3.p4.1.m1.2.3.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.p4.1.m1.2.3.3.2.1.cmml">[</mo><mn id="S3.p4.1.m1.1.1" mathsize="90%" xref="S3.p4.1.m1.1.1.cmml">0</mn><mo id="S3.p4.1.m1.2.3.3.2.2.2" mathsize="90%" xref="S3.p4.1.m1.2.3.3.2.1.cmml">,</mo><mn id="S3.p4.1.m1.2.2" mathsize="90%" xref="S3.p4.1.m1.2.2.cmml">1</mn><mo id="S3.p4.1.m1.2.3.3.2.2.3" maxsize="90%" minsize="90%" xref="S3.p4.1.m1.2.3.3.2.1.cmml">]</mo></mrow><mrow id="S3.p4.1.m1.2.3.3.3" xref="S3.p4.1.m1.2.3.3.3.cmml"><msup id="S3.p4.1.m1.2.3.3.3.2" xref="S3.p4.1.m1.2.3.3.3.2.cmml"><mi id="S3.p4.1.m1.2.3.3.3.2.2" mathsize="90%" xref="S3.p4.1.m1.2.3.3.3.2.2.cmml">w</mi><mo id="S3.p4.1.m1.2.3.3.3.2.3" mathsize="90%" xref="S3.p4.1.m1.2.3.3.3.2.3.cmml">â€²</mo></msup><mo id="S3.p4.1.m1.2.3.3.3.1" xref="S3.p4.1.m1.2.3.3.3.1.cmml">â¢</mo><msup id="S3.p4.1.m1.2.3.3.3.3" xref="S3.p4.1.m1.2.3.3.3.3.cmml"><mi id="S3.p4.1.m1.2.3.3.3.3.2" mathsize="90%" xref="S3.p4.1.m1.2.3.3.3.3.2.cmml">h</mi><mo id="S3.p4.1.m1.2.3.3.3.3.3" mathsize="90%" xref="S3.p4.1.m1.2.3.3.3.3.3.cmml">â€²</mo></msup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.2b"><apply id="S3.p4.1.m1.2.3.cmml" xref="S3.p4.1.m1.2.3"><in id="S3.p4.1.m1.2.3.1.cmml" xref="S3.p4.1.m1.2.3.1"></in><apply id="S3.p4.1.m1.2.3.2.cmml" xref="S3.p4.1.m1.2.3.2"><ci id="S3.p4.1.m1.2.3.2.1.cmml" xref="S3.p4.1.m1.2.3.2.1">bold-^</ci><ci id="S3.p4.1.m1.2.3.2.2.cmml" xref="S3.p4.1.m1.2.3.2.2">ğ‘·</ci></apply><apply id="S3.p4.1.m1.2.3.3.cmml" xref="S3.p4.1.m1.2.3.3"><csymbol cd="ambiguous" id="S3.p4.1.m1.2.3.3.1.cmml" xref="S3.p4.1.m1.2.3.3">superscript</csymbol><interval closure="closed" id="S3.p4.1.m1.2.3.3.2.1.cmml" xref="S3.p4.1.m1.2.3.3.2.2"><cn id="S3.p4.1.m1.1.1.cmml" type="integer" xref="S3.p4.1.m1.1.1">0</cn><cn id="S3.p4.1.m1.2.2.cmml" type="integer" xref="S3.p4.1.m1.2.2">1</cn></interval><apply id="S3.p4.1.m1.2.3.3.3.cmml" xref="S3.p4.1.m1.2.3.3.3"><times id="S3.p4.1.m1.2.3.3.3.1.cmml" xref="S3.p4.1.m1.2.3.3.3.1"></times><apply id="S3.p4.1.m1.2.3.3.3.2.cmml" xref="S3.p4.1.m1.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.p4.1.m1.2.3.3.3.2.1.cmml" xref="S3.p4.1.m1.2.3.3.3.2">superscript</csymbol><ci id="S3.p4.1.m1.2.3.3.3.2.2.cmml" xref="S3.p4.1.m1.2.3.3.3.2.2">ğ‘¤</ci><ci id="S3.p4.1.m1.2.3.3.3.2.3.cmml" xref="S3.p4.1.m1.2.3.3.3.2.3">â€²</ci></apply><apply id="S3.p4.1.m1.2.3.3.3.3.cmml" xref="S3.p4.1.m1.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.p4.1.m1.2.3.3.3.3.1.cmml" xref="S3.p4.1.m1.2.3.3.3.3">superscript</csymbol><ci id="S3.p4.1.m1.2.3.3.3.3.2.cmml" xref="S3.p4.1.m1.2.3.3.3.3.2">â„</ci><ci id="S3.p4.1.m1.2.3.3.3.3.3.cmml" xref="S3.p4.1.m1.2.3.3.3.3.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.2c">\bm{\hat{P}}\in[0,1]^{w^{\prime}h^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.1.m1.2d">overbold_^ start_ARG bold_italic_P end_ARG âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.2" style="font-size:90%;">, whose cells represent the likelihood of depicting a robot in the respective location;
the distance map </span><math alttext="\bm{\hat{D}}\in[0,d_{\text{max}}]^{w^{\prime}h^{\prime}}" class="ltx_Math" display="inline" id="S3.p4.2.m2.2"><semantics id="S3.p4.2.m2.2a"><mrow id="S3.p4.2.m2.2.2" xref="S3.p4.2.m2.2.2.cmml"><mover accent="true" id="S3.p4.2.m2.2.2.3" xref="S3.p4.2.m2.2.2.3.cmml"><mi id="S3.p4.2.m2.2.2.3.2" mathsize="90%" xref="S3.p4.2.m2.2.2.3.2.cmml">ğ‘«</mi><mo class="ltx_mathvariant_bold" id="S3.p4.2.m2.2.2.3.1" mathsize="90%" mathvariant="bold" xref="S3.p4.2.m2.2.2.3.1.cmml">^</mo></mover><mo id="S3.p4.2.m2.2.2.2" mathsize="90%" xref="S3.p4.2.m2.2.2.2.cmml">âˆˆ</mo><msup id="S3.p4.2.m2.2.2.1" xref="S3.p4.2.m2.2.2.1.cmml"><mrow id="S3.p4.2.m2.2.2.1.1.1" xref="S3.p4.2.m2.2.2.1.1.2.cmml"><mo id="S3.p4.2.m2.2.2.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.p4.2.m2.2.2.1.1.2.cmml">[</mo><mn id="S3.p4.2.m2.1.1" mathsize="90%" xref="S3.p4.2.m2.1.1.cmml">0</mn><mo id="S3.p4.2.m2.2.2.1.1.1.3" mathsize="90%" xref="S3.p4.2.m2.2.2.1.1.2.cmml">,</mo><msub id="S3.p4.2.m2.2.2.1.1.1.1" xref="S3.p4.2.m2.2.2.1.1.1.1.cmml"><mi id="S3.p4.2.m2.2.2.1.1.1.1.2" mathsize="90%" xref="S3.p4.2.m2.2.2.1.1.1.1.2.cmml">d</mi><mtext id="S3.p4.2.m2.2.2.1.1.1.1.3" mathsize="90%" xref="S3.p4.2.m2.2.2.1.1.1.1.3a.cmml">max</mtext></msub><mo id="S3.p4.2.m2.2.2.1.1.1.4" maxsize="90%" minsize="90%" xref="S3.p4.2.m2.2.2.1.1.2.cmml">]</mo></mrow><mrow id="S3.p4.2.m2.2.2.1.3" xref="S3.p4.2.m2.2.2.1.3.cmml"><msup id="S3.p4.2.m2.2.2.1.3.2" xref="S3.p4.2.m2.2.2.1.3.2.cmml"><mi id="S3.p4.2.m2.2.2.1.3.2.2" mathsize="90%" xref="S3.p4.2.m2.2.2.1.3.2.2.cmml">w</mi><mo id="S3.p4.2.m2.2.2.1.3.2.3" mathsize="90%" xref="S3.p4.2.m2.2.2.1.3.2.3.cmml">â€²</mo></msup><mo id="S3.p4.2.m2.2.2.1.3.1" xref="S3.p4.2.m2.2.2.1.3.1.cmml">â¢</mo><msup id="S3.p4.2.m2.2.2.1.3.3" xref="S3.p4.2.m2.2.2.1.3.3.cmml"><mi id="S3.p4.2.m2.2.2.1.3.3.2" mathsize="90%" xref="S3.p4.2.m2.2.2.1.3.3.2.cmml">h</mi><mo id="S3.p4.2.m2.2.2.1.3.3.3" mathsize="90%" xref="S3.p4.2.m2.2.2.1.3.3.3.cmml">â€²</mo></msup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.2b"><apply id="S3.p4.2.m2.2.2.cmml" xref="S3.p4.2.m2.2.2"><in id="S3.p4.2.m2.2.2.2.cmml" xref="S3.p4.2.m2.2.2.2"></in><apply id="S3.p4.2.m2.2.2.3.cmml" xref="S3.p4.2.m2.2.2.3"><ci id="S3.p4.2.m2.2.2.3.1.cmml" xref="S3.p4.2.m2.2.2.3.1">bold-^</ci><ci id="S3.p4.2.m2.2.2.3.2.cmml" xref="S3.p4.2.m2.2.2.3.2">ğ‘«</ci></apply><apply id="S3.p4.2.m2.2.2.1.cmml" xref="S3.p4.2.m2.2.2.1"><csymbol cd="ambiguous" id="S3.p4.2.m2.2.2.1.2.cmml" xref="S3.p4.2.m2.2.2.1">superscript</csymbol><interval closure="closed" id="S3.p4.2.m2.2.2.1.1.2.cmml" xref="S3.p4.2.m2.2.2.1.1.1"><cn id="S3.p4.2.m2.1.1.cmml" type="integer" xref="S3.p4.2.m2.1.1">0</cn><apply id="S3.p4.2.m2.2.2.1.1.1.1.cmml" xref="S3.p4.2.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.2.m2.2.2.1.1.1.1.1.cmml" xref="S3.p4.2.m2.2.2.1.1.1.1">subscript</csymbol><ci id="S3.p4.2.m2.2.2.1.1.1.1.2.cmml" xref="S3.p4.2.m2.2.2.1.1.1.1.2">ğ‘‘</ci><ci id="S3.p4.2.m2.2.2.1.1.1.1.3a.cmml" xref="S3.p4.2.m2.2.2.1.1.1.1.3"><mtext id="S3.p4.2.m2.2.2.1.1.1.1.3.cmml" mathsize="63%" xref="S3.p4.2.m2.2.2.1.1.1.1.3">max</mtext></ci></apply></interval><apply id="S3.p4.2.m2.2.2.1.3.cmml" xref="S3.p4.2.m2.2.2.1.3"><times id="S3.p4.2.m2.2.2.1.3.1.cmml" xref="S3.p4.2.m2.2.2.1.3.1"></times><apply id="S3.p4.2.m2.2.2.1.3.2.cmml" xref="S3.p4.2.m2.2.2.1.3.2"><csymbol cd="ambiguous" id="S3.p4.2.m2.2.2.1.3.2.1.cmml" xref="S3.p4.2.m2.2.2.1.3.2">superscript</csymbol><ci id="S3.p4.2.m2.2.2.1.3.2.2.cmml" xref="S3.p4.2.m2.2.2.1.3.2.2">ğ‘¤</ci><ci id="S3.p4.2.m2.2.2.1.3.2.3.cmml" xref="S3.p4.2.m2.2.2.1.3.2.3">â€²</ci></apply><apply id="S3.p4.2.m2.2.2.1.3.3.cmml" xref="S3.p4.2.m2.2.2.1.3.3"><csymbol cd="ambiguous" id="S3.p4.2.m2.2.2.1.3.3.1.cmml" xref="S3.p4.2.m2.2.2.1.3.3">superscript</csymbol><ci id="S3.p4.2.m2.2.2.1.3.3.2.cmml" xref="S3.p4.2.m2.2.2.1.3.3.2">â„</ci><ci id="S3.p4.2.m2.2.2.1.3.3.3.cmml" xref="S3.p4.2.m2.2.2.1.3.3.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.2c">\bm{\hat{D}}\in[0,d_{\text{max}}]^{w^{\prime}h^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.2.m2.2d">overbold_^ start_ARG bold_italic_D end_ARG âˆˆ [ 0 , italic_d start_POSTSUBSCRIPT max end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.3" style="font-size:90%;">, representing the distance of the robot up to a maximum parametrized by </span><math alttext="d_{\text{max}}" class="ltx_Math" display="inline" id="S3.p4.3.m3.1"><semantics id="S3.p4.3.m3.1a"><msub id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml"><mi id="S3.p4.3.m3.1.1.2" mathsize="90%" xref="S3.p4.3.m3.1.1.2.cmml">d</mi><mtext id="S3.p4.3.m3.1.1.3" mathsize="90%" xref="S3.p4.3.m3.1.1.3a.cmml">max</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><apply id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p4.3.m3.1.1.1.cmml" xref="S3.p4.3.m3.1.1">subscript</csymbol><ci id="S3.p4.3.m3.1.1.2.cmml" xref="S3.p4.3.m3.1.1.2">ğ‘‘</ci><ci id="S3.p4.3.m3.1.1.3a.cmml" xref="S3.p4.3.m3.1.1.3"><mtext id="S3.p4.3.m3.1.1.3.cmml" mathsize="63%" xref="S3.p4.3.m3.1.1.3">max</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">d_{\text{max}}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.3.m3.1d">italic_d start_POSTSUBSCRIPT max end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.4" style="font-size:90%;">;
the orientation maps </span><math alttext="\bm{\hat{O}}\in[-1,1]^{w^{\prime}h^{\prime}2}" class="ltx_Math" display="inline" id="S3.p4.4.m4.2"><semantics id="S3.p4.4.m4.2a"><mrow id="S3.p4.4.m4.2.2" xref="S3.p4.4.m4.2.2.cmml"><mover accent="true" id="S3.p4.4.m4.2.2.3" xref="S3.p4.4.m4.2.2.3.cmml"><mi id="S3.p4.4.m4.2.2.3.2" mathsize="90%" xref="S3.p4.4.m4.2.2.3.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S3.p4.4.m4.2.2.3.1" mathsize="90%" mathvariant="bold" xref="S3.p4.4.m4.2.2.3.1.cmml">^</mo></mover><mo id="S3.p4.4.m4.2.2.2" mathsize="90%" xref="S3.p4.4.m4.2.2.2.cmml">âˆˆ</mo><msup id="S3.p4.4.m4.2.2.1" xref="S3.p4.4.m4.2.2.1.cmml"><mrow id="S3.p4.4.m4.2.2.1.1.1" xref="S3.p4.4.m4.2.2.1.1.2.cmml"><mo id="S3.p4.4.m4.2.2.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.p4.4.m4.2.2.1.1.2.cmml">[</mo><mrow id="S3.p4.4.m4.2.2.1.1.1.1" xref="S3.p4.4.m4.2.2.1.1.1.1.cmml"><mo id="S3.p4.4.m4.2.2.1.1.1.1a" mathsize="90%" xref="S3.p4.4.m4.2.2.1.1.1.1.cmml">âˆ’</mo><mn id="S3.p4.4.m4.2.2.1.1.1.1.2" mathsize="90%" xref="S3.p4.4.m4.2.2.1.1.1.1.2.cmml">1</mn></mrow><mo id="S3.p4.4.m4.2.2.1.1.1.3" mathsize="90%" xref="S3.p4.4.m4.2.2.1.1.2.cmml">,</mo><mn id="S3.p4.4.m4.1.1" mathsize="90%" xref="S3.p4.4.m4.1.1.cmml">1</mn><mo id="S3.p4.4.m4.2.2.1.1.1.4" maxsize="90%" minsize="90%" xref="S3.p4.4.m4.2.2.1.1.2.cmml">]</mo></mrow><mrow id="S3.p4.4.m4.2.2.1.3" xref="S3.p4.4.m4.2.2.1.3.cmml"><msup id="S3.p4.4.m4.2.2.1.3.2" xref="S3.p4.4.m4.2.2.1.3.2.cmml"><mi id="S3.p4.4.m4.2.2.1.3.2.2" mathsize="90%" xref="S3.p4.4.m4.2.2.1.3.2.2.cmml">w</mi><mo id="S3.p4.4.m4.2.2.1.3.2.3" mathsize="90%" xref="S3.p4.4.m4.2.2.1.3.2.3.cmml">â€²</mo></msup><mo id="S3.p4.4.m4.2.2.1.3.1" xref="S3.p4.4.m4.2.2.1.3.1.cmml">â¢</mo><msup id="S3.p4.4.m4.2.2.1.3.3" xref="S3.p4.4.m4.2.2.1.3.3.cmml"><mi id="S3.p4.4.m4.2.2.1.3.3.2" mathsize="90%" xref="S3.p4.4.m4.2.2.1.3.3.2.cmml">h</mi><mo id="S3.p4.4.m4.2.2.1.3.3.3" mathsize="90%" xref="S3.p4.4.m4.2.2.1.3.3.3.cmml">â€²</mo></msup><mo id="S3.p4.4.m4.2.2.1.3.1a" xref="S3.p4.4.m4.2.2.1.3.1.cmml">â¢</mo><mn id="S3.p4.4.m4.2.2.1.3.4" mathsize="90%" xref="S3.p4.4.m4.2.2.1.3.4.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.2b"><apply id="S3.p4.4.m4.2.2.cmml" xref="S3.p4.4.m4.2.2"><in id="S3.p4.4.m4.2.2.2.cmml" xref="S3.p4.4.m4.2.2.2"></in><apply id="S3.p4.4.m4.2.2.3.cmml" xref="S3.p4.4.m4.2.2.3"><ci id="S3.p4.4.m4.2.2.3.1.cmml" xref="S3.p4.4.m4.2.2.3.1">bold-^</ci><ci id="S3.p4.4.m4.2.2.3.2.cmml" xref="S3.p4.4.m4.2.2.3.2">ğ‘¶</ci></apply><apply id="S3.p4.4.m4.2.2.1.cmml" xref="S3.p4.4.m4.2.2.1"><csymbol cd="ambiguous" id="S3.p4.4.m4.2.2.1.2.cmml" xref="S3.p4.4.m4.2.2.1">superscript</csymbol><interval closure="closed" id="S3.p4.4.m4.2.2.1.1.2.cmml" xref="S3.p4.4.m4.2.2.1.1.1"><apply id="S3.p4.4.m4.2.2.1.1.1.1.cmml" xref="S3.p4.4.m4.2.2.1.1.1.1"><minus id="S3.p4.4.m4.2.2.1.1.1.1.1.cmml" xref="S3.p4.4.m4.2.2.1.1.1.1"></minus><cn id="S3.p4.4.m4.2.2.1.1.1.1.2.cmml" type="integer" xref="S3.p4.4.m4.2.2.1.1.1.1.2">1</cn></apply><cn id="S3.p4.4.m4.1.1.cmml" type="integer" xref="S3.p4.4.m4.1.1">1</cn></interval><apply id="S3.p4.4.m4.2.2.1.3.cmml" xref="S3.p4.4.m4.2.2.1.3"><times id="S3.p4.4.m4.2.2.1.3.1.cmml" xref="S3.p4.4.m4.2.2.1.3.1"></times><apply id="S3.p4.4.m4.2.2.1.3.2.cmml" xref="S3.p4.4.m4.2.2.1.3.2"><csymbol cd="ambiguous" id="S3.p4.4.m4.2.2.1.3.2.1.cmml" xref="S3.p4.4.m4.2.2.1.3.2">superscript</csymbol><ci id="S3.p4.4.m4.2.2.1.3.2.2.cmml" xref="S3.p4.4.m4.2.2.1.3.2.2">ğ‘¤</ci><ci id="S3.p4.4.m4.2.2.1.3.2.3.cmml" xref="S3.p4.4.m4.2.2.1.3.2.3">â€²</ci></apply><apply id="S3.p4.4.m4.2.2.1.3.3.cmml" xref="S3.p4.4.m4.2.2.1.3.3"><csymbol cd="ambiguous" id="S3.p4.4.m4.2.2.1.3.3.1.cmml" xref="S3.p4.4.m4.2.2.1.3.3">superscript</csymbol><ci id="S3.p4.4.m4.2.2.1.3.3.2.cmml" xref="S3.p4.4.m4.2.2.1.3.3.2">â„</ci><ci id="S3.p4.4.m4.2.2.1.3.3.3.cmml" xref="S3.p4.4.m4.2.2.1.3.3.3">â€²</ci></apply><cn id="S3.p4.4.m4.2.2.1.3.4.cmml" type="integer" xref="S3.p4.4.m4.2.2.1.3.4">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.2c">\bm{\hat{O}}\in[-1,1]^{w^{\prime}h^{\prime}2}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.4.m4.2d">overbold_^ start_ARG bold_italic_O end_ARG âˆˆ [ - 1 , 1 ] start_POSTSUPERSCRIPT italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.5" style="font-size:90%;">, representing the robotâ€™s orientation and consisting of sine </span><math alttext="\bm{\hat{O}}_{\text{sin}}^{\psi}" class="ltx_Math" display="inline" id="S3.p4.5.m5.1"><semantics id="S3.p4.5.m5.1a"><msubsup id="S3.p4.5.m5.1.1" xref="S3.p4.5.m5.1.1.cmml"><mover accent="true" id="S3.p4.5.m5.1.1.2.2" xref="S3.p4.5.m5.1.1.2.2.cmml"><mi id="S3.p4.5.m5.1.1.2.2.2" mathsize="90%" xref="S3.p4.5.m5.1.1.2.2.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S3.p4.5.m5.1.1.2.2.1" mathsize="90%" mathvariant="bold" xref="S3.p4.5.m5.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.p4.5.m5.1.1.2.3" mathsize="90%" xref="S3.p4.5.m5.1.1.2.3a.cmml">sin</mtext><mi id="S3.p4.5.m5.1.1.3" mathsize="90%" xref="S3.p4.5.m5.1.1.3.cmml">Ïˆ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p4.5.m5.1b"><apply id="S3.p4.5.m5.1.1.cmml" xref="S3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p4.5.m5.1.1.1.cmml" xref="S3.p4.5.m5.1.1">superscript</csymbol><apply id="S3.p4.5.m5.1.1.2.cmml" xref="S3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p4.5.m5.1.1.2.1.cmml" xref="S3.p4.5.m5.1.1">subscript</csymbol><apply id="S3.p4.5.m5.1.1.2.2.cmml" xref="S3.p4.5.m5.1.1.2.2"><ci id="S3.p4.5.m5.1.1.2.2.1.cmml" xref="S3.p4.5.m5.1.1.2.2.1">bold-^</ci><ci id="S3.p4.5.m5.1.1.2.2.2.cmml" xref="S3.p4.5.m5.1.1.2.2.2">ğ‘¶</ci></apply><ci id="S3.p4.5.m5.1.1.2.3a.cmml" xref="S3.p4.5.m5.1.1.2.3"><mtext id="S3.p4.5.m5.1.1.2.3.cmml" mathsize="63%" xref="S3.p4.5.m5.1.1.2.3">sin</mtext></ci></apply><ci id="S3.p4.5.m5.1.1.3.cmml" xref="S3.p4.5.m5.1.1.3">ğœ“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m5.1c">\bm{\hat{O}}_{\text{sin}}^{\psi}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.5.m5.1d">overbold_^ start_ARG bold_italic_O end_ARG start_POSTSUBSCRIPT sin end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Ïˆ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.6" style="font-size:90%;"> and cosine maps </span><math alttext="\bm{\hat{O}}_{\text{cos}}^{\psi}" class="ltx_Math" display="inline" id="S3.p4.6.m6.1"><semantics id="S3.p4.6.m6.1a"><msubsup id="S3.p4.6.m6.1.1" xref="S3.p4.6.m6.1.1.cmml"><mover accent="true" id="S3.p4.6.m6.1.1.2.2" xref="S3.p4.6.m6.1.1.2.2.cmml"><mi id="S3.p4.6.m6.1.1.2.2.2" mathsize="90%" xref="S3.p4.6.m6.1.1.2.2.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S3.p4.6.m6.1.1.2.2.1" mathsize="90%" mathvariant="bold" xref="S3.p4.6.m6.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.p4.6.m6.1.1.2.3" mathsize="90%" xref="S3.p4.6.m6.1.1.2.3a.cmml">cos</mtext><mi id="S3.p4.6.m6.1.1.3" mathsize="90%" xref="S3.p4.6.m6.1.1.3.cmml">Ïˆ</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p4.6.m6.1b"><apply id="S3.p4.6.m6.1.1.cmml" xref="S3.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p4.6.m6.1.1.1.cmml" xref="S3.p4.6.m6.1.1">superscript</csymbol><apply id="S3.p4.6.m6.1.1.2.cmml" xref="S3.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p4.6.m6.1.1.2.1.cmml" xref="S3.p4.6.m6.1.1">subscript</csymbol><apply id="S3.p4.6.m6.1.1.2.2.cmml" xref="S3.p4.6.m6.1.1.2.2"><ci id="S3.p4.6.m6.1.1.2.2.1.cmml" xref="S3.p4.6.m6.1.1.2.2.1">bold-^</ci><ci id="S3.p4.6.m6.1.1.2.2.2.cmml" xref="S3.p4.6.m6.1.1.2.2.2">ğ‘¶</ci></apply><ci id="S3.p4.6.m6.1.1.2.3a.cmml" xref="S3.p4.6.m6.1.1.2.3"><mtext id="S3.p4.6.m6.1.1.2.3.cmml" mathsize="63%" xref="S3.p4.6.m6.1.1.2.3">cos</mtext></ci></apply><ci id="S3.p4.6.m6.1.1.3.cmml" xref="S3.p4.6.m6.1.1.3">ğœ“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m6.1c">\bm{\hat{O}}_{\text{cos}}^{\psi}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.6.m6.1d">overbold_^ start_ARG bold_italic_O end_ARG start_POSTSUBSCRIPT cos end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Ïˆ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.7" style="font-size:90%;">;
and the LED state maps </span><math alttext="\bm{\hat{L}}\in[0,1]^{w^{\prime}h^{\prime}k}" class="ltx_Math" display="inline" id="S3.p4.7.m7.2"><semantics id="S3.p4.7.m7.2a"><mrow id="S3.p4.7.m7.2.3" xref="S3.p4.7.m7.2.3.cmml"><mover accent="true" id="S3.p4.7.m7.2.3.2" xref="S3.p4.7.m7.2.3.2.cmml"><mi id="S3.p4.7.m7.2.3.2.2" mathsize="90%" xref="S3.p4.7.m7.2.3.2.2.cmml">ğ‘³</mi><mo class="ltx_mathvariant_bold" id="S3.p4.7.m7.2.3.2.1" mathsize="90%" mathvariant="bold" xref="S3.p4.7.m7.2.3.2.1.cmml">^</mo></mover><mo id="S3.p4.7.m7.2.3.1" mathsize="90%" xref="S3.p4.7.m7.2.3.1.cmml">âˆˆ</mo><msup id="S3.p4.7.m7.2.3.3" xref="S3.p4.7.m7.2.3.3.cmml"><mrow id="S3.p4.7.m7.2.3.3.2.2" xref="S3.p4.7.m7.2.3.3.2.1.cmml"><mo id="S3.p4.7.m7.2.3.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.p4.7.m7.2.3.3.2.1.cmml">[</mo><mn id="S3.p4.7.m7.1.1" mathsize="90%" xref="S3.p4.7.m7.1.1.cmml">0</mn><mo id="S3.p4.7.m7.2.3.3.2.2.2" mathsize="90%" xref="S3.p4.7.m7.2.3.3.2.1.cmml">,</mo><mn id="S3.p4.7.m7.2.2" mathsize="90%" xref="S3.p4.7.m7.2.2.cmml">1</mn><mo id="S3.p4.7.m7.2.3.3.2.2.3" maxsize="90%" minsize="90%" xref="S3.p4.7.m7.2.3.3.2.1.cmml">]</mo></mrow><mrow id="S3.p4.7.m7.2.3.3.3" xref="S3.p4.7.m7.2.3.3.3.cmml"><msup id="S3.p4.7.m7.2.3.3.3.2" xref="S3.p4.7.m7.2.3.3.3.2.cmml"><mi id="S3.p4.7.m7.2.3.3.3.2.2" mathsize="90%" xref="S3.p4.7.m7.2.3.3.3.2.2.cmml">w</mi><mo id="S3.p4.7.m7.2.3.3.3.2.3" mathsize="90%" xref="S3.p4.7.m7.2.3.3.3.2.3.cmml">â€²</mo></msup><mo id="S3.p4.7.m7.2.3.3.3.1" xref="S3.p4.7.m7.2.3.3.3.1.cmml">â¢</mo><msup id="S3.p4.7.m7.2.3.3.3.3" xref="S3.p4.7.m7.2.3.3.3.3.cmml"><mi id="S3.p4.7.m7.2.3.3.3.3.2" mathsize="90%" xref="S3.p4.7.m7.2.3.3.3.3.2.cmml">h</mi><mo id="S3.p4.7.m7.2.3.3.3.3.3" mathsize="90%" xref="S3.p4.7.m7.2.3.3.3.3.3.cmml">â€²</mo></msup><mo id="S3.p4.7.m7.2.3.3.3.1a" xref="S3.p4.7.m7.2.3.3.3.1.cmml">â¢</mo><mi id="S3.p4.7.m7.2.3.3.3.4" mathsize="90%" xref="S3.p4.7.m7.2.3.3.3.4.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.7.m7.2b"><apply id="S3.p4.7.m7.2.3.cmml" xref="S3.p4.7.m7.2.3"><in id="S3.p4.7.m7.2.3.1.cmml" xref="S3.p4.7.m7.2.3.1"></in><apply id="S3.p4.7.m7.2.3.2.cmml" xref="S3.p4.7.m7.2.3.2"><ci id="S3.p4.7.m7.2.3.2.1.cmml" xref="S3.p4.7.m7.2.3.2.1">bold-^</ci><ci id="S3.p4.7.m7.2.3.2.2.cmml" xref="S3.p4.7.m7.2.3.2.2">ğ‘³</ci></apply><apply id="S3.p4.7.m7.2.3.3.cmml" xref="S3.p4.7.m7.2.3.3"><csymbol cd="ambiguous" id="S3.p4.7.m7.2.3.3.1.cmml" xref="S3.p4.7.m7.2.3.3">superscript</csymbol><interval closure="closed" id="S3.p4.7.m7.2.3.3.2.1.cmml" xref="S3.p4.7.m7.2.3.3.2.2"><cn id="S3.p4.7.m7.1.1.cmml" type="integer" xref="S3.p4.7.m7.1.1">0</cn><cn id="S3.p4.7.m7.2.2.cmml" type="integer" xref="S3.p4.7.m7.2.2">1</cn></interval><apply id="S3.p4.7.m7.2.3.3.3.cmml" xref="S3.p4.7.m7.2.3.3.3"><times id="S3.p4.7.m7.2.3.3.3.1.cmml" xref="S3.p4.7.m7.2.3.3.3.1"></times><apply id="S3.p4.7.m7.2.3.3.3.2.cmml" xref="S3.p4.7.m7.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.p4.7.m7.2.3.3.3.2.1.cmml" xref="S3.p4.7.m7.2.3.3.3.2">superscript</csymbol><ci id="S3.p4.7.m7.2.3.3.3.2.2.cmml" xref="S3.p4.7.m7.2.3.3.3.2.2">ğ‘¤</ci><ci id="S3.p4.7.m7.2.3.3.3.2.3.cmml" xref="S3.p4.7.m7.2.3.3.3.2.3">â€²</ci></apply><apply id="S3.p4.7.m7.2.3.3.3.3.cmml" xref="S3.p4.7.m7.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.p4.7.m7.2.3.3.3.3.1.cmml" xref="S3.p4.7.m7.2.3.3.3.3">superscript</csymbol><ci id="S3.p4.7.m7.2.3.3.3.3.2.cmml" xref="S3.p4.7.m7.2.3.3.3.3.2">â„</ci><ci id="S3.p4.7.m7.2.3.3.3.3.3.cmml" xref="S3.p4.7.m7.2.3.3.3.3.3">â€²</ci></apply><ci id="S3.p4.7.m7.2.3.3.3.4.cmml" xref="S3.p4.7.m7.2.3.3.3.4">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.7.m7.2c">\bm{\hat{L}}\in[0,1]^{w^{\prime}h^{\prime}k}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.7.m7.2d">overbold_^ start_ARG bold_italic_L end_ARG âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.8" style="font-size:90%;">, where the </span><math alttext="i" class="ltx_Math" display="inline" id="S3.p4.8.m8.1"><semantics id="S3.p4.8.m8.1a"><mi id="S3.p4.8.m8.1.1" mathsize="90%" xref="S3.p4.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p4.8.m8.1b"><ci id="S3.p4.8.m8.1.1.cmml" xref="S3.p4.8.m8.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.8.m8.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.p4.8.m8.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.9" style="font-size:90%;">-th map represents the state of </span><math alttext="l_{i}" class="ltx_Math" display="inline" id="S3.p4.9.m9.1"><semantics id="S3.p4.9.m9.1a"><msub id="S3.p4.9.m9.1.1" xref="S3.p4.9.m9.1.1.cmml"><mi id="S3.p4.9.m9.1.1.2" mathsize="90%" xref="S3.p4.9.m9.1.1.2.cmml">l</mi><mi id="S3.p4.9.m9.1.1.3" mathsize="90%" xref="S3.p4.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.9.m9.1b"><apply id="S3.p4.9.m9.1.1.cmml" xref="S3.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p4.9.m9.1.1.1.cmml" xref="S3.p4.9.m9.1.1">subscript</csymbol><ci id="S3.p4.9.m9.1.1.2.cmml" xref="S3.p4.9.m9.1.1.2">ğ‘™</ci><ci id="S3.p4.9.m9.1.1.3.cmml" xref="S3.p4.9.m9.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.9.m9.1c">l_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.9.m9.1d">italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.10" style="font-size:90%;"> and </span><math alttext="1\!\leq\!i\!\leq\!k" class="ltx_Math" display="inline" id="S3.p4.10.m10.1"><semantics id="S3.p4.10.m10.1a"><mrow id="S3.p4.10.m10.1.1" xref="S3.p4.10.m10.1.1.cmml"><mn id="S3.p4.10.m10.1.1.2" mathsize="90%" xref="S3.p4.10.m10.1.1.2.cmml">1</mn><mo id="S3.p4.10.m10.1.1.3" lspace="0.108em" mathsize="90%" rspace="0.108em" xref="S3.p4.10.m10.1.1.3.cmml">â‰¤</mo><mi id="S3.p4.10.m10.1.1.4" mathsize="90%" xref="S3.p4.10.m10.1.1.4.cmml">i</mi><mo id="S3.p4.10.m10.1.1.5" lspace="0.108em" mathsize="90%" rspace="0.108em" xref="S3.p4.10.m10.1.1.5.cmml">â‰¤</mo><mi id="S3.p4.10.m10.1.1.6" mathsize="90%" xref="S3.p4.10.m10.1.1.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.10.m10.1b"><apply id="S3.p4.10.m10.1.1.cmml" xref="S3.p4.10.m10.1.1"><and id="S3.p4.10.m10.1.1a.cmml" xref="S3.p4.10.m10.1.1"></and><apply id="S3.p4.10.m10.1.1b.cmml" xref="S3.p4.10.m10.1.1"><leq id="S3.p4.10.m10.1.1.3.cmml" xref="S3.p4.10.m10.1.1.3"></leq><cn id="S3.p4.10.m10.1.1.2.cmml" type="integer" xref="S3.p4.10.m10.1.1.2">1</cn><ci id="S3.p4.10.m10.1.1.4.cmml" xref="S3.p4.10.m10.1.1.4">ğ‘–</ci></apply><apply id="S3.p4.10.m10.1.1c.cmml" xref="S3.p4.10.m10.1.1"><leq id="S3.p4.10.m10.1.1.5.cmml" xref="S3.p4.10.m10.1.1.5"></leq><share href="https://arxiv.org/html/2407.10661v2#S3.p4.10.m10.1.1.4.cmml" id="S3.p4.10.m10.1.1d.cmml" xref="S3.p4.10.m10.1.1"></share><ci id="S3.p4.10.m10.1.1.6.cmml" xref="S3.p4.10.m10.1.1.6">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.10.m10.1c">1\!\leq\!i\!\leq\!k</annotation><annotation encoding="application/x-llamapun" id="S3.p4.10.m10.1d">1 â‰¤ italic_i â‰¤ italic_k</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.11" style="font-size:90%;">.
We obtain scalar values from the modelâ€™s predicted maps by weighting them with the predicted position map </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S3.p4.11.m11.1"><semantics id="S3.p4.11.m11.1a"><mover accent="true" id="S3.p4.11.m11.1.1" xref="S3.p4.11.m11.1.1.cmml"><mi id="S3.p4.11.m11.1.1.2" mathsize="90%" xref="S3.p4.11.m11.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.p4.11.m11.1.1.1" mathsize="90%" mathvariant="bold" xref="S3.p4.11.m11.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p4.11.m11.1b"><apply id="S3.p4.11.m11.1.1.cmml" xref="S3.p4.11.m11.1.1"><ci id="S3.p4.11.m11.1.1.1.cmml" xref="S3.p4.11.m11.1.1.1">bold-^</ci><ci id="S3.p4.11.m11.1.1.2.cmml" xref="S3.p4.11.m11.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.11.m11.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.11.m11.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.12" style="font-size:90%;"> according to </span><math alttext="\operatorname{\bm{wm_{\hat{P}}}}(\bm{X})=\sum_{i=1}^{h^{\prime}}\sum_{j=1}^{w^%
{\prime}}\bigl{(}\text{norm}(\bm{\hat{P}})_{ij}\cdot\bm{X}_{ij}\bigr{)}" class="ltx_Math" display="inline" id="S3.p4.12.m12.4"><semantics id="S3.p4.12.m12.4a"><mrow id="S3.p4.12.m12.4.4" xref="S3.p4.12.m12.4.4.cmml"><mrow id="S3.p4.12.m12.4.4.3.2" xref="S3.p4.12.m12.4.4.3.1.cmml"><msub id="S3.p4.12.m12.1.1" xref="S3.p4.12.m12.1.1.cmml"><mi id="S3.p4.12.m12.1.1.2" mathsize="90%" xref="S3.p4.12.m12.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.p4.12.m12.1.1.3" xref="S3.p4.12.m12.1.1.3.cmml"><mi id="S3.p4.12.m12.1.1.3.2" mathsize="90%" xref="S3.p4.12.m12.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.p4.12.m12.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.p4.12.m12.1.1.3.1.cmml">^</mo></mover></msub><mo id="S3.p4.12.m12.4.4.3.2a" xref="S3.p4.12.m12.4.4.3.1.cmml">â¡</mo><mrow id="S3.p4.12.m12.4.4.3.2.1" xref="S3.p4.12.m12.4.4.3.1.cmml"><mo id="S3.p4.12.m12.4.4.3.2.1.1" maxsize="90%" minsize="90%" xref="S3.p4.12.m12.4.4.3.1.cmml">(</mo><mi id="S3.p4.12.m12.2.2" mathsize="90%" xref="S3.p4.12.m12.2.2.cmml">ğ‘¿</mi><mo id="S3.p4.12.m12.4.4.3.2.1.2" maxsize="90%" minsize="90%" xref="S3.p4.12.m12.4.4.3.1.cmml">)</mo></mrow></mrow><mo id="S3.p4.12.m12.4.4.2" mathsize="90%" rspace="0.111em" xref="S3.p4.12.m12.4.4.2.cmml">=</mo><mrow id="S3.p4.12.m12.4.4.1" xref="S3.p4.12.m12.4.4.1.cmml"><msubsup id="S3.p4.12.m12.4.4.1.2" xref="S3.p4.12.m12.4.4.1.2.cmml"><mo id="S3.p4.12.m12.4.4.1.2.2.2" maxsize="90%" minsize="90%" rspace="0em" stretchy="true" xref="S3.p4.12.m12.4.4.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.p4.12.m12.4.4.1.2.2.3" xref="S3.p4.12.m12.4.4.1.2.2.3.cmml"><mi id="S3.p4.12.m12.4.4.1.2.2.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.2.2.3.2.cmml">i</mi><mo id="S3.p4.12.m12.4.4.1.2.2.3.1" mathsize="90%" xref="S3.p4.12.m12.4.4.1.2.2.3.1.cmml">=</mo><mn id="S3.p4.12.m12.4.4.1.2.2.3.3" mathsize="90%" xref="S3.p4.12.m12.4.4.1.2.2.3.3.cmml">1</mn></mrow><msup id="S3.p4.12.m12.4.4.1.2.3" xref="S3.p4.12.m12.4.4.1.2.3.cmml"><mi id="S3.p4.12.m12.4.4.1.2.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.2.3.2.cmml">h</mi><mo id="S3.p4.12.m12.4.4.1.2.3.3" mathsize="90%" xref="S3.p4.12.m12.4.4.1.2.3.3.cmml">â€²</mo></msup></msubsup><mrow id="S3.p4.12.m12.4.4.1.1" xref="S3.p4.12.m12.4.4.1.1.cmml"><msubsup id="S3.p4.12.m12.4.4.1.1.2" xref="S3.p4.12.m12.4.4.1.1.2.cmml"><mo id="S3.p4.12.m12.4.4.1.1.2.2.2" maxsize="90%" minsize="90%" rspace="0em" stretchy="true" xref="S3.p4.12.m12.4.4.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.p4.12.m12.4.4.1.1.2.2.3" xref="S3.p4.12.m12.4.4.1.1.2.2.3.cmml"><mi id="S3.p4.12.m12.4.4.1.1.2.2.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.2.2.3.2.cmml">j</mi><mo id="S3.p4.12.m12.4.4.1.1.2.2.3.1" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.2.2.3.1.cmml">=</mo><mn id="S3.p4.12.m12.4.4.1.1.2.2.3.3" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.2.2.3.3.cmml">1</mn></mrow><msup id="S3.p4.12.m12.4.4.1.1.2.3" xref="S3.p4.12.m12.4.4.1.1.2.3.cmml"><mi id="S3.p4.12.m12.4.4.1.1.2.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.2.3.2.cmml">w</mi><mo id="S3.p4.12.m12.4.4.1.1.2.3.3" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.2.3.3.cmml">â€²</mo></msup></msubsup><mrow id="S3.p4.12.m12.4.4.1.1.1.1" xref="S3.p4.12.m12.4.4.1.1.1.1.1.cmml"><mo id="S3.p4.12.m12.4.4.1.1.1.1.2" maxsize="120%" minsize="120%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S3.p4.12.m12.4.4.1.1.1.1.1" xref="S3.p4.12.m12.4.4.1.1.1.1.1.cmml"><mrow id="S3.p4.12.m12.4.4.1.1.1.1.1.2" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.cmml"><mtext id="S3.p4.12.m12.4.4.1.1.1.1.1.2.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.2a.cmml">norm</mtext><mo id="S3.p4.12.m12.4.4.1.1.1.1.1.2.1" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.1.cmml">â¢</mo><msub id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.cmml"><mrow id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.2.2" xref="S3.p4.12.m12.3.3.cmml"><mo id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.p4.12.m12.3.3.cmml">(</mo><mover accent="true" id="S3.p4.12.m12.3.3" xref="S3.p4.12.m12.3.3.cmml"><mi id="S3.p4.12.m12.3.3.2" mathsize="90%" xref="S3.p4.12.m12.3.3.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.p4.12.m12.3.3.1" mathsize="90%" mathvariant="bold" xref="S3.p4.12.m12.3.3.1.cmml">^</mo></mover><mo id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.2.2.2" maxsize="90%" minsize="90%" rspace="0.055em" xref="S3.p4.12.m12.3.3.cmml">)</mo></mrow><mrow id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.cmml"><mi id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.2.cmml">i</mi><mo id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.1" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.1.cmml">â¢</mo><mi id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.3" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.3.cmml">j</mi></mrow></msub></mrow><mo id="S3.p4.12.m12.4.4.1.1.1.1.1.1" mathsize="90%" rspace="0.222em" xref="S3.p4.12.m12.4.4.1.1.1.1.1.1.cmml">â‹…</mo><msub id="S3.p4.12.m12.4.4.1.1.1.1.1.3" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.cmml"><mi id="S3.p4.12.m12.4.4.1.1.1.1.1.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.2.cmml">ğ‘¿</mi><mrow id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.cmml"><mi id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.2" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.2.cmml">i</mi><mo id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.1" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.1.cmml">â¢</mo><mi id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.3" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.3.cmml">j</mi></mrow></msub></mrow><mo id="S3.p4.12.m12.4.4.1.1.1.1.3" maxsize="120%" minsize="120%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.12.m12.4b"><apply id="S3.p4.12.m12.4.4.cmml" xref="S3.p4.12.m12.4.4"><eq id="S3.p4.12.m12.4.4.2.cmml" xref="S3.p4.12.m12.4.4.2"></eq><apply id="S3.p4.12.m12.4.4.3.1.cmml" xref="S3.p4.12.m12.4.4.3.2"><apply id="S3.p4.12.m12.1.1.cmml" xref="S3.p4.12.m12.1.1"><csymbol cd="ambiguous" id="S3.p4.12.m12.1.1.1.cmml" xref="S3.p4.12.m12.1.1">subscript</csymbol><ci id="S3.p4.12.m12.1.1.2.cmml" xref="S3.p4.12.m12.1.1.2">ğ°ğ¦</ci><apply id="S3.p4.12.m12.1.1.3.cmml" xref="S3.p4.12.m12.1.1.3"><ci id="S3.p4.12.m12.1.1.3.1.cmml" xref="S3.p4.12.m12.1.1.3.1">bold-^</ci><ci id="S3.p4.12.m12.1.1.3.2.cmml" xref="S3.p4.12.m12.1.1.3.2">ğ</ci></apply></apply><ci id="S3.p4.12.m12.2.2.cmml" xref="S3.p4.12.m12.2.2">ğ‘¿</ci></apply><apply id="S3.p4.12.m12.4.4.1.cmml" xref="S3.p4.12.m12.4.4.1"><apply id="S3.p4.12.m12.4.4.1.2.cmml" xref="S3.p4.12.m12.4.4.1.2"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.2.1.cmml" xref="S3.p4.12.m12.4.4.1.2">superscript</csymbol><apply id="S3.p4.12.m12.4.4.1.2.2.cmml" xref="S3.p4.12.m12.4.4.1.2"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.2.2.1.cmml" xref="S3.p4.12.m12.4.4.1.2">subscript</csymbol><sum id="S3.p4.12.m12.4.4.1.2.2.2.cmml" xref="S3.p4.12.m12.4.4.1.2.2.2"></sum><apply id="S3.p4.12.m12.4.4.1.2.2.3.cmml" xref="S3.p4.12.m12.4.4.1.2.2.3"><eq id="S3.p4.12.m12.4.4.1.2.2.3.1.cmml" xref="S3.p4.12.m12.4.4.1.2.2.3.1"></eq><ci id="S3.p4.12.m12.4.4.1.2.2.3.2.cmml" xref="S3.p4.12.m12.4.4.1.2.2.3.2">ğ‘–</ci><cn id="S3.p4.12.m12.4.4.1.2.2.3.3.cmml" type="integer" xref="S3.p4.12.m12.4.4.1.2.2.3.3">1</cn></apply></apply><apply id="S3.p4.12.m12.4.4.1.2.3.cmml" xref="S3.p4.12.m12.4.4.1.2.3"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.2.3.1.cmml" xref="S3.p4.12.m12.4.4.1.2.3">superscript</csymbol><ci id="S3.p4.12.m12.4.4.1.2.3.2.cmml" xref="S3.p4.12.m12.4.4.1.2.3.2">â„</ci><ci id="S3.p4.12.m12.4.4.1.2.3.3.cmml" xref="S3.p4.12.m12.4.4.1.2.3.3">â€²</ci></apply></apply><apply id="S3.p4.12.m12.4.4.1.1.cmml" xref="S3.p4.12.m12.4.4.1.1"><apply id="S3.p4.12.m12.4.4.1.1.2.cmml" xref="S3.p4.12.m12.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.1.2.1.cmml" xref="S3.p4.12.m12.4.4.1.1.2">superscript</csymbol><apply id="S3.p4.12.m12.4.4.1.1.2.2.cmml" xref="S3.p4.12.m12.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.1.2.2.1.cmml" xref="S3.p4.12.m12.4.4.1.1.2">subscript</csymbol><sum id="S3.p4.12.m12.4.4.1.1.2.2.2.cmml" xref="S3.p4.12.m12.4.4.1.1.2.2.2"></sum><apply id="S3.p4.12.m12.4.4.1.1.2.2.3.cmml" xref="S3.p4.12.m12.4.4.1.1.2.2.3"><eq id="S3.p4.12.m12.4.4.1.1.2.2.3.1.cmml" xref="S3.p4.12.m12.4.4.1.1.2.2.3.1"></eq><ci id="S3.p4.12.m12.4.4.1.1.2.2.3.2.cmml" xref="S3.p4.12.m12.4.4.1.1.2.2.3.2">ğ‘—</ci><cn id="S3.p4.12.m12.4.4.1.1.2.2.3.3.cmml" type="integer" xref="S3.p4.12.m12.4.4.1.1.2.2.3.3">1</cn></apply></apply><apply id="S3.p4.12.m12.4.4.1.1.2.3.cmml" xref="S3.p4.12.m12.4.4.1.1.2.3"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.1.2.3.1.cmml" xref="S3.p4.12.m12.4.4.1.1.2.3">superscript</csymbol><ci id="S3.p4.12.m12.4.4.1.1.2.3.2.cmml" xref="S3.p4.12.m12.4.4.1.1.2.3.2">ğ‘¤</ci><ci id="S3.p4.12.m12.4.4.1.1.2.3.3.cmml" xref="S3.p4.12.m12.4.4.1.1.2.3.3">â€²</ci></apply></apply><apply id="S3.p4.12.m12.4.4.1.1.1.1.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1"><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.1">â‹…</ci><apply id="S3.p4.12.m12.4.4.1.1.1.1.1.2.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2"><times id="S3.p4.12.m12.4.4.1.1.1.1.1.2.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.1"></times><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.2.2a.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.2"><mtext id="S3.p4.12.m12.4.4.1.1.1.1.1.2.2.cmml" mathsize="90%" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.2">norm</mtext></ci><apply id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3">subscript</csymbol><apply id="S3.p4.12.m12.3.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.2.2"><ci id="S3.p4.12.m12.3.3.1.cmml" xref="S3.p4.12.m12.3.3.1">bold-^</ci><ci id="S3.p4.12.m12.3.3.2.cmml" xref="S3.p4.12.m12.3.3.2">ğ‘·</ci></apply><apply id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3"><times id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.1"></times><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.2.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.2">ğ‘–</ci><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.2.3.3.3">ğ‘—</ci></apply></apply></apply><apply id="S3.p4.12.m12.4.4.1.1.1.1.1.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.p4.12.m12.4.4.1.1.1.1.1.3.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3">subscript</csymbol><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.3.2.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.2">ğ‘¿</ci><apply id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3"><times id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.1.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.1"></times><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.2.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.2">ğ‘–</ci><ci id="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.3.cmml" xref="S3.p4.12.m12.4.4.1.1.1.1.1.3.3.3">ğ‘—</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.12.m12.4c">\operatorname{\bm{wm_{\hat{P}}}}(\bm{X})=\sum_{i=1}^{h^{\prime}}\sum_{j=1}^{w^%
{\prime}}\bigl{(}\text{norm}(\bm{\hat{P}})_{ij}\cdot\bm{X}_{ij}\bigr{)}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.12.m12.4d">start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( bold_italic_X ) = âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( norm ( overbold_^ start_ARG bold_italic_P end_ARG ) start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT â‹… bold_italic_X start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.13" style="font-size:90%;">, where </span><math alttext="\text{norm}(\cdot)" class="ltx_Math" display="inline" id="S3.p4.13.m13.1"><semantics id="S3.p4.13.m13.1a"><mrow id="S3.p4.13.m13.1.2" xref="S3.p4.13.m13.1.2.cmml"><mtext id="S3.p4.13.m13.1.2.2" mathsize="90%" xref="S3.p4.13.m13.1.2.2a.cmml">norm</mtext><mo id="S3.p4.13.m13.1.2.1" xref="S3.p4.13.m13.1.2.1.cmml">â¢</mo><mrow id="S3.p4.13.m13.1.2.3.2" xref="S3.p4.13.m13.1.2.cmml"><mo id="S3.p4.13.m13.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.p4.13.m13.1.2.cmml">(</mo><mo id="S3.p4.13.m13.1.1" lspace="0em" mathsize="90%" rspace="0em" xref="S3.p4.13.m13.1.1.cmml">â‹…</mo><mo id="S3.p4.13.m13.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.p4.13.m13.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.13.m13.1b"><apply id="S3.p4.13.m13.1.2.cmml" xref="S3.p4.13.m13.1.2"><times id="S3.p4.13.m13.1.2.1.cmml" xref="S3.p4.13.m13.1.2.1"></times><ci id="S3.p4.13.m13.1.2.2a.cmml" xref="S3.p4.13.m13.1.2.2"><mtext id="S3.p4.13.m13.1.2.2.cmml" mathsize="90%" xref="S3.p4.13.m13.1.2.2">norm</mtext></ci><ci id="S3.p4.13.m13.1.1.cmml" xref="S3.p4.13.m13.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.13.m13.1c">\text{norm}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.p4.13.m13.1d">norm ( â‹… )</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.14" style="font-size:90%;"> normalizes the map s.t. its cells sum to one.
Specifically for orientation, we obtain the value of the angle from the predicted sine and cosine maps as </span><math alttext="\hat{\psi}=\text{atan2}\bigl{(}\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{O}}_{%
\text{sin}}^{\psi}),\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{O}}_{\text{cos}}%
^{\psi})\bigr{)}" class="ltx_Math" display="inline" id="S3.p4.14.m14.4"><semantics id="S3.p4.14.m14.4a"><mrow id="S3.p4.14.m14.4.4" xref="S3.p4.14.m14.4.4.cmml"><mover accent="true" id="S3.p4.14.m14.4.4.4" xref="S3.p4.14.m14.4.4.4.cmml"><mi id="S3.p4.14.m14.4.4.4.2" mathsize="90%" xref="S3.p4.14.m14.4.4.4.2.cmml">Ïˆ</mi><mo id="S3.p4.14.m14.4.4.4.1" mathsize="90%" xref="S3.p4.14.m14.4.4.4.1.cmml">^</mo></mover><mo id="S3.p4.14.m14.4.4.3" mathsize="90%" xref="S3.p4.14.m14.4.4.3.cmml">=</mo><mrow id="S3.p4.14.m14.4.4.2" xref="S3.p4.14.m14.4.4.2.cmml"><mtext id="S3.p4.14.m14.4.4.2.4" mathsize="90%" xref="S3.p4.14.m14.4.4.2.4a.cmml">atan2</mtext><mo id="S3.p4.14.m14.4.4.2.3" xref="S3.p4.14.m14.4.4.2.3.cmml">â¢</mo><mrow id="S3.p4.14.m14.4.4.2.2.2" xref="S3.p4.14.m14.4.4.2.2.3.cmml"><mo id="S3.p4.14.m14.4.4.2.2.2.3" maxsize="120%" minsize="120%" xref="S3.p4.14.m14.4.4.2.2.3.cmml">(</mo><mrow id="S3.p4.14.m14.3.3.1.1.1.1.1" xref="S3.p4.14.m14.3.3.1.1.1.1.2.cmml"><msub id="S3.p4.14.m14.1.1" xref="S3.p4.14.m14.1.1.cmml"><mi id="S3.p4.14.m14.1.1.2" mathsize="90%" xref="S3.p4.14.m14.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.p4.14.m14.1.1.3" xref="S3.p4.14.m14.1.1.3.cmml"><mi id="S3.p4.14.m14.1.1.3.2" mathsize="90%" xref="S3.p4.14.m14.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.p4.14.m14.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.p4.14.m14.1.1.3.1.cmml">^</mo></mover></msub><mo id="S3.p4.14.m14.3.3.1.1.1.1.1a" xref="S3.p4.14.m14.3.3.1.1.1.1.2.cmml">â¡</mo><mrow id="S3.p4.14.m14.3.3.1.1.1.1.1.1" xref="S3.p4.14.m14.3.3.1.1.1.1.2.cmml"><mo id="S3.p4.14.m14.3.3.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.p4.14.m14.3.3.1.1.1.1.2.cmml">(</mo><msubsup id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.2" mathsize="90%" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.1" mathsize="90%" mathvariant="bold" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.3" mathsize="90%" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.3a.cmml">sin</mtext><mi id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.3" mathsize="90%" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.3.cmml">Ïˆ</mi></msubsup><mo id="S3.p4.14.m14.3.3.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.p4.14.m14.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.p4.14.m14.4.4.2.2.2.4" mathsize="90%" xref="S3.p4.14.m14.4.4.2.2.3.cmml">,</mo><mrow id="S3.p4.14.m14.4.4.2.2.2.2.1" xref="S3.p4.14.m14.4.4.2.2.2.2.2.cmml"><msub id="S3.p4.14.m14.2.2" xref="S3.p4.14.m14.2.2.cmml"><mi id="S3.p4.14.m14.2.2.2" mathsize="90%" xref="S3.p4.14.m14.2.2.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.p4.14.m14.2.2.3" xref="S3.p4.14.m14.2.2.3.cmml"><mi id="S3.p4.14.m14.2.2.3.2" mathsize="90%" xref="S3.p4.14.m14.2.2.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.p4.14.m14.2.2.3.1" mathsize="90%" mathvariant="bold" xref="S3.p4.14.m14.2.2.3.1.cmml">^</mo></mover></msub><mo id="S3.p4.14.m14.4.4.2.2.2.2.1a" xref="S3.p4.14.m14.4.4.2.2.2.2.2.cmml">â¡</mo><mrow id="S3.p4.14.m14.4.4.2.2.2.2.1.1" xref="S3.p4.14.m14.4.4.2.2.2.2.2.cmml"><mo id="S3.p4.14.m14.4.4.2.2.2.2.1.1.2" maxsize="90%" minsize="90%" xref="S3.p4.14.m14.4.4.2.2.2.2.2.cmml">(</mo><msubsup id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.cmml"><mover accent="true" id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.cmml"><mi id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.2" mathsize="90%" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.1" mathsize="90%" mathvariant="bold" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.3" mathsize="90%" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.3a.cmml">cos</mtext><mi id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.3" mathsize="90%" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.3.cmml">Ïˆ</mi></msubsup><mo id="S3.p4.14.m14.4.4.2.2.2.2.1.1.3" maxsize="90%" minsize="90%" xref="S3.p4.14.m14.4.4.2.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S3.p4.14.m14.4.4.2.2.2.5" maxsize="120%" minsize="120%" xref="S3.p4.14.m14.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.14.m14.4b"><apply id="S3.p4.14.m14.4.4.cmml" xref="S3.p4.14.m14.4.4"><eq id="S3.p4.14.m14.4.4.3.cmml" xref="S3.p4.14.m14.4.4.3"></eq><apply id="S3.p4.14.m14.4.4.4.cmml" xref="S3.p4.14.m14.4.4.4"><ci id="S3.p4.14.m14.4.4.4.1.cmml" xref="S3.p4.14.m14.4.4.4.1">^</ci><ci id="S3.p4.14.m14.4.4.4.2.cmml" xref="S3.p4.14.m14.4.4.4.2">ğœ“</ci></apply><apply id="S3.p4.14.m14.4.4.2.cmml" xref="S3.p4.14.m14.4.4.2"><times id="S3.p4.14.m14.4.4.2.3.cmml" xref="S3.p4.14.m14.4.4.2.3"></times><ci id="S3.p4.14.m14.4.4.2.4a.cmml" xref="S3.p4.14.m14.4.4.2.4"><mtext id="S3.p4.14.m14.4.4.2.4.cmml" mathsize="90%" xref="S3.p4.14.m14.4.4.2.4">atan2</mtext></ci><interval closure="open" id="S3.p4.14.m14.4.4.2.2.3.cmml" xref="S3.p4.14.m14.4.4.2.2.2"><apply id="S3.p4.14.m14.3.3.1.1.1.1.2.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1"><apply id="S3.p4.14.m14.1.1.cmml" xref="S3.p4.14.m14.1.1"><csymbol cd="ambiguous" id="S3.p4.14.m14.1.1.1.cmml" xref="S3.p4.14.m14.1.1">subscript</csymbol><ci id="S3.p4.14.m14.1.1.2.cmml" xref="S3.p4.14.m14.1.1.2">ğ°ğ¦</ci><apply id="S3.p4.14.m14.1.1.3.cmml" xref="S3.p4.14.m14.1.1.3"><ci id="S3.p4.14.m14.1.1.3.1.cmml" xref="S3.p4.14.m14.1.1.3.1">bold-^</ci><ci id="S3.p4.14.m14.1.1.3.2.cmml" xref="S3.p4.14.m14.1.1.3.2">ğ</ci></apply></apply><apply id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2"><ci id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.1">bold-^</ci><ci id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.2.2">ğ‘¶</ci></apply><ci id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.3a.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.3"><mtext id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.3.cmml" mathsize="63%" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.2.3">sin</mtext></ci></apply><ci id="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.p4.14.m14.3.3.1.1.1.1.1.1.1.3">ğœ“</ci></apply></apply><apply id="S3.p4.14.m14.4.4.2.2.2.2.2.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1"><apply id="S3.p4.14.m14.2.2.cmml" xref="S3.p4.14.m14.2.2"><csymbol cd="ambiguous" id="S3.p4.14.m14.2.2.1.cmml" xref="S3.p4.14.m14.2.2">subscript</csymbol><ci id="S3.p4.14.m14.2.2.2.cmml" xref="S3.p4.14.m14.2.2.2">ğ°ğ¦</ci><apply id="S3.p4.14.m14.2.2.3.cmml" xref="S3.p4.14.m14.2.2.3"><ci id="S3.p4.14.m14.2.2.3.1.cmml" xref="S3.p4.14.m14.2.2.3.1">bold-^</ci><ci id="S3.p4.14.m14.2.2.3.2.cmml" xref="S3.p4.14.m14.2.2.3.2">ğ</ci></apply></apply><apply id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.1.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1">superscript</csymbol><apply id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.1.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1">subscript</csymbol><apply id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2"><ci id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.1.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.1">bold-^</ci><ci id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.2.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.2.2">ğ‘¶</ci></apply><ci id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.3a.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.3"><mtext id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.3.cmml" mathsize="63%" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.2.3">cos</mtext></ci></apply><ci id="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.3.cmml" xref="S3.p4.14.m14.4.4.2.2.2.2.1.1.1.3">ğœ“</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.14.m14.4c">\hat{\psi}=\text{atan2}\bigl{(}\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{O}}_{%
\text{sin}}^{\psi}),\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{O}}_{\text{cos}}%
^{\psi})\bigr{)}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.14.m14.4d">over^ start_ARG italic_Ïˆ end_ARG = atan2 ( start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( overbold_^ start_ARG bold_italic_O end_ARG start_POSTSUBSCRIPT sin end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Ïˆ end_POSTSUPERSCRIPT ) , start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( overbold_^ start_ARG bold_italic_O end_ARG start_POSTSUBSCRIPT cos end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Ïˆ end_POSTSUPERSCRIPT ) )</annotation></semantics></math><span class="ltx_text" id="S3.p4.14.15" style="font-size:90%;">.</span></p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Losses</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.11"><span class="ltx_text" id="S3.SS1.p1.11.1" style="font-size:90%;">We train our model on one of two losses based on the availability of labels for the pose estimation task:
we define the downstream or end task loss as </span><math alttext="\mathcal{L}_{\text{task}}=\frac{1}{3}(\mathcal{L}_{\text{pos}}+\mathcal{L}_{%
\text{dist}}+\mathcal{L}_{\text{ori}})" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.3.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">â„’</mi><mtext id="S3.SS1.p1.1.m1.1.1.3.3" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.3.3a.cmml">task</mtext></msub><mo id="S3.SS1.p1.1.m1.1.1.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.2.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml"><mfrac id="S3.SS1.p1.1.m1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.3.cmml"><mn id="S3.SS1.p1.1.m1.1.1.1.3.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.3.2.cmml">1</mn><mn id="S3.SS1.p1.1.m1.1.1.1.3.3" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.3.3.cmml">3</mn></mfrac><mo id="S3.SS1.p1.1.m1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS1.p1.1.m1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml"><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.2.cmml">â„’</mi><mtext id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.3" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.3a.cmml">pos</mtext></msub><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.2.cmml">â„’</mi><mtext id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.3" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.3a.cmml">dist</mtext></msub><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1a" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.2.cmml">â„’</mi><mtext id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.3" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.3a.cmml">ori</mtext></msub></mrow><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><eq id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2"></eq><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">â„’</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3a.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3"><mtext id="S3.SS1.p1.1.m1.1.1.3.3.cmml" mathsize="63%" xref="S3.SS1.p1.1.m1.1.1.3.3">task</mtext></ci></apply><apply id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"><times id="S3.SS1.p1.1.m1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.2"></times><apply id="S3.SS1.p1.1.m1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.3"><divide id="S3.SS1.p1.1.m1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.3"></divide><cn id="S3.SS1.p1.1.m1.1.1.1.3.2.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.1.3.2">1</cn><cn id="S3.SS1.p1.1.m1.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.1.3.3">3</cn></apply><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1"><plus id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1"></plus><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.2">â„’</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.3a.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.3"><mtext id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.3.cmml" mathsize="63%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.2.3">pos</mtext></ci></apply><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.2">â„’</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.3a.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.3"><mtext id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.3.cmml" mathsize="63%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.3.3">dist</mtext></ci></apply><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.2">â„’</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.3a.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.3"><mtext id="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.3.cmml" mathsize="63%" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.4.3">ori</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathcal{L}_{\text{task}}=\frac{1}{3}(\mathcal{L}_{\text{pos}}+\mathcal{L}_{%
\text{dist}}+\mathcal{L}_{\text{ori}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT task end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG 3 end_ARG ( caligraphic_L start_POSTSUBSCRIPT pos end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT ori end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.2" style="font-size:90%;">, trained on the labeled set </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1.2" mathsize="90%" xref="S3.SS1.p1.2.m2.1.1.2.cmml">ğ’¯</mi><mi id="S3.SS1.p1.2.m2.1.1.3" mathsize="90%" mathvariant="normal" xref="S3.SS1.p1.2.m2.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ’¯</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.3" style="font-size:90%;">, and the LED-based pretext loss </span><math alttext="\mathcal{L}_{\text{led}}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.3.m3.1.1.2" mathsize="90%" xref="S3.SS1.p1.3.m3.1.1.2.cmml">â„’</mi><mtext id="S3.SS1.p1.3.m3.1.1.3" mathsize="90%" xref="S3.SS1.p1.3.m3.1.1.3a.cmml">led</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">â„’</ci><ci id="S3.SS1.p1.3.m3.1.1.3a.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><mtext id="S3.SS1.p1.3.m3.1.1.3.cmml" mathsize="63%" xref="S3.SS1.p1.3.m3.1.1.3">led</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathcal{L}_{\text{led}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT led end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.4" style="font-size:90%;">, trained on </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msubsup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.4.m4.1.1.2.2" mathsize="90%" xref="S3.SS1.p1.4.m4.1.1.2.2.cmml">ğ’¯</mi><mi id="S3.SS1.p1.4.m4.1.1.2.3" mathsize="90%" xref="S3.SS1.p1.4.m4.1.1.2.3.cmml">u</mi><mi id="S3.SS1.p1.4.m4.1.1.3" mathsize="90%" xref="S3.SS1.p1.4.m4.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">superscript</csymbol><apply id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2.2">ğ’¯</ci><ci id="S3.SS1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.2.3">ğ‘¢</ci></apply><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.5" style="font-size:90%;"> or the visible subset </span><math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msubsup id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.5.m5.1.1.2.2" mathsize="90%" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">ğ’¯</mi><mi id="S3.SS1.p1.5.m5.1.1.2.3" mathsize="90%" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml">u</mi><mi id="S3.SS1.p1.5.m5.1.1.3" mathsize="90%" xref="S3.SS1.p1.5.m5.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">superscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">ğ’¯</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3">ğ‘¢</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.6" style="font-size:90%;">; all losses are designed to be bounded between zero and one.
To compute the position loss we first generate the ground truth map </span><math alttext="\bm{{P}}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" mathsize="90%" xref="S3.SS1.p1.6.m6.1.1.cmml">ğ‘·</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ğ‘·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\bm{{P}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">bold_italic_P</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.7" style="font-size:90%;">. To do this, we set cells in a circle of radius </span><math alttext="r" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" mathsize="90%" xref="S3.SS1.p1.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_r</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.8" style="font-size:90%;"> centered in </span><math alttext="uv" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1"><semantics id="S3.SS1.p1.8.m8.1a"><mrow id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2" mathsize="90%" xref="S3.SS1.p1.8.m8.1.1.2.cmml">u</mi><mo id="S3.SS1.p1.8.m8.1.1.1" xref="S3.SS1.p1.8.m8.1.1.1.cmml">â¢</mo><mi id="S3.SS1.p1.8.m8.1.1.3" mathsize="90%" xref="S3.SS1.p1.8.m8.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><times id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1"></times><ci id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2">ğ‘¢</ci><ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.9" style="font-size:90%;"> to one while the remaining cells are set to zero. We then calculate the element-wise product between the normalized position map and the ground truth one using </span><math alttext="\operatorname{\bm{wm_{\hat{P}}}}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1"><semantics id="S3.SS1.p1.9.m9.1a"><msub id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" mathsize="90%" xref="S3.SS1.p1.9.m9.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.2" mathsize="90%" xref="S3.SS1.p1.9.m9.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.SS1.p1.9.m9.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.SS1.p1.9.m9.1.1.3.1.cmml">^</mo></mover></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">ğ°ğ¦</ci><apply id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3"><ci id="S3.SS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3.1">bold-^</ci><ci id="S3.SS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.2">ğ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\operatorname{\bm{wm_{\hat{P}}}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m9.1d">bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.10" style="font-size:90%;">. By doing this, we measure the portion of pixels with high value in the predicted map </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1"><semantics id="S3.SS1.p1.10.m10.1a"><mover accent="true" id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2" mathsize="90%" xref="S3.SS1.p1.10.m10.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.SS1.p1.10.m10.1.1.1" mathsize="90%" mathvariant="bold" xref="S3.SS1.p1.10.m10.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><ci id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1">bold-^</ci><ci id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m10.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.11" style="font-size:90%;"> that share the same coordinates with high-valued elements in </span><math alttext="\bm{P}" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m11.1"><semantics id="S3.SS1.p1.11.m11.1a"><mi id="S3.SS1.p1.11.m11.1.1" mathsize="90%" xref="S3.SS1.p1.11.m11.1.1.cmml">ğ‘·</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><ci id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">ğ‘·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">\bm{P}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m11.1d">bold_italic_P</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.11.12" style="font-size:90%;">.
This loss reaches zero only when predicted and ground truth maps perfectly overlap.</span></p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{pos}}=1-\operatorname{\bm{wm_{\hat{P}}}}(\bm{P})" class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.3" xref="S3.E1.m1.2.3.cmml"><msub id="S3.E1.m1.2.3.2" xref="S3.E1.m1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.3.2.2" mathsize="90%" xref="S3.E1.m1.2.3.2.2.cmml">â„’</mi><mtext id="S3.E1.m1.2.3.2.3" mathsize="90%" xref="S3.E1.m1.2.3.2.3a.cmml">pos</mtext></msub><mo id="S3.E1.m1.2.3.1" mathsize="90%" xref="S3.E1.m1.2.3.1.cmml">=</mo><mrow id="S3.E1.m1.2.3.3" xref="S3.E1.m1.2.3.3.cmml"><mn id="S3.E1.m1.2.3.3.2" mathsize="90%" xref="S3.E1.m1.2.3.3.2.cmml">1</mn><mo id="S3.E1.m1.2.3.3.1" mathsize="90%" xref="S3.E1.m1.2.3.3.1.cmml">âˆ’</mo><mrow id="S3.E1.m1.2.3.3.3.2" xref="S3.E1.m1.2.3.3.3.1.cmml"><msub id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mi id="S3.E1.m1.1.1.2" mathsize="90%" xref="S3.E1.m1.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.3.2" mathsize="90%" xref="S3.E1.m1.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.E1.m1.1.1.3.1.cmml">^</mo></mover></msub><mo id="S3.E1.m1.2.3.3.3.2a" xref="S3.E1.m1.2.3.3.3.1.cmml">â¡</mo><mrow id="S3.E1.m1.2.3.3.3.2.1" xref="S3.E1.m1.2.3.3.3.1.cmml"><mo id="S3.E1.m1.2.3.3.3.2.1.1" maxsize="90%" minsize="90%" xref="S3.E1.m1.2.3.3.3.1.cmml">(</mo><mi id="S3.E1.m1.2.2" mathsize="90%" xref="S3.E1.m1.2.2.cmml">ğ‘·</mi><mo id="S3.E1.m1.2.3.3.3.2.1.2" maxsize="90%" minsize="90%" xref="S3.E1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.3.cmml" xref="S3.E1.m1.2.3"><eq id="S3.E1.m1.2.3.1.cmml" xref="S3.E1.m1.2.3.1"></eq><apply id="S3.E1.m1.2.3.2.cmml" xref="S3.E1.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.3.2.1.cmml" xref="S3.E1.m1.2.3.2">subscript</csymbol><ci id="S3.E1.m1.2.3.2.2.cmml" xref="S3.E1.m1.2.3.2.2">â„’</ci><ci id="S3.E1.m1.2.3.2.3a.cmml" xref="S3.E1.m1.2.3.2.3"><mtext id="S3.E1.m1.2.3.2.3.cmml" mathsize="63%" xref="S3.E1.m1.2.3.2.3">pos</mtext></ci></apply><apply id="S3.E1.m1.2.3.3.cmml" xref="S3.E1.m1.2.3.3"><minus id="S3.E1.m1.2.3.3.1.cmml" xref="S3.E1.m1.2.3.3.1"></minus><cn id="S3.E1.m1.2.3.3.2.cmml" type="integer" xref="S3.E1.m1.2.3.3.2">1</cn><apply id="S3.E1.m1.2.3.3.3.1.cmml" xref="S3.E1.m1.2.3.3.3.2"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">ğ°ğ¦</ci><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><ci id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1">bold-^</ci><ci id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2">ğ</ci></apply></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğ‘·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\mathcal{L}_{\text{pos}}=1-\operatorname{\bm{wm_{\hat{P}}}}(\bm{P})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">caligraphic_L start_POSTSUBSCRIPT pos end_POSTSUBSCRIPT = 1 - start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( bold_italic_P )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.13"><span class="ltx_text" id="S3.SS1.p1.13.1" style="font-size:90%;">The distance loss uses </span><math alttext="\operatorname{\bm{wm_{\hat{P}}}}" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m1.1"><semantics id="S3.SS1.p1.12.m1.1a"><msub id="S3.SS1.p1.12.m1.1.1" xref="S3.SS1.p1.12.m1.1.1.cmml"><mi id="S3.SS1.p1.12.m1.1.1.2" mathsize="90%" xref="S3.SS1.p1.12.m1.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.SS1.p1.12.m1.1.1.3" xref="S3.SS1.p1.12.m1.1.1.3.cmml"><mi id="S3.SS1.p1.12.m1.1.1.3.2" mathsize="90%" xref="S3.SS1.p1.12.m1.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.SS1.p1.12.m1.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.SS1.p1.12.m1.1.1.3.1.cmml">^</mo></mover></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m1.1b"><apply id="S3.SS1.p1.12.m1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m1.1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.12.m1.1.1.2.cmml" xref="S3.SS1.p1.12.m1.1.1.2">ğ°ğ¦</ci><apply id="S3.SS1.p1.12.m1.1.1.3.cmml" xref="S3.SS1.p1.12.m1.1.1.3"><ci id="S3.SS1.p1.12.m1.1.1.3.1.cmml" xref="S3.SS1.p1.12.m1.1.1.3.1">bold-^</ci><ci id="S3.SS1.p1.12.m1.1.1.3.2.cmml" xref="S3.SS1.p1.12.m1.1.1.3.2">ğ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m1.1c">\operatorname{\bm{wm_{\hat{P}}}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.12.m1.1d">bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.13.2" style="font-size:90%;"> to recover </span><math alttext="\hat{d}" class="ltx_Math" display="inline" id="S3.SS1.p1.13.m2.1"><semantics id="S3.SS1.p1.13.m2.1a"><mover accent="true" id="S3.SS1.p1.13.m2.1.1" xref="S3.SS1.p1.13.m2.1.1.cmml"><mi id="S3.SS1.p1.13.m2.1.1.2" mathsize="90%" xref="S3.SS1.p1.13.m2.1.1.2.cmml">d</mi><mo id="S3.SS1.p1.13.m2.1.1.1" mathsize="90%" xref="S3.SS1.p1.13.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m2.1b"><apply id="S3.SS1.p1.13.m2.1.1.cmml" xref="S3.SS1.p1.13.m2.1.1"><ci id="S3.SS1.p1.13.m2.1.1.1.cmml" xref="S3.SS1.p1.13.m2.1.1.1">^</ci><ci id="S3.SS1.p1.13.m2.1.1.2.cmml" xref="S3.SS1.p1.13.m2.1.1.2">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m2.1c">\hat{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.13.m2.1d">over^ start_ARG italic_d end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.13.3" style="font-size:90%;"> and then computes the mean squared error with the ground truth distance</span></p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{dist}}=\frac{1}{d_{\text{max}}^{2}}\text{mse}\bigl{(}d,%
\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{D}})\bigr{)}" class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><msub id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.4.4.3.2" mathsize="90%" xref="S3.E2.m1.4.4.3.2.cmml">â„’</mi><mtext id="S3.E2.m1.4.4.3.3" mathsize="90%" xref="S3.E2.m1.4.4.3.3a.cmml">dist</mtext></msub><mo id="S3.E2.m1.4.4.2" mathsize="90%" xref="S3.E2.m1.4.4.2.cmml">=</mo><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.cmml"><mfrac id="S3.E2.m1.4.4.1.3" xref="S3.E2.m1.4.4.1.3.cmml"><mn id="S3.E2.m1.4.4.1.3.2" mathsize="90%" xref="S3.E2.m1.4.4.1.3.2.cmml">1</mn><msubsup id="S3.E2.m1.4.4.1.3.3" xref="S3.E2.m1.4.4.1.3.3.cmml"><mi id="S3.E2.m1.4.4.1.3.3.2.2" mathsize="90%" xref="S3.E2.m1.4.4.1.3.3.2.2.cmml">d</mi><mtext id="S3.E2.m1.4.4.1.3.3.2.3" mathsize="90%" xref="S3.E2.m1.4.4.1.3.3.2.3a.cmml">max</mtext><mn id="S3.E2.m1.4.4.1.3.3.3" mathsize="90%" xref="S3.E2.m1.4.4.1.3.3.3.cmml">2</mn></msubsup></mfrac><mo id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.2.cmml">â¢</mo><mtext id="S3.E2.m1.4.4.1.4" mathsize="90%" xref="S3.E2.m1.4.4.1.4a.cmml">mse</mtext><mo id="S3.E2.m1.4.4.1.2a" xref="S3.E2.m1.4.4.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.1.2.cmml"><mo id="S3.E2.m1.4.4.1.1.1.2" maxsize="120%" minsize="120%" xref="S3.E2.m1.4.4.1.1.2.cmml">(</mo><mi id="S3.E2.m1.3.3" mathsize="90%" xref="S3.E2.m1.3.3.cmml">d</mi><mo id="S3.E2.m1.4.4.1.1.1.3" mathsize="90%" xref="S3.E2.m1.4.4.1.1.2.cmml">,</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.2" mathsize="90%" xref="S3.E2.m1.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.3.2" mathsize="90%" xref="S3.E2.m1.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.E2.m1.1.1.3.1.cmml">^</mo></mover></msub><mo id="S3.E2.m1.4.4.1.1.1.1.2a" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml">â¡</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.2.1" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml"><mo id="S3.E2.m1.4.4.1.1.1.1.2.1.1" maxsize="90%" minsize="90%" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml">(</mo><mover accent="true" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mi id="S3.E2.m1.2.2.2" mathsize="90%" xref="S3.E2.m1.2.2.2.cmml">ğ‘«</mi><mo class="ltx_mathvariant_bold" id="S3.E2.m1.2.2.1" mathsize="90%" mathvariant="bold" xref="S3.E2.m1.2.2.1.cmml">^</mo></mover><mo id="S3.E2.m1.4.4.1.1.1.1.2.1.2" maxsize="90%" minsize="90%" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.4.1.1.1.4" maxsize="120%" minsize="120%" xref="S3.E2.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><eq id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"></eq><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.1.cmml" xref="S3.E2.m1.4.4.3">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2">â„’</ci><ci id="S3.E2.m1.4.4.3.3a.cmml" xref="S3.E2.m1.4.4.3.3"><mtext id="S3.E2.m1.4.4.3.3.cmml" mathsize="63%" xref="S3.E2.m1.4.4.3.3">dist</mtext></ci></apply><apply id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.4.1"><times id="S3.E2.m1.4.4.1.2.cmml" xref="S3.E2.m1.4.4.1.2"></times><apply id="S3.E2.m1.4.4.1.3.cmml" xref="S3.E2.m1.4.4.1.3"><divide id="S3.E2.m1.4.4.1.3.1.cmml" xref="S3.E2.m1.4.4.1.3"></divide><cn id="S3.E2.m1.4.4.1.3.2.cmml" type="integer" xref="S3.E2.m1.4.4.1.3.2">1</cn><apply id="S3.E2.m1.4.4.1.3.3.cmml" xref="S3.E2.m1.4.4.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.3.3.1.cmml" xref="S3.E2.m1.4.4.1.3.3">superscript</csymbol><apply id="S3.E2.m1.4.4.1.3.3.2.cmml" xref="S3.E2.m1.4.4.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.3.3.2.1.cmml" xref="S3.E2.m1.4.4.1.3.3">subscript</csymbol><ci id="S3.E2.m1.4.4.1.3.3.2.2.cmml" xref="S3.E2.m1.4.4.1.3.3.2.2">ğ‘‘</ci><ci id="S3.E2.m1.4.4.1.3.3.2.3a.cmml" xref="S3.E2.m1.4.4.1.3.3.2.3"><mtext id="S3.E2.m1.4.4.1.3.3.2.3.cmml" mathsize="63%" xref="S3.E2.m1.4.4.1.3.3.2.3">max</mtext></ci></apply><cn id="S3.E2.m1.4.4.1.3.3.3.cmml" type="integer" xref="S3.E2.m1.4.4.1.3.3.3">2</cn></apply></apply><ci id="S3.E2.m1.4.4.1.4a.cmml" xref="S3.E2.m1.4.4.1.4"><mtext id="S3.E2.m1.4.4.1.4.cmml" mathsize="90%" xref="S3.E2.m1.4.4.1.4">mse</mtext></ci><interval closure="open" id="S3.E2.m1.4.4.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1"><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">ğ‘‘</ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2">ğ°ğ¦</ci><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><ci id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3.1">bold-^</ci><ci id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2">ğ</ci></apply></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><ci id="S3.E2.m1.2.2.1.cmml" xref="S3.E2.m1.2.2.1">bold-^</ci><ci id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2">ğ‘«</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\mathcal{L}_{\text{dist}}=\frac{1}{d_{\text{max}}^{2}}\text{mse}\bigl{(}d,%
\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{D}})\bigr{)}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">caligraphic_L start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_d start_POSTSUBSCRIPT max end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG mse ( italic_d , start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( overbold_^ start_ARG bold_italic_D end_ARG ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.15"><span class="ltx_text" id="S3.SS1.p1.15.1" style="font-size:90%;">The orientation loss is defined as the sum of the mean squared error on the sine and cosine maps of each angle</span></p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{ori}}=\frac{1}{4}\sum_{f\in\{\text{sin},\text{cos}\}}\text{%
mse}\bigl{(}f(\psi),\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{O}}_{f}^{\psi})%
\bigr{)}" class="ltx_Math" display="block" id="S3.E3.m1.6"><semantics id="S3.E3.m1.6a"><mrow id="S3.E3.m1.6.6" xref="S3.E3.m1.6.6.cmml"><msub id="S3.E3.m1.6.6.4" xref="S3.E3.m1.6.6.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.6.6.4.2" mathsize="90%" xref="S3.E3.m1.6.6.4.2.cmml">â„’</mi><mtext id="S3.E3.m1.6.6.4.3" mathsize="90%" xref="S3.E3.m1.6.6.4.3a.cmml">ori</mtext></msub><mo id="S3.E3.m1.6.6.3" mathsize="90%" xref="S3.E3.m1.6.6.3.cmml">=</mo><mrow id="S3.E3.m1.6.6.2" xref="S3.E3.m1.6.6.2.cmml"><mfrac id="S3.E3.m1.6.6.2.4" xref="S3.E3.m1.6.6.2.4.cmml"><mn id="S3.E3.m1.6.6.2.4.2" mathsize="90%" xref="S3.E3.m1.6.6.2.4.2.cmml">1</mn><mn id="S3.E3.m1.6.6.2.4.3" mathsize="90%" xref="S3.E3.m1.6.6.2.4.3.cmml">4</mn></mfrac><mo id="S3.E3.m1.6.6.2.3" xref="S3.E3.m1.6.6.2.3.cmml">â¢</mo><mrow id="S3.E3.m1.6.6.2.2" xref="S3.E3.m1.6.6.2.2.cmml"><munder id="S3.E3.m1.6.6.2.2.3" xref="S3.E3.m1.6.6.2.2.3.cmml"><mo id="S3.E3.m1.6.6.2.2.3.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S3.E3.m1.6.6.2.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.4" mathsize="90%" xref="S3.E3.m1.2.2.2.4.cmml">f</mi><mo id="S3.E3.m1.2.2.2.3" mathsize="90%" xref="S3.E3.m1.2.2.2.3.cmml">âˆˆ</mo><mrow id="S3.E3.m1.2.2.2.5.2" xref="S3.E3.m1.2.2.2.5.1.cmml"><mo id="S3.E3.m1.2.2.2.5.2.1" maxsize="90%" minsize="90%" xref="S3.E3.m1.2.2.2.5.1.cmml">{</mo><mtext id="S3.E3.m1.1.1.1.1" mathsize="90%" xref="S3.E3.m1.1.1.1.1a.cmml">sin</mtext><mo id="S3.E3.m1.2.2.2.5.2.2" mathsize="90%" xref="S3.E3.m1.2.2.2.5.1.cmml">,</mo><mtext id="S3.E3.m1.2.2.2.2" mathsize="90%" xref="S3.E3.m1.2.2.2.2a.cmml">cos</mtext><mo id="S3.E3.m1.2.2.2.5.2.3" maxsize="90%" minsize="90%" xref="S3.E3.m1.2.2.2.5.1.cmml">}</mo></mrow></mrow></munder><mrow id="S3.E3.m1.6.6.2.2.2" xref="S3.E3.m1.6.6.2.2.2.cmml"><mtext id="S3.E3.m1.6.6.2.2.2.4" mathsize="90%" xref="S3.E3.m1.6.6.2.2.2.4a.cmml">mse</mtext><mo id="S3.E3.m1.6.6.2.2.2.3" xref="S3.E3.m1.6.6.2.2.2.3.cmml">â¢</mo><mrow id="S3.E3.m1.6.6.2.2.2.2.2" xref="S3.E3.m1.6.6.2.2.2.2.3.cmml"><mo id="S3.E3.m1.6.6.2.2.2.2.2.3" maxsize="120%" minsize="120%" xref="S3.E3.m1.6.6.2.2.2.2.3.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.2" mathsize="90%" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml">f</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.3.3" mathsize="90%" xref="S3.E3.m1.3.3.cmml">Ïˆ</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.6.6.2.2.2.2.2.4" mathsize="90%" xref="S3.E3.m1.6.6.2.2.2.2.3.cmml">,</mo><mrow id="S3.E3.m1.6.6.2.2.2.2.2.2.1" xref="S3.E3.m1.6.6.2.2.2.2.2.2.2.cmml"><msub id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml"><mi id="S3.E3.m1.4.4.2" mathsize="90%" xref="S3.E3.m1.4.4.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.E3.m1.4.4.3" xref="S3.E3.m1.4.4.3.cmml"><mi id="S3.E3.m1.4.4.3.2" mathsize="90%" xref="S3.E3.m1.4.4.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.E3.m1.4.4.3.1" mathsize="90%" mathvariant="bold" xref="S3.E3.m1.4.4.3.1.cmml">^</mo></mover></msub><mo id="S3.E3.m1.6.6.2.2.2.2.2.2.1a" xref="S3.E3.m1.6.6.2.2.2.2.2.2.2.cmml">â¡</mo><mrow id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1" xref="S3.E3.m1.6.6.2.2.2.2.2.2.2.cmml"><mo id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.6.6.2.2.2.2.2.2.2.cmml">(</mo><msubsup id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.cmml"><mi id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.2" mathsize="90%" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.2.cmml">ğ‘¶</mi><mo class="ltx_mathvariant_bold" id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.1" mathsize="90%" mathvariant="bold" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.3" mathsize="90%" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.3.cmml">f</mi><mi id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.3" mathsize="90%" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.3.cmml">Ïˆ</mi></msubsup><mo id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.3" maxsize="90%" minsize="90%" xref="S3.E3.m1.6.6.2.2.2.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.6.6.2.2.2.2.2.5" maxsize="120%" minsize="120%" xref="S3.E3.m1.6.6.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.6b"><apply id="S3.E3.m1.6.6.cmml" xref="S3.E3.m1.6.6"><eq id="S3.E3.m1.6.6.3.cmml" xref="S3.E3.m1.6.6.3"></eq><apply id="S3.E3.m1.6.6.4.cmml" xref="S3.E3.m1.6.6.4"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.4.1.cmml" xref="S3.E3.m1.6.6.4">subscript</csymbol><ci id="S3.E3.m1.6.6.4.2.cmml" xref="S3.E3.m1.6.6.4.2">â„’</ci><ci id="S3.E3.m1.6.6.4.3a.cmml" xref="S3.E3.m1.6.6.4.3"><mtext id="S3.E3.m1.6.6.4.3.cmml" mathsize="63%" xref="S3.E3.m1.6.6.4.3">ori</mtext></ci></apply><apply id="S3.E3.m1.6.6.2.cmml" xref="S3.E3.m1.6.6.2"><times id="S3.E3.m1.6.6.2.3.cmml" xref="S3.E3.m1.6.6.2.3"></times><apply id="S3.E3.m1.6.6.2.4.cmml" xref="S3.E3.m1.6.6.2.4"><divide id="S3.E3.m1.6.6.2.4.1.cmml" xref="S3.E3.m1.6.6.2.4"></divide><cn id="S3.E3.m1.6.6.2.4.2.cmml" type="integer" xref="S3.E3.m1.6.6.2.4.2">1</cn><cn id="S3.E3.m1.6.6.2.4.3.cmml" type="integer" xref="S3.E3.m1.6.6.2.4.3">4</cn></apply><apply id="S3.E3.m1.6.6.2.2.cmml" xref="S3.E3.m1.6.6.2.2"><apply id="S3.E3.m1.6.6.2.2.3.cmml" xref="S3.E3.m1.6.6.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.2.2.3.1.cmml" xref="S3.E3.m1.6.6.2.2.3">subscript</csymbol><sum id="S3.E3.m1.6.6.2.2.3.2.cmml" xref="S3.E3.m1.6.6.2.2.3.2"></sum><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><in id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></in><ci id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4">ğ‘“</ci><set id="S3.E3.m1.2.2.2.5.1.cmml" xref="S3.E3.m1.2.2.2.5.2"><ci id="S3.E3.m1.1.1.1.1a.cmml" xref="S3.E3.m1.1.1.1.1"><mtext id="S3.E3.m1.1.1.1.1.cmml" mathsize="63%" xref="S3.E3.m1.1.1.1.1">sin</mtext></ci><ci id="S3.E3.m1.2.2.2.2a.cmml" xref="S3.E3.m1.2.2.2.2"><mtext id="S3.E3.m1.2.2.2.2.cmml" mathsize="63%" xref="S3.E3.m1.2.2.2.2">cos</mtext></ci></set></apply></apply><apply id="S3.E3.m1.6.6.2.2.2.cmml" xref="S3.E3.m1.6.6.2.2.2"><times id="S3.E3.m1.6.6.2.2.2.3.cmml" xref="S3.E3.m1.6.6.2.2.2.3"></times><ci id="S3.E3.m1.6.6.2.2.2.4a.cmml" xref="S3.E3.m1.6.6.2.2.2.4"><mtext id="S3.E3.m1.6.6.2.2.2.4.cmml" mathsize="90%" xref="S3.E3.m1.6.6.2.2.2.4">mse</mtext></ci><interval closure="open" id="S3.E3.m1.6.6.2.2.2.2.3.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2"><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1"><times id="S3.E3.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2">ğ‘“</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">ğœ“</ci></apply><apply id="S3.E3.m1.6.6.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1"><apply id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.cmml" xref="S3.E3.m1.4.4">subscript</csymbol><ci id="S3.E3.m1.4.4.2.cmml" xref="S3.E3.m1.4.4.2">ğ°ğ¦</ci><apply id="S3.E3.m1.4.4.3.cmml" xref="S3.E3.m1.4.4.3"><ci id="S3.E3.m1.4.4.3.1.cmml" xref="S3.E3.m1.4.4.3.1">bold-^</ci><ci id="S3.E3.m1.4.4.3.2.cmml" xref="S3.E3.m1.4.4.3.2">ğ</ci></apply></apply><apply id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1">superscript</csymbol><apply id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1">subscript</csymbol><apply id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2"><ci id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.1.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.1">bold-^</ci><ci id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.2.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.2.2">ğ‘¶</ci></apply><ci id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.3.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.2.3">ğ‘“</ci></apply><ci id="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E3.m1.6.6.2.2.2.2.2.2.1.1.1.3">ğœ“</ci></apply></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.6c">\mathcal{L}_{\text{ori}}=\frac{1}{4}\sum_{f\in\{\text{sin},\text{cos}\}}\text{%
mse}\bigl{(}f(\psi),\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{O}}_{f}^{\psi})%
\bigr{)}</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.6d">caligraphic_L start_POSTSUBSCRIPT ori end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG 4 end_ARG âˆ‘ start_POSTSUBSCRIPT italic_f âˆˆ { sin , cos } end_POSTSUBSCRIPT mse ( italic_f ( italic_Ïˆ ) , start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( overbold_^ start_ARG bold_italic_O end_ARG start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Ïˆ end_POSTSUPERSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.14"><span class="ltx_text" id="S3.SS1.p1.14.1" style="font-size:90%;">The LED state loss is defined as the mean of the binary cross entropy for each of the </span><math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.14.m1.1"><semantics id="S3.SS1.p1.14.m1.1a"><mi id="S3.SS1.p1.14.m1.1.1" mathsize="90%" xref="S3.SS1.p1.14.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m1.1b"><ci id="S3.SS1.p1.14.m1.1.1.cmml" xref="S3.SS1.p1.14.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.14.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.14.2" style="font-size:90%;"> robot LEDs</span></p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{led}}=\frac{1}{k}\sum_{i=1}^{k}\text{bce}\bigl{(}l_{i},%
\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{L}}_{i})\bigr{)}" class="ltx_Math" display="block" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><msub id="S3.E4.m1.3.3.4" xref="S3.E4.m1.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.3.3.4.2" mathsize="90%" xref="S3.E4.m1.3.3.4.2.cmml">â„’</mi><mtext id="S3.E4.m1.3.3.4.3" mathsize="90%" xref="S3.E4.m1.3.3.4.3a.cmml">led</mtext></msub><mo id="S3.E4.m1.3.3.3" mathsize="90%" xref="S3.E4.m1.3.3.3.cmml">=</mo><mrow id="S3.E4.m1.3.3.2" xref="S3.E4.m1.3.3.2.cmml"><mfrac id="S3.E4.m1.3.3.2.4" xref="S3.E4.m1.3.3.2.4.cmml"><mn id="S3.E4.m1.3.3.2.4.2" mathsize="90%" xref="S3.E4.m1.3.3.2.4.2.cmml">1</mn><mi id="S3.E4.m1.3.3.2.4.3" mathsize="90%" xref="S3.E4.m1.3.3.2.4.3.cmml">k</mi></mfrac><mo id="S3.E4.m1.3.3.2.3" xref="S3.E4.m1.3.3.2.3.cmml">â¢</mo><mrow id="S3.E4.m1.3.3.2.2" xref="S3.E4.m1.3.3.2.2.cmml"><munderover id="S3.E4.m1.3.3.2.2.3" xref="S3.E4.m1.3.3.2.2.3.cmml"><mo id="S3.E4.m1.3.3.2.2.3.2.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S3.E4.m1.3.3.2.2.3.2.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.3.3.2.2.3.2.3" xref="S3.E4.m1.3.3.2.2.3.2.3.cmml"><mi id="S3.E4.m1.3.3.2.2.3.2.3.2" mathsize="90%" xref="S3.E4.m1.3.3.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E4.m1.3.3.2.2.3.2.3.1" mathsize="90%" xref="S3.E4.m1.3.3.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E4.m1.3.3.2.2.3.2.3.3" mathsize="90%" xref="S3.E4.m1.3.3.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.3.3.2.2.3.3" mathsize="90%" xref="S3.E4.m1.3.3.2.2.3.3.cmml">k</mi></munderover><mrow id="S3.E4.m1.3.3.2.2.2" xref="S3.E4.m1.3.3.2.2.2.cmml"><mtext id="S3.E4.m1.3.3.2.2.2.4" mathsize="90%" xref="S3.E4.m1.3.3.2.2.2.4a.cmml">bce</mtext><mo id="S3.E4.m1.3.3.2.2.2.3" xref="S3.E4.m1.3.3.2.2.2.3.cmml">â¢</mo><mrow id="S3.E4.m1.3.3.2.2.2.2.2" xref="S3.E4.m1.3.3.2.2.2.2.3.cmml"><mo id="S3.E4.m1.3.3.2.2.2.2.2.3" maxsize="120%" minsize="120%" xref="S3.E4.m1.3.3.2.2.2.2.3.cmml">(</mo><msub id="S3.E4.m1.2.2.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.2" mathsize="90%" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.cmml">l</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3" mathsize="90%" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.3.3.2.2.2.2.2.4" mathsize="90%" xref="S3.E4.m1.3.3.2.2.2.2.3.cmml">,</mo><mrow id="S3.E4.m1.3.3.2.2.2.2.2.2.1" xref="S3.E4.m1.3.3.2.2.2.2.2.2.2.cmml"><msub id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" mathsize="90%" xref="S3.E4.m1.1.1.2.cmml">ğ°ğ¦</mi><mover accent="true" id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.3.2" mathsize="90%" xref="S3.E4.m1.1.1.3.2.cmml">ğ</mi><mo class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.3.1" mathsize="90%" mathvariant="bold" xref="S3.E4.m1.1.1.3.1.cmml">^</mo></mover></msub><mo id="S3.E4.m1.3.3.2.2.2.2.2.2.1a" xref="S3.E4.m1.3.3.2.2.2.2.2.2.2.cmml">â¡</mo><mrow id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1" xref="S3.E4.m1.3.3.2.2.2.2.2.2.2.cmml"><mo id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.2" maxsize="90%" minsize="90%" xref="S3.E4.m1.3.3.2.2.2.2.2.2.2.cmml">(</mo><msub id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.cmml"><mover accent="true" id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.2" mathsize="90%" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.2.cmml">ğ‘³</mi><mo class="ltx_mathvariant_bold" id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.1" mathsize="90%" mathvariant="bold" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.3" mathsize="90%" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.3" maxsize="90%" minsize="90%" xref="S3.E4.m1.3.3.2.2.2.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.2.2.2.2.2.5" maxsize="120%" minsize="120%" xref="S3.E4.m1.3.3.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><eq id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"></eq><apply id="S3.E4.m1.3.3.4.cmml" xref="S3.E4.m1.3.3.4"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.4.1.cmml" xref="S3.E4.m1.3.3.4">subscript</csymbol><ci id="S3.E4.m1.3.3.4.2.cmml" xref="S3.E4.m1.3.3.4.2">â„’</ci><ci id="S3.E4.m1.3.3.4.3a.cmml" xref="S3.E4.m1.3.3.4.3"><mtext id="S3.E4.m1.3.3.4.3.cmml" mathsize="63%" xref="S3.E4.m1.3.3.4.3">led</mtext></ci></apply><apply id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.2"><times id="S3.E4.m1.3.3.2.3.cmml" xref="S3.E4.m1.3.3.2.3"></times><apply id="S3.E4.m1.3.3.2.4.cmml" xref="S3.E4.m1.3.3.2.4"><divide id="S3.E4.m1.3.3.2.4.1.cmml" xref="S3.E4.m1.3.3.2.4"></divide><cn id="S3.E4.m1.3.3.2.4.2.cmml" type="integer" xref="S3.E4.m1.3.3.2.4.2">1</cn><ci id="S3.E4.m1.3.3.2.4.3.cmml" xref="S3.E4.m1.3.3.2.4.3">ğ‘˜</ci></apply><apply id="S3.E4.m1.3.3.2.2.cmml" xref="S3.E4.m1.3.3.2.2"><apply id="S3.E4.m1.3.3.2.2.3.cmml" xref="S3.E4.m1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.2.2.3.1.cmml" xref="S3.E4.m1.3.3.2.2.3">superscript</csymbol><apply id="S3.E4.m1.3.3.2.2.3.2.cmml" xref="S3.E4.m1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.2.2.3.2.1.cmml" xref="S3.E4.m1.3.3.2.2.3">subscript</csymbol><sum id="S3.E4.m1.3.3.2.2.3.2.2.cmml" xref="S3.E4.m1.3.3.2.2.3.2.2"></sum><apply id="S3.E4.m1.3.3.2.2.3.2.3.cmml" xref="S3.E4.m1.3.3.2.2.3.2.3"><eq id="S3.E4.m1.3.3.2.2.3.2.3.1.cmml" xref="S3.E4.m1.3.3.2.2.3.2.3.1"></eq><ci id="S3.E4.m1.3.3.2.2.3.2.3.2.cmml" xref="S3.E4.m1.3.3.2.2.3.2.3.2">ğ‘–</ci><cn id="S3.E4.m1.3.3.2.2.3.2.3.3.cmml" type="integer" xref="S3.E4.m1.3.3.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.3.3.2.2.3.3.cmml" xref="S3.E4.m1.3.3.2.2.3.3">ğ‘˜</ci></apply><apply id="S3.E4.m1.3.3.2.2.2.cmml" xref="S3.E4.m1.3.3.2.2.2"><times id="S3.E4.m1.3.3.2.2.2.3.cmml" xref="S3.E4.m1.3.3.2.2.2.3"></times><ci id="S3.E4.m1.3.3.2.2.2.4a.cmml" xref="S3.E4.m1.3.3.2.2.2.4"><mtext id="S3.E4.m1.3.3.2.2.2.4.cmml" mathsize="90%" xref="S3.E4.m1.3.3.2.2.2.4">bce</mtext></ci><interval closure="open" id="S3.E4.m1.3.3.2.2.2.2.3.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2"><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2">ğ‘™</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E4.m1.3.3.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">ğ°ğ¦</ci><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><ci id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1">bold-^</ci><ci id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2">ğ</ci></apply></apply><apply id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1">subscript</csymbol><apply id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2"><ci id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.1">bold-^</ci><ci id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.2.2">ğ‘³</ci></apply><ci id="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E4.m1.3.3.2.2.2.2.2.2.1.1.1.3">ğ‘–</ci></apply></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\mathcal{L}_{\text{led}}=\frac{1}{k}\sum_{i=1}^{k}\text{bce}\bigl{(}l_{i},%
\operatorname{\bm{wm_{\hat{P}}}}(\bm{\hat{L}}_{i})\bigr{)}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">caligraphic_L start_POSTSUBSCRIPT led end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_k end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT bce ( italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , start_OPFUNCTION bold_wm start_POSTSUBSCRIPT overbold_^ start_ARG bold_P end_ARG end_POSTSUBSCRIPT end_OPFUNCTION ( overbold_^ start_ARG bold_italic_L end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.7"><span class="ltx_text" id="S3.SS1.p2.7.1" style="font-size:90%;">It is important to note that in </span><math alttext="\mathcal{L}_{\text{led}}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.2" mathsize="90%" xref="S3.SS1.p2.1.m1.1.1.2.cmml">â„’</mi><mtext id="S3.SS1.p2.1.m1.1.1.3" mathsize="90%" xref="S3.SS1.p2.1.m1.1.1.3a.cmml">led</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">â„’</ci><ci id="S3.SS1.p2.1.m1.1.1.3a.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><mtext id="S3.SS1.p2.1.m1.1.1.3.cmml" mathsize="63%" xref="S3.SS1.p2.1.m1.1.1.3">led</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{L}_{\text{led}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT led end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.2" style="font-size:90%;">, we allow gradients to flow through the predicted position map </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mover accent="true" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" mathsize="90%" xref="S3.SS1.p2.2.m2.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.SS1.p2.2.m2.1.1.1" mathsize="90%" mathvariant="bold" xref="S3.SS1.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><ci id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1">bold-^</ci><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.3" style="font-size:90%;">, enabling the optimization of the robot position map without using labels;
this results in an attention-like mechanism, where the position map weights the cells of the LED map, assigning higher values to pixels containing relevant information for estimating the LEDsâ€™ state, i.e., those depicting the robot.
Instead, </span><math alttext="\mathcal{L}_{\text{dist}}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.1.2" mathsize="90%" xref="S3.SS1.p2.3.m3.1.1.2.cmml">â„’</mi><mtext id="S3.SS1.p2.3.m3.1.1.3" mathsize="90%" xref="S3.SS1.p2.3.m3.1.1.3a.cmml">dist</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">â„’</ci><ci id="S3.SS1.p2.3.m3.1.1.3a.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><mtext id="S3.SS1.p2.3.m3.1.1.3.cmml" mathsize="63%" xref="S3.SS1.p2.3.m3.1.1.3">dist</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathcal{L}_{\text{dist}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT dist end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.4" style="font-size:90%;"> and </span><math alttext="\mathcal{L}_{\text{ori}}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.1.2" mathsize="90%" xref="S3.SS1.p2.4.m4.1.1.2.cmml">â„’</mi><mtext id="S3.SS1.p2.4.m4.1.1.3" mathsize="90%" xref="S3.SS1.p2.4.m4.1.1.3a.cmml">ori</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">â„’</ci><ci id="S3.SS1.p2.4.m4.1.1.3a.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><mtext id="S3.SS1.p2.4.m4.1.1.3.cmml" mathsize="63%" xref="S3.SS1.p2.4.m4.1.1.3">ori</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathcal{L}_{\text{ori}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT ori end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.5" style="font-size:90%;"> block the gradients from flowing through the predicted position map </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mover accent="true" id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" mathsize="90%" xref="S3.SS1.p2.5.m5.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.SS1.p2.5.m5.1.1.1" mathsize="90%" mathvariant="bold" xref="S3.SS1.p2.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><ci id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1">bold-^</ci><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.6" style="font-size:90%;">;
this avoids having the gradients for the </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mover accent="true" id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" mathsize="90%" xref="S3.SS1.p2.6.m6.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S3.SS1.p2.6.m6.1.1.1" mathsize="90%" mathvariant="bold" xref="S3.SS1.p2.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><ci id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1">bold-^</ci><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.7" style="font-size:90%;"> map applied twice when optimizing </span><math alttext="\mathcal{L}_{\text{task}}" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1"><semantics id="S3.SS1.p2.7.m7.1a"><msub id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.7.m7.1.1.2" mathsize="90%" xref="S3.SS1.p2.7.m7.1.1.2.cmml">â„’</mi><mtext id="S3.SS1.p2.7.m7.1.1.3" mathsize="90%" xref="S3.SS1.p2.7.m7.1.1.3a.cmml">task</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">â„’</ci><ci id="S3.SS1.p2.7.m7.1.1.3a.cmml" xref="S3.SS1.p2.7.m7.1.1.3"><mtext id="S3.SS1.p2.7.m7.1.1.3.cmml" mathsize="63%" xref="S3.SS1.p2.7.m7.1.1.3">task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">\mathcal{L}_{\text{task}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m7.1d">caligraphic_L start_POSTSUBSCRIPT task end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p2.7.8" style="font-size:90%;">.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Setup</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text" id="S4.p1.1.1" style="font-size:90%;">The proposed approach is applied to the problem of peer-to-peer localization of DJI S1 RoboMasters, omnidirectional ground robots equipped with four Swedish wheels and a front-facing monocular camera with a resolution of </span><math alttext="640\times 360" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mn id="S4.p1.1.m1.1.1.2" mathsize="90%" xref="S4.p1.1.m1.1.1.2.cmml">640</mn><mo id="S4.p1.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.p1.1.m1.1.1.3" mathsize="90%" xref="S4.p1.1.m1.1.1.3.cmml">360</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><times id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></times><cn id="S4.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.p1.1.m1.1.1.2">640</cn><cn id="S4.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.p1.1.m1.1.1.3">360</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">640\times 360</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">640 Ã— 360</annotation></semantics></math><span class="ltx_text" id="S4.p1.1.2" style="font-size:90%;"> pixels mounted on a pan-and-tilt turret.
The robot features six RGB LEDs: four are mounted on the base of the robot, one for each cardinal direction, and two are mounted on the left and right sides of the robotâ€™s turret; in our experiments we consider four LEDs: the two turret ones and the front and back ones of the robot base, while the left and right base LEDs are always off and ignored in our evaluation.</span></p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="226" id="S4.F3.g1" src="extracted/5878331/fig/dataset.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Six samples from the unlabeled training set <math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S4.F3.2.m1.1"><semantics id="S4.F3.2.m1.1b"><msubsup id="S4.F3.2.m1.1.1" xref="S4.F3.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F3.2.m1.1.1.2.2" xref="S4.F3.2.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.F3.2.m1.1.1.2.3" xref="S4.F3.2.m1.1.1.2.3.cmml">u</mi><mi id="S4.F3.2.m1.1.1.3" xref="S4.F3.2.m1.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.F3.2.m1.1c"><apply id="S4.F3.2.m1.1.1.cmml" xref="S4.F3.2.m1.1.1"><csymbol cd="ambiguous" id="S4.F3.2.m1.1.1.1.cmml" xref="S4.F3.2.m1.1.1">superscript</csymbol><apply id="S4.F3.2.m1.1.1.2.cmml" xref="S4.F3.2.m1.1.1"><csymbol cd="ambiguous" id="S4.F3.2.m1.1.1.2.1.cmml" xref="S4.F3.2.m1.1.1">subscript</csymbol><ci id="S4.F3.2.m1.1.1.2.2.cmml" xref="S4.F3.2.m1.1.1.2.2">ğ’¯</ci><ci id="S4.F3.2.m1.1.1.2.3.cmml" xref="S4.F3.2.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S4.F3.2.m1.1.1.3.cmml" xref="S4.F3.2.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.2.m1.1d">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.F3.2.m1.1e">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math>, where only 22% of images feature a visible robot; ground truth robot poses are depicted with a blue bounding box.</figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Dataset</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.6"><span class="ltx_text" id="S4.SS1.p1.6.1" style="font-size:90%;">The data collection setup consists of two robots roaming a </span><math alttext="4\times 4" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" mathsize="90%" xref="S4.SS1.p1.1.m1.1.1.2.cmml">4</mn><mo id="S4.SS1.p1.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS1.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p1.1.m1.1.1.3" mathsize="90%" xref="S4.SS1.p1.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><cn id="S4.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.2">4</cn><cn id="S4.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">4\times 4</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">4 Ã— 4</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p1.6.2" style="font-size:90%;"> meters area inside our lab with a random policy: it keeps robots moving in a straight line until they collide with the edges of the area or with one another;
when it happens, they rotate in-place in one of the two directions by </span><math class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1.2"><mn id="S4.SS1.p1.2.m2.1.1.2.2" mathsize="90%" xref="S4.SS1.p1.2.m2.1.1.1.cmml">90</mn><mo id="S4.SS1.p1.2.m2.1.1.2.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">â¢</mo><mi id="S4.SS1.p1.2.m2.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S4.SS1.p1.2.m2.1.1.1.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn id="S4.SS1.p1.2.m2.1.1.1.cmml" type="float" xref="S4.SS1.p1.2.m2.1.1.2.2">90Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1c">90 â¢ Â°</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p1.6.3" style="font-size:90%;"> </span><math alttext="\pm\ \mathcal{U}(" class="ltx_math_unparsed" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1b"><mo id="S4.SS1.p1.3.m3.1.1" mathsize="90%" rspace="0.672em">Â±</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.3.m3.1.2" mathsize="90%">ğ’°</mi><mo id="S4.SS1.p1.3.m3.1.3" maxsize="90%" minsize="90%">(</mo></mrow><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\pm\ \mathcal{U}(</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">Â± caligraphic_U (</annotation></semantics></math><math class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1.2"><mo id="S4.SS1.p1.4.m4.1.1.2a" mathsize="90%" xref="S4.SS1.p1.4.m4.1.1.1.cmml">âˆ’</mo><mrow id="S4.SS1.p1.4.m4.1.1.2.2"><mn id="S4.SS1.p1.4.m4.1.1.2.2.2" mathsize="90%" xref="S4.SS1.p1.4.m4.1.1.1.cmml">20</mn><mo id="S4.SS1.p1.4.m4.1.1.2.2.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">â¢</mo><mi id="S4.SS1.p1.4.m4.1.1.2.2.3" mathsize="90%" mathvariant="normal" xref="S4.SS1.p1.4.m4.1.1.1.cmml">Â°</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><cn id="S4.SS1.p1.4.m4.1.1.1.cmml" type="float" xref="S4.SS1.p1.4.m4.1.1.2a">-20Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1c">- 20 â¢ Â°</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p1.6.4" style="font-size:90%;">, </span><math class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1.2"><mn id="S4.SS1.p1.5.m5.1.1.2.2" mathsize="90%" xref="S4.SS1.p1.5.m5.1.1.1.cmml">20</mn><mo id="S4.SS1.p1.5.m5.1.1.2.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">â¢</mo><mi id="S4.SS1.p1.5.m5.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S4.SS1.p1.5.m5.1.1.1.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><cn id="S4.SS1.p1.5.m5.1.1.1.cmml" type="float" xref="S4.SS1.p1.5.m5.1.1.2.2">20Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1c">20 â¢ Â°</annotation></semantics></math><math alttext=")" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mo id="S4.SS1.p1.6.m6.1.1" maxsize="90%" minsize="90%" xref="S4.SS1.p1.6.m6.1.1.cmml">)</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><ci id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">)</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">)</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p1.6.5" style="font-size:90%;">.
Every five seconds, each of the four LEDs of the target robot is randomly toggled, and its state is stored.
During data collection, we keep the turret at a fixed relative orientation w.r.t. the base of the robot, gathering images at 3 fps and the precise pose of the robots using a motion-tracking system featuring 18 infra-red cameras.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.4"><span class="ltx_text" id="S4.SS1.p2.4.1" style="font-size:90%;">In total, we collected 37k samples over two recording sessions lasting approximately 1 hour each.
The samples are divided into 34k for the unlabeled training set </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><msubsup id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.1.m1.1.1.2.2" mathsize="90%" xref="S4.SS1.p2.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.SS1.p2.1.m1.1.1.2.3" mathsize="90%" xref="S4.SS1.p2.1.m1.1.1.2.3.cmml">u</mi><mi id="S4.SS1.p2.1.m1.1.1.3" mathsize="90%" xref="S4.SS1.p2.1.m1.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">superscript</csymbol><apply id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.2.1.cmml" xref="S4.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2.2">ğ’¯</ci><ci id="S4.SS1.p2.1.m1.1.1.2.3.cmml" xref="S4.SS1.p2.1.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p2.4.2" style="font-size:90%;">, out of which only 7k have the robot visible (22%) in them, 1k for the labeled training set </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><msub id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.2.m2.1.1.2" mathsize="90%" xref="S4.SS1.p2.2.m2.1.1.2.cmml">ğ’¯</mi><mi id="S4.SS1.p2.2.m2.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.SS1.p2.2.m2.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">ğ’¯</ci><ci id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p2.4.3" style="font-size:90%;">, and 2k for the testing set </span><math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.3.m3.1.1" mathsize="90%" xref="S4.SS1.p2.3.m3.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">caligraphic_Q</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p2.4.4" style="font-size:90%;">, the last two featuring the robot always visible;
we show samples from </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S4.SS1.p2.4.m4.1"><semantics id="S4.SS1.p2.4.m4.1a"><msubsup id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.4.m4.1.1.2.2" mathsize="90%" xref="S4.SS1.p2.4.m4.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.SS1.p2.4.m4.1.1.2.3" mathsize="90%" xref="S4.SS1.p2.4.m4.1.1.2.3.cmml">u</mi><mi id="S4.SS1.p2.4.m4.1.1.3" mathsize="90%" xref="S4.SS1.p2.4.m4.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">superscript</csymbol><apply id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.2.1.cmml" xref="S4.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.2.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2.2">ğ’¯</ci><ci id="S4.SS1.p2.4.m4.1.1.2.3.cmml" xref="S4.SS1.p2.4.m4.1.1.2.3">ğ‘¢</ci></apply><ci id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS1.p2.4.5" style="font-size:90%;"> in FigureÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4.F3" style="font-size:90%;" title="Figure 3 â€£ IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S4.SS1.p2.4.6" style="font-size:90%;">.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Training Strategies</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.3"><span class="ltx_text" id="S4.SS2.p1.3.1" style="font-size:90%;">We devise different training strategies based on the availability of robot pose labels.
With no access to labels, we train the model with </span><math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><msubsup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.1.m1.1.1.2.2" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.SS2.p1.1.m1.1.1.2.3" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">u</mi><mi id="S4.SS2.p1.1.m1.1.1.3" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">ğ’¯</ci><ci id="S4.SS2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p1.3.2" style="font-size:90%;"> on the LED state estimation pretext task with </span><math alttext="\mathcal{L}_{\text{led}}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.2.m2.1.1.2" mathsize="90%" xref="S4.SS2.p1.2.m2.1.1.2.cmml">â„’</mi><mtext id="S4.SS2.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS2.p1.2.m2.1.1.3a.cmml">led</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">â„’</ci><ci id="S4.SS2.p1.2.m2.1.1.3a.cmml" xref="S4.SS2.p1.2.m2.1.1.3"><mtext id="S4.SS2.p1.2.m2.1.1.3.cmml" mathsize="63%" xref="S4.SS2.p1.2.m2.1.1.3">led</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\mathcal{L}_{\text{led}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT led end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p1.3.3" style="font-size:90%;">, learning features that are also useful for pose estimation; additionally, we explore the effectiveness of the LED-based pretext task by training with the entire unlabeled training set </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><msubsup id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.3.m3.1.1.2.2" mathsize="90%" xref="S4.SS2.p1.3.m3.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.SS2.p1.3.m3.1.1.2.3" mathsize="90%" xref="S4.SS2.p1.3.m3.1.1.2.3.cmml">u</mi><mi id="S4.SS2.p1.3.m3.1.1.3" mathsize="90%" xref="S4.SS2.p1.3.m3.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">superscript</csymbol><apply id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.2.1.cmml" xref="S4.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2.2">ğ’¯</ci><ci id="S4.SS2.p1.3.m3.1.1.2.3.cmml" xref="S4.SS2.p1.3.m3.1.1.2.3">ğ‘¢</ci></apply><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p1.3.4" style="font-size:90%;">, including the predominant type of image featuring no robot visible (88%).</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text" id="S4.SS2.p2.1.1" style="font-size:90%;">We compare our pretext strategy with Ablation-CAM, a gradient-free CAM technique producing a score for each pixel of the input image.
High scores are assigned to areas of the image responsible for making the model predict the image class.
In weakly supervised learning, this technique is used to localize objects from a pre-trained classification modelÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib12" title="">12</a><span class="ltx_text" id="S4.SS2.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p2.1.4" style="font-size:90%;">.
This strategy involves training a custom MobileNet-V2 modelÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p2.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib34" title="">34</a><span class="ltx_text" id="S4.SS2.p2.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p2.1.7" style="font-size:90%;">, featuring 380k parameters, on the LED state estimation pretext task with </span><math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><msubsup id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p2.1.m1.1.1.2.2" mathsize="90%" xref="S4.SS2.p2.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.SS2.p2.1.m1.1.1.2.3" mathsize="90%" xref="S4.SS2.p2.1.m1.1.1.2.3.cmml">u</mi><mi id="S4.SS2.p2.1.m1.1.1.3" mathsize="90%" xref="S4.SS2.p2.1.m1.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">superscript</csymbol><apply id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2.2">ğ’¯</ci><ci id="S4.SS2.p2.1.m1.1.1.2.3.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p2.1.8" style="font-size:90%;">.
Then, the model is fed to Ablation-CAM to generate the robot image-space position based on the four class activation maps (one for each LED).
Given these maps, we obtain the robotâ€™s position in the image as the average coordinates of the pixel with maximum value within each map.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.6"><span class="ltx_text" id="S4.SS2.p3.6.1" style="font-size:90%;">Assuming access to a limited amount of labeled data, the most straight-forward strategy is to directly train with </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><msub id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.1.m1.1.1.2" mathsize="90%" xref="S4.SS2.p3.1.m1.1.1.2.cmml">ğ’¯</mi><mi id="S4.SS2.p3.1.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.SS2.p3.1.m1.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">ğ’¯</ci><ci id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.6.2" style="font-size:90%;"> on the pose task loss </span><math alttext="\mathcal{L}_{\text{task}}" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><msub id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.2.m2.1.1.2" mathsize="90%" xref="S4.SS2.p3.2.m2.1.1.2.cmml">â„’</mi><mtext id="S4.SS2.p3.2.m2.1.1.3" mathsize="90%" xref="S4.SS2.p3.2.m2.1.1.3a.cmml">task</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">â„’</ci><ci id="S4.SS2.p3.2.m2.1.1.3a.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><mtext id="S4.SS2.p3.2.m2.1.1.3.cmml" mathsize="63%" xref="S4.SS2.p3.2.m2.1.1.3">task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\mathcal{L}_{\text{task}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT task end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.6.3" style="font-size:90%;">, representing a baseline.
We compare this baseline with the strategy that takes the pretrained model on the LED state estimation pretext task and transfers its skills to the downstream or end task, training with </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><msub id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.3.m3.1.1.2" mathsize="90%" xref="S4.SS2.p3.3.m3.1.1.2.cmml">ğ’¯</mi><mi id="S4.SS2.p3.3.m3.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.SS2.p3.3.m3.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">ğ’¯</ci><ci id="S4.SS2.p3.3.m3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.6.4" style="font-size:90%;"> on the pose task loss </span><math alttext="\mathcal{L}_{\text{task}}" class="ltx_Math" display="inline" id="S4.SS2.p3.4.m4.1"><semantics id="S4.SS2.p3.4.m4.1a"><msub id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.4.m4.1.1.2" mathsize="90%" xref="S4.SS2.p3.4.m4.1.1.2.cmml">â„’</mi><mtext id="S4.SS2.p3.4.m4.1.1.3" mathsize="90%" xref="S4.SS2.p3.4.m4.1.1.3a.cmml">task</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.4.m4.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2">â„’</ci><ci id="S4.SS2.p3.4.m4.1.1.3a.cmml" xref="S4.SS2.p3.4.m4.1.1.3"><mtext id="S4.SS2.p3.4.m4.1.1.3.cmml" mathsize="63%" xref="S4.SS2.p3.4.m4.1.1.3">task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">\mathcal{L}_{\text{task}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT task end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.6.5" style="font-size:90%;">.
Additionally, we compare it against a different pretext approach of Contrastive Language-Image Pre-training (CLIP).
CLIP is a vision-language model trained on a large corpus of data to learn a similar encoding for images and associated captions, whose performance has been shown to outperform supervised counterparts on multiple tasksÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p3.6.6.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#bib.bib13" title="">13</a><span class="ltx_text" id="S4.SS2.p3.6.7.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p3.6.8" style="font-size:90%;">.
Specifically, we consider features extracted by the image encoder, and train a small feed forward neural network with </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S4.SS2.p3.5.m5.1"><semantics id="S4.SS2.p3.5.m5.1a"><msub id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.5.m5.1.1.2" mathsize="90%" xref="S4.SS2.p3.5.m5.1.1.2.cmml">ğ’¯</mi><mi id="S4.SS2.p3.5.m5.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.SS2.p3.5.m5.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><apply id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.5.m5.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.p3.5.m5.1.1.2.cmml" xref="S4.SS2.p3.5.m5.1.1.2">ğ’¯</ci><ci id="S4.SS2.p3.5.m5.1.1.3.cmml" xref="S4.SS2.p3.5.m5.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.6.9" style="font-size:90%;"> on the pose task loss </span><math alttext="\mathcal{L}_{\text{task}}" class="ltx_Math" display="inline" id="S4.SS2.p3.6.m6.1"><semantics id="S4.SS2.p3.6.m6.1a"><msub id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.6.m6.1.1.2" mathsize="90%" xref="S4.SS2.p3.6.m6.1.1.2.cmml">â„’</mi><mtext id="S4.SS2.p3.6.m6.1.1.3" mathsize="90%" xref="S4.SS2.p3.6.m6.1.1.3a.cmml">task</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><apply id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.6.m6.1.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.p3.6.m6.1.1.2.cmml" xref="S4.SS2.p3.6.m6.1.1.2">â„’</ci><ci id="S4.SS2.p3.6.m6.1.1.3a.cmml" xref="S4.SS2.p3.6.m6.1.1.3"><mtext id="S4.SS2.p3.6.m6.1.1.3.cmml" mathsize="63%" xref="S4.SS2.p3.6.m6.1.1.3">task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">\mathcal{L}_{\text{task}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.6.m6.1d">caligraphic_L start_POSTSUBSCRIPT task end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.6.10" style="font-size:90%;"> to predict the robot pose from CLIPâ€™s features.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.3"><span class="ltx_text" id="S4.SS2.p4.3.1" style="font-size:90%;">Finally, we consider an upperbound model trained with </span><math alttext="\mathcal{T}_{u}^{*}\cup\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S4.SS2.p4.1.m1.1"><semantics id="S4.SS2.p4.1.m1.1a"><mrow id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><msubsup id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.1.m1.1.1.2.2.2" mathsize="90%" xref="S4.SS2.p4.1.m1.1.1.2.2.2.cmml">ğ’¯</mi><mi id="S4.SS2.p4.1.m1.1.1.2.2.3" mathsize="90%" xref="S4.SS2.p4.1.m1.1.1.2.2.3.cmml">u</mi><mo id="S4.SS2.p4.1.m1.1.1.2.3" mathsize="90%" xref="S4.SS2.p4.1.m1.1.1.2.3.cmml">âˆ—</mo></msubsup><mo id="S4.SS2.p4.1.m1.1.1.1" mathsize="90%" xref="S4.SS2.p4.1.m1.1.1.1.cmml">âˆª</mo><msub id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.1.m1.1.1.3.2" mathsize="90%" xref="S4.SS2.p4.1.m1.1.1.3.2.cmml">ğ’¯</mi><mi id="S4.SS2.p4.1.m1.1.1.3.3" mathsize="90%" mathvariant="normal" xref="S4.SS2.p4.1.m1.1.1.3.3.cmml">â„“</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><union id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1"></union><apply id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.2.1.cmml" xref="S4.SS2.p4.1.m1.1.1.2">superscript</csymbol><apply id="S4.SS2.p4.1.m1.1.1.2.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.2.2.1.cmml" xref="S4.SS2.p4.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2.2.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2.2.2">ğ’¯</ci><ci id="S4.SS2.p4.1.m1.1.1.2.2.3.cmml" xref="S4.SS2.p4.1.m1.1.1.2.2.3">ğ‘¢</ci></apply><times id="S4.SS2.p4.1.m1.1.1.2.3.cmml" xref="S4.SS2.p4.1.m1.1.1.2.3"></times></apply><apply id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.3.1.cmml" xref="S4.SS2.p4.1.m1.1.1.3">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.3.2.cmml" xref="S4.SS2.p4.1.m1.1.1.3.2">ğ’¯</ci><ci id="S4.SS2.p4.1.m1.1.1.3.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3.3">â„“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">\mathcal{T}_{u}^{*}\cup\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT âˆª caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p4.3.2" style="font-size:90%;"> on the pose task loss </span><math alttext="\mathcal{L}_{\text{task}}" class="ltx_Math" display="inline" id="S4.SS2.p4.2.m2.1"><semantics id="S4.SS2.p4.2.m2.1a"><msub id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.2.m2.1.1.2" mathsize="90%" xref="S4.SS2.p4.2.m2.1.1.2.cmml">â„’</mi><mtext id="S4.SS2.p4.2.m2.1.1.3" mathsize="90%" xref="S4.SS2.p4.2.m2.1.1.3a.cmml">task</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">â„’</ci><ci id="S4.SS2.p4.2.m2.1.1.3a.cmml" xref="S4.SS2.p4.2.m2.1.1.3"><mtext id="S4.SS2.p4.2.m2.1.1.3.cmml" mathsize="63%" xref="S4.SS2.p4.2.m2.1.1.3">task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">\mathcal{L}_{\text{task}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT task end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p4.3.3" style="font-size:90%;">, representing the best performance achievable with our setup under the assumption of having unlimited access to robot pose labels, even for </span><math alttext="\mathcal{T}_{u}^{*}" class="ltx_Math" display="inline" id="S4.SS2.p4.3.m3.1"><semantics id="S4.SS2.p4.3.m3.1a"><msubsup id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p4.3.m3.1.1.2.2" mathsize="90%" xref="S4.SS2.p4.3.m3.1.1.2.2.cmml">ğ’¯</mi><mi id="S4.SS2.p4.3.m3.1.1.2.3" mathsize="90%" xref="S4.SS2.p4.3.m3.1.1.2.3.cmml">u</mi><mo id="S4.SS2.p4.3.m3.1.1.3" mathsize="90%" xref="S4.SS2.p4.3.m3.1.1.3.cmml">âˆ—</mo></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">superscript</csymbol><apply id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.3.m3.1.1.2.1.cmml" xref="S4.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p4.3.m3.1.1.2.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2.2">ğ’¯</ci><ci id="S4.SS2.p4.3.m3.1.1.2.3.cmml" xref="S4.SS2.p4.3.m3.1.1.2.3">ğ‘¢</ci></apply><times id="S4.SS2.p4.3.m3.1.1.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">\mathcal{T}_{u}^{*}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p4.3.4" style="font-size:90%;"> marked with an asterisk to denote the inclusion of pose labels.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Neural Network Training</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.11"><span class="ltx_text" id="S4.SS3.p1.11.1" style="font-size:90%;">In our experiments, we consider the pose of a ground robot; as such, we only consider the model performance on the heading </span><math alttext="\psi" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" mathsize="90%" xref="S4.SS3.p1.1.m1.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_Ïˆ</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.2" style="font-size:90%;"> and modify </span><math alttext="\mathcal{L}_{\text{ori}}" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><msub id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.2.m2.1.1.2" mathsize="90%" xref="S4.SS3.p1.2.m2.1.1.2.cmml">â„’</mi><mtext id="S4.SS3.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS3.p1.2.m2.1.1.3a.cmml">ori</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">â„’</ci><ci id="S4.SS3.p1.2.m2.1.1.3a.cmml" xref="S4.SS3.p1.2.m2.1.1.3"><mtext id="S4.SS3.p1.2.m2.1.1.3.cmml" mathsize="63%" xref="S4.SS3.p1.2.m2.1.1.3">ori</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\mathcal{L}_{\text{ori}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT ori end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.3" style="font-size:90%;"> accordingly.
Additionally, we estimate the state of </span><math alttext="k=4" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><mrow id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" mathsize="90%" xref="S4.SS3.p1.3.m3.1.1.2.cmml">k</mi><mo id="S4.SS3.p1.3.m3.1.1.1" mathsize="90%" xref="S4.SS3.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.3.m3.1.1.3" mathsize="90%" xref="S4.SS3.p1.3.m3.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><eq id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1"></eq><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">ğ‘˜</ci><cn id="S4.SS3.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.SS3.p1.3.m3.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">k=4</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">italic_k = 4</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.4" style="font-size:90%;"> LEDs and set the maximum distance parameter </span><math alttext="d_{\text{max}}=5" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><msub id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2.2" mathsize="90%" xref="S4.SS3.p1.4.m4.1.1.2.2.cmml">d</mi><mtext id="S4.SS3.p1.4.m4.1.1.2.3" mathsize="90%" xref="S4.SS3.p1.4.m4.1.1.2.3a.cmml">max</mtext></msub><mo id="S4.SS3.p1.4.m4.1.1.1" mathsize="90%" xref="S4.SS3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.4.m4.1.1.3" mathsize="90%" xref="S4.SS3.p1.4.m4.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><eq id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></eq><apply id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.2.1.cmml" xref="S4.SS3.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.4.m4.1.1.2.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2.2">ğ‘‘</ci><ci id="S4.SS3.p1.4.m4.1.1.2.3a.cmml" xref="S4.SS3.p1.4.m4.1.1.2.3"><mtext id="S4.SS3.p1.4.m4.1.1.2.3.cmml" mathsize="63%" xref="S4.SS3.p1.4.m4.1.1.2.3">max</mtext></ci></apply><cn id="S4.SS3.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS3.p1.4.m4.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">d_{\text{max}}=5</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">italic_d start_POSTSUBSCRIPT max end_POSTSUBSCRIPT = 5</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.5" style="font-size:90%;"> meters, as robots do not exceed this relative distance in the collected data.
All strategies train on their respective datasets for 100 epochs with the Adam optimizer, using a cosine annealing learning rate schedule starting at </span><math alttext="10^{-3}" class="ltx_Math" display="inline" id="S4.SS3.p1.5.m5.1"><semantics id="S4.SS3.p1.5.m5.1a"><msup id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mn id="S4.SS3.p1.5.m5.1.1.2" mathsize="90%" xref="S4.SS3.p1.5.m5.1.1.2.cmml">10</mn><mrow id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml"><mo id="S4.SS3.p1.5.m5.1.1.3a" mathsize="90%" xref="S4.SS3.p1.5.m5.1.1.3.cmml">âˆ’</mo><mn id="S4.SS3.p1.5.m5.1.1.3.2" mathsize="90%" xref="S4.SS3.p1.5.m5.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">superscript</csymbol><cn id="S4.SS3.p1.5.m5.1.1.2.cmml" type="integer" xref="S4.SS3.p1.5.m5.1.1.2">10</cn><apply id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3"><minus id="S4.SS3.p1.5.m5.1.1.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3"></minus><cn id="S4.SS3.p1.5.m5.1.1.3.2.cmml" type="integer" xref="S4.SS3.p1.5.m5.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">10^{-3}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.5.m5.1d">10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.6" style="font-size:90%;"> and decaying to </span><math alttext="10^{-5}" class="ltx_Math" display="inline" id="S4.SS3.p1.6.m6.1"><semantics id="S4.SS3.p1.6.m6.1a"><msup id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml"><mn id="S4.SS3.p1.6.m6.1.1.2" mathsize="90%" xref="S4.SS3.p1.6.m6.1.1.2.cmml">10</mn><mrow id="S4.SS3.p1.6.m6.1.1.3" xref="S4.SS3.p1.6.m6.1.1.3.cmml"><mo id="S4.SS3.p1.6.m6.1.1.3a" mathsize="90%" xref="S4.SS3.p1.6.m6.1.1.3.cmml">âˆ’</mo><mn id="S4.SS3.p1.6.m6.1.1.3.2" mathsize="90%" xref="S4.SS3.p1.6.m6.1.1.3.2.cmml">5</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><apply id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.6.m6.1.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">superscript</csymbol><cn id="S4.SS3.p1.6.m6.1.1.2.cmml" type="integer" xref="S4.SS3.p1.6.m6.1.1.2">10</cn><apply id="S4.SS3.p1.6.m6.1.1.3.cmml" xref="S4.SS3.p1.6.m6.1.1.3"><minus id="S4.SS3.p1.6.m6.1.1.3.1.cmml" xref="S4.SS3.p1.6.m6.1.1.3"></minus><cn id="S4.SS3.p1.6.m6.1.1.3.2.cmml" type="integer" xref="S4.SS3.p1.6.m6.1.1.3.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.6.m6.1d">10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.7" style="font-size:90%;"> at the end of the training, and a batch size of 64 samples.
We employ the following data augmentations to increase the variability of the images: additive simplex noise; random translation and rotation (</span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.SS3.p1.7.m7.1"><semantics id="S4.SS3.p1.7.m7.1a"><mo id="S4.SS3.p1.7.m7.1.1" mathsize="90%" xref="S4.SS3.p1.7.m7.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><csymbol cd="latexml" id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.7.m7.1d">Â±</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.8" style="font-size:90%;"> 64 px, </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.SS3.p1.8.m8.1"><semantics id="S4.SS3.p1.8.m8.1a"><mo id="S4.SS3.p1.8.m8.1.1" mathsize="90%" xref="S4.SS3.p1.8.m8.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><csymbol cd="latexml" id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.8.m8.1d">Â±</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.9" style="font-size:90%;"> </span><math class="ltx_Math" display="inline" id="S4.SS3.p1.9.m9.1"><semantics id="S4.SS3.p1.9.m9.1a"><mrow id="S4.SS3.p1.9.m9.1.1.2"><mn id="S4.SS3.p1.9.m9.1.1.2.2" mathsize="90%" xref="S4.SS3.p1.9.m9.1.1.1.cmml">9</mn><mo id="S4.SS3.p1.9.m9.1.1.2.1" xref="S4.SS3.p1.9.m9.1.1.1.cmml">â¢</mo><mi id="S4.SS3.p1.9.m9.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S4.SS3.p1.9.m9.1.1.1.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><cn id="S4.SS3.p1.9.m9.1.1.1.cmml" type="float" xref="S4.SS3.p1.9.m9.1.1.2.2">9Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S4.SS3.p1.9.m9.1c">9 â¢ Â°</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.10" style="font-size:90%;">); and random hue shift, brightness and contrast.
FCN models produce output maps of size </span><math alttext="w^{\prime}\times h^{\prime}=80\times 45" class="ltx_Math" display="inline" id="S4.SS3.p1.10.m10.1"><semantics id="S4.SS3.p1.10.m10.1a"><mrow id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml"><mrow id="S4.SS3.p1.10.m10.1.1.2" xref="S4.SS3.p1.10.m10.1.1.2.cmml"><msup id="S4.SS3.p1.10.m10.1.1.2.2" xref="S4.SS3.p1.10.m10.1.1.2.2.cmml"><mi id="S4.SS3.p1.10.m10.1.1.2.2.2" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.2.2.2.cmml">w</mi><mo id="S4.SS3.p1.10.m10.1.1.2.2.3" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.2.2.3.cmml">â€²</mo></msup><mo id="S4.SS3.p1.10.m10.1.1.2.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS3.p1.10.m10.1.1.2.1.cmml">Ã—</mo><msup id="S4.SS3.p1.10.m10.1.1.2.3" xref="S4.SS3.p1.10.m10.1.1.2.3.cmml"><mi id="S4.SS3.p1.10.m10.1.1.2.3.2" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.2.3.2.cmml">h</mi><mo id="S4.SS3.p1.10.m10.1.1.2.3.3" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.2.3.3.cmml">â€²</mo></msup></mrow><mo id="S4.SS3.p1.10.m10.1.1.1" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.1.cmml">=</mo><mrow id="S4.SS3.p1.10.m10.1.1.3" xref="S4.SS3.p1.10.m10.1.1.3.cmml"><mn id="S4.SS3.p1.10.m10.1.1.3.2" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.3.2.cmml">80</mn><mo id="S4.SS3.p1.10.m10.1.1.3.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS3.p1.10.m10.1.1.3.1.cmml">Ã—</mo><mn id="S4.SS3.p1.10.m10.1.1.3.3" mathsize="90%" xref="S4.SS3.p1.10.m10.1.1.3.3.cmml">45</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b"><apply id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1"><eq id="S4.SS3.p1.10.m10.1.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1.1"></eq><apply id="S4.SS3.p1.10.m10.1.1.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2"><times id="S4.SS3.p1.10.m10.1.1.2.1.cmml" xref="S4.SS3.p1.10.m10.1.1.2.1"></times><apply id="S4.SS3.p1.10.m10.1.1.2.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.2.2.1.cmml" xref="S4.SS3.p1.10.m10.1.1.2.2">superscript</csymbol><ci id="S4.SS3.p1.10.m10.1.1.2.2.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2.2.2">ğ‘¤</ci><ci id="S4.SS3.p1.10.m10.1.1.2.2.3.cmml" xref="S4.SS3.p1.10.m10.1.1.2.2.3">â€²</ci></apply><apply id="S4.SS3.p1.10.m10.1.1.2.3.cmml" xref="S4.SS3.p1.10.m10.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.2.3.1.cmml" xref="S4.SS3.p1.10.m10.1.1.2.3">superscript</csymbol><ci id="S4.SS3.p1.10.m10.1.1.2.3.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2.3.2">â„</ci><ci id="S4.SS3.p1.10.m10.1.1.2.3.3.cmml" xref="S4.SS3.p1.10.m10.1.1.2.3.3">â€²</ci></apply></apply><apply id="S4.SS3.p1.10.m10.1.1.3.cmml" xref="S4.SS3.p1.10.m10.1.1.3"><times id="S4.SS3.p1.10.m10.1.1.3.1.cmml" xref="S4.SS3.p1.10.m10.1.1.3.1"></times><cn id="S4.SS3.p1.10.m10.1.1.3.2.cmml" type="integer" xref="S4.SS3.p1.10.m10.1.1.3.2">80</cn><cn id="S4.SS3.p1.10.m10.1.1.3.3.cmml" type="integer" xref="S4.SS3.p1.10.m10.1.1.3.3">45</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">w^{\prime}\times h^{\prime}=80\times 45</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.10.m10.1d">italic_w start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT Ã— italic_h start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = 80 Ã— 45</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.11" style="font-size:90%;"> pixels;
they are evaluated using weights </span><math alttext="\bm{\theta}" class="ltx_Math" display="inline" id="S4.SS3.p1.11.m11.1"><semantics id="S4.SS3.p1.11.m11.1a"><mi id="S4.SS3.p1.11.m11.1.1" mathsize="90%" xref="S4.SS3.p1.11.m11.1.1.cmml">ğœ½</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.11.m11.1b"><ci id="S4.SS3.p1.11.m11.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1">ğœ½</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.11.m11.1c">\bm{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.11.m11.1d">bold_italic_Î¸</annotation></semantics></math><span class="ltx_text" id="S4.SS3.p1.11.12" style="font-size:90%;"> at the last epoch of training with the exception of upperbound, which reaches its best performance after 40 epochs.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.5.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.6.2">Evaluation Metrics</span>
</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.15"><span class="ltx_text" id="S4.SS4.p1.15.1" style="font-size:90%;">Models trained using the different strategies are evaluated on the testing set </span><math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1" mathsize="90%" xref="S4.SS4.p1.1.m1.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">caligraphic_Q</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.2" style="font-size:90%;">.
For the LED state estimation task, we consider the area under the receiver-operator characteristic curve (AUC) averaged over the four LEDs.
An ideal model has an AUC of 100%, while a naive classifier scores 50%.
We introduce an evaluation metric for each of the pose task losses: for the 2D detection task, we report the median euclidean distance between ground truth </span><math alttext="uv" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.1"><semantics id="S4.SS4.p1.2.m2.1a"><mrow id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml"><mi id="S4.SS4.p1.2.m2.1.1.2" mathsize="90%" xref="S4.SS4.p1.2.m2.1.1.2.cmml">u</mi><mo id="S4.SS4.p1.2.m2.1.1.1" xref="S4.SS4.p1.2.m2.1.1.1.cmml">â¢</mo><mi id="S4.SS4.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS4.p1.2.m2.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><apply id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1"><times id="S4.SS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1.1"></times><ci id="S4.SS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2">ğ‘¢</ci><ci id="S4.SS4.p1.2.m2.1.1.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.2.m2.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.3" style="font-size:90%;"> and predicted </span><math alttext="\widehat{uv}" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.1"><semantics id="S4.SS4.p1.3.m3.1a"><mover accent="true" id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml"><mrow id="S4.SS4.p1.3.m3.1.1.2" xref="S4.SS4.p1.3.m3.1.1.2.cmml"><mi id="S4.SS4.p1.3.m3.1.1.2.2" mathsize="90%" xref="S4.SS4.p1.3.m3.1.1.2.2.cmml">u</mi><mo id="S4.SS4.p1.3.m3.1.1.2.1" xref="S4.SS4.p1.3.m3.1.1.2.1.cmml">â¢</mo><mi id="S4.SS4.p1.3.m3.1.1.2.3" mathsize="90%" xref="S4.SS4.p1.3.m3.1.1.2.3.cmml">v</mi></mrow><mo id="S4.SS4.p1.3.m3.1.1.1" mathsize="90%" xref="S4.SS4.p1.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><apply id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1"><ci id="S4.SS4.p1.3.m3.1.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1.1">^</ci><apply id="S4.SS4.p1.3.m3.1.1.2.cmml" xref="S4.SS4.p1.3.m3.1.1.2"><times id="S4.SS4.p1.3.m3.1.1.2.1.cmml" xref="S4.SS4.p1.3.m3.1.1.2.1"></times><ci id="S4.SS4.p1.3.m3.1.1.2.2.cmml" xref="S4.SS4.p1.3.m3.1.1.2.2">ğ‘¢</ci><ci id="S4.SS4.p1.3.m3.1.1.2.3.cmml" xref="S4.SS4.p1.3.m3.1.1.2.3">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">\widehat{uv}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.3.m3.1d">over^ start_ARG italic_u italic_v end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.4" style="font-size:90%;"> pixel position of the robot in the image plane </span><math alttext="E_{uv}" class="ltx_Math" display="inline" id="S4.SS4.p1.4.m4.1"><semantics id="S4.SS4.p1.4.m4.1a"><msub id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml"><mi id="S4.SS4.p1.4.m4.1.1.2" mathsize="90%" xref="S4.SS4.p1.4.m4.1.1.2.cmml">E</mi><mrow id="S4.SS4.p1.4.m4.1.1.3" xref="S4.SS4.p1.4.m4.1.1.3.cmml"><mi id="S4.SS4.p1.4.m4.1.1.3.2" mathsize="90%" xref="S4.SS4.p1.4.m4.1.1.3.2.cmml">u</mi><mo id="S4.SS4.p1.4.m4.1.1.3.1" xref="S4.SS4.p1.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S4.SS4.p1.4.m4.1.1.3.3" mathsize="90%" xref="S4.SS4.p1.4.m4.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><apply id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.4.m4.1.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.p1.4.m4.1.1.2.cmml" xref="S4.SS4.p1.4.m4.1.1.2">ğ¸</ci><apply id="S4.SS4.p1.4.m4.1.1.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3"><times id="S4.SS4.p1.4.m4.1.1.3.1.cmml" xref="S4.SS4.p1.4.m4.1.1.3.1"></times><ci id="S4.SS4.p1.4.m4.1.1.3.2.cmml" xref="S4.SS4.p1.4.m4.1.1.3.2">ğ‘¢</ci><ci id="S4.SS4.p1.4.m4.1.1.3.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3.3">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">E_{uv}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.4.m4.1d">italic_E start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.5" style="font-size:90%;">;
for the distance task, we report the median absolute difference of ground truth </span><math alttext="d" class="ltx_Math" display="inline" id="S4.SS4.p1.5.m5.1"><semantics id="S4.SS4.p1.5.m5.1a"><mi id="S4.SS4.p1.5.m5.1.1" mathsize="90%" xref="S4.SS4.p1.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><ci id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">d</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.5.m5.1d">italic_d</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.6" style="font-size:90%;"> and predicted </span><math alttext="\hat{d}" class="ltx_Math" display="inline" id="S4.SS4.p1.6.m6.1"><semantics id="S4.SS4.p1.6.m6.1a"><mover accent="true" id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml"><mi id="S4.SS4.p1.6.m6.1.1.2" mathsize="90%" xref="S4.SS4.p1.6.m6.1.1.2.cmml">d</mi><mo id="S4.SS4.p1.6.m6.1.1.1" mathsize="90%" xref="S4.SS4.p1.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><apply id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1"><ci id="S4.SS4.p1.6.m6.1.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1.1">^</ci><ci id="S4.SS4.p1.6.m6.1.1.2.cmml" xref="S4.SS4.p1.6.m6.1.1.2">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">\hat{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.6.m6.1d">over^ start_ARG italic_d end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.7" style="font-size:90%;"> relative robot distance </span><math alttext="E_{d}" class="ltx_Math" display="inline" id="S4.SS4.p1.7.m7.1"><semantics id="S4.SS4.p1.7.m7.1a"><msub id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml"><mi id="S4.SS4.p1.7.m7.1.1.2" mathsize="90%" xref="S4.SS4.p1.7.m7.1.1.2.cmml">E</mi><mi id="S4.SS4.p1.7.m7.1.1.3" mathsize="90%" xref="S4.SS4.p1.7.m7.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><apply id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.7.m7.1.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS4.p1.7.m7.1.1.2.cmml" xref="S4.SS4.p1.7.m7.1.1.2">ğ¸</ci><ci id="S4.SS4.p1.7.m7.1.1.3.cmml" xref="S4.SS4.p1.7.m7.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">E_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.7.m7.1d">italic_E start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.8" style="font-size:90%;">;
and for the orientation task, we report the median circular distance between ground truth </span><math alttext="\psi" class="ltx_Math" display="inline" id="S4.SS4.p1.8.m8.1"><semantics id="S4.SS4.p1.8.m8.1a"><mi id="S4.SS4.p1.8.m8.1.1" mathsize="90%" xref="S4.SS4.p1.8.m8.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.8.m8.1b"><ci id="S4.SS4.p1.8.m8.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.8.m8.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.8.m8.1d">italic_Ïˆ</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.9" style="font-size:90%;"> and predicted </span><math alttext="\hat{\psi}" class="ltx_Math" display="inline" id="S4.SS4.p1.9.m9.1"><semantics id="S4.SS4.p1.9.m9.1a"><mover accent="true" id="S4.SS4.p1.9.m9.1.1" xref="S4.SS4.p1.9.m9.1.1.cmml"><mi id="S4.SS4.p1.9.m9.1.1.2" mathsize="90%" xref="S4.SS4.p1.9.m9.1.1.2.cmml">Ïˆ</mi><mo id="S4.SS4.p1.9.m9.1.1.1" mathsize="90%" xref="S4.SS4.p1.9.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.9.m9.1b"><apply id="S4.SS4.p1.9.m9.1.1.cmml" xref="S4.SS4.p1.9.m9.1.1"><ci id="S4.SS4.p1.9.m9.1.1.1.cmml" xref="S4.SS4.p1.9.m9.1.1.1">^</ci><ci id="S4.SS4.p1.9.m9.1.1.2.cmml" xref="S4.SS4.p1.9.m9.1.1.2">ğœ“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.9.m9.1c">\hat{\psi}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.9.m9.1d">over^ start_ARG italic_Ïˆ end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.10" style="font-size:90%;"> robot heading </span><math alttext="E_{\psi}" class="ltx_Math" display="inline" id="S4.SS4.p1.10.m10.1"><semantics id="S4.SS4.p1.10.m10.1a"><msub id="S4.SS4.p1.10.m10.1.1" xref="S4.SS4.p1.10.m10.1.1.cmml"><mi id="S4.SS4.p1.10.m10.1.1.2" mathsize="90%" xref="S4.SS4.p1.10.m10.1.1.2.cmml">E</mi><mi id="S4.SS4.p1.10.m10.1.1.3" mathsize="90%" xref="S4.SS4.p1.10.m10.1.1.3.cmml">Ïˆ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.10.m10.1b"><apply id="S4.SS4.p1.10.m10.1.1.cmml" xref="S4.SS4.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.10.m10.1.1.1.cmml" xref="S4.SS4.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS4.p1.10.m10.1.1.2.cmml" xref="S4.SS4.p1.10.m10.1.1.2">ğ¸</ci><ci id="S4.SS4.p1.10.m10.1.1.3.cmml" xref="S4.SS4.p1.10.m10.1.1.3">ğœ“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.10.m10.1c">E_{\psi}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.10.m10.1d">italic_E start_POSTSUBSCRIPT italic_Ïˆ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.11" style="font-size:90%;">.
The circular distance measures the difference between two angles accounting for the discontinuity at zero.
Additionally, we consider the median of the euclidean distance of the ground truth </span><math alttext="xyz" class="ltx_Math" display="inline" id="S4.SS4.p1.11.m11.1"><semantics id="S4.SS4.p1.11.m11.1a"><mrow id="S4.SS4.p1.11.m11.1.1" xref="S4.SS4.p1.11.m11.1.1.cmml"><mi id="S4.SS4.p1.11.m11.1.1.2" mathsize="90%" xref="S4.SS4.p1.11.m11.1.1.2.cmml">x</mi><mo id="S4.SS4.p1.11.m11.1.1.1" xref="S4.SS4.p1.11.m11.1.1.1.cmml">â¢</mo><mi id="S4.SS4.p1.11.m11.1.1.3" mathsize="90%" xref="S4.SS4.p1.11.m11.1.1.3.cmml">y</mi><mo id="S4.SS4.p1.11.m11.1.1.1a" xref="S4.SS4.p1.11.m11.1.1.1.cmml">â¢</mo><mi id="S4.SS4.p1.11.m11.1.1.4" mathsize="90%" xref="S4.SS4.p1.11.m11.1.1.4.cmml">z</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.11.m11.1b"><apply id="S4.SS4.p1.11.m11.1.1.cmml" xref="S4.SS4.p1.11.m11.1.1"><times id="S4.SS4.p1.11.m11.1.1.1.cmml" xref="S4.SS4.p1.11.m11.1.1.1"></times><ci id="S4.SS4.p1.11.m11.1.1.2.cmml" xref="S4.SS4.p1.11.m11.1.1.2">ğ‘¥</ci><ci id="S4.SS4.p1.11.m11.1.1.3.cmml" xref="S4.SS4.p1.11.m11.1.1.3">ğ‘¦</ci><ci id="S4.SS4.p1.11.m11.1.1.4.cmml" xref="S4.SS4.p1.11.m11.1.1.4">ğ‘§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.11.m11.1c">xyz</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.11.m11.1d">italic_x italic_y italic_z</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.12" style="font-size:90%;"> and predicted </span><math alttext="\widehat{xyz}" class="ltx_Math" display="inline" id="S4.SS4.p1.12.m12.1"><semantics id="S4.SS4.p1.12.m12.1a"><mover accent="true" id="S4.SS4.p1.12.m12.1.1" xref="S4.SS4.p1.12.m12.1.1.cmml"><mrow id="S4.SS4.p1.12.m12.1.1.2" xref="S4.SS4.p1.12.m12.1.1.2.cmml"><mi id="S4.SS4.p1.12.m12.1.1.2.2" mathsize="90%" xref="S4.SS4.p1.12.m12.1.1.2.2.cmml">x</mi><mo id="S4.SS4.p1.12.m12.1.1.2.1" xref="S4.SS4.p1.12.m12.1.1.2.1.cmml">â¢</mo><mi id="S4.SS4.p1.12.m12.1.1.2.3" mathsize="90%" xref="S4.SS4.p1.12.m12.1.1.2.3.cmml">y</mi><mo id="S4.SS4.p1.12.m12.1.1.2.1a" xref="S4.SS4.p1.12.m12.1.1.2.1.cmml">â¢</mo><mi id="S4.SS4.p1.12.m12.1.1.2.4" mathsize="90%" xref="S4.SS4.p1.12.m12.1.1.2.4.cmml">z</mi></mrow><mo id="S4.SS4.p1.12.m12.1.1.1" mathsize="90%" xref="S4.SS4.p1.12.m12.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.12.m12.1b"><apply id="S4.SS4.p1.12.m12.1.1.cmml" xref="S4.SS4.p1.12.m12.1.1"><ci id="S4.SS4.p1.12.m12.1.1.1.cmml" xref="S4.SS4.p1.12.m12.1.1.1">^</ci><apply id="S4.SS4.p1.12.m12.1.1.2.cmml" xref="S4.SS4.p1.12.m12.1.1.2"><times id="S4.SS4.p1.12.m12.1.1.2.1.cmml" xref="S4.SS4.p1.12.m12.1.1.2.1"></times><ci id="S4.SS4.p1.12.m12.1.1.2.2.cmml" xref="S4.SS4.p1.12.m12.1.1.2.2">ğ‘¥</ci><ci id="S4.SS4.p1.12.m12.1.1.2.3.cmml" xref="S4.SS4.p1.12.m12.1.1.2.3">ğ‘¦</ci><ci id="S4.SS4.p1.12.m12.1.1.2.4.cmml" xref="S4.SS4.p1.12.m12.1.1.2.4">ğ‘§</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.12.m12.1c">\widehat{xyz}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.12.m12.1d">over^ start_ARG italic_x italic_y italic_z end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.13" style="font-size:90%;"> 3D position of the robot </span><math alttext="E_{xyz}" class="ltx_Math" display="inline" id="S4.SS4.p1.13.m13.1"><semantics id="S4.SS4.p1.13.m13.1a"><msub id="S4.SS4.p1.13.m13.1.1" xref="S4.SS4.p1.13.m13.1.1.cmml"><mi id="S4.SS4.p1.13.m13.1.1.2" mathsize="90%" xref="S4.SS4.p1.13.m13.1.1.2.cmml">E</mi><mrow id="S4.SS4.p1.13.m13.1.1.3" xref="S4.SS4.p1.13.m13.1.1.3.cmml"><mi id="S4.SS4.p1.13.m13.1.1.3.2" mathsize="90%" xref="S4.SS4.p1.13.m13.1.1.3.2.cmml">x</mi><mo id="S4.SS4.p1.13.m13.1.1.3.1" xref="S4.SS4.p1.13.m13.1.1.3.1.cmml">â¢</mo><mi id="S4.SS4.p1.13.m13.1.1.3.3" mathsize="90%" xref="S4.SS4.p1.13.m13.1.1.3.3.cmml">y</mi><mo id="S4.SS4.p1.13.m13.1.1.3.1a" xref="S4.SS4.p1.13.m13.1.1.3.1.cmml">â¢</mo><mi id="S4.SS4.p1.13.m13.1.1.3.4" mathsize="90%" xref="S4.SS4.p1.13.m13.1.1.3.4.cmml">z</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.13.m13.1b"><apply id="S4.SS4.p1.13.m13.1.1.cmml" xref="S4.SS4.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.13.m13.1.1.1.cmml" xref="S4.SS4.p1.13.m13.1.1">subscript</csymbol><ci id="S4.SS4.p1.13.m13.1.1.2.cmml" xref="S4.SS4.p1.13.m13.1.1.2">ğ¸</ci><apply id="S4.SS4.p1.13.m13.1.1.3.cmml" xref="S4.SS4.p1.13.m13.1.1.3"><times id="S4.SS4.p1.13.m13.1.1.3.1.cmml" xref="S4.SS4.p1.13.m13.1.1.3.1"></times><ci id="S4.SS4.p1.13.m13.1.1.3.2.cmml" xref="S4.SS4.p1.13.m13.1.1.3.2">ğ‘¥</ci><ci id="S4.SS4.p1.13.m13.1.1.3.3.cmml" xref="S4.SS4.p1.13.m13.1.1.3.3">ğ‘¦</ci><ci id="S4.SS4.p1.13.m13.1.1.3.4.cmml" xref="S4.SS4.p1.13.m13.1.1.3.4">ğ‘§</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.13.m13.1c">E_{xyz}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.13.m13.1d">italic_E start_POSTSUBSCRIPT italic_x italic_y italic_z end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.14" style="font-size:90%;">, computed from </span><math alttext="\widehat{uv}" class="ltx_Math" display="inline" id="S4.SS4.p1.14.m14.1"><semantics id="S4.SS4.p1.14.m14.1a"><mover accent="true" id="S4.SS4.p1.14.m14.1.1" xref="S4.SS4.p1.14.m14.1.1.cmml"><mrow id="S4.SS4.p1.14.m14.1.1.2" xref="S4.SS4.p1.14.m14.1.1.2.cmml"><mi id="S4.SS4.p1.14.m14.1.1.2.2" mathsize="90%" xref="S4.SS4.p1.14.m14.1.1.2.2.cmml">u</mi><mo id="S4.SS4.p1.14.m14.1.1.2.1" xref="S4.SS4.p1.14.m14.1.1.2.1.cmml">â¢</mo><mi id="S4.SS4.p1.14.m14.1.1.2.3" mathsize="90%" xref="S4.SS4.p1.14.m14.1.1.2.3.cmml">v</mi></mrow><mo id="S4.SS4.p1.14.m14.1.1.1" mathsize="90%" xref="S4.SS4.p1.14.m14.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.14.m14.1b"><apply id="S4.SS4.p1.14.m14.1.1.cmml" xref="S4.SS4.p1.14.m14.1.1"><ci id="S4.SS4.p1.14.m14.1.1.1.cmml" xref="S4.SS4.p1.14.m14.1.1.1">^</ci><apply id="S4.SS4.p1.14.m14.1.1.2.cmml" xref="S4.SS4.p1.14.m14.1.1.2"><times id="S4.SS4.p1.14.m14.1.1.2.1.cmml" xref="S4.SS4.p1.14.m14.1.1.2.1"></times><ci id="S4.SS4.p1.14.m14.1.1.2.2.cmml" xref="S4.SS4.p1.14.m14.1.1.2.2">ğ‘¢</ci><ci id="S4.SS4.p1.14.m14.1.1.2.3.cmml" xref="S4.SS4.p1.14.m14.1.1.2.3">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.14.m14.1c">\widehat{uv}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.14.m14.1d">over^ start_ARG italic_u italic_v end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.15" style="font-size:90%;"> and </span><math alttext="\hat{d}" class="ltx_Math" display="inline" id="S4.SS4.p1.15.m15.1"><semantics id="S4.SS4.p1.15.m15.1a"><mover accent="true" id="S4.SS4.p1.15.m15.1.1" xref="S4.SS4.p1.15.m15.1.1.cmml"><mi id="S4.SS4.p1.15.m15.1.1.2" mathsize="90%" xref="S4.SS4.p1.15.m15.1.1.2.cmml">d</mi><mo id="S4.SS4.p1.15.m15.1.1.1" mathsize="90%" xref="S4.SS4.p1.15.m15.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.15.m15.1b"><apply id="S4.SS4.p1.15.m15.1.1.cmml" xref="S4.SS4.p1.15.m15.1.1"><ci id="S4.SS4.p1.15.m15.1.1.1.cmml" xref="S4.SS4.p1.15.m15.1.1.1">^</ci><ci id="S4.SS4.p1.15.m15.1.1.2.cmml" xref="S4.SS4.p1.15.m15.1.1.2">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.15.m15.1c">\hat{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.15.m15.1d">over^ start_ARG italic_d end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p1.15.16" style="font-size:90%;"> using the camera intrinsics, as described in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S3" style="font-size:90%;" title="III Method â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">III</span></a><span class="ltx_text" id="S4.SS4.p1.15.17" style="font-size:90%;">.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text" id="S5.p1.1.1" style="font-size:90%;">In this section, we report a detailed analysis of our experimental results.
Specifically, we show that the proposed approach enables learning of the robot detection task without position labels in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS1" style="font-size:90%;" title="V-A LED Pretext Task Learns Robot Detection Without Labels â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a><span class="ltx_text" id="S5.p1.1.2" style="font-size:90%;">.
The trained models are then transferred to the 3D position and heading tasks, investigating how the amount of labeled training data affects performance in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS2" style="font-size:90%;" title="V-B LED Pretext Task Transfers Well to Pose Estimation â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a><span class="ltx_text" id="S5.p1.1.3" style="font-size:90%;">, and the role of the pretext in learning the robotâ€™s heading in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS3" style="font-size:90%;" title="V-C LED Pretext Task Captures Robot Heading â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span></span></a><span class="ltx_text" id="S5.p1.1.4" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text" id="S5.p2.1.1" style="font-size:90%;">The robustness of the pretext approach is explored in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS4" style="font-size:90%;" title="V-D LED Pretext Task is Robust to Images Without Robots â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-D</span></span></a><span class="ltx_text" id="S5.p2.1.2" style="font-size:90%;"> by training on the unlabeled dataset </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><msubsup id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p2.1.m1.1.1.2.2" mathsize="90%" xref="S5.p2.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.p2.1.m1.1.1.2.3" mathsize="90%" xref="S5.p2.1.m1.1.1.2.3.cmml">u</mi><mi id="S5.p2.1.m1.1.1.3" mathsize="90%" xref="S5.p2.1.m1.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1">superscript</csymbol><apply id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.2.1.cmml" xref="S5.p2.1.m1.1.1">subscript</csymbol><ci id="S5.p2.1.m1.1.1.2.2.cmml" xref="S5.p2.1.m1.1.1.2.2">ğ’¯</ci><ci id="S5.p2.1.m1.1.1.2.3.cmml" xref="S5.p2.1.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.p2.1.3" style="font-size:90%;"> in which only 22% of the images depict the target robot, whereas the rest only feature the background.
Finally, we test the generalization ability by deploying the model in never-seen-before environments in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS5" style="font-size:90%;" title="V-E LED Pretext Task Generalizes to Unseen Environments â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-E</span></span></a><span class="ltx_text" id="S5.p2.1.4" style="font-size:90%;">.</span></p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">LED Pretext Task Learns Robot Detection Without Labels</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2"><span class="ltx_text" id="S5.SS1.p1.2.1" style="font-size:90%;">We report in the first panel of TableÂ </span><span class="ltx_ref ltx_missing_label ltx_ref_self" style="font-size:90%;">LABEL:tab:table</span><span class="ltx_text" id="S5.SS1.p1.2.2" style="font-size:90%;"> the performance of our pretext strategy compared with a dummy mean and the upperbound.
Without having access to robot pose labels, the pretext model has learned to detect the robot in the image-plane simply by optimizing the LED-based pretext loss </span><math alttext="\mathcal{L}_{\text{led}}" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><msub id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p1.1.m1.1.1.2" mathsize="90%" xref="S5.SS1.p1.1.m1.1.1.2.cmml">â„’</mi><mtext id="S5.SS1.p1.1.m1.1.1.3" mathsize="90%" xref="S5.SS1.p1.1.m1.1.1.3a.cmml">led</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">â„’</ci><ci id="S5.SS1.p1.1.m1.1.1.3a.cmml" xref="S5.SS1.p1.1.m1.1.1.3"><mtext id="S5.SS1.p1.1.m1.1.1.3.cmml" mathsize="63%" xref="S5.SS1.p1.1.m1.1.1.3">led</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\mathcal{L}_{\text{led}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT led end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.2.3" style="font-size:90%;">.
Remarkably, it achieves a median 2D position error of only 51 pixels for an input image of </span><math alttext="640\times 480" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mrow id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mn id="S5.SS1.p1.2.m2.1.1.2" mathsize="90%" xref="S5.SS1.p1.2.m2.1.1.2.cmml">640</mn><mo id="S5.SS1.p1.2.m2.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S5.SS1.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="S5.SS1.p1.2.m2.1.1.3" mathsize="90%" xref="S5.SS1.p1.2.m2.1.1.3.cmml">480</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><times id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1"></times><cn id="S5.SS1.p1.2.m2.1.1.2.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1.2">640</cn><cn id="S5.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1.3">480</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">640\times 480</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">640 Ã— 480</annotation></semantics></math><span class="ltx_text" id="S5.SS1.p1.2.4" style="font-size:90%;"> pixels, a considerable feat given the very limited supervision it received.
This result indicates that our strategy of weighting the LED maps with the position map, combined with the inductive bias of FCNs, described in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S3" style="font-size:90%;" title="III Method â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">III</span></a><span class="ltx_text" id="S5.SS1.p1.2.5" style="font-size:90%;">, induces the model to recognize the area of the image where information of the LEDsâ€™ state is found, i.e., the area where the robot is depicted.</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text" id="S5.SS1.p2.1.1" style="font-size:90%;">Comparing pretext with Ablation-CAM, we note that our approach is outperformed by Ablation-CAM on robot detection;
however, this strategy does not lend itself to skill transfer to a downstream task as it requires pre-training a separate classification model.
In addition, this strategy is not feasible for real-time inference: on a NVIDIA RTX 2080, Ablation-CAM requires about 10 seconds per image, while our FCN model takes only 2.1 ms.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">LED Pretext Task Transfers Well to Pose Estimation</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.9"><span class="ltx_text" id="S5.SS2.p1.9.1" style="font-size:90%;">In the second panel of TableÂ </span><span class="ltx_ref ltx_missing_label ltx_ref_self" style="font-size:90%;">LABEL:tab:table</span><span class="ltx_text" id="S5.SS2.p1.9.2" style="font-size:90%;">, we compare the performance of the baseline strategy with the downstream one, the only difference being the initial weights: for baseline they are randomly initialized, while for downstream we use the weights of the pretext model.
Additionally, we investigate how the size of the labeled training set affects the performance by training the two strategies with 10, 100 or 1000 samples from </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><msub id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.1.m1.1.1.2" mathsize="90%" xref="S5.SS2.p1.1.m1.1.1.2.cmml">ğ’¯</mi><mi id="S5.SS2.p1.1.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p1.1.m1.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">ğ’¯</ci><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.3" style="font-size:90%;">; we represent these sets respectively as </span><math alttext="\mathcal{T}_{\ell}^{10}" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><msubsup id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.2.m2.1.1.2.2" mathsize="90%" xref="S5.SS2.p1.2.m2.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p1.2.m2.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p1.2.m2.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p1.2.m2.1.1.3" mathsize="90%" xref="S5.SS2.p1.2.m2.1.1.3.cmml">10</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">superscript</csymbol><apply id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.m2.1.1.2.1.cmml" xref="S5.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p1.2.m2.1.1.2.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p1.2.m2.1.1.2.3.cmml" xref="S5.SS2.p1.2.m2.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS2.p1.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">\mathcal{T}_{\ell}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.4" style="font-size:90%;">, </span><math alttext="\mathcal{T}_{\ell}^{100}" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><msubsup id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.3.m3.1.1.2.2" mathsize="90%" xref="S5.SS2.p1.3.m3.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p1.3.m3.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p1.3.m3.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p1.3.m3.1.1.3" mathsize="90%" xref="S5.SS2.p1.3.m3.1.1.3.cmml">100</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">superscript</csymbol><apply id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.3.m3.1.1.2.1.cmml" xref="S5.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.p1.3.m3.1.1.2.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p1.3.m3.1.1.2.3.cmml" xref="S5.SS2.p1.3.m3.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p1.3.m3.1.1.3.cmml" type="integer" xref="S5.SS2.p1.3.m3.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">\mathcal{T}_{\ell}^{100}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 100 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.5" style="font-size:90%;">, and </span><math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><msubsup id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.4.m4.1.1.2.2" mathsize="90%" xref="S5.SS2.p1.4.m4.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p1.4.m4.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p1.4.m4.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p1.4.m4.1.1.3" mathsize="90%" xref="S5.SS2.p1.4.m4.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><apply id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m4.1.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">superscript</csymbol><apply id="S5.SS2.p1.4.m4.1.1.2.cmml" xref="S5.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m4.1.1.2.1.cmml" xref="S5.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.p1.4.m4.1.1.2.2.cmml" xref="S5.SS2.p1.4.m4.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p1.4.m4.1.1.2.3.cmml" xref="S5.SS2.p1.4.m4.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p1.4.m4.1.1.3.cmml" type="integer" xref="S5.SS2.p1.4.m4.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.6" style="font-size:90%;">.
Regardless of the amount of labels, the downstream model outperforms the baseline counterpart on all metrics;
in particular, the two score closest when training on </span><math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><msubsup id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.5.m5.1.1.2.2" mathsize="90%" xref="S5.SS2.p1.5.m5.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p1.5.m5.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p1.5.m5.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p1.5.m5.1.1.3" mathsize="90%" xref="S5.SS2.p1.5.m5.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.5.m5.1.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">superscript</csymbol><apply id="S5.SS2.p1.5.m5.1.1.2.cmml" xref="S5.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.5.m5.1.1.2.1.cmml" xref="S5.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.p1.5.m5.1.1.2.2.cmml" xref="S5.SS2.p1.5.m5.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p1.5.m5.1.1.2.3.cmml" xref="S5.SS2.p1.5.m5.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p1.5.m5.1.1.3.cmml" type="integer" xref="S5.SS2.p1.5.m5.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.7" style="font-size:90%;">, where the downstream model achieves a statistically significant</span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>P-values computed using the one tailed Welchâ€™s T-test on four replicas.</span></span></span><span class="ltx_text" id="S5.SS2.p1.9.8" style="font-size:90%;">
improvement on the median </span><math alttext="uv" class="ltx_Math" display="inline" id="S5.SS2.p1.6.m6.1"><semantics id="S5.SS2.p1.6.m6.1a"><mrow id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml"><mi id="S5.SS2.p1.6.m6.1.1.2" mathsize="90%" xref="S5.SS2.p1.6.m6.1.1.2.cmml">u</mi><mo id="S5.SS2.p1.6.m6.1.1.1" xref="S5.SS2.p1.6.m6.1.1.1.cmml">â¢</mo><mi id="S5.SS2.p1.6.m6.1.1.3" mathsize="90%" xref="S5.SS2.p1.6.m6.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><apply id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1"><times id="S5.SS2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1.1"></times><ci id="S5.SS2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.2">ğ‘¢</ci><ci id="S5.SS2.p1.6.m6.1.1.3.cmml" xref="S5.SS2.p1.6.m6.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.6.m6.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.9" style="font-size:90%;"> error of 11 pixels, p-value=0.005, and on </span><math alttext="\psi" class="ltx_Math" display="inline" id="S5.SS2.p1.7.m7.1"><semantics id="S5.SS2.p1.7.m7.1a"><mi id="S5.SS2.p1.7.m7.1.1" mathsize="90%" xref="S5.SS2.p1.7.m7.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.7.m7.1b"><ci id="S5.SS2.p1.7.m7.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.7.m7.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.7.m7.1d">italic_Ïˆ</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.10" style="font-size:90%;"> by </span><math class="ltx_Math" display="inline" id="S5.SS2.p1.8.m8.1"><semantics id="S5.SS2.p1.8.m8.1a"><mrow id="S5.SS2.p1.8.m8.1.1.2"><mn id="S5.SS2.p1.8.m8.1.1.2.2" mathsize="90%" xref="S5.SS2.p1.8.m8.1.1.1.cmml">29.8</mn><mo id="S5.SS2.p1.8.m8.1.1.2.1" xref="S5.SS2.p1.8.m8.1.1.1.cmml">â¢</mo><mi id="S5.SS2.p1.8.m8.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p1.8.m8.1.1.1.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.8.m8.1b"><cn id="S5.SS2.p1.8.m8.1.1.1.cmml" type="float" xref="S5.SS2.p1.8.m8.1.1.2.2">29.8Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S5.SS2.p1.8.m8.1c">29.8 â¢ Â°</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.11" style="font-size:90%;">, p-value</span><math alttext="&lt;" class="ltx_Math" display="inline" id="S5.SS2.p1.9.m9.1"><semantics id="S5.SS2.p1.9.m9.1a"><mo id="S5.SS2.p1.9.m9.1.1" mathsize="90%" xref="S5.SS2.p1.9.m9.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.9.m9.1b"><lt id="S5.SS2.p1.9.m9.1.1.cmml" xref="S5.SS2.p1.9.m9.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.9.m9.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.9.m9.1d">&lt;</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p1.9.12" style="font-size:90%;">0.001.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.10"><span class="ltx_text" id="S5.SS2.p2.10.1" style="font-size:90%;">More interestingly, the downstream model trained with </span><math alttext="\mathcal{T}_{\ell}^{100}" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><msubsup id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p2.1.m1.1.1.2.2" mathsize="90%" xref="S5.SS2.p2.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p2.1.m1.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p2.1.m1.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p2.1.m1.1.1.3" mathsize="90%" xref="S5.SS2.p2.1.m1.1.1.3.cmml">100</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">superscript</csymbol><apply id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.2.1.cmml" xref="S5.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.2.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p2.1.m1.1.1.2.3.cmml" xref="S5.SS2.p2.1.m1.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p2.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">\mathcal{T}_{\ell}^{100}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 100 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.2" style="font-size:90%;"> achieves the same performance on </span><math alttext="uv" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" mathsize="90%" xref="S5.SS2.p2.2.m2.1.1.2.cmml">u</mi><mo id="S5.SS2.p2.2.m2.1.1.1" xref="S5.SS2.p2.2.m2.1.1.1.cmml">â¢</mo><mi id="S5.SS2.p2.2.m2.1.1.3" mathsize="90%" xref="S5.SS2.p2.2.m2.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><times id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1.1"></times><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">ğ‘¢</ci><ci id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.3" style="font-size:90%;"> of the baseline model trained with </span><math alttext="10\times" class="ltx_math_unparsed" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mrow id="S5.SS2.p2.3.m3.1b"><mn id="S5.SS2.p2.3.m3.1.1" mathsize="90%">10</mn><mo id="S5.SS2.p2.3.m3.1.2" lspace="0.222em" mathsize="90%">Ã—</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">10\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">10 Ã—</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.4" style="font-size:90%;"> the amount of labeled data, and the downstream model trained with </span><math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.SS2.p2.4.m4.1"><semantics id="S5.SS2.p2.4.m4.1a"><msubsup id="S5.SS2.p2.4.m4.1.1" xref="S5.SS2.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p2.4.m4.1.1.2.2" mathsize="90%" xref="S5.SS2.p2.4.m4.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p2.4.m4.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p2.4.m4.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p2.4.m4.1.1.3" mathsize="90%" xref="S5.SS2.p2.4.m4.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.4.m4.1b"><apply id="S5.SS2.p2.4.m4.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.4.m4.1.1.1.cmml" xref="S5.SS2.p2.4.m4.1.1">superscript</csymbol><apply id="S5.SS2.p2.4.m4.1.1.2.cmml" xref="S5.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.4.m4.1.1.2.1.cmml" xref="S5.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.p2.4.m4.1.1.2.2.cmml" xref="S5.SS2.p2.4.m4.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p2.4.m4.1.1.2.3.cmml" xref="S5.SS2.p2.4.m4.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p2.4.m4.1.1.3.cmml" type="integer" xref="S5.SS2.p2.4.m4.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.4.m4.1c">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.5" style="font-size:90%;"> reduces the gap to just 4 pixels of </span><math alttext="uv" class="ltx_Math" display="inline" id="S5.SS2.p2.5.m5.1"><semantics id="S5.SS2.p2.5.m5.1a"><mrow id="S5.SS2.p2.5.m5.1.1" xref="S5.SS2.p2.5.m5.1.1.cmml"><mi id="S5.SS2.p2.5.m5.1.1.2" mathsize="90%" xref="S5.SS2.p2.5.m5.1.1.2.cmml">u</mi><mo id="S5.SS2.p2.5.m5.1.1.1" xref="S5.SS2.p2.5.m5.1.1.1.cmml">â¢</mo><mi id="S5.SS2.p2.5.m5.1.1.3" mathsize="90%" xref="S5.SS2.p2.5.m5.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.5.m5.1b"><apply id="S5.SS2.p2.5.m5.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1"><times id="S5.SS2.p2.5.m5.1.1.1.cmml" xref="S5.SS2.p2.5.m5.1.1.1"></times><ci id="S5.SS2.p2.5.m5.1.1.2.cmml" xref="S5.SS2.p2.5.m5.1.1.2">ğ‘¢</ci><ci id="S5.SS2.p2.5.m5.1.1.3.cmml" xref="S5.SS2.p2.5.m5.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.5.m5.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.5.m5.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.6" style="font-size:90%;"> error with the upperbound model, which is trained on 35k labeled samples.
Baseline models trained on </span><math alttext="\mathcal{T}_{\ell}^{10}" class="ltx_Math" display="inline" id="S5.SS2.p2.6.m6.1"><semantics id="S5.SS2.p2.6.m6.1a"><msubsup id="S5.SS2.p2.6.m6.1.1" xref="S5.SS2.p2.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p2.6.m6.1.1.2.2" mathsize="90%" xref="S5.SS2.p2.6.m6.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p2.6.m6.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p2.6.m6.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p2.6.m6.1.1.3" mathsize="90%" xref="S5.SS2.p2.6.m6.1.1.3.cmml">10</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.6.m6.1b"><apply id="S5.SS2.p2.6.m6.1.1.cmml" xref="S5.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.6.m6.1.1.1.cmml" xref="S5.SS2.p2.6.m6.1.1">superscript</csymbol><apply id="S5.SS2.p2.6.m6.1.1.2.cmml" xref="S5.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.6.m6.1.1.2.1.cmml" xref="S5.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S5.SS2.p2.6.m6.1.1.2.2.cmml" xref="S5.SS2.p2.6.m6.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p2.6.m6.1.1.2.3.cmml" xref="S5.SS2.p2.6.m6.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p2.6.m6.1.1.3.cmml" type="integer" xref="S5.SS2.p2.6.m6.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.6.m6.1c">\mathcal{T}_{\ell}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.6.m6.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.7" style="font-size:90%;"> and </span><math alttext="\mathcal{T}_{\ell}^{100}" class="ltx_Math" display="inline" id="S5.SS2.p2.7.m7.1"><semantics id="S5.SS2.p2.7.m7.1a"><msubsup id="S5.SS2.p2.7.m7.1.1" xref="S5.SS2.p2.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p2.7.m7.1.1.2.2" mathsize="90%" xref="S5.SS2.p2.7.m7.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p2.7.m7.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p2.7.m7.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p2.7.m7.1.1.3" mathsize="90%" xref="S5.SS2.p2.7.m7.1.1.3.cmml">100</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.7.m7.1b"><apply id="S5.SS2.p2.7.m7.1.1.cmml" xref="S5.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.7.m7.1.1.1.cmml" xref="S5.SS2.p2.7.m7.1.1">superscript</csymbol><apply id="S5.SS2.p2.7.m7.1.1.2.cmml" xref="S5.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.7.m7.1.1.2.1.cmml" xref="S5.SS2.p2.7.m7.1.1">subscript</csymbol><ci id="S5.SS2.p2.7.m7.1.1.2.2.cmml" xref="S5.SS2.p2.7.m7.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p2.7.m7.1.1.2.3.cmml" xref="S5.SS2.p2.7.m7.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p2.7.m7.1.1.3.cmml" type="integer" xref="S5.SS2.p2.7.m7.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.7.m7.1c">\mathcal{T}_{\ell}^{100}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.7.m7.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 100 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.8" style="font-size:90%;"> perform equal or worse to the dummy mean model, while the downstream model trained on </span><math alttext="\mathcal{T}_{\ell}^{100}" class="ltx_Math" display="inline" id="S5.SS2.p2.8.m8.1"><semantics id="S5.SS2.p2.8.m8.1a"><msubsup id="S5.SS2.p2.8.m8.1.1" xref="S5.SS2.p2.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p2.8.m8.1.1.2.2" mathsize="90%" xref="S5.SS2.p2.8.m8.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p2.8.m8.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p2.8.m8.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p2.8.m8.1.1.3" mathsize="90%" xref="S5.SS2.p2.8.m8.1.1.3.cmml">100</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.8.m8.1b"><apply id="S5.SS2.p2.8.m8.1.1.cmml" xref="S5.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.8.m8.1.1.1.cmml" xref="S5.SS2.p2.8.m8.1.1">superscript</csymbol><apply id="S5.SS2.p2.8.m8.1.1.2.cmml" xref="S5.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.8.m8.1.1.2.1.cmml" xref="S5.SS2.p2.8.m8.1.1">subscript</csymbol><ci id="S5.SS2.p2.8.m8.1.1.2.2.cmml" xref="S5.SS2.p2.8.m8.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p2.8.m8.1.1.2.3.cmml" xref="S5.SS2.p2.8.m8.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p2.8.m8.1.1.3.cmml" type="integer" xref="S5.SS2.p2.8.m8.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.8.m8.1c">\mathcal{T}_{\ell}^{100}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.8.m8.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 100 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.9" style="font-size:90%;"> outperforms dummy on all metrics and the downstream model trained on </span><math alttext="\mathcal{T}_{\ell}^{10}" class="ltx_Math" display="inline" id="S5.SS2.p2.9.m9.1"><semantics id="S5.SS2.p2.9.m9.1a"><msubsup id="S5.SS2.p2.9.m9.1.1" xref="S5.SS2.p2.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p2.9.m9.1.1.2.2" mathsize="90%" xref="S5.SS2.p2.9.m9.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p2.9.m9.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p2.9.m9.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p2.9.m9.1.1.3" mathsize="90%" xref="S5.SS2.p2.9.m9.1.1.3.cmml">10</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.9.m9.1b"><apply id="S5.SS2.p2.9.m9.1.1.cmml" xref="S5.SS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.9.m9.1.1.1.cmml" xref="S5.SS2.p2.9.m9.1.1">superscript</csymbol><apply id="S5.SS2.p2.9.m9.1.1.2.cmml" xref="S5.SS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.9.m9.1.1.2.1.cmml" xref="S5.SS2.p2.9.m9.1.1">subscript</csymbol><ci id="S5.SS2.p2.9.m9.1.1.2.2.cmml" xref="S5.SS2.p2.9.m9.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p2.9.m9.1.1.2.3.cmml" xref="S5.SS2.p2.9.m9.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p2.9.m9.1.1.3.cmml" type="integer" xref="S5.SS2.p2.9.m9.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.9.m9.1c">\mathcal{T}_{\ell}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.9.m9.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.10" style="font-size:90%;"> on all metrics except for </span><math alttext="\psi" class="ltx_Math" display="inline" id="S5.SS2.p2.10.m10.1"><semantics id="S5.SS2.p2.10.m10.1a"><mi id="S5.SS2.p2.10.m10.1.1" mathsize="90%" xref="S5.SS2.p2.10.m10.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.10.m10.1b"><ci id="S5.SS2.p2.10.m10.1.1.cmml" xref="S5.SS2.p2.10.m10.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.10.m10.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.10.m10.1d">italic_Ïˆ</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p2.10.11" style="font-size:90%;">.
Comparing with CLIP demonstrates that our LED pretext better captures geometrical information about the robot;
instead, CLIPâ€™s language-image pretext does not lend itself well to pose estimation, and further lacks the inductive bias that our FCN architecture posses, resulting in a worse performance than baseline trained on the same data.</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.2"><span class="ltx_text" id="S5.SS2.p3.2.1" style="font-size:90%;">On the 3D position, the downstream model consistently outperforms the respective baseline model across all percentages of </span><math alttext="\mathcal{T}_{\ell}" class="ltx_Math" display="inline" id="S5.SS2.p3.1.m1.1"><semantics id="S5.SS2.p3.1.m1.1a"><msub id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p3.1.m1.1.1.2" mathsize="90%" xref="S5.SS2.p3.1.m1.1.1.2.cmml">ğ’¯</mi><mi id="S5.SS2.p3.1.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p3.1.m1.1.1.3.cmml">â„“</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><apply id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p3.1.m1.1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p3.1.m1.1.1.2.cmml" xref="S5.SS2.p3.1.m1.1.1.2">ğ’¯</ci><ci id="S5.SS2.p3.1.m1.1.1.3.cmml" xref="S5.SS2.p3.1.m1.1.1.3">â„“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">\mathcal{T}_{\ell}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p3.2.2" style="font-size:90%;"> in a statistically significant manner, with the closest example being of models trained on </span><math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.SS2.p3.2.m2.1"><semantics id="S5.SS2.p3.2.m2.1a"><msubsup id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p3.2.m2.1.1.2.2" mathsize="90%" xref="S5.SS2.p3.2.m2.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS2.p3.2.m2.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS2.p3.2.m2.1.1.2.3.cmml">â„“</mi><mn id="S5.SS2.p3.2.m2.1.1.3" mathsize="90%" xref="S5.SS2.p3.2.m2.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><apply id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p3.2.m2.1.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1">superscript</csymbol><apply id="S5.SS2.p3.2.m2.1.1.2.cmml" xref="S5.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p3.2.m2.1.1.2.1.cmml" xref="S5.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p3.2.m2.1.1.2.2.cmml" xref="S5.SS2.p3.2.m2.1.1.2.2">ğ’¯</ci><ci id="S5.SS2.p3.2.m2.1.1.2.3.cmml" xref="S5.SS2.p3.2.m2.1.1.2.3">â„“</ci></apply><cn id="S5.SS2.p3.2.m2.1.1.3.cmml" type="integer" xref="S5.SS2.p3.2.m2.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS2.p3.2.3" style="font-size:90%;"> where p-value=0.013.</span></p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="274" id="S5.F4.g1" src="extracted/5878331/fig/confidence.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Predicted LED maps by the pretext model trained on random 3.5k samples from <math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S5.F4.2.m1.1"><semantics id="S5.F4.2.m1.1b"><msubsup id="S5.F4.2.m1.1.1" xref="S5.F4.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.F4.2.m1.1.1.2.2" xref="S5.F4.2.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.F4.2.m1.1.1.2.3" xref="S5.F4.2.m1.1.1.2.3.cmml">u</mi><mi id="S5.F4.2.m1.1.1.3" xref="S5.F4.2.m1.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.F4.2.m1.1c"><apply id="S5.F4.2.m1.1.1.cmml" xref="S5.F4.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F4.2.m1.1.1.1.cmml" xref="S5.F4.2.m1.1.1">superscript</csymbol><apply id="S5.F4.2.m1.1.1.2.cmml" xref="S5.F4.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F4.2.m1.1.1.2.1.cmml" xref="S5.F4.2.m1.1.1">subscript</csymbol><ci id="S5.F4.2.m1.1.1.2.2.cmml" xref="S5.F4.2.m1.1.1.2.2">ğ’¯</ci><ci id="S5.F4.2.m1.1.1.2.3.cmml" xref="S5.F4.2.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S5.F4.2.m1.1.1.3.cmml" xref="S5.F4.2.m1.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.2.m1.1d">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S5.F4.2.m1.1e">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math>. From left to right, input image, left LED map, and right LED map. Top image depicts the robot with left LED visible and turned on; bottom image depicts right LED visible and turned off. Position map cells with low probability of having a robot are depicted in gray. Predicted LED state scalars are reported on the top right corners of the LED maps.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="56" id="S5.F5.g1" src="extracted/5878331/fig/generalization.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Six images from unseen environments and predicted robotâ€™s bounding boxes (red) generated by the downstream model trained on <math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.F5.2.m1.1"><semantics id="S5.F5.2.m1.1b"><msubsup id="S5.F5.2.m1.1.1" xref="S5.F5.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.F5.2.m1.1.1.2.2" xref="S5.F5.2.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.F5.2.m1.1.1.2.3" mathvariant="normal" xref="S5.F5.2.m1.1.1.2.3.cmml">â„“</mi><mn id="S5.F5.2.m1.1.1.3" xref="S5.F5.2.m1.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.F5.2.m1.1c"><apply id="S5.F5.2.m1.1.1.cmml" xref="S5.F5.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F5.2.m1.1.1.1.cmml" xref="S5.F5.2.m1.1.1">superscript</csymbol><apply id="S5.F5.2.m1.1.1.2.cmml" xref="S5.F5.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F5.2.m1.1.1.2.1.cmml" xref="S5.F5.2.m1.1.1">subscript</csymbol><ci id="S5.F5.2.m1.1.1.2.2.cmml" xref="S5.F5.2.m1.1.1.2.2">ğ’¯</ci><ci id="S5.F5.2.m1.1.1.2.3.cmml" xref="S5.F5.2.m1.1.1.2.3">â„“</ci></apply><cn id="S5.F5.2.m1.1.1.3.cmml" type="integer" xref="S5.F5.2.m1.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.2.m1.1d">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.F5.2.m1.1e">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">LED Pretext Task Captures Robot Heading</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.5"><span class="ltx_text" id="S5.SS3.p1.5.1" style="font-size:90%;">So far, we considered each LED to be independent from the others and speculated that this helps the pretext in learning useful features for the robotâ€™s heading.
In the following, we address this point with an experiment in which we consider the downstream training strategy using a subset of samples of </span><math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><msubsup id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS3.p1.1.m1.1.1.2.2" mathsize="90%" xref="S5.SS3.p1.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS3.p1.1.m1.1.1.2.3" mathsize="90%" xref="S5.SS3.p1.1.m1.1.1.2.3.cmml">u</mi><mi id="S5.SS3.p1.1.m1.1.1.3" mathsize="90%" xref="S5.SS3.p1.1.m1.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.2.1.cmml" xref="S5.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p1.1.m1.1.1.2.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2.2">ğ’¯</ci><ci id="S5.SS3.p1.1.m1.1.1.2.3.cmml" xref="S5.SS3.p1.1.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S5.SS3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.p1.1.m1.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS3.p1.5.2" style="font-size:90%;">.
We compare two models pretrained on the pretext task: the first uses 3.5k samples where the left and right turret LEDs have the same state, while the second uses 3.5k random samples from the same dataset;
the models are then transferred to the downstream task of pose estimation using </span><math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><msubsup id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS3.p1.2.m2.1.1.2.2" mathsize="90%" xref="S5.SS3.p1.2.m2.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS3.p1.2.m2.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS3.p1.2.m2.1.1.2.3.cmml">â„“</mi><mn id="S5.SS3.p1.2.m2.1.1.3" mathsize="90%" xref="S5.SS3.p1.2.m2.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1">superscript</csymbol><apply id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.2.1.cmml" xref="S5.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.2.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2.2">ğ’¯</ci><ci id="S5.SS3.p1.2.m2.1.1.2.3.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3">â„“</ci></apply><cn id="S5.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS3.p1.5.3" style="font-size:90%;">.
We report a median heading estimation error of </span><math class="ltx_Math" display="inline" id="S5.SS3.p1.3.m3.1"><semantics id="S5.SS3.p1.3.m3.1a"><mrow id="S5.SS3.p1.3.m3.1.1.2"><mn id="S5.SS3.p1.3.m3.1.1.2.2" mathsize="90%" xref="S5.SS3.p1.3.m3.1.1.1.cmml">45.9</mn><mo id="S5.SS3.p1.3.m3.1.1.2.1" xref="S5.SS3.p1.3.m3.1.1.1.cmml">â¢</mo><mi id="S5.SS3.p1.3.m3.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS3.p1.3.m3.1.1.1.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><cn id="S5.SS3.p1.3.m3.1.1.1.cmml" type="float" xref="S5.SS3.p1.3.m3.1.1.2.2">45.9Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S5.SS3.p1.3.m3.1c">45.9 â¢ Â°</annotation></semantics></math><span class="ltx_text" id="S5.SS3.p1.5.4" style="font-size:90%;"> for the downstream model trained with synchronized LEDs, and an error of </span><math class="ltx_Math" display="inline" id="S5.SS3.p1.4.m4.1"><semantics id="S5.SS3.p1.4.m4.1a"><mrow id="S5.SS3.p1.4.m4.1.1.2"><mn id="S5.SS3.p1.4.m4.1.1.2.2" mathsize="90%" xref="S5.SS3.p1.4.m4.1.1.1.cmml">35.7</mn><mo id="S5.SS3.p1.4.m4.1.1.2.1" xref="S5.SS3.p1.4.m4.1.1.1.cmml">â¢</mo><mi id="S5.SS3.p1.4.m4.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS3.p1.4.m4.1.1.1.cmml">Â°</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><cn id="S5.SS3.p1.4.m4.1.1.1.cmml" type="float" xref="S5.SS3.p1.4.m4.1.1.2.2">35.7Â°</cn></annotation-xml><annotation encoding="application/x-llamapun" id="S5.SS3.p1.4.m4.1c">35.7 â¢ Â°</annotation></semantics></math><span class="ltx_text" id="S5.SS3.p1.5.5" style="font-size:90%;"> for the downstream model trained with all possible LEDs combination.
Using the same statistical test as in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.SS2" style="font-size:90%;" title="V-B LED Pretext Task Transfers Well to Pose Estimation â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a><span class="ltx_text" id="S5.SS3.p1.5.6" style="font-size:90%;">, we report a statistically significant improvement on </span><math alttext="\psi" class="ltx_Math" display="inline" id="S5.SS3.p1.5.m5.1"><semantics id="S5.SS3.p1.5.m5.1a"><mi id="S5.SS3.p1.5.m5.1.1" mathsize="90%" xref="S5.SS3.p1.5.m5.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.5.m5.1b"><ci id="S5.SS3.p1.5.m5.1.1.cmml" xref="S5.SS3.p1.5.m5.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.5.m5.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.5.m5.1d">italic_Ïˆ</annotation></semantics></math><span class="ltx_text" id="S5.SS3.p1.5.7" style="font-size:90%;"> w.r.t. the synchronized LEDs pretext training, with a p-value of 0.003 obtained from four replicas of the experiment.</span></p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1"><span class="ltx_text" id="S5.SS3.p2.1.1" style="font-size:90%;">To further highlight the understating of the robotâ€™s heading achieved with the LED-based pretext training, we show in FigureÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.F4" style="font-size:90%;" title="Figure 4 â€£ V-B LED Pretext Task Transfers Well to Pose Estimation â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S5.SS3.p2.1.2" style="font-size:90%;"> the left and right LED maps when the pretext model is fed images with the robot placed on its side.
The maps for the visible LED are very consistent in its values, showing high confidence, while the maps for the invisible LED are divergent, showing uncertainty about the state; this indicates that our strategy does allow a model to capture the robotâ€™s orientation.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">LED Pretext Task is Robust to Images Without Robots</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.3"><span class="ltx_text" id="S5.SS4.p1.3.1" style="font-size:90%;">In the last panel of TableÂ </span><span class="ltx_ref ltx_missing_label ltx_ref_self" style="font-size:90%;">LABEL:tab:table</span><span class="ltx_text" id="S5.SS4.p1.3.2" style="font-size:90%;">, we report the performance of our approach when considering the entirety of </span><math alttext="\mathcal{T}_{u}^{a}" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><msubsup id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p1.1.m1.1.1.2.2" mathsize="90%" xref="S5.SS4.p1.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS4.p1.1.m1.1.1.2.3" mathsize="90%" xref="S5.SS4.p1.1.m1.1.1.2.3.cmml">u</mi><mi id="S5.SS4.p1.1.m1.1.1.3" mathsize="90%" xref="S5.SS4.p1.1.m1.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">superscript</csymbol><apply id="S5.SS4.p1.1.m1.1.1.2.cmml" xref="S5.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.1.m1.1.1.2.1.cmml" xref="S5.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.p1.1.m1.1.1.2.2.cmml" xref="S5.SS4.p1.1.m1.1.1.2.2">ğ’¯</ci><ci id="S5.SS4.p1.1.m1.1.1.2.3.cmml" xref="S5.SS4.p1.1.m1.1.1.2.3">ğ‘¢</ci></apply><ci id="S5.SS4.p1.1.m1.1.1.3.cmml" xref="S5.SS4.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\mathcal{T}_{u}^{a}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p1.3.3" style="font-size:90%;">, which features the robot visible only for 22% of images, based on trajectories of the random controller described in SectionÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S4.SS1" style="font-size:90%;" title="IV-A Dataset â€£ IV Experimental Setup â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a><span class="ltx_text" id="S5.SS4.p1.3.4" style="font-size:90%;">.
The median </span><math alttext="uv" class="ltx_Math" display="inline" id="S5.SS4.p1.2.m2.1"><semantics id="S5.SS4.p1.2.m2.1a"><mrow id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml"><mi id="S5.SS4.p1.2.m2.1.1.2" mathsize="90%" xref="S5.SS4.p1.2.m2.1.1.2.cmml">u</mi><mo id="S5.SS4.p1.2.m2.1.1.1" xref="S5.SS4.p1.2.m2.1.1.1.cmml">â¢</mo><mi id="S5.SS4.p1.2.m2.1.1.3" mathsize="90%" xref="S5.SS4.p1.2.m2.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.1b"><apply id="S5.SS4.p1.2.m2.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1"><times id="S5.SS4.p1.2.m2.1.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1.1"></times><ci id="S5.SS4.p1.2.m2.1.1.2.cmml" xref="S5.SS4.p1.2.m2.1.1.2">ğ‘¢</ci><ci id="S5.SS4.p1.2.m2.1.1.3.cmml" xref="S5.SS4.p1.2.m2.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.1c">uv</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.m2.1d">italic_u italic_v</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p1.3.5" style="font-size:90%;"> error of the pretext and downstream models are in line with their counterparts trained using only images with visible robot of </span><math alttext="\mathcal{T}_{u}^{\nu}" class="ltx_Math" display="inline" id="S5.SS4.p1.3.m3.1"><semantics id="S5.SS4.p1.3.m3.1a"><msubsup id="S5.SS4.p1.3.m3.1.1" xref="S5.SS4.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p1.3.m3.1.1.2.2" mathsize="90%" xref="S5.SS4.p1.3.m3.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS4.p1.3.m3.1.1.2.3" mathsize="90%" xref="S5.SS4.p1.3.m3.1.1.2.3.cmml">u</mi><mi id="S5.SS4.p1.3.m3.1.1.3" mathsize="90%" xref="S5.SS4.p1.3.m3.1.1.3.cmml">Î½</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.3.m3.1b"><apply id="S5.SS4.p1.3.m3.1.1.cmml" xref="S5.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.3.m3.1.1.1.cmml" xref="S5.SS4.p1.3.m3.1.1">superscript</csymbol><apply id="S5.SS4.p1.3.m3.1.1.2.cmml" xref="S5.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.3.m3.1.1.2.1.cmml" xref="S5.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS4.p1.3.m3.1.1.2.2.cmml" xref="S5.SS4.p1.3.m3.1.1.2.2">ğ’¯</ci><ci id="S5.SS4.p1.3.m3.1.1.2.3.cmml" xref="S5.SS4.p1.3.m3.1.1.2.3">ğ‘¢</ci></apply><ci id="S5.SS4.p1.3.m3.1.1.3.cmml" xref="S5.SS4.p1.3.m3.1.1.3">ğœˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.3.m3.1c">\mathcal{T}_{u}^{\nu}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Î½ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p1.3.6" style="font-size:90%;">, highlighting the strength of this simple approach when applied to collected data without any filtering.
The robot heading and distance estimation suffer from training with a large quantity of images with no robot visible, degrading the performance of downstream models.</span></p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.5"><span class="ltx_text" id="S5.SS4.p2.5.1" style="font-size:90%;">The notable exception is the downstream-</span><math alttext="a" class="ltx_Math" display="inline" id="S5.SS4.p2.1.m1.1"><semantics id="S5.SS4.p2.1.m1.1a"><mi id="S5.SS4.p2.1.m1.1.1" mathsize="90%" xref="S5.SS4.p2.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.1b"><ci id="S5.SS4.p2.1.m1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.1.m1.1d">italic_a</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p2.5.2" style="font-size:90%;">-10 model, which shows large instability during training and has a higher error than the downstream-10 model, at 76 pixels.
The cause is the different </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S5.SS4.p2.2.m2.1"><semantics id="S5.SS4.p2.2.m2.1a"><mover accent="true" id="S5.SS4.p2.2.m2.1.1" xref="S5.SS4.p2.2.m2.1.1.cmml"><mi id="S5.SS4.p2.2.m2.1.1.2" mathsize="90%" xref="S5.SS4.p2.2.m2.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S5.SS4.p2.2.m2.1.1.1" mathsize="90%" mathvariant="bold" xref="S5.SS4.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.2.m2.1b"><apply id="S5.SS4.p2.2.m2.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1"><ci id="S5.SS4.p2.2.m2.1.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1.1">bold-^</ci><ci id="S5.SS4.p2.2.m2.1.1.2.cmml" xref="S5.SS4.p2.2.m2.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.2.m2.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.2.m2.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p2.5.3" style="font-size:90%;"> mapâ€™s behavior in the pretext and downstream models:
in the former case, the </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S5.SS4.p2.3.m3.1"><semantics id="S5.SS4.p2.3.m3.1a"><mover accent="true" id="S5.SS4.p2.3.m3.1.1" xref="S5.SS4.p2.3.m3.1.1.cmml"><mi id="S5.SS4.p2.3.m3.1.1.2" mathsize="90%" xref="S5.SS4.p2.3.m3.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S5.SS4.p2.3.m3.1.1.1" mathsize="90%" mathvariant="bold" xref="S5.SS4.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.3.m3.1b"><apply id="S5.SS4.p2.3.m3.1.1.cmml" xref="S5.SS4.p2.3.m3.1.1"><ci id="S5.SS4.p2.3.m3.1.1.1.cmml" xref="S5.SS4.p2.3.m3.1.1.1">bold-^</ci><ci id="S5.SS4.p2.3.m3.1.1.2.cmml" xref="S5.SS4.p2.3.m3.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.3.m3.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.3.m3.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p2.5.4" style="font-size:90%;"> map activates over a large area around the center of the robot; in the latter, the activations are more punctual and centered on the robotâ€™s body.
By fine-tuning the model on the downstream task, the position map </span><math alttext="\bm{\hat{P}}" class="ltx_Math" display="inline" id="S5.SS4.p2.4.m4.1"><semantics id="S5.SS4.p2.4.m4.1a"><mover accent="true" id="S5.SS4.p2.4.m4.1.1" xref="S5.SS4.p2.4.m4.1.1.cmml"><mi id="S5.SS4.p2.4.m4.1.1.2" mathsize="90%" xref="S5.SS4.p2.4.m4.1.1.2.cmml">ğ‘·</mi><mo class="ltx_mathvariant_bold" id="S5.SS4.p2.4.m4.1.1.1" mathsize="90%" mathvariant="bold" xref="S5.SS4.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.4.m4.1b"><apply id="S5.SS4.p2.4.m4.1.1.cmml" xref="S5.SS4.p2.4.m4.1.1"><ci id="S5.SS4.p2.4.m4.1.1.1.cmml" xref="S5.SS4.p2.4.m4.1.1.1">bold-^</ci><ci id="S5.SS4.p2.4.m4.1.1.2.cmml" xref="S5.SS4.p2.4.m4.1.1.2">ğ‘·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.4.m4.1c">\bm{\hat{P}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.4.m4.1d">overbold_^ start_ARG bold_italic_P end_ARG</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p2.5.5" style="font-size:90%;"> transitions from a coarser and broader response to a more punctual one.
Transferring the modelâ€™s skills from the pretext to the downstream pose task using only the 10 samples contained in </span><math alttext="\mathcal{T}_{\ell}^{10}" class="ltx_Math" display="inline" id="S5.SS4.p2.5.m5.1"><semantics id="S5.SS4.p2.5.m5.1a"><msubsup id="S5.SS4.p2.5.m5.1.1" xref="S5.SS4.p2.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS4.p2.5.m5.1.1.2.2" mathsize="90%" xref="S5.SS4.p2.5.m5.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS4.p2.5.m5.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS4.p2.5.m5.1.1.2.3.cmml">â„“</mi><mn id="S5.SS4.p2.5.m5.1.1.3" mathsize="90%" xref="S5.SS4.p2.5.m5.1.1.3.cmml">10</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.5.m5.1b"><apply id="S5.SS4.p2.5.m5.1.1.cmml" xref="S5.SS4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS4.p2.5.m5.1.1.1.cmml" xref="S5.SS4.p2.5.m5.1.1">superscript</csymbol><apply id="S5.SS4.p2.5.m5.1.1.2.cmml" xref="S5.SS4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS4.p2.5.m5.1.1.2.1.cmml" xref="S5.SS4.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS4.p2.5.m5.1.1.2.2.cmml" xref="S5.SS4.p2.5.m5.1.1.2.2">ğ’¯</ci><ci id="S5.SS4.p2.5.m5.1.1.2.3.cmml" xref="S5.SS4.p2.5.m5.1.1.2.3">â„“</ci></apply><cn id="S5.SS4.p2.5.m5.1.1.3.cmml" type="integer" xref="S5.SS4.p2.5.m5.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.5.m5.1c">\mathcal{T}_{\ell}^{10}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p2.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS4.p2.5.6" style="font-size:90%;"> is not enough to correctly drive the optimization, whereas more samples are enough.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS5.5.1.1">V-E</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS5.6.2">LED Pretext Task Generalizes to Unseen Environments</span>
</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1"><span class="ltx_text" id="S5.SS5.p1.1.1" style="font-size:90%;">To test the generalization ability of our approach and the effect of the LEDsâ€™ state on pose estimation, we show in FigureÂ </span><a class="ltx_ref" href="https://arxiv.org/html/2407.10661v2#S5.F5" style="font-size:90%;" title="Figure 5 â€£ V-B LED Pretext Task Transfers Well to Pose Estimation â€£ V Results â€£ Learning to Estimate the Pose of a Peer Robot in a Camera Image by Predicting the States of its LEDs"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S5.SS5.p1.1.2" style="font-size:90%;"> the prediction of the downstream model trained with </span><math alttext="\mathcal{T}_{\ell}^{1000}" class="ltx_Math" display="inline" id="S5.SS5.p1.1.m1.1"><semantics id="S5.SS5.p1.1.m1.1a"><msubsup id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS5.p1.1.m1.1.1.2.2" mathsize="90%" xref="S5.SS5.p1.1.m1.1.1.2.2.cmml">ğ’¯</mi><mi id="S5.SS5.p1.1.m1.1.1.2.3" mathsize="90%" mathvariant="normal" xref="S5.SS5.p1.1.m1.1.1.2.3.cmml">â„“</mi><mn id="S5.SS5.p1.1.m1.1.1.3" mathsize="90%" xref="S5.SS5.p1.1.m1.1.1.3.cmml">1000</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><apply id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS5.p1.1.m1.1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1">superscript</csymbol><apply id="S5.SS5.p1.1.m1.1.1.2.cmml" xref="S5.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS5.p1.1.m1.1.1.2.1.cmml" xref="S5.SS5.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS5.p1.1.m1.1.1.2.2.cmml" xref="S5.SS5.p1.1.m1.1.1.2.2">ğ’¯</ci><ci id="S5.SS5.p1.1.m1.1.1.2.3.cmml" xref="S5.SS5.p1.1.m1.1.1.2.3">â„“</ci></apply><cn id="S5.SS5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS5.p1.1.m1.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">\mathcal{T}_{\ell}^{1000}</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.1.m1.1d">caligraphic_T start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1000 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S5.SS5.p1.1.3" style="font-size:90%;"> on data collected in never-seen-before environments.
Despite the different visual appearance of environments, the model correctly predicts the robot pose. The environments highlight the increase in difficulty when estimating the robotâ€™s distance and heading, which show larger errors than image-space detection.
Failure cases occur when the robot is further away than the maximum of 5 meters of the training set and when it is partially visible in the field of view.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusions</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text" id="S6.p1.1.1" style="font-size:90%;">We presented a self-supervised learning approach for peer-to-peer robot pose estimation, leveraging robot LEDs to define a pretext task in order to learn useful features for pose estimation.
By predicting the state of LEDs from a given image, our approach improves in the estimation ability when compared to a baseline trained using the same amount of labeled data.</span></p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text" id="S6.p2.1.1" style="font-size:90%;">Results show that the approach is able to capture the 3D position and heading of ground robots, even when trained on images that feature the robot visible only 22% of the times.
It also shows good generalization ability to never-seen-before environments.</span></p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text" id="S6.p3.1.1" style="font-size:90%;">Interestingly, our FCN model trained on the LED pretext using the attention-like mechanism has led the model to learning robot localization in images without using ground truth pose labels with a fair accuracy.
Future work will focus on exploring pose estimation without ground truth labels, improving the presented results in terms of performance, and integrating additional supervision sources.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
M.Â Dorigo, G.Â Theraulaz, and V.Â Trianni, â€œSwarm robotics: Past, present, and future,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib1.2.2" style="font-size:90%;">IEEE Point of View</em><span class="ltx_text" id="bib.bib1.3.3" style="font-size:90%;">, vol. 109, no.Â 7, pp. 1152â€“1165, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
M.Â Vrba, D.Â HeÅ™t, and M.Â Saska, â€œOnboard marker-less detection and localization of non-cooperating drones for their safe interception by an autonomous aerial system,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib2.2.2" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span class="ltx_text" id="bib.bib2.3.3" style="font-size:90%;">, vol.Â 4, no.Â 4, pp. 3402â€“3409, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
B.Â Mishra, D.Â Garg, P.Â Narang, and V.Â Mishra, â€œDrone-surveillance for search and rescue in natural disaster,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2" style="font-size:90%;">Elsevier Computer Communications</em><span class="ltx_text" id="bib.bib3.3.3" style="font-size:90%;">, vol. 156, pp. 1â€“10, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
K.Â McGuire, C.Â DeÂ Wagter, K.Â Tuyls, H.Â Kappen, and G.Â C. deÂ Croon, â€œMinimal navigation solution for a swarm of tiny flying robots to explore an unknown environment,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2" style="font-size:90%;">Science Robotics</em><span class="ltx_text" id="bib.bib4.3.3" style="font-size:90%;">, vol.Â 4, no.Â 35, p. eaaw9710, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
L.Â A. Nguyen, T.Â L. Harman, and C.Â Fairchild, â€œSwarmathon: a swarm robotics experiment for future space exploration,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib5.2.2" style="font-size:90%;">IEEE International Symposium on Measurement and Control in Robotics</em><span class="ltx_text" id="bib.bib5.3.3" style="font-size:90%;">, 2019, pp. B1â€“3.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
D.Â Dias, R.Â Ventura, P.Â Lima, and A.Â Martinoli, â€œOn-board vision-based 3d relative localization system for multiple quadrotors,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2" style="font-size:90%;">IEEE International Conference on Robotics and Automation</em><span class="ltx_text" id="bib.bib6.3.3" style="font-size:90%;">, 2016, pp. 1181â€“1187.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
G.Â VÃ¡sÃ¡rhelyi, C.Â VirÃ¡gh, G.Â Somorjai, T.Â Nepusz, A.Â E. Eiben, and T.Â Vicsek, â€œOptimized flocking of autonomous drones in confined environments,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.2.2" style="font-size:90%;">Science Robotics</em><span class="ltx_text" id="bib.bib7.3.3" style="font-size:90%;">, vol.Â 3, no.Â 20, p. eaat3536, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
K.-C. Weng, S.-T. Lin, C.-C. Hu, R.-T. Soong, and M.-T. Chi, â€œMulti-view approach for drone light show,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib8.2.2" style="font-size:90%;">Springer The Visual Computer</em><span class="ltx_text" id="bib.bib8.3.3" style="font-size:90%;">, vol.Â 39, no.Â 11, pp. 5797â€“5808, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
L.Â Jing and Y.Â Tian, â€œSelf-supervised visual feature learning with deep neural networks: A survey,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.2.2" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span class="ltx_text" id="bib.bib9.3.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
M.Â Nava, N.Â Carlotti, L.Â Crupi, D.Â Palossi, and A.Â Giusti, â€œSelf-supervised learning of visual robot localization using led state prediction as a pretext task,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib10.2.2" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span class="ltx_text" id="bib.bib10.3.3" style="font-size:90%;">, vol.Â 9, no.Â 4, pp. 3363â€“3370, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
J.Â Long, E.Â Shelhamer, and T.Â Darrell, â€œFully convolutional networks for semantic segmentation,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib11.2.2" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib11.3.3" style="font-size:90%;">, 2015, pp. 3431â€“3440.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
D.Â Zhang, J.Â Han, G.Â Cheng, and M.-H. Yang, â€œWeakly Supervised Object Localization and Detection: A Survey,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib12.2.2" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span class="ltx_text" id="bib.bib12.3.3" style="font-size:90%;">, vol.Â 44, pp. 5866â€“5885, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
A.Â Radford, J.Â W. Kim, C.Â Hallacy, A.Â Ramesh, G.Â Goh, S.Â Agarwal, G.Â Sastry, A.Â Askell, P.Â Mishkin, J.Â Clark, </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.2.2" style="font-size:90%;">etÂ al.</em><span class="ltx_text" id="bib.bib13.3.3" style="font-size:90%;">, â€œLearning transferable visual models from natural language supervision,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.4.4" style="font-size:90%;">PMLR International Conference on Machine Learning</em><span class="ltx_text" id="bib.bib13.5.5" style="font-size:90%;">, 2021, pp. 8748â€“8763.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
M.Â Saska, T.Â Baca, J.Â Thomas, J.Â Chudoba, L.Â Preucil, T.Â Krajnik, J.Â Faigl, G.Â Loianno, and V.Â Kumar, â€œSystem for deployment of groups of unmanned micro aerial vehicles in gps-denied environments using onboard visual relative localization,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2" style="font-size:90%;">Springer Autonomous Robots</em><span class="ltx_text" id="bib.bib14.3.3" style="font-size:90%;">, vol.Â 41, no.Â 4, pp. 919â€“944, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
H.Â Yu, Q.Â Fu, Z.Â Yang, L.Â Tan, W.Â Sun, and M.Â Sun, â€œRobust robot pose estimation for challenging scenes with an rgb-d camera,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib15.2.2" style="font-size:90%;">IEEE Sensors Journal</em><span class="ltx_text" id="bib.bib15.3.3" style="font-size:90%;">, vol.Â 19, no.Â 6, pp. 2217â€“2229, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
T.Â E. Lee, J.Â Tremblay, T.Â To, J.Â Cheng, T.Â Mosier, O.Â Kroemer, D.Â Fox, and S.Â Birchfield, â€œCamera-to-Robot Pose Estimation from a Single Image,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.2.2" style="font-size:90%;">IEEE International Conference on Robotics and Automation</em><span class="ltx_text" id="bib.bib16.3.3" style="font-size:90%;">, 2020, pp. 9426â€“9432.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
J.Â Lu, F.Â Richter, and M.Â C. Yip, â€œPose Estimation for Robot Manipulators via Keypoint Optimization and Sim-to-Real Transfer,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib17.2.2" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span class="ltx_text" id="bib.bib17.3.3" style="font-size:90%;">, vol.Â 7, pp. 4622â€“4629, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
E.Â Jang, C.Â Devin, V.Â Vanhoucke, and S.Â Levine, â€œGrasp2vec: Learning object representations from self-supervised grasping,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib18.2.2" style="font-size:90%;">PMLR Conference on Robot Learning</em><span class="ltx_text" id="bib.bib18.3.3" style="font-size:90%;">, 2018, pp. 99â€“112.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
X.Â Deng, Y.Â Xiang, A.Â Mousavian, C.Â Eppner, T.Â Bretl, and D.Â Fox, â€œSelf-supervised 6d object pose estimation for robot manipulation,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib19.2.2" style="font-size:90%;">IEEE International Conference on Robotics and Automation</em><span class="ltx_text" id="bib.bib19.3.3" style="font-size:90%;">, 2020, pp. 3665â€“3671.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
S.Â Li, C.Â DeÂ Wagter, and G.Â C. DeÂ Croon, â€œSelf-supervised monocular multi-robot relative localization with efficient deep neural networks,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib20.2.2" style="font-size:90%;">IEEE International Conference on Robotics and Automation</em><span class="ltx_text" id="bib.bib20.3.3" style="font-size:90%;">, 2022, pp. 9689â€“9695.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
I.Â Radosavovic, T.Â Xiao, S.Â James, P.Â Abbeel, J.Â Malik, and T.Â Darrell, â€œReal-world robot learning with masked visual pre-training,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib21.2.2" style="font-size:90%;">PMLR Conference on Robot Learning</em><span class="ltx_text" id="bib.bib21.3.3" style="font-size:90%;">, 2023, pp. 416â€“426.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
M.Â Nava, A.Â Paolillo, J.Â Guzzi, L.Â M. Gambardella, and A.Â Giusti, â€œLearning visual localization of a quadrotor using its noise as self-supervision,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.2.2" style="font-size:90%;">IEEE Robotics and Automation Letters</em><span class="ltx_text" id="bib.bib22.3.3" style="font-size:90%;">, vol.Â 7, no.Â 2, pp. 2218â€“2225, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
M.Â Zhang, Y.Â Zhou, J.Â Zhao, Y.Â Man, B.Â Liu, and R.Â Yao, â€œA survey of semi-and weakly supervised semantic segmentation of images,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib23.2.2" style="font-size:90%;">Springer Artificial Intelligence Review</em><span class="ltx_text" id="bib.bib23.3.3" style="font-size:90%;">, vol.Â 53, pp. 4259â€“4288, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
S.Â Woo, J.Â Park, J.-Y. Lee, and I.Â S. Kweon, â€œCbam: Convolutional block attention module,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib24.2.2" style="font-size:90%;">European Conference on Computer Vision</em><span class="ltx_text" id="bib.bib24.3.3" style="font-size:90%;">, 2018, pp. 3â€“19.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
A.Â Dosovitskiy, L.Â Beyer, A.Â Kolesnikov, D.Â Weissenborn, X.Â Zhai, T.Â Unterthiner, M.Â Dehghani, M.Â Minderer, G.Â Heigold, S.Â Gelly, </span><em class="ltx_emph ltx_font_italic" id="bib.bib25.2.2" style="font-size:90%;">etÂ al.</em><span class="ltx_text" id="bib.bib25.3.3" style="font-size:90%;">, â€œAn image is worth 16x16 words: Transformers for image recognition at scale,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib25.4.4" style="font-size:90%;">International Conference on Learning Representations, Virtual Event</em><span class="ltx_text" id="bib.bib25.5.5" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
N.Â Pourian, S.Â Karthikeyan, and B.Â S. Manjunath, â€œWeakly supervised graph based semantic segmentation by learning communities of image-parts,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib26.2.2" style="font-size:90%;">IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib26.3.3" style="font-size:90%;">, 2015, pp. 1359â€“1367.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
B.Â Zhou, A.Â Khosla, A.Â Lapedriza, A.Â Oliva, and A.Â Torralba, â€œLearning deep features for discriminative localization,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib27.3.3" style="font-size:90%;">, 2016, pp. 2921â€“2929.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
H.Â G. Ramaswamy </span><em class="ltx_emph ltx_font_italic" id="bib.bib28.2.2" style="font-size:90%;">etÂ al.</em><span class="ltx_text" id="bib.bib28.3.3" style="font-size:90%;">, â€œAblation-cam: Visual explanations for deep convolutional network via gradient-free localization,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib28.4.4" style="font-size:90%;">IEEE/CVF Winter conference on applications of computer vision</em><span class="ltx_text" id="bib.bib28.5.5" style="font-size:90%;">, 2020, pp. 983â€“991.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.1.1" style="font-size:90%;">
H.Â Bilen and A.Â Vedaldi, â€œWeakly supervised deep detection networks,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib29.2.2" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib29.3.3" style="font-size:90%;">, 2016, pp. 2846â€“2854.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.1.1" style="font-size:90%;">
D.Â Pathak, P.Â Krahenbuhl, and T.Â Darrell, â€œConstrained convolutional neural networks for weakly supervised segmentation,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib30.2.2" style="font-size:90%;">IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib30.3.3" style="font-size:90%;">, 2015, pp. 1796â€“1804.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.1.1" style="font-size:90%;">
Z.Â Ma, M.Â Yuan, J.Â Gu, W.Â Meng, S.Â Xu, and X.Â Zhang, â€œTriple-strip attention mechanism-based natural disaster images classification and segmentation,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib31.2.2" style="font-size:90%;">Springer The Visual Computer</em><span class="ltx_text" id="bib.bib31.3.3" style="font-size:90%;">, vol.Â 38, no.Â 9, pp. 3163â€“3173, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.1.1" style="font-size:90%;">
Y.Â Liang, Z.Â Chen, D.Â Lin, J.Â Tan, Z.Â Yang, J.Â Li, and X.Â Li, â€œThree-dimension attention mechanism and self-supervised pretext task for augmenting few-shot learning,â€ </span><em class="ltx_emph ltx_font_italic" id="bib.bib32.2.2" style="font-size:90%;">IEEE Access</em><span class="ltx_text" id="bib.bib32.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.1.1" style="font-size:90%;">
S.Â Gupta, S.Â Lakhotia, A.Â Rawat, and R.Â Tallamraju, â€œVitol: Vision transformer for weakly supervised object localization,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib33.2.2" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib33.3.3" style="font-size:90%;">, 2022, pp. 4101â€“4110.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.1.1" style="font-size:90%;">
M.Â Sandler, A.Â Howard, M.Â Zhu, A.Â Zhmoginov, and L.-C. Chen, â€œMobilenetv2: Inverted residuals and linear bottlenecks,â€ in </span><em class="ltx_emph ltx_font_italic" id="bib.bib34.2.2" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib34.3.3" style="font-size:90%;">, 2018, pp. 4510â€“4520.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 25 07:53:44 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
