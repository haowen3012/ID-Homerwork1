<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>GearTrack: Automating 6D Pose Estimation</title>
<!--Generated on Mon Sep 30 06:19:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="6D Pose Estimation,  Industrial Automation,  SAM2,  LightGlue,  Object Tracking" lang="en" name="keywords"/>
<base href="/html/2409.19986v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S1" title="In GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S2" title="In GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S2.SS1" title="In 2 Related Work ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>CAD Model-Based Object Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S2.SS2" title="In 2 Related Work ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Instance Segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S2.SS3" title="In 2 Related Work ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Feature Point Matching</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3" title="In GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proposed Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.SS1" title="In 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Integration and Testing of Methods</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.SS1.SSS1" title="In 3.1 Integration and Testing of Methods ‣ 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Initial Target Identification via Manual Selection or Pure Image Input</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.SS1.SSS2" title="In 3.1 Integration and Testing of Methods ‣ 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Segmentation Prompt Generation Based on User Input or Feature Matching</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.SS1.SSS3" title="In 3.1 Integration and Testing of Methods ‣ 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>6D Pose Estimation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.SS2" title="In 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Handling Tracking Loss in FoundationPose</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.SS3" title="In 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Addressing Long-Term Object Loss: A Memory Mechanism</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S4" title="In GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S4.SS1" title="In 4 Experiment ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Deployment and Evaluation of FoundationPose</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S4.SS1.SSS1" title="In 4.1 Deployment and Evaluation of FoundationPose ‣ 4 Experiment ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>CNOS and CNOS+FoundationPose</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S4.SS1.SSS2" title="In 4.1 Deployment and Evaluation of FoundationPose ‣ 4 Experiment ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>PerSAM and PerSAM+FoundationPose</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S4.SS1.SSS3" title="In 4.1 Deployment and Evaluation of FoundationPose ‣ 4 Experiment ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>SAM2 and SAM2+FoundationPose</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5" title="In GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Result</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.SS1" title="In 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Runtime of each model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.SS2" title="In 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>IoU of each Segmentation model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.SS3" title="In 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>ADD of FoundationPose with different Segmentation model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S6" title="In GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">GearTrack: Automating 6D Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yu Deng
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Teng Cao
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiahong Xue
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">We developed a robust solution for real-time 6D object detection in industrial applications by integrating FoundationPose, SAM2, and LightGlue, eliminating the need for retraining. Our approach addresses two key challenges: the requirement for an initial object mask in the first frame in FoundationPose and issues with tracking loss and automatic rotation for symmetric objects.
The algorithm requires only a CAD model of the target object, with the user clicking on its location in the live feed during the initial setup. Once set, the algorithm automatically saves a reference image of the object and, in subsequent runs, employs LightGlue for feature matching between the object and the real-time scene, providing an initial prompt for detection. Tested on the YCB dataset and industrial components such as bleach cleanser and gears, the algorithm demonstrated reliable 6D detection and tracking.
By integrating SAM2 and FoundationPose, we effectively mitigated common limitations such as the problem of tracking loss, ensuring continuous and accurate tracking under challenging conditions like occlusion or rapid movement.</p>
</div>
<div class="ltx_keywords">6D Pose Estimation, Industrial Automation, SAM2, LightGlue, Object Tracking
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break"/>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Estimating the rigid 6D transformation between an object and the camera, also referred to as object pose estimation, is a critical task in various domains such as robotic manipulation <cite class="ltx_cite ltx_citemacro_citep">(Kappler et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib9" title="">2018</a>; Wen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib37" title="">2022a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib38" title="">b</a>)</cite> and mixed reality <cite class="ltx_cite ltx_citemacro_citep">(Marchand et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib17" title="">2015</a>)</cite>. Traditional methods <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib7" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib8" title="">2021</a>; Labbé et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib11" title="">2020</a>; Park et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib20" title="">2019</a>; Wen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib36" title="">2020</a>)</cite> are typically instance-level, meaning they only function with specific object instances defined during training.
These instance-level approaches usually require a textured CAD model for generating training data and are not applicable to novel, unseen objects at test time. In contrast, category-level methods <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib2" title="">2020</a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib13" title="">2023</a>; Tian et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib30" title="">2020</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib35" title="">2019</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib43" title="">2022</a>)</cite> do not require CAD models but are constrained to objects within predefined categories from the training phase.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To overcome the limitations of both approaches, FoundationPose <cite class="ltx_cite ltx_citemacro_citep">(Wen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib39" title="">2024</a>)</cite> offers a hybrid solution capable of robust 6D pose estimation using both model-based and model-free techniques. However, FoundationPose requires a manually annotated mask of the object in the first frame, a process that is tedious and impractical for automated pipelines. Automating the mask annotation step or minimizing user interaction would significantly enhance its applicability in real-time settings.
To address this limitation, we incorporated a segmentation algorithm, enabling users to perform live, image, and video-based pose estimation by providing only a CAD model. Additionally, this segmentation approach resolves issues related to tracking loss.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Our aim is to streamline the entire process, requiring users to provide only a CAD model. As such, the input to the segmentation process must also be derived from the CAD model. We conducted extensive experiments on CNOS <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib19" title="">2023</a>)</cite> and PerSAM <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib44" title="">2023</a>)</cite>, but both algorithms exhibited shortcomings. While CNOS meets the CAD model requirement, its performance lacks consistency, particularly when the CAD model is imprecise, leading to significant loss of edge information in the final segmentation.
PerSAM, on the other hand, demands a reference image and mask file, making it highly sensitive to variations in angle and occlusions, as it relies on cosine similarity to compare the reference and test images.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Ultimately, we found that SAM2 <cite class="ltx_cite ltx_citemacro_citep">(Ravi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib23" title="">2024</a>)</cite> provided superior results. By simply clicking on the location of the object in the test image, the algorithm automatically generates a segmentation and a ‘pure’ image based on the user-specified object. For future runs, only the CAD model is needed, and the system leverages LightGlue <cite class="ltx_cite ltx_citemacro_citep">(Lindenberger et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib15" title="">2023</a>)</cite> to match feature points between the ‘pure’ image and the first frame of the live video or image.
These matched points serve as location prompts for SAM2, enabling fully automated object tracking and segmentation without any additional user input. This approach not only addresses the mask annotation challenge but also facilitates a fully automated workflow for object pose estimation.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="265" id="S1.F1.g1" src="extracted/5870539/Images/workflow.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1">System workflow</span> The image shows the implementation process of the entire system. In our system, the object’s positional information within the real image is initially obtained either through user clicks or by employing LightGlue to perform feature matching between the pure image and the real image, thus providing a positional prompt.
This information is then transmitted to SAM2. If a pure image of the object does not exist, one is generated and stored in memory. Simultaneously, a mask matrix for the object is created. Subsequently, by integrating the generated mask, the object’s CAD model, and the real frame, FoundationPose is ultimately utilized to perform 6D pose estimation.</figcaption>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">As shown in Figure 1, we only need to provide a CAD model and click on the target we want to recognize during the first use or provide a pure image of the target. The system can then automatically complete the entire 6D pose estimation without any other operations.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We also tackled the problem of tracking loss in FoundationPose by incorporating a method that calculates the distance between centroids during 6D pose detection and segmentation.
SAM2’s introduction of a memory module significantly enhances tracking performance, as demonstrated in our tests. Even if an object temporarily disappears from the scene and reappears, SAM2 is capable of effectively re-establishing the track.
Despite this, SAM2 exhibits limitations when the object remains absent for an extended period, which can hinder its ability to regain detection and tracking. To mitigate this limitation, we employed feature point matching, allowing the system to re-identify the object and continue tracking reliably after prolonged absences.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Our main contributions are summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p8">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">A novel 6D object pose estimation system without manual mask annotation:</span> We introduce a system that requires only a single click and a CAD model for initialization, eliminating the need for labor-intensive mask annotations.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Live and stable pose estimation from images and videos:</span> Our approach enables efficient, live and stable estimation of object poses from both image and video data, enhancing applicability in dynamic environments.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Addressing key challenges for continuous and accurate tracking:</span> The system tackles critical issues such as pose re-registration and automatic orientation correction for symmetric objects, ensuring continuous and precise tracking over time.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>CAD Model-Based Object Pose Estimation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The first category of methods is instance-level pose estimation approaches <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib7" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib8" title="">2021</a>; Labbé et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib11" title="">2020</a>; Park et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib20" title="">2019</a>)</cite>, which assume that a textured CAD model of the object is available. These methods are trained and tested on the exact same object instance. Pose estimation can be performed through direct regression <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib14" title="">2019</a>; Xiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib40" title="">2017</a>)</cite> or by leveraging Perspective-n-Point (PnP) algorithms <cite class="ltx_cite ltx_citemacro_citep">(Park et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib20" title="">2019</a>; Tremblay et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib32" title="">2018</a>)</cite>, which construct 2D-3D correspondences. Additionally, 3D-3D correspondences can be used to solve the object pose through least-squares fitting techniques <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib7" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib8" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">In contrast, category-level methods <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib2" title="">2020</a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib13" title="">2023</a>; Tian et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib30" title="">2020</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib35" title="">2019</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib43" title="">2022</a>)</cite> enable pose estimation for novel objects within the same category. However, these methods are limited to predefined categories and cannot generalize to arbitrary objects outside of these categories.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">A third approach <cite class="ltx_cite ltx_citemacro_citep">(Labbé et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib12" title="">2022</a>; Shugurov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib28" title="">2022</a>)</cite> aims to estimate the pose of non-predefined objects by using only a CAD model and a mask of the object in the first frame. FoundationPose is a representative example of this category. It uses a synthetic dataset generated with the help of large language models (LLMs) and employs a Transformer-based network architecture combined with contrastive learning, achieving state-of-the-art results on datasets such as YCB.
However, FoundationPose<cite class="ltx_cite ltx_citemacro_citep">(Wen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib39" title="">2024</a>)</cite> does not provide a built-in tool for mask generation, often requiring manual annotation. Additionally, it lacks the capability for real-time pose estimation, and tracking loss can occur when the object moves rapidly or becomes occluded.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Instance Segmentation</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Most instance-level segmentation algorithms <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib6" title="">2017</a>; Yurtkulu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib42" title="">2019</a>)</cite> require fine-tuning when applied to specific datasets, such as gears or objects outside predefined categories. This process can result in significant redundancy and demand substantial human and computational resources.
Typically, it involves collecting a new dataset tailored to the segmentation task, annotating it, and retraining the model while monitoring for convergence.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Recently, with the introduction of the Segment Anything Model (SAM) <cite class="ltx_cite ltx_citemacro_citep">(Kirillov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib10" title="">2023</a>)</cite>, several train-free algorithms have emerged, including PerSAM <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib44" title="">2023</a>)</cite> and CNOS <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib19" title="">2023</a>)</cite>. PerSAM utilizes cosine similarity between a reference image, processed through the SAM algorithm, and a test image to perform segmentation.
CNOS, given a CAD file, generates images from various angles and uses them as inputs to the SAM algorithm for segmentation. However, both methods have notable limitations. PerSAM is highly sensitive to variations in the object’s angle and still requires additional data, such as a mask, for initialization. CNOS, while effective in theory, is particularly sensitive to the CAD file; if the texture and details of the CAD model significantly differ from the real object, the segmentation process may fail.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">A newly introduced algorithm, SAM2 <cite class="ltx_cite ltx_citemacro_citep">(Ravi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib23" title="">2024</a>)</cite>, offers improvements through its memory mechanism, allowing for instance segmentation and real-time tracking with minimal input, such as a prompt. SAM2 is capable of re-tracking an object even after temporary disappearance, provided it reappears within a short timeframe, making it a more robust solution for real-time applications.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Feature Point Matching</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Traditional image matching algorithms rely on hand-crafted criteria and gradient statistics <cite class="ltx_cite ltx_citemacro_citep">(Lowe, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib16" title="">2004</a>; Harris et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib5" title="">1988</a>; Bay et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib1" title="">2006</a>; Rosten &amp; Drummond, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib25" title="">2006</a>)</cite>. In recent years, however, much research has shifted toward using Convolutional Neural Networks (CNNs) for feature detection <cite class="ltx_cite ltx_citemacro_citep">(Yi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib41" title="">2016</a>; DeTone et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib3" title="">2018</a>; Dusmanu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib4" title="">2019</a>; Revaud et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib24" title="">2019</a>; Tyszkiewicz et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib33" title="">2020</a>)</cite> and description <cite class="ltx_cite ltx_citemacro_citep">(Mishchuk et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib18" title="">2017</a>; Tian et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib31" title="">2019</a>)</cite>.
CNN-based approaches have significantly enhanced the accuracy of feature matching. Some algorithms improve feature localization <cite class="ltx_cite ltx_citemacro_citep">(Lowe, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib16" title="">2004</a>)</cite>, while others offer high repeatability <cite class="ltx_cite ltx_citemacro_citep">(DeTone et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib3" title="">2018</a>)</cite>. Certain methods reduce storage and matching costs <cite class="ltx_cite ltx_citemacro_citep">(Rublee et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib26" title="">2011</a>)</cite>, some are invariant to specific transformations <cite class="ltx_cite ltx_citemacro_citep">(Pautrat et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib21" title="">2020</a>)</cite>, and others ignore unreliable features <cite class="ltx_cite ltx_citemacro_citep">(Tyszkiewicz et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib33" title="">2020</a>)</cite>. These techniques typically rely on nearest neighbor search in descriptor space to match local features.
However, non-matchable keypoints and imperfect descriptors can result in erroneous correspondences.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Deep matchers, such as SuperGlue <cite class="ltx_cite ltx_citemacro_citep">(Sarlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib27" title="">2020</a>)</cite>, are trained neural networks designed to jointly match local descriptors and reject outliers based on an input image pair. SuperGlue, which combines Transformers <cite class="ltx_cite ltx_citemacro_citep">(Vaswani, <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib34" title="">2017</a>)</cite> and optimal transport theory <cite class="ltx_cite ltx_citemacro_citep">(Peyré et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib22" title="">2019</a>)</cite>, leverages scene geometry and camera motion priors to achieve robust performance under extreme conditions. However, training SuperGlue is challenging due to its computational complexity, which scales quadratically with the number of keypoints.
As a result, the original SuperGlue’s long runtime often necessitates reducing the size of the attention mechanism to improve efficiency, though this compromises performance.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">Another approach is LoFTR <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib29" title="">2021</a>)</cite>, which matches points on dense grids rather than sparse locations. This method significantly improves robustness but comes at the cost of slower processing, as it must handle a larger number of elements, thereby limiting the resolution of the input image.</p>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">LightGlue, by contrast, surpasses existing methods such as SuperGlue in both speed and efficiency when matching sparse features. Its adaptive stopping mechanism allows for fine-grained control over the trade-off between speed and accuracy, making it possible to train high-performance deep matchers even with limited computational resources. LightGlue achieves Pareto optimality in balancing efficiency and accuracy, providing a versatile and effective solution for feature matching tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our system integrates SAM2, LightGlue, and FoundationPose to achieve 6D pose estimation from a CAD model. The framework is illustrated in Figure 1, which outlines the entire process and the generated results.
In the following subsections, we explain the system in detail, focusing on how it addresses key challenges.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Integration and Testing of Methods</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We combine SAM2, LightGlue, and FoundationPose to achieve 6D pose estimation, instance segmentation, and feature point matching using only a CAD model file. The detailed implementation process is outlined as follows:</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Initial Target Identification via Manual Selection or Pure Image Input</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">The system requires the user to provide a CAD model of the object to be recognized. During the first run, the user can either manually select the target object by clicking on it or provide a pure image of the object.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Segmentation Prompt Generation Based on User Input or Feature Matching</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">Once the target object is identified via manual selection or pure image input(an image of the object with a pure white background), the system generates prompt information used by SAM2 for segmentation.
SAM2, trained on the SA-V dataset<cite class="ltx_cite ltx_citemacro_citep">(Ravi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib23" title="">2024</a>)</cite>, utilizes a Transformer-based encoder with ViT<cite class="ltx_cite ltx_citemacro_citep">(Ravi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib23" title="">2024</a>)</cite> to extract image features and applies a Memory Attention mechanism to handle dependencies in video data.
For mask, point, and box-type prompts, the encoder encodes these prompts, and the resulting representations, along with image features, are fed into a mask decoder to generate the mask.
Thus, the object’s location, determined either by the user’s click or through feature point matching via LightGlue, serves as a point-type prompt for SAM2’s mask decoder, which then generates the final object mask.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>6D Pose Estimation</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Using the mask and CAD model, a rough pose estimation is initially performed through global sampling. The sampled poses and the cropped image are then fed into the Encoder and Conv ResBlock.
The Encoder extracts the rotation and translation vectors. For pose hypothesis selection, images generated from different poses, along with the cropped region of the original image, are input into the Encoder to obtain feature representations, which are then pooled.
Self-attention and multi-head attention mechanisms, followed by a fully connected layer, are used to score each pose hypothesis, with the highest-scoring hypothesis selected as the final pose estimate.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Handling Tracking Loss in FoundationPose</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">FoundationPose relies on positional information from the previous frame for pose estimation, which can result in tracking loss if the object moves too quickly. To address this, SAM2 performs real-time object segmentation for each frame.
We calculate the distance between the centroid of the mask and the center point of the pose estimate to detect tracking loss. In Eq.<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.E1" title="Equation 1 ‣ 3.2 Handling Tracking Loss in FoundationPose ‣ 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a>, this distance is measured using Robust Lorentzian centroid Distance with Lorentzian error function and square of L2 norm.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="D=\log\left(1+\frac{1}{2\sigma^{2}}\left\|\frac{1}{n}\sum_{i=1}^{n}\mathbf{r}_%
{i}-\mathbf{Hc}\right\|^{2}\right)" class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mi id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.3.cmml">D</mi><mo id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.2.cmml"><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">log</mi><mo id="S3.E1.m1.2.2.1.1a" xref="S3.E1.m1.2.2.1.2.cmml">⁡</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.2.cmml"><mo id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.2.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mn id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml">1</mn><mo id="S3.E1.m1.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">+</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml"><mfrac id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.cmml"><mn id="S3.E1.m1.2.2.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml">1</mn><mrow id="S3.E1.m1.2.2.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml"><mn id="S3.E1.m1.2.2.1.1.1.1.1.3.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml">2</mn><mo id="S3.E1.m1.2.2.1.1.1.1.1.3.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml">⁢</mo><msup id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.2.cmml">σ</mi><mn id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.3.cmml">2</mn></msup></mrow></mfrac><mo id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml">⁢</mo><msup id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml"><mfrac id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml"><mn id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml">1</mn><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3.cmml">n</mi></mfrac><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml"><munderover id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.cmml"><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.2" movablelimits="false" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.3.cmml">n</mi></munderover><msub id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">𝐫</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.3.cmml">i</mi></msub></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">𝐇𝐜</mi></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E1.m1.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><eq id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"></eq><ci id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3">𝐷</ci><apply id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.1"><log id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"></log><apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1"><plus id="S3.E1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2"></plus><cn id="S3.E1.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.3">1</cn><apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2"></times><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3"><divide id="S3.E1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3"></divide><cn id="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2">1</cn><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3"><times id="S3.E1.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.1"></times><cn id="S3.E1.m1.2.2.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.2">2</cn><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.2">𝜎</ci><cn id="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.3.3">2</cn></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2"><times id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.1"></times><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><divide id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"></divide><cn id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2">1</cn><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3">𝑛</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3"><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1">subscript</csymbol><sum id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.2"></sum><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3"><eq id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.1"></eq><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.2">𝑖</ci><cn id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.1.3">𝑛</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.2">𝐫</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.2.3">𝑖</ci></apply></apply></apply><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝐇𝐜</ci></apply></apply><cn id="S3.E1.m1.2.2.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">D=\log\left(1+\frac{1}{2\sigma^{2}}\left\|\frac{1}{n}\sum_{i=1}^{n}\mathbf{r}_%
{i}-\mathbf{Hc}\right\|^{2}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">italic_D = roman_log ( 1 + divide start_ARG 1 end_ARG start_ARG 2 italic_σ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ∥ divide start_ARG 1 end_ARG start_ARG italic_n end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - bold_Hc ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.4">where <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_σ</annotation></semantics></math> is a parameter that regulates the sensitivity of the distance function to larger error values (outliers). The vector <math alttext="\mathbf{r}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">𝐫</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝐫</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathbf{r}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">bold_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> corresponds to each point on the largest contour in the mask, while <math alttext="\mathbf{c}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">bold_c</annotation></semantics></math> represents the 3D center point obtained from the pose estimation.
The matrix <math alttext="\mathbf{H}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\mathbf{H}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">bold_H</annotation></semantics></math> is the transformation matrix that converts the 3D coordinate system to the image coordinate system.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">As defined in Eq.<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.E2" title="Equation 2 ‣ 3.2 Handling Tracking Loss in FoundationPose ‣ 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>, if the distance exceeds a certain threshold, the current mask generated by SAM2 is used to re-register the object, thereby correcting the tracking loss.</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="D&gt;\tau\max_{x_{i},x_{j}\in M}\|x_{i}-x_{j}\|" class="ltx_Math" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml"><mi id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml">D</mi><mo id="S3.E2.m1.3.3.2" xref="S3.E2.m1.3.3.2.cmml">&gt;</mo><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.cmml"><mi id="S3.E2.m1.3.3.1.3" xref="S3.E2.m1.3.3.1.3.cmml">τ</mi><mo id="S3.E2.m1.3.3.1.2" lspace="0.167em" xref="S3.E2.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><munder id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml"><mi id="S3.E2.m1.3.3.1.1.2.2" xref="S3.E2.m1.3.3.1.1.2.2.cmml">max</mi><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mrow id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.3.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.2.cmml">x</mi><mi id="S3.E2.m1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.2.3.cmml">j</mi></msub></mrow><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">∈</mo><mi id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml">M</mi></mrow></munder><mo id="S3.E2.m1.3.3.1.1a" xref="S3.E2.m1.3.3.1.1.cmml">⁡</mo><mrow id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"><gt id="S3.E2.m1.3.3.2.cmml" xref="S3.E2.m1.3.3.2"></gt><ci id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3">𝐷</ci><apply id="S3.E2.m1.3.3.1.cmml" xref="S3.E2.m1.3.3.1"><times id="S3.E2.m1.3.3.1.2.cmml" xref="S3.E2.m1.3.3.1.2"></times><ci id="S3.E2.m1.3.3.1.3.cmml" xref="S3.E2.m1.3.3.1.3">𝜏</ci><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1"><apply id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.2">subscript</csymbol><max id="S3.E2.m1.3.3.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.2.2"></max><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><in id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></in><list id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.2">𝑥</ci><ci id="S3.E2.m1.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3">𝑗</ci></apply></list><ci id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4">𝑀</ci></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2">norm</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><minus id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1"></minus><apply id="S3.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2">𝑥</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.3">𝑗</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">D&gt;\tau\max_{x_{i},x_{j}\in M}\|x_{i}-x_{j}\|</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">italic_D &gt; italic_τ roman_max start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ italic_M end_POSTSUBSCRIPT ∥ italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∥</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.3">where <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.1"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.1d">italic_τ</annotation></semantics></math> is the coefficient of the maximum diameter, typically set to 0.2, and <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><msub id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml"><mi id="S3.SS2.p6.2.m2.1.1.2" xref="S3.SS2.p6.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS2.p6.2.m2.1.1.3" xref="S3.SS2.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><apply id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.2.m2.1.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p6.2.m2.1.1.2.cmml" xref="S3.SS2.p6.2.m2.1.1.2">𝑥</ci><ci id="S3.SS2.p6.2.m2.1.1.3.cmml" xref="S3.SS2.p6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="x_{j}" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><msub id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml"><mi id="S3.SS2.p6.3.m3.1.1.2" xref="S3.SS2.p6.3.m3.1.1.2.cmml">x</mi><mi id="S3.SS2.p6.3.m3.1.1.3" xref="S3.SS2.p6.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><apply id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m3.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p6.3.m3.1.1.2.cmml" xref="S3.SS2.p6.3.m3.1.1.2">𝑥</ci><ci id="S3.SS2.p6.3.m3.1.1.3.cmml" xref="S3.SS2.p6.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">x_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> represent the vectors of points on the 3D model.</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">Additionally, we found that providing a higher-quality mask during registration mitigates automatic rotation and results in more stable tracking.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Addressing Long-Term Object Loss: A Memory Mechanism</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To handle long-term object loss, we implemented a memory-like mechanism. As defined in Eq.<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S3.E3" title="Equation 3 ‣ 3.3 Addressing Long-Term Object Loss: A Memory Mechanism ‣ 3 Proposed Method ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a>, if the object is lost for an extended period (typically 10 seconds), both FoundationPose and SAM2 may fail to track it.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="T\left(\max_{C_{i}\in\mathcal{C}}A(C_{i})&lt;\alpha A(C_{\text{Initial}})\right)&gt;t" class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml">T</mi><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml"><munder id="S3.E3.m1.1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.2.cmml">max</mi><mrow id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.2.cmml">C</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.3.cmml">𝒞</mi></mrow></munder><mo id="S3.E3.m1.1.1.1.1.1.1.1.3a" lspace="0.167em" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.3.2.cmml">A</mi></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">C</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">&lt;</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.2.3.cmml">α</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.2.2.cmml">⁢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.2.4" xref="S3.E3.m1.1.1.1.1.1.1.2.4.cmml">A</mi><mo id="S3.E3.m1.1.1.1.1.1.1.2.2a" xref="S3.E3.m1.1.1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.2.1.1" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.2.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.cmml">C</mi><mtext id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3a.cmml">Initial</mtext></msub><mo id="S3.E3.m1.1.1.1.1.1.1.2.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">&gt;</mo><mi id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><gt id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"></gt><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3">𝑇</ci><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><lt id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3"></lt><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3"><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1">subscript</csymbol><max id="S3.E3.m1.1.1.1.1.1.1.1.3.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.2"></max><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3"><in id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.1"></in><apply id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.2">𝐶</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.2.3">𝑖</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.1.3.3">𝒞</ci></apply></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3.2">𝐴</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2">𝐶</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.2"></times><ci id="S3.E3.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.3">𝛼</ci><ci id="S3.E3.m1.1.1.1.1.1.1.2.4.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.4">𝐴</ci><apply id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.2">𝐶</ci><ci id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3"><mtext id="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3.cmml" mathsize="70%" xref="S3.E3.m1.1.1.1.1.1.1.2.1.1.1.3">Initial</mtext></ci></apply></apply></apply></apply><ci id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">T\left(\max_{C_{i}\in\mathcal{C}}A(C_{i})&lt;\alpha A(C_{\text{Initial}})\right)&gt;t</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">italic_T ( roman_max start_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_C end_POSTSUBSCRIPT italic_A ( italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) &lt; italic_α italic_A ( italic_C start_POSTSUBSCRIPT Initial end_POSTSUBSCRIPT ) ) &gt; italic_t</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.5">where <math alttext="C_{i}" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝐶</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">C_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents different contours in the mask image, <math alttext="A(C_{i})" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">A</mi><mo id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p3.2.m2.1.1.1.1" xref="S3.SS3.p3.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS3.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS3.p3.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p3.2.m2.1.1.1.1.1" xref="S3.SS3.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.1.1.1.2" xref="S3.SS3.p3.2.m2.1.1.1.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.2.m2.1.1.1.1.1.3" xref="S3.SS3.p3.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS3.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><times id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2"></times><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝐴</ci><apply id="S3.SS3.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS3.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">A(C_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">italic_A ( italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is used to calculate the area of each contour, and <math alttext="C_{\text{Initial}}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">C</mi><mtext id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3a.cmml">Initial</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝐶</ci><ci id="S3.SS3.p3.3.m3.1.1.3a.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><mtext id="S3.SS3.p3.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS3.p3.3.m3.1.1.3">Initial</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">C_{\text{Initial}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">italic_C start_POSTSUBSCRIPT Initial end_POSTSUBSCRIPT</annotation></semantics></math> represents the largest contour in the mask during initialization.
<math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m4.1d">italic_α</annotation></semantics></math> is a parameter used to control the sensitivity of the memory mechanism, typically set to 0.6, and <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m5.1"><semantics id="S3.SS3.p3.5.m5.1a"><mi id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><ci id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m5.1d">italic_t</annotation></semantics></math> is the time threshold, usually set to 10 seconds.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">In such cases, we reload the pure image of the object saved during the initial SAM2 run and perform feature point matching on the current frames using LightGlue. If the object reappears, a location prompt is generated, which is passed to SAM2 for re-segmentation.
The segmentation result is then fed into FoundationPose for re-registration, allowing the system to resume tracking the object.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Deployment and Evaluation of FoundationPose</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To enhance object recognition and detection systems, we performed a series of experiments evaluating the performance of FoundationPose, focusing on its application to the YCB-Video dataset and industrial objects. The selected objects, such as detergent bottles (bleach cleanser) and gears, presented unique challenges due to their diverse shapes and textures.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">FoundationPose was deployed in a live system using an Azure Kinect camera, which captured both RGB and depth data for real-time object detection and pose estimation in dynamic environments. However, several challenges arose during testing.
First, FoundationPose requires accurate segmentation information, specifically a mask of the target object, to initiate the registration process. Generating this mask in real time proved difficult, highlighting the need for a real-time instance segmentation algorithm.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">Furthermore, we observed tracking failures when objects moved too quickly or temporarily left the camera’s view, underscoring the need for more robust tracking mechanisms to maintain consistent detection.
Another issue emerged when detecting gears; the system experienced rotation errors due to the symmetrical nature of the gears, resulting in incorrect orientation interpretations. This suggests that improved handling mechanisms for symmetrical objects are essential.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">Addressing these challenges is critical to enhancing the system’s reliability and accuracy, particularly in complex, real-time operational environments.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>CNOS and CNOS+FoundationPose</h4>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="385" id="S4.F2.g1" src="extracted/5870539/Images/CNOS_output_image.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S4.F2.2.1">The initial reference images generated from CNOS</span>
<br class="ltx_break"/>The results demonstrate that CNOS initially generates 42 reference images from the CAD model as prompts, which are then passed to SAM.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">In our approach to instance segmentation, we initially selected CNOS due to its capability of performing segmentation using only the CAD model of the object, which is essential for tasks that rely on accurate geometric properties defined by the CAD model.
We tested CNOS on various objects, including a bleach cleanser, and found that it effectively detected the object’s location and approximate shape. However, a significant limitation was identified with the edge representation.
The segmented edges appeared jagged due to CNOS’s process of downsampling the input image to 224x224 pixels before upsampling it back to the original resolution, leading to a loss of fine edge details. Despite this limitation, CNOS remained functional within our system.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">We integrated CNOS and FoundationPose into separate modules, with a workflow designed such that when the camera captures data and registration is required, CNOS generates a mask matrix, which is then passed to FoundationPose for registration and tracking.
This pipeline delivered satisfactory results with fast processing speeds for the bleach cleanser, with the primary time cost occurring during initialization when CNOS rendered the CAD model to generate images from multiple angles.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p3">
<p class="ltx_p" id="S4.SS1.SSS1.p3.1">However, a major challenge arose when testing CNOS on a gear object. It frequently failed to generate an accurate mask, which we traced to discrepancies between the CAD model and the real object, particularly regarding texture and material properties, despite the shape and edge information being consistent.
These limitations, especially with complex objects like gears, highlighted that relying solely on CNOS would not be sufficient for all scenarios.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p4">
<p class="ltx_p" id="S4.SS1.SSS1.p4.1">To overcome these limitations, we propose exploring alternative segmentation models and implementing a polymorphic approach within the mask class, allowing the system to switch between different models as needed.
This modular design will enhance the system’s robustness and ensure high accuracy across a diverse range of objects and segmentation challenges.</p>
</div>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.1" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F3.1.g1" src="extracted/5870539/Images/CNOS_color_bleach.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.2" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F3.2.g1" src="extracted/5870539/Images/CNOS_mask_bleach.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.3" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F3.3.g1" src="extracted/5870539/Images/CNOS_rgb.png" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.4" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F3.4.g1" src="extracted/5870539/Images/CNOS_mask_gear.png" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S4.F3.6.1">CNOS+FoundationPose Experimental Results</span>
<br class="ltx_break"/>As shown, CNOS successfully generates a mask for the bleach cleanser, though it tends to lose finer edge details.
In contrast, CNOS often fails to produce a valid mask for the gear, likely due to discrepancies between the CAD model and the real object’s texture and material properties.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>PerSAM and PerSAM+FoundationPose</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">The Segment Anything Model (SAM) has recently gained significant attention in instance segmentation, and we explored the use of its variant, PerSAM, for generating mask information in our object detection system.
PerSAM computes cosine similarity between a reference image and the current image to identify the target object’s mask. It demonstrated significant speed advantages over CNOS by eliminating the need for initialization, while offering more stable detections and effectively preserving edge details.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1">We integrated PerSAM into our system within the mask class, alongside FoundationPose. This integration improved the system’s overall robustness and accuracy across a variety of objects, including detergent bottles and gears.
However, despite these improvements, several challenges emerged. First, PerSAM’s reliance on cosine similarity introduces instability due to its sensitivity to variations in viewing angles. This sensitivity can negatively affect tracking accuracy, particularly in dynamic environments where objects frequently change orientation.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p3">
<p class="ltx_p" id="S4.SS1.SSS2.p3.1">Second, the requirement to provide a reference image and corresponding mask file for each object complicates the workflow, making it cumbersome, particularly in industrial settings where efficiency is critical. This added complexity can introduce delays, especially in fast-paced or large-scale operations.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p4">
<p class="ltx_p" id="S4.SS1.SSS2.p4.1">While PerSAM offers superior speed and precision compared to CNOS, addressing the sensitivity to angle variations and simplifying the workflow are necessary steps to ensure consistent and efficient performance in real-world applications.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.1" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F4.1.g1" src="extracted/5870539/Images/PerSAM_original_gear_0.jpg" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.2" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F4.2.g1" src="extracted/5870539/Images/PerSAM_mask_gear_0.jpg" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.3" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="337" id="S4.F4.3.g1" src="extracted/5870539/Images/PerSAM_original_gear_3.jpg" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.4" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F4.4.g1" src="extracted/5870539/Images/PerSAM_mask_gear_3.jpg" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S4.F4.6.1">PerSAM+FoundationPose Experimental Results</span>
<br class="ltx_break"/>PerSAM demonstrates superior performance in handling edge details, successfully recognizing both the gear and bleach cleanser in most cases. However, its sensitivity to variations in angles and occlusions often leads to misidentifications.
The figure above illustrates instances where edge details are lost and misidentifications occur.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>SAM2 and SAM2+FoundationPose</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">To address the challenges identified in previous instance segmentation approaches, we adopted the recently introduced SAM2 algorithm, which provided significant improvements and effectively resolved key issues, including the loss of fine edge details, sensitivity to viewing angle variations, and the need for reference images and corresponding mask files.
SAM2’s internal memory mechanism greatly enhances tracking capabilities, allowing it to maintain reliable object tracking even when objects temporarily disappear from the frame. Upon reappearance, SAM2 quickly and accurately reacquires the object, ensuring seamless tracking continuity—an improvement over earlier models that struggled with rapid orientation changes or when objects moved out of view.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p2">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1">Additionally, SAM2 simplifies the segmentation process with a click-to-segment operation, where the user selects the object at the beginning of a video, and SAM2 handles real-time segmentation and tracking throughout. This approach eliminates the need for pre-prepared reference images and masks, significantly reducing operational complexity.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p3">
<p class="ltx_p" id="S4.SS1.SSS3.p3.1">Extensive experimentation demonstrated SAM2’s efficiency and accuracy in segmenting a variety of objects, including bleach cleansers and gears, with detection times averaging just 50 milliseconds per frame while delivering exceptional tracking accuracy.
These advantages led to the integration of SAM2 into a dedicated class within the FoundationPose framework, resulting in a robust and efficient solution that overcomes the limitations of previous approaches.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.1" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F5.1.g1" src="extracted/5870539/Images/original_gear1.jpg" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.2" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F5.2.g1" src="extracted/5870539/Images/mask_gear1.jpg" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.3" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F5.3.g1" src="extracted/5870539/Images/original_gear_5.jpg" width="598"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.4" style="width:86.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="337" id="S4.F5.4.g1" src="extracted/5870539/Images/mask_gear_5.jpg" width="598"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S4.F5.6.1">SAM2+FoundationPose Experimental Results</span>
<br class="ltx_break"/>The figure above illustrates the experimental results of SAM2 combined with FoundationPose. As shown, SAM2 excels in generating accurate masks for object segmentation, not only correctly identifying the target object but also preserving fine texture details.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.SSS3.p4">
<p class="ltx_p" id="S4.SS1.SSS3.p4.1">SAM2 provides real-time segmentation and tracking with minimal user input, significantly enhancing the system’s practicality in dynamic environments. This integration represents a major advancement in object segmentation and tracking technology, ensuring the system is well-equipped for real-world deployment with high performance and reduced operational complexity.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Result</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Runtime of each model</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Runtime is a key metric used to evaluate the speed of various models. This analysis includes different segmentation models, such as CNOS, PerSAM, and SAM2, as well as different feature point matching models, SuperGlue and LightGlue.
Additionally, the runtime of the base FoundationPose model, as well as FoundationPose enhanced with track loss resolving, is also considered.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T1.1" style="width:216.8pt;height:74.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-74.6pt,25.7pt) scale(0.592286197644796,0.592286197644796) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.1">Algorithm</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.2">Initialised time(ms)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.3">Track time for each frame(ms)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.1">CNOS</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.2">5700</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.3">1200</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.3.2.1">SAM2 with tiny model</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.3.2.2">250</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.3.2.3">48</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.4.3.1">PerSAM with FastSAM</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.4.3.2">280</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.4.3.3">35</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.5.4.1">FoundationPose</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.5.4.2">1200</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.5.4.3">100</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.6.5.1">LightGlue</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.6.5.2">38</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T1.1.1.6.5.3">25</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.7.6.1">SuperGlue</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.1.7.6.2">250</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T1.1.1.7.6.3">120</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text ltx_font_bold" id="S5.T1.3.1">Runtime of each model</span>
</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Based on Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.T1" title="Table 1 ‣ 5.1 Runtime of each model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a>, we compared the runtime performance of LightGlue versus SuperGlue, as well as CNOS, PerSAM, and SAM2.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">LightGlue vs. SuperGlue: LightGlue has an initialization time of 38 milliseconds and a per-frame tracking time of 25 milliseconds, significantly faster than SuperGlue’s 250 milliseconds and 120 milliseconds.
This indicates that LightGlue is more suitable for real-time applications.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Comparison of CNOS, PerSAM, and SAM2: CNOS has the highest initialization and per-frame tracking times, at 5700 milliseconds and 1200 milliseconds, respectively.
PerSAM and SAM2 both have initialization times around 250 milliseconds, with per-frame tracking times of 35 milliseconds and 48 milliseconds. PerSAM slightly outperforms SAM2 in tracking speed.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">LightGlue demonstrates superior runtime efficiency over SuperGlue, making it more appropriate for scenarios requiring high real-time performance. PerSAM and SAM2 have significantly lower runtimes compared to CNOS, with PerSAM being slightly faster in tracking.
This suggests that when selecting an algorithm, one must balance performance and computational cost to meet specific requirements.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>IoU of each Segmentation model</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The Intersection over Union (IoU) metric evaluates the overlap between the predicted segmentation and the ground truth, which can be seen in below Eq.(<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.E4" title="Equation 4 ‣ 5.2 IoU of each Segmentation model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">4</span></a>).
We tested and compared the IoU results of SAM2, PerSAM, and CNOS on the YCB-Video dataset for segmentation tasks based on CAD models.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S5.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Average IoU}=\frac{1}{N}\sum_{i=1}^{N}\frac{|A_{i}\cap B_{i}|}{|A_{i}%
\cup B_{i}|}" class="ltx_Math" display="block" id="S5.E4.m1.2"><semantics id="S5.E4.m1.2a"><mrow id="S5.E4.m1.2.3" xref="S5.E4.m1.2.3.cmml"><mtext id="S5.E4.m1.2.3.2" xref="S5.E4.m1.2.3.2a.cmml">Average IoU</mtext><mo id="S5.E4.m1.2.3.1" xref="S5.E4.m1.2.3.1.cmml">=</mo><mrow id="S5.E4.m1.2.3.3" xref="S5.E4.m1.2.3.3.cmml"><mfrac id="S5.E4.m1.2.3.3.2" xref="S5.E4.m1.2.3.3.2.cmml"><mn id="S5.E4.m1.2.3.3.2.2" xref="S5.E4.m1.2.3.3.2.2.cmml">1</mn><mi id="S5.E4.m1.2.3.3.2.3" xref="S5.E4.m1.2.3.3.2.3.cmml">N</mi></mfrac><mo id="S5.E4.m1.2.3.3.1" xref="S5.E4.m1.2.3.3.1.cmml">⁢</mo><mrow id="S5.E4.m1.2.3.3.3" xref="S5.E4.m1.2.3.3.3.cmml"><munderover id="S5.E4.m1.2.3.3.3.1" xref="S5.E4.m1.2.3.3.3.1.cmml"><mo id="S5.E4.m1.2.3.3.3.1.2.2" movablelimits="false" xref="S5.E4.m1.2.3.3.3.1.2.2.cmml">∑</mo><mrow id="S5.E4.m1.2.3.3.3.1.2.3" xref="S5.E4.m1.2.3.3.3.1.2.3.cmml"><mi id="S5.E4.m1.2.3.3.3.1.2.3.2" xref="S5.E4.m1.2.3.3.3.1.2.3.2.cmml">i</mi><mo id="S5.E4.m1.2.3.3.3.1.2.3.1" xref="S5.E4.m1.2.3.3.3.1.2.3.1.cmml">=</mo><mn id="S5.E4.m1.2.3.3.3.1.2.3.3" xref="S5.E4.m1.2.3.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S5.E4.m1.2.3.3.3.1.3" xref="S5.E4.m1.2.3.3.3.1.3.cmml">N</mi></munderover><mfrac id="S5.E4.m1.2.2" xref="S5.E4.m1.2.2.cmml"><mrow id="S5.E4.m1.1.1.1.1" xref="S5.E4.m1.1.1.1.2.cmml"><mo id="S5.E4.m1.1.1.1.1.2" stretchy="false" xref="S5.E4.m1.1.1.1.2.1.cmml">|</mo><mrow id="S5.E4.m1.1.1.1.1.1" xref="S5.E4.m1.1.1.1.1.1.cmml"><msub id="S5.E4.m1.1.1.1.1.1.2" xref="S5.E4.m1.1.1.1.1.1.2.cmml"><mi id="S5.E4.m1.1.1.1.1.1.2.2" xref="S5.E4.m1.1.1.1.1.1.2.2.cmml">A</mi><mi id="S5.E4.m1.1.1.1.1.1.2.3" xref="S5.E4.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S5.E4.m1.1.1.1.1.1.1" xref="S5.E4.m1.1.1.1.1.1.1.cmml">∩</mo><msub id="S5.E4.m1.1.1.1.1.1.3" xref="S5.E4.m1.1.1.1.1.1.3.cmml"><mi id="S5.E4.m1.1.1.1.1.1.3.2" xref="S5.E4.m1.1.1.1.1.1.3.2.cmml">B</mi><mi id="S5.E4.m1.1.1.1.1.1.3.3" xref="S5.E4.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E4.m1.1.1.1.1.3" stretchy="false" xref="S5.E4.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S5.E4.m1.2.2.2.1" xref="S5.E4.m1.2.2.2.2.cmml"><mo id="S5.E4.m1.2.2.2.1.2" stretchy="false" xref="S5.E4.m1.2.2.2.2.1.cmml">|</mo><mrow id="S5.E4.m1.2.2.2.1.1" xref="S5.E4.m1.2.2.2.1.1.cmml"><msub id="S5.E4.m1.2.2.2.1.1.2" xref="S5.E4.m1.2.2.2.1.1.2.cmml"><mi id="S5.E4.m1.2.2.2.1.1.2.2" xref="S5.E4.m1.2.2.2.1.1.2.2.cmml">A</mi><mi id="S5.E4.m1.2.2.2.1.1.2.3" xref="S5.E4.m1.2.2.2.1.1.2.3.cmml">i</mi></msub><mo id="S5.E4.m1.2.2.2.1.1.1" xref="S5.E4.m1.2.2.2.1.1.1.cmml">∪</mo><msub id="S5.E4.m1.2.2.2.1.1.3" xref="S5.E4.m1.2.2.2.1.1.3.cmml"><mi id="S5.E4.m1.2.2.2.1.1.3.2" xref="S5.E4.m1.2.2.2.1.1.3.2.cmml">B</mi><mi id="S5.E4.m1.2.2.2.1.1.3.3" xref="S5.E4.m1.2.2.2.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E4.m1.2.2.2.1.3" stretchy="false" xref="S5.E4.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.2b"><apply id="S5.E4.m1.2.3.cmml" xref="S5.E4.m1.2.3"><eq id="S5.E4.m1.2.3.1.cmml" xref="S5.E4.m1.2.3.1"></eq><ci id="S5.E4.m1.2.3.2a.cmml" xref="S5.E4.m1.2.3.2"><mtext id="S5.E4.m1.2.3.2.cmml" xref="S5.E4.m1.2.3.2">Average IoU</mtext></ci><apply id="S5.E4.m1.2.3.3.cmml" xref="S5.E4.m1.2.3.3"><times id="S5.E4.m1.2.3.3.1.cmml" xref="S5.E4.m1.2.3.3.1"></times><apply id="S5.E4.m1.2.3.3.2.cmml" xref="S5.E4.m1.2.3.3.2"><divide id="S5.E4.m1.2.3.3.2.1.cmml" xref="S5.E4.m1.2.3.3.2"></divide><cn id="S5.E4.m1.2.3.3.2.2.cmml" type="integer" xref="S5.E4.m1.2.3.3.2.2">1</cn><ci id="S5.E4.m1.2.3.3.2.3.cmml" xref="S5.E4.m1.2.3.3.2.3">𝑁</ci></apply><apply id="S5.E4.m1.2.3.3.3.cmml" xref="S5.E4.m1.2.3.3.3"><apply id="S5.E4.m1.2.3.3.3.1.cmml" xref="S5.E4.m1.2.3.3.3.1"><csymbol cd="ambiguous" id="S5.E4.m1.2.3.3.3.1.1.cmml" xref="S5.E4.m1.2.3.3.3.1">superscript</csymbol><apply id="S5.E4.m1.2.3.3.3.1.2.cmml" xref="S5.E4.m1.2.3.3.3.1"><csymbol cd="ambiguous" id="S5.E4.m1.2.3.3.3.1.2.1.cmml" xref="S5.E4.m1.2.3.3.3.1">subscript</csymbol><sum id="S5.E4.m1.2.3.3.3.1.2.2.cmml" xref="S5.E4.m1.2.3.3.3.1.2.2"></sum><apply id="S5.E4.m1.2.3.3.3.1.2.3.cmml" xref="S5.E4.m1.2.3.3.3.1.2.3"><eq id="S5.E4.m1.2.3.3.3.1.2.3.1.cmml" xref="S5.E4.m1.2.3.3.3.1.2.3.1"></eq><ci id="S5.E4.m1.2.3.3.3.1.2.3.2.cmml" xref="S5.E4.m1.2.3.3.3.1.2.3.2">𝑖</ci><cn id="S5.E4.m1.2.3.3.3.1.2.3.3.cmml" type="integer" xref="S5.E4.m1.2.3.3.3.1.2.3.3">1</cn></apply></apply><ci id="S5.E4.m1.2.3.3.3.1.3.cmml" xref="S5.E4.m1.2.3.3.3.1.3">𝑁</ci></apply><apply id="S5.E4.m1.2.2.cmml" xref="S5.E4.m1.2.2"><divide id="S5.E4.m1.2.2.3.cmml" xref="S5.E4.m1.2.2"></divide><apply id="S5.E4.m1.1.1.1.2.cmml" xref="S5.E4.m1.1.1.1.1"><abs id="S5.E4.m1.1.1.1.2.1.cmml" xref="S5.E4.m1.1.1.1.1.2"></abs><apply id="S5.E4.m1.1.1.1.1.1.cmml" xref="S5.E4.m1.1.1.1.1.1"><intersect id="S5.E4.m1.1.1.1.1.1.1.cmml" xref="S5.E4.m1.1.1.1.1.1.1"></intersect><apply id="S5.E4.m1.1.1.1.1.1.2.cmml" xref="S5.E4.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.1.1.1.1.1.2.1.cmml" xref="S5.E4.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.1.1.1.1.1.2.2.cmml" xref="S5.E4.m1.1.1.1.1.1.2.2">𝐴</ci><ci id="S5.E4.m1.1.1.1.1.1.2.3.cmml" xref="S5.E4.m1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S5.E4.m1.1.1.1.1.1.3.cmml" xref="S5.E4.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.1.1.1.1.1.3.1.cmml" xref="S5.E4.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E4.m1.1.1.1.1.1.3.2.cmml" xref="S5.E4.m1.1.1.1.1.1.3.2">𝐵</ci><ci id="S5.E4.m1.1.1.1.1.1.3.3.cmml" xref="S5.E4.m1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><apply id="S5.E4.m1.2.2.2.2.cmml" xref="S5.E4.m1.2.2.2.1"><abs id="S5.E4.m1.2.2.2.2.1.cmml" xref="S5.E4.m1.2.2.2.1.2"></abs><apply id="S5.E4.m1.2.2.2.1.1.cmml" xref="S5.E4.m1.2.2.2.1.1"><union id="S5.E4.m1.2.2.2.1.1.1.cmml" xref="S5.E4.m1.2.2.2.1.1.1"></union><apply id="S5.E4.m1.2.2.2.1.1.2.cmml" xref="S5.E4.m1.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.2.1.1.2.1.cmml" xref="S5.E4.m1.2.2.2.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.2.1.1.2.2.cmml" xref="S5.E4.m1.2.2.2.1.1.2.2">𝐴</ci><ci id="S5.E4.m1.2.2.2.1.1.2.3.cmml" xref="S5.E4.m1.2.2.2.1.1.2.3">𝑖</ci></apply><apply id="S5.E4.m1.2.2.2.1.1.3.cmml" xref="S5.E4.m1.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.2.1.1.3.1.cmml" xref="S5.E4.m1.2.2.2.1.1.3">subscript</csymbol><ci id="S5.E4.m1.2.2.2.1.1.3.2.cmml" xref="S5.E4.m1.2.2.2.1.1.3.2">𝐵</ci><ci id="S5.E4.m1.2.2.2.1.1.3.3.cmml" xref="S5.E4.m1.2.2.2.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.2c">\text{Average IoU}=\frac{1}{N}\sum_{i=1}^{N}\frac{|A_{i}\cap B_{i}|}{|A_{i}%
\cup B_{i}|}</annotation><annotation encoding="application/x-llamapun" id="S5.E4.m1.2d">Average IoU = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT divide start_ARG | italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∩ italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | end_ARG start_ARG | italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∪ italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS2.p2.3">where <math alttext="A_{i}" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><msub id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">A</mi><mi id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">𝐴</ci><ci id="S5.SS2.p2.1.m1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">A_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the ground truth mask, <math alttext="B_{i}" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><msub id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">B</mi><mi id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">𝐵</ci><ci id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">B_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the predicted mask, and <math alttext="N" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mi id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><ci id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">italic_N</annotation></semantics></math> represents the size of the dataset.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.T2" title="Table 2 ‣ 5.2 IoU of each Segmentation model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>, there are significant differences in the average IoU among the three algorithms: CNOS, PerSAM, and SAM2.
Overall, SAM2 achieves the highest average IoU on most objects, demonstrating superior segmentation performance. For example, for the object <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.1.1">003_cracker_box</span>, SAM2 attains an average IoU of 0.8727, which is substantially higher than CNOS’s 0.5409 and PerSAM’s 0.3700.
However, CNOS performs best on the object <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.1.2">009_gelatin_box</span>, achieving an average IoU of 0.9299, surpassing SAM2’s 0.8900. This suggests that although SAM2 generally leads, there is still room for improvement on certain objects. PerSAM’s average IoU is generally lower than the other two algorithms.
In summary, while SAM2 exhibits the best overall performance, the algorithms display varying effectiveness across different objects.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:216.8pt;height:191.9pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-115.9pt,102.3pt) scale(0.483320778797353,0.483320778797353) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.1.1">Object name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.2.1">Average IoU (CNOS)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.3.1">Average IoU (PerSAM)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.1.1.4.1">Average IoU (SAM2)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.1">002_master_chef_can</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.2">0.7567</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.3">0.4592</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.4">0.8501</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.1">003_cracker_box</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.2">0.5409</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.3">0.3700</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2.4">0.8727</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.1">004_sugar_box</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.2">0.8232</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.3">0.5484</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.4.3.4">0.8525</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.5.4.1">005_tomato_soup_can</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.5.4.2">0.8222</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.5.4.3">0.5546</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.5.4.4">0.8523</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.6.5.1">006_mustard_bottle</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.6.5.2">0.9097</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.6.5.3">0.7489</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.6.5.4">0.9184</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.7.6.1">007_tuna_fish_can</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.7.6.2">0.9007</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.7.6.3">0.4080</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.7.6.4">0.6771</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.8.7.1">008_pudding_box</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.8.7.2">0.0406</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.8.7.3">0.3168</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.8.7.4">0.9299</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.9.8.1">009_gelatin_box</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.9.8.2">0.9299</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.9.8.3">0.5126</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.9.8.4">0.8900</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.10.9.1">010_potted_meat_can</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.10.9.2">0.6965</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.10.9.3">0.3268</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.10.9.4">0.8060</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.11.10.1">011_banana</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.11.10.2">0.7003</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.11.10.3">0.7615</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.11.10.4">0.9110</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.12.11.1">019_pitcher_base</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.12.11.2">0.8793</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.12.11.3">0.7160</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.12.11.4">0.8926</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.13.12.1">021_bleach_cleanser</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.13.12.2">0.7395</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.13.12.3">0.7040</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.13.12.4">0.8473</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.14.13.1">024_bowl</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.14.13.2">0.4320</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.14.13.3">0.7117</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.14.13.4">0.8810</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.15.14.1">025_mug</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.15.14.2">0.7944</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.15.14.3">0.3696</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.15.14.4">0.8601</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.16.15.1">035_power_drill</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.16.15.2">0.7590</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.16.15.3">0.3885</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.16.15.4">0.7910</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.17.16.1">036_wood_block</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.17.16.2">0.6492</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.17.16.3">0.4904</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.17.16.4">0.8090</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.18.17.1">037_scissors</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.18.17.2">0.5551</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.18.17.3">0.2133</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.18.17.4">0.6892</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.19.18.1">040_large_marker</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.19.18.2">0.7361</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.19.18.3">0.3070</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.19.18.4">0.7469</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.20.19.1">051_large_clamp</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.20.19.2">0.6268</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.20.19.3">0.3632</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.20.19.4">0.8010</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.21.20.1">052_extra_large_clamp</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.21.20.2">0.4848</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.21.20.3">0.1611</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.21.20.4">0.7949</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.22.21.1">061_foam_brick</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.1.22.21.2">0.4600</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.1.22.21.3">0.3396</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T2.1.1.22.21.4">0.8626</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold" id="S5.T2.3.1">The comparison of IoU among different algorithms</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>ADD of FoundationPose with different Segmentation model</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">ADD (Average Distance of Model Points)<cite class="ltx_cite ltx_citemacro_citep">(Xiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#bib.bib40" title="">2017</a>)</cite> is a metric commonly used to evaluate the accuracy of 6D object pose estimation.
As shown in below Eq.<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.E5" title="Equation 5 ‣ 5.3 ADD of FoundationPose with different Segmentation model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">5</span></a> it measures the average distance between corresponding 3D points on the ground truth model and the predicted model after transformation.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S5.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{ADD}=\frac{1}{m}\sum_{x\in M}\left\|(Rx+t)-(R_{\text{gt}}x+t_{\text{gt}}%
)\right\|" class="ltx_Math" display="block" id="S5.E5.m1.1"><semantics id="S5.E5.m1.1a"><mrow id="S5.E5.m1.1.1" xref="S5.E5.m1.1.1.cmml"><mtext id="S5.E5.m1.1.1.3" xref="S5.E5.m1.1.1.3a.cmml">ADD</mtext><mo id="S5.E5.m1.1.1.2" xref="S5.E5.m1.1.1.2.cmml">=</mo><mrow id="S5.E5.m1.1.1.1" xref="S5.E5.m1.1.1.1.cmml"><mfrac id="S5.E5.m1.1.1.1.3" xref="S5.E5.m1.1.1.1.3.cmml"><mn id="S5.E5.m1.1.1.1.3.2" xref="S5.E5.m1.1.1.1.3.2.cmml">1</mn><mi id="S5.E5.m1.1.1.1.3.3" xref="S5.E5.m1.1.1.1.3.3.cmml">m</mi></mfrac><mo id="S5.E5.m1.1.1.1.2" xref="S5.E5.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml"><munder id="S5.E5.m1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.2.cmml"><mo id="S5.E5.m1.1.1.1.1.2.2" movablelimits="false" rspace="0em" xref="S5.E5.m1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S5.E5.m1.1.1.1.1.2.3" xref="S5.E5.m1.1.1.1.1.2.3.cmml"><mi id="S5.E5.m1.1.1.1.1.2.3.2" xref="S5.E5.m1.1.1.1.1.2.3.2.cmml">x</mi><mo id="S5.E5.m1.1.1.1.1.2.3.1" xref="S5.E5.m1.1.1.1.1.2.3.1.cmml">∈</mo><mi id="S5.E5.m1.1.1.1.1.2.3.3" xref="S5.E5.m1.1.1.1.1.2.3.3.cmml">M</mi></mrow></munder><mrow id="S5.E5.m1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.2.cmml"><mo id="S5.E5.m1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E5.m1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S5.E5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">x</mi></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1.2.1" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.cmml"><mo id="S5.E5.m1.1.1.1.1.1.1.1.2.1.2" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.cmml"><mrow id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.cmml"><msub id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml">R</mi><mtext id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.3" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.3a.cmml">gt</mtext></msub><mo id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.1" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">⁢</mo><mi id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.3" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.3.cmml">x</mi></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.1.cmml">+</mo><msub id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.2" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.2.cmml">t</mi><mtext id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.3" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.3a.cmml">gt</mtext></msub></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.1.2.1.3" stretchy="false" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E5.m1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.1b"><apply id="S5.E5.m1.1.1.cmml" xref="S5.E5.m1.1.1"><eq id="S5.E5.m1.1.1.2.cmml" xref="S5.E5.m1.1.1.2"></eq><ci id="S5.E5.m1.1.1.3a.cmml" xref="S5.E5.m1.1.1.3"><mtext id="S5.E5.m1.1.1.3.cmml" xref="S5.E5.m1.1.1.3">ADD</mtext></ci><apply id="S5.E5.m1.1.1.1.cmml" xref="S5.E5.m1.1.1.1"><times id="S5.E5.m1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.2"></times><apply id="S5.E5.m1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.3"><divide id="S5.E5.m1.1.1.1.3.1.cmml" xref="S5.E5.m1.1.1.1.3"></divide><cn id="S5.E5.m1.1.1.1.3.2.cmml" type="integer" xref="S5.E5.m1.1.1.1.3.2">1</cn><ci id="S5.E5.m1.1.1.1.3.3.cmml" xref="S5.E5.m1.1.1.1.3.3">𝑚</ci></apply><apply id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1"><apply id="S5.E5.m1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.1.1.1.1.2">subscript</csymbol><sum id="S5.E5.m1.1.1.1.1.2.2.cmml" xref="S5.E5.m1.1.1.1.1.2.2"></sum><apply id="S5.E5.m1.1.1.1.1.2.3.cmml" xref="S5.E5.m1.1.1.1.1.2.3"><in id="S5.E5.m1.1.1.1.1.2.3.1.cmml" xref="S5.E5.m1.1.1.1.1.2.3.1"></in><ci id="S5.E5.m1.1.1.1.1.2.3.2.cmml" xref="S5.E5.m1.1.1.1.1.2.3.2">𝑥</ci><ci id="S5.E5.m1.1.1.1.1.2.3.3.cmml" xref="S5.E5.m1.1.1.1.1.2.3.3">𝑀</ci></apply></apply><apply id="S5.E5.m1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E5.m1.1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.E5.m1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1"><minus id="S5.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.3"></minus><apply id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1"><plus id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2"><times id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2">𝑅</ci><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.2.3">𝑥</ci></apply><ci id="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1"><plus id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.1"></plus><apply id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2"><times id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.1"></times><apply id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2">subscript</csymbol><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.2">𝑅</ci><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.3a.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.3"><mtext id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.3.cmml" mathsize="70%" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.2.3">gt</mtext></ci></apply><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.2.3">𝑥</ci></apply><apply id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.2">𝑡</ci><ci id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.3a.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.3"><mtext id="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.3.cmml" mathsize="70%" xref="S5.E5.m1.1.1.1.1.1.1.1.2.1.1.3.3">gt</mtext></ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.1c">\text{ADD}=\frac{1}{m}\sum_{x\in M}\left\|(Rx+t)-(R_{\text{gt}}x+t_{\text{gt}}%
)\right\|</annotation><annotation encoding="application/x-llamapun" id="S5.E5.m1.1d">ADD = divide start_ARG 1 end_ARG start_ARG italic_m end_ARG ∑ start_POSTSUBSCRIPT italic_x ∈ italic_M end_POSTSUBSCRIPT ∥ ( italic_R italic_x + italic_t ) - ( italic_R start_POSTSUBSCRIPT gt end_POSTSUBSCRIPT italic_x + italic_t start_POSTSUBSCRIPT gt end_POSTSUBSCRIPT ) ∥</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<table class="ltx_equation ltx_eqn_table" id="S5.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{ADD-S}=\frac{1}{m}\sum_{x_{1}\in M}\min_{x_{2}\in M}\left\|(Rx_{1}+t)-(R%
_{\text{gt}}x_{2}+t_{\text{gt}})\right\|" class="ltx_Math" display="block" id="S5.E6.m1.1"><semantics id="S5.E6.m1.1a"><mrow id="S5.E6.m1.1.1" xref="S5.E6.m1.1.1.cmml"><mtext id="S5.E6.m1.1.1.3" xref="S5.E6.m1.1.1.3a.cmml">ADD-S</mtext><mo id="S5.E6.m1.1.1.2" xref="S5.E6.m1.1.1.2.cmml">=</mo><mrow id="S5.E6.m1.1.1.1" xref="S5.E6.m1.1.1.1.cmml"><mfrac id="S5.E6.m1.1.1.1.3" xref="S5.E6.m1.1.1.1.3.cmml"><mn id="S5.E6.m1.1.1.1.3.2" xref="S5.E6.m1.1.1.1.3.2.cmml">1</mn><mi id="S5.E6.m1.1.1.1.3.3" xref="S5.E6.m1.1.1.1.3.3.cmml">m</mi></mfrac><mo id="S5.E6.m1.1.1.1.2" xref="S5.E6.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E6.m1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.cmml"><munder id="S5.E6.m1.1.1.1.1.2" xref="S5.E6.m1.1.1.1.1.2.cmml"><mo id="S5.E6.m1.1.1.1.1.2.2" movablelimits="false" xref="S5.E6.m1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S5.E6.m1.1.1.1.1.2.3" xref="S5.E6.m1.1.1.1.1.2.3.cmml"><msub id="S5.E6.m1.1.1.1.1.2.3.2" xref="S5.E6.m1.1.1.1.1.2.3.2.cmml"><mi id="S5.E6.m1.1.1.1.1.2.3.2.2" xref="S5.E6.m1.1.1.1.1.2.3.2.2.cmml">x</mi><mn id="S5.E6.m1.1.1.1.1.2.3.2.3" xref="S5.E6.m1.1.1.1.1.2.3.2.3.cmml">1</mn></msub><mo id="S5.E6.m1.1.1.1.1.2.3.1" xref="S5.E6.m1.1.1.1.1.2.3.1.cmml">∈</mo><mi id="S5.E6.m1.1.1.1.1.2.3.3" xref="S5.E6.m1.1.1.1.1.2.3.3.cmml">M</mi></mrow></munder><mrow id="S5.E6.m1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.cmml"><munder id="S5.E6.m1.1.1.1.1.1.2" xref="S5.E6.m1.1.1.1.1.1.2.cmml"><mi id="S5.E6.m1.1.1.1.1.1.2.2" xref="S5.E6.m1.1.1.1.1.1.2.2.cmml">min</mi><mrow id="S5.E6.m1.1.1.1.1.1.2.3" xref="S5.E6.m1.1.1.1.1.1.2.3.cmml"><msub id="S5.E6.m1.1.1.1.1.1.2.3.2" xref="S5.E6.m1.1.1.1.1.1.2.3.2.cmml"><mi id="S5.E6.m1.1.1.1.1.1.2.3.2.2" xref="S5.E6.m1.1.1.1.1.1.2.3.2.2.cmml">x</mi><mn id="S5.E6.m1.1.1.1.1.1.2.3.2.3" xref="S5.E6.m1.1.1.1.1.1.2.3.2.3.cmml">2</mn></msub><mo id="S5.E6.m1.1.1.1.1.1.2.3.1" xref="S5.E6.m1.1.1.1.1.1.2.3.1.cmml">∈</mo><mi id="S5.E6.m1.1.1.1.1.1.2.3.3" xref="S5.E6.m1.1.1.1.1.1.2.3.3.cmml">M</mi></mrow></munder><mo id="S5.E6.m1.1.1.1.1.1a" xref="S5.E6.m1.1.1.1.1.1.cmml">⁡</mo><mrow id="S5.E6.m1.1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.2.cmml"><mo id="S5.E6.m1.1.1.1.1.1.1.1.2" xref="S5.E6.m1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><msub id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">x</mi><mn id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></mrow><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.2" stretchy="false" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mrow id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.cmml"><msub id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml"><mi id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml">R</mi><mtext id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.3a.cmml">gt</mtext></msub><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">⁢</mo><msub id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml"><mi id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2.cmml">x</mi><mn id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3.cmml">2</mn></msub></mrow><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">+</mo><msub id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.2" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml">t</mi><mtext id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.3" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.3a.cmml">gt</mtext></msub></mrow><mo id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.3" stretchy="false" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E6.m1.1.1.1.1.1.1.1.3" xref="S5.E6.m1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E6.m1.1b"><apply id="S5.E6.m1.1.1.cmml" xref="S5.E6.m1.1.1"><eq id="S5.E6.m1.1.1.2.cmml" xref="S5.E6.m1.1.1.2"></eq><ci id="S5.E6.m1.1.1.3a.cmml" xref="S5.E6.m1.1.1.3"><mtext id="S5.E6.m1.1.1.3.cmml" xref="S5.E6.m1.1.1.3">ADD-S</mtext></ci><apply id="S5.E6.m1.1.1.1.cmml" xref="S5.E6.m1.1.1.1"><times id="S5.E6.m1.1.1.1.2.cmml" xref="S5.E6.m1.1.1.1.2"></times><apply id="S5.E6.m1.1.1.1.3.cmml" xref="S5.E6.m1.1.1.1.3"><divide id="S5.E6.m1.1.1.1.3.1.cmml" xref="S5.E6.m1.1.1.1.3"></divide><cn id="S5.E6.m1.1.1.1.3.2.cmml" type="integer" xref="S5.E6.m1.1.1.1.3.2">1</cn><ci id="S5.E6.m1.1.1.1.3.3.cmml" xref="S5.E6.m1.1.1.1.3.3">𝑚</ci></apply><apply id="S5.E6.m1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1"><apply id="S5.E6.m1.1.1.1.1.2.cmml" xref="S5.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.2.1.cmml" xref="S5.E6.m1.1.1.1.1.2">subscript</csymbol><sum id="S5.E6.m1.1.1.1.1.2.2.cmml" xref="S5.E6.m1.1.1.1.1.2.2"></sum><apply id="S5.E6.m1.1.1.1.1.2.3.cmml" xref="S5.E6.m1.1.1.1.1.2.3"><in id="S5.E6.m1.1.1.1.1.2.3.1.cmml" xref="S5.E6.m1.1.1.1.1.2.3.1"></in><apply id="S5.E6.m1.1.1.1.1.2.3.2.cmml" xref="S5.E6.m1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.2.3.2.1.cmml" xref="S5.E6.m1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.2.3.2.2.cmml" xref="S5.E6.m1.1.1.1.1.2.3.2.2">𝑥</ci><cn id="S5.E6.m1.1.1.1.1.2.3.2.3.cmml" type="integer" xref="S5.E6.m1.1.1.1.1.2.3.2.3">1</cn></apply><ci id="S5.E6.m1.1.1.1.1.2.3.3.cmml" xref="S5.E6.m1.1.1.1.1.2.3.3">𝑀</ci></apply></apply><apply id="S5.E6.m1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1"><apply id="S5.E6.m1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.2">subscript</csymbol><min id="S5.E6.m1.1.1.1.1.1.2.2.cmml" xref="S5.E6.m1.1.1.1.1.1.2.2"></min><apply id="S5.E6.m1.1.1.1.1.1.2.3.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3"><in id="S5.E6.m1.1.1.1.1.1.2.3.1.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3.1"></in><apply id="S5.E6.m1.1.1.1.1.1.2.3.2.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.2.3.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.2.3.2.2.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3.2.2">𝑥</ci><cn id="S5.E6.m1.1.1.1.1.1.2.3.2.3.cmml" type="integer" xref="S5.E6.m1.1.1.1.1.1.2.3.2.3">2</cn></apply><ci id="S5.E6.m1.1.1.1.1.1.2.3.3.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3.3">𝑀</ci></apply></apply><apply id="S5.E6.m1.1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E6.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1"><minus id="S5.E6.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.3"></minus><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1"><plus id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2"><times id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑅</ci><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2">𝑥</ci><cn id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1"><plus id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.1"></plus><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2"><times id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.1"></times><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2">𝑅</ci><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.3a.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.3"><mtext id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.3.cmml" mathsize="70%" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.3">gt</mtext></ci></apply><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2">𝑥</ci><cn id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3.cmml" type="integer" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3">2</cn></apply></apply><apply id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.2">𝑡</ci><ci id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.3a.cmml" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.3"><mtext id="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.3.cmml" mathsize="70%" xref="S5.E6.m1.1.1.1.1.1.1.1.1.2.1.1.3.3">gt</mtext></ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E6.m1.1c">\text{ADD-S}=\frac{1}{m}\sum_{x_{1}\in M}\min_{x_{2}\in M}\left\|(Rx_{1}+t)-(R%
_{\text{gt}}x_{2}+t_{\text{gt}})\right\|</annotation><annotation encoding="application/x-llamapun" id="S5.E6.m1.1d">ADD-S = divide start_ARG 1 end_ARG start_ARG italic_m end_ARG ∑ start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∈ italic_M end_POSTSUBSCRIPT roman_min start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∈ italic_M end_POSTSUBSCRIPT ∥ ( italic_R italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_t ) - ( italic_R start_POSTSUBSCRIPT gt end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_t start_POSTSUBSCRIPT gt end_POSTSUBSCRIPT ) ∥</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.6">where <math alttext="x" class="ltx_Math" display="inline" id="S5.SS3.p4.1.m1.1"><semantics id="S5.SS3.p4.1.m1.1a"><mi id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><ci id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.1.m1.1d">italic_x</annotation></semantics></math> represents the vectors of each point on the model, <math alttext="R" class="ltx_Math" display="inline" id="S5.SS3.p4.2.m2.1"><semantics id="S5.SS3.p4.2.m2.1a"><mi id="S5.SS3.p4.2.m2.1.1" xref="S5.SS3.p4.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.2.m2.1b"><ci id="S5.SS3.p4.2.m2.1.1.cmml" xref="S5.SS3.p4.2.m2.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.2.m2.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.2.m2.1d">italic_R</annotation></semantics></math> represents the predicted rotation matrix, <math alttext="t" class="ltx_Math" display="inline" id="S5.SS3.p4.3.m3.1"><semantics id="S5.SS3.p4.3.m3.1a"><mi id="S5.SS3.p4.3.m3.1.1" xref="S5.SS3.p4.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.3.m3.1b"><ci id="S5.SS3.p4.3.m3.1.1.cmml" xref="S5.SS3.p4.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.3.m3.1d">italic_t</annotation></semantics></math> represents the predicted translation vector, <math alttext="R_{\text{gt}}" class="ltx_Math" display="inline" id="S5.SS3.p4.4.m4.1"><semantics id="S5.SS3.p4.4.m4.1a"><msub id="S5.SS3.p4.4.m4.1.1" xref="S5.SS3.p4.4.m4.1.1.cmml"><mi id="S5.SS3.p4.4.m4.1.1.2" xref="S5.SS3.p4.4.m4.1.1.2.cmml">R</mi><mtext id="S5.SS3.p4.4.m4.1.1.3" xref="S5.SS3.p4.4.m4.1.1.3a.cmml">gt</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.4.m4.1b"><apply id="S5.SS3.p4.4.m4.1.1.cmml" xref="S5.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS3.p4.4.m4.1.1.1.cmml" xref="S5.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S5.SS3.p4.4.m4.1.1.2.cmml" xref="S5.SS3.p4.4.m4.1.1.2">𝑅</ci><ci id="S5.SS3.p4.4.m4.1.1.3a.cmml" xref="S5.SS3.p4.4.m4.1.1.3"><mtext id="S5.SS3.p4.4.m4.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p4.4.m4.1.1.3">gt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.4.m4.1c">R_{\text{gt}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.4.m4.1d">italic_R start_POSTSUBSCRIPT gt end_POSTSUBSCRIPT</annotation></semantics></math> represents the ground truth rotation matrix, <math alttext="t_{\text{gt}}" class="ltx_Math" display="inline" id="S5.SS3.p4.5.m5.1"><semantics id="S5.SS3.p4.5.m5.1a"><msub id="S5.SS3.p4.5.m5.1.1" xref="S5.SS3.p4.5.m5.1.1.cmml"><mi id="S5.SS3.p4.5.m5.1.1.2" xref="S5.SS3.p4.5.m5.1.1.2.cmml">t</mi><mtext id="S5.SS3.p4.5.m5.1.1.3" xref="S5.SS3.p4.5.m5.1.1.3a.cmml">gt</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.5.m5.1b"><apply id="S5.SS3.p4.5.m5.1.1.cmml" xref="S5.SS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS3.p4.5.m5.1.1.1.cmml" xref="S5.SS3.p4.5.m5.1.1">subscript</csymbol><ci id="S5.SS3.p4.5.m5.1.1.2.cmml" xref="S5.SS3.p4.5.m5.1.1.2">𝑡</ci><ci id="S5.SS3.p4.5.m5.1.1.3a.cmml" xref="S5.SS3.p4.5.m5.1.1.3"><mtext id="S5.SS3.p4.5.m5.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p4.5.m5.1.1.3">gt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.5.m5.1c">t_{\text{gt}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.5.m5.1d">italic_t start_POSTSUBSCRIPT gt end_POSTSUBSCRIPT</annotation></semantics></math> represents the ground truth translation vector,
and <math alttext="m" class="ltx_Math" display="inline" id="S5.SS3.p4.6.m6.1"><semantics id="S5.SS3.p4.6.m6.1a"><mi id="S5.SS3.p4.6.m6.1.1" xref="S5.SS3.p4.6.m6.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.6.m6.1b"><ci id="S5.SS3.p4.6.m6.1.1.cmml" xref="S5.SS3.p4.6.m6.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.6.m6.1c">m</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p4.6.m6.1d">italic_m</annotation></semantics></math> represents the total number of points in the model.
A pose is considered correct if the ADD is below a certain threshold.</p>
</div>
<div class="ltx_para" id="S5.SS3.p5">
<table class="ltx_equation ltx_eqn_table" id="S5.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Accuracy}=\frac{1}{N_{\text{total}}}\sum_{i=1}^{N_{\text{total}}}\mathbf%
{1}\left(\text{ADD}_{i}&lt;\alpha\max_{x_{j},x_{k}\in M}\|x_{j}-x_{k}\|\right)" class="ltx_Math" display="block" id="S5.E7.m1.3"><semantics id="S5.E7.m1.3a"><mrow id="S5.E7.m1.3.3" xref="S5.E7.m1.3.3.cmml"><mtext id="S5.E7.m1.3.3.3" xref="S5.E7.m1.3.3.3a.cmml">Accuracy</mtext><mo id="S5.E7.m1.3.3.2" xref="S5.E7.m1.3.3.2.cmml">=</mo><mrow id="S5.E7.m1.3.3.1" xref="S5.E7.m1.3.3.1.cmml"><mfrac id="S5.E7.m1.3.3.1.3" xref="S5.E7.m1.3.3.1.3.cmml"><mn id="S5.E7.m1.3.3.1.3.2" xref="S5.E7.m1.3.3.1.3.2.cmml">1</mn><msub id="S5.E7.m1.3.3.1.3.3" xref="S5.E7.m1.3.3.1.3.3.cmml"><mi id="S5.E7.m1.3.3.1.3.3.2" xref="S5.E7.m1.3.3.1.3.3.2.cmml">N</mi><mtext id="S5.E7.m1.3.3.1.3.3.3" xref="S5.E7.m1.3.3.1.3.3.3a.cmml">total</mtext></msub></mfrac><mo id="S5.E7.m1.3.3.1.2" xref="S5.E7.m1.3.3.1.2.cmml">⁢</mo><mrow id="S5.E7.m1.3.3.1.1" xref="S5.E7.m1.3.3.1.1.cmml"><munderover id="S5.E7.m1.3.3.1.1.2" xref="S5.E7.m1.3.3.1.1.2.cmml"><mo id="S5.E7.m1.3.3.1.1.2.2.2" movablelimits="false" xref="S5.E7.m1.3.3.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E7.m1.3.3.1.1.2.2.3" xref="S5.E7.m1.3.3.1.1.2.2.3.cmml"><mi id="S5.E7.m1.3.3.1.1.2.2.3.2" xref="S5.E7.m1.3.3.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E7.m1.3.3.1.1.2.2.3.1" xref="S5.E7.m1.3.3.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E7.m1.3.3.1.1.2.2.3.3" xref="S5.E7.m1.3.3.1.1.2.2.3.3.cmml">1</mn></mrow><msub id="S5.E7.m1.3.3.1.1.2.3" xref="S5.E7.m1.3.3.1.1.2.3.cmml"><mi id="S5.E7.m1.3.3.1.1.2.3.2" xref="S5.E7.m1.3.3.1.1.2.3.2.cmml">N</mi><mtext id="S5.E7.m1.3.3.1.1.2.3.3" xref="S5.E7.m1.3.3.1.1.2.3.3a.cmml">total</mtext></msub></munderover><mrow id="S5.E7.m1.3.3.1.1.1" xref="S5.E7.m1.3.3.1.1.1.cmml"><mn id="S5.E7.m1.3.3.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.3.cmml">𝟏</mn><mo id="S5.E7.m1.3.3.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S5.E7.m1.3.3.1.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S5.E7.m1.3.3.1.1.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.cmml"><mtext id="S5.E7.m1.3.3.1.1.1.1.1.1.3.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.2a.cmml">ADD</mtext><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.3.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml">&lt;</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.3.cmml">α</mi><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.1.2" lspace="0.167em" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.cmml"><munder id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml">max</mi><mrow id="S5.E7.m1.2.2.2" xref="S5.E7.m1.2.2.2.cmml"><mrow id="S5.E7.m1.2.2.2.2.2" xref="S5.E7.m1.2.2.2.2.3.cmml"><msub id="S5.E7.m1.1.1.1.1.1.1" xref="S5.E7.m1.1.1.1.1.1.1.cmml"><mi id="S5.E7.m1.1.1.1.1.1.1.2" xref="S5.E7.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S5.E7.m1.1.1.1.1.1.1.3" xref="S5.E7.m1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S5.E7.m1.2.2.2.2.2.3" xref="S5.E7.m1.2.2.2.2.3.cmml">,</mo><msub id="S5.E7.m1.2.2.2.2.2.2" xref="S5.E7.m1.2.2.2.2.2.2.cmml"><mi id="S5.E7.m1.2.2.2.2.2.2.2" xref="S5.E7.m1.2.2.2.2.2.2.2.cmml">x</mi><mi id="S5.E7.m1.2.2.2.2.2.2.3" xref="S5.E7.m1.2.2.2.2.2.2.3.cmml">k</mi></msub></mrow><mo id="S5.E7.m1.2.2.2.3" xref="S5.E7.m1.2.2.2.3.cmml">∈</mo><mi id="S5.E7.m1.2.2.2.4" xref="S5.E7.m1.2.2.2.4.cmml">M</mi></mrow></munder><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1a" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.cmml">⁡</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">j</mi></msub><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">k</mi></msub></mrow><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow><mo id="S5.E7.m1.3.3.1.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E7.m1.3b"><apply id="S5.E7.m1.3.3.cmml" xref="S5.E7.m1.3.3"><eq id="S5.E7.m1.3.3.2.cmml" xref="S5.E7.m1.3.3.2"></eq><ci id="S5.E7.m1.3.3.3a.cmml" xref="S5.E7.m1.3.3.3"><mtext id="S5.E7.m1.3.3.3.cmml" xref="S5.E7.m1.3.3.3">Accuracy</mtext></ci><apply id="S5.E7.m1.3.3.1.cmml" xref="S5.E7.m1.3.3.1"><times id="S5.E7.m1.3.3.1.2.cmml" xref="S5.E7.m1.3.3.1.2"></times><apply id="S5.E7.m1.3.3.1.3.cmml" xref="S5.E7.m1.3.3.1.3"><divide id="S5.E7.m1.3.3.1.3.1.cmml" xref="S5.E7.m1.3.3.1.3"></divide><cn id="S5.E7.m1.3.3.1.3.2.cmml" type="integer" xref="S5.E7.m1.3.3.1.3.2">1</cn><apply id="S5.E7.m1.3.3.1.3.3.cmml" xref="S5.E7.m1.3.3.1.3.3"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.3.3.1.cmml" xref="S5.E7.m1.3.3.1.3.3">subscript</csymbol><ci id="S5.E7.m1.3.3.1.3.3.2.cmml" xref="S5.E7.m1.3.3.1.3.3.2">𝑁</ci><ci id="S5.E7.m1.3.3.1.3.3.3a.cmml" xref="S5.E7.m1.3.3.1.3.3.3"><mtext id="S5.E7.m1.3.3.1.3.3.3.cmml" mathsize="70%" xref="S5.E7.m1.3.3.1.3.3.3">total</mtext></ci></apply></apply><apply id="S5.E7.m1.3.3.1.1.cmml" xref="S5.E7.m1.3.3.1.1"><apply id="S5.E7.m1.3.3.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.2">superscript</csymbol><apply id="S5.E7.m1.3.3.1.1.2.2.cmml" xref="S5.E7.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.2.2.1.cmml" xref="S5.E7.m1.3.3.1.1.2">subscript</csymbol><sum id="S5.E7.m1.3.3.1.1.2.2.2.cmml" xref="S5.E7.m1.3.3.1.1.2.2.2"></sum><apply id="S5.E7.m1.3.3.1.1.2.2.3.cmml" xref="S5.E7.m1.3.3.1.1.2.2.3"><eq id="S5.E7.m1.3.3.1.1.2.2.3.1.cmml" xref="S5.E7.m1.3.3.1.1.2.2.3.1"></eq><ci id="S5.E7.m1.3.3.1.1.2.2.3.2.cmml" xref="S5.E7.m1.3.3.1.1.2.2.3.2">𝑖</ci><cn id="S5.E7.m1.3.3.1.1.2.2.3.3.cmml" type="integer" xref="S5.E7.m1.3.3.1.1.2.2.3.3">1</cn></apply></apply><apply id="S5.E7.m1.3.3.1.1.2.3.cmml" xref="S5.E7.m1.3.3.1.1.2.3"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.2.3.1.cmml" xref="S5.E7.m1.3.3.1.1.2.3">subscript</csymbol><ci id="S5.E7.m1.3.3.1.1.2.3.2.cmml" xref="S5.E7.m1.3.3.1.1.2.3.2">𝑁</ci><ci id="S5.E7.m1.3.3.1.1.2.3.3a.cmml" xref="S5.E7.m1.3.3.1.1.2.3.3"><mtext id="S5.E7.m1.3.3.1.1.2.3.3.cmml" mathsize="50%" xref="S5.E7.m1.3.3.1.1.2.3.3">total</mtext></ci></apply></apply><apply id="S5.E7.m1.3.3.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1"><times id="S5.E7.m1.3.3.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.2"></times><cn id="S5.E7.m1.3.3.1.1.1.3.cmml" type="integer" xref="S5.E7.m1.3.3.1.1.1.3">1</cn><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1"><lt id="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2"></lt><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.3.2a.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.2"><mtext id="S5.E7.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.2">ADD</mtext></ci><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1"><times id="S5.E7.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.2"></times><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.3">𝛼</ci><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1"><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><max id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.2.2"></max><apply id="S5.E7.m1.2.2.2.cmml" xref="S5.E7.m1.2.2.2"><in id="S5.E7.m1.2.2.2.3.cmml" xref="S5.E7.m1.2.2.2.3"></in><list id="S5.E7.m1.2.2.2.2.3.cmml" xref="S5.E7.m1.2.2.2.2.2"><apply id="S5.E7.m1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E7.m1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E7.m1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="S5.E7.m1.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S5.E7.m1.2.2.2.2.2.2.cmml" xref="S5.E7.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.E7.m1.2.2.2.2.2.2.1.cmml" xref="S5.E7.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S5.E7.m1.2.2.2.2.2.2.2.cmml" xref="S5.E7.m1.2.2.2.2.2.2.2">𝑥</ci><ci id="S5.E7.m1.2.2.2.2.2.2.3.cmml" xref="S5.E7.m1.2.2.2.2.2.2.3">𝑘</ci></apply></list><ci id="S5.E7.m1.2.2.2.4.cmml" xref="S5.E7.m1.2.2.2.4">𝑀</ci></apply></apply><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><minus id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑗</ci></apply><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2">𝑥</ci><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑘</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E7.m1.3c">\text{Accuracy}=\frac{1}{N_{\text{total}}}\sum_{i=1}^{N_{\text{total}}}\mathbf%
{1}\left(\text{ADD}_{i}&lt;\alpha\max_{x_{j},x_{k}\in M}\|x_{j}-x_{k}\|\right)</annotation><annotation encoding="application/x-llamapun" id="S5.E7.m1.3d">Accuracy = divide start_ARG 1 end_ARG start_ARG italic_N start_POSTSUBSCRIPT total end_POSTSUBSCRIPT end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT total end_POSTSUBSCRIPT end_POSTSUPERSCRIPT bold_1 ( ADD start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT &lt; italic_α roman_max start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∈ italic_M end_POSTSUBSCRIPT ∥ italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∥ )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S5.SS3.p6">
<p class="ltx_p" id="S5.SS3.p6.4">where <math alttext="\alpha" class="ltx_Math" display="inline" id="S5.SS3.p6.1.m1.1"><semantics id="S5.SS3.p6.1.m1.1a"><mi id="S5.SS3.p6.1.m1.1.1" xref="S5.SS3.p6.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.1.m1.1b"><ci id="S5.SS3.p6.1.m1.1.1.cmml" xref="S5.SS3.p6.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p6.1.m1.1d">italic_α</annotation></semantics></math> represents the parameter for the maximum diameter, typically set to 0.1, <math alttext="x_{j}" class="ltx_Math" display="inline" id="S5.SS3.p6.2.m2.1"><semantics id="S5.SS3.p6.2.m2.1a"><msub id="S5.SS3.p6.2.m2.1.1" xref="S5.SS3.p6.2.m2.1.1.cmml"><mi id="S5.SS3.p6.2.m2.1.1.2" xref="S5.SS3.p6.2.m2.1.1.2.cmml">x</mi><mi id="S5.SS3.p6.2.m2.1.1.3" xref="S5.SS3.p6.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.2.m2.1b"><apply id="S5.SS3.p6.2.m2.1.1.cmml" xref="S5.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p6.2.m2.1.1.1.cmml" xref="S5.SS3.p6.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p6.2.m2.1.1.2.cmml" xref="S5.SS3.p6.2.m2.1.1.2">𝑥</ci><ci id="S5.SS3.p6.2.m2.1.1.3.cmml" xref="S5.SS3.p6.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.2.m2.1c">x_{j}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p6.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="x_{k}" class="ltx_Math" display="inline" id="S5.SS3.p6.3.m3.1"><semantics id="S5.SS3.p6.3.m3.1a"><msub id="S5.SS3.p6.3.m3.1.1" xref="S5.SS3.p6.3.m3.1.1.cmml"><mi id="S5.SS3.p6.3.m3.1.1.2" xref="S5.SS3.p6.3.m3.1.1.2.cmml">x</mi><mi id="S5.SS3.p6.3.m3.1.1.3" xref="S5.SS3.p6.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.3.m3.1b"><apply id="S5.SS3.p6.3.m3.1.1.cmml" xref="S5.SS3.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p6.3.m3.1.1.1.cmml" xref="S5.SS3.p6.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p6.3.m3.1.1.2.cmml" xref="S5.SS3.p6.3.m3.1.1.2">𝑥</ci><ci id="S5.SS3.p6.3.m3.1.1.3.cmml" xref="S5.SS3.p6.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.3.m3.1c">x_{k}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p6.3.m3.1d">italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> represent the vectors of points on the model, and <math alttext="N_{\text{total}}" class="ltx_Math" display="inline" id="S5.SS3.p6.4.m4.1"><semantics id="S5.SS3.p6.4.m4.1a"><msub id="S5.SS3.p6.4.m4.1.1" xref="S5.SS3.p6.4.m4.1.1.cmml"><mi id="S5.SS3.p6.4.m4.1.1.2" xref="S5.SS3.p6.4.m4.1.1.2.cmml">N</mi><mtext id="S5.SS3.p6.4.m4.1.1.3" xref="S5.SS3.p6.4.m4.1.1.3a.cmml">total</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p6.4.m4.1b"><apply id="S5.SS3.p6.4.m4.1.1.cmml" xref="S5.SS3.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS3.p6.4.m4.1.1.1.cmml" xref="S5.SS3.p6.4.m4.1.1">subscript</csymbol><ci id="S5.SS3.p6.4.m4.1.1.2.cmml" xref="S5.SS3.p6.4.m4.1.1.2">𝑁</ci><ci id="S5.SS3.p6.4.m4.1.1.3a.cmml" xref="S5.SS3.p6.4.m4.1.1.3"><mtext id="S5.SS3.p6.4.m4.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p6.4.m4.1.1.3">total</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p6.4.m4.1c">N_{\text{total}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p6.4.m4.1d">italic_N start_POSTSUBSCRIPT total end_POSTSUBSCRIPT</annotation></semantics></math> represents the size of the dataset.</p>
</div>
<div class="ltx_para" id="S5.SS3.p7">
<p class="ltx_p" id="S5.SS3.p7.1">However, for symmetric objects, the traditional ADD metric may not accurately measure pose estimation errors because symmetric objects can appear identical under certain rotations.
To address this issue, the ADD-S (Average Distance of Model Points for Symmetric Objects) metric Eq.<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.E6" title="Equation 6 ‣ 5.3 ADD of FoundationPose with different Segmentation model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">6</span></a> is used.</p>
</div>
<div class="ltx_para" id="S5.SS3.p8">
<p class="ltx_p" id="S5.SS3.p8.1">ADD-S calculates the average distance between each point on the predicted model and the closest point on the ground truth model, rather than between corresponding points.
This approach more accurately evaluates the pose estimation accuracy for symmetric objects. A pose is considered correct if the ADD-S is below a specific threshold.</p>
</div>
<div class="ltx_para" id="S5.SS3.p9">
<p class="ltx_p" id="S5.SS3.p9.1">We tested the ADD accuracy Eq.<a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.E7" title="Equation 7 ‣ 5.3 ADD of FoundationPose with different Segmentation model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">7</span></a> on the YCB-Video dataset, comparing the results of FoundationPose with Ground Truth, FoundationPose with CNOS, FoundationPose with PerSAM, and FoundationPose with SAM2.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T3.1" style="width:216.8pt;height:188.5pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-140.6pt,122.0pt) scale(0.435311996840748,0.435311996840748) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T3.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.1.1">Algorithm</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S5.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.2.1">FP+CNOS</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S5.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.3.1">FP+PerSAM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S5.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.4.1">FP+Groundtruth</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2" id="S5.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.5.1">FP+SAM2</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r" id="S5.T3.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.1.1">Metric</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.2.1">ADD-S</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.3.1">ADD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.4.1">ADD-S</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.5.1">ADD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.6.1">ADD-S</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.7.1">ADD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.8.1">ADD-S</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.2.9.1">ADD</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.1">002_master_chef_can</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.2">95.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.3">68.33 %</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.4">78.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.5">52.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.7">70.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3.9">70.33%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.1">003_cracker_box</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.2">66.22%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.3">66.22%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.4">52.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.5">51.11%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.4.4.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.1">004_sugar_box</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.2">99.73%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.3">99.73%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.4">79.47%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.5">78.93%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.8">99.73%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.5.5.9">99.73%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.1">005_tomato_soup_can</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.2">77.78%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.3">77.78%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.4">67.56%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.5">62.22%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.6">95.11%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.7">94.89%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.8">95.56%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.6.6.9">95.56%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.7.7">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.1">006_mustard_bottle</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.2">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.3">97.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.4">96.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.5">94.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.7">98.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.7.7.9">98.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.8.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.1">007_tuna_fish_can</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.2">99.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.3">99.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.4">54.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.5">53.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.8">99.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.8.8.9">99.67%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.1">008_pudding_box</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.2">85.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.3">85.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.4">73.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.5">73.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.9.9.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.10.10">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.1">009_gelatin_box</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.2">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.3">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.4">77.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.5">77.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.10.10.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.11.11">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.1">010_potted_meat_can</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.2">76.44%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.3">76.44%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.4">37.78%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.5">29.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.6">93.78%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.7">80.89%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.8">93.78%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.11.11.9">80.89%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.12.12">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.1">011_banana</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.2">77.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.3">77.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.4">84.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.5">84.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.12.12.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.13.13">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.1">019_pitcher_base</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.2">98.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.3">98.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.4">90.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.5">90.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.13.13.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.14.14">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.1">021_bleach_cleanser</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.2">83.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.3">83.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.4">87.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.5">85.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.14.14.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.15.15">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.1">024_bowl</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.2">50.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.3">1.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.4">94.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.5">10.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.7">4.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.15.15.9">7.33%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.16.16">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.1">025_mug</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.2">94.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.3">92.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.4">47.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.5">42.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.7">98.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.16.16.9">98.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.17.17">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.1">035_power_drill</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.2">98.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.3">98.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.4">85.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.5">84.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.17.17.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.18.18">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.1">036_wood_block</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.2">78.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.3">8.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.4">65.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.5">6.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.7">8.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.18.18.9">9.33%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.19.19">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.1">037_scissors</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.2">85.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.3">85.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.4">81.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.5">80.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.7">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.19.19.9">100.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.20.20">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.1">040_large_marker</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.2">96.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.3">54.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.4">52.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.5">19.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.7">52.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.20.20.9">52.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.21.21">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.1">051_large_clamp</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.2">78.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.3">28.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.4">54.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.5">26.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.7">49.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.21.21.9">50.67%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.22.22">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.1">052_extra_large_clamp</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.2">62.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.3">8.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.4">32.67%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.5">4.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.7">17.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.22.22.9">18.00%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.23.23">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.1">061_foam_brick</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.2">61.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.3">52.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.4">41.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.5">36.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.6">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.7">85.33%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.8">100.00%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.1.1.23.23.9">85.33%</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.24.24">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.1.1">MEAN</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.2.1">85.94%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.3"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.3.1">75.22%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.4"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.4.1">69.60%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.5"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.5.1">58.52%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.6"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.6.1">99.13%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.7"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.7.1">84.12%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.8"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.8.1">99.13%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S5.T3.1.1.24.24.9"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.24.24.9.1">84.32%</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="S5.T3.3.1">Pose tracking results of RGBD methods measured by AUC of ADD and ADD-S on YCB-Video dataset
<br class="ltx_break"/></span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p10">
<p class="ltx_p" id="S5.SS3.p10.1">As shown in the Table <a class="ltx_ref" href="https://arxiv.org/html/2409.19986v1#S5.T3" title="Table 3 ‣ 5.3 ADD of FoundationPose with different Segmentation model ‣ 5 Experimental Result ‣ GearTrack: Automating 6D Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a>, significant differences exist in the ADD and ADD-S metrics among the three algorithms: FP+CNOS, FP+PerSAM, and FoundationPose+SAM2, across different objects.
Overall, FoundationPose+SAM2 achieves the highest average ADD-S and ADD values on most objects, exhibiting superior performance in 6D pose estimation. For example, for the object <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p10.1.1">003_cracker_box</span>,
FoundationPose+SAM2 attains 100.00% in ADD-S and ADD, significantly surpassing FP+CNOS’s 66.22% and FP+PerSAM’s 52.00%.</p>
</div>
<div class="ltx_para" id="S5.SS3.p11">
<p class="ltx_p" id="S5.SS3.p11.1">FP+CNOS performs better on average than FP+PerSAM, with an average ADD-S of 85.94% compared to FP+PerSAM’s 69.60%. However, FP+CNOS still shows shortcomings on certain objects such as object <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p11.1.1">051_large_clamp</span>.</p>
</div>
<div class="ltx_para" id="S5.SS3.p12">
<p class="ltx_p" id="S5.SS3.p12.1">Notably, the performance of FoundationPose+SAM2 is very close to that of FP+Groundtruth, with both achieving an average ADD-S of 99.13% and average ADDs of 84.32% and 84.12%, respectively.
This indicates that SAM2 can assist in 6D pose estimation to achieve results comparable to those obtained using ground-truth segmentation.</p>
</div>
<div class="ltx_para" id="S5.SS3.p13">
<p class="ltx_p" id="S5.SS3.p13.1">In summary, FoundationPose+SAM2 exhibits the best performance in the 6D pose estimation task, followed by FP+CNOS, with FP+PerSAM showing relatively lower performance.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In conclusion, we have successfully developed and implemented an algorithm that integrates FoundationPose, SAM2, and LightGlue, offering a robust solution for real-time and video-based 6D pose estimation.
Our system represents a significant improvement over previous methods by eliminating the need for a pre-existing mask, resolving tracking loss issues, and simplifying the process to require only a single CAD file and an initial click from the user.
By leveraging SAM2’s advanced segmentation capabilities and LightGlue’s feature point matching, our algorithm ensures stable and accurate 6D pose estimation across a wide range of objects. This has been validated through rigorous testing on the YCB dataset and industrial products, such as gears.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The system’s ability to maintain reliable tracking in dynamic environments, along with its fully automated operation after initial setup, makes it highly suitable for practical, real-world industrial applications.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bay et al. (2006)</span>
<span class="ltx_bibblock">
Bay, H., Tuytelaars, T., and Van Gool, L.

</span>
<span class="ltx_bibblock">Surf: Speeded up robust features.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Computer Vision–ECCV 2006: 9th European Conference on
Computer Vision, Graz, Austria, May 7-13, 2006. Proceedings, Part I 9</em>, pp. 404–417. Springer, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Chen, D., Li, J., Wang, Z., and Xu, K.

</span>
<span class="ltx_bibblock">Learning canonical shape space for category-level 6d object pose and
size estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.  11973–11982, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeTone et al. (2018)</span>
<span class="ltx_bibblock">
DeTone, D., Malisiewicz, T., and Rabinovich, A.

</span>
<span class="ltx_bibblock">Superpoint: Self-supervised interest point detection and description.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR) Workshops</em>, June 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dusmanu et al. (2019)</span>
<span class="ltx_bibblock">
Dusmanu, M., Rocco, I., Pajdla, T., Pollefeys, M., Sivic, J., Torii, A., and
Sattler, T.

</span>
<span class="ltx_bibblock">D2-net: A trainable CNN for joint detection and description of
local features.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">CoRR</em>, abs/1905.03561, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1905.03561" title="">http://arxiv.org/abs/1905.03561</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harris et al. (1988)</span>
<span class="ltx_bibblock">
Harris, C., Stephens, M., et al.

</span>
<span class="ltx_bibblock">A combined corner and edge detector.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Alvey vision conference</em>, volume 15, pp.  10–5244.
Citeseer, 1988.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2017)</span>
<span class="ltx_bibblock">
He, K., Gkioxari, G., Dollár, P., and Girshick, R.

</span>
<span class="ltx_bibblock">Mask r-cnn.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the IEEE international conference on computer
vision</em>, pp.  2961–2969, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2020)</span>
<span class="ltx_bibblock">
He, Y., Sun, W., Huang, H., Liu, J., Fan, H., and Sun, J.

</span>
<span class="ltx_bibblock">Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose
estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.  11632–11641, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2021)</span>
<span class="ltx_bibblock">
He, Y., Huang, H., Fan, H., Chen, Q., and Sun, J.

</span>
<span class="ltx_bibblock">Ffb6d: A full flow bidirectional fusion network for 6d pose
estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.  3003–3013, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kappler et al. (2018)</span>
<span class="ltx_bibblock">
Kappler, D., Meier, F., Issac, J., Mainprice, J., Cifuentes, C. G.,
Wüthrich, M., Berenz, V., Schaal, S., Ratliff, N., and Bohg, J.

</span>
<span class="ltx_bibblock">Real-time perception meets reactive motion generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">IEEE Robotics and Automation Letters</em>, 3(3):1864–1871, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirillov et al. (2023)</span>
<span class="ltx_bibblock">
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
T., Whitehead, S., Berg, A. C., Lo, W.-Y., et al.

</span>
<span class="ltx_bibblock">Segment anything.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.  4015–4026, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Labbé et al. (2020)</span>
<span class="ltx_bibblock">
Labbé, Y., Carpentier, J., Aubry, M., and Sivic, J.

</span>
<span class="ltx_bibblock">Cosypose: Consistent multi-view multi-object 6d pose estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Computer Vision–ECCV 2020: 16th European Conference,
Glasgow, UK, August 23–28, 2020, Proceedings, Part XVII 16</em>, pp.  574–591.
Springer, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Labbé et al. (2022)</span>
<span class="ltx_bibblock">
Labbé, Y., Manuelli, L., Mousavian, A., Tyree, S., Birchfield, S.,
Tremblay, J., Carpentier, J., Aubry, M., Fox, D., and Sivic, J.

</span>
<span class="ltx_bibblock">Megapose: 6d pose estimation of novel objects via render &amp; compare.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2212.06870</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2023)</span>
<span class="ltx_bibblock">
Lee, T., Tremblay, J., Blukis, V., Wen, B., Lee, B.-U., Shin, I., Birchfield,
S., Kweon, I. S., and Yoon, K.-J.

</span>
<span class="ltx_bibblock">Tta-cope: Test-time adaptation for category-level object pose
estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  21285–21295, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2019)</span>
<span class="ltx_bibblock">
Li, Z., Wang, G., and Ji, X.

</span>
<span class="ltx_bibblock">Cdpn: Coordinates-based disentangled pose network for real-time
rgb-based 6-dof object pose estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the IEEE/CVF international conference on
computer vision</em>, pp.  7678–7687, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lindenberger et al. (2023)</span>
<span class="ltx_bibblock">
Lindenberger, P., Sarlin, P.-E., and Pollefeys, M.

</span>
<span class="ltx_bibblock">Lightglue: Local feature matching at light speed.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.  17627–17638, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lowe (2004)</span>
<span class="ltx_bibblock">
Lowe, D. G.

</span>
<span class="ltx_bibblock">Distinctive image features from scale-invariant keypoints.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International journal of computer vision</em>, 60:91–110, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marchand et al. (2015)</span>
<span class="ltx_bibblock">
Marchand, E., Uchiyama, H., and Spindler, F.

</span>
<span class="ltx_bibblock">Pose estimation for augmented reality: a hands-on survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">IEEE transactions on visualization and computer graphics</em>,
22(12):2633–2651, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishchuk et al. (2017)</span>
<span class="ltx_bibblock">
Mishchuk, A., Mishkin, D., Radenovic, F., and Matas, J.

</span>
<span class="ltx_bibblock">Working hard to know your neighbor's margins: Local
descriptor learning loss.

</span>
<span class="ltx_bibblock">In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R.,
Vishwanathan, S., and Garnett, R. (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural
Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/831caa1b600f852b7844499430ecac17-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2017/file/831caa1b600f852b7844499430ecac17-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. (2023)</span>
<span class="ltx_bibblock">
Nguyen, V. N., Groueix, T., Ponimatkin, G., Lepetit, V., and Hodan, T.

</span>
<span class="ltx_bibblock">Cnos: A strong baseline for cad-based novel object segmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.  2134–2140, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. (2019)</span>
<span class="ltx_bibblock">
Park, K., Patten, T., and Vincze, M.

</span>
<span class="ltx_bibblock">Pix2pose: Pixel-wise coordinate regression of objects for 6d pose
estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the IEEE/CVF international conference on
computer vision</em>, pp.  7668–7677, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pautrat et al. (2020)</span>
<span class="ltx_bibblock">
Pautrat, R., Larsson, V., Oswald, M. R., and Pollefeys, M.

</span>
<span class="ltx_bibblock">Online invariance selection for local feature descriptors.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Computer Vision–ECCV 2020: 16th European Conference,
Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16</em>, pp.  707–724.
Springer, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peyré et al. (2019)</span>
<span class="ltx_bibblock">
Peyré, G., Cuturi, M., et al.

</span>
<span class="ltx_bibblock">Computational optimal transport: With applications to data science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Foundations and Trends® in Machine Learning</em>,
11(5-6):355–607, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ravi et al. (2024)</span>
<span class="ltx_bibblock">
Ravi, N., Gabeur, V., Hu, Y.-T., Hu, R., Ryali, C., Ma, T., Khedr, H.,
Rädle, R., Rolland, C., Gustafson, L., et al.

</span>
<span class="ltx_bibblock">Sam 2: Segment anything in images and videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2408.00714</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Revaud et al. (2019)</span>
<span class="ltx_bibblock">
Revaud, J., De Souza, C., Humenberger, M., and Weinzaepfel, P.

</span>
<span class="ltx_bibblock">R2d2: Reliable and repeatable detector and descriptor.

</span>
<span class="ltx_bibblock">In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alché-Buc, F., Fox, E., and Garnett, R. (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Advances in Neural
Information Processing Systems</em>, volume 32. Curran Associates, Inc., 2019.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2019/file/3198dfd0aef271d22f7bcddd6f12f5cb-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2019/file/3198dfd0aef271d22f7bcddd6f12f5cb-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rosten &amp; Drummond (2006)</span>
<span class="ltx_bibblock">
Rosten, E. and Drummond, T.

</span>
<span class="ltx_bibblock">Machine learning for high-speed corner detection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Computer Vision–ECCV 2006: 9th European Conference on
Computer Vision, Graz, Austria, May 7-13, 2006. Proceedings, Part I 9</em>, pp. 430–443. Springer, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rublee et al. (2011)</span>
<span class="ltx_bibblock">
Rublee, E., Rabaud, V., Konolige, K., and Bradski, G.

</span>
<span class="ltx_bibblock">Orb: An efficient alternative to sift or surf.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">2011 International conference on computer vision</em>, pp. 2564–2571. Ieee, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarlin et al. (2020)</span>
<span class="ltx_bibblock">
Sarlin, P.-E., DeTone, D., Malisiewicz, T., and Rabinovich, A.

</span>
<span class="ltx_bibblock">Superglue: Learning feature matching with graph neural networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.  4938–4947, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shugurov et al. (2022)</span>
<span class="ltx_bibblock">
Shugurov, I., Li, F., Busam, B., and Ilic, S.

</span>
<span class="ltx_bibblock">Osop: A multi-stage one shot object pose estimation framework.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  6835–6844, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2021)</span>
<span class="ltx_bibblock">
Sun, J., Shen, Z., Wang, Y., Bao, H., and Zhou, X.

</span>
<span class="ltx_bibblock">Loftr: Detector-free local feature matching with transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.  8922–8931, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2020)</span>
<span class="ltx_bibblock">
Tian, M., Ang, M. H., and Lee, G. H.

</span>
<span class="ltx_bibblock">Shape prior deformation for categorical 6d object pose and size
estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Computer Vision–ECCV 2020: 16th European Conference,
Glasgow, UK, August 23–28, 2020, Proceedings, Part XXI 16</em>, pp.  530–546.
Springer, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2019)</span>
<span class="ltx_bibblock">
Tian, Y., Yu, X., Fan, B., Wu, F., Heijnen, H., and Balntas, V.

</span>
<span class="ltx_bibblock">Sosnet: Second order similarity regularization for local descriptor
learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em>, June 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tremblay et al. (2018)</span>
<span class="ltx_bibblock">
Tremblay, J., To, T., Sundaralingam, B., Xiang, Y., Fox, D., and Birchfield, S.

</span>
<span class="ltx_bibblock">Deep object pose estimation for semantic robotic grasping of
household objects.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:1809.10790</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tyszkiewicz et al. (2020)</span>
<span class="ltx_bibblock">
Tyszkiewicz, M., Fua, P., and Trulls, E.

</span>
<span class="ltx_bibblock">Disk: Learning local features with policy gradient.

</span>
<span class="ltx_bibblock">In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
(eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Advances in Neural Information Processing Systems</em>, volume 33,
pp.  14254–14265. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/a42a596fc71e17828440030074d15e74-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2020/file/a42a596fc71e17828440030074d15e74-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani (2017)</span>
<span class="ltx_bibblock">
Vaswani, A.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Advances in Neural Information Processing Systems</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2019)</span>
<span class="ltx_bibblock">
Wang, H., Sridhar, S., Huang, J., Valentin, J., Song, S., and Guibas, L. J.

</span>
<span class="ltx_bibblock">Normalized object coordinate space for category-level 6d object pose
and size estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  2642–2651, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2020)</span>
<span class="ltx_bibblock">
Wen, B., Mitash, C., Soorian, S., Kimmel, A., Sintov, A., and Bekris, K. E.

</span>
<span class="ltx_bibblock">Robust, occlusion-aware pose estimation for objects grasped by
adaptive hands.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">2020 IEEE International Conference on Robotics and
Automation (ICRA)</em>, pp.  6210–6217. IEEE, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2022a)</span>
<span class="ltx_bibblock">
Wen, B., Lian, W., Bekris, K., and Schaal, S.

</span>
<span class="ltx_bibblock">Catgrasp: Learning category-level task-relevant grasping in clutter
from simulation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">2022 International Conference on Robotics and Automation
(ICRA)</em>, pp.  6401–6408. IEEE, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2022b)</span>
<span class="ltx_bibblock">
Wen, B., Lian, W., Bekris, K., and Schaal, S.

</span>
<span class="ltx_bibblock">You only demonstrate once: Category-level manipulation from single
visual demonstration.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2201.12716</em>, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2024)</span>
<span class="ltx_bibblock">
Wen, B., Yang, W., Kautz, J., and Birchfield, S.

</span>
<span class="ltx_bibblock">Foundationpose: Unified 6d pose estimation and tracking of novel
objects.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  17868–17879, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang et al. (2017)</span>
<span class="ltx_bibblock">
Xiang, Y., Schmidt, T., Narayanan, V., and Fox, D.

</span>
<span class="ltx_bibblock">Posecnn: A convolutional neural network for 6d object pose estimation
in cluttered scenes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:1711.00199</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et al. (2016)</span>
<span class="ltx_bibblock">
Yi, K. M., Trulls, E., Lepetit, V., and Fua, P.

</span>
<span class="ltx_bibblock">Lift: Learned invariant feature transform.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Computer Vision–ECCV 2016: 14th European Conference,
Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VI 14</em>,
pp.  467–483. Springer, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yurtkulu et al. (2019)</span>
<span class="ltx_bibblock">
Yurtkulu, S. C., Şahin, Y. H., and Unal, G.

</span>
<span class="ltx_bibblock">Semantic segmentation with extended deeplabv3 architecture.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">2019 27th Signal Processing and Communications Applications
Conference (SIU)</em>, pp.  1–4. IEEE, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
Zhang, R., Di, Y., Manhardt, F., Tombari, F., and Ji, X.

</span>
<span class="ltx_bibblock">Ssp-pose: Symmetry-aware shape prior deformation for direct
category-level object pose estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">2022 IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS)</em>, pp.  7452–7459. IEEE, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Zhang, R., Jiang, Z., Guo, Z., Yan, S., Pan, J., Ma, X., Dong, H., Gao, P., and
Li, H.

</span>
<span class="ltx_bibblock">Personalize segment anything model with one shot.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2305.03048</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep 30 06:19:33 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
