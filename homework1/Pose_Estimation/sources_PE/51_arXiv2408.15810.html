<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation</title>
<!--Generated on Wed Aug 28 14:04:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="3D Human Pose Estimation Multi-view Fusion Human-Robot Collaboration" lang="en" name="keywords"/>
<base href="/html/2408.15810v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S1" title="In Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S2" title="In Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S2.SS0.SSS1" title="In 2 Related Work ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.1 </span>Multi-view 3D Human Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S2.SS0.SSS2" title="In 2 Related Work ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.2 </span>Absolute 3D Human Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S2.SS0.SSS3" title="In 2 Related Work ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.0.3 </span>Occlusion-Aware Human Pose Estimation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S3" title="In Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S3.SS1" title="In 3 Method ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Single-view 3D Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S3.SS2" title="In 3 Method ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Multi-view Fusion Module</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S3.SS3" title="In 3 Method ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Optimization Module</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4" title="In Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS1" title="In 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Settings and Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS1.SSS1" title="In 4.1 Experimental Settings and Metrics ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Human3.6M and Human3.6M-Occluded</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS1.SSS2" title="In 4.1 Experimental Settings and Metrics ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Human-Robot Workcell</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS1.SSS3" title="In 4.1 Experimental Settings and Metrics ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS1.SSS4" title="In 4.1 Experimental Settings and Metrics ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.4 </span>Implementation Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS2" title="In 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results on Human3.6M and Human3.6M-Occluded</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS3" title="In 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Results on the Human-Robot Workcell Scenario</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS4" title="In 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation Studies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS4.SSS1" title="In 4.4 Ablation Studies ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.1 </span>Camera Synchronization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.SS4.SSS2" title="In 4.4 Ablation Studies ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.2 </span>Number of Occluded Viewpoints</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S5" title="In Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Intelligent Autonomous Systems Lab, Department of
Information Engineering, University of Padova, 35131 Padua, Italy 
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{bragagnolo, terreran, allegrodav, ghidoni}@dei.unipd.it</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Laura Bragagnolo<span class="ltx_ERROR undefined" id="id1.1.id1">\orcidlink</span>0009-0007-8096-4588
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Matteo Terreran<span class="ltx_ERROR undefined" id="id2.1.id1">\orcidlink</span>0000-0001-9862-8469
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Davide Allegro<span class="ltx_ERROR undefined" id="id3.1.id1">\orcidlink</span>0009-0008-1180-9290
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Stefano Ghidoni<span class="ltx_ERROR undefined" id="id4.1.id1">\orcidlink</span>0000-0003-3406-8719
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Robust 3D human pose estimation is crucial to ensure safe and effective human-robot collaboration. Accurate human perception, however, is particularly challenging in these scenarios due to strong occlusions and limited camera viewpoints. Current 3D human pose estimation approaches are rather vulnerable in such conditions.
In this work we present a novel approach for robust 3D human pose estimation in the context of human-robot collaboration.
Instead of relying on noisy 2D features triangulation, we perform multi-view fusion on 3D skeletons provided by absolute monocular methods. Accurate 3D pose estimation is then obtained via reprojection error optimization, introducing limbs length symmetry constraints.
We evaluate our approach on the public dataset Human3.6M and on a novel version Human3.6M-Occluded, derived adding synthetic occlusions on the camera views with the purpose of testing pose estimation algorithms under severe occlusions. We further validate our method on real human-robot collaboration workcells, in which we strongly surpass current 3D human pose estimation methods.
Our approach outperforms state-of-the-art multi-view human pose estimation techniques and demonstrates superior capabilities in handling challenging scenarios with strong occlusions, representing a reliable and effective solution for real human-robot collaboration setups.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>3D Human Pose Estimation Multi-view Fusion Human-Robot Collaboration
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Three-dimensional human pose estimation is a fundamental task in computer vision, relevant for many applications, such as virtual reality¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib16" title="">16</a>]</cite>, sport analysis¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib2" title="">2</a>]</cite> and human action recognition¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib23" title="">23</a>]</cite>.
Accurate 3D human pose estimation is crucial for human-robot collaboration. Reliable 3D human perception is essential for robots to understand the exact position and motion of humans, effectively preventing collisions and ensuring safety. Human pose monitoring also helps in assessing and improving worker ergonomics, enhancing overall workplace health and productivity. Moreover, robust 3D human pose estimation is critical for precise and prompt recognition of human actions and intentions, that can enable smooth and efficient human-robot collaboration¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib28" title="">28</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In industrial scenarios, accurate human pose estimation is a real challenge. The typical setting includes a multi-camera setup that frames the human-robot collaboration area‚Äîcameras are usually very tilted and often not synchronized. Moreover, the human body is often only partially visible, as surrounding obstacles and equipment often occlude the subject.
Such conditions are very under-represented in 3D human pose estimation datasets, which are usually collected in very controlled environments.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">As multiple viewpoints are often available in human-robot collaboration workcells, most commonly adopted solutions are multi-view human pose estimation methods, that can accurately estimate 3D human joint position when camera calibration parameters are known. Most state-of-the-art multi-view approaches are, however, based on triangulation of 2D keypoints¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>, so they cannot handle significant amounts of occlusions and clutter, as 2D pose estimation quality quickly degrades under these conditions and good predictions cannot be recovered.
Recent monocular 3D human pose estimation methods have achieved remarkable results on public benchmarks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib34" title="">34</a>]</cite> and exhibit strong generalization to new and diverse scenarios¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib35" title="">35</a>]</cite>. On the other hand, when huge parts of the body are not visible, they tend to struggle with precise absolute scale prediction and reliable 3D joint configuration.
For these reasons, current human pose estimation systems are unsuitable for real industrial scenarios¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib1" title="">1</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we propose a novel multi-view 3D human pose estimation method based on the fusion of 3D keypoints from multiple viewpoints to achieve robust and reliable human pose prediction in human-robot collaboration settings, characterized by the presence of heavy occlusions and few camera viewpoints.
While many current approaches are based on multi-view fusion of 2D features and significantly suffer when human joints are obscured, we take as input 3D human pose predictions given by absolute monocular methods.
To mitigate joints position artifacts produced in presence of large occlusions, we leverage multiple viewpoints and introduce a novel multi-view 3D keypoint fusion module to merge single-view 3D pose predictions.
Considering per-joint reprojection errors on all camera views, we can effectively correct body pose hallucinations and scale recovery errors. Accurate 3D pose localization is then achieved thanks to an optimization procedure on the fused pose, considering reprojection errors on 2D views. The final prediction is further refined considering body symmetry constraints during optimization.
With respect to previous work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib3" title="">3</a>]</cite> we do not require any prior information or statistics about human limbs length.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We validate our method on data collected from real human-robot collaboration workcells and on Human3.6M-Occluded, a novel benchmark derived from the public dataset Human3.6M¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib10" title="">10</a>]</cite> adding synthetic occlusions on camera views.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">To summarise, the main contributions of this paper are:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">a multi-view 3D human pose estimation method based on per-joint multi-view fusion and optimization, designed to tackle common problems in complex real scenarios, such as occlusions;</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">limbs length symmetry constraints to refine 3D human pose, that do not depend on any prior information or statistics;</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">an analysis on robustness and generalization capabilities of multi-view 3D human pose estimation methods in real human-robot collaboration workcells;</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">the novel benchmark Human3.6M-Occluded, to test pose estimation algorithms under severe occlusions;</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S1.I1.i5.p1">
<p class="ltx_p" id="S1.I1.i5.p1.1">extensive evaluation and ablation studies considering multi-view 3D human pose estimation methods on the public dataset Human3.6M and on Human3.6M-Occluded.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsubsection" id="S2.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.1 </span>Multi-view 3D Human Pose Estimation</h4>
<div class="ltx_para" id="S2.SS0.SSS1.p1">
<p class="ltx_p" id="S2.SS0.SSS1.p1.1">Multi-view human pose estimation methods leverage multiple camera viewpoints to provide accurate human pose predictions in 3D space. They typically include two steps: first they extract 2D features from each view independently, and then reconstruct 3D information via triangulation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib9" title="">9</a>]</cite>. If triangulation-based approaches are very precise when provided with good quality 2D predictions, occluded environments are traditionally challenging for these methods, as 2D estimated poses tend to be very noisy.
Some approaches try to refine 2D predictions and triangulation incorporating epipolar geometry constraints: the epipolar transformer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib9" title="">9</a>]</cite> learns attention weights to fuse pixels along the epipolar line in neighboring views; Ma <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS1.p1.1.1">et al</em>.<span class="ltx_text" id="S2.SS0.SSS1.p1.1.2"></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite> introduce Transfusion, a transformer framework for multi-view 3D pose estimation, aiming at directly improving 2D predictions integrating information from different views via geometry position encoding. Similarly,¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib32" title="">32</a>]</cite> propose to leverage geometric correlations between views to refine 2D pose estimations.
Zhang <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS1.p1.1.3">et al</em>.<span class="ltx_text" id="S2.SS0.SSS1.p1.1.4"></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite> present AdaFuse, which tackles human pose estimation in presence of occlusions by learning an adaptive fusion weight to reduce the impact of poor quality views.
In¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib8" title="">8</a>]</cite> and¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib3" title="">3</a>]</cite> constraints on human limbs length are exploited in the human pose estimation process in order to boost accuracy and robustness. They, however, require knowledge about subject‚Äôs bones length or bone length statistics computed on the dataset of interest, making it difficult to apply such methods in unconstrained environments.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS1.p2">
<p class="ltx_p" id="S2.SS0.SSS1.p2.1">These methods typically do not generalize well to new scenarios and camera arrangements without extensive re-training and still struggle when dealing with strong occlusion. Therefore, they are not suitable to industrial multi-camera environments, which are prone to significant occlusions and in which collecting huge amounts of data for training may be impractical or even impossible.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.2 </span>Absolute 3D Human Pose Estimation</h4>
<div class="ltx_para" id="S2.SS0.SSS2.p1">
<p class="ltx_p" id="S2.SS0.SSS2.p1.1">Recently, many 3D human pose estimation approaches have focused on single-view images or videos¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib34" title="">34</a>]</cite>. This is an ill-posed problem, affected by depth ambiguities and occlusions. Most works¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib36" title="">36</a>]</cite> mainly focus on root-relative human pose estimation, which provide human pose predictions with respect to a reference frame centered in the pelvis joint (root). Nevertheless, for real-world applications such as human-robot collaboration, it is crucial to accurately estimate the human body pose in the global 3D space¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib23" title="">23</a>]</cite>. Pavlakos et al.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib22" title="">22</a>]</cite> used a simple anthropometric approach, optimizing the absolute person distance based on 2D pixel positions and root-relative depth estimates from volumetric heatmaps, ensuring that the back-projected skeleton‚Äôs bone lengths matched the average bone lengths from the training set. This method, however, has limited generalization power, as it requires pre-calculated statistics about human bone lengths.
Zhan <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS2.p1.1.1">et al</em>.<span class="ltx_text" id="S2.SS0.SSS2.p1.1.2"></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib33" title="">33</a>]</cite> use an intrinsic-parameter-invariant representation to convert the 2D keypoints from pixel space to 3D rays in a normalized 3D space; such rays are then fused from consecutive frames using temporal convolution. S√°r√°ndi <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS2.p1.1.3">et al</em>.<span class="ltx_text" id="S2.SS0.SSS2.p1.1.4"></span> introduce MeTRAbs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib24" title="">24</a>]</cite>, tackling scale and distance estimation of 3D poses while also addressing body occlusions. They train a fully-convolutional network to output location and depth heatmaps for 2D joints, providing accurate metric-scale depth information.
Still, when huge parts of the body are not visible, predicted scale and pose may be unreliable.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS0.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.0.3 </span>Occlusion-Aware Human Pose Estimation</h4>
<div class="ltx_para" id="S2.SS0.SSS3.p1">
<p class="ltx_p" id="S2.SS0.SSS3.p1.1">Occlusion-aware human pose estimation has been primarily addressed by root-relative single-view methods.
To boost resilience to missing joints, synthetically occluded data can be exploited during training, as suggested in¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib25" title="">25</a>]</cite>. Cheng <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS3.p1.1.1">et al</em>.<span class="ltx_text" id="S2.SS0.SSS3.p1.1.2"></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib4" title="">4</a>]</cite> make use of 2D confidence heatmaps of keypoints and introduce an optical-flow consistency constraint, to filter out the unreliable estimations. More recently, generative models have been successfully employed to retrieve occlusion-robust 3D pose, as in¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib36" title="">36</a>]</cite>. Several single-view datasets representing scenarios with occlusions, such as 3DPW-Occ¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib35" title="">35</a>]</cite> and 3DOH50K¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib35" title="">35</a>]</cite> have also been proposed. Such works tackle root-relative 3D human pose estimation from monocular images and videos and mainly focus on everyday life scenarios.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS3.p2">
<p class="ltx_p" id="S2.SS0.SSS3.p2.1">Our work addresses the gaps in the current literature by proposing an occlusion-aware 3D human pose estimation method from multi-view images, targeting human-robot collaboration environments. Differently from current multi-view approaches, mostly relying on 2D feature triangulation, we aggregate single-view 3D predictions from absolute human pose estimation algorithms, to achieve robustness against strong occlusions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The proposed method consists of three main parts: (i) single-view 3D pose prediction; (ii) multi-view 3D pose aggregation; (iii) 3D pose refinement based on reprojection error minimization.
In the first step, for each camera in the network, a candidate 3D pose is estimated by means of a monocular 3D human pose estimation algorithm, such as¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib33" title="">33</a>]</cite>.
The 3D poses obtained from each view are then aggregated together by means of a dedicated multi-view fusion module, which aims to combine all the independent single-view predictions in a same 3D pose. Finally, the aggregated 3D pose is further refined in an optimization module based on constrained reprojection error minimization.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Single-view 3D Pose Estimation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">As a first step, our approach takes as input multiple images captured simultaneously by <math alttext="C" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_C</annotation></semantics></math> cameras with known calibration parameters. Three-dimensional human poses are extracted from 2D images following a top-down approach: (i) a people detector finds all the possible patches containing a person, (ii) for each patch, a CNN predicts the 3D location of the human body joints with respect to the camera reference frame.
Our method assumes that all the cameras in the network are calibrated with respect to the same reference frame (e.g., robot base frame), so that the rotation <math alttext="R_{k}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">R</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ùëÖ</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">R_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and translation <math alttext="t_{k}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">t</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ùë°</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">t_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> of each camera <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_k</annotation></semantics></math> with respect to the reference frame are known.
For each view, the final output is a tuple of 3D poses, 2D bounding boxes and confidence scores.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multi-view Fusion Module</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Monocular 3D human pose estimation methods typically provide accurate and plausible body joint predictions when considering relative joint positions.
However, they typically struggle in estimating the absolute distance of each body joints from the camera, especially in presence of large body occlusions.
Moreover, when portions of the human body are not visible, there exists an ambiguity between distance and size: small objects close to the camera may look similar to large objects farther away from the camera <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib26" title="">26</a>]</cite>, leading to incorrect 3D pose prediction in metric space.
In order to alleviate this problem, we propose to leverage information from multiple views, from the intuition that averaging the absolute positions of the single-view estimations should give a good approximation of the true location of the human body.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.5">Consider a network of <math alttext="C" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_C</annotation></semantics></math> cameras and denote as <math alttext="\{\hat{P}_{j,i}\}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.3"><semantics id="S3.SS2.p2.2.m2.3a"><mrow id="S3.SS2.p2.2.m2.3.3.1" xref="S3.SS2.p2.2.m2.3.3.2.cmml"><mo id="S3.SS2.p2.2.m2.3.3.1.2" stretchy="false" xref="S3.SS2.p2.2.m2.3.3.2.cmml">{</mo><msub id="S3.SS2.p2.2.m2.3.3.1.1" xref="S3.SS2.p2.2.m2.3.3.1.1.cmml"><mover accent="true" id="S3.SS2.p2.2.m2.3.3.1.1.2" xref="S3.SS2.p2.2.m2.3.3.1.1.2.cmml"><mi id="S3.SS2.p2.2.m2.3.3.1.1.2.2" xref="S3.SS2.p2.2.m2.3.3.1.1.2.2.cmml">P</mi><mo id="S3.SS2.p2.2.m2.3.3.1.1.2.1" xref="S3.SS2.p2.2.m2.3.3.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p2.2.m2.2.2.2.4" xref="S3.SS2.p2.2.m2.2.2.2.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.cmml">j</mi><mo id="S3.SS2.p2.2.m2.2.2.2.4.1" xref="S3.SS2.p2.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.2.m2.2.2.2.2" xref="S3.SS2.p2.2.m2.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S3.SS2.p2.2.m2.3.3.1.3" stretchy="false" xref="S3.SS2.p2.2.m2.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.3b"><set id="S3.SS2.p2.2.m2.3.3.2.cmml" xref="S3.SS2.p2.2.m2.3.3.1"><apply id="S3.SS2.p2.2.m2.3.3.1.1.cmml" xref="S3.SS2.p2.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.3.3.1.1.1.cmml" xref="S3.SS2.p2.2.m2.3.3.1.1">subscript</csymbol><apply id="S3.SS2.p2.2.m2.3.3.1.1.2.cmml" xref="S3.SS2.p2.2.m2.3.3.1.1.2"><ci id="S3.SS2.p2.2.m2.3.3.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.3.3.1.1.2.1">^</ci><ci id="S3.SS2.p2.2.m2.3.3.1.1.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.1.1.2.2">ùëÉ</ci></apply><list id="S3.SS2.p2.2.m2.2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.2.2.2.4"><ci id="S3.SS2.p2.2.m2.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1">ùëó</ci><ci id="S3.SS2.p2.2.m2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2">ùëñ</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.3c">\{\hat{P}_{j,i}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.3d">{ over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT }</annotation></semantics></math> the set of 3D joints predicted from camera <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_i</annotation></semantics></math>. The <math alttext="j^{th}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><msup id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">j</mi><mrow id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p2.4.m4.1.1.3.1" xref="S3.SS2.p2.4.m4.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p2.4.m4.1.1.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ùëó</ci><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><times id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.1"></times><ci id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2">ùë°</ci><ci id="S3.SS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3">‚Ñé</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">j^{th}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_j start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> joint of the fused skeleton can be expressed as the weighted average of the <math alttext="j^{th}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><msup id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">j</mi><mrow id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p2.5.m5.1.1.3.1" xref="S3.SS2.p2.5.m5.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ùëó</ci><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><times id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3.1"></times><ci id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2">ùë°</ci><ci id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3">‚Ñé</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">j^{th}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_j start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT</annotation></semantics></math> joint for all single-view detections:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bar{P_{j}}=\frac{\sum_{i=1}^{C}w_{i}^{j}\hat{P}_{j,i}}{\sum_{i=1}^{C}w_{i}^{j%
}}~{}." class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mover accent="true" id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml"><msub id="S3.E1.m1.3.3.1.1.2.2" xref="S3.E1.m1.3.3.1.1.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.cmml">P</mi><mi id="S3.E1.m1.3.3.1.1.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.3.3.1.1.2.1" xref="S3.E1.m1.3.3.1.1.2.1.cmml">¬Ø</mo></mover><mo id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><msubsup id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.3.cmml"><mo id="S3.E1.m1.2.2.2.3.2.2" xref="S3.E1.m1.2.2.2.3.2.2.cmml">‚àë</mo><mrow id="S3.E1.m1.2.2.2.3.2.3" xref="S3.E1.m1.2.2.2.3.2.3.cmml"><mi id="S3.E1.m1.2.2.2.3.2.3.2" xref="S3.E1.m1.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.2.3.2.3.1" xref="S3.E1.m1.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.2.2.3.2.3.3" xref="S3.E1.m1.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.2.2.3.3" xref="S3.E1.m1.2.2.2.3.3.cmml">C</mi></msubsup><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.4.cmml"><msubsup id="S3.E1.m1.2.2.2.4.2" xref="S3.E1.m1.2.2.2.4.2.cmml"><mi id="S3.E1.m1.2.2.2.4.2.2.2" xref="S3.E1.m1.2.2.2.4.2.2.2.cmml">w</mi><mi id="S3.E1.m1.2.2.2.4.2.2.3" xref="S3.E1.m1.2.2.2.4.2.2.3.cmml">i</mi><mi id="S3.E1.m1.2.2.2.4.2.3" xref="S3.E1.m1.2.2.2.4.2.3.cmml">j</mi></msubsup><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.4.1.cmml">‚Å¢</mo><msub id="S3.E1.m1.2.2.2.4.3" xref="S3.E1.m1.2.2.2.4.3.cmml"><mover accent="true" id="S3.E1.m1.2.2.2.4.3.2" xref="S3.E1.m1.2.2.2.4.3.2.cmml"><mi id="S3.E1.m1.2.2.2.4.3.2.2" xref="S3.E1.m1.2.2.2.4.3.2.2.cmml">P</mi><mo id="S3.E1.m1.2.2.2.4.3.2.1" xref="S3.E1.m1.2.2.2.4.3.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">j</mi><mo id="S3.E1.m1.2.2.2.2.2.4.1" xref="S3.E1.m1.2.2.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.cmml">i</mi></mrow></msub></mrow></mrow><mrow id="S3.E1.m1.2.2.4" xref="S3.E1.m1.2.2.4.cmml"><msubsup id="S3.E1.m1.2.2.4.1" xref="S3.E1.m1.2.2.4.1.cmml"><mo id="S3.E1.m1.2.2.4.1.2.2" xref="S3.E1.m1.2.2.4.1.2.2.cmml">‚àë</mo><mrow id="S3.E1.m1.2.2.4.1.2.3" xref="S3.E1.m1.2.2.4.1.2.3.cmml"><mi id="S3.E1.m1.2.2.4.1.2.3.2" xref="S3.E1.m1.2.2.4.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.4.1.2.3.1" xref="S3.E1.m1.2.2.4.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.2.2.4.1.2.3.3" xref="S3.E1.m1.2.2.4.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.2.4.1.3" xref="S3.E1.m1.2.2.4.1.3.cmml">C</mi></msubsup><msubsup id="S3.E1.m1.2.2.4.2" xref="S3.E1.m1.2.2.4.2.cmml"><mi id="S3.E1.m1.2.2.4.2.2.2" xref="S3.E1.m1.2.2.4.2.2.2.cmml">w</mi><mi id="S3.E1.m1.2.2.4.2.2.3" xref="S3.E1.m1.2.2.4.2.2.3.cmml">i</mi><mi id="S3.E1.m1.2.2.4.2.3" xref="S3.E1.m1.2.2.4.2.3.cmml">j</mi></msubsup></mrow></mfrac></mrow><mo id="S3.E1.m1.3.3.1.2" lspace="0.330em" xref="S3.E1.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"></eq><apply id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"><ci id="S3.E1.m1.3.3.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2.1">¬Ø</ci><apply id="S3.E1.m1.3.3.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2">ùëÉ</ci><ci id="S3.E1.m1.3.3.1.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3">ùëó</ci></apply></apply><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><divide id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2"></divide><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><apply id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.3">superscript</csymbol><apply id="S3.E1.m1.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.3.2.1.cmml" xref="S3.E1.m1.2.2.2.3">subscript</csymbol><sum id="S3.E1.m1.2.2.2.3.2.2.cmml" xref="S3.E1.m1.2.2.2.3.2.2"></sum><apply id="S3.E1.m1.2.2.2.3.2.3.cmml" xref="S3.E1.m1.2.2.2.3.2.3"><eq id="S3.E1.m1.2.2.2.3.2.3.1.cmml" xref="S3.E1.m1.2.2.2.3.2.3.1"></eq><ci id="S3.E1.m1.2.2.2.3.2.3.2.cmml" xref="S3.E1.m1.2.2.2.3.2.3.2">ùëñ</ci><cn id="S3.E1.m1.2.2.2.3.2.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.3.3">ùê∂</ci></apply><apply id="S3.E1.m1.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.4"><times id="S3.E1.m1.2.2.2.4.1.cmml" xref="S3.E1.m1.2.2.2.4.1"></times><apply id="S3.E1.m1.2.2.2.4.2.cmml" xref="S3.E1.m1.2.2.2.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.4.2.1.cmml" xref="S3.E1.m1.2.2.2.4.2">superscript</csymbol><apply id="S3.E1.m1.2.2.2.4.2.2.cmml" xref="S3.E1.m1.2.2.2.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.4.2.2.1.cmml" xref="S3.E1.m1.2.2.2.4.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.4.2.2.2.cmml" xref="S3.E1.m1.2.2.2.4.2.2.2">ùë§</ci><ci id="S3.E1.m1.2.2.2.4.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4.2.2.3">ùëñ</ci></apply><ci id="S3.E1.m1.2.2.2.4.2.3.cmml" xref="S3.E1.m1.2.2.2.4.2.3">ùëó</ci></apply><apply id="S3.E1.m1.2.2.2.4.3.cmml" xref="S3.E1.m1.2.2.2.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.2.4.3">subscript</csymbol><apply id="S3.E1.m1.2.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.2.4.3.2"><ci id="S3.E1.m1.2.2.2.4.3.2.1.cmml" xref="S3.E1.m1.2.2.2.4.3.2.1">^</ci><ci id="S3.E1.m1.2.2.2.4.3.2.2.cmml" xref="S3.E1.m1.2.2.2.4.3.2.2">ùëÉ</ci></apply><list id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">ùëó</ci><ci id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2">ùëñ</ci></list></apply></apply></apply><apply id="S3.E1.m1.2.2.4.cmml" xref="S3.E1.m1.2.2.4"><apply id="S3.E1.m1.2.2.4.1.cmml" xref="S3.E1.m1.2.2.4.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.4.1.1.cmml" xref="S3.E1.m1.2.2.4.1">superscript</csymbol><apply id="S3.E1.m1.2.2.4.1.2.cmml" xref="S3.E1.m1.2.2.4.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.4.1.2.1.cmml" xref="S3.E1.m1.2.2.4.1">subscript</csymbol><sum id="S3.E1.m1.2.2.4.1.2.2.cmml" xref="S3.E1.m1.2.2.4.1.2.2"></sum><apply id="S3.E1.m1.2.2.4.1.2.3.cmml" xref="S3.E1.m1.2.2.4.1.2.3"><eq id="S3.E1.m1.2.2.4.1.2.3.1.cmml" xref="S3.E1.m1.2.2.4.1.2.3.1"></eq><ci id="S3.E1.m1.2.2.4.1.2.3.2.cmml" xref="S3.E1.m1.2.2.4.1.2.3.2">ùëñ</ci><cn id="S3.E1.m1.2.2.4.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.4.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.2.4.1.3.cmml" xref="S3.E1.m1.2.2.4.1.3">ùê∂</ci></apply><apply id="S3.E1.m1.2.2.4.2.cmml" xref="S3.E1.m1.2.2.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.4.2.1.cmml" xref="S3.E1.m1.2.2.4.2">superscript</csymbol><apply id="S3.E1.m1.2.2.4.2.2.cmml" xref="S3.E1.m1.2.2.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.4.2.2.1.cmml" xref="S3.E1.m1.2.2.4.2">subscript</csymbol><ci id="S3.E1.m1.2.2.4.2.2.2.cmml" xref="S3.E1.m1.2.2.4.2.2.2">ùë§</ci><ci id="S3.E1.m1.2.2.4.2.2.3.cmml" xref="S3.E1.m1.2.2.4.2.2.3">ùëñ</ci></apply><ci id="S3.E1.m1.2.2.4.2.3.cmml" xref="S3.E1.m1.2.2.4.2.3">ùëó</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\bar{P_{j}}=\frac{\sum_{i=1}^{C}w_{i}^{j}\hat{P}_{j,i}}{\sum_{i=1}^{C}w_{i}^{j%
}}~{}.</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">over¬Ø start_ARG italic_P start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG = divide start_ARG ‚àë start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT end_ARG start_ARG ‚àë start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p2.6">The use of weights <math alttext="w_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m1.1"><semantics id="S3.SS2.p2.6.m1.1a"><msub id="S3.SS2.p2.6.m1.1.1" xref="S3.SS2.p2.6.m1.1.1.cmml"><mi id="S3.SS2.p2.6.m1.1.1.2" xref="S3.SS2.p2.6.m1.1.1.2.cmml">w</mi><mi id="S3.SS2.p2.6.m1.1.1.3" xref="S3.SS2.p2.6.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m1.1b"><apply id="S3.SS2.p2.6.m1.1.1.cmml" xref="S3.SS2.p2.6.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m1.1.1.1.cmml" xref="S3.SS2.p2.6.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m1.1.1.2.cmml" xref="S3.SS2.p2.6.m1.1.1.2">ùë§</ci><ci id="S3.SS2.p2.6.m1.1.1.3.cmml" xref="S3.SS2.p2.6.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m1.1c">w_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m1.1d">italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> allows to penalize the views framing the subject from a higher distance or the detections with lower confidence.
When the human body is partially or heavily occluded, in fact, the 3D pose obtained from monocular 3D pose estimation methods is not fully reliable: if some parts of the body are not visible, the pose estimation algorithm uses clues from the visible parts to estimate the positions of the missing joints. Significant occlusions reduce evidence for the obscured joints‚Äô positions, leading to incorrect final predictions compared to the true pose. For instance, if a person‚Äôs legs are occluded by a table, the model lacks evidence to determine whether the person is standing with crossed, bent or straight legs.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">To better incorporate all the available information, we propose the use of per-joint weights: if a 3D joint (<em class="ltx_emph ltx_font_italic" id="S3.SS2.p3.1.1">e.g</em>.<span class="ltx_text" id="S3.SS2.p3.1.2"></span> the right ankle) is incorrectly predicted in one view, the error given by projecting that joint over all the other views will be higher with respect to the reprojection error computed for that same joint correctly predicted from another view.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.9">In particular, given the set <math alttext="\{\hat{P}_{j,i}\}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.3"><semantics id="S3.SS2.p4.1.m1.3a"><mrow id="S3.SS2.p4.1.m1.3.3.1" xref="S3.SS2.p4.1.m1.3.3.2.cmml"><mo id="S3.SS2.p4.1.m1.3.3.1.2" stretchy="false" xref="S3.SS2.p4.1.m1.3.3.2.cmml">{</mo><msub id="S3.SS2.p4.1.m1.3.3.1.1" xref="S3.SS2.p4.1.m1.3.3.1.1.cmml"><mover accent="true" id="S3.SS2.p4.1.m1.3.3.1.1.2" xref="S3.SS2.p4.1.m1.3.3.1.1.2.cmml"><mi id="S3.SS2.p4.1.m1.3.3.1.1.2.2" xref="S3.SS2.p4.1.m1.3.3.1.1.2.2.cmml">P</mi><mo id="S3.SS2.p4.1.m1.3.3.1.1.2.1" xref="S3.SS2.p4.1.m1.3.3.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p4.1.m1.2.2.2.4" xref="S3.SS2.p4.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.1.1" xref="S3.SS2.p4.1.m1.1.1.1.1.cmml">j</mi><mo id="S3.SS2.p4.1.m1.2.2.2.4.1" xref="S3.SS2.p4.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.1.m1.2.2.2.2" xref="S3.SS2.p4.1.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S3.SS2.p4.1.m1.3.3.1.3" stretchy="false" xref="S3.SS2.p4.1.m1.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.3b"><set id="S3.SS2.p4.1.m1.3.3.2.cmml" xref="S3.SS2.p4.1.m1.3.3.1"><apply id="S3.SS2.p4.1.m1.3.3.1.1.cmml" xref="S3.SS2.p4.1.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.3.3.1.1.1.cmml" xref="S3.SS2.p4.1.m1.3.3.1.1">subscript</csymbol><apply id="S3.SS2.p4.1.m1.3.3.1.1.2.cmml" xref="S3.SS2.p4.1.m1.3.3.1.1.2"><ci id="S3.SS2.p4.1.m1.3.3.1.1.2.1.cmml" xref="S3.SS2.p4.1.m1.3.3.1.1.2.1">^</ci><ci id="S3.SS2.p4.1.m1.3.3.1.1.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.1.1.2.2">ùëÉ</ci></apply><list id="S3.SS2.p4.1.m1.2.2.2.3.cmml" xref="S3.SS2.p4.1.m1.2.2.2.4"><ci id="S3.SS2.p4.1.m1.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1.1">ùëó</ci><ci id="S3.SS2.p4.1.m1.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.2.2.2.2">ùëñ</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.3c">\{\hat{P}_{j,i}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.3d">{ over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT }</annotation></semantics></math> of 3D joints predicted from camera <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_i</annotation></semantics></math>, a single joint <math alttext="\hat{P}_{j,i}" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.2"><semantics id="S3.SS2.p4.3.m3.2a"><msub id="S3.SS2.p4.3.m3.2.3" xref="S3.SS2.p4.3.m3.2.3.cmml"><mover accent="true" id="S3.SS2.p4.3.m3.2.3.2" xref="S3.SS2.p4.3.m3.2.3.2.cmml"><mi id="S3.SS2.p4.3.m3.2.3.2.2" xref="S3.SS2.p4.3.m3.2.3.2.2.cmml">P</mi><mo id="S3.SS2.p4.3.m3.2.3.2.1" xref="S3.SS2.p4.3.m3.2.3.2.1.cmml">^</mo></mover><mrow id="S3.SS2.p4.3.m3.2.2.2.4" xref="S3.SS2.p4.3.m3.2.2.2.3.cmml"><mi id="S3.SS2.p4.3.m3.1.1.1.1" xref="S3.SS2.p4.3.m3.1.1.1.1.cmml">j</mi><mo id="S3.SS2.p4.3.m3.2.2.2.4.1" xref="S3.SS2.p4.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.3.m3.2.2.2.2" xref="S3.SS2.p4.3.m3.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.2b"><apply id="S3.SS2.p4.3.m3.2.3.cmml" xref="S3.SS2.p4.3.m3.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.2.3.1.cmml" xref="S3.SS2.p4.3.m3.2.3">subscript</csymbol><apply id="S3.SS2.p4.3.m3.2.3.2.cmml" xref="S3.SS2.p4.3.m3.2.3.2"><ci id="S3.SS2.p4.3.m3.2.3.2.1.cmml" xref="S3.SS2.p4.3.m3.2.3.2.1">^</ci><ci id="S3.SS2.p4.3.m3.2.3.2.2.cmml" xref="S3.SS2.p4.3.m3.2.3.2.2">ùëÉ</ci></apply><list id="S3.SS2.p4.3.m3.2.2.2.3.cmml" xref="S3.SS2.p4.3.m3.2.2.2.4"><ci id="S3.SS2.p4.3.m3.1.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1.1.1">ùëó</ci><ci id="S3.SS2.p4.3.m3.2.2.2.2.cmml" xref="S3.SS2.p4.3.m3.2.2.2.2">ùëñ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.2c">\hat{P}_{j,i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.2d">over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> can be easily projected onto the image plane of a camera <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">italic_k</annotation></semantics></math> by means of the camera intrinsic parameters <math alttext="K_{k}" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m5.1"><semantics id="S3.SS2.p4.5.m5.1a"><msub id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml">K</mi><mi id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2">ùêæ</ci><ci id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">K_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m5.1d">italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and extrinsic parameters <math alttext="R_{k}" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m6.1"><semantics id="S3.SS2.p4.6.m6.1a"><msub id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mi id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">R</mi><mi id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2">ùëÖ</ci><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">R_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m6.1d">italic_R start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="t_{k}" class="ltx_Math" display="inline" id="S3.SS2.p4.7.m7.1"><semantics id="S3.SS2.p4.7.m7.1a"><msub id="S3.SS2.p4.7.m7.1.1" xref="S3.SS2.p4.7.m7.1.1.cmml"><mi id="S3.SS2.p4.7.m7.1.1.2" xref="S3.SS2.p4.7.m7.1.1.2.cmml">t</mi><mi id="S3.SS2.p4.7.m7.1.1.3" xref="S3.SS2.p4.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m7.1b"><apply id="S3.SS2.p4.7.m7.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m7.1.1.2.cmml" xref="S3.SS2.p4.7.m7.1.1.2">ùë°</ci><ci id="S3.SS2.p4.7.m7.1.1.3.cmml" xref="S3.SS2.p4.7.m7.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m7.1c">t_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.7.m7.1d">italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>.
Averaging the reprojection error between the 2D joints and the predictions on each frame <math alttext="\{p_{j,i}\}" class="ltx_Math" display="inline" id="S3.SS2.p4.8.m8.3"><semantics id="S3.SS2.p4.8.m8.3a"><mrow id="S3.SS2.p4.8.m8.3.3.1" xref="S3.SS2.p4.8.m8.3.3.2.cmml"><mo id="S3.SS2.p4.8.m8.3.3.1.2" stretchy="false" xref="S3.SS2.p4.8.m8.3.3.2.cmml">{</mo><msub id="S3.SS2.p4.8.m8.3.3.1.1" xref="S3.SS2.p4.8.m8.3.3.1.1.cmml"><mi id="S3.SS2.p4.8.m8.3.3.1.1.2" xref="S3.SS2.p4.8.m8.3.3.1.1.2.cmml">p</mi><mrow id="S3.SS2.p4.8.m8.2.2.2.4" xref="S3.SS2.p4.8.m8.2.2.2.3.cmml"><mi id="S3.SS2.p4.8.m8.1.1.1.1" xref="S3.SS2.p4.8.m8.1.1.1.1.cmml">j</mi><mo id="S3.SS2.p4.8.m8.2.2.2.4.1" xref="S3.SS2.p4.8.m8.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.8.m8.2.2.2.2" xref="S3.SS2.p4.8.m8.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S3.SS2.p4.8.m8.3.3.1.3" stretchy="false" xref="S3.SS2.p4.8.m8.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.8.m8.3b"><set id="S3.SS2.p4.8.m8.3.3.2.cmml" xref="S3.SS2.p4.8.m8.3.3.1"><apply id="S3.SS2.p4.8.m8.3.3.1.1.cmml" xref="S3.SS2.p4.8.m8.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.8.m8.3.3.1.1.1.cmml" xref="S3.SS2.p4.8.m8.3.3.1.1">subscript</csymbol><ci id="S3.SS2.p4.8.m8.3.3.1.1.2.cmml" xref="S3.SS2.p4.8.m8.3.3.1.1.2">ùëù</ci><list id="S3.SS2.p4.8.m8.2.2.2.3.cmml" xref="S3.SS2.p4.8.m8.2.2.2.4"><ci id="S3.SS2.p4.8.m8.1.1.1.1.cmml" xref="S3.SS2.p4.8.m8.1.1.1.1">ùëó</ci><ci id="S3.SS2.p4.8.m8.2.2.2.2.cmml" xref="S3.SS2.p4.8.m8.2.2.2.2">ùëñ</ci></list></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.8.m8.3c">\{p_{j,i}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.8.m8.3d">{ italic_p start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT }</annotation></semantics></math>, allows to define the per-joint weight <math alttext="w_{j,i}" class="ltx_Math" display="inline" id="S3.SS2.p4.9.m9.2"><semantics id="S3.SS2.p4.9.m9.2a"><msub id="S3.SS2.p4.9.m9.2.3" xref="S3.SS2.p4.9.m9.2.3.cmml"><mi id="S3.SS2.p4.9.m9.2.3.2" xref="S3.SS2.p4.9.m9.2.3.2.cmml">w</mi><mrow id="S3.SS2.p4.9.m9.2.2.2.4" xref="S3.SS2.p4.9.m9.2.2.2.3.cmml"><mi id="S3.SS2.p4.9.m9.1.1.1.1" xref="S3.SS2.p4.9.m9.1.1.1.1.cmml">j</mi><mo id="S3.SS2.p4.9.m9.2.2.2.4.1" xref="S3.SS2.p4.9.m9.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.9.m9.2.2.2.2" xref="S3.SS2.p4.9.m9.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.9.m9.2b"><apply id="S3.SS2.p4.9.m9.2.3.cmml" xref="S3.SS2.p4.9.m9.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.9.m9.2.3.1.cmml" xref="S3.SS2.p4.9.m9.2.3">subscript</csymbol><ci id="S3.SS2.p4.9.m9.2.3.2.cmml" xref="S3.SS2.p4.9.m9.2.3.2">ùë§</ci><list id="S3.SS2.p4.9.m9.2.2.2.3.cmml" xref="S3.SS2.p4.9.m9.2.2.2.4"><ci id="S3.SS2.p4.9.m9.1.1.1.1.cmml" xref="S3.SS2.p4.9.m9.1.1.1.1">ùëó</ci><ci id="S3.SS2.p4.9.m9.2.2.2.2.cmml" xref="S3.SS2.p4.9.m9.2.2.2.2">ùëñ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.9.m9.2c">w_{j,i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.9.m9.2d">italic_w start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="w_{j,i}=\frac{1}{{e}_{j,i}}~{},\qquad{e}_{j,i}=\frac{1}{C}\sum_{k=1}^{C}\left%
\|[{K_{k}}|\vec{0}][{R_{k}}|{t_{k}}]\hat{P}_{j,i}-{p}_{j,k}\right\|^{2}~{}." class="ltx_math_unparsed" display="block" id="S3.E2.m1.10"><semantics id="S3.E2.m1.10a"><mrow id="S3.E2.m1.10b"><msub id="S3.E2.m1.10.11"><mi id="S3.E2.m1.10.11.2">w</mi><mrow id="S3.E2.m1.2.2.2.4"><mi id="S3.E2.m1.1.1.1.1">j</mi><mo id="S3.E2.m1.2.2.2.4.1">,</mo><mi id="S3.E2.m1.2.2.2.2">i</mi></mrow></msub><mo id="S3.E2.m1.10.12">=</mo><mfrac id="S3.E2.m1.4.4"><mn id="S3.E2.m1.4.4.4">1</mn><msub id="S3.E2.m1.4.4.2"><mi id="S3.E2.m1.4.4.2.4">e</mi><mrow id="S3.E2.m1.4.4.2.2.2.4"><mi id="S3.E2.m1.3.3.1.1.1.1">j</mi><mo id="S3.E2.m1.4.4.2.2.2.4.1">,</mo><mi id="S3.E2.m1.4.4.2.2.2.2">i</mi></mrow></msub></mfrac><mo id="S3.E2.m1.10.13" lspace="0.330em" rspace="2.167em">,</mo><msub id="S3.E2.m1.10.14"><mi id="S3.E2.m1.10.14.2">e</mi><mrow id="S3.E2.m1.6.6.2.4"><mi id="S3.E2.m1.5.5.1.1">j</mi><mo id="S3.E2.m1.6.6.2.4.1">,</mo><mi id="S3.E2.m1.6.6.2.2">i</mi></mrow></msub><mo id="S3.E2.m1.10.15">=</mo><mfrac id="S3.E2.m1.10.16"><mn id="S3.E2.m1.10.16.2">1</mn><mi id="S3.E2.m1.10.16.3">C</mi></mfrac><munderover id="S3.E2.m1.10.17"><mo id="S3.E2.m1.10.17.2.2" movablelimits="false" rspace="0em">‚àë</mo><mrow id="S3.E2.m1.10.17.2.3"><mi id="S3.E2.m1.10.17.2.3.2">k</mi><mo id="S3.E2.m1.10.17.2.3.1">=</mo><mn id="S3.E2.m1.10.17.2.3.3">1</mn></mrow><mi id="S3.E2.m1.10.17.3">C</mi></munderover><mo id="S3.E2.m1.10.18" lspace="0em" rspace="0.167em" stretchy="true">‚à•</mo><mrow id="S3.E2.m1.10.19"><mo id="S3.E2.m1.10.19.1" stretchy="false">[</mo><msub id="S3.E2.m1.10.19.2"><mi id="S3.E2.m1.10.19.2.2">K</mi><mi id="S3.E2.m1.10.19.2.3">k</mi></msub><mo fence="false" id="S3.E2.m1.10.19.3" rspace="0.167em" stretchy="false">|</mo><mover accent="true" id="S3.E2.m1.10.19.4"><mn id="S3.E2.m1.10.19.4.2">0</mn><mo id="S3.E2.m1.10.19.4.1" stretchy="false">‚Üí</mo></mover><mo id="S3.E2.m1.10.19.5" stretchy="false">]</mo></mrow><mrow id="S3.E2.m1.10.20"><mo id="S3.E2.m1.10.20.1" stretchy="false">[</mo><msub id="S3.E2.m1.10.20.2"><mi id="S3.E2.m1.10.20.2.2">R</mi><mi id="S3.E2.m1.10.20.2.3">k</mi></msub><mo fence="false" id="S3.E2.m1.10.20.3" rspace="0.167em" stretchy="false">|</mo><msub id="S3.E2.m1.10.20.4"><mi id="S3.E2.m1.10.20.4.2">t</mi><mi id="S3.E2.m1.10.20.4.3">k</mi></msub><mo id="S3.E2.m1.10.20.5" stretchy="false">]</mo></mrow><msub id="S3.E2.m1.10.21"><mover accent="true" id="S3.E2.m1.10.21.2"><mi id="S3.E2.m1.10.21.2.2">P</mi><mo id="S3.E2.m1.10.21.2.1">^</mo></mover><mrow id="S3.E2.m1.8.8.2.4"><mi id="S3.E2.m1.7.7.1.1">j</mi><mo id="S3.E2.m1.8.8.2.4.1">,</mo><mi id="S3.E2.m1.8.8.2.2">i</mi></mrow></msub><mo id="S3.E2.m1.10.22">‚àí</mo><msub id="S3.E2.m1.10.23"><mi id="S3.E2.m1.10.23.2">p</mi><mrow id="S3.E2.m1.10.10.2.4"><mi id="S3.E2.m1.9.9.1.1">j</mi><mo id="S3.E2.m1.10.10.2.4.1">,</mo><mi id="S3.E2.m1.10.10.2.2">k</mi></mrow></msub><msup id="S3.E2.m1.10.24"><mo id="S3.E2.m1.10.24.2" lspace="0em" rspace="0.0835em" stretchy="true">‚à•</mo><mn id="S3.E2.m1.10.24.3">2</mn></msup><mo id="S3.E2.m1.10.25" lspace="0.0835em">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.10c">w_{j,i}=\frac{1}{{e}_{j,i}}~{},\qquad{e}_{j,i}=\frac{1}{C}\sum_{k=1}^{C}\left%
\|[{K_{k}}|\vec{0}][{R_{k}}|{t_{k}}]\hat{P}_{j,i}-{p}_{j,k}\right\|^{2}~{}.</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.10d">italic_w start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_e start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT end_ARG , italic_e start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_C end_ARG ‚àë start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT ‚à• [ italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT | over‚Üí start_ARG 0 end_ARG ] [ italic_R start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT - italic_p start_POSTSUBSCRIPT italic_j , italic_k end_POSTSUBSCRIPT ‚à• start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Optimization Module</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">The fusion module merges multi-view 3D predictions, leveraging multiple viewpoints to mitigate artifacts in joint positions caused by occluded body parts. However, when significant occlusions occur in multiple camera views, averaging predictions may not suffice, as estimated pose and camera distance can be slightly incorrect in all views.
To address this issue, we formulate an optimization problem to refine the fused 3D pose <math alttext="\bar{P_{j}}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mover accent="true" id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">P</mi><mi id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">¬Ø</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><ci id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1">¬Ø</ci><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.2">ùëÉ</ci><ci id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3">ùëó</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\bar{P_{j}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">over¬Ø start_ARG italic_P start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG</annotation></semantics></math>, minimizing the per-joint reprojection error across all <math alttext="C" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_C</annotation></semantics></math> cameras available:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\underset{\bar{P_{j}}}{\mathrm{argmin}}\ \ \sum_{k=1}^{C}\sum_{j=1}^{J}\left\|%
[{K_{k}}|\vec{0}][{R_{k}}|{t_{k}}]\bar{P}_{j,i}-{p}_{j,k}\right\|^{2}~{}." class="ltx_math_unparsed" display="block" id="S3.E3.m1.5"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5b"><munder accentunder="true" id="S3.E3.m1.5.5"><mi id="S3.E3.m1.5.5.2">argmin</mi><mover accent="true" id="S3.E3.m1.5.5.1"><msub id="S3.E3.m1.5.5.1.2"><mi id="S3.E3.m1.5.5.1.2.2">P</mi><mi id="S3.E3.m1.5.5.1.2.3">j</mi></msub><mo id="S3.E3.m1.5.5.1.1">¬Ø</mo></mover></munder><mspace id="S3.E3.m1.5.6" width="1em"></mspace><munderover id="S3.E3.m1.5.7"><mo id="S3.E3.m1.5.7.2.2" movablelimits="false" rspace="0em">‚àë</mo><mrow id="S3.E3.m1.5.7.2.3"><mi id="S3.E3.m1.5.7.2.3.2">k</mi><mo id="S3.E3.m1.5.7.2.3.1">=</mo><mn id="S3.E3.m1.5.7.2.3.3">1</mn></mrow><mi id="S3.E3.m1.5.7.3">C</mi></munderover><munderover id="S3.E3.m1.5.8"><mo id="S3.E3.m1.5.8.2.2" movablelimits="false" rspace="0em">‚àë</mo><mrow id="S3.E3.m1.5.8.2.3"><mi id="S3.E3.m1.5.8.2.3.2">j</mi><mo id="S3.E3.m1.5.8.2.3.1">=</mo><mn id="S3.E3.m1.5.8.2.3.3">1</mn></mrow><mi id="S3.E3.m1.5.8.3">J</mi></munderover><mo id="S3.E3.m1.5.9" lspace="0em" rspace="0.167em" stretchy="true">‚à•</mo><mrow id="S3.E3.m1.5.10"><mo id="S3.E3.m1.5.10.1" stretchy="false">[</mo><msub id="S3.E3.m1.5.10.2"><mi id="S3.E3.m1.5.10.2.2">K</mi><mi id="S3.E3.m1.5.10.2.3">k</mi></msub><mo fence="false" id="S3.E3.m1.5.10.3" rspace="0.167em" stretchy="false">|</mo><mover accent="true" id="S3.E3.m1.5.10.4"><mn id="S3.E3.m1.5.10.4.2">0</mn><mo id="S3.E3.m1.5.10.4.1" stretchy="false">‚Üí</mo></mover><mo id="S3.E3.m1.5.10.5" stretchy="false">]</mo></mrow><mrow id="S3.E3.m1.5.11"><mo id="S3.E3.m1.5.11.1" stretchy="false">[</mo><msub id="S3.E3.m1.5.11.2"><mi id="S3.E3.m1.5.11.2.2">R</mi><mi id="S3.E3.m1.5.11.2.3">k</mi></msub><mo fence="false" id="S3.E3.m1.5.11.3" rspace="0.167em" stretchy="false">|</mo><msub id="S3.E3.m1.5.11.4"><mi id="S3.E3.m1.5.11.4.2">t</mi><mi id="S3.E3.m1.5.11.4.3">k</mi></msub><mo id="S3.E3.m1.5.11.5" stretchy="false">]</mo></mrow><msub id="S3.E3.m1.5.12"><mover accent="true" id="S3.E3.m1.5.12.2"><mi id="S3.E3.m1.5.12.2.2">P</mi><mo id="S3.E3.m1.5.12.2.1">¬Ø</mo></mover><mrow id="S3.E3.m1.2.2.2.4"><mi id="S3.E3.m1.1.1.1.1">j</mi><mo id="S3.E3.m1.2.2.2.4.1">,</mo><mi id="S3.E3.m1.2.2.2.2">i</mi></mrow></msub><mo id="S3.E3.m1.5.13">‚àí</mo><msub id="S3.E3.m1.5.14"><mi id="S3.E3.m1.5.14.2">p</mi><mrow id="S3.E3.m1.4.4.2.4"><mi id="S3.E3.m1.3.3.1.1">j</mi><mo id="S3.E3.m1.4.4.2.4.1">,</mo><mi id="S3.E3.m1.4.4.2.2">k</mi></mrow></msub><msup id="S3.E3.m1.5.15"><mo id="S3.E3.m1.5.15.2" lspace="0em" rspace="0.0835em" stretchy="true">‚à•</mo><mn id="S3.E3.m1.5.15.3">2</mn></msup><mo id="S3.E3.m1.5.16" lspace="0.0835em">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.5c">\underset{\bar{P_{j}}}{\mathrm{argmin}}\ \ \sum_{k=1}^{C}\sum_{j=1}^{J}\left\|%
[{K_{k}}|\vec{0}][{R_{k}}|{t_{k}}]\bar{P}_{j,i}-{p}_{j,k}\right\|^{2}~{}.</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.5d">start_UNDERACCENT over¬Ø start_ARG italic_P start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG end_UNDERACCENT start_ARG roman_argmin end_ARG ‚àë start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT ‚àë start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_J end_POSTSUPERSCRIPT ‚à• [ italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT | over‚Üí start_ARG 0 end_ARG ] [ italic_R start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT - italic_p start_POSTSUBSCRIPT italic_j , italic_k end_POSTSUBSCRIPT ‚à• start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.5">Without additional constraints, the optimization process can change the position of all body joints; however, there are symmetries in the human body that can be exploited to guide optimization. In particular, we design a limb length symmetry constraint considering four pairs of bones: left and right upper arms, lower arms, upper legs and lower legs. For each pair we constrain the limb length to be the same, that is, we enforce left and right limbs to have consistent measures.
In particular, we compute the left (<em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.5.1">L</em>) and right (<em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.5.2">R</em>) 3D limb lengths as the euclidean distance <math alttext="d(\hat{P}_{i},\bar{P}_{j})" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m1.2"><semantics id="S3.SS3.p1.3.m1.2a"><mrow id="S3.SS3.p1.3.m1.2.2" xref="S3.SS3.p1.3.m1.2.2.cmml"><mi id="S3.SS3.p1.3.m1.2.2.4" xref="S3.SS3.p1.3.m1.2.2.4.cmml">d</mi><mo id="S3.SS3.p1.3.m1.2.2.3" xref="S3.SS3.p1.3.m1.2.2.3.cmml">‚Å¢</mo><mrow id="S3.SS3.p1.3.m1.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml"><mo id="S3.SS3.p1.3.m1.2.2.2.2.3" stretchy="false" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p1.3.m1.1.1.1.1.1" xref="S3.SS3.p1.3.m1.1.1.1.1.1.cmml"><mover accent="true" id="S3.SS3.p1.3.m1.1.1.1.1.1.2" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.3.m1.1.1.1.1.1.2.2" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.2.cmml">P</mi><mo id="S3.SS3.p1.3.m1.1.1.1.1.1.2.1" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS3.p1.3.m1.1.1.1.1.1.3" xref="S3.SS3.p1.3.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p1.3.m1.2.2.2.2.4" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS3.p1.3.m1.2.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.2.2.cmml"><mover accent="true" id="S3.SS3.p1.3.m1.2.2.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.3.m1.2.2.2.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.2.cmml">P</mi><mo id="S3.SS3.p1.3.m1.2.2.2.2.2.2.1" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.1.cmml">¬Ø</mo></mover><mi id="S3.SS3.p1.3.m1.2.2.2.2.2.3" xref="S3.SS3.p1.3.m1.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.SS3.p1.3.m1.2.2.2.2.5" stretchy="false" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.2b"><apply id="S3.SS3.p1.3.m1.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2"><times id="S3.SS3.p1.3.m1.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.3"></times><ci id="S3.SS3.p1.3.m1.2.2.4.cmml" xref="S3.SS3.p1.3.m1.2.2.4">ùëë</ci><interval closure="open" id="S3.SS3.p1.3.m1.2.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2"><apply id="S3.SS3.p1.3.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS3.p1.3.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2"><ci id="S3.SS3.p1.3.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.1">^</ci><ci id="S3.SS3.p1.3.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.2">ùëÉ</ci></apply><ci id="S3.SS3.p1.3.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.3">ùëñ</ci></apply><apply id="S3.SS3.p1.3.m1.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2">subscript</csymbol><apply id="S3.SS3.p1.3.m1.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2"><ci id="S3.SS3.p1.3.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.1">¬Ø</ci><ci id="S3.SS3.p1.3.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.2">ùëÉ</ci></apply><ci id="S3.SS3.p1.3.m1.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.3">ùëó</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.2c">d(\hat{P}_{i},\bar{P}_{j})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m1.2d">italic_d ( over^ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math> between the corresponding left and right joints. If <math alttext="u" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m2.1"><semantics id="S3.SS3.p1.4.m2.1a"><mi id="S3.SS3.p1.4.m2.1.1" xref="S3.SS3.p1.4.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.1b"><ci id="S3.SS3.p1.4.m2.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m2.1d">italic_u</annotation></semantics></math> and <math alttext="v" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m3.1"><semantics id="S3.SS3.p1.5.m3.1a"><mi id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.1b"><ci id="S3.SS3.p1.5.m3.1.1.cmml" xref="S3.SS3.p1.5.m3.1.1">ùë£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m3.1d">italic_v</annotation></semantics></math> are a pair of corresponding limb joints, the final cost for the symmetry constraint is given by:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="C_{sym}=\sum_{u=1}^{J}\sum_{v=1}^{J}\mathds{1}(u,v)\cdot\left\|d(\bar{P}_{u_{L%
}},\bar{P}_{v_{L}})-d(\bar{P}_{u_{R}},\bar{P}_{v_{R}})\right\|^{2}~{}," class="ltx_Math" display="block" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml">C</mi><mrow id="S3.E4.m1.3.3.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.3.2.cmml">s</mi><mo id="S3.E4.m1.3.3.1.1.3.3.1" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.1.1.3.3.3" xref="S3.E4.m1.3.3.1.1.3.3.3.cmml">y</mi><mo id="S3.E4.m1.3.3.1.1.3.3.1a" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.3.3.1.1.3.3.4" xref="S3.E4.m1.3.3.1.1.3.3.4.cmml">m</mi></mrow></msub><mo id="S3.E4.m1.3.3.1.1.2" rspace="0.111em" xref="S3.E4.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml"><munderover id="S3.E4.m1.3.3.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.2.cmml"><mo id="S3.E4.m1.3.3.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E4.m1.3.3.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E4.m1.3.3.1.1.1.2.2.3" xref="S3.E4.m1.3.3.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.2.2.3.2" xref="S3.E4.m1.3.3.1.1.1.2.2.3.2.cmml">u</mi><mo id="S3.E4.m1.3.3.1.1.1.2.2.3.1" xref="S3.E4.m1.3.3.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.3.3.1.1.1.2.2.3.3" xref="S3.E4.m1.3.3.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.3.3.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.2.3.cmml">J</mi></munderover><mrow id="S3.E4.m1.3.3.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.cmml"><munderover id="S3.E4.m1.3.3.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.2.2.2" movablelimits="false" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.2.2.3" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.2.2.3.2" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.2.cmml">v</mi><mo id="S3.E4.m1.3.3.1.1.1.1.2.2.3.1" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.3.3.1.1.1.1.2.2.3.3" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.3.3.1.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.1.2.3.cmml">J</mi></munderover><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3.cmml"><mn id="S3.E4.m1.3.3.1.1.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2.cmml">ùüô</mn><mo id="S3.E4.m1.3.3.1.1.1.1.1.3.1" xref="S3.E4.m1.3.3.1.1.1.1.1.3.1.cmml">‚Å¢</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.1.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.1.3.3.2.1" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.1.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">u</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.3.3.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.1.cmml">,</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">v</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.3.3.2.3" rspace="0.055em" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.1.1.1.2" rspace="0.222em" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">‚ãÖ</mo><msup id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.4.cmml">d</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">P</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">¬Ø</mo></mover><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">u</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">L</mi></msub></msub><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml">P</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.cmml">¬Ø</mo></mover><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml">v</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml">L</mi></msub></msub><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.5" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.5.cmml">‚àí</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.4.cmml">d</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.3.cmml"><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.3" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.3.cmml">(</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.2.cmml">P</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.1.cmml">¬Ø</mo></mover><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.2.cmml">u</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.3.cmml">R</mi></msub></msub><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.3.cmml">,</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.2.cmml">P</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.1.cmml">¬Ø</mo></mover><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.2.cmml">v</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.3.cmml">R</mi></msub></msub><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.5" stretchy="false" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S3.E4.m1.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"></eq><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2">ùê∂</ci><apply id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3"><times id="S3.E4.m1.3.3.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3.1"></times><ci id="S3.E4.m1.3.3.1.1.3.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2">ùë†</ci><ci id="S3.E4.m1.3.3.1.1.3.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3.3">ùë¶</ci><ci id="S3.E4.m1.3.3.1.1.3.3.4.cmml" xref="S3.E4.m1.3.3.1.1.3.3.4">ùëö</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S3.E4.m1.3.3.1.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2.2.2"></sum><apply id="S3.E4.m1.3.3.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.2.2.3"><eq id="S3.E4.m1.3.3.1.1.1.2.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.3.3.1.1.1.2.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2.2.3.2">ùë¢</ci><cn id="S3.E4.m1.3.3.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E4.m1.3.3.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.3.3.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.2.3">ùêΩ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S3.E4.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2"></sum><apply id="S3.E4.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3"><eq id="S3.E4.m1.3.3.1.1.1.1.2.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.3.3.1.1.1.1.2.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.2">ùë£</ci><cn id="S3.E4.m1.3.3.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.3">ùêΩ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><ci id="S3.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2">‚ãÖ</ci><apply id="S3.E4.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3"><times id="S3.E4.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.1"></times><cn id="S3.E4.m1.3.3.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2">1</cn><interval closure="open" id="S3.E4.m1.3.3.1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.2"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ùë¢</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ùë£</ci></interval></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1"><minus id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.5"></minus><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.3"></times><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.4">ùëë</ci><interval closure="open" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2"><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1">¬Ø</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ùëÉ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">ùë¢</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">ùêø</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2"><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1">¬Ø</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2">ùëÉ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2">ùë£</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3">ùêø</ci></apply></apply></interval></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4"><times id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.3"></times><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.4">ùëë</ci><interval closure="open" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2"><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2"><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.1">¬Ø</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.2.2">ùëÉ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.2">ùë¢</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.1.1.3.3">ùëÖ</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2"><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.1">¬Ø</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.2.2">ùëÉ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.2">ùë£</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.2.2.3.3">ùëÖ</ci></apply></apply></interval></apply></apply></apply><cn id="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">C_{sym}=\sum_{u=1}^{J}\sum_{v=1}^{J}\mathds{1}(u,v)\cdot\left\|d(\bar{P}_{u_{L%
}},\bar{P}_{v_{L}})-d(\bar{P}_{u_{R}},\bar{P}_{v_{R}})\right\|^{2}~{},</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">italic_C start_POSTSUBSCRIPT italic_s italic_y italic_m end_POSTSUBSCRIPT = ‚àë start_POSTSUBSCRIPT italic_u = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_J end_POSTSUPERSCRIPT ‚àë start_POSTSUBSCRIPT italic_v = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_J end_POSTSUPERSCRIPT blackboard_1 ( italic_u , italic_v ) ‚ãÖ ‚à• italic_d ( over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT end_POSTSUBSCRIPT , over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) - italic_d ( over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT end_POSTSUBSCRIPT , over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) ‚à• start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{where}\ \ \mathds{1}(u,v)=\begin{cases}1&amp;\text{if }(u,v)\text{ is upper/%
lower arm, upper/lower leg}\\
0&amp;\text{otherwise}~{}.\end{cases}" class="ltx_Math" display="block" id="S3.Ex1.m1.6"><semantics id="S3.Ex1.m1.6a"><mrow id="S3.Ex1.m1.6.7" xref="S3.Ex1.m1.6.7.cmml"><mrow id="S3.Ex1.m1.6.7.2" xref="S3.Ex1.m1.6.7.2.cmml"><mtext id="S3.Ex1.m1.6.7.2.2" xref="S3.Ex1.m1.6.7.2.2a.cmml">where</mtext><mo id="S3.Ex1.m1.6.7.2.1" xref="S3.Ex1.m1.6.7.2.1.cmml">‚Å¢</mo><mn class="ltx_mathvariant_double-struck" id="S3.Ex1.m1.6.7.2.3" mathvariant="double-struck" xref="S3.Ex1.m1.6.7.2.3.cmml">  1</mn><mo id="S3.Ex1.m1.6.7.2.1a" xref="S3.Ex1.m1.6.7.2.1.cmml">‚Å¢</mo><mrow id="S3.Ex1.m1.6.7.2.4.2" xref="S3.Ex1.m1.6.7.2.4.1.cmml"><mo id="S3.Ex1.m1.6.7.2.4.2.1" stretchy="false" xref="S3.Ex1.m1.6.7.2.4.1.cmml">(</mo><mi id="S3.Ex1.m1.5.5" xref="S3.Ex1.m1.5.5.cmml">u</mi><mo id="S3.Ex1.m1.6.7.2.4.2.2" xref="S3.Ex1.m1.6.7.2.4.1.cmml">,</mo><mi id="S3.Ex1.m1.6.6" xref="S3.Ex1.m1.6.6.cmml">v</mi><mo id="S3.Ex1.m1.6.7.2.4.2.3" stretchy="false" xref="S3.Ex1.m1.6.7.2.4.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.6.7.1" xref="S3.Ex1.m1.6.7.1.cmml">=</mo><mrow id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.6.7.3.1.cmml"><mo id="S3.Ex1.m1.4.4.5" xref="S3.Ex1.m1.6.7.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" id="S3.Ex1.m1.4.4.4" rowspacing="0pt" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtr id="S3.Ex1.m1.4.4.4a" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4b" xref="S3.Ex1.m1.6.7.3.1.cmml"><mn id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4c" xref="S3.Ex1.m1.6.7.3.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1" xref="S3.Ex1.m1.2.2.2.2.2.1.cmml"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.4" xref="S3.Ex1.m1.2.2.2.2.2.1.4a.cmml">if¬†</mtext><mo id="S3.Ex1.m1.2.2.2.2.2.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.3.cmml">‚Å¢</mo><mrow id="S3.Ex1.m1.2.2.2.2.2.1.5.2" xref="S3.Ex1.m1.2.2.2.2.2.1.5.1.cmml"><mo id="S3.Ex1.m1.2.2.2.2.2.1.5.2.1" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.2.1.5.1.cmml">(</mo><mi id="S3.Ex1.m1.2.2.2.2.2.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.1.cmml">u</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.5.2.2" xref="S3.Ex1.m1.2.2.2.2.2.1.5.1.cmml">,</mo><mi id="S3.Ex1.m1.2.2.2.2.2.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.cmml">v</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.5.2.3" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.2.1.5.1.cmml">)</mo></mrow><mo id="S3.Ex1.m1.2.2.2.2.2.1.3a" xref="S3.Ex1.m1.2.2.2.2.2.1.3.cmml">‚Å¢</mo><mtext id="S3.Ex1.m1.2.2.2.2.2.1.6" xref="S3.Ex1.m1.2.2.2.2.2.1.6a.cmml">¬†is upper/lower arm, upper/lower leg</mtext></mrow></mtd></mtr><mtr id="S3.Ex1.m1.4.4.4d" xref="S3.Ex1.m1.6.7.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4e" xref="S3.Ex1.m1.6.7.3.1.cmml"><mn id="S3.Ex1.m1.3.3.3.3.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4f" xref="S3.Ex1.m1.6.7.3.1.cmml"><mrow id="S3.Ex1.m1.4.4.4.4.2.1.3" xref="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.1" xref="S3.Ex1.m1.4.4.4.4.2.1.1.cmml">otherwise</mtext><mo id="S3.Ex1.m1.4.4.4.4.2.1.3.1" lspace="0.330em" xref="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml">.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.6b"><apply id="S3.Ex1.m1.6.7.cmml" xref="S3.Ex1.m1.6.7"><eq id="S3.Ex1.m1.6.7.1.cmml" xref="S3.Ex1.m1.6.7.1"></eq><apply id="S3.Ex1.m1.6.7.2.cmml" xref="S3.Ex1.m1.6.7.2"><times id="S3.Ex1.m1.6.7.2.1.cmml" xref="S3.Ex1.m1.6.7.2.1"></times><ci id="S3.Ex1.m1.6.7.2.2a.cmml" xref="S3.Ex1.m1.6.7.2.2"><mtext id="S3.Ex1.m1.6.7.2.2.cmml" xref="S3.Ex1.m1.6.7.2.2">where</mtext></ci><cn id="S3.Ex1.m1.6.7.2.3.cmml" type="integer" xref="S3.Ex1.m1.6.7.2.3">1</cn><interval closure="open" id="S3.Ex1.m1.6.7.2.4.1.cmml" xref="S3.Ex1.m1.6.7.2.4.2"><ci id="S3.Ex1.m1.5.5.cmml" xref="S3.Ex1.m1.5.5">ùë¢</ci><ci id="S3.Ex1.m1.6.6.cmml" xref="S3.Ex1.m1.6.6">ùë£</ci></interval></apply><apply id="S3.Ex1.m1.6.7.3.1.cmml" xref="S3.Ex1.m1.4.4"><csymbol cd="latexml" id="S3.Ex1.m1.6.7.3.1.1.cmml" xref="S3.Ex1.m1.4.4.5">cases</csymbol><cn id="S3.Ex1.m1.1.1.1.1.1.1.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1">1</cn><apply id="S3.Ex1.m1.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1"><times id="S3.Ex1.m1.2.2.2.2.2.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.3"></times><ci id="S3.Ex1.m1.2.2.2.2.2.1.4a.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.4"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.4.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.4">if¬†</mtext></ci><interval closure="open" id="S3.Ex1.m1.2.2.2.2.2.1.5.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.5.2"><ci id="S3.Ex1.m1.2.2.2.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.1">ùë¢</ci><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2">ùë£</ci></interval><ci id="S3.Ex1.m1.2.2.2.2.2.1.6a.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.6"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.6.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.6">¬†is upper/lower arm, upper/lower leg</mtext></ci></apply><cn id="S3.Ex1.m1.3.3.3.3.1.1.cmml" type="integer" xref="S3.Ex1.m1.3.3.3.3.1.1">0</cn><ci id="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1.3"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.1.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1.1">otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.6c">\text{where}\ \ \mathds{1}(u,v)=\begin{cases}1&amp;\text{if }(u,v)\text{ is upper/%
lower arm, upper/lower leg}\\
0&amp;\text{otherwise}~{}.\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.6d">where blackboard_1 ( italic_u , italic_v ) = { start_ROW start_CELL 1 end_CELL start_CELL if ( italic_u , italic_v ) is upper/lower arm, upper/lower leg end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL otherwise . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p2.1">Note that, with respect to previous work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib8" title="">8</a>]</cite>, we do not require any prior information on human limbs length or pre-computed statistics on datasets‚Äô 3D annotations.
Finally, the optimization problem is defined as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\underset{\bar{P_{j}}}{\mathrm{argmin}}\ \ \sum_{k=1}^{C}\sum_{j=1}^{J}\left\|%
[{K_{k}}|\vec{0}][{R_{k}}|{t_{k}}]\bar{P}_{j,i}-{p}_{j,k}\right\|^{2}+C_{sym}~%
{}." class="ltx_math_unparsed" display="block" id="S3.E5.m1.5"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5b"><munder accentunder="true" id="S3.E5.m1.5.5"><mi id="S3.E5.m1.5.5.2">argmin</mi><mover accent="true" id="S3.E5.m1.5.5.1"><msub id="S3.E5.m1.5.5.1.2"><mi id="S3.E5.m1.5.5.1.2.2">P</mi><mi id="S3.E5.m1.5.5.1.2.3">j</mi></msub><mo id="S3.E5.m1.5.5.1.1">¬Ø</mo></mover></munder><mspace id="S3.E5.m1.5.6" width="1em"></mspace><munderover id="S3.E5.m1.5.7"><mo id="S3.E5.m1.5.7.2.2" movablelimits="false" rspace="0em">‚àë</mo><mrow id="S3.E5.m1.5.7.2.3"><mi id="S3.E5.m1.5.7.2.3.2">k</mi><mo id="S3.E5.m1.5.7.2.3.1">=</mo><mn id="S3.E5.m1.5.7.2.3.3">1</mn></mrow><mi id="S3.E5.m1.5.7.3">C</mi></munderover><munderover id="S3.E5.m1.5.8"><mo id="S3.E5.m1.5.8.2.2" movablelimits="false" rspace="0em">‚àë</mo><mrow id="S3.E5.m1.5.8.2.3"><mi id="S3.E5.m1.5.8.2.3.2">j</mi><mo id="S3.E5.m1.5.8.2.3.1">=</mo><mn id="S3.E5.m1.5.8.2.3.3">1</mn></mrow><mi id="S3.E5.m1.5.8.3">J</mi></munderover><mo id="S3.E5.m1.5.9" lspace="0em" rspace="0.167em" stretchy="true">‚à•</mo><mrow id="S3.E5.m1.5.10"><mo id="S3.E5.m1.5.10.1" stretchy="false">[</mo><msub id="S3.E5.m1.5.10.2"><mi id="S3.E5.m1.5.10.2.2">K</mi><mi id="S3.E5.m1.5.10.2.3">k</mi></msub><mo fence="false" id="S3.E5.m1.5.10.3" rspace="0.167em" stretchy="false">|</mo><mover accent="true" id="S3.E5.m1.5.10.4"><mn id="S3.E5.m1.5.10.4.2">0</mn><mo id="S3.E5.m1.5.10.4.1" stretchy="false">‚Üí</mo></mover><mo id="S3.E5.m1.5.10.5" stretchy="false">]</mo></mrow><mrow id="S3.E5.m1.5.11"><mo id="S3.E5.m1.5.11.1" stretchy="false">[</mo><msub id="S3.E5.m1.5.11.2"><mi id="S3.E5.m1.5.11.2.2">R</mi><mi id="S3.E5.m1.5.11.2.3">k</mi></msub><mo fence="false" id="S3.E5.m1.5.11.3" rspace="0.167em" stretchy="false">|</mo><msub id="S3.E5.m1.5.11.4"><mi id="S3.E5.m1.5.11.4.2">t</mi><mi id="S3.E5.m1.5.11.4.3">k</mi></msub><mo id="S3.E5.m1.5.11.5" stretchy="false">]</mo></mrow><msub id="S3.E5.m1.5.12"><mover accent="true" id="S3.E5.m1.5.12.2"><mi id="S3.E5.m1.5.12.2.2">P</mi><mo id="S3.E5.m1.5.12.2.1">¬Ø</mo></mover><mrow id="S3.E5.m1.2.2.2.4"><mi id="S3.E5.m1.1.1.1.1">j</mi><mo id="S3.E5.m1.2.2.2.4.1">,</mo><mi id="S3.E5.m1.2.2.2.2">i</mi></mrow></msub><mo id="S3.E5.m1.5.13">‚àí</mo><msub id="S3.E5.m1.5.14"><mi id="S3.E5.m1.5.14.2">p</mi><mrow id="S3.E5.m1.4.4.2.4"><mi id="S3.E5.m1.3.3.1.1">j</mi><mo id="S3.E5.m1.4.4.2.4.1">,</mo><mi id="S3.E5.m1.4.4.2.2">k</mi></mrow></msub><msup id="S3.E5.m1.5.15"><mo id="S3.E5.m1.5.15.2" lspace="0em" rspace="0em" stretchy="true">‚à•</mo><mn id="S3.E5.m1.5.15.3">2</mn></msup><mo id="S3.E5.m1.5.16" lspace="0em">+</mo><msub id="S3.E5.m1.5.17"><mi id="S3.E5.m1.5.17.2">C</mi><mrow id="S3.E5.m1.5.17.3"><mi id="S3.E5.m1.5.17.3.2">s</mi><mo id="S3.E5.m1.5.17.3.1">‚Å¢</mo><mi id="S3.E5.m1.5.17.3.3">y</mi><mo id="S3.E5.m1.5.17.3.1a">‚Å¢</mo><mi id="S3.E5.m1.5.17.3.4">m</mi></mrow></msub><mo id="S3.E5.m1.5.18" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E5.m1.5c">\underset{\bar{P_{j}}}{\mathrm{argmin}}\ \ \sum_{k=1}^{C}\sum_{j=1}^{J}\left\|%
[{K_{k}}|\vec{0}][{R_{k}}|{t_{k}}]\bar{P}_{j,i}-{p}_{j,k}\right\|^{2}+C_{sym}~%
{}.</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.5d">start_UNDERACCENT over¬Ø start_ARG italic_P start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG end_UNDERACCENT start_ARG roman_argmin end_ARG ‚àë start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT ‚àë start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_J end_POSTSUPERSCRIPT ‚à• [ italic_K start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT | over‚Üí start_ARG 0 end_ARG ] [ italic_R start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] over¬Ø start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_j , italic_i end_POSTSUBSCRIPT - italic_p start_POSTSUBSCRIPT italic_j , italic_k end_POSTSUBSCRIPT ‚à• start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_C start_POSTSUBSCRIPT italic_s italic_y italic_m end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In order to evaluate the capabilities of our method to handle significant occlusions and clutter, following the work of¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib25" title="">25</a>]</cite> and¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib35" title="">35</a>]</cite>, we propose Human3.6M-Occluded, a novel benchmark derived from Human3.6M¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib10" title="">10</a>]</cite>, adding synthetic occlusions on camera views. The robustness and reliability of our method in challenging human-robot environments is then inspected considering data sequences of human-robot collaboration tasks acquired in a real industrial workcell and in a laboratory environment. We finally conduct ablation studies to analyse the behaviour of our framework in presence of few occluded viewpoints and camera synchronization errors, typical in industrial multi-camera setups.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings and Metrics</h3>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Human3.6M and Human3.6M-Occluded</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">The Human3.6M dataset is currently one of the largest multi-view datasets providing 3D human pose annotations. It consists of 3.6 million frames captured by 4 synchronized 50‚ÄâHz cameras. 3D and 2D keypoint ground truth is obtained by a marker-based motion capture system composed of 10 IR-cameras.
The dataset includes 11 different subjects performing 15 daily actions, such as eating, walking, and giving directions. Each scene features only one subject.
Following the traditional protocol, subjects S9 and S11 are considered for evaluation. To provide fair comparisons with previous work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>, sequences of subject S9 with incorrect 3D annotations (parts of ‚ÄòGreeting‚Äô, ‚ÄòSittingDown‚Äô and ‚ÄòWaiting‚Äô) were ignored for final results calculations.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">Motivated by the lack of human body occlusions in Human3.6M and of public multi-view human pose estimation datasets including real occlusions in cluttered scenarios, we introduce the novel benchmark Human3.6M-Occluded. This is derived from the Human3.6M dataset by synthetically adding significant body occlusions, by taking objects and animals images from the Pascal VOC 2012 dataset¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib5" title="">5</a>]</cite> as occluders, as done in¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib25" title="">25</a>]</cite>. Considering the four available camera views for each scene in the dataset, we partially cover the subject‚Äôs body on three out of four views. This kind of scenario is very difficult to deal with, as each body joint is not guaranteed to be visible by at least two views. An occluded view includes two random objects overlapping the human bounding box. Object size and location inside the box are chosen at random.
Sample images from the Human3.6M-Occluded benchmark are shown in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.F1" title="In 4.1.1 Human3.6M and Human3.6M-Occluded ‚Ä£ 4.1 Experimental Settings and Metrics ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p3">
<p class="ltx_p" id="S4.SS1.SSS1.p3.1">Differently from previous works presenting similar approaches, we make reproducible code available to generate the dataset, to encourage further research on occlusion-aware human pose estimation and to facilitate comparison with other methods. Code is available here <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/laurabragagnolo/human3.6m-occluded" title="">https://github.com/laurabragagnolo/human3.6m-occluded</a></span></span></span>.</p>
</div>
<figure class="ltx_figure" id="S4.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="599" id="S4.F1.sf1.g1" src="extracted/5819025/figures/frame_000075_1.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S4.F1.sf2.g1" src="extracted/5819025/figures/frame_000075_2.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S4.F1.sf3.g1" src="extracted/5819025/figures/frame_000075_3.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.sf3.2.1.1" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="599" id="S4.F1.sf4.g1" src="extracted/5819025/figures/frame_000075_4.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.sf4.2.1.1" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S4.F1.3.2" style="font-size:90%;">Sample sequence from the Human3.6M-Occluded dataset, with occlusions on three of four views.</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Human-Robot Workcell</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">To test the robustness of our human pose estimation method in real industrial environments, we conducted experimental validation on data acquired in two different human-robot collaboration scenarios: an industrial workcell developed as use case for the DrapeBot project¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib29" title="">29</a>]</cite>, and a laboratory collaborative workcell.
The former has been designed for collaborative transportation of flexible materials and covers an area of about 20‚Äâm<sup class="ltx_sup" id="S4.SS1.SSS2.p1.1.1">2</sup>. It was equipped with four Intel RealSense Depth D455 sensors surrounding an ABB industrial manipulator at an average distance of 4‚Äâm from the base of the robot.
The latter, equipped with four Intel RealSense Depth D455 cameras and a Franka Emika Panda collaborative manipulator, has been designed for the collaborative assembly of furniture, (<em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS2.p1.1.2">e.g</em>.<span class="ltx_text" id="S4.SS1.SSS2.p1.1.3"></span>, wooden chair).
The industrial workcell provides a very challenging testing scenario, with a lot of clutter in the scene and very tilted cameras. The laboratory workcell represents a simpler scenario, with less occluders.
In both settings cameras are not perfectly synchronized.
Sample images extracted from acquired sequences are shown in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.F2" title="In 4.1.2 Human-Robot Workcell ‚Ä£ 4.1 Experimental Settings and Metrics ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1">In all sequences collected, participants were equipped with the Xsens MVN Awinda motion capture system¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib27" title="">27</a>]</cite> to record whole-body kinematics. The system consists of 17 wearable inertial measurement units (IMUs) placed all over the body, providing an accurate full-body 3D pose not affected by occlusions that has been used as a ground truth information. Since the 3D pose obtained from inertial sensors suffers from drifting errors in the absolute position over long period of time, we correct this effect using the information provided by the multi-camera pose tracking solution OpenPTrack¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib20" title="">20</a>]</cite>, by aligning the inertial-based 3D pose with the 3D position of the the neck joint detected by OpenPTrack, which has been empirically proven to be the most robust to occlusions among all body joints.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S4.F2.sf1.g1" src="extracted/5819025/figures/000353_defaced.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F2.sf1.3.2" style="font-size:90%;">Workcell for collaborative draping</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S4.F2.sf2.g1" src="extracted/5819025/figures/000800_defaced.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F2.sf2.3.2" style="font-size:90%;">Workcell for collaborative assembly</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">Sample images from the sequences acquired in real human-robot collaboration scenarios. a) Industrial workcell; b) Laboratory workcell.</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Evaluation Metrics</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">The 3D pose estimation accuracy is measured considering the Mean Per Joint Position Error (MPJPE), that is, the Euclidean distance between predicted 3D position and ground truth, for each joint.
We consider both the absolute and the root-relative MPJPE, that requires aligning the pelvis joints coordinates of the estimated and ground truth pose. While the absolute error takes into account the accuracy of the global localization of the prediction, the relative error focuses on the accuracy of the human keypoints configuration with respect to the pelvis joint, also known as the root joint.
The MPJPE is expressed in millimeters, where lower values represent higher accuracy.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4 </span>Implementation Details</h4>
<div class="ltx_para" id="S4.SS1.SSS4.p1">
<p class="ltx_p" id="S4.SS1.SSS4.p1.1">The single-view 3D predictions for multi-camera fusion are obtained using MeTRAbs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib24" title="">24</a>]</cite>. The considered model has been trained considering multiple skeleton conventions, <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS4.p1.1.1">e.g</em>.<span class="ltx_text" id="S4.SS1.SSS4.p1.1.2"></span> H36M¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib10" title="">10</a>]</cite>, 3DHP¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib18" title="">18</a>]</cite>, SMPL-X¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib21" title="">21</a>]</cite>, and several 3D human pose estimation datasets, including Human3.6M¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib10" title="">10</a>]</cite>, CMU Panoptic¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib12" title="">12</a>]</cite> and TotalCapture¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib31" title="">31</a>]</cite>.
For each of the experiments presented below, we do not perform any fine-tuning.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results on Human3.6M and Human3.6M-Occluded</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The results of the evaluation of our method and state-of-the-art multi-view human pose estimation algorithms on the Human3.6M dataset is reported in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T1" title="In 4.2 Results on Human3.6M and Human3.6M-Occluded ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T2" title="In 4.2 Results on Human3.6M and Human3.6M-Occluded ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a>.
Considering the root-relative MPJPE (<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T1" title="In 4.2 Results on Human3.6M and Human3.6M-Occluded ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>), in scenarios with very few occlusions and in which the human body is well visible from all the four viewpoints, our method performs slightly worse with respect to current approaches. For multi-view methods, however, the absolute position error is much more interesting to look at, since it represents the quality of the 3D global localization of the human body prediction. Results for the absolute MPJPE are reported in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T2" title="In 4.2 Results on Human3.6M and Human3.6M-Occluded ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a>. Our framework surpasses most recent approaches and gives comparable results to strong baselines such as algebraic triangulation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>.
Looking the state of the art, it is worth noticing that our method and TransFusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite> yield very similar results, while AdaFuse <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite> produces the strongest performance on this benchmark, considering both relative and absolute errors.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The loss of accuracy with respect to the state of the art is mainly due to the fact that competing approaches rely on heavy geometrical constraints, such as triangulation and epipolar lines, to perform 2D feature fusion. When the human body is fully visible and 2D features are very reliable, exploiting geometry gives extremely precise results that, however, poorly adapt to scenarios with occlusions, in which 2D joint predictions are not as reliable. Differently, our method uses information about the geometry of the scene, <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.1">i.e</em>.<span class="ltx_text" id="S4.SS2.p2.1.2"></span>, rotation and translation between cameras, for the sole 3D joint reprojection and then finds the optimal pose that minimizes reprojection errors on multiple views. This enforces looser geometrical constrains on the final pose, which lead to slightly worse results on the standard Human3.6M with respect to the other methods, but more robust performance in presence of occlusions.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S4.T1.3.2" style="font-size:90%;">The results of evaluation on the Human3.6M dataset. The table presents the MPJPE relative to pelvis for state-of-the-art multi-view human pose estimation methods.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T1.4" style="width:433.6pt;height:92.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-164.0pt,34.9pt) scale(0.569375883109334,0.569375883109334) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" colspan="17" id="S4.T1.4.1.1.1.1">MPJPE relative to pelvis, mm</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.1.2.1.1">Methods</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.2">Dir.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.3">Disc.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.4">Eat</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.5">Greet</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.6">Phone</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.7">Photo</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.8">Pose</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.9">Purch.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.10">Sit</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.11">SitD.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.12">Smoke</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.13">Wait</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.14">WalkD.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.15">Walk</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.16">WalkT.</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.4.1.2.1.17"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.2.1.17.1">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.1.3.2.1">RANSAC (as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.2">18.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.3">19.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.4">19.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.5">20.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.6">22.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.7">17.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.8">19.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.9">24.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.10">31.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.11">22.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.12">21.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.13">22.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.14"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.3.2.14.1">17.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.15">22.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.16">17.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.4.1.3.2.17">21.7</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.1.4.3.1">T-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T1.4.1.4.3.1.1">et al</em>.<span class="ltx_text" id="S4.T1.4.1.4.3.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.2">20.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.3">22.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.4">20.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.5">19.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.6">22.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.7">20.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.8">19.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.9">23.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.10">25.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.11">33.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.12">23.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.13">21.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.14">20.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.15">23.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.4.3.16">21.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.4.1.4.3.17">22.6</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.1.5.4.1">V-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T1.4.1.5.4.1.1">et al</em>.<span class="ltx_text" id="S4.T1.4.1.5.4.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.2">19.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.3">20.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.4">18.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.5">18.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.6">20.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.7">19.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.8">18.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.9">22.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.10"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.5.4.10.1">22.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.11">28.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.12">21.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.13">20.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.14">19.7</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.15">22.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.5.4.16">20.2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.4.1.5.4.17">20.8</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.1.6.5.1">Zhang <em class="ltx_emph ltx_font_italic" id="S4.T1.4.1.6.5.1.1">et al</em>.<span class="ltx_text" id="S4.T1.4.1.6.5.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.2"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.2.1">17.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.3.1">18.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.4.1">17.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.5">21.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.6.1">19.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.7"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.7.1">16.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.8">18.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.9"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.9.1">19.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.10">26.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.11"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.11.1">19.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.12"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.12.1">19.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.13">21.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.14">16.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.15"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.15.1">19.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.6.5.16"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.16.1">16.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.4.1.6.5.17"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.6.5.17.1">19.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.1.7.6.1">Ma <em class="ltx_emph ltx_font_italic" id="S4.T1.4.1.7.6.1.1">et al</em>.<span class="ltx_text" id="S4.T1.4.1.7.6.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.2">25.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.3">27.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.4">24.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.5">24.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.6">27.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.7">28.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.8">24.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.9">25.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.10">63.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.11">32.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.12">27.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.13">25.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.14">27.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.15">25.2</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.7.6.16">24.7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.4.1.7.6.17">29.4</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.1.8.7.1">Wan <em class="ltx_emph ltx_font_italic" id="S4.T1.4.1.8.7.1.1">et al</em>.<span class="ltx_text" id="S4.T1.4.1.8.7.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib32" title="">32</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.2">19.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.3">20.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.4">19.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.8.7.5.1">18.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.6">21.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.7">20.0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.8"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.8.7.8.1">17.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.9">21.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.10">23.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.11">30.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.12">21.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.13"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.8.7.13.1">19.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.14">18.9</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.15">22.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.1.8.7.16">19.5</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.4.1.8.7.17">21.1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.1"><span class="ltx_text ltx_font_bold" id="S4.T1.4.1.9.8.1.1">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.2">25.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.3">27.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.4">27.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.5">27.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.6">31.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.7">26.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.8">29.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.9">33.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.10">36.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.11">29.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.12">29.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.13">28.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.14">25.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.15">30.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.16">26.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.4.1.9.8.17">29.0</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.2.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.3.2" style="font-size:90%;">The results of evaluation on the Human3.6M dataset. The table presents the absolute MPJPE for state-of-the-art multi-view human pose estimation methods.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T2.4" style="width:433.6pt;height:102.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-164.0pt,38.8pt) scale(0.569375883109334,0.569375883109334) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="17" id="S4.T2.4.1.1.1.1">MPJPE absolute, mm</th>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T2.4.1.2.2.1">Methods</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.2">Dir.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.3">Disc.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.4">Eat</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.5">Greet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.6">Phone</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.7">Photo</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.8">Pose</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.9">Purch.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.10">Sit</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.11">SitD.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.12">Smoke</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.13">Wait</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.14">WalkD.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.15">Walk</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.16">WalkT.</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.1.2.2.17"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.2.2.17.1">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.4.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.4.1.3.1.1">RANSAC (as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.2">18.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.3">19.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.4">20.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.5">18.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.6">22.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.7">17.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.8">19.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.9">23.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.10">28.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.11">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.12">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.13">17.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.14">18.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.15">21.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.16">17.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.4.1.3.1.17">21.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.1.4.2.1">T-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T2.4.1.4.2.1.1">et al</em>.<span class="ltx_text" id="S4.T2.4.1.4.2.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.2">21.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.3">23.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.4">22.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.5">20.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.6">26.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.7">24.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.8">19.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.9">22.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.10">31.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.11">35.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.12">26.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.13">21.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.14">20.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.15">24.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.4.2.16">21.1</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.1.4.2.17">24.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.1.5.3.1">V-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T2.4.1.5.3.1.1">et al</em>.<span class="ltx_text" id="S4.T2.4.1.5.3.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.2">18.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.3.1">18.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.4.1">16.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.5.1">16.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.6.1">17.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.7">18.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.8.1">16.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.9"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.9.1">18.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.10"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.10.1">19.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.11">20.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.12"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.12.1">18.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.13">17.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.14"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.14.1">17.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.15"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.15.1">19.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.5.3.16"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.16.1">16.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.1.5.3.17"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.5.3.17.1">17.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.1.6.4.1">Zhang <em class="ltx_emph ltx_font_italic" id="S4.T2.4.1.6.4.1.1">et al</em>.<span class="ltx_text" id="S4.T2.4.1.6.4.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.2"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.6.4.2.1">17.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.3"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.6.4.3.1">18.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.4">17.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.5">17.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.6">19.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.7"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.6.4.7.1">16.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.8">18.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.9">19.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.10">22.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.11"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.6.4.11.1">19.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.12">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.13"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.6.4.13.1">16.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.14">17.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.15">19.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.6.4.16">17.4</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.1.6.4.17">19.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.1.7.5.1">Ma <em class="ltx_emph ltx_font_italic" id="S4.T2.4.1.7.5.1.1">et al</em>.<span class="ltx_text" id="S4.T2.4.1.7.5.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.2">24.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.3">26.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.4">23.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.5">21.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.6">25.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.7">23.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.8">24.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.9">33.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.10">29.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.11">26.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.12">26.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.13">24.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.14">23.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.15">26.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.7.5.16">23.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.1.7.5.17">25.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.1.8.6.1">He <em class="ltx_emph ltx_font_italic" id="S4.T2.4.1.8.6.1.1">et al</em>.<span class="ltx_text" id="S4.T2.4.1.8.6.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib9" title="">9</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.2">25.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.3">27.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.4">23.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.5">24.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.6">26.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.7">31.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.8">24.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.9">26.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.10">28.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.11">31.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.12">28.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.13">26.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.14">23.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.15">28.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.8.6.16">23.5</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.1.8.6.17">26.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.4.1.9.7.1">Moliner <em class="ltx_emph ltx_font_italic" id="S4.T2.4.1.9.7.1.1">et al</em>.<span class="ltx_text" id="S4.T2.4.1.9.7.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib19" title="">19</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.2">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.3">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.7">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.8">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.10">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.11">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.12">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.13">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.14">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.15">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.9.7.16">-</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.4.1.9.7.17">26.0</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.1"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.10.8.1.1">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.2">23.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.3">24.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.4">23.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.5">24.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.6">26.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.7">24.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.8">25.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.9">28.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.10">31.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.11">25.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.12">26.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.13">24.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.14">23.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.15">27.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.16">24.2</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.4.1.10.8.17">25.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">To validate this, we now test our approach in presence of significant occlusions, on the proposed Human3.6M-Occluded benchmark.
For comparisons we select AdaFuse¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite> and TransFusion¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>, which have a specific focus on human pose estimation in unconstrained environments with occlusions and provide official codes and training weights on Human3.6M. We also compare with RANSAC (implementation from¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>) and the algebraic triangulation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>, taken as baselines.
For this experiment all the models are trained on the original Human3.6M dataset, without any fine-tuning on the Human3.6M-Occluded data.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">Results for the relative and absolute MPJPE on this benchmark are shown in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T3" title="In 4.2 Results on Human3.6M and Human3.6M-Occluded ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T4" title="In 4.2 Results on Human3.6M and Human3.6M-Occluded ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">4</span></a>. Our system provides the best performances with respect to both evaluation metrics, proving its superior capabilities in handling challenging scenes with occlusions with respect to competing methods relying on 2D features and strong geometrical constraints.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.2.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.3.2" style="font-size:90%;">The results of evaluation on the proposed Human3.6M-Occluded benchmark. The table presents the MPJPE relative to pelvis for our method and state-of-the-art multi-view human pose estimation algorithms.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T3.4" style="width:433.6pt;height:69.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-173.8pt,28.0pt) scale(0.555042472261422,0.555042472261422) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" colspan="17" id="S4.T3.4.1.1.1.1">MPJPE relative to pelvis, mm</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.4.1.2.1.1">Methods</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.2">Dir.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.3">Disc.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.4">Eat</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.5">Greet</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.6">Phone</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.7">Photo</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.8">Pose</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.9">Purch.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.10">Sit</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.11">SitD.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.12">Smoke</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.13">Wait</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.14">WalkD.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.15">Walk</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.16">WalkT.</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.17"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.1.17.1">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.4.1.3.2.1">RANSAC (as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.2">302.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.3">69.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.4">57.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.5">48.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.6">49.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.7">94.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.8">67.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.9">132.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.10">137.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.11">58.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.12">66.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.13">54.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.14">38.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.15">267.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.16">56.9</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T3.4.1.3.2.17">97.0</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.1.4.3.1">T-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T3.4.1.4.3.1.1">et al</em>.<span class="ltx_text" id="S4.T3.4.1.4.3.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.2">69.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.3">75.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.4">83.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.5">65.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.6">76.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.7">91.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.8">106.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.9">192.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.10">632.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.11">117.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.12">91.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.13">105.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.14">49.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.15">101.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.4.3.16">70.7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.4.3.17">134.9</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.1.5.4.1">Zhang <em class="ltx_emph ltx_font_italic" id="S4.T3.4.1.5.4.1.1">et al</em>.<span class="ltx_text" id="S4.T3.4.1.5.4.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.2.1">32.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.3">41.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.4.1">33.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.5.1">35.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.6"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.6.1">37.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.7">38.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.8"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.8.1">36.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.9"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.9.1">50.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.10">83.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.11">47.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.12">47.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.13">38.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.14"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.14.1">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.15"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.5.4.15.1">40.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.4.16">37.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.5.4.17">43.5</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.4.1.6.5.1">Ma <em class="ltx_emph ltx_font_italic" id="S4.T3.4.1.6.5.1.1">et al</em>.<span class="ltx_text" id="S4.T3.4.1.6.5.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.2">48.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.3">65.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.4">51.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.5">48.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.6">61.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.7">57.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.8">62.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.9">75.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.10">384.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.11">224.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.12">74.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.13">50.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.14">122.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.15">97.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.6.5.16">35.9</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.1.6.5.17">97.3</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.1"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.1.1">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.2">34.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.3"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.3.1">40.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.4">36.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.5">35.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.6">42.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.7"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.7.1">35.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.8">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.9">60.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.10"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.10.1">68.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.11"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.11.1">42.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.12"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.12.1">41.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.13"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.13.1">35.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.14">30.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.15">43.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.16"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.16.1">34.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.4.1.7.6.17"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.7.6.17.1">41.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.2.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.3.2" style="font-size:90%;">The results of evaluation on the proposed Human3.6M-Occluded benchmark. The table presents the absolute MPJPE for our method and state-of-the-art multi-view human pose estimation algorithms.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.4" style="width:433.6pt;height:70pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-173.7pt,28.0pt) scale(0.555239900075372,0.555239900075372) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="17" id="S4.T4.4.1.1.1.1">MPJPE absolute, mm</th>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T4.4.1.2.2.1">Methods</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.2">Dir.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.3">Disc.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.4">Eat</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.5">Greet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.6">Phone</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.7">Photo</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.8">Pose</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.9">Purch.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.10">Sit</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.11">SitD.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.12">Smoke</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.13">Wait</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.14">WalkD.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.15">Walk</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.16">WalkT.</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.1.2.2.17"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.2.2.17.1">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.4.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.4.1.3.1.1">RANSAC (as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.2">305.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.3">61.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.4">51.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.5">47.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.6">46.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.7">130.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.8">62.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.9">117.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.10">117.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.11">53.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.12">65.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.13">55.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.14">35.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.15">60.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.16">51.6</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.4.1.3.1.17">80.7</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.4.1.4.2.1">T-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T4.4.1.4.2.1.1">et al</em>.<span class="ltx_text" id="S4.T4.4.1.4.2.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.2">67.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.3">71.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.4">80.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.5">63.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.6">74.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.7">88.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.8">100.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.9">188.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.10">611.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.11">111.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.12">92.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.13">110.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.14">47.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.15">99.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.2.16">69.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.4.2.17">127.4</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.4.1.5.3.1">Zhang <em class="ltx_emph ltx_font_italic" id="S4.T4.4.1.5.3.1.1">et al</em>.<span class="ltx_text" id="S4.T4.4.1.5.3.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.5.3.2.1">31.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.3">39.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.4"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.5.3.4.1">32.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.5">32.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.5.3.6.1">36.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.7">36.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.5.3.8.1">34.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.9"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.5.3.9.1">46.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.10">71.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.11">45.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.12">47.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.13">37.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.14">28.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.15"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.5.3.15.1">37.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.3.16">35.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.5.3.17">41.1</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.4.1.6.4.1">Ma <em class="ltx_emph ltx_font_italic" id="S4.T4.4.1.6.4.1.1">et al</em>.<span class="ltx_text" id="S4.T4.4.1.6.4.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.2">48.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.3">65.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.4">50.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.5">47.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.6">60.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.7">56.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.8">61.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.9">74.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.10">384.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.11">224.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.12">73.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.13">49.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.14">122.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.15">96.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.4.16">35.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.4.1.6.4.17">96.5</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.1"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.1.1">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.2">32.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.3"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.3.1">36.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.4">32.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.5"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.5.1">31.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.6">37.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.7"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.7.1">32.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.8">36.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.9">53.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.10"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.10.1">64.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.11"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.11.1">37.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.12"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.12.1">38.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.13"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.13.1">32.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.14"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.14.1">27.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.15">38.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.16"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.16.1">31.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.4.1.7.5.17"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.7.5.17.1">37.8</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results on the Human-Robot Workcell Scenario</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We now inspect the robustness of our human pose estimation approach on real industrial environments. For this, we consider the data sequences collected in the industrial workcell and in our laboratory, presented earlier in this section.
Results are shown in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T5" title="In 4.3 Results on the Human-Robot Workcell Scenario ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.T6" title="In 4.3 Results on the Human-Robot Workcell Scenario ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">6</span></a>. Sequences acquired in the industrial workcell include the participation of two different subjects (performing two sequences each) and are numbered from 1 to 4; sequences collected in our laboratory include only one subject and are numbered from 5 to 7.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Our framework demonstrates a great advantage with respect to the other approaches, producing reliable predictions even on such challenging scenes, with an average absolute joint position error of about 14‚Äâcm. On the other hand, the performance of the other methods dramatically decreases in the same context, leading to errors of several meters with respect to the ground truth reference, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.F3" title="In 4.3 Results on the Human-Robot Workcell Scenario ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.F4" title="In 4.3 Results on the Human-Robot Workcell Scenario ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">4</span></a>.
Differently, our framework produces consistently better results on both scenarios, displaying excellent generalization power and adaptability to real multi-camera setups.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">While results on Human3.6M-Occluded already confirmed the superior performance of our method in presence of significant occlusions, results on the real human-robot collaboration scenario really highlight the shortcomings of current methods and the true advantage of our framework. Nevertheless, the discrepancy that we observe between our results and those provided by the literature is due to conditions that characterize industrial multi-camera setups, such as camera synchronization errors and large occlusions on all viewpoints. These factors are not considered in public datasets¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib12" title="">12</a>]</cite>, and thus, not handled by most approaches in the literature.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="210" id="S4.F3.g1" src="extracted/5819025/figures/industrial_workcell_results.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Qualitative comparison between our approach and the state of the art on the industrial workcell scenario.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="204" id="S4.F4.g1" src="extracted/5819025/figures/lab_workcell_results.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">Qualitative results of our approach and state-of-the-art multi-view methods on the laboratory collaborative workcell.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.2.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.3.2" style="font-size:90%;">The results of evaluation on data sequences collected in real human-robot workcells. The table presents the MPJPE relative to pelvis for our method and state-of-the-art multi-view human pose estimation algorithms.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.4" style="width:303.5pt;height:80.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-85.1pt,22.6pt) scale(0.640626148298919,0.640626148298919) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" colspan="9" id="S4.T5.4.1.1.1.1">MPJPE relative to pelvis, mm</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.4.1.2.1.1">Methods</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.2">Seq 1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.3">Seq 2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.4">Seq 3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.5">Seq 4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.6">Seq 5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.7">Seq 6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.8">Seq 7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.4.1.2.1.9"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.2.1.9.1">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.4.1.3.2.1">RANSAC (as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.2">541.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.3">265.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.4">328.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.5">312.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.6">261.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.7">287.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.8">260.4</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.4.1.3.2.9">322.4</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.4.1.4.3.1">T-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T5.4.1.4.3.1.1">et al</em>.<span class="ltx_text" id="S4.T5.4.1.4.3.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.2">439.5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.3">257.5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.4">315.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.5">307.0</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.6">270.7</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.7">288.1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.3.8">257.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.4.1.4.3.9">305.2</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.4.1.5.4.1">Zhang <em class="ltx_emph ltx_font_italic" id="S4.T5.4.1.5.4.1.1">et al</em>.<span class="ltx_text" id="S4.T5.4.1.5.4.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.2">580.7</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.3">370.0</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.4">402.1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.5">447.0</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.6">347.2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.7">344.9</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.4.8">321.7</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.4.1.5.4.9">401.9</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.4.1.6.5.1">Ma <em class="ltx_emph ltx_font_italic" id="S4.T5.4.1.6.5.1.1">et al</em>.<span class="ltx_text" id="S4.T5.4.1.6.5.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.2">505.7</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.3">453.7</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.4">446.9</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.5">481.4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.6">412.5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.7">430.5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.5.8">410.9</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.4.1.6.5.9">448.8</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.1"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.1.1">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.2.1">90.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.3"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.3.1">98.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.4"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.4.1">87.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.5"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.5.1">88.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.6"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.6.1">100.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.7"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.7.1">114.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.8"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.8.1">109.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.4.1.7.6.9"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.7.6.9.1">98.6</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.2.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="S4.T6.3.2" style="font-size:90%;">The table presents the absolute MPJPE on data collected in real human-robot workcells for our method and state-of-the-art multi-view human pose estimation algorithms.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T6.4" style="width:303.5pt;height:75.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-102.2pt,25.4pt) scale(0.597536681369844,0.597536681369844) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="9" id="S4.T6.4.1.1.1.1">MPJPE absolute, mm</th>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T6.4.1.2.2.1">Methods</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.2">Seq 1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.3">Seq 2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.4">Seq 3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.5">Seq 4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.6">Seq 5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.7">Seq 6</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.8">Seq 7</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.4.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.2.2.9.1">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.4.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.4.1.3.1.1">RANSAC (as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.2">8981.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.3">7295.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.4">8109.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.5">7336.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.6">2800.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.7">2817.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.8">2813.5</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T6.4.1.3.1.9">5736.2</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.1.4.2.1">T-Iskakov <em class="ltx_emph ltx_font_italic" id="S4.T6.4.1.4.2.1.1">et al</em>.<span class="ltx_text" id="S4.T6.4.1.4.2.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib11" title="">11</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.2">8784.7</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.3">7291.9</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.4">8112.4</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.5">7327.2</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.6">2796.3</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.7">2813.9</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.2.8">2808.4</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.1.4.2.9">5705.0</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.1.5.3.1">Zhang <em class="ltx_emph ltx_font_italic" id="S4.T6.4.1.5.3.1.1">et al</em>.<span class="ltx_text" id="S4.T6.4.1.5.3.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.2">9000.7</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.3">7276.1</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.4">8116.3</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.5">7308.6</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.6">2754.0</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.7">2765.7</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.5.3.8">2773.4</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.1.5.3.9">5713.5</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.1.6.4.1">Ma <em class="ltx_emph ltx_font_italic" id="S4.T6.4.1.6.4.1.1">et al</em>.<span class="ltx_text" id="S4.T6.4.1.6.4.1.2"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.2">8907.5</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.3">7370.7</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.4">7296.0</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.5">8211.2</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.6">2788.6</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.7">2785.8</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.6.4.8">2786.8</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.1.6.4.9">5735.2</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.1"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.1.1">Ours</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.2"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.2.1">110.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.3"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.3.1">106.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.4"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.4.1">171.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.5"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.5.1">154.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.6"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.6.1">116.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.7"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.7.1">198.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.8"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.8.1">140.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T6.4.1.7.5.9"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.7.5.9.1">142.7</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Studies</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">In the remainder of this section we consider the Human3.6M and the Human3.6M-Occluded benchmarks to carry out ablation studies on different aspects typical of real industrial scenarios: (i) imperfect synchronization of cameras and (ii) heavy occlusions with few viewpoints available.</p>
</div>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F6.1" style="width:212.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="598" id="S4.F6.1.g1" src="extracted/5819025/figures/ablation_synch.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.1.1.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F6.1.2.2" style="font-size:90%;">Variation of relative and absolute MPJPE with increasing number of de-synchronized cameras. Solid lines represent variation of the relative error, dashed lines represent variation of the absolute errors.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.F6.2" style="width:212.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="598" id="S4.F6.2.g1" src="extracted/5819025/figures/ablation_views.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.2.1.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.2.2.2" style="font-size:90%;">Relative and absolute MPJPE gradually removing the number of viewpoints, with occlusions. Solid lines represent variation of the relative error, dashed lines represent variation of the absolute errors.</span></figcaption>
</figure>
</div>
</div>
</figure>
<section class="ltx_subsubsection" id="S4.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Camera Synchronization</h4>
<div class="ltx_para" id="S4.SS4.SSS1.p1">
<p class="ltx_p" id="S4.SS4.SSS1.p1.2">While public datasets are acquired in very constrained and controlled environments employing reliable camera synchronization mechanisms, such conditions are hardly met in industrial environments. To assess the advantages of our method, we now isolate the effect of slight errors in camera synchronization on multi-view human pose estimation methods.
Considering the Human3.6M dataset, we study the variation of the mean joint position error as we simulate synchronization errors on an increasing number of cameras.
At first, three of the four cameras will give the correct frame corresponding to time <math alttext="t" class="ltx_Math" display="inline" id="S4.SS4.SSS1.p1.1.m1.1"><semantics id="S4.SS4.SSS1.p1.1.m1.1a"><mi id="S4.SS4.SSS1.p1.1.m1.1.1" xref="S4.SS4.SSS1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p1.1.m1.1b"><ci id="S4.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS1.p1.1.m1.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p1.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS1.p1.1.m1.1d">italic_t</annotation></semantics></math> while we simulate a synchronization error on the fourth one. The de-synchronized camera will give a frame corresponding to a wrong timestamp <math alttext="t_{e}" class="ltx_Math" display="inline" id="S4.SS4.SSS1.p1.2.m2.1"><semantics id="S4.SS4.SSS1.p1.2.m2.1a"><msub id="S4.SS4.SSS1.p1.2.m2.1.1" xref="S4.SS4.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS4.SSS1.p1.2.m2.1.1.2" xref="S4.SS4.SSS1.p1.2.m2.1.1.2.cmml">t</mi><mi id="S4.SS4.SSS1.p1.2.m2.1.1.3" xref="S4.SS4.SSS1.p1.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p1.2.m2.1b"><apply id="S4.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS4.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS4.SSS1.p1.2.m2.1.1.2">ùë°</ci><ci id="S4.SS4.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS4.SSS1.p1.2.m2.1.1.3">ùëí</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p1.2.m2.1c">t_{e}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS1.p1.2.m2.1d">italic_t start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, defined according to <a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.E6" title="In 4.4.1 Camera Synchronization ‚Ä£ 4.4 Ablation Studies ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Equation</span>¬†<span class="ltx_text ltx_ref_tag">6</span></a>.</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="t_{e}=t+e\ \ \text{with}\ \ e\sim\text{Uniform}(\{-2,-1,+1,+2\})" class="ltx_Math" display="block" id="S4.E6.m1.3"><semantics id="S4.E6.m1.3a"><mrow id="S4.E6.m1.3.3.2" xref="S4.E6.m1.3.3.3.cmml"><mrow id="S4.E6.m1.2.2.1.1" xref="S4.E6.m1.2.2.1.1.cmml"><msub id="S4.E6.m1.2.2.1.1.3" xref="S4.E6.m1.2.2.1.1.3.cmml"><mi id="S4.E6.m1.2.2.1.1.3.2" xref="S4.E6.m1.2.2.1.1.3.2.cmml">t</mi><mi id="S4.E6.m1.2.2.1.1.3.3" xref="S4.E6.m1.2.2.1.1.3.3.cmml">e</mi></msub><mo id="S4.E6.m1.2.2.1.1.2" xref="S4.E6.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E6.m1.2.2.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.2.cmml"><mrow id="S4.E6.m1.2.2.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.2.cmml">t</mi><mo id="S4.E6.m1.2.2.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.cmml">+</mo><mi id="S4.E6.m1.2.2.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.3.cmml">e</mi></mrow><mspace id="S4.E6.m1.2.2.1.1.1.1.2" width="1em" xref="S4.E6.m1.2.2.1.1.1.2.cmml"></mspace><mtext id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1a.cmml">with</mtext></mrow></mrow><mspace id="S4.E6.m1.3.3.2.3" width="1em" xref="S4.E6.m1.3.3.3a.cmml"></mspace><mrow id="S4.E6.m1.3.3.2.2" xref="S4.E6.m1.3.3.2.2.cmml"><mi id="S4.E6.m1.3.3.2.2.3" xref="S4.E6.m1.3.3.2.2.3.cmml">e</mi><mo id="S4.E6.m1.3.3.2.2.2" xref="S4.E6.m1.3.3.2.2.2.cmml">‚àº</mo><mrow id="S4.E6.m1.3.3.2.2.1" xref="S4.E6.m1.3.3.2.2.1.cmml"><mtext id="S4.E6.m1.3.3.2.2.1.3" xref="S4.E6.m1.3.3.2.2.1.3a.cmml">Uniform</mtext><mo id="S4.E6.m1.3.3.2.2.1.2" xref="S4.E6.m1.3.3.2.2.1.2.cmml">‚Å¢</mo><mrow id="S4.E6.m1.3.3.2.2.1.1.1" xref="S4.E6.m1.3.3.2.2.1.cmml"><mo id="S4.E6.m1.3.3.2.2.1.1.1.2" stretchy="false" xref="S4.E6.m1.3.3.2.2.1.cmml">(</mo><mrow id="S4.E6.m1.3.3.2.2.1.1.1.1.4" xref="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml"><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.4.5" stretchy="false" xref="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml">{</mo><mrow id="S4.E6.m1.3.3.2.2.1.1.1.1.1.1" xref="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.cmml"><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.1.1a" xref="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.cmml">‚àí</mo><mn id="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.2" xref="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.2.cmml">2</mn></mrow><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.4.6" xref="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml">,</mo><mrow id="S4.E6.m1.3.3.2.2.1.1.1.1.2.2" xref="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.cmml"><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.2.2a" xref="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.cmml">‚àí</mo><mn id="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.2" xref="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.2.cmml">1</mn></mrow><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.4.7" xref="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml">,</mo><mrow id="S4.E6.m1.3.3.2.2.1.1.1.1.3.3" xref="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.cmml"><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.3.3a" xref="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.cmml">+</mo><mn id="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.2" xref="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.2.cmml">1</mn></mrow><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.4.8" xref="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml">,</mo><mrow id="S4.E6.m1.3.3.2.2.1.1.1.1.4.4" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.cmml"><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.4.4a" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.cmml">+</mo><mn id="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.2" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.2.cmml">2</mn></mrow><mo id="S4.E6.m1.3.3.2.2.1.1.1.1.4.9" stretchy="false" xref="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml">}</mo></mrow><mo id="S4.E6.m1.3.3.2.2.1.1.1.3" stretchy="false" xref="S4.E6.m1.3.3.2.2.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.3b"><apply id="S4.E6.m1.3.3.3.cmml" xref="S4.E6.m1.3.3.2"><csymbol cd="ambiguous" id="S4.E6.m1.3.3.3a.cmml" xref="S4.E6.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S4.E6.m1.2.2.1.1.cmml" xref="S4.E6.m1.2.2.1.1"><eq id="S4.E6.m1.2.2.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.2"></eq><apply id="S4.E6.m1.2.2.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.3">subscript</csymbol><ci id="S4.E6.m1.2.2.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.3.2">ùë°</ci><ci id="S4.E6.m1.2.2.1.1.3.3.cmml" xref="S4.E6.m1.2.2.1.1.3.3">ùëí</ci></apply><list id="S4.E6.m1.2.2.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1"><apply id="S4.E6.m1.2.2.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1"><plus id="S4.E6.m1.2.2.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1"></plus><ci id="S4.E6.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.2">ùë°</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.3">ùëí</ci></apply><ci id="S4.E6.m1.1.1a.cmml" xref="S4.E6.m1.1.1"><mtext id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1">with</mtext></ci></list></apply><apply id="S4.E6.m1.3.3.2.2.cmml" xref="S4.E6.m1.3.3.2.2"><csymbol cd="latexml" id="S4.E6.m1.3.3.2.2.2.cmml" xref="S4.E6.m1.3.3.2.2.2">similar-to</csymbol><ci id="S4.E6.m1.3.3.2.2.3.cmml" xref="S4.E6.m1.3.3.2.2.3">ùëí</ci><apply id="S4.E6.m1.3.3.2.2.1.cmml" xref="S4.E6.m1.3.3.2.2.1"><times id="S4.E6.m1.3.3.2.2.1.2.cmml" xref="S4.E6.m1.3.3.2.2.1.2"></times><ci id="S4.E6.m1.3.3.2.2.1.3a.cmml" xref="S4.E6.m1.3.3.2.2.1.3"><mtext id="S4.E6.m1.3.3.2.2.1.3.cmml" xref="S4.E6.m1.3.3.2.2.1.3">Uniform</mtext></ci><set id="S4.E6.m1.3.3.2.2.1.1.1.1.5.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4"><apply id="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.1.1"><minus id="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.1.1"></minus><cn id="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.2.cmml" type="integer" xref="S4.E6.m1.3.3.2.2.1.1.1.1.1.1.2">2</cn></apply><apply id="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.2.2"><minus id="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.1.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.2.2"></minus><cn id="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.2.cmml" type="integer" xref="S4.E6.m1.3.3.2.2.1.1.1.1.2.2.2">1</cn></apply><apply id="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.3.3"><plus id="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.1.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.3.3"></plus><cn id="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.2.cmml" type="integer" xref="S4.E6.m1.3.3.2.2.1.1.1.1.3.3.2">1</cn></apply><apply id="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4.4"><plus id="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.1.cmml" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4.4"></plus><cn id="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.2.cmml" type="integer" xref="S4.E6.m1.3.3.2.2.1.1.1.1.4.4.2">2</cn></apply></set></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.3c">t_{e}=t+e\ \ \text{with}\ \ e\sim\text{Uniform}(\{-2,-1,+1,+2\})</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.3d">italic_t start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = italic_t + italic_e with italic_e ‚àº Uniform ( { - 2 , - 1 , + 1 , + 2 } )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS4.SSS1.p1.3">Then, we simulate a synchronization error on two of the four cameras and, finally, on three out of four cameras.
<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.F6" title="In 4.4 Ablation Studies ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">6</span></a> shows how the absolute and relative MPJPE vary over the three experiments. Our method proves to be the most robust to camera synchronization errors in terms of both relative and absolute MPJPE, which increase of only 1 and 2‚Äâmm when three cameras out of four are unsynchronized.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Number of Occluded Viewpoints</h4>
<div class="ltx_para" id="S4.SS4.SSS2.p1">
<p class="ltx_p" id="S4.SS4.SSS2.p1.1">To study the robustness of multi-view pose estimation approaches in presence of few occluded viewpoints, we consider Human3.6-Occluded and progressively reduce the number of available cameras to three and to two.
It is worth noticing that in Human3.6M-Occluded, for each scene, three out of four views contain occlusions and the occluded cameras are selected at random. This means that when removing a camera, it can happen that for some scenes all views are occluded.</p>
</div>
<div class="ltx_para" id="S4.SS4.SSS2.p2">
<p class="ltx_p" id="S4.SS4.SSS2.p2.1"><a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#S4.F6" title="In 4.4 Ablation Studies ‚Ä£ 4 Experiments ‚Ä£ Multi-view Pose Fusion for Occlusion-Aware 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">6</span></a> shows the relative and absolute MPJPE with reduced number of viewpoints for the compared methods. For a fair comparison, we do not consider TransFusion¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.15810v1#bib.bib17" title="">17</a>]</cite> for this ablation study, as this approach requires to be re-trained when the number of available cameras change.
One can easily notice that our framework is the most robust to significant occlusions with few viewpoints, yielding a relative and absolute joint position error of about 6‚Äâcm when tested on scenes with only two cameras and occlusions on at least one view.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we proposed a novel multi-view 3D pose fusion approach for robust and reliable 3D human pose estimation in human-robot collaboration scenarios, generally characterized by significant occlusions and limited camera viewpoints. While most methods rely on 2D keypoints triangulation, we aggregate single-view 3D joint predictions, proposing a per-joint weighting depending on the mean reprojection error on all views, to mitigate the effect of incorrect predictions. The fused 3D pose is further refined via reprojection error optimization, introducing limb length symmetry constraints to enhance estimation accuracy.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Our framework was evaluated on challenging scenarios with sever occlusions, considering data sequences from real human-robot collaboration workcells and the proposed benchmark Human3.6M-Occluded. Our method outperforms state-of-the-art techniques on heavy occlusions and exhibits strong generalization capabilities to unseen environments, making it a suitable solution for 3D human pose estimation in challenging human-robot collaboration settings.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The research leading to these results has received funding from the European Union‚Äôs Horizon 2020 research and innovation programme under grant agreement No. 101006732 (DrapeBot).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Boldo, M., De¬†Marchi, M., Martini, E., Aldegheri, S., Quaglia, D., Fummi, F., Bombieri, N.: Real-time multi-camera 3d human pose estimation at the edge for industrial applications. Expert Syst. Appl. <span class="ltx_text ltx_font_bold" id="bib.bib1.1.1">252</span>, 124089 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Bridgeman, L., Volino, M., Guillemaut, J.Y., Hilton, A.: Multi-person 3d pose estimation and tracking in sports. In: IEEE Conf. Comput. Vis. Pattern Recog. Worksh. pp.¬†0‚Äì0 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Chen, Z., Zhao, X., Wan, X.: Structural triangulation: A closed-form solution to constrained 3d human pose estimation. In: Eur. Conf. Comput. Vis. pp. 695‚Äì711. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Cheng, Y., Yang, B., Wang, B., Yan, W., Tan, R.T.: Occlusion-aware networks for 3d human pose estimation in video. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 723‚Äì732 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Everingham, M., Van¬†Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Ghidoni, S., Terreran, M., Evangelista, D., Eitzinger, C., Zambal, S., Villagrossi, E., Pedrocchi, N., Castaman, N., Malecha, M.: A smart workcell for human-robot cooperative assembly of carbon fiber parts. In: Atti della 4¬™ Conferenza Italiana di Robotica e Macchine Intelligenti (2021). https://doi.org/10.5281/zenodo.6367920

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Gong, J., Foo, L.G., Fan, Z., Ke, Q., Rahmani, H., Liu, J.: Diffpose: Toward more reliable 3d pose estimation. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 13041‚Äì13051 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Guidolin, M., Tagliapietra, L., Menegatti, E., Reggiani, M.: Hi-ros: Open-source multi-camera sensor fusion for real-time people tracking. Comput. Vis. Image Und. <span class="ltx_text ltx_font_bold" id="bib.bib8.1.1">232</span>, 103694 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
He, Y., Yan, R., Fragkiadaki, K., Yu, S.I.: Epipolar transformer for multi-view human pose estimation. In: IEEE Conf. Comput. Vis. Pattern Recog. Worksh. pp. 1036‚Äì1037 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Ionescu, C., Papava, D., Olaru, V., Sminchisescu, C.: Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE Trans. Pattern Anal. Mach. Intell. <span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">36</span>(7), 1325‚Äì1339 (2013)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Iskakov, K., Burkov, E., Lempitsky, V., Malkov, Y.: Learnable triangulation of human pose. In: Int. Conf. Comput. Vis. pp. 7718‚Äì7727 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Joo, H., Liu, H., Tan, L., Gui, L., Nabbe, B., Matthews, I., Kanade, T., Nobuhara, S., Sheikh, Y.: Panoptic studio: A massively multiview system for social motion capture. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 3334‚Äì3342 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Joo, H., Neverova, N., Vedaldi, A.: Exemplar fine-tuning for 3d human model fitting towards in-the-wild 3d human pose estimation. In: 3DV. pp. 42‚Äì52. IEEE (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Kocabas, M., Huang, C.H.P., Hilliges, O., Black, M.J.: Pare: Part attention regressor for 3d human body estimation. In: Int. Conf. Comput. Vis. pp. 11127‚Äì11137 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Li, W., Liu, H., Tang, H., Wang, P., Van¬†Gool, L.: Mhformer: Multi-hypothesis transformer for 3d human pose estimation. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 13147‚Äì13156 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Lin, H.Y., Chen, T.W.: Augmented reality with human body interaction based on monocular 3d pose estimation. In: International Conference on Advanced Concepts for Intelligent Vision Systems. pp. 321‚Äì331. Springer (2010)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Ma, H., Chen, L., Kong, D., Wang, Z., Liu, X., Tang, H., Yan, X., Xie, Y., Lin, S.Y., Xie, X.: Transfusion: Cross-view fusion with transformer for 3d human pose estimation. arXiv preprint arXiv:2110.09554 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Mehta, D., Sotnychenko, O., Mueller, F., Xu, W., Sridhar, S., Pons-Moll, G., Theobalt, C.: Single-shot multi-person 3d pose estimation from monocular rgb. In: 3DV. pp. 120‚Äì130. IEEE (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Moliner, O., Huang, S., √Östr√∂m, K.: Geometry-biased transformer for robust multi-view 3d human pose reconstruction. In: FG. pp.¬†1‚Äì8. IEEE (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Munaro, M., Basso, F., Menegatti, E.: Openptrack: Open source multi-camera calibration and people tracking for rgb-d camera networks. RAS <span class="ltx_text ltx_font_bold" id="bib.bib20.1.1">75</span>, 525‚Äì538 (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Pavlakos, G., Choutas, V., Ghorbani, N., Bolkart, T., Osman, A.A., Tzionas, D., Black, M.J.: Expressive body capture: 3d hands, face, and body from a single image. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 10975‚Äì10985 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 459‚Äì468 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Peng, K., Roitberg, A., Yang, K., Zhang, J., Stiefelhagen, R.: Delving deep into one-shot skeleton-based action recognition with diverse occlusions. IEEE Trans. Multimedia <span class="ltx_text ltx_font_bold" id="bib.bib23.1.1">25</span>, 1489‚Äì1504 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
S√°r√°ndi, I., Hermans, A., Leibe, B.: Learning 3d human pose estimation from dozens of datasets using a geometry-aware autoencoder to bridge between skeleton formats. In: WACV. pp. 2956‚Äì2966 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
S√°r√°ndi, I., Linder, T., Arras, K.O., Leibe, B.: How robust is 3d human pose estimation to occlusion? arXiv preprint arXiv:1808.09316 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
S√°r√°ndi, I., Linder, T., Arras, K.O., Leibe, B.: Metrabs: metric-scale truncation-robust heatmaps for absolute 3d human pose estimation. IEEE Trans. Biom. Behav. Identity Sci. <span class="ltx_text ltx_font_bold" id="bib.bib26.1.1">3</span>(1), 16‚Äì30 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Schepers, M., Giuberti, M., Bellusci, G., et¬†al.: Xsens mvn: Consistent tracking of human motion using inertial sensing. Xsens Technol <span class="ltx_text ltx_font_bold" id="bib.bib27.1.1">1</span>(8), ¬†1‚Äì8 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Terreran, M., Barcellona, L., Ghidoni, S.: A general skeleton-based action and gesture recognition framework for human‚Äìrobot collaboration. RAS <span class="ltx_text ltx_font_bold" id="bib.bib28.1.1">170</span>, 104523 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Terreran, M., Ghidoni, S., Menegatti, E., Villagrossi, E., Pedrocchi, N., Castaman, N., Gottardi, A., Eitzinger, C., Vescovi, L., Salemi, G., et¬†al.: A smart workcell for cooperative assembly of carbon fiber parts guided by human actions. In: Atti della 4¬™ Conferenza Italiana di Robotica e Macchine Intelligenti (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Terreran, M., Lazzaretto, M., Ghidoni, S.: Skeleton-based action and gesture recognition for human-robot collaboration. In: International Conference on Intelligent Autonomous Systems. pp. 29‚Äì45. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Trumble, M., Gilbert, A., Malleson, C., Hilton, A., Collomosse, J.P.: Total capture: 3d human pose estimation fusing video and inertial sensors. In: Brit. Mach. Vis. Conf. vol.¬†2, pp. 1‚Äì13. London, UK (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Wan, X., Chen, Z., Zhao, X.: View consistency aware holistic triangulation for 3d human pose estimation. Comput. Vis. Image Und. <span class="ltx_text ltx_font_bold" id="bib.bib32.1.1">236</span>, 103830 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Zhan, Y., Li, F., Weng, R., Choi, W.: Ray3d: ray-based 3d human pose estimation for monocular absolute 3d localization. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 13116‚Äì13125 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Zhang, J., Tu, Z., Yang, J., Chen, Y., Yuan, J.: Mixste: Seq2seq mixed spatio-temporal encoder for 3d human pose estimation in video. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 13232‚Äì13242 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Zhang, T., Huang, B., Wang, Y.: Object-occluded human shape and pose estimation from a single color image. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 7376‚Äì7385 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Zhang, Y., Ji, P., Wang, A., Mei, J., Kortylewski, A., Yuille, A.: 3d-aware neural body fitting for occlusion robust 3d human pose estimation. In: Int. Conf. Comput. Vis. pp. 9399‚Äì9410 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Zhang, Z., Wang, C., Qiu, W., Qin, W., Zeng, W.: Adafuse: Adaptive multiview fusion for accurate human pose estimation in the wild. Int. J. Comput. Vis. <span class="ltx_text ltx_font_bold" id="bib.bib37.1.1">129</span>, 703‚Äì718 (2021)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug 28 14:04:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
