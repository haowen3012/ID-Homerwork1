<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference</title>
<!--Generated on Wed Jun 26 16:00:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
3D Relative Pose Estimation,  Differentiable Renderer,  Zero-Shot Unseen Generalization,  Single Reference,  Label/Training-Free Refinement.
" lang="en" name="keywords"/>
<base href="/html/2406.18453v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1" title="In Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.SS1" title="In I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">I-A</span> </span><span class="ltx_text ltx_font_italic">Taxonomy and Applicability of Our Method</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2" title="In Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.SS1" title="In II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Instance-level 6D Pose Estimation </span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.SS2" title="In II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Category-level 6D Pose Estimation </span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.SS3" title="In II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">Generalizable 6D Pose Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.SS4" title="In II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-D</span> </span><span class="ltx_text ltx_font_italic">Generalizable Relative Pose Estimation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3" title="In Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Method</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS1" title="In III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Overview</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS2" title="In III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Semantic Map Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS3" title="In III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Textured 2.5D Mesh Reconstruction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS4" title="In III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Label/Training-Free Refinement via Differentiable Renderer</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4" title="In Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.SS1" title="In IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Experimental Setups</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.SS2" title="In IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Experimental Results on the LineMOD Dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.SS3" title="In IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Experimental Results on the YCB-V Dataset</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.SS4" title="In IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic">Experimental Results on the LM-O Dataset</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5" title="In Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Ablation Analysis</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS1" title="In V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">The Contributions of the Proposed Comprising Elements</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS2" title="In V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Effects of Different Initialization Strategies</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS3" title="In V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Effects of Different Refinement Iterations.</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS4" title="In V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">The Statistics of Our Inference Time</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS5" title="In V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-E</span> </span><span class="ltx_text ltx_font_italic">Illustrations of the Failure Cases</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S6" title="In Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Discussions and Conclusions</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuan Gao*, Yajing Luo*, Junhong Wang, Kui Jia, Gui-Song Xia
</span><span class="ltx_author_notes">
Y. Gao is with the School of Electronic Information, Wuhan University, Wuhan, China. E-mail: ethan.y.gao@gmail.com
Y. Luo and G.-S. Xia are with the School of Computer Science, Wuhan University, Wuhan, China. E-mails: {yajingluo, guisong.xia}@whu.edu.cn
J. Wang is with MoreFun Studio, Tencent Games, Tencent, Shenzhen, China. E-mails: junhongwang@tencent.com
K. Jia is with the School of Data Science, The Chinese University of Hong Kong, Shenzhen, China. E-mails: kuijia@cuhk.edu.cn
Corresponding authors: Gui-Song Xia, Yuan Gao.* indicates equal contribution.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Humans can easily deduce the relative pose of a previously unseen object, without labeling or training, given only a single query-reference image pair. This is arguably achieved by incorporating (i) 3D/2.5D shape perception from a single image, (ii) render-and-compare simulation, and (iii) rich semantic cue awareness to furnish (coarse) reference-query correspondence. Existing methods implement (i) by a 3D CAD model or well-calibrated multiple images and (ii) by training a network on specific objects, which necessitate laborious ground-truth labeling and tedious training, potentially leading to challenges in generalization. Moreover, (iii) was less exploited in the paradigm of (ii), despite that the coarse correspondence from (iii) is able to enhance the compare process by filtering out non-overlapped parts under substantial pose differences/occlusions. Motivated by this, we propose a novel 3D generalizable relative pose estimation method by elaborating (i) with a 2.5D shape from an RGB-D reference, (ii) with an off-the-shelf differentiable renderer, and (iii) with semantic cues from a pretrained model like DINOv2. Specifically, our differentiable renderer takes the 2.5D rotatable mesh textured by the RGB and the semantic maps (obtained by DINOv2 from the RGB input), then renders new RGB and semantic maps (with back-surface culling) under a novel rotated view. The refinement loss comes from comparing the rendered RGB and semantic maps with the query ones, back-propagating the gradients through the differentiable renderer to refine the 3D relative pose. As a result, <em class="ltx_emph ltx_font_italic" id="id1.1.2">our method can be readily applied to unseen objects, given only a single RGB-D reference, without labeling or training</em>. Extensive experiments on LineMOD, LM-O, and YCB-V show that our training-free method significantly outperforms the state-of-the-art supervised methods, especially under the rigorous <span class="ltx_text ltx_font_typewriter" id="id1.1.1">Acc@5/10/15<sup class="ltx_sup" id="id1.1.1.1"><span class="ltx_text ltx_font_serif" id="id1.1.1.1.1">∘</span></sup></span> metrics and the challenging cross-dataset settings. The codes are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ethanygao/training-free_generalizable_relative_pose" title="">https://github.com/ethanygao/training-free_generalizable_relative_pose</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
3D Relative Pose Estimation, Differentiable Renderer, Zero-Shot Unseen Generalization, Single Reference, Label/Training-Free Refinement.

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent years have witnessed great progress in 3D object pose estimation <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib40" title=""><span class="ltx_text" style="font-size:80%;">nguyen2023nope</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib66" title=""><span class="ltx_text" style="font-size:80%;">wang2024object</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib63" title=""><span class="ltx_text" style="font-size:80%;">wang2021nemo</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib20" title=""><span class="ltx_text" style="font-size:80%;">kaushik2024source</span> </a></cite>, which estimates the 3D rotation of an object depicted in a query RGB image. As a key to facilitating interaction with real-world objects, 3D object pose estimation attracts increasing attention from various areas including computer vision, virtual/augmented reality, robotics, and human-computer interaction <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib48" title=""><span class="ltx_text" style="font-size:80%;">perez2016robot</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib1" title=""><span class="ltx_text" style="font-size:80%;">robots</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib58" title=""><span class="ltx_text" style="font-size:80%;">AR</span> </a></cite>. To date, the community shows great interest in generalizable 3D object pose estimation <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">onepose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">onepose++</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib75" title=""><span class="ltx_text" style="font-size:80%;">relpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> owing to its wide applicability, which focuses on the generalization to previously unseen objects, preferably in a zero-shot manner<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We discuss the relatively easier instance- or category-level object pose estimation in the Related Work Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.SS1" title="II-A Instance-level 6D Pose Estimation ‣ II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-A</span></span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.SS2" title="II-B Category-level 6D Pose Estimation ‣ II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-B</span></span></a>, respectively.</span></span></span>.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<p class="ltx_p ltx_align_center" id="S1.F1.1"><span class="ltx_text" id="S1.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="373" id="S1.F1.1.1.g1" src="x1.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.3.1">Generalizable object pose estimation with different references, i.e., <em class="ltx_emph ltx_font_italic" id="S1.F1.3.1.1">a CAD model, multiple images</em>, or <em class="ltx_emph ltx_font_italic" id="S1.F1.3.1.2">a single image</em>.</span> CAD models and multi-view references offer rich geometry details, however, scanning the precise CAD model and/or calibrating dense views for multiple images are laborious or even impossible for unseen objects in practice, such as augmented reality. We thus focus on estimating the relative pose w.r.t. a single-view reference following <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>, i.e., the relative pose between a reference-query pair, where we treat the reference pose as canonical without any calibration.</figcaption>
</figure>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The taxonomy of our method in <span class="ltx_text ltx_font_bold" id="S1.T1.4.1">generalizable pose estimation</span>. For each column, we illustrate the applicability in descending order using the text of <span class="ltx_text ltx_font_bold" id="S1.T1.5.2">Bold</span>, <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.6.3">Underlined</span>, and Normal. We also include the Human Intelligence as a reference. The state-of-the-art methods used in our experiments are highlighted with their name.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.T1.7" style="width:346.9pt;height:77.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-288.8pt,64.9pt) scale(0.37520371987079,0.37520371987079) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S1.T1.7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S1.T1.7.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S1.T1.7.1.1.1.1" rowspan="2"><span class="ltx_text" id="S1.T1.7.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.7.1.1.1.2" rowspan="2"><span class="ltx_text" id="S1.T1.7.1.1.1.2.1">Training</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.7.1.1.1.3" rowspan="2"><span class="ltx_text" id="S1.T1.7.1.1.1.3.1">Label</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S1.T1.7.1.1.1.4">Reference</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S1.T1.7.1.1.1.5">Query</th>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.2.2.1">Modality</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.2.2.2">#Instance</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.2.2.3">Modality</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.2.2.4">#Instance</th>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S1.T1.7.1.3.3.1">Human Intelligence</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.3.3.2"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.3.3.2.1">training-free</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.3.3.3"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.3.3.3.1">label-free</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.3.3.4"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.3.3.4.1">RGB</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.3.3.5"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.3.3.5.1">single</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.3.3.6"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.3.3.6.1">RGB</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S1.T1.7.1.3.3.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.3.3.7.1">single</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S1.T1.7.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S1.T1.7.1.4.1.1"><cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib8" title=""><span class="ltx_text" style="font-size:80%;">zeropose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib43" title=""><span class="ltx_text" style="font-size:80%;">zephyr</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib33" title=""><span class="ltx_text" style="font-size:80%;">lin2023sam6d</span> </a></cite></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.7.1.4.1.2">supervised</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.7.1.4.1.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.4.1.3.1">pose</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.7.1.4.1.4">CAD</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.7.1.4.1.5">multiple</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.7.1.4.1.6">RGB-D</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.7.1.4.1.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.4.1.7.1">single</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.7.1.5.2.1"><cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib54" title=""><span class="ltx_text" style="font-size:80%;">osop</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">megapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib45" title=""><span class="ltx_text" style="font-size:80%;">ornek2023foundpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib41" title=""><span class="ltx_text" style="font-size:80%;">nguyen2023gigapose</span> </a></cite></th>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.5.2.2">supervised</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.5.2.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.5.2.3.1">pose</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.5.2.4">CAD</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.5.2.5">multiple</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.5.2.6"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.5.2.6.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.5.2.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.5.2.7.1">single</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.7.1.6.3.1"><cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib17" title=""><span class="ltx_text" style="font-size:80%;">fs6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">latentfusion</span> </a></cite></th>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.6.3.2">supervised</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.6.3.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.6.3.3.1">pose</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.6.3.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.6.3.4.1">RGB-D</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.6.3.5">multiple</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.6.3.6">RGB-D</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.6.3.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.6.3.7.1">single</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.7.1.7.4.1">RelPose++ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite>, <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">gen6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">onepose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">onepose++</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib75" title=""><span class="ltx_text" style="font-size:80%;">relpose</span> </a></cite>
</th>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.7.4.2">supervised</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.7.4.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.7.4.3.1">pose</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.7.4.4"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.7.4.4.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.7.4.5">multiple</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.7.4.6"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.7.4.6.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.7.4.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.7.4.7.1">single</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.7.1.8.5.1">LoFTR <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib56" title=""><span class="ltx_text" style="font-size:80%;">loftr</span> </a></cite>
</th>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.8.5.2">supervised</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.8.5.3">pose+depth</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.8.5.4"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.8.5.4.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.8.5.5"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.8.5.5.1">single</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.8.5.6"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.8.5.6.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.8.5.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.8.5.7.1">single</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.7.1.9.6.1">3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>
</th>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.9.6.2">supervised</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.9.6.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.9.6.3.1">pose</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.9.6.4"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.9.6.4.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.9.6.5"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.9.6.5.1">single</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.9.6.6"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.9.6.6.1">RGB</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.9.6.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.9.6.7.1">single</span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S1.T1.7.1.10.7.1">ZSP <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib14" title=""><span class="ltx_text" style="font-size:80%;">zsp</span> </a></cite>
</th>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.10.7.2"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.10.7.2.1">training-free</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.10.7.3"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.10.7.3.1">label-free</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.10.7.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.10.7.4.1">RGB-D</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.10.7.5"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.10.7.5.1">single</span></td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.10.7.6">RGB-D</td>
<td class="ltx_td ltx_align_center" id="S1.T1.7.1.10.7.7">multiple</td>
</tr>
<tr class="ltx_tr" id="S1.T1.7.1.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S1.T1.7.1.11.8.1">Ours</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.7.1.11.8.2"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.11.8.2.1">training-free</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.7.1.11.8.3"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.11.8.3.1">label-free</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.7.1.11.8.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S1.T1.7.1.11.8.4.1">RGB-D</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.7.1.11.8.5"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.11.8.5.1">single</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.7.1.11.8.6"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.11.8.6.1">RGB</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.7.1.11.8.7"><span class="ltx_text ltx_font_bold" id="S1.T1.7.1.11.8.7.1">single</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Existing generalizable 3D object pose estimation methods can be categorized according to how they exploit the reference information, i.e., using <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">a CAD model, multiple images</em>, or <em class="ltx_emph ltx_font_italic" id="S1.p2.1.2">a single image</em> as references, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.F1" title="Figure 1 ‣ I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, most existing methods leverage a 3D CAD model <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">megapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib54" title=""><span class="ltx_text" style="font-size:80%;">osop</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib8" title=""><span class="ltx_text" style="font-size:80%;">zeropose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib43" title=""><span class="ltx_text" style="font-size:80%;">zephyr</span> </a></cite> or multiple images <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">latentfusion</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">gen6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">onepose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">onepose++</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib17" title=""><span class="ltx_text" style="font-size:80%;">fs6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib75" title=""><span class="ltx_text" style="font-size:80%;">relpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite> for template matching or feature extraction, while the requirement of laborious 3D scanning (for the CAD-based methods) or multiple-image pose labeling (for most multi-image methods) severely limits their applicability.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">On the other hand, recent methods propose to reframe the generalizable object pose estimation task as relative pose estimation between a query and a reference images from an unseen object, which is termed as <em class="ltx_emph ltx_font_italic" id="S1.p3.1.1">generalizable <span class="ltx_text ltx_font_bold" id="S1.p3.1.1.1">relative</span> object pose estimation</em> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>. By treating the reference pose as canonical, estimating the relative pose between the reference-query pair successfully bypasses the laborious 3D scanning (of the CAD reference) or dense views calibration (of the multiple-image reference). However, existing methods rely on a large amount of well-labeled poses between the query-reference pairs to effectively train a neural network, thereby imposing the challenge of acquiring high-quantity training data <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib75" title=""><span class="ltx_text" style="font-size:80%;">relpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite>. Moreover, the generalizability of some network-based methods may be hindered by the training datasets. We empirically find that after pretrained on an external large-scale dataset such as Objaverse <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib11" title=""><span class="ltx_text" style="font-size:80%;">objaverse</span> </a></cite>, the current state-of-the-art methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> need to perform in-dataset finetune<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The in-dataset finetuning denotes that the finetune set comes from the same dataset with the testing set, while not including the testing objects.</span></span></span> before testing on the in-dataset unseen objects, which impedes the cross-dataset generalize-ability.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this context, we work towards universally applicable zero-shot 3D generalizable relative pose estimation, where (i) the object is agnostic/unseen from a cross-dataset, (ii) only a single RGB-D image is available for reference without a 3D CAD model or multi-view images, and (iii) the ground-truth (relative) pose label is not available. In other words, we aim to establish a novel 3D generalizable (in terms of both objects and datasets) relative pose estimation method given only one reference and one query image, without labeling or training. This is extremely challenging due to the mixture of <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">incomplete shape information</span> and <span class="ltx_text ltx_font_bold" id="S1.p4.1.2">missing reference-query correspondence</span>, which leads to a severely degraded optimization problem.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our method is inspired by the fact that humans can easily infer the relative pose under the aforementioned rigorous setting, even with large pose differences or severe occlusions. We hypothesize that such intelligence is accomplished through (i) perceiving 3D/2.5D shapes from a single image, (ii) conducting render-and-compare simulations via imagination, and (iii) understanding rich semantic cues of the object. For example, given two viewpoints of an unseen animal, humans are able to infer the 3D/2.5D shape of that animal, then identify the correspondences of the animal eyes, noses, ears, etc, and finally rotate and render the 3D/2.5D model until its projection matches the other view. Note that the semantic cues have the potential to deal with the (self-) occluded missing parts, thus enhancing the comparison process, e.g., an animal tail can be simply ignored in the render-and-compare simulations if it only appears in one image and is (self-) occluded in the other.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The above analysis motivates us to break down our difficulties and fulfill those three requirements. Concretely, we achieve this by formulating a label/training-free framework through an off-the-shelf differentiable renderer following the render-and-compare paradigm. Our input shape to the differentiable renderer is an RGB- and semantic-textured 2.5D mesh of the reference (avoiding the difficult 3D hallucination of an unseen object). Based on this, we construct a pose refinement framework, where the differentiable renderer takes an initial pose to render projections, then back-propagates the gradients from the projection loss (between the rendered and the query images) to refine the initial pose.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Specifically, our method starts with an RGB-D reference and an RGB query, where their semantic maps can be obtained by leveraging an advanced pretrained model DINOv2 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite> with the RGB inputs<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Note that our method possesses the potential of using only an RGB reference, please see the discussion in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.SS1" title="I-A Taxonomy and Applicability of Our Method ‣ I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">I-A</span></span></a> (Applicability) and Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S6" title="VI Discussions and Conclusions ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">VI</span></a> (Limitations and Future Works) for more details. Moreover, our method works reasonably well even without the DINOv2 semantic maps on the LineMOD dataset, as illustrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T5" title="TABLE V ‣ V-A The Contributions of the Proposed Comprising Elements ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">V</span></a>.</span></span></span>. We leverage an easy-to-use differentiable renderer nvdiffrast <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib25" title=""><span class="ltx_text" style="font-size:80%;">nvidiffrast</span> </a></cite>, which takes the RGB- and semantic-textured 2.5D mesh of the reference as input, then renders new RGB and semantic maps (with back-surface culling) under a novel rotated view. The pose refinement loss comes from comparing the rendered RGB and semantic maps with the query ones, which flows the gradients through the differentiable renderer to refine the 3D relative pose. As a result, our method can be readily applied to unseen objects from an arbitrary dataset without labeling or training.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">In summary, we propose a novel 3D generalizable relative pose estimation method, which takes only an RGB-D reference and an RGB query pair, without requiring the ground-truth pose labels or training. We achieve this by formulating a pose refinement framework via an off-the-shelf differentiable renderer under the render-and-compare paradigm. Our method does not involve training a network, which naturally possesses zero-shot generalize-ability in terms of both unseen objects and datasets. We conducted extensive experiments on LineMOD <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib18" title=""><span class="ltx_text" style="font-size:80%;">linemod</span> </a></cite>, LM-O <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib3" title=""><span class="ltx_text" style="font-size:80%;">lmo</span> </a></cite> and YCB-V <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">posecnn</span> </a></cite> datasets. The results from our training-free method exhibit significant improvement over the state-of-the-art supervised methods, e.g., for <span class="ltx_text ltx_font_typewriter" id="S1.p8.1.1">Acc@15<sup class="ltx_sup" id="S1.p8.1.1.1"><span class="ltx_text ltx_font_serif" id="S1.p8.1.1.1.1">∘</span></sup></span> metric on the LineMOD dataset <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib18" title=""><span class="ltx_text" style="font-size:80%;">linemod</span> </a></cite> and the YCB-V dataset <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">posecnn</span> </a></cite>, our label- and training-free method outperforms the supervised state-of-the-art results by <span class="ltx_text ltx_font_bold" id="S1.p8.1.2">29.98%</span> and <span class="ltx_text ltx_font_bold" id="S1.p8.1.3">14.28%</span>, respectively.</p>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S1.SS1.5.1.1">I-A</span> </span><span class="ltx_text ltx_font_italic" id="S1.SS1.6.2">Taxonomy and Applicability of Our Method</span>
</h3>
<div class="ltx_para ltx_noindent" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p1.1.1">Taxonomy</span>. The taxonomy of our methods in generalizable pose estimation, in terms of <span class="ltx_text ltx_font_typewriter" id="S1.SS1.p1.1.2">training</span>, <span class="ltx_text ltx_font_typewriter" id="S1.SS1.p1.1.3">labeling</span>, as well as the <span class="ltx_text ltx_font_typewriter" id="S1.SS1.p1.1.4">modality</span> and the <span class="ltx_text ltx_font_typewriter" id="S1.SS1.p1.1.5">number of required instances</span> of the <em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.6">reference</em> and the <em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.7">query</em> images, is illustrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.T1" title="TABLE I ‣ I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">I</span></a>. Our method falls under the category of <em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.8">label/training-free</em> with a <em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.9">single RGB query</em> and a <em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.10">single RGB-D reference</em>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S1.SS1.p2.1.1">Applicability</span>. Among Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.T1" title="TABLE I ‣ I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">I</span></a>, the proposed method shares the closest setting to the human intelligence on relative pose estimation that is able to generalize to unseen objects from an arbitrary dataset, with only an additional one-time-collection depth map for the reference image. We have testified in supplementary material that our method can still deliver good estimations with an imprecise depth map, which implies the potential to fully distill human intelligence by a generalizable depth estimator. We note that training a generalizable depth estimator is beyond the scope of, and may introduce distractions to, our current focus. In addition, our method also incorporates the segmentation maps of both query and reference objects as input, which can be obtained by pretrained segmentation models such as SAM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib23" title=""><span class="ltx_text" style="font-size:80%;">sam</span> </a></cite>, FastSAM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib79" title=""><span class="ltx_text" style="font-size:80%;">zhao2023fast</span> </a></cite> and Grounded SAM <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib52" title=""><span class="ltx_text" style="font-size:80%;">ren2024grounded</span> </a></cite>. We chose not to delve into these segmentation techniques extensively either, for the same sake of minimizing potential distractions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related work</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.5.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.6.2">Instance-level 6D Pose Estimation </span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Current object pose estimation can be categorized into instance-level, category-level, and generalizable methods based on different problem formulations. For instance-level methods, there are roughly three categories: direct regression-based, correspondence-based, and refinement-based.
Direct regression-based methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib49" title=""><span class="ltx_text" style="font-size:80%;">bb8</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib21" title=""><span class="ltx_text" style="font-size:80%;">ssd6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">posecnn</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib59" title=""><span class="ltx_text" style="font-size:80%;">yolo6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib4" title=""><span class="ltx_text" style="font-size:80%;">efficientpose</span> </a></cite> predict the object pose directly through a neural network. Correspondence-based methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib47" title=""><span class="ltx_text" style="font-size:80%;">pvnet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib16" title=""><span class="ltx_text" style="font-size:80%;">pvn3d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib30" title=""><span class="ltx_text" style="font-size:80%;">cdpn</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib73" title=""><span class="ltx_text" style="font-size:80%;">dpod</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib19" title=""><span class="ltx_text" style="font-size:80%;">epos</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib64" title=""><span class="ltx_text" style="font-size:80%;">gdrnet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib12" title=""><span class="ltx_text" style="font-size:80%;">sopose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib55" title=""><span class="ltx_text" style="font-size:80%;">zebrapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib71" title=""><span class="ltx_text" style="font-size:80%;">cvpr2023keypoint</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib31" title=""><span class="ltx_text" style="font-size:80%;">checkerpose</span> </a></cite> estimate the 2D-3D/3D-3D correspondence between the 2D images and 3D object models, followed by PnP solvers <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib28" title=""><span class="ltx_text" style="font-size:80%;">Epnp</span> </a></cite> to calculate 6D poses. Additionally, refinement-based methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib29" title=""><span class="ltx_text" style="font-size:80%;">deepim</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib70" title=""><span class="ltx_text" style="font-size:80%;">rnnpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib37" title=""><span class="ltx_text" style="font-size:80%;">cir</span> </a></cite> incorporate refinement-based steps to improve the prediction performance. However, instance-level methods are trained on instance-specific data and rely heavily on CAD models to render numerous training data. Consequently, their application is limited to the objects on which they were trained.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.5.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.6.2">Category-level 6D Pose Estimation </span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In category-level methods, the test instances are not seen during training but belong to known categories. Most methods achieve this by either alignment or directly regressing. Alignment-based methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib27" title=""><span class="ltx_text" style="font-size:80%;">lee2021category</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib65" title=""><span class="ltx_text" style="font-size:80%;">nocs</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib62" title=""><span class="ltx_text" style="font-size:80%;">socs</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib60" title=""><span class="ltx_text" style="font-size:80%;">spd</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib9" title=""><span class="ltx_text" style="font-size:80%;">sgpa</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib34" title=""><span class="ltx_text" style="font-size:80%;">dpdn</span> </a></cite> first propose a Normalized Object Coordinate Space (NOCS) <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib65" title=""><span class="ltx_text" style="font-size:80%;">nocs</span> </a></cite> as a canonical representation for all possible object instances within a category. A network is then trained to predict the NOCS maps and align the object point cloud with the NOCS maps using the Umeyama algorithm <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib61" title=""><span class="ltx_text" style="font-size:80%;">umeyama1991least</span> </a></cite> to determine the object pose. This method typically constructs the mean shape of specific categories as shape priors using offline categorical object models, and the networks are trained to learn deformation fields from the shape priors to enhance the prediction of NOCS maps.
In contrast, directly regressing methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib7" title=""><span class="ltx_text" style="font-size:80%;">cass</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib35" title=""><span class="ltx_text" style="font-size:80%;">dualposenet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib10" title=""><span class="ltx_text" style="font-size:80%;">fsnet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib36" title=""><span class="ltx_text" style="font-size:80%;">vinet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib39" title=""><span class="ltx_text" style="font-size:80%;">cps++</span> </a></cite> avoid the non-differentiable Umeyama algorithm and often focus on geometry-aware feature extraction. For instance, CASS <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib7" title=""><span class="ltx_text" style="font-size:80%;">cass</span> </a></cite> contrasts and fuses shape-dependent/pose-dependent features to predict both the object’s pose and size directly. Fs-net <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib10" title=""><span class="ltx_text" style="font-size:80%;">fsnet</span> </a></cite> leverages 3D Graph Convolution for latent feature extraction, and designs shape-based and residual-based networks for pose estimation.
However, while category-level methods strive to address different instances within the same category, their capacity to predict the poses of objects from entirely new categories remains limited, highlighting the ongoing need to broaden the scope of object pose estimation to encompass unfamiliar objects.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.5.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.6.2">Generalizable 6D Pose Estimation</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Generalizable algorithms aim to enhance the generalizability of unseen objects without the need for retraining or finetuning. Methods in this category can be classified as CAD-based <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib54" title=""><span class="ltx_text" style="font-size:80%;">osop</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib8" title=""><span class="ltx_text" style="font-size:80%;">zeropose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib43" title=""><span class="ltx_text" style="font-size:80%;">zephyr</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib45" title=""><span class="ltx_text" style="font-size:80%;">ornek2023foundpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">megapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib41" title=""><span class="ltx_text" style="font-size:80%;">nguyen2023gigapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib5" title=""><span class="ltx_text" style="font-size:80%;">caraffa2023object</span> </a></cite> or multi-view reference-based <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">latentfusion</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">gen6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">onepose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">onepose++</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib17" title=""><span class="ltx_text" style="font-size:80%;">fs6d</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib67" title=""><span class="ltx_text" style="font-size:80%;">bundlesdf</span> </a></cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">For CAD-based approaches, CAD models are often used as prior knowledge for direct feature matching or template generation. In particular, ZeroPose <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib8" title=""><span class="ltx_text" style="font-size:80%;">zeropose</span> </a></cite> performs point feature extraction for both CAD models and observed point clouds, utilizing a hierarchical geometric feature matching network to establish correspondences. Following ZeroPose, SAM-6D <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib33" title=""><span class="ltx_text" style="font-size:80%;">lin2023sam6d</span> </a></cite> proposed a two-stage partial-to-partial point matching model to construct dense 3D-3D correspondence effectively. Instead, Template-Pose <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a></cite> utilizes a CAD model to generate a collection of templates and selects the most similar one for a given query image. Similarly, OSOP <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib54" title=""><span class="ltx_text" style="font-size:80%;">osop</span> </a></cite> renders plenty of templates and estimates the 2D-2D correspondence between the best matching template and the query image to solve the object pose. MegaPose <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">megapose</span> </a></cite> proposed a coarse network to classify which rendered image best matches the query image and generate an initial pose. Subsequently, multi-view renderings of the initial pose are produced, and a refiner is trained to predict an updated pose.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">Multi-view reference-based methods can be further divided into feature matching-based and template matching-based approaches.
For the former, multi-view reference-based feature matching methods mainly aim to establish 2D-3D correspondences between the RGB query image and sparse point cloud reconstructed by reference views or 3D-3D correspondences between the RGB-D query and RGB-D reference images. For instance, FS6D <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib17" title=""><span class="ltx_text" style="font-size:80%;">fs6d</span> </a></cite> designed a dense prototype matching framework by extracting and matching dense RGBD prototypes with transformers. After the correspondence is established, Umeyama <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib61" title=""><span class="ltx_text" style="font-size:80%;">umeyama1991least</span> </a></cite> algorithms are utilized for pose estimation. OnePose/Onepose++ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib57" title=""><span class="ltx_text" style="font-size:80%;">onepose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib15" title=""><span class="ltx_text" style="font-size:80%;">onepose++</span> </a></cite>
apply the Structure from Motion (SfM) method to reconstruct a sparse point cloud of the unseen object using all reference viewpoints. They then employ an attention-based network to predict the correspondence between 2D pixels and the reconstructed point clouds to estimate the object pose.
For the latter, Multi-view references can be reviewed as templates for retrieval when plenty of views exist, or used to reconstruct the 3D object models for template rendering, similar to the CAD-based methods. As an illustration, Gen6D <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib38" title=""><span class="ltx_text" style="font-size:80%;">gen6d</span> </a></cite> selects the closest reference view for the query image, and then refines the pose through the 3D feature volume constructed from both the reference and query images. Notably, Gen6D requires more than 200 reference images for initial pose selection. On the contrary, LatentFusion <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">latentfusion</span> </a></cite> reconstructs a latent 3D representation of an object to present an end-to-end differentiable reconstruction and rendering pipeline, and then estimates the pose through gradients update. Since a 3D object representation can be reconstructed utilizing the multi-view information, FoundationPose <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib68" title=""><span class="ltx_text" style="font-size:80%;">wen2023foundationpose</span> </a></cite> proposed a unified framework to support both CAD-based and multi-view supported setups. When no CAD model is available, they leverage multi-view references to build a neural implicit representation, which is then used for render-and-compare.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS4.5.1.1">II-D</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS4.6.2">Generalizable Relative Pose Estimation</span>
</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Recent methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib75" title=""><span class="ltx_text" style="font-size:80%;">relpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite> highlight the importance of formulating object pose estimation as a relative pose estimation problem. Specifically, <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> and <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> address situations where only a single-view reference image is available. <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> evidence that some state-of-the-art feature matching approaches <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib53" title=""><span class="ltx_text" style="font-size:80%;">sarlin2020superglue</span> </a></cite>, <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib56" title=""><span class="ltx_text" style="font-size:80%;">loftr</span> </a></cite>, <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib14" title=""><span class="ltx_text" style="font-size:80%;">zsp</span> </a></cite> fail to generate reliable correspondence between the reference-query pair, while energy-base methods <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib75" title=""><span class="ltx_text" style="font-size:80%;">relpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite> struggles to capture 3D information. Instead, 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> introduces a framework of hypothesis and verification for generating and evaluating multiple pose hypotheses. Following 3DAHV, DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> directly lifts the 2D image features to 3D voxel information in a hypothesis-free way, computing the relative pose estimation in an end-to-end fashion by aligning the 3D voxels.</p>
</div>
<figure class="ltx_figure" id="S2.F2">
<p class="ltx_p ltx_align_center" id="S2.F2.1"><span class="ltx_text" id="S2.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="360" id="S2.F2.1.1.g1" src="x2.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S2.F2.3.1">The overview of the proposed method.</span> Given an RGB-D reference and an RGB query, we extract the semantic maps from a pretrained DINOv2 model <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite> for both reference and query. Then, the reference 2.5D front-surface mesh is reconstructed by the depth input without hallucination, which is subsequently texture-mapped by its RGB and semantic images. By leveraging a differentiable renderer <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib25" title=""><span class="ltx_text" style="font-size:80%;">nvidiffrast</span> </a></cite>, we generate the rendered RGB and semantic maps using the textured 2.5D reference mesh under a novel view/pose. Finally, the rendered RGB and semantic maps are compared to their query counterparts, producing losses and back-propagating the gradients through the differentiable renderer to refine the relative pose.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Method</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Following the render-and-compare paradigm, current generalizable pose estimation methods often rely on rotatable 3D CAD models or well-calibrated multi-view images, imposing challenges to acquire the 3D CAD models or expensive pose calibration, especially for previously unseen objects. We instead focus on the generalizable <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">relative</span> pose estimation defined in <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>, which aims to estimate the relative pose between a reference-query pair, using only a single reference with an arbitrary pose as canonical (without calibration). Our method differs from <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> in not requiring labeled relative pose to train an estimation network.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.5.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.6.2">Overview</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Taking an RGB query and an RGB-D reference as input, our method establishes a refinement optimization under the render-and-compare framework, by leveraging a 2.5D (i.e., RGB-D) shape of the reference, a pair of semantic maps for both the query and the reference acquired by a pretrained DINOv2 model <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite> along with the corresponding RGB maps, and a differentiable renderer to backpropagate the gradients. Note that the 2.5D shape is exploited due to the inherent difficulty of accurately hallucinating the 3D shape of unseen objects when relying solely on a single RGB-D image. This challenge further complicates the task of relative pose estimation, as the hallucinated 3D shape must align precisely with the query to achieve a successful estimation.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.22">Formally, by using <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.22.1">subscript</em> to denote query or reference, our method starts with an RGB pair <math alttext="I_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝐼</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">I_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="I_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝐼</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> for both reference and query, as well as a depth map <math alttext="D_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">D</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝐷</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">D_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> for the reference. We proposed to estimate the relative pose between <math alttext="I_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐼</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">I_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="I_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝐼</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>, assisted by <math alttext="D_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><msub id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">D</mi><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">𝐷</ci><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">D_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>. To this end, we first infer the semantic maps <math alttext="S_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1"><semantics id="S3.SS1.p2.7.m7.1a"><msub id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">S</mi><mi id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">𝑆</ci><ci id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">S_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m7.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="S_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m8.1"><semantics id="S3.SS1.p2.8.m8.1a"><msub id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><mi id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml">S</mi><mi id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2">𝑆</ci><ci id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">S_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m8.1d">italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="I_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m9.1"><semantics id="S3.SS1.p2.9.m9.1a"><msub id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml"><mi id="S3.SS1.p2.9.m9.1.1.2" xref="S3.SS1.p2.9.m9.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.9.m9.1.1.3" xref="S3.SS1.p2.9.m9.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><apply id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m9.1.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p2.9.m9.1.1.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2">𝐼</ci><ci id="S3.SS1.p2.9.m9.1.1.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">I_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m9.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="I_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.10.m10.1"><semantics id="S3.SS1.p2.10.m10.1a"><msub id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml"><mi id="S3.SS1.p2.10.m10.1.1.2" xref="S3.SS1.p2.10.m10.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.10.m10.1.1.3" xref="S3.SS1.p2.10.m10.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><apply id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.p2.10.m10.1.1.2">𝐼</ci><ci id="S3.SS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.10.m10.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> exploiting a pretrained DINOv2 model <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite>. Then, we construct a 2.5D mesh model <math alttext="M_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.11.m11.1"><semantics id="S3.SS1.p2.11.m11.1a"><msub id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml"><mi id="S3.SS1.p2.11.m11.1.1.2" xref="S3.SS1.p2.11.m11.1.1.2.cmml">M</mi><mi id="S3.SS1.p2.11.m11.1.1.3" xref="S3.SS1.p2.11.m11.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b"><apply id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m11.1.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p2.11.m11.1.1.2.cmml" xref="S3.SS1.p2.11.m11.1.1.2">𝑀</ci><ci id="S3.SS1.p2.11.m11.1.1.3.cmml" xref="S3.SS1.p2.11.m11.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">M_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.11.m11.1d">italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> for the reference object based on <math alttext="D_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.12.m12.1"><semantics id="S3.SS1.p2.12.m12.1a"><msub id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml"><mi id="S3.SS1.p2.12.m12.1.1.2" xref="S3.SS1.p2.12.m12.1.1.2.cmml">D</mi><mi id="S3.SS1.p2.12.m12.1.1.3" xref="S3.SS1.p2.12.m12.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b"><apply id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p2.12.m12.1.1.2.cmml" xref="S3.SS1.p2.12.m12.1.1.2">𝐷</ci><ci id="S3.SS1.p2.12.m12.1.1.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">D_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.12.m12.1d">italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, to formulate an RGB and semantic maps textured 2.5D mesh <math alttext="\mathcal{M}_{r}=\{M_{r},I_{r},S_{r}\}" class="ltx_Math" display="inline" id="S3.SS1.p2.13.m13.3"><semantics id="S3.SS1.p2.13.m13.3a"><mrow id="S3.SS1.p2.13.m13.3.3" xref="S3.SS1.p2.13.m13.3.3.cmml"><msub id="S3.SS1.p2.13.m13.3.3.5" xref="S3.SS1.p2.13.m13.3.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.13.m13.3.3.5.2" xref="S3.SS1.p2.13.m13.3.3.5.2.cmml">ℳ</mi><mi id="S3.SS1.p2.13.m13.3.3.5.3" xref="S3.SS1.p2.13.m13.3.3.5.3.cmml">r</mi></msub><mo id="S3.SS1.p2.13.m13.3.3.4" xref="S3.SS1.p2.13.m13.3.3.4.cmml">=</mo><mrow id="S3.SS1.p2.13.m13.3.3.3.3" xref="S3.SS1.p2.13.m13.3.3.3.4.cmml"><mo id="S3.SS1.p2.13.m13.3.3.3.3.4" stretchy="false" xref="S3.SS1.p2.13.m13.3.3.3.4.cmml">{</mo><msub id="S3.SS1.p2.13.m13.1.1.1.1.1" xref="S3.SS1.p2.13.m13.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.13.m13.1.1.1.1.1.2" xref="S3.SS1.p2.13.m13.1.1.1.1.1.2.cmml">M</mi><mi id="S3.SS1.p2.13.m13.1.1.1.1.1.3" xref="S3.SS1.p2.13.m13.1.1.1.1.1.3.cmml">r</mi></msub><mo id="S3.SS1.p2.13.m13.3.3.3.3.5" xref="S3.SS1.p2.13.m13.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.13.m13.2.2.2.2.2" xref="S3.SS1.p2.13.m13.2.2.2.2.2.cmml"><mi id="S3.SS1.p2.13.m13.2.2.2.2.2.2" xref="S3.SS1.p2.13.m13.2.2.2.2.2.2.cmml">I</mi><mi id="S3.SS1.p2.13.m13.2.2.2.2.2.3" xref="S3.SS1.p2.13.m13.2.2.2.2.2.3.cmml">r</mi></msub><mo id="S3.SS1.p2.13.m13.3.3.3.3.6" xref="S3.SS1.p2.13.m13.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.13.m13.3.3.3.3.3" xref="S3.SS1.p2.13.m13.3.3.3.3.3.cmml"><mi id="S3.SS1.p2.13.m13.3.3.3.3.3.2" xref="S3.SS1.p2.13.m13.3.3.3.3.3.2.cmml">S</mi><mi id="S3.SS1.p2.13.m13.3.3.3.3.3.3" xref="S3.SS1.p2.13.m13.3.3.3.3.3.3.cmml">r</mi></msub><mo id="S3.SS1.p2.13.m13.3.3.3.3.7" stretchy="false" xref="S3.SS1.p2.13.m13.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.3b"><apply id="S3.SS1.p2.13.m13.3.3.cmml" xref="S3.SS1.p2.13.m13.3.3"><eq id="S3.SS1.p2.13.m13.3.3.4.cmml" xref="S3.SS1.p2.13.m13.3.3.4"></eq><apply id="S3.SS1.p2.13.m13.3.3.5.cmml" xref="S3.SS1.p2.13.m13.3.3.5"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.3.3.5.1.cmml" xref="S3.SS1.p2.13.m13.3.3.5">subscript</csymbol><ci id="S3.SS1.p2.13.m13.3.3.5.2.cmml" xref="S3.SS1.p2.13.m13.3.3.5.2">ℳ</ci><ci id="S3.SS1.p2.13.m13.3.3.5.3.cmml" xref="S3.SS1.p2.13.m13.3.3.5.3">𝑟</ci></apply><set id="S3.SS1.p2.13.m13.3.3.3.4.cmml" xref="S3.SS1.p2.13.m13.3.3.3.3"><apply id="S3.SS1.p2.13.m13.1.1.1.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.13.m13.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.13.m13.1.1.1.1.1.2">𝑀</ci><ci id="S3.SS1.p2.13.m13.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.13.m13.1.1.1.1.1.3">𝑟</ci></apply><apply id="S3.SS1.p2.13.m13.2.2.2.2.2.cmml" xref="S3.SS1.p2.13.m13.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.13.m13.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.13.m13.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.13.m13.2.2.2.2.2.2">𝐼</ci><ci id="S3.SS1.p2.13.m13.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.13.m13.2.2.2.2.2.3">𝑟</ci></apply><apply id="S3.SS1.p2.13.m13.3.3.3.3.3.cmml" xref="S3.SS1.p2.13.m13.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.3.3.3.3.3.1.cmml" xref="S3.SS1.p2.13.m13.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.13.m13.3.3.3.3.3.2.cmml" xref="S3.SS1.p2.13.m13.3.3.3.3.3.2">𝑆</ci><ci id="S3.SS1.p2.13.m13.3.3.3.3.3.3.cmml" xref="S3.SS1.p2.13.m13.3.3.3.3.3.3">𝑟</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.3c">\mathcal{M}_{r}=\{M_{r},I_{r},S_{r}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.13.m13.3d">caligraphic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = { italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT }</annotation></semantics></math>. Subsequently, the textured 2.5D reference mesh <math alttext="\mathcal{M}_{r}" class="ltx_Math" display="inline" id="S3.SS1.p2.14.m14.1"><semantics id="S3.SS1.p2.14.m14.1a"><msub id="S3.SS1.p2.14.m14.1.1" xref="S3.SS1.p2.14.m14.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.14.m14.1.1.2" xref="S3.SS1.p2.14.m14.1.1.2.cmml">ℳ</mi><mi id="S3.SS1.p2.14.m14.1.1.3" xref="S3.SS1.p2.14.m14.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m14.1b"><apply id="S3.SS1.p2.14.m14.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p2.14.m14.1.1.2.cmml" xref="S3.SS1.p2.14.m14.1.1.2">ℳ</ci><ci id="S3.SS1.p2.14.m14.1.1.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m14.1c">\mathcal{M}_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.14.m14.1d">caligraphic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> is rotated with an (arbitrary) initial pose <math alttext="P" class="ltx_Math" display="inline" id="S3.SS1.p2.15.m15.1"><semantics id="S3.SS1.p2.15.m15.1a"><mi id="S3.SS1.p2.15.m15.1.1" xref="S3.SS1.p2.15.m15.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.15.m15.1b"><ci id="S3.SS1.p2.15.m15.1.1.cmml" xref="S3.SS1.p2.15.m15.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.15.m15.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.15.m15.1d">italic_P</annotation></semantics></math> by a differentiable renderer <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib25" title=""><span class="ltx_text" style="font-size:80%;">nvidiffrast</span> </a></cite> to generate novel <math alttext="I_{r}(P)" class="ltx_Math" display="inline" id="S3.SS1.p2.16.m16.1"><semantics id="S3.SS1.p2.16.m16.1a"><mrow id="S3.SS1.p2.16.m16.1.2" xref="S3.SS1.p2.16.m16.1.2.cmml"><msub id="S3.SS1.p2.16.m16.1.2.2" xref="S3.SS1.p2.16.m16.1.2.2.cmml"><mi id="S3.SS1.p2.16.m16.1.2.2.2" xref="S3.SS1.p2.16.m16.1.2.2.2.cmml">I</mi><mi id="S3.SS1.p2.16.m16.1.2.2.3" xref="S3.SS1.p2.16.m16.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS1.p2.16.m16.1.2.1" xref="S3.SS1.p2.16.m16.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.16.m16.1.2.3.2" xref="S3.SS1.p2.16.m16.1.2.cmml"><mo id="S3.SS1.p2.16.m16.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.16.m16.1.2.cmml">(</mo><mi id="S3.SS1.p2.16.m16.1.1" xref="S3.SS1.p2.16.m16.1.1.cmml">P</mi><mo id="S3.SS1.p2.16.m16.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.16.m16.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.16.m16.1b"><apply id="S3.SS1.p2.16.m16.1.2.cmml" xref="S3.SS1.p2.16.m16.1.2"><times id="S3.SS1.p2.16.m16.1.2.1.cmml" xref="S3.SS1.p2.16.m16.1.2.1"></times><apply id="S3.SS1.p2.16.m16.1.2.2.cmml" xref="S3.SS1.p2.16.m16.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.16.m16.1.2.2.1.cmml" xref="S3.SS1.p2.16.m16.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.16.m16.1.2.2.2.cmml" xref="S3.SS1.p2.16.m16.1.2.2.2">𝐼</ci><ci id="S3.SS1.p2.16.m16.1.2.2.3.cmml" xref="S3.SS1.p2.16.m16.1.2.2.3">𝑟</ci></apply><ci id="S3.SS1.p2.16.m16.1.1.cmml" xref="S3.SS1.p2.16.m16.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.16.m16.1c">I_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.16.m16.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math> and <math alttext="S_{r}(P)" class="ltx_Math" display="inline" id="S3.SS1.p2.17.m17.1"><semantics id="S3.SS1.p2.17.m17.1a"><mrow id="S3.SS1.p2.17.m17.1.2" xref="S3.SS1.p2.17.m17.1.2.cmml"><msub id="S3.SS1.p2.17.m17.1.2.2" xref="S3.SS1.p2.17.m17.1.2.2.cmml"><mi id="S3.SS1.p2.17.m17.1.2.2.2" xref="S3.SS1.p2.17.m17.1.2.2.2.cmml">S</mi><mi id="S3.SS1.p2.17.m17.1.2.2.3" xref="S3.SS1.p2.17.m17.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS1.p2.17.m17.1.2.1" xref="S3.SS1.p2.17.m17.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.17.m17.1.2.3.2" xref="S3.SS1.p2.17.m17.1.2.cmml"><mo id="S3.SS1.p2.17.m17.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.17.m17.1.2.cmml">(</mo><mi id="S3.SS1.p2.17.m17.1.1" xref="S3.SS1.p2.17.m17.1.1.cmml">P</mi><mo id="S3.SS1.p2.17.m17.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.17.m17.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.17.m17.1b"><apply id="S3.SS1.p2.17.m17.1.2.cmml" xref="S3.SS1.p2.17.m17.1.2"><times id="S3.SS1.p2.17.m17.1.2.1.cmml" xref="S3.SS1.p2.17.m17.1.2.1"></times><apply id="S3.SS1.p2.17.m17.1.2.2.cmml" xref="S3.SS1.p2.17.m17.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.17.m17.1.2.2.1.cmml" xref="S3.SS1.p2.17.m17.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.17.m17.1.2.2.2.cmml" xref="S3.SS1.p2.17.m17.1.2.2.2">𝑆</ci><ci id="S3.SS1.p2.17.m17.1.2.2.3.cmml" xref="S3.SS1.p2.17.m17.1.2.2.3">𝑟</ci></apply><ci id="S3.SS1.p2.17.m17.1.1.cmml" xref="S3.SS1.p2.17.m17.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.17.m17.1c">S_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.17.m17.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math>. Finally, the generated <math alttext="I_{r}(P)" class="ltx_Math" display="inline" id="S3.SS1.p2.18.m18.1"><semantics id="S3.SS1.p2.18.m18.1a"><mrow id="S3.SS1.p2.18.m18.1.2" xref="S3.SS1.p2.18.m18.1.2.cmml"><msub id="S3.SS1.p2.18.m18.1.2.2" xref="S3.SS1.p2.18.m18.1.2.2.cmml"><mi id="S3.SS1.p2.18.m18.1.2.2.2" xref="S3.SS1.p2.18.m18.1.2.2.2.cmml">I</mi><mi id="S3.SS1.p2.18.m18.1.2.2.3" xref="S3.SS1.p2.18.m18.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS1.p2.18.m18.1.2.1" xref="S3.SS1.p2.18.m18.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.18.m18.1.2.3.2" xref="S3.SS1.p2.18.m18.1.2.cmml"><mo id="S3.SS1.p2.18.m18.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.18.m18.1.2.cmml">(</mo><mi id="S3.SS1.p2.18.m18.1.1" xref="S3.SS1.p2.18.m18.1.1.cmml">P</mi><mo id="S3.SS1.p2.18.m18.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.18.m18.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.18.m18.1b"><apply id="S3.SS1.p2.18.m18.1.2.cmml" xref="S3.SS1.p2.18.m18.1.2"><times id="S3.SS1.p2.18.m18.1.2.1.cmml" xref="S3.SS1.p2.18.m18.1.2.1"></times><apply id="S3.SS1.p2.18.m18.1.2.2.cmml" xref="S3.SS1.p2.18.m18.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.18.m18.1.2.2.1.cmml" xref="S3.SS1.p2.18.m18.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.18.m18.1.2.2.2.cmml" xref="S3.SS1.p2.18.m18.1.2.2.2">𝐼</ci><ci id="S3.SS1.p2.18.m18.1.2.2.3.cmml" xref="S3.SS1.p2.18.m18.1.2.2.3">𝑟</ci></apply><ci id="S3.SS1.p2.18.m18.1.1.cmml" xref="S3.SS1.p2.18.m18.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.18.m18.1c">I_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.18.m18.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math> and <math alttext="S_{r}(P)" class="ltx_Math" display="inline" id="S3.SS1.p2.19.m19.1"><semantics id="S3.SS1.p2.19.m19.1a"><mrow id="S3.SS1.p2.19.m19.1.2" xref="S3.SS1.p2.19.m19.1.2.cmml"><msub id="S3.SS1.p2.19.m19.1.2.2" xref="S3.SS1.p2.19.m19.1.2.2.cmml"><mi id="S3.SS1.p2.19.m19.1.2.2.2" xref="S3.SS1.p2.19.m19.1.2.2.2.cmml">S</mi><mi id="S3.SS1.p2.19.m19.1.2.2.3" xref="S3.SS1.p2.19.m19.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS1.p2.19.m19.1.2.1" xref="S3.SS1.p2.19.m19.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p2.19.m19.1.2.3.2" xref="S3.SS1.p2.19.m19.1.2.cmml"><mo id="S3.SS1.p2.19.m19.1.2.3.2.1" stretchy="false" xref="S3.SS1.p2.19.m19.1.2.cmml">(</mo><mi id="S3.SS1.p2.19.m19.1.1" xref="S3.SS1.p2.19.m19.1.1.cmml">P</mi><mo id="S3.SS1.p2.19.m19.1.2.3.2.2" stretchy="false" xref="S3.SS1.p2.19.m19.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.19.m19.1b"><apply id="S3.SS1.p2.19.m19.1.2.cmml" xref="S3.SS1.p2.19.m19.1.2"><times id="S3.SS1.p2.19.m19.1.2.1.cmml" xref="S3.SS1.p2.19.m19.1.2.1"></times><apply id="S3.SS1.p2.19.m19.1.2.2.cmml" xref="S3.SS1.p2.19.m19.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.19.m19.1.2.2.1.cmml" xref="S3.SS1.p2.19.m19.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.19.m19.1.2.2.2.cmml" xref="S3.SS1.p2.19.m19.1.2.2.2">𝑆</ci><ci id="S3.SS1.p2.19.m19.1.2.2.3.cmml" xref="S3.SS1.p2.19.m19.1.2.2.3">𝑟</ci></apply><ci id="S3.SS1.p2.19.m19.1.1.cmml" xref="S3.SS1.p2.19.m19.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.19.m19.1c">S_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.19.m19.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math> are compared with the query <math alttext="I_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.20.m20.1"><semantics id="S3.SS1.p2.20.m20.1a"><msub id="S3.SS1.p2.20.m20.1.1" xref="S3.SS1.p2.20.m20.1.1.cmml"><mi id="S3.SS1.p2.20.m20.1.1.2" xref="S3.SS1.p2.20.m20.1.1.2.cmml">I</mi><mi id="S3.SS1.p2.20.m20.1.1.3" xref="S3.SS1.p2.20.m20.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.20.m20.1b"><apply id="S3.SS1.p2.20.m20.1.1.cmml" xref="S3.SS1.p2.20.m20.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.20.m20.1.1.1.cmml" xref="S3.SS1.p2.20.m20.1.1">subscript</csymbol><ci id="S3.SS1.p2.20.m20.1.1.2.cmml" xref="S3.SS1.p2.20.m20.1.1.2">𝐼</ci><ci id="S3.SS1.p2.20.m20.1.1.3.cmml" xref="S3.SS1.p2.20.m20.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.20.m20.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.20.m20.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="S_{q}" class="ltx_Math" display="inline" id="S3.SS1.p2.21.m21.1"><semantics id="S3.SS1.p2.21.m21.1a"><msub id="S3.SS1.p2.21.m21.1.1" xref="S3.SS1.p2.21.m21.1.1.cmml"><mi id="S3.SS1.p2.21.m21.1.1.2" xref="S3.SS1.p2.21.m21.1.1.2.cmml">S</mi><mi id="S3.SS1.p2.21.m21.1.1.3" xref="S3.SS1.p2.21.m21.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.21.m21.1b"><apply id="S3.SS1.p2.21.m21.1.1.cmml" xref="S3.SS1.p2.21.m21.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.21.m21.1.1.1.cmml" xref="S3.SS1.p2.21.m21.1.1">subscript</csymbol><ci id="S3.SS1.p2.21.m21.1.1.2.cmml" xref="S3.SS1.p2.21.m21.1.1.2">𝑆</ci><ci id="S3.SS1.p2.21.m21.1.1.3.cmml" xref="S3.SS1.p2.21.m21.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.21.m21.1c">S_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.21.m21.1d">italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>, producing a refinement loss and consequently back-propagate gradients to <math alttext="P" class="ltx_Math" display="inline" id="S3.SS1.p2.22.m22.1"><semantics id="S3.SS1.p2.22.m22.1a"><mi id="S3.SS1.p2.22.m22.1.1" xref="S3.SS1.p2.22.m22.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.22.m22.1b"><ci id="S3.SS1.p2.22.m22.1.1.cmml" xref="S3.SS1.p2.22.m22.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.22.m22.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.22.m22.1d">italic_P</annotation></semantics></math> through the differentiable renderer. Our method operates the render-and-compare procedure in a self-supervised and network-free manner, without labeling or training.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The overview of the proposed method is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S2.F2" title="Figure 2 ‣ II-D Generalizable Relative Pose Estimation ‣ II Related work ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">2</span></a>. We detail the comprising elements of our method in the following sections, i.e., <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">semantic map estimation</span> in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS2" title="III-B Semantic Map Estimation ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>, <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.2">textured 2.5D mesh reconstruction</span> in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS3" title="III-C Textured 2.5D Mesh Reconstruction ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>, and <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.3">label/training-free refinement via differentiable renderer</span> in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS4" title="III-D Label/Training-Free Refinement via Differentiable Renderer ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.5.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.6.2">Semantic Map Estimation</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In order to estimate the relative pose, human intelligence may unconsciously infer the semantics of the reference-query pair. Subsequently, coarse correspondence can be established with those semantics, resulting in three-fold benefits: it (i) helps to filter out the large non-overlapped part under a substantial pose difference, (ii) alleviates the influence of occlusions, and (iii) eases the degraded optimization of the relative pose estimation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Benefit from the rapid development of large pretrained models, an elegant off-the-shelf semantic feature extractor is available as DINO/DINOv2 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib6" title=""><span class="ltx_text" style="font-size:80%;">dino</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite>, which shows great zero-shot generalize-ability to diverse (even texture-less) objects (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.F3" title="Figure 3 ‣ III-B Semantic Map Estimation ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">3</span></a> for some examples). We thus incorporate the off-the-shelf DINOv2 model <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite> to acquire the rich semantics of the input unseen objects.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<p class="ltx_p ltx_align_center" id="S3.F3.1"><span class="ltx_text" id="S3.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="208" id="S3.F3.1.1.g1" src="x3.png" width="692"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S3.F3.3.1">Illustration of the semantic maps estimated by DINOv2 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite></span>, demonstrating promising zero-shot performance even for texture-less objects.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.7">Specifically, we utilize DINOv2 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite> as the semantic feature extractor <math alttext="\mathbf{\Phi(x)}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.2" xref="S3.SS2.p3.1.m1.1.2.cmml"><mi id="S3.SS2.p3.1.m1.1.2.2" xref="S3.SS2.p3.1.m1.1.2.2.cmml">𝚽</mi><mo id="S3.SS2.p3.1.m1.1.2.1" xref="S3.SS2.p3.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.p3.1.m1.1.2.3.2" xref="S3.SS2.p3.1.m1.1.2.cmml"><mo id="S3.SS2.p3.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS2.p3.1.m1.1.2.cmml">(</mo><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">𝐱</mi><mo id="S3.SS2.p3.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS2.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.2"><times id="S3.SS2.p3.1.m1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.1.2.1"></times><ci id="S3.SS2.p3.1.m1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.1.2.2">𝚽</ci><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbf{\Phi(x)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">bold_Φ ( bold_x )</annotation></semantics></math>, which takes an RGB image <math alttext="I" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_I</annotation></semantics></math> to produce a set of semantic features <math alttext="F\in\mathbb{R}^{w\times h\times d}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mrow id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">F</mi><mo id="S3.SS2.p3.3.m3.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.3.2" xref="S3.SS2.p3.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.3.m3.1.1.3.3" xref="S3.SS2.p3.3.m3.1.1.3.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.3.3.2" xref="S3.SS2.p3.3.m3.1.1.3.3.2.cmml">w</mi><mo id="S3.SS2.p3.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p3.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p3.3.m3.1.1.3.3.3" xref="S3.SS2.p3.3.m3.1.1.3.3.3.cmml">h</mi><mo id="S3.SS2.p3.3.m3.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p3.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p3.3.m3.1.1.3.3.4" xref="S3.SS2.p3.3.m3.1.1.3.3.4.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><in id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1"></in><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝐹</ci><apply id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3"><times id="S3.SS2.p3.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3.1"></times><ci id="S3.SS2.p3.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3.2">𝑤</ci><ci id="S3.SS2.p3.3.m3.1.1.3.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3.3">ℎ</ci><ci id="S3.SS2.p3.3.m3.1.1.3.3.4.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3.4">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">F\in\mathbb{R}^{w\times h\times d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_F ∈ blackboard_R start_POSTSUPERSCRIPT italic_w × italic_h × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>. In order to texture <math alttext="F" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">F</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_F</annotation></semantics></math> to the 2.5D model and facilitate the novel pose rendering, we use the principal component analysis (PCA) to reduce the dimension of <math alttext="F" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">F</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_F</annotation></semantics></math> from <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_d</annotation></semantics></math> to 3, obtaining a semantic map <math alttext="S" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">S</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_S</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S=\texttt{PCA}(\mathbf{\Phi}(I)),\quad\texttt{PCA}:\mathbb{R}^{w\times h\times
d%
}\rightarrow\mathbb{R}^{w\times h\times 3}." class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.3.cmml">S</mi><mo id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3a.cmml">PCA</mtext><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">𝚽</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">I</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.1.1.1.2" rspace="1.167em" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2a.cmml">PCA</mtext></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.2" lspace="0.278em" rspace="0.278em" xref="S3.E1.m1.3.3.1.1.2.cmml">:</mo><mrow id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml"><msup id="S3.E1.m1.3.3.1.1.3.2" xref="S3.E1.m1.3.3.1.1.3.2.cmml"><mi id="S3.E1.m1.3.3.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.3.2.2.cmml">ℝ</mi><mrow id="S3.E1.m1.3.3.1.1.3.2.3" xref="S3.E1.m1.3.3.1.1.3.2.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.2.3.2" xref="S3.E1.m1.3.3.1.1.3.2.3.2.cmml">w</mi><mo id="S3.E1.m1.3.3.1.1.3.2.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.3.3.1.1.3.2.3.1.cmml">×</mo><mi id="S3.E1.m1.3.3.1.1.3.2.3.3" xref="S3.E1.m1.3.3.1.1.3.2.3.3.cmml">h</mi><mo id="S3.E1.m1.3.3.1.1.3.2.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.3.3.1.1.3.2.3.1.cmml">×</mo><mi id="S3.E1.m1.3.3.1.1.3.2.3.4" xref="S3.E1.m1.3.3.1.1.3.2.3.4.cmml">d</mi></mrow></msup><mo id="S3.E1.m1.3.3.1.1.3.1" stretchy="false" xref="S3.E1.m1.3.3.1.1.3.1.cmml">→</mo><msup id="S3.E1.m1.3.3.1.1.3.3" xref="S3.E1.m1.3.3.1.1.3.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.3.2" xref="S3.E1.m1.3.3.1.1.3.3.2.cmml">ℝ</mi><mrow id="S3.E1.m1.3.3.1.1.3.3.3" xref="S3.E1.m1.3.3.1.1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.3.3.2" xref="S3.E1.m1.3.3.1.1.3.3.3.2.cmml">w</mi><mo id="S3.E1.m1.3.3.1.1.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.3.3.1.1.3.3.3.1.cmml">×</mo><mi id="S3.E1.m1.3.3.1.1.3.3.3.3" xref="S3.E1.m1.3.3.1.1.3.3.3.3.cmml">h</mi><mo id="S3.E1.m1.3.3.1.1.3.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.3.3.1.1.3.3.3.1.cmml">×</mo><mn id="S3.E1.m1.3.3.1.1.3.3.3.4" xref="S3.E1.m1.3.3.1.1.3.3.3.4.cmml">3</mn></mrow></msup></mrow></mrow><mo id="S3.E1.m1.3.3.1.2" lspace="0em" xref="S3.E1.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><ci id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2">:</ci><apply id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><eq id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"></eq><ci id="S3.E1.m1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3">𝑆</ci><list id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3a.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3">PCA</mtext></ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.2">𝚽</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝐼</ci></apply></apply><ci id="S3.E1.m1.2.2a.cmml" xref="S3.E1.m1.2.2"><mtext class="ltx_mathvariant_monospace" id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">PCA</mtext></ci></list></apply><apply id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"><ci id="S3.E1.m1.3.3.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.1">→</ci><apply id="S3.E1.m1.3.3.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2.2">ℝ</ci><apply id="S3.E1.m1.3.3.1.1.3.2.3.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3"><times id="S3.E1.m1.3.3.1.1.3.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3.1"></times><ci id="S3.E1.m1.3.3.1.1.3.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3.2">𝑤</ci><ci id="S3.E1.m1.3.3.1.1.3.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3.3">ℎ</ci><ci id="S3.E1.m1.3.3.1.1.3.2.3.4.cmml" xref="S3.E1.m1.3.3.1.1.3.2.3.4">𝑑</ci></apply></apply><apply id="S3.E1.m1.3.3.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.3">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.3.2">ℝ</ci><apply id="S3.E1.m1.3.3.1.1.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3"><times id="S3.E1.m1.3.3.1.1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.1"></times><ci id="S3.E1.m1.3.3.1.1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.2">𝑤</ci><ci id="S3.E1.m1.3.3.1.1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.3.3.3.3">ℎ</ci><cn id="S3.E1.m1.3.3.1.1.3.3.3.4.cmml" type="integer" xref="S3.E1.m1.3.3.1.1.3.3.3.4">3</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">S=\texttt{PCA}(\mathbf{\Phi}(I)),\quad\texttt{PCA}:\mathbb{R}^{w\times h\times
d%
}\rightarrow\mathbb{R}^{w\times h\times 3}.</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">italic_S = PCA ( bold_Φ ( italic_I ) ) , PCA : blackboard_R start_POSTSUPERSCRIPT italic_w × italic_h × italic_d end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_w × italic_h × 3 end_POSTSUPERSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.4">By feeding Eq. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.E1" title="In III-B Semantic Map Estimation ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">1</span></a>) with <math alttext="I_{q}" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><msub id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml"><mi id="S3.SS2.p5.1.m1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.2.cmml">I</mi><mi id="S3.SS2.p5.1.m1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2">𝐼</ci><ci id="S3.SS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="I_{r}" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><msub id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml">I</mi><mi id="S3.SS2.p5.2.m2.1.1.3" xref="S3.SS2.p5.2.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.2">𝐼</ci><ci id="S3.SS2.p5.2.m2.1.1.3.cmml" xref="S3.SS2.p5.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">I_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, we can obtain the semantic maps for the query and the reference, <math alttext="S_{q}" class="ltx_Math" display="inline" id="S3.SS2.p5.3.m3.1"><semantics id="S3.SS2.p5.3.m3.1a"><msub id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.2" xref="S3.SS2.p5.3.m3.1.1.2.cmml">S</mi><mi id="S3.SS2.p5.3.m3.1.1.3" xref="S3.SS2.p5.3.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><apply id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.2">𝑆</ci><ci id="S3.SS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">S_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.3.m3.1d">italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="S_{r}" class="ltx_Math" display="inline" id="S3.SS2.p5.4.m4.1"><semantics id="S3.SS2.p5.4.m4.1a"><msub id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml"><mi id="S3.SS2.p5.4.m4.1.1.2" xref="S3.SS2.p5.4.m4.1.1.2.cmml">S</mi><mi id="S3.SS2.p5.4.m4.1.1.3" xref="S3.SS2.p5.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><apply id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.p5.4.m4.1.1.2">𝑆</ci><ci id="S3.SS2.p5.4.m4.1.1.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">S_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.4.m4.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.5.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.6.2">Textured 2.5D Mesh Reconstruction</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">In this section, we reconstruct a rotatable 2.5D model of the reference given its depth map <math alttext="D_{r}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝐷</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">D_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, which is subsequently used to generate novel renderings through the differentiable renderer. Note that our design avoids the challenging 3D hallucination of an unseen object from the depth map, as the hallucinated 3D shape must consistently align with the query for relative pose estimation.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.10">Specifically, given the depth map <math alttext="D_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝐷</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">D_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> of the reference, we lift the coordinates of the image plane into the 3D space and obtain the 2.5D point clouds <math alttext="X_{r}\in\mathbb{R}^{N\times 3}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><msub id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2.2" xref="S3.SS3.p2.2.m2.1.1.2.2.cmml">X</mi><mi id="S3.SS3.p2.2.m2.1.1.2.3" xref="S3.SS3.p2.2.m2.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.3.2" xref="S3.SS3.p2.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.2.m2.1.1.3.3" xref="S3.SS3.p2.2.m2.1.1.3.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.3.3.2" xref="S3.SS3.p2.2.m2.1.1.3.3.2.cmml">N</mi><mo id="S3.SS3.p2.2.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p2.2.m2.1.1.3.3.1.cmml">×</mo><mn id="S3.SS3.p2.2.m2.1.1.3.3.3" xref="S3.SS3.p2.2.m2.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><in id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></in><apply id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS3.p2.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2.2">𝑋</ci><ci id="S3.SS3.p2.2.m2.1.1.2.3.cmml" xref="S3.SS3.p2.2.m2.1.1.2.3">𝑟</ci></apply><apply id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS3.p2.2.m2.1.1.3.2">ℝ</ci><apply id="S3.SS3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3"><times id="S3.SS3.p2.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3.1"></times><ci id="S3.SS3.p2.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3.2">𝑁</ci><cn id="S3.SS3.p2.2.m2.1.1.3.3.3.cmml" type="integer" xref="S3.SS3.p2.2.m2.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">X_{r}\in\mathbb{R}^{N\times 3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × 3 end_POSTSUPERSCRIPT</annotation></semantics></math> of the front surface. We then reconstruct the corresponding 2.5D mesh <math alttext="M_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">M</mi><mi id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">𝑀</ci><ci id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">M_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="X_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">X</mi><mi id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">𝑋</ci><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">X_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">italic_X start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, to facilitate the rasterization in the renderer. Since the <math alttext="xy" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m5.1"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">x</mi><mo id="S3.SS3.p2.5.m5.1.1.1" xref="S3.SS3.p2.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><times id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1.1"></times><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝑥</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">xy</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">italic_x italic_y</annotation></semantics></math> coordinates of <math alttext="X_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.6.m6.1"><semantics id="S3.SS3.p2.6.m6.1a"><msub id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">X</mi><mi id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝑋</ci><ci id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">X_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.6.m6.1d">italic_X start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> are sampled regularly from the 2D grids, reconstructing <math alttext="M_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.7.m7.1"><semantics id="S3.SS3.p2.7.m7.1a"><msub id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><mi id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml">M</mi><mi id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2">𝑀</ci><ci id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">M_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.7.m7.1d">italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="X_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.8.m8.1"><semantics id="S3.SS3.p2.8.m8.1a"><msub id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2" xref="S3.SS3.p2.8.m8.1.1.2.cmml">X</mi><mi id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2">𝑋</ci><ci id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">X_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.8.m8.1d">italic_X start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> can be easily achieved by the Delaunay triangulations <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib26" title=""><span class="ltx_text" style="font-size:80%;">lee1980two</span> </a></cite>. Finally, we texture <math alttext="M_{r}" class="ltx_Math" display="inline" id="S3.SS3.p2.9.m9.1"><semantics id="S3.SS3.p2.9.m9.1a"><msub id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2" xref="S3.SS3.p2.9.m9.1.1.2.cmml">M</mi><mi id="S3.SS3.p2.9.m9.1.1.3" xref="S3.SS3.p2.9.m9.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><apply id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2">𝑀</ci><ci id="S3.SS3.p2.9.m9.1.1.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">M_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.9.m9.1d">italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> with both color and semantic maps, obtaining <math alttext="\mathcal{M}_{r}=\texttt{TextMap}(M_{r},I_{r},S_{r})" class="ltx_Math" display="inline" id="S3.SS3.p2.10.m10.3"><semantics id="S3.SS3.p2.10.m10.3a"><mrow id="S3.SS3.p2.10.m10.3.3" xref="S3.SS3.p2.10.m10.3.3.cmml"><msub id="S3.SS3.p2.10.m10.3.3.5" xref="S3.SS3.p2.10.m10.3.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.10.m10.3.3.5.2" xref="S3.SS3.p2.10.m10.3.3.5.2.cmml">ℳ</mi><mi id="S3.SS3.p2.10.m10.3.3.5.3" xref="S3.SS3.p2.10.m10.3.3.5.3.cmml">r</mi></msub><mo id="S3.SS3.p2.10.m10.3.3.4" xref="S3.SS3.p2.10.m10.3.3.4.cmml">=</mo><mrow id="S3.SS3.p2.10.m10.3.3.3" xref="S3.SS3.p2.10.m10.3.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p2.10.m10.3.3.3.5" xref="S3.SS3.p2.10.m10.3.3.3.5a.cmml">TextMap</mtext><mo id="S3.SS3.p2.10.m10.3.3.3.4" xref="S3.SS3.p2.10.m10.3.3.3.4.cmml">⁢</mo><mrow id="S3.SS3.p2.10.m10.3.3.3.3.3" xref="S3.SS3.p2.10.m10.3.3.3.3.4.cmml"><mo id="S3.SS3.p2.10.m10.3.3.3.3.3.4" stretchy="false" xref="S3.SS3.p2.10.m10.3.3.3.3.4.cmml">(</mo><msub id="S3.SS3.p2.10.m10.1.1.1.1.1.1" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p2.10.m10.1.1.1.1.1.1.2" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1.2.cmml">M</mi><mi id="S3.SS3.p2.10.m10.1.1.1.1.1.1.3" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1.3.cmml">r</mi></msub><mo id="S3.SS3.p2.10.m10.3.3.3.3.3.5" xref="S3.SS3.p2.10.m10.3.3.3.3.4.cmml">,</mo><msub id="S3.SS3.p2.10.m10.2.2.2.2.2.2" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2.cmml"><mi id="S3.SS3.p2.10.m10.2.2.2.2.2.2.2" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2.2.cmml">I</mi><mi id="S3.SS3.p2.10.m10.2.2.2.2.2.2.3" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2.3.cmml">r</mi></msub><mo id="S3.SS3.p2.10.m10.3.3.3.3.3.6" xref="S3.SS3.p2.10.m10.3.3.3.3.4.cmml">,</mo><msub id="S3.SS3.p2.10.m10.3.3.3.3.3.3" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3.cmml"><mi id="S3.SS3.p2.10.m10.3.3.3.3.3.3.2" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3.2.cmml">S</mi><mi id="S3.SS3.p2.10.m10.3.3.3.3.3.3.3" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3.3.cmml">r</mi></msub><mo id="S3.SS3.p2.10.m10.3.3.3.3.3.7" stretchy="false" xref="S3.SS3.p2.10.m10.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.3b"><apply id="S3.SS3.p2.10.m10.3.3.cmml" xref="S3.SS3.p2.10.m10.3.3"><eq id="S3.SS3.p2.10.m10.3.3.4.cmml" xref="S3.SS3.p2.10.m10.3.3.4"></eq><apply id="S3.SS3.p2.10.m10.3.3.5.cmml" xref="S3.SS3.p2.10.m10.3.3.5"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.3.3.5.1.cmml" xref="S3.SS3.p2.10.m10.3.3.5">subscript</csymbol><ci id="S3.SS3.p2.10.m10.3.3.5.2.cmml" xref="S3.SS3.p2.10.m10.3.3.5.2">ℳ</ci><ci id="S3.SS3.p2.10.m10.3.3.5.3.cmml" xref="S3.SS3.p2.10.m10.3.3.5.3">𝑟</ci></apply><apply id="S3.SS3.p2.10.m10.3.3.3.cmml" xref="S3.SS3.p2.10.m10.3.3.3"><times id="S3.SS3.p2.10.m10.3.3.3.4.cmml" xref="S3.SS3.p2.10.m10.3.3.3.4"></times><ci id="S3.SS3.p2.10.m10.3.3.3.5a.cmml" xref="S3.SS3.p2.10.m10.3.3.3.5"><mtext class="ltx_mathvariant_monospace" id="S3.SS3.p2.10.m10.3.3.3.5.cmml" xref="S3.SS3.p2.10.m10.3.3.3.5">TextMap</mtext></ci><vector id="S3.SS3.p2.10.m10.3.3.3.3.4.cmml" xref="S3.SS3.p2.10.m10.3.3.3.3.3"><apply id="S3.SS3.p2.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1.2">𝑀</ci><ci id="S3.SS3.p2.10.m10.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.1.1.1.1.3">𝑟</ci></apply><apply id="S3.SS3.p2.10.m10.2.2.2.2.2.2.cmml" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.10.m10.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2.2">𝐼</ci><ci id="S3.SS3.p2.10.m10.2.2.2.2.2.2.3.cmml" xref="S3.SS3.p2.10.m10.2.2.2.2.2.2.3">𝑟</ci></apply><apply id="S3.SS3.p2.10.m10.3.3.3.3.3.3.cmml" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.3.3.3.3.3.3.1.cmml" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS3.p2.10.m10.3.3.3.3.3.3.2.cmml" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3.2">𝑆</ci><ci id="S3.SS3.p2.10.m10.3.3.3.3.3.3.3.cmml" xref="S3.SS3.p2.10.m10.3.3.3.3.3.3.3">𝑟</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.3c">\mathcal{M}_{r}=\texttt{TextMap}(M_{r},I_{r},S_{r})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.10.m10.3d">caligraphic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = TextMap ( italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT )</annotation></semantics></math> for rendering under novel poses.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">Note that as discussed in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.SS1" title="I-A Taxonomy and Applicability of Our Method ‣ I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">I-A</span></span></a> (Applicability), our method possesses the potential of using only an RGB reference and estimating an imprecise depth map exploiting an off-the-shelf generalizable depth estimator. Good estimation is validated in supplementary material given an imprecise and noising depth. We leave training a generalizable depth estimator as our future work to avoid possible distractions in this paper.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.5.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.6.2">Label/Training-Free Refinement via Differentiable Renderer</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.5">Our last module of label/training-free refinement is constructed by a differentiable renderer, which takes the textured 2.5D reference mesh <math alttext="\mathcal{M}_{r}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">ℳ</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">ℳ</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mathcal{M}_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">caligraphic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and a pose <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><mi id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">italic_P</annotation></semantics></math> as input, then renders a novel RGB image and a novel semantic map under the view <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m3.1"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m3.1d">italic_P</annotation></semantics></math>. By implementing the pose <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p1.4.m4.1"><semantics id="S3.SS4.p1.4.m4.1a"><mi id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.4.m4.1d">italic_P</annotation></semantics></math> as a random variable, the render-and-compare/reprojection loss can be back-propagated directly to <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p1.5.m5.1"><semantics id="S3.SS4.p1.5.m5.1a"><mi id="S3.SS4.p1.5.m5.1.1" xref="S3.SS4.p1.5.m5.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m5.1b"><ci id="S3.SS4.p1.5.m5.1.1.cmml" xref="S3.SS4.p1.5.m5.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m5.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.5.m5.1d">italic_P</annotation></semantics></math>, ensuring the label/training-free and zero-shot unseen generalization merits of our proposed method.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.6">Formally, by assuming a perspective camera, we leverage a recent differentiable renderer <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p2.6.1">nvidiffrast</span> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib25" title=""><span class="ltx_text" style="font-size:80%;">nvidiffrast</span> </a></cite>, denoted as <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">caligraphic_R</annotation></semantics></math>, to generate novel RGB and semantic maps, <math alttext="I_{r}(P)" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.1"><semantics id="S3.SS4.p2.2.m2.1a"><mrow id="S3.SS4.p2.2.m2.1.2" xref="S3.SS4.p2.2.m2.1.2.cmml"><msub id="S3.SS4.p2.2.m2.1.2.2" xref="S3.SS4.p2.2.m2.1.2.2.cmml"><mi id="S3.SS4.p2.2.m2.1.2.2.2" xref="S3.SS4.p2.2.m2.1.2.2.2.cmml">I</mi><mi id="S3.SS4.p2.2.m2.1.2.2.3" xref="S3.SS4.p2.2.m2.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS4.p2.2.m2.1.2.1" xref="S3.SS4.p2.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p2.2.m2.1.2.3.2" xref="S3.SS4.p2.2.m2.1.2.cmml"><mo id="S3.SS4.p2.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS4.p2.2.m2.1.2.cmml">(</mo><mi id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">P</mi><mo id="S3.SS4.p2.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS4.p2.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.2.cmml" xref="S3.SS4.p2.2.m2.1.2"><times id="S3.SS4.p2.2.m2.1.2.1.cmml" xref="S3.SS4.p2.2.m2.1.2.1"></times><apply id="S3.SS4.p2.2.m2.1.2.2.cmml" xref="S3.SS4.p2.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.2.2.1.cmml" xref="S3.SS4.p2.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS4.p2.2.m2.1.2.2.2.cmml" xref="S3.SS4.p2.2.m2.1.2.2.2">𝐼</ci><ci id="S3.SS4.p2.2.m2.1.2.2.3.cmml" xref="S3.SS4.p2.2.m2.1.2.2.3">𝑟</ci></apply><ci id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">I_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math> and <math alttext="S_{r}(P)" class="ltx_Math" display="inline" id="S3.SS4.p2.3.m3.1"><semantics id="S3.SS4.p2.3.m3.1a"><mrow id="S3.SS4.p2.3.m3.1.2" xref="S3.SS4.p2.3.m3.1.2.cmml"><msub id="S3.SS4.p2.3.m3.1.2.2" xref="S3.SS4.p2.3.m3.1.2.2.cmml"><mi id="S3.SS4.p2.3.m3.1.2.2.2" xref="S3.SS4.p2.3.m3.1.2.2.2.cmml">S</mi><mi id="S3.SS4.p2.3.m3.1.2.2.3" xref="S3.SS4.p2.3.m3.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS4.p2.3.m3.1.2.1" xref="S3.SS4.p2.3.m3.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p2.3.m3.1.2.3.2" xref="S3.SS4.p2.3.m3.1.2.cmml"><mo id="S3.SS4.p2.3.m3.1.2.3.2.1" stretchy="false" xref="S3.SS4.p2.3.m3.1.2.cmml">(</mo><mi id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml">P</mi><mo id="S3.SS4.p2.3.m3.1.2.3.2.2" stretchy="false" xref="S3.SS4.p2.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.2.cmml" xref="S3.SS4.p2.3.m3.1.2"><times id="S3.SS4.p2.3.m3.1.2.1.cmml" xref="S3.SS4.p2.3.m3.1.2.1"></times><apply id="S3.SS4.p2.3.m3.1.2.2.cmml" xref="S3.SS4.p2.3.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.2.2.1.cmml" xref="S3.SS4.p2.3.m3.1.2.2">subscript</csymbol><ci id="S3.SS4.p2.3.m3.1.2.2.2.cmml" xref="S3.SS4.p2.3.m3.1.2.2.2">𝑆</ci><ci id="S3.SS4.p2.3.m3.1.2.2.3.cmml" xref="S3.SS4.p2.3.m3.1.2.2.3">𝑟</ci></apply><ci id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">S_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.3.m3.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math>, from the textured 2.5D reference mesh <math alttext="\mathcal{M}_{r}" class="ltx_Math" display="inline" id="S3.SS4.p2.4.m4.1"><semantics id="S3.SS4.p2.4.m4.1a"><msub id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.4.m4.1.1.2" xref="S3.SS4.p2.4.m4.1.1.2.cmml">ℳ</mi><mi id="S3.SS4.p2.4.m4.1.1.3" xref="S3.SS4.p2.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><apply id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p2.4.m4.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2">ℳ</ci><ci id="S3.SS4.p2.4.m4.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">\mathcal{M}_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.4.m4.1d">caligraphic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, an arbitrary pose <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p2.5.m5.1"><semantics id="S3.SS4.p2.5.m5.1a"><mi id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><ci id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.5.m5.1d">italic_P</annotation></semantics></math>, and the camera intrinsics <math alttext="K" class="ltx_Math" display="inline" id="S3.SS4.p2.6.m6.1"><semantics id="S3.SS4.p2.6.m6.1a"><mi id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><ci id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.6.m6.1d">italic_K</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="I_{r}(P),S_{r}(P)=\mathcal{R}(P,\mathcal{M_{\text{r}}},K)" class="ltx_Math" display="block" id="S3.E2.m1.7"><semantics id="S3.E2.m1.7a"><mrow id="S3.E2.m1.7.7" xref="S3.E2.m1.7.7.cmml"><mrow id="S3.E2.m1.6.6.2.2" xref="S3.E2.m1.6.6.2.3.cmml"><mrow id="S3.E2.m1.5.5.1.1.1" xref="S3.E2.m1.5.5.1.1.1.cmml"><msub id="S3.E2.m1.5.5.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.2.cmml"><mi id="S3.E2.m1.5.5.1.1.1.2.2" xref="S3.E2.m1.5.5.1.1.1.2.2.cmml">I</mi><mi id="S3.E2.m1.5.5.1.1.1.2.3" xref="S3.E2.m1.5.5.1.1.1.2.3.cmml">r</mi></msub><mo id="S3.E2.m1.5.5.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.cmml">⁢</mo><mrow id="S3.E2.m1.5.5.1.1.1.3.2" xref="S3.E2.m1.5.5.1.1.1.cmml"><mo id="S3.E2.m1.5.5.1.1.1.3.2.1" stretchy="false" xref="S3.E2.m1.5.5.1.1.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">P</mi><mo id="S3.E2.m1.5.5.1.1.1.3.2.2" stretchy="false" xref="S3.E2.m1.5.5.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.6.6.2.2.3" xref="S3.E2.m1.6.6.2.3.cmml">,</mo><mrow id="S3.E2.m1.6.6.2.2.2" xref="S3.E2.m1.6.6.2.2.2.cmml"><msub id="S3.E2.m1.6.6.2.2.2.2" xref="S3.E2.m1.6.6.2.2.2.2.cmml"><mi id="S3.E2.m1.6.6.2.2.2.2.2" xref="S3.E2.m1.6.6.2.2.2.2.2.cmml">S</mi><mi id="S3.E2.m1.6.6.2.2.2.2.3" xref="S3.E2.m1.6.6.2.2.2.2.3.cmml">r</mi></msub><mo id="S3.E2.m1.6.6.2.2.2.1" xref="S3.E2.m1.6.6.2.2.2.1.cmml">⁢</mo><mrow id="S3.E2.m1.6.6.2.2.2.3.2" xref="S3.E2.m1.6.6.2.2.2.cmml"><mo id="S3.E2.m1.6.6.2.2.2.3.2.1" stretchy="false" xref="S3.E2.m1.6.6.2.2.2.cmml">(</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">P</mi><mo id="S3.E2.m1.6.6.2.2.2.3.2.2" stretchy="false" xref="S3.E2.m1.6.6.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.7.7.4" xref="S3.E2.m1.7.7.4.cmml">=</mo><mrow id="S3.E2.m1.7.7.3" xref="S3.E2.m1.7.7.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.7.7.3.3" xref="S3.E2.m1.7.7.3.3.cmml">ℛ</mi><mo id="S3.E2.m1.7.7.3.2" xref="S3.E2.m1.7.7.3.2.cmml">⁢</mo><mrow id="S3.E2.m1.7.7.3.1.1" xref="S3.E2.m1.7.7.3.1.2.cmml"><mo id="S3.E2.m1.7.7.3.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.3.1.2.cmml">(</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">P</mi><mo id="S3.E2.m1.7.7.3.1.1.3" xref="S3.E2.m1.7.7.3.1.2.cmml">,</mo><msub id="S3.E2.m1.7.7.3.1.1.1" xref="S3.E2.m1.7.7.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.7.7.3.1.1.1.2" xref="S3.E2.m1.7.7.3.1.1.1.2.cmml">ℳ</mi><mtext id="S3.E2.m1.7.7.3.1.1.1.3" xref="S3.E2.m1.7.7.3.1.1.1.3a.cmml">r</mtext></msub><mo id="S3.E2.m1.7.7.3.1.1.4" xref="S3.E2.m1.7.7.3.1.2.cmml">,</mo><mi id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">K</mi><mo id="S3.E2.m1.7.7.3.1.1.5" stretchy="false" xref="S3.E2.m1.7.7.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.7b"><apply id="S3.E2.m1.7.7.cmml" xref="S3.E2.m1.7.7"><eq id="S3.E2.m1.7.7.4.cmml" xref="S3.E2.m1.7.7.4"></eq><list id="S3.E2.m1.6.6.2.3.cmml" xref="S3.E2.m1.6.6.2.2"><apply id="S3.E2.m1.5.5.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1"><times id="S3.E2.m1.5.5.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1"></times><apply id="S3.E2.m1.5.5.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.1.1.1.2.1.cmml" xref="S3.E2.m1.5.5.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.5.5.1.1.1.2.2.cmml" xref="S3.E2.m1.5.5.1.1.1.2.2">𝐼</ci><ci id="S3.E2.m1.5.5.1.1.1.2.3.cmml" xref="S3.E2.m1.5.5.1.1.1.2.3">𝑟</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑃</ci></apply><apply id="S3.E2.m1.6.6.2.2.2.cmml" xref="S3.E2.m1.6.6.2.2.2"><times id="S3.E2.m1.6.6.2.2.2.1.cmml" xref="S3.E2.m1.6.6.2.2.2.1"></times><apply id="S3.E2.m1.6.6.2.2.2.2.cmml" xref="S3.E2.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.2.2.2.2.1.cmml" xref="S3.E2.m1.6.6.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.6.6.2.2.2.2.2.cmml" xref="S3.E2.m1.6.6.2.2.2.2.2">𝑆</ci><ci id="S3.E2.m1.6.6.2.2.2.2.3.cmml" xref="S3.E2.m1.6.6.2.2.2.2.3">𝑟</ci></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑃</ci></apply></list><apply id="S3.E2.m1.7.7.3.cmml" xref="S3.E2.m1.7.7.3"><times id="S3.E2.m1.7.7.3.2.cmml" xref="S3.E2.m1.7.7.3.2"></times><ci id="S3.E2.m1.7.7.3.3.cmml" xref="S3.E2.m1.7.7.3.3">ℛ</ci><vector id="S3.E2.m1.7.7.3.1.2.cmml" xref="S3.E2.m1.7.7.3.1.1"><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝑃</ci><apply id="S3.E2.m1.7.7.3.1.1.1.cmml" xref="S3.E2.m1.7.7.3.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.3.1.1.1.1.cmml" xref="S3.E2.m1.7.7.3.1.1.1">subscript</csymbol><ci id="S3.E2.m1.7.7.3.1.1.1.2.cmml" xref="S3.E2.m1.7.7.3.1.1.1.2">ℳ</ci><ci id="S3.E2.m1.7.7.3.1.1.1.3a.cmml" xref="S3.E2.m1.7.7.3.1.1.1.3"><mtext id="S3.E2.m1.7.7.3.1.1.1.3.cmml" mathsize="70%" xref="S3.E2.m1.7.7.3.1.1.1.3">r</mtext></ci></apply><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">𝐾</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.7c">I_{r}(P),S_{r}(P)=\mathcal{R}(P,\mathcal{M_{\text{r}}},K)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.7d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) , italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) = caligraphic_R ( italic_P , caligraphic_M start_POSTSUBSCRIPT r end_POSTSUBSCRIPT , italic_K )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p3.1.1">Back Surface Culling.</span> As the reconstructed mesh is only 2.5D representing the front surface, it is crucial to conduct the back-surface culling during the rendering to filter out the incorrect back-facing polygons. Specifically, for every triangle of the mesh, we first calculate the dot product of their surface normal and the camera-to-triangle (usually set to <math alttext="[0,0,1]" class="ltx_Math" display="inline" id="S3.SS4.p3.1.m1.3"><semantics id="S3.SS4.p3.1.m1.3a"><mrow id="S3.SS4.p3.1.m1.3.4.2" xref="S3.SS4.p3.1.m1.3.4.1.cmml"><mo id="S3.SS4.p3.1.m1.3.4.2.1" stretchy="false" xref="S3.SS4.p3.1.m1.3.4.1.cmml">[</mo><mn id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml">0</mn><mo id="S3.SS4.p3.1.m1.3.4.2.2" xref="S3.SS4.p3.1.m1.3.4.1.cmml">,</mo><mn id="S3.SS4.p3.1.m1.2.2" xref="S3.SS4.p3.1.m1.2.2.cmml">0</mn><mo id="S3.SS4.p3.1.m1.3.4.2.3" xref="S3.SS4.p3.1.m1.3.4.1.cmml">,</mo><mn id="S3.SS4.p3.1.m1.3.3" xref="S3.SS4.p3.1.m1.3.3.cmml">1</mn><mo id="S3.SS4.p3.1.m1.3.4.2.4" stretchy="false" xref="S3.SS4.p3.1.m1.3.4.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.3b"><list id="S3.SS4.p3.1.m1.3.4.1.cmml" xref="S3.SS4.p3.1.m1.3.4.2"><cn id="S3.SS4.p3.1.m1.1.1.cmml" type="integer" xref="S3.SS4.p3.1.m1.1.1">0</cn><cn id="S3.SS4.p3.1.m1.2.2.cmml" type="integer" xref="S3.SS4.p3.1.m1.2.2">0</cn><cn id="S3.SS4.p3.1.m1.3.3.cmml" type="integer" xref="S3.SS4.p3.1.m1.3.3">1</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.3c">[0,0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.1.m1.3d">[ 0 , 0 , 1 ]</annotation></semantics></math>) and then discard all triangles whose dot product is greater or equal to 0 <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib74" title=""><span class="ltx_text" style="font-size:80%;">backface_culling</span> </a></cite>. Please also see the ablation with and without the back-surface culling in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T5" title="TABLE V ‣ V-A The Contributions of the Proposed Comprising Elements ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.5">Finally, the pose <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p4.1.m1.1"><semantics id="S3.SS4.p4.1.m1.1a"><mi id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.1b"><ci id="S3.SS4.p4.1.m1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.1.m1.1d">italic_P</annotation></semantics></math> can be optimized to align the rendered <math alttext="I_{r}(P)" class="ltx_Math" display="inline" id="S3.SS4.p4.2.m2.1"><semantics id="S3.SS4.p4.2.m2.1a"><mrow id="S3.SS4.p4.2.m2.1.2" xref="S3.SS4.p4.2.m2.1.2.cmml"><msub id="S3.SS4.p4.2.m2.1.2.2" xref="S3.SS4.p4.2.m2.1.2.2.cmml"><mi id="S3.SS4.p4.2.m2.1.2.2.2" xref="S3.SS4.p4.2.m2.1.2.2.2.cmml">I</mi><mi id="S3.SS4.p4.2.m2.1.2.2.3" xref="S3.SS4.p4.2.m2.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS4.p4.2.m2.1.2.1" xref="S3.SS4.p4.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p4.2.m2.1.2.3.2" xref="S3.SS4.p4.2.m2.1.2.cmml"><mo id="S3.SS4.p4.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS4.p4.2.m2.1.2.cmml">(</mo><mi id="S3.SS4.p4.2.m2.1.1" xref="S3.SS4.p4.2.m2.1.1.cmml">P</mi><mo id="S3.SS4.p4.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS4.p4.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.2.m2.1b"><apply id="S3.SS4.p4.2.m2.1.2.cmml" xref="S3.SS4.p4.2.m2.1.2"><times id="S3.SS4.p4.2.m2.1.2.1.cmml" xref="S3.SS4.p4.2.m2.1.2.1"></times><apply id="S3.SS4.p4.2.m2.1.2.2.cmml" xref="S3.SS4.p4.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS4.p4.2.m2.1.2.2.1.cmml" xref="S3.SS4.p4.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS4.p4.2.m2.1.2.2.2.cmml" xref="S3.SS4.p4.2.m2.1.2.2.2">𝐼</ci><ci id="S3.SS4.p4.2.m2.1.2.2.3.cmml" xref="S3.SS4.p4.2.m2.1.2.2.3">𝑟</ci></apply><ci id="S3.SS4.p4.2.m2.1.1.cmml" xref="S3.SS4.p4.2.m2.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.2.m2.1c">I_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.2.m2.1d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math> and <math alttext="S_{r}(P)" class="ltx_Math" display="inline" id="S3.SS4.p4.3.m3.1"><semantics id="S3.SS4.p4.3.m3.1a"><mrow id="S3.SS4.p4.3.m3.1.2" xref="S3.SS4.p4.3.m3.1.2.cmml"><msub id="S3.SS4.p4.3.m3.1.2.2" xref="S3.SS4.p4.3.m3.1.2.2.cmml"><mi id="S3.SS4.p4.3.m3.1.2.2.2" xref="S3.SS4.p4.3.m3.1.2.2.2.cmml">S</mi><mi id="S3.SS4.p4.3.m3.1.2.2.3" xref="S3.SS4.p4.3.m3.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS4.p4.3.m3.1.2.1" xref="S3.SS4.p4.3.m3.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p4.3.m3.1.2.3.2" xref="S3.SS4.p4.3.m3.1.2.cmml"><mo id="S3.SS4.p4.3.m3.1.2.3.2.1" stretchy="false" xref="S3.SS4.p4.3.m3.1.2.cmml">(</mo><mi id="S3.SS4.p4.3.m3.1.1" xref="S3.SS4.p4.3.m3.1.1.cmml">P</mi><mo id="S3.SS4.p4.3.m3.1.2.3.2.2" stretchy="false" xref="S3.SS4.p4.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.3.m3.1b"><apply id="S3.SS4.p4.3.m3.1.2.cmml" xref="S3.SS4.p4.3.m3.1.2"><times id="S3.SS4.p4.3.m3.1.2.1.cmml" xref="S3.SS4.p4.3.m3.1.2.1"></times><apply id="S3.SS4.p4.3.m3.1.2.2.cmml" xref="S3.SS4.p4.3.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS4.p4.3.m3.1.2.2.1.cmml" xref="S3.SS4.p4.3.m3.1.2.2">subscript</csymbol><ci id="S3.SS4.p4.3.m3.1.2.2.2.cmml" xref="S3.SS4.p4.3.m3.1.2.2.2">𝑆</ci><ci id="S3.SS4.p4.3.m3.1.2.2.3.cmml" xref="S3.SS4.p4.3.m3.1.2.2.3">𝑟</ci></apply><ci id="S3.SS4.p4.3.m3.1.1.cmml" xref="S3.SS4.p4.3.m3.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.3.m3.1c">S_{r}(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.3.m3.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P )</annotation></semantics></math> with the query <math alttext="I_{q}" class="ltx_Math" display="inline" id="S3.SS4.p4.4.m4.1"><semantics id="S3.SS4.p4.4.m4.1a"><msub id="S3.SS4.p4.4.m4.1.1" xref="S3.SS4.p4.4.m4.1.1.cmml"><mi id="S3.SS4.p4.4.m4.1.1.2" xref="S3.SS4.p4.4.m4.1.1.2.cmml">I</mi><mi id="S3.SS4.p4.4.m4.1.1.3" xref="S3.SS4.p4.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.4.m4.1b"><apply id="S3.SS4.p4.4.m4.1.1.cmml" xref="S3.SS4.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p4.4.m4.1.1.1.cmml" xref="S3.SS4.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p4.4.m4.1.1.2.cmml" xref="S3.SS4.p4.4.m4.1.1.2">𝐼</ci><ci id="S3.SS4.p4.4.m4.1.1.3.cmml" xref="S3.SS4.p4.4.m4.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.4.m4.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.4.m4.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="S_{q}" class="ltx_Math" display="inline" id="S3.SS4.p4.5.m5.1"><semantics id="S3.SS4.p4.5.m5.1a"><msub id="S3.SS4.p4.5.m5.1.1" xref="S3.SS4.p4.5.m5.1.1.cmml"><mi id="S3.SS4.p4.5.m5.1.1.2" xref="S3.SS4.p4.5.m5.1.1.2.cmml">S</mi><mi id="S3.SS4.p4.5.m5.1.1.3" xref="S3.SS4.p4.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.5.m5.1b"><apply id="S3.SS4.p4.5.m5.1.1.cmml" xref="S3.SS4.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p4.5.m5.1.1.1.cmml" xref="S3.SS4.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS4.p4.5.m5.1.1.2.cmml" xref="S3.SS4.p4.5.m5.1.1.2">𝑆</ci><ci id="S3.SS4.p4.5.m5.1.1.3.cmml" xref="S3.SS4.p4.5.m5.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.5.m5.1c">S_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.5.m5.1d">italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>, with the re-projection loss calculated by:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L(P)=L_{1}\left\{I_{r}(P);I_{q}\right\}+L_{2}\left\{S_{r}(P);S_{q}\right\}," class="ltx_Math" display="block" id="S3.E3.m1.4"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.4.1" xref="S3.E3.m1.4.4.1.1.cmml"><mrow id="S3.E3.m1.4.4.1.1" xref="S3.E3.m1.4.4.1.1.cmml"><mrow id="S3.E3.m1.4.4.1.1.6" xref="S3.E3.m1.4.4.1.1.6.cmml"><mi id="S3.E3.m1.4.4.1.1.6.2" xref="S3.E3.m1.4.4.1.1.6.2.cmml">L</mi><mo id="S3.E3.m1.4.4.1.1.6.1" xref="S3.E3.m1.4.4.1.1.6.1.cmml">⁢</mo><mrow id="S3.E3.m1.4.4.1.1.6.3.2" xref="S3.E3.m1.4.4.1.1.6.cmml"><mo id="S3.E3.m1.4.4.1.1.6.3.2.1" stretchy="false" xref="S3.E3.m1.4.4.1.1.6.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">P</mi><mo id="S3.E3.m1.4.4.1.1.6.3.2.2" stretchy="false" xref="S3.E3.m1.4.4.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.4.4.1.1.5" xref="S3.E3.m1.4.4.1.1.5.cmml">=</mo><mrow id="S3.E3.m1.4.4.1.1.4" xref="S3.E3.m1.4.4.1.1.4.cmml"><mrow id="S3.E3.m1.4.4.1.1.2.2" xref="S3.E3.m1.4.4.1.1.2.2.cmml"><msub id="S3.E3.m1.4.4.1.1.2.2.4" xref="S3.E3.m1.4.4.1.1.2.2.4.cmml"><mi id="S3.E3.m1.4.4.1.1.2.2.4.2" xref="S3.E3.m1.4.4.1.1.2.2.4.2.cmml">L</mi><mn id="S3.E3.m1.4.4.1.1.2.2.4.3" xref="S3.E3.m1.4.4.1.1.2.2.4.3.cmml">1</mn></msub><mo id="S3.E3.m1.4.4.1.1.2.2.3" xref="S3.E3.m1.4.4.1.1.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.4.4.1.1.2.2.2.2" xref="S3.E3.m1.4.4.1.1.2.2.2.3.cmml"><mo id="S3.E3.m1.4.4.1.1.2.2.2.2.3" xref="S3.E3.m1.4.4.1.1.2.2.2.3.cmml">{</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.3.cmml">r</mi></msub><mo id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.4.4.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">P</mi><mo id="S3.E3.m1.4.4.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.4.4.1.1.2.2.2.2.4" xref="S3.E3.m1.4.4.1.1.2.2.2.3.cmml">;</mo><msub id="S3.E3.m1.4.4.1.1.2.2.2.2.2" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2.cmml"><mi id="S3.E3.m1.4.4.1.1.2.2.2.2.2.2" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2.2.cmml">I</mi><mi id="S3.E3.m1.4.4.1.1.2.2.2.2.2.3" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2.3.cmml">q</mi></msub><mo id="S3.E3.m1.4.4.1.1.2.2.2.2.5" xref="S3.E3.m1.4.4.1.1.2.2.2.3.cmml">}</mo></mrow></mrow><mo id="S3.E3.m1.4.4.1.1.4.5" xref="S3.E3.m1.4.4.1.1.4.5.cmml">+</mo><mrow id="S3.E3.m1.4.4.1.1.4.4" xref="S3.E3.m1.4.4.1.1.4.4.cmml"><msub id="S3.E3.m1.4.4.1.1.4.4.4" xref="S3.E3.m1.4.4.1.1.4.4.4.cmml"><mi id="S3.E3.m1.4.4.1.1.4.4.4.2" xref="S3.E3.m1.4.4.1.1.4.4.4.2.cmml">L</mi><mn id="S3.E3.m1.4.4.1.1.4.4.4.3" xref="S3.E3.m1.4.4.1.1.4.4.4.3.cmml">2</mn></msub><mo id="S3.E3.m1.4.4.1.1.4.4.3" xref="S3.E3.m1.4.4.1.1.4.4.3.cmml">⁢</mo><mrow id="S3.E3.m1.4.4.1.1.4.4.2.2" xref="S3.E3.m1.4.4.1.1.4.4.2.3.cmml"><mo id="S3.E3.m1.4.4.1.1.4.4.2.2.3" xref="S3.E3.m1.4.4.1.1.4.4.2.3.cmml">{</mo><mrow id="S3.E3.m1.4.4.1.1.3.3.1.1.1" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.cmml"><msub id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.cmml"><mi id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.2" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.2.cmml">S</mi><mi id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.3" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.3.cmml">r</mi></msub><mo id="S3.E3.m1.4.4.1.1.3.3.1.1.1.1" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.1.cmml">⁢</mo><mrow id="S3.E3.m1.4.4.1.1.3.3.1.1.1.3.2" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.cmml"><mo id="S3.E3.m1.4.4.1.1.3.3.1.1.1.3.2.1" stretchy="false" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.cmml">(</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">P</mi><mo id="S3.E3.m1.4.4.1.1.3.3.1.1.1.3.2.2" stretchy="false" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.4.4.1.1.4.4.2.2.4" xref="S3.E3.m1.4.4.1.1.4.4.2.3.cmml">;</mo><msub id="S3.E3.m1.4.4.1.1.4.4.2.2.2" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2.cmml"><mi id="S3.E3.m1.4.4.1.1.4.4.2.2.2.2" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2.2.cmml">S</mi><mi id="S3.E3.m1.4.4.1.1.4.4.2.2.2.3" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2.3.cmml">q</mi></msub><mo id="S3.E3.m1.4.4.1.1.4.4.2.2.5" xref="S3.E3.m1.4.4.1.1.4.4.2.3.cmml">}</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.4.4.1.2" xref="S3.E3.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.4.1.1.cmml" xref="S3.E3.m1.4.4.1"><eq id="S3.E3.m1.4.4.1.1.5.cmml" xref="S3.E3.m1.4.4.1.1.5"></eq><apply id="S3.E3.m1.4.4.1.1.6.cmml" xref="S3.E3.m1.4.4.1.1.6"><times id="S3.E3.m1.4.4.1.1.6.1.cmml" xref="S3.E3.m1.4.4.1.1.6.1"></times><ci id="S3.E3.m1.4.4.1.1.6.2.cmml" xref="S3.E3.m1.4.4.1.1.6.2">𝐿</ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑃</ci></apply><apply id="S3.E3.m1.4.4.1.1.4.cmml" xref="S3.E3.m1.4.4.1.1.4"><plus id="S3.E3.m1.4.4.1.1.4.5.cmml" xref="S3.E3.m1.4.4.1.1.4.5"></plus><apply id="S3.E3.m1.4.4.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2"><times id="S3.E3.m1.4.4.1.1.2.2.3.cmml" xref="S3.E3.m1.4.4.1.1.2.2.3"></times><apply id="S3.E3.m1.4.4.1.1.2.2.4.cmml" xref="S3.E3.m1.4.4.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.2.2.4.1.cmml" xref="S3.E3.m1.4.4.1.1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.2.2.4.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2.4.2">𝐿</ci><cn id="S3.E3.m1.4.4.1.1.2.2.4.3.cmml" type="integer" xref="S3.E3.m1.4.4.1.1.2.2.4.3">1</cn></apply><list id="S3.E3.m1.4.4.1.1.2.2.2.3.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.2"><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1"><times id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1"></times><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.2">𝐼</ci><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝑃</ci></apply><apply id="S3.E3.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2.2">𝐼</ci><ci id="S3.E3.m1.4.4.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.4.4.1.1.2.2.2.2.2.3">𝑞</ci></apply></list></apply><apply id="S3.E3.m1.4.4.1.1.4.4.cmml" xref="S3.E3.m1.4.4.1.1.4.4"><times id="S3.E3.m1.4.4.1.1.4.4.3.cmml" xref="S3.E3.m1.4.4.1.1.4.4.3"></times><apply id="S3.E3.m1.4.4.1.1.4.4.4.cmml" xref="S3.E3.m1.4.4.1.1.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.4.4.4.1.cmml" xref="S3.E3.m1.4.4.1.1.4.4.4">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.4.4.4.2.cmml" xref="S3.E3.m1.4.4.1.1.4.4.4.2">𝐿</ci><cn id="S3.E3.m1.4.4.1.1.4.4.4.3.cmml" type="integer" xref="S3.E3.m1.4.4.1.1.4.4.4.3">2</cn></apply><list id="S3.E3.m1.4.4.1.1.4.4.2.3.cmml" xref="S3.E3.m1.4.4.1.1.4.4.2.2"><apply id="S3.E3.m1.4.4.1.1.3.3.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1"><times id="S3.E3.m1.4.4.1.1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.1"></times><apply id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.2">𝑆</ci><ci id="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.3.cmml" xref="S3.E3.m1.4.4.1.1.3.3.1.1.1.2.3">𝑟</ci></apply><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">𝑃</ci></apply><apply id="S3.E3.m1.4.4.1.1.4.4.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.4.4.2.2.2.1.cmml" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.4.4.2.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2.2">𝑆</ci><ci id="S3.E3.m1.4.4.1.1.4.4.2.2.2.3.cmml" xref="S3.E3.m1.4.4.1.1.4.4.2.2.2.3">𝑞</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">L(P)=L_{1}\left\{I_{r}(P);I_{q}\right\}+L_{2}\left\{S_{r}(P);S_{q}\right\},</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.4d">italic_L ( italic_P ) = italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT { italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ; italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT } + italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT { italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ; italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p4.7">where <math alttext="L(P)" class="ltx_Math" display="inline" id="S3.SS4.p4.6.m1.1"><semantics id="S3.SS4.p4.6.m1.1a"><mrow id="S3.SS4.p4.6.m1.1.2" xref="S3.SS4.p4.6.m1.1.2.cmml"><mi id="S3.SS4.p4.6.m1.1.2.2" xref="S3.SS4.p4.6.m1.1.2.2.cmml">L</mi><mo id="S3.SS4.p4.6.m1.1.2.1" xref="S3.SS4.p4.6.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS4.p4.6.m1.1.2.3.2" xref="S3.SS4.p4.6.m1.1.2.cmml"><mo id="S3.SS4.p4.6.m1.1.2.3.2.1" stretchy="false" xref="S3.SS4.p4.6.m1.1.2.cmml">(</mo><mi id="S3.SS4.p4.6.m1.1.1" xref="S3.SS4.p4.6.m1.1.1.cmml">P</mi><mo id="S3.SS4.p4.6.m1.1.2.3.2.2" stretchy="false" xref="S3.SS4.p4.6.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.6.m1.1b"><apply id="S3.SS4.p4.6.m1.1.2.cmml" xref="S3.SS4.p4.6.m1.1.2"><times id="S3.SS4.p4.6.m1.1.2.1.cmml" xref="S3.SS4.p4.6.m1.1.2.1"></times><ci id="S3.SS4.p4.6.m1.1.2.2.cmml" xref="S3.SS4.p4.6.m1.1.2.2">𝐿</ci><ci id="S3.SS4.p4.6.m1.1.1.cmml" xref="S3.SS4.p4.6.m1.1.1">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.6.m1.1c">L(P)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.6.m1.1d">italic_L ( italic_P )</annotation></semantics></math> is the final loss to optimize the pose <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p4.7.m2.1"><semantics id="S3.SS4.p4.7.m2.1a"><mi id="S3.SS4.p4.7.m2.1.1" xref="S3.SS4.p4.7.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.7.m2.1b"><ci id="S3.SS4.p4.7.m2.1.1.cmml" xref="S3.SS4.p4.7.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.7.m2.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.7.m2.1d">italic_P</annotation></semantics></math>, and we implement both losses by the multi-scale structural similarity (MS-SSIM) <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib78" title=""><span class="ltx_text" style="font-size:80%;">msssim</span> </a></cite> as the following:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S6.EGx1">
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle L_{1}=1-\text{ms-ssim}\left\{I_{r}(P);I_{q}\right\}," class="ltx_Math" display="inline" id="S3.E4.m1.2"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2.1" xref="S3.E4.m1.2.2.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1" xref="S3.E4.m1.2.2.1.1.cmml"><msub id="S3.E4.m1.2.2.1.1.4" xref="S3.E4.m1.2.2.1.1.4.cmml"><mi id="S3.E4.m1.2.2.1.1.4.2" xref="S3.E4.m1.2.2.1.1.4.2.cmml">L</mi><mn id="S3.E4.m1.2.2.1.1.4.3" xref="S3.E4.m1.2.2.1.1.4.3.cmml">1</mn></msub><mo id="S3.E4.m1.2.2.1.1.3" xref="S3.E4.m1.2.2.1.1.3.cmml">=</mo><mrow id="S3.E4.m1.2.2.1.1.2" xref="S3.E4.m1.2.2.1.1.2.cmml"><mn id="S3.E4.m1.2.2.1.1.2.4" xref="S3.E4.m1.2.2.1.1.2.4.cmml">1</mn><mo id="S3.E4.m1.2.2.1.1.2.3" xref="S3.E4.m1.2.2.1.1.2.3.cmml">−</mo><mrow id="S3.E4.m1.2.2.1.1.2.2" xref="S3.E4.m1.2.2.1.1.2.2.cmml"><mtext id="S3.E4.m1.2.2.1.1.2.2.4" xref="S3.E4.m1.2.2.1.1.2.2.4a.cmml">ms-ssim</mtext><mo id="S3.E4.m1.2.2.1.1.2.2.3" xref="S3.E4.m1.2.2.1.1.2.2.3.cmml">⁢</mo><mrow id="S3.E4.m1.2.2.1.1.2.2.2.2" xref="S3.E4.m1.2.2.1.1.2.2.2.3.cmml"><mo id="S3.E4.m1.2.2.1.1.2.2.2.2.3" xref="S3.E4.m1.2.2.1.1.2.2.2.3.cmml">{</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">I</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">r</mi></msub><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">P</mi><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.2.2.1.1.2.2.2.2.4" xref="S3.E4.m1.2.2.1.1.2.2.2.3.cmml">;</mo><msub id="S3.E4.m1.2.2.1.1.2.2.2.2.2" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2.cmml"><mi id="S3.E4.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2.2.cmml">I</mi><mi id="S3.E4.m1.2.2.1.1.2.2.2.2.2.3" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2.3.cmml">q</mi></msub><mo id="S3.E4.m1.2.2.1.1.2.2.2.2.5" xref="S3.E4.m1.2.2.1.1.2.2.2.3.cmml">}</mo></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.2.2.1.2" xref="S3.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.1.1.cmml" xref="S3.E4.m1.2.2.1"><eq id="S3.E4.m1.2.2.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.3"></eq><apply id="S3.E4.m1.2.2.1.1.4.cmml" xref="S3.E4.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.4.1.cmml" xref="S3.E4.m1.2.2.1.1.4">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.4.2.cmml" xref="S3.E4.m1.2.2.1.1.4.2">𝐿</ci><cn id="S3.E4.m1.2.2.1.1.4.3.cmml" type="integer" xref="S3.E4.m1.2.2.1.1.4.3">1</cn></apply><apply id="S3.E4.m1.2.2.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.2"><minus id="S3.E4.m1.2.2.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.2.3"></minus><cn id="S3.E4.m1.2.2.1.1.2.4.cmml" type="integer" xref="S3.E4.m1.2.2.1.1.2.4">1</cn><apply id="S3.E4.m1.2.2.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.2.2"><times id="S3.E4.m1.2.2.1.1.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.2.2.3"></times><ci id="S3.E4.m1.2.2.1.1.2.2.4a.cmml" xref="S3.E4.m1.2.2.1.1.2.2.4"><mtext id="S3.E4.m1.2.2.1.1.2.2.4.cmml" xref="S3.E4.m1.2.2.1.1.2.2.4">ms-ssim</mtext></ci><list id="S3.E4.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.2.2.2.2"><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.2">𝐼</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝑃</ci></apply><apply id="S3.E4.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2.2">𝐼</ci><ci id="S3.E4.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.2.2.2.2.2.3">𝑞</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">\displaystyle L_{1}=1-\text{ms-ssim}\left\{I_{r}(P);I_{q}\right\},</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.2d">italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 - ms-ssim { italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ; italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle L_{2}=1-\text{ms-ssim}\left\{S_{r}(P);S_{q}\right\}," class="ltx_Math" display="inline" id="S3.E5.m1.2"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1" xref="S3.E5.m1.2.2.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.4" xref="S3.E5.m1.2.2.1.1.4.cmml"><mi id="S3.E5.m1.2.2.1.1.4.2" xref="S3.E5.m1.2.2.1.1.4.2.cmml">L</mi><mn id="S3.E5.m1.2.2.1.1.4.3" xref="S3.E5.m1.2.2.1.1.4.3.cmml">2</mn></msub><mo id="S3.E5.m1.2.2.1.1.3" xref="S3.E5.m1.2.2.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.2.2.1.1.2" xref="S3.E5.m1.2.2.1.1.2.cmml"><mn id="S3.E5.m1.2.2.1.1.2.4" xref="S3.E5.m1.2.2.1.1.2.4.cmml">1</mn><mo id="S3.E5.m1.2.2.1.1.2.3" xref="S3.E5.m1.2.2.1.1.2.3.cmml">−</mo><mrow id="S3.E5.m1.2.2.1.1.2.2" xref="S3.E5.m1.2.2.1.1.2.2.cmml"><mtext id="S3.E5.m1.2.2.1.1.2.2.4" xref="S3.E5.m1.2.2.1.1.2.2.4a.cmml">ms-ssim</mtext><mo id="S3.E5.m1.2.2.1.1.2.2.3" xref="S3.E5.m1.2.2.1.1.2.2.3.cmml">⁢</mo><mrow id="S3.E5.m1.2.2.1.1.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml"><mo id="S3.E5.m1.2.2.1.1.2.2.2.2.3" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">{</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">S</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">r</mi></msub><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">P</mi><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.1.1.2.2.2.2.4" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">;</mo><msub id="S3.E5.m1.2.2.1.1.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.cmml">S</mi><mi id="S3.E5.m1.2.2.1.1.2.2.2.2.2.3" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.3.cmml">q</mi></msub><mo id="S3.E5.m1.2.2.1.1.2.2.2.2.5" xref="S3.E5.m1.2.2.1.1.2.2.2.3.cmml">}</mo></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.1.1.cmml" xref="S3.E5.m1.2.2.1"><eq id="S3.E5.m1.2.2.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.3"></eq><apply id="S3.E5.m1.2.2.1.1.4.cmml" xref="S3.E5.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.4.1.cmml" xref="S3.E5.m1.2.2.1.1.4">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.4.2.cmml" xref="S3.E5.m1.2.2.1.1.4.2">𝐿</ci><cn id="S3.E5.m1.2.2.1.1.4.3.cmml" type="integer" xref="S3.E5.m1.2.2.1.1.4.3">2</cn></apply><apply id="S3.E5.m1.2.2.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.2"><minus id="S3.E5.m1.2.2.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.3"></minus><cn id="S3.E5.m1.2.2.1.1.2.4.cmml" type="integer" xref="S3.E5.m1.2.2.1.1.2.4">1</cn><apply id="S3.E5.m1.2.2.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2"><times id="S3.E5.m1.2.2.1.1.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.2.3"></times><ci id="S3.E5.m1.2.2.1.1.2.2.4a.cmml" xref="S3.E5.m1.2.2.1.1.2.2.4"><mtext id="S3.E5.m1.2.2.1.1.2.2.4.cmml" xref="S3.E5.m1.2.2.1.1.2.2.4">ms-ssim</mtext></ci><list id="S3.E5.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2"><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1"></times><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.2">𝑆</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑃</ci></apply><apply id="S3.E5.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.2">𝑆</ci><ci id="S3.E5.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.2.2.2.2.2.3">𝑞</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">\displaystyle L_{2}=1-\text{ms-ssim}\left\{S_{r}(P);S_{q}\right\},</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.2d">italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 - ms-ssim { italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ; italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p4.8">Equation (<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.E3" title="In III-D Label/Training-Free Refinement via Differentiable Renderer ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">3</span></a>) enables us to optimize <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p4.8.m1.1"><semantics id="S3.SS4.p4.8.m1.1a"><mi id="S3.SS4.p4.8.m1.1.1" xref="S3.SS4.p4.8.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.8.m1.1b"><ci id="S3.SS4.p4.8.m1.1.1.cmml" xref="S3.SS4.p4.8.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.8.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.8.m1.1d">italic_P</annotation></semantics></math> simply by gradient descent.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.4"><span class="ltx_text ltx_font_bold" id="S3.SS4.p5.4.1">Initialization.</span> As revealed in the majority of prior arts <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib29" title=""><span class="ltx_text" style="font-size:80%;">deepim</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">megapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">latentfusion</span> </a></cite>, a good initialization significantly boosts the performance of the render-and-compare framework.
To this end, we implement our initialization by evenly sampling candidate poses on a sphere and chasing the best one. Specifically, we first sample <math alttext="m" class="ltx_Math" display="inline" id="S3.SS4.p5.1.m1.1"><semantics id="S3.SS4.p5.1.m1.1a"><mi id="S3.SS4.p5.1.m1.1.1" xref="S3.SS4.p5.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.1.m1.1b"><ci id="S3.SS4.p5.1.m1.1.1.cmml" xref="S3.SS4.p5.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.1.m1.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p5.1.m1.1d">italic_m</annotation></semantics></math> viewpoints (azimuth and elevation angles) uniformly using a Fibonacci lattice <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib13" title=""><span class="ltx_text" style="font-size:80%;">gonzalez2010measurement</span> </a></cite>, then uniformly sample <math alttext="n" class="ltx_Math" display="inline" id="S3.SS4.p5.2.m2.1"><semantics id="S3.SS4.p5.2.m2.1a"><mi id="S3.SS4.p5.2.m2.1.1" xref="S3.SS4.p5.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.2.m2.1b"><ci id="S3.SS4.p5.2.m2.1.1.cmml" xref="S3.SS4.p5.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p5.2.m2.1d">italic_n</annotation></semantics></math> in-plane rotation angles for each viewpoint, producing <math alttext="t=m*n" class="ltx_Math" display="inline" id="S3.SS4.p5.3.m3.1"><semantics id="S3.SS4.p5.3.m3.1a"><mrow id="S3.SS4.p5.3.m3.1.1" xref="S3.SS4.p5.3.m3.1.1.cmml"><mi id="S3.SS4.p5.3.m3.1.1.2" xref="S3.SS4.p5.3.m3.1.1.2.cmml">t</mi><mo id="S3.SS4.p5.3.m3.1.1.1" xref="S3.SS4.p5.3.m3.1.1.1.cmml">=</mo><mrow id="S3.SS4.p5.3.m3.1.1.3" xref="S3.SS4.p5.3.m3.1.1.3.cmml"><mi id="S3.SS4.p5.3.m3.1.1.3.2" xref="S3.SS4.p5.3.m3.1.1.3.2.cmml">m</mi><mo id="S3.SS4.p5.3.m3.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS4.p5.3.m3.1.1.3.1.cmml">∗</mo><mi id="S3.SS4.p5.3.m3.1.1.3.3" xref="S3.SS4.p5.3.m3.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.3.m3.1b"><apply id="S3.SS4.p5.3.m3.1.1.cmml" xref="S3.SS4.p5.3.m3.1.1"><eq id="S3.SS4.p5.3.m3.1.1.1.cmml" xref="S3.SS4.p5.3.m3.1.1.1"></eq><ci id="S3.SS4.p5.3.m3.1.1.2.cmml" xref="S3.SS4.p5.3.m3.1.1.2">𝑡</ci><apply id="S3.SS4.p5.3.m3.1.1.3.cmml" xref="S3.SS4.p5.3.m3.1.1.3"><times id="S3.SS4.p5.3.m3.1.1.3.1.cmml" xref="S3.SS4.p5.3.m3.1.1.3.1"></times><ci id="S3.SS4.p5.3.m3.1.1.3.2.cmml" xref="S3.SS4.p5.3.m3.1.1.3.2">𝑚</ci><ci id="S3.SS4.p5.3.m3.1.1.3.3.cmml" xref="S3.SS4.p5.3.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.3.m3.1c">t=m*n</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p5.3.m3.1d">italic_t = italic_m ∗ italic_n</annotation></semantics></math> poses as the initializing candidates. By rendering both RGB and semantic maps of those candidate poses, we are able to calculate the re-projection loss by Eq. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.E3" title="In III-D Label/Training-Free Refinement via Differentiable Renderer ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">3</span></a>) (without back-propagation in this phase) and choose the pose with the minimal loss as our initialization <math alttext="P^{\text{init}}" class="ltx_Math" display="inline" id="S3.SS4.p5.4.m4.1"><semantics id="S3.SS4.p5.4.m4.1a"><msup id="S3.SS4.p5.4.m4.1.1" xref="S3.SS4.p5.4.m4.1.1.cmml"><mi id="S3.SS4.p5.4.m4.1.1.2" xref="S3.SS4.p5.4.m4.1.1.2.cmml">P</mi><mtext id="S3.SS4.p5.4.m4.1.1.3" xref="S3.SS4.p5.4.m4.1.1.3a.cmml">init</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p5.4.m4.1b"><apply id="S3.SS4.p5.4.m4.1.1.cmml" xref="S3.SS4.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p5.4.m4.1.1.1.cmml" xref="S3.SS4.p5.4.m4.1.1">superscript</csymbol><ci id="S3.SS4.p5.4.m4.1.1.2.cmml" xref="S3.SS4.p5.4.m4.1.1.2">𝑃</ci><ci id="S3.SS4.p5.4.m4.1.1.3a.cmml" xref="S3.SS4.p5.4.m4.1.1.3"><mtext id="S3.SS4.p5.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS4.p5.4.m4.1.1.3">init</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p5.4.m4.1c">P^{\text{init}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p5.4.m4.1d">italic_P start_POSTSUPERSCRIPT init end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.2">Given the initialized pose <math alttext="P^{\text{init}}" class="ltx_Math" display="inline" id="S3.SS4.p6.1.m1.1"><semantics id="S3.SS4.p6.1.m1.1a"><msup id="S3.SS4.p6.1.m1.1.1" xref="S3.SS4.p6.1.m1.1.1.cmml"><mi id="S3.SS4.p6.1.m1.1.1.2" xref="S3.SS4.p6.1.m1.1.1.2.cmml">P</mi><mtext id="S3.SS4.p6.1.m1.1.1.3" xref="S3.SS4.p6.1.m1.1.1.3a.cmml">init</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.1.m1.1b"><apply id="S3.SS4.p6.1.m1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p6.1.m1.1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1">superscript</csymbol><ci id="S3.SS4.p6.1.m1.1.1.2.cmml" xref="S3.SS4.p6.1.m1.1.1.2">𝑃</ci><ci id="S3.SS4.p6.1.m1.1.1.3a.cmml" xref="S3.SS4.p6.1.m1.1.1.3"><mtext id="S3.SS4.p6.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS4.p6.1.m1.1.1.3">init</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.1.m1.1c">P^{\text{init}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.1.m1.1d">italic_P start_POSTSUPERSCRIPT init end_POSTSUPERSCRIPT</annotation></semantics></math>, we perform <math alttext="N" class="ltx_Math" display="inline" id="S3.SS4.p6.2.m2.1"><semantics id="S3.SS4.p6.2.m2.1a"><mi id="S3.SS4.p6.2.m2.1.1" xref="S3.SS4.p6.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.2.m2.1b"><ci id="S3.SS4.p6.2.m2.1.1.cmml" xref="S3.SS4.p6.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.2.m2.1d">italic_N</annotation></semantics></math> iterations with gradient back-propagation to carry out the label/training-free refinement via the differentiable renderer. Our algorithm is detailed in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#alg1" title="Algorithm 1 ‣ III-D Label/Training-Free Refinement via Differentiable Renderer ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Generalizable Label/Training-Free Refinement</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0.1.1.1" style="font-size:80%;">0:</span></span>  Reference RGB and depth <math alttext="I_{r},D_{r}" class="ltx_Math" display="inline" id="alg1.l0.m1.2"><semantics id="alg1.l0.m1.2a"><mrow id="alg1.l0.m1.2.2.2" xref="alg1.l0.m1.2.2.3.cmml"><msub id="alg1.l0.m1.1.1.1.1" xref="alg1.l0.m1.1.1.1.1.cmml"><mi id="alg1.l0.m1.1.1.1.1.2" xref="alg1.l0.m1.1.1.1.1.2.cmml">I</mi><mi id="alg1.l0.m1.1.1.1.1.3" xref="alg1.l0.m1.1.1.1.1.3.cmml">r</mi></msub><mo id="alg1.l0.m1.2.2.2.3" xref="alg1.l0.m1.2.2.3.cmml">,</mo><msub id="alg1.l0.m1.2.2.2.2" xref="alg1.l0.m1.2.2.2.2.cmml"><mi id="alg1.l0.m1.2.2.2.2.2" xref="alg1.l0.m1.2.2.2.2.2.cmml">D</mi><mi id="alg1.l0.m1.2.2.2.2.3" xref="alg1.l0.m1.2.2.2.2.3.cmml">r</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l0.m1.2b"><list id="alg1.l0.m1.2.2.3.cmml" xref="alg1.l0.m1.2.2.2"><apply id="alg1.l0.m1.1.1.1.1.cmml" xref="alg1.l0.m1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l0.m1.1.1.1.1.1.cmml" xref="alg1.l0.m1.1.1.1.1">subscript</csymbol><ci id="alg1.l0.m1.1.1.1.1.2.cmml" xref="alg1.l0.m1.1.1.1.1.2">𝐼</ci><ci id="alg1.l0.m1.1.1.1.1.3.cmml" xref="alg1.l0.m1.1.1.1.1.3">𝑟</ci></apply><apply id="alg1.l0.m1.2.2.2.2.cmml" xref="alg1.l0.m1.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l0.m1.2.2.2.2.1.cmml" xref="alg1.l0.m1.2.2.2.2">subscript</csymbol><ci id="alg1.l0.m1.2.2.2.2.2.cmml" xref="alg1.l0.m1.2.2.2.2.2">𝐷</ci><ci id="alg1.l0.m1.2.2.2.2.3.cmml" xref="alg1.l0.m1.2.2.2.2.3">𝑟</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m1.2c">I_{r},D_{r}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m1.2d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>; query RGB <math alttext="I_{q}" class="ltx_Math" display="inline" id="alg1.l0.m2.1"><semantics id="alg1.l0.m2.1a"><msub id="alg1.l0.m2.1.1" xref="alg1.l0.m2.1.1.cmml"><mi id="alg1.l0.m2.1.1.2" xref="alg1.l0.m2.1.1.2.cmml">I</mi><mi id="alg1.l0.m2.1.1.3" xref="alg1.l0.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l0.m2.1b"><apply id="alg1.l0.m2.1.1.cmml" xref="alg1.l0.m2.1.1"><csymbol cd="ambiguous" id="alg1.l0.m2.1.1.1.cmml" xref="alg1.l0.m2.1.1">subscript</csymbol><ci id="alg1.l0.m2.1.1.2.cmml" xref="alg1.l0.m2.1.1.2">𝐼</ci><ci id="alg1.l0.m2.1.1.3.cmml" xref="alg1.l0.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m2.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m2.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>; differentiable renderer <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="alg1.l0.m3.1"><semantics id="alg1.l0.m3.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l0.m3.1.1" xref="alg1.l0.m3.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m3.1b"><ci id="alg1.l0.m3.1.1.cmml" xref="alg1.l0.m3.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m3.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m3.1d">caligraphic_R</annotation></semantics></math>; pretrained DINOv2 model <math alttext="\mathbf{\Phi}" class="ltx_Math" display="inline" id="alg1.l0.m4.1"><semantics id="alg1.l0.m4.1a"><mi id="alg1.l0.m4.1.1" xref="alg1.l0.m4.1.1.cmml">𝚽</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m4.1b"><ci id="alg1.l0.m4.1.1.cmml" xref="alg1.l0.m4.1.1">𝚽</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m4.1c">\mathbf{\Phi}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m4.1d">bold_Φ</annotation></semantics></math>, iteration quota <math alttext="N" class="ltx_Math" display="inline" id="alg1.l0.m5.1"><semantics id="alg1.l0.m5.1a"><mi id="alg1.l0.m5.1.1" xref="alg1.l0.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m5.1b"><ci id="alg1.l0.m5.1.1.cmml" xref="alg1.l0.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m5.1d">italic_N</annotation></semantics></math>, learning rate <math alttext="\alpha" class="ltx_Math" display="inline" id="alg1.l0.m6.1"><semantics id="alg1.l0.m6.1a"><mi id="alg1.l0.m6.1.1" xref="alg1.l0.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m6.1b"><ci id="alg1.l0.m6.1.1.cmml" xref="alg1.l0.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m6.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m6.1d">italic_α</annotation></semantics></math>, camera intrinsic <math alttext="K" class="ltx_Math" display="inline" id="alg1.l0.m7.1"><semantics id="alg1.l0.m7.1a"><mi id="alg1.l0.m7.1.1" xref="alg1.l0.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m7.1b"><ci id="alg1.l0.m7.1.1.cmml" xref="alg1.l0.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m7.1c">K</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m7.1d">italic_K</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span>  <math alttext="S_{q}\leftarrow\texttt{PCA}(\mathbf{\Phi}(I_{q}))" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mrow id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><msub id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml"><mi id="alg1.l1.m1.1.1.3.2" xref="alg1.l1.m1.1.1.3.2.cmml">S</mi><mi id="alg1.l1.m1.1.1.3.3" xref="alg1.l1.m1.1.1.3.3.cmml">q</mi></msub><mo id="alg1.l1.m1.1.1.2" stretchy="false" xref="alg1.l1.m1.1.1.2.cmml">←</mo><mrow id="alg1.l1.m1.1.1.1" xref="alg1.l1.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="alg1.l1.m1.1.1.1.3" xref="alg1.l1.m1.1.1.1.3a.cmml">PCA</mtext><mo id="alg1.l1.m1.1.1.1.2" xref="alg1.l1.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l1.m1.1.1.1.1.1" xref="alg1.l1.m1.1.1.1.1.1.1.cmml"><mo id="alg1.l1.m1.1.1.1.1.1.2" stretchy="false" xref="alg1.l1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l1.m1.1.1.1.1.1.1" xref="alg1.l1.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l1.m1.1.1.1.1.1.1.3" xref="alg1.l1.m1.1.1.1.1.1.1.3.cmml">𝚽</mi><mo id="alg1.l1.m1.1.1.1.1.1.1.2" xref="alg1.l1.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l1.m1.1.1.1.1.1.1.1.1" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="alg1.l1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l1.m1.1.1.1.1.1.1.1.1.1" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l1.m1.1.1.1.1.1.1.1.1.1.2" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="alg1.l1.m1.1.1.1.1.1.1.1.1.1.3" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.3.cmml">q</mi></msub><mo id="alg1.l1.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l1.m1.1.1.1.1.1.3" stretchy="false" xref="alg1.l1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">←</ci><apply id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.3.1.cmml" xref="alg1.l1.m1.1.1.3">subscript</csymbol><ci id="alg1.l1.m1.1.1.3.2.cmml" xref="alg1.l1.m1.1.1.3.2">𝑆</ci><ci id="alg1.l1.m1.1.1.3.3.cmml" xref="alg1.l1.m1.1.1.3.3">𝑞</ci></apply><apply id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1"><times id="alg1.l1.m1.1.1.1.2.cmml" xref="alg1.l1.m1.1.1.1.2"></times><ci id="alg1.l1.m1.1.1.1.3a.cmml" xref="alg1.l1.m1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="alg1.l1.m1.1.1.1.3.cmml" xref="alg1.l1.m1.1.1.1.3">PCA</mtext></ci><apply id="alg1.l1.m1.1.1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1.1"><times id="alg1.l1.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l1.m1.1.1.1.1.1.1.2"></times><ci id="alg1.l1.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l1.m1.1.1.1.1.1.1.3">𝚽</ci><apply id="alg1.l1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.2">𝐼</ci><ci id="alg1.l1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l1.m1.1.1.1.1.1.1.1.1.1.3">𝑞</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">S_{q}\leftarrow\texttt{PCA}(\mathbf{\Phi}(I_{q}))</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ← PCA ( bold_Φ ( italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) )</annotation></semantics></math>, <math alttext="S_{r}\leftarrow\texttt{PCA}(\mathbf{\Phi}(I_{r}))" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><mrow id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><msub id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3.cmml"><mi id="alg1.l1.m2.1.1.3.2" xref="alg1.l1.m2.1.1.3.2.cmml">S</mi><mi id="alg1.l1.m2.1.1.3.3" xref="alg1.l1.m2.1.1.3.3.cmml">r</mi></msub><mo id="alg1.l1.m2.1.1.2" stretchy="false" xref="alg1.l1.m2.1.1.2.cmml">←</mo><mrow id="alg1.l1.m2.1.1.1" xref="alg1.l1.m2.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="alg1.l1.m2.1.1.1.3" xref="alg1.l1.m2.1.1.1.3a.cmml">PCA</mtext><mo id="alg1.l1.m2.1.1.1.2" xref="alg1.l1.m2.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l1.m2.1.1.1.1.1" xref="alg1.l1.m2.1.1.1.1.1.1.cmml"><mo id="alg1.l1.m2.1.1.1.1.1.2" stretchy="false" xref="alg1.l1.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l1.m2.1.1.1.1.1.1" xref="alg1.l1.m2.1.1.1.1.1.1.cmml"><mi id="alg1.l1.m2.1.1.1.1.1.1.3" xref="alg1.l1.m2.1.1.1.1.1.1.3.cmml">𝚽</mi><mo id="alg1.l1.m2.1.1.1.1.1.1.2" xref="alg1.l1.m2.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l1.m2.1.1.1.1.1.1.1.1" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.cmml"><mo id="alg1.l1.m2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l1.m2.1.1.1.1.1.1.1.1.1" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l1.m2.1.1.1.1.1.1.1.1.1.2" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="alg1.l1.m2.1.1.1.1.1.1.1.1.1.3" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.3.cmml">r</mi></msub><mo id="alg1.l1.m2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l1.m2.1.1.1.1.1.3" stretchy="false" xref="alg1.l1.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><ci id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">←</ci><apply id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.3.1.cmml" xref="alg1.l1.m2.1.1.3">subscript</csymbol><ci id="alg1.l1.m2.1.1.3.2.cmml" xref="alg1.l1.m2.1.1.3.2">𝑆</ci><ci id="alg1.l1.m2.1.1.3.3.cmml" xref="alg1.l1.m2.1.1.3.3">𝑟</ci></apply><apply id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1.1"><times id="alg1.l1.m2.1.1.1.2.cmml" xref="alg1.l1.m2.1.1.1.2"></times><ci id="alg1.l1.m2.1.1.1.3a.cmml" xref="alg1.l1.m2.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="alg1.l1.m2.1.1.1.3.cmml" xref="alg1.l1.m2.1.1.1.3">PCA</mtext></ci><apply id="alg1.l1.m2.1.1.1.1.1.1.cmml" xref="alg1.l1.m2.1.1.1.1.1"><times id="alg1.l1.m2.1.1.1.1.1.1.2.cmml" xref="alg1.l1.m2.1.1.1.1.1.1.2"></times><ci id="alg1.l1.m2.1.1.1.1.1.1.3.cmml" xref="alg1.l1.m2.1.1.1.1.1.1.3">𝚽</ci><apply id="alg1.l1.m2.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l1.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l1.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l1.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.2">𝐼</ci><ci id="alg1.l1.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l1.m2.1.1.1.1.1.1.1.1.1.3">𝑟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">S_{r}\leftarrow\texttt{PCA}(\mathbf{\Phi}(I_{r}))</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ← PCA ( bold_Φ ( italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>  <math alttext="M_{r}\leftarrow\texttt{DelaunayTriangulations}(I_{r},D_{r})" class="ltx_Math" display="inline" id="alg1.l2.m1.2"><semantics id="alg1.l2.m1.2a"><mrow id="alg1.l2.m1.2.2" xref="alg1.l2.m1.2.2.cmml"><msub id="alg1.l2.m1.2.2.4" xref="alg1.l2.m1.2.2.4.cmml"><mi id="alg1.l2.m1.2.2.4.2" xref="alg1.l2.m1.2.2.4.2.cmml">M</mi><mi id="alg1.l2.m1.2.2.4.3" xref="alg1.l2.m1.2.2.4.3.cmml">r</mi></msub><mo id="alg1.l2.m1.2.2.3" stretchy="false" xref="alg1.l2.m1.2.2.3.cmml">←</mo><mrow id="alg1.l2.m1.2.2.2" xref="alg1.l2.m1.2.2.2.cmml"><mtext class="ltx_mathvariant_monospace" id="alg1.l2.m1.2.2.2.4" xref="alg1.l2.m1.2.2.2.4a.cmml">DelaunayTriangulations</mtext><mo id="alg1.l2.m1.2.2.2.3" xref="alg1.l2.m1.2.2.2.3.cmml">⁢</mo><mrow id="alg1.l2.m1.2.2.2.2.2" xref="alg1.l2.m1.2.2.2.2.3.cmml"><mo id="alg1.l2.m1.2.2.2.2.2.3" stretchy="false" xref="alg1.l2.m1.2.2.2.2.3.cmml">(</mo><msub id="alg1.l2.m1.1.1.1.1.1.1" xref="alg1.l2.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l2.m1.1.1.1.1.1.1.2" xref="alg1.l2.m1.1.1.1.1.1.1.2.cmml">I</mi><mi id="alg1.l2.m1.1.1.1.1.1.1.3" xref="alg1.l2.m1.1.1.1.1.1.1.3.cmml">r</mi></msub><mo id="alg1.l2.m1.2.2.2.2.2.4" xref="alg1.l2.m1.2.2.2.2.3.cmml">,</mo><msub id="alg1.l2.m1.2.2.2.2.2.2" xref="alg1.l2.m1.2.2.2.2.2.2.cmml"><mi id="alg1.l2.m1.2.2.2.2.2.2.2" xref="alg1.l2.m1.2.2.2.2.2.2.2.cmml">D</mi><mi id="alg1.l2.m1.2.2.2.2.2.2.3" xref="alg1.l2.m1.2.2.2.2.2.2.3.cmml">r</mi></msub><mo id="alg1.l2.m1.2.2.2.2.2.5" stretchy="false" xref="alg1.l2.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.2b"><apply id="alg1.l2.m1.2.2.cmml" xref="alg1.l2.m1.2.2"><ci id="alg1.l2.m1.2.2.3.cmml" xref="alg1.l2.m1.2.2.3">←</ci><apply id="alg1.l2.m1.2.2.4.cmml" xref="alg1.l2.m1.2.2.4"><csymbol cd="ambiguous" id="alg1.l2.m1.2.2.4.1.cmml" xref="alg1.l2.m1.2.2.4">subscript</csymbol><ci id="alg1.l2.m1.2.2.4.2.cmml" xref="alg1.l2.m1.2.2.4.2">𝑀</ci><ci id="alg1.l2.m1.2.2.4.3.cmml" xref="alg1.l2.m1.2.2.4.3">𝑟</ci></apply><apply id="alg1.l2.m1.2.2.2.cmml" xref="alg1.l2.m1.2.2.2"><times id="alg1.l2.m1.2.2.2.3.cmml" xref="alg1.l2.m1.2.2.2.3"></times><ci id="alg1.l2.m1.2.2.2.4a.cmml" xref="alg1.l2.m1.2.2.2.4"><mtext class="ltx_mathvariant_monospace" id="alg1.l2.m1.2.2.2.4.cmml" xref="alg1.l2.m1.2.2.2.4">DelaunayTriangulations</mtext></ci><interval closure="open" id="alg1.l2.m1.2.2.2.2.3.cmml" xref="alg1.l2.m1.2.2.2.2.2"><apply id="alg1.l2.m1.1.1.1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l2.m1.1.1.1.1.1.1.2">𝐼</ci><ci id="alg1.l2.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l2.m1.1.1.1.1.1.1.3">𝑟</ci></apply><apply id="alg1.l2.m1.2.2.2.2.2.2.cmml" xref="alg1.l2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l2.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l2.m1.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l2.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l2.m1.2.2.2.2.2.2.2">𝐷</ci><ci id="alg1.l2.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l2.m1.2.2.2.2.2.2.3">𝑟</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.2c">M_{r}\leftarrow\texttt{DelaunayTriangulations}(I_{r},D_{r})</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.2d">italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ← DelaunayTriangulations ( italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>  <math alttext="\mathcal{M}_{r}\leftarrow\texttt{TextMap}(M_{r},I_{r},S_{r})" class="ltx_Math" display="inline" id="alg1.l3.m1.3"><semantics id="alg1.l3.m1.3a"><mrow id="alg1.l3.m1.3.3" xref="alg1.l3.m1.3.3.cmml"><msub id="alg1.l3.m1.3.3.5" xref="alg1.l3.m1.3.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l3.m1.3.3.5.2" xref="alg1.l3.m1.3.3.5.2.cmml">ℳ</mi><mi id="alg1.l3.m1.3.3.5.3" xref="alg1.l3.m1.3.3.5.3.cmml">r</mi></msub><mo id="alg1.l3.m1.3.3.4" stretchy="false" xref="alg1.l3.m1.3.3.4.cmml">←</mo><mrow id="alg1.l3.m1.3.3.3" xref="alg1.l3.m1.3.3.3.cmml"><mtext class="ltx_mathvariant_monospace" id="alg1.l3.m1.3.3.3.5" xref="alg1.l3.m1.3.3.3.5a.cmml">TextMap</mtext><mo id="alg1.l3.m1.3.3.3.4" xref="alg1.l3.m1.3.3.3.4.cmml">⁢</mo><mrow id="alg1.l3.m1.3.3.3.3.3" xref="alg1.l3.m1.3.3.3.3.4.cmml"><mo id="alg1.l3.m1.3.3.3.3.3.4" stretchy="false" xref="alg1.l3.m1.3.3.3.3.4.cmml">(</mo><msub id="alg1.l3.m1.1.1.1.1.1.1" xref="alg1.l3.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l3.m1.1.1.1.1.1.1.2" xref="alg1.l3.m1.1.1.1.1.1.1.2.cmml">M</mi><mi id="alg1.l3.m1.1.1.1.1.1.1.3" xref="alg1.l3.m1.1.1.1.1.1.1.3.cmml">r</mi></msub><mo id="alg1.l3.m1.3.3.3.3.3.5" xref="alg1.l3.m1.3.3.3.3.4.cmml">,</mo><msub id="alg1.l3.m1.2.2.2.2.2.2" xref="alg1.l3.m1.2.2.2.2.2.2.cmml"><mi id="alg1.l3.m1.2.2.2.2.2.2.2" xref="alg1.l3.m1.2.2.2.2.2.2.2.cmml">I</mi><mi id="alg1.l3.m1.2.2.2.2.2.2.3" xref="alg1.l3.m1.2.2.2.2.2.2.3.cmml">r</mi></msub><mo id="alg1.l3.m1.3.3.3.3.3.6" xref="alg1.l3.m1.3.3.3.3.4.cmml">,</mo><msub id="alg1.l3.m1.3.3.3.3.3.3" xref="alg1.l3.m1.3.3.3.3.3.3.cmml"><mi id="alg1.l3.m1.3.3.3.3.3.3.2" xref="alg1.l3.m1.3.3.3.3.3.3.2.cmml">S</mi><mi id="alg1.l3.m1.3.3.3.3.3.3.3" xref="alg1.l3.m1.3.3.3.3.3.3.3.cmml">r</mi></msub><mo id="alg1.l3.m1.3.3.3.3.3.7" stretchy="false" xref="alg1.l3.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.3b"><apply id="alg1.l3.m1.3.3.cmml" xref="alg1.l3.m1.3.3"><ci id="alg1.l3.m1.3.3.4.cmml" xref="alg1.l3.m1.3.3.4">←</ci><apply id="alg1.l3.m1.3.3.5.cmml" xref="alg1.l3.m1.3.3.5"><csymbol cd="ambiguous" id="alg1.l3.m1.3.3.5.1.cmml" xref="alg1.l3.m1.3.3.5">subscript</csymbol><ci id="alg1.l3.m1.3.3.5.2.cmml" xref="alg1.l3.m1.3.3.5.2">ℳ</ci><ci id="alg1.l3.m1.3.3.5.3.cmml" xref="alg1.l3.m1.3.3.5.3">𝑟</ci></apply><apply id="alg1.l3.m1.3.3.3.cmml" xref="alg1.l3.m1.3.3.3"><times id="alg1.l3.m1.3.3.3.4.cmml" xref="alg1.l3.m1.3.3.3.4"></times><ci id="alg1.l3.m1.3.3.3.5a.cmml" xref="alg1.l3.m1.3.3.3.5"><mtext class="ltx_mathvariant_monospace" id="alg1.l3.m1.3.3.3.5.cmml" xref="alg1.l3.m1.3.3.3.5">TextMap</mtext></ci><vector id="alg1.l3.m1.3.3.3.3.4.cmml" xref="alg1.l3.m1.3.3.3.3.3"><apply id="alg1.l3.m1.1.1.1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l3.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l3.m1.1.1.1.1.1.1.2">𝑀</ci><ci id="alg1.l3.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l3.m1.1.1.1.1.1.1.3">𝑟</ci></apply><apply id="alg1.l3.m1.2.2.2.2.2.2.cmml" xref="alg1.l3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l3.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l3.m1.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l3.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l3.m1.2.2.2.2.2.2.2">𝐼</ci><ci id="alg1.l3.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l3.m1.2.2.2.2.2.2.3">𝑟</ci></apply><apply id="alg1.l3.m1.3.3.3.3.3.3.cmml" xref="alg1.l3.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="alg1.l3.m1.3.3.3.3.3.3.1.cmml" xref="alg1.l3.m1.3.3.3.3.3.3">subscript</csymbol><ci id="alg1.l3.m1.3.3.3.3.3.3.2.cmml" xref="alg1.l3.m1.3.3.3.3.3.3.2">𝑆</ci><ci id="alg1.l3.m1.3.3.3.3.3.3.3.cmml" xref="alg1.l3.m1.3.3.3.3.3.3.3">𝑟</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.3c">\mathcal{M}_{r}\leftarrow\texttt{TextMap}(M_{r},I_{r},S_{r})</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.3d">caligraphic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ← TextMap ( italic_M start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT )</annotation></semantics></math>
<math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l3.m2.1"><semantics id="alg1.l3.m2.1a"><mo id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.1d">▷</annotation></semantics></math> <span class="ltx_text" id="alg1.l3.2" style="color:#008080;">Sampling Poses for Initialization</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span>  <math alttext="\left\{P^{\text{1}},P^{\text{2}},...,P^{n}\right\}\leftarrow\texttt{Uniformly%
\_sampling()}" class="ltx_Math" display="inline" id="alg1.l4.m1.4"><semantics id="alg1.l4.m1.4a"><mrow id="alg1.l4.m1.4.4" xref="alg1.l4.m1.4.4.cmml"><mrow id="alg1.l4.m1.4.4.3.3" xref="alg1.l4.m1.4.4.3.4.cmml"><mo id="alg1.l4.m1.4.4.3.3.4" xref="alg1.l4.m1.4.4.3.4.cmml">{</mo><msup id="alg1.l4.m1.2.2.1.1.1" xref="alg1.l4.m1.2.2.1.1.1.cmml"><mi id="alg1.l4.m1.2.2.1.1.1.2" xref="alg1.l4.m1.2.2.1.1.1.2.cmml">P</mi><mtext id="alg1.l4.m1.2.2.1.1.1.3" xref="alg1.l4.m1.2.2.1.1.1.3a.cmml">1</mtext></msup><mo id="alg1.l4.m1.4.4.3.3.5" xref="alg1.l4.m1.4.4.3.4.cmml">,</mo><msup id="alg1.l4.m1.3.3.2.2.2" xref="alg1.l4.m1.3.3.2.2.2.cmml"><mi id="alg1.l4.m1.3.3.2.2.2.2" xref="alg1.l4.m1.3.3.2.2.2.2.cmml">P</mi><mtext id="alg1.l4.m1.3.3.2.2.2.3" xref="alg1.l4.m1.3.3.2.2.2.3a.cmml">2</mtext></msup><mo id="alg1.l4.m1.4.4.3.3.6" xref="alg1.l4.m1.4.4.3.4.cmml">,</mo><mi id="alg1.l4.m1.1.1" mathvariant="normal" xref="alg1.l4.m1.1.1.cmml">…</mi><mo id="alg1.l4.m1.4.4.3.3.7" xref="alg1.l4.m1.4.4.3.4.cmml">,</mo><msup id="alg1.l4.m1.4.4.3.3.3" xref="alg1.l4.m1.4.4.3.3.3.cmml"><mi id="alg1.l4.m1.4.4.3.3.3.2" xref="alg1.l4.m1.4.4.3.3.3.2.cmml">P</mi><mi id="alg1.l4.m1.4.4.3.3.3.3" xref="alg1.l4.m1.4.4.3.3.3.3.cmml">n</mi></msup><mo id="alg1.l4.m1.4.4.3.3.8" xref="alg1.l4.m1.4.4.3.4.cmml">}</mo></mrow><mo id="alg1.l4.m1.4.4.4" stretchy="false" xref="alg1.l4.m1.4.4.4.cmml">←</mo><mtext class="ltx_mathvariant_monospace" id="alg1.l4.m1.4.4.5" xref="alg1.l4.m1.4.4.5a.cmml">Uniformly_sampling()</mtext></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.4b"><apply id="alg1.l4.m1.4.4.cmml" xref="alg1.l4.m1.4.4"><ci id="alg1.l4.m1.4.4.4.cmml" xref="alg1.l4.m1.4.4.4">←</ci><set id="alg1.l4.m1.4.4.3.4.cmml" xref="alg1.l4.m1.4.4.3.3"><apply id="alg1.l4.m1.2.2.1.1.1.cmml" xref="alg1.l4.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l4.m1.2.2.1.1.1.1.cmml" xref="alg1.l4.m1.2.2.1.1.1">superscript</csymbol><ci id="alg1.l4.m1.2.2.1.1.1.2.cmml" xref="alg1.l4.m1.2.2.1.1.1.2">𝑃</ci><ci id="alg1.l4.m1.2.2.1.1.1.3a.cmml" xref="alg1.l4.m1.2.2.1.1.1.3"><mtext id="alg1.l4.m1.2.2.1.1.1.3.cmml" mathsize="70%" xref="alg1.l4.m1.2.2.1.1.1.3">1</mtext></ci></apply><apply id="alg1.l4.m1.3.3.2.2.2.cmml" xref="alg1.l4.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l4.m1.3.3.2.2.2.1.cmml" xref="alg1.l4.m1.3.3.2.2.2">superscript</csymbol><ci id="alg1.l4.m1.3.3.2.2.2.2.cmml" xref="alg1.l4.m1.3.3.2.2.2.2">𝑃</ci><ci id="alg1.l4.m1.3.3.2.2.2.3a.cmml" xref="alg1.l4.m1.3.3.2.2.2.3"><mtext id="alg1.l4.m1.3.3.2.2.2.3.cmml" mathsize="70%" xref="alg1.l4.m1.3.3.2.2.2.3">2</mtext></ci></apply><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">…</ci><apply id="alg1.l4.m1.4.4.3.3.3.cmml" xref="alg1.l4.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="alg1.l4.m1.4.4.3.3.3.1.cmml" xref="alg1.l4.m1.4.4.3.3.3">superscript</csymbol><ci id="alg1.l4.m1.4.4.3.3.3.2.cmml" xref="alg1.l4.m1.4.4.3.3.3.2">𝑃</ci><ci id="alg1.l4.m1.4.4.3.3.3.3.cmml" xref="alg1.l4.m1.4.4.3.3.3.3">𝑛</ci></apply></set><ci id="alg1.l4.m1.4.4.5a.cmml" xref="alg1.l4.m1.4.4.5"><mtext class="ltx_mathvariant_monospace" id="alg1.l4.m1.4.4.5.cmml" xref="alg1.l4.m1.4.4.5">Uniformly_sampling()</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.4c">\left\{P^{\text{1}},P^{\text{2}},...,P^{n}\right\}\leftarrow\texttt{Uniformly%
\_sampling()}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.4d">{ italic_P start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_P start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , italic_P start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT } ← Uniformly_sampling()</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>  <math alttext="\mathbf{P}=\left\{P^{\text{1}},P^{\text{2}},...,P^{n}\right\}" class="ltx_Math" display="inline" id="alg1.l5.m1.4"><semantics id="alg1.l5.m1.4a"><mrow id="alg1.l5.m1.4.4" xref="alg1.l5.m1.4.4.cmml"><mi id="alg1.l5.m1.4.4.5" xref="alg1.l5.m1.4.4.5.cmml">𝐏</mi><mo id="alg1.l5.m1.4.4.4" xref="alg1.l5.m1.4.4.4.cmml">=</mo><mrow id="alg1.l5.m1.4.4.3.3" xref="alg1.l5.m1.4.4.3.4.cmml"><mo id="alg1.l5.m1.4.4.3.3.4" xref="alg1.l5.m1.4.4.3.4.cmml">{</mo><msup id="alg1.l5.m1.2.2.1.1.1" xref="alg1.l5.m1.2.2.1.1.1.cmml"><mi id="alg1.l5.m1.2.2.1.1.1.2" xref="alg1.l5.m1.2.2.1.1.1.2.cmml">P</mi><mtext id="alg1.l5.m1.2.2.1.1.1.3" xref="alg1.l5.m1.2.2.1.1.1.3a.cmml">1</mtext></msup><mo id="alg1.l5.m1.4.4.3.3.5" xref="alg1.l5.m1.4.4.3.4.cmml">,</mo><msup id="alg1.l5.m1.3.3.2.2.2" xref="alg1.l5.m1.3.3.2.2.2.cmml"><mi id="alg1.l5.m1.3.3.2.2.2.2" xref="alg1.l5.m1.3.3.2.2.2.2.cmml">P</mi><mtext id="alg1.l5.m1.3.3.2.2.2.3" xref="alg1.l5.m1.3.3.2.2.2.3a.cmml">2</mtext></msup><mo id="alg1.l5.m1.4.4.3.3.6" xref="alg1.l5.m1.4.4.3.4.cmml">,</mo><mi id="alg1.l5.m1.1.1" mathvariant="normal" xref="alg1.l5.m1.1.1.cmml">…</mi><mo id="alg1.l5.m1.4.4.3.3.7" xref="alg1.l5.m1.4.4.3.4.cmml">,</mo><msup id="alg1.l5.m1.4.4.3.3.3" xref="alg1.l5.m1.4.4.3.3.3.cmml"><mi id="alg1.l5.m1.4.4.3.3.3.2" xref="alg1.l5.m1.4.4.3.3.3.2.cmml">P</mi><mi id="alg1.l5.m1.4.4.3.3.3.3" xref="alg1.l5.m1.4.4.3.3.3.3.cmml">n</mi></msup><mo id="alg1.l5.m1.4.4.3.3.8" xref="alg1.l5.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.4b"><apply id="alg1.l5.m1.4.4.cmml" xref="alg1.l5.m1.4.4"><eq id="alg1.l5.m1.4.4.4.cmml" xref="alg1.l5.m1.4.4.4"></eq><ci id="alg1.l5.m1.4.4.5.cmml" xref="alg1.l5.m1.4.4.5">𝐏</ci><set id="alg1.l5.m1.4.4.3.4.cmml" xref="alg1.l5.m1.4.4.3.3"><apply id="alg1.l5.m1.2.2.1.1.1.cmml" xref="alg1.l5.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.2.2.1.1.1.1.cmml" xref="alg1.l5.m1.2.2.1.1.1">superscript</csymbol><ci id="alg1.l5.m1.2.2.1.1.1.2.cmml" xref="alg1.l5.m1.2.2.1.1.1.2">𝑃</ci><ci id="alg1.l5.m1.2.2.1.1.1.3a.cmml" xref="alg1.l5.m1.2.2.1.1.1.3"><mtext id="alg1.l5.m1.2.2.1.1.1.3.cmml" mathsize="70%" xref="alg1.l5.m1.2.2.1.1.1.3">1</mtext></ci></apply><apply id="alg1.l5.m1.3.3.2.2.2.cmml" xref="alg1.l5.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l5.m1.3.3.2.2.2.1.cmml" xref="alg1.l5.m1.3.3.2.2.2">superscript</csymbol><ci id="alg1.l5.m1.3.3.2.2.2.2.cmml" xref="alg1.l5.m1.3.3.2.2.2.2">𝑃</ci><ci id="alg1.l5.m1.3.3.2.2.2.3a.cmml" xref="alg1.l5.m1.3.3.2.2.2.3"><mtext id="alg1.l5.m1.3.3.2.2.2.3.cmml" mathsize="70%" xref="alg1.l5.m1.3.3.2.2.2.3">2</mtext></ci></apply><ci id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1">…</ci><apply id="alg1.l5.m1.4.4.3.3.3.cmml" xref="alg1.l5.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="alg1.l5.m1.4.4.3.3.3.1.cmml" xref="alg1.l5.m1.4.4.3.3.3">superscript</csymbol><ci id="alg1.l5.m1.4.4.3.3.3.2.cmml" xref="alg1.l5.m1.4.4.3.3.3.2">𝑃</ci><ci id="alg1.l5.m1.4.4.3.3.3.3.cmml" xref="alg1.l5.m1.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.4c">\mathbf{P}=\left\{P^{\text{1}},P^{\text{2}},...,P^{n}\right\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.4d">bold_P = { italic_P start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_P start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , italic_P start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>  <math alttext="I_{r}(\mathbf{P}),S_{r}(\mathbf{P})\leftarrow\mathcal{R}(\mathbf{P},\mathcal{M%
_{\text{r}}},K)" class="ltx_Math" display="inline" id="alg1.l6.m1.7"><semantics id="alg1.l6.m1.7a"><mrow id="alg1.l6.m1.7.7" xref="alg1.l6.m1.7.7.cmml"><mrow id="alg1.l6.m1.6.6.2.2" xref="alg1.l6.m1.6.6.2.3.cmml"><mrow id="alg1.l6.m1.5.5.1.1.1" xref="alg1.l6.m1.5.5.1.1.1.cmml"><msub id="alg1.l6.m1.5.5.1.1.1.2" xref="alg1.l6.m1.5.5.1.1.1.2.cmml"><mi id="alg1.l6.m1.5.5.1.1.1.2.2" xref="alg1.l6.m1.5.5.1.1.1.2.2.cmml">I</mi><mi id="alg1.l6.m1.5.5.1.1.1.2.3" xref="alg1.l6.m1.5.5.1.1.1.2.3.cmml">r</mi></msub><mo id="alg1.l6.m1.5.5.1.1.1.1" xref="alg1.l6.m1.5.5.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l6.m1.5.5.1.1.1.3.2" xref="alg1.l6.m1.5.5.1.1.1.cmml"><mo id="alg1.l6.m1.5.5.1.1.1.3.2.1" stretchy="false" xref="alg1.l6.m1.5.5.1.1.1.cmml">(</mo><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">𝐏</mi><mo id="alg1.l6.m1.5.5.1.1.1.3.2.2" stretchy="false" xref="alg1.l6.m1.5.5.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l6.m1.6.6.2.2.3" xref="alg1.l6.m1.6.6.2.3.cmml">,</mo><mrow id="alg1.l6.m1.6.6.2.2.2" xref="alg1.l6.m1.6.6.2.2.2.cmml"><msub id="alg1.l6.m1.6.6.2.2.2.2" xref="alg1.l6.m1.6.6.2.2.2.2.cmml"><mi id="alg1.l6.m1.6.6.2.2.2.2.2" xref="alg1.l6.m1.6.6.2.2.2.2.2.cmml">S</mi><mi id="alg1.l6.m1.6.6.2.2.2.2.3" xref="alg1.l6.m1.6.6.2.2.2.2.3.cmml">r</mi></msub><mo id="alg1.l6.m1.6.6.2.2.2.1" xref="alg1.l6.m1.6.6.2.2.2.1.cmml">⁢</mo><mrow id="alg1.l6.m1.6.6.2.2.2.3.2" xref="alg1.l6.m1.6.6.2.2.2.cmml"><mo id="alg1.l6.m1.6.6.2.2.2.3.2.1" stretchy="false" xref="alg1.l6.m1.6.6.2.2.2.cmml">(</mo><mi id="alg1.l6.m1.2.2" xref="alg1.l6.m1.2.2.cmml">𝐏</mi><mo id="alg1.l6.m1.6.6.2.2.2.3.2.2" stretchy="false" xref="alg1.l6.m1.6.6.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="alg1.l6.m1.7.7.4" stretchy="false" xref="alg1.l6.m1.7.7.4.cmml">←</mo><mrow id="alg1.l6.m1.7.7.3" xref="alg1.l6.m1.7.7.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m1.7.7.3.3" xref="alg1.l6.m1.7.7.3.3.cmml">ℛ</mi><mo id="alg1.l6.m1.7.7.3.2" xref="alg1.l6.m1.7.7.3.2.cmml">⁢</mo><mrow id="alg1.l6.m1.7.7.3.1.1" xref="alg1.l6.m1.7.7.3.1.2.cmml"><mo id="alg1.l6.m1.7.7.3.1.1.2" stretchy="false" xref="alg1.l6.m1.7.7.3.1.2.cmml">(</mo><mi id="alg1.l6.m1.3.3" xref="alg1.l6.m1.3.3.cmml">𝐏</mi><mo id="alg1.l6.m1.7.7.3.1.1.3" xref="alg1.l6.m1.7.7.3.1.2.cmml">,</mo><msub id="alg1.l6.m1.7.7.3.1.1.1" xref="alg1.l6.m1.7.7.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m1.7.7.3.1.1.1.2" xref="alg1.l6.m1.7.7.3.1.1.1.2.cmml">ℳ</mi><mtext id="alg1.l6.m1.7.7.3.1.1.1.3" xref="alg1.l6.m1.7.7.3.1.1.1.3a.cmml">r</mtext></msub><mo id="alg1.l6.m1.7.7.3.1.1.4" xref="alg1.l6.m1.7.7.3.1.2.cmml">,</mo><mi id="alg1.l6.m1.4.4" xref="alg1.l6.m1.4.4.cmml">K</mi><mo id="alg1.l6.m1.7.7.3.1.1.5" stretchy="false" xref="alg1.l6.m1.7.7.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.7b"><apply id="alg1.l6.m1.7.7.cmml" xref="alg1.l6.m1.7.7"><ci id="alg1.l6.m1.7.7.4.cmml" xref="alg1.l6.m1.7.7.4">←</ci><list id="alg1.l6.m1.6.6.2.3.cmml" xref="alg1.l6.m1.6.6.2.2"><apply id="alg1.l6.m1.5.5.1.1.1.cmml" xref="alg1.l6.m1.5.5.1.1.1"><times id="alg1.l6.m1.5.5.1.1.1.1.cmml" xref="alg1.l6.m1.5.5.1.1.1.1"></times><apply id="alg1.l6.m1.5.5.1.1.1.2.cmml" xref="alg1.l6.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l6.m1.5.5.1.1.1.2.1.cmml" xref="alg1.l6.m1.5.5.1.1.1.2">subscript</csymbol><ci id="alg1.l6.m1.5.5.1.1.1.2.2.cmml" xref="alg1.l6.m1.5.5.1.1.1.2.2">𝐼</ci><ci id="alg1.l6.m1.5.5.1.1.1.2.3.cmml" xref="alg1.l6.m1.5.5.1.1.1.2.3">𝑟</ci></apply><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">𝐏</ci></apply><apply id="alg1.l6.m1.6.6.2.2.2.cmml" xref="alg1.l6.m1.6.6.2.2.2"><times id="alg1.l6.m1.6.6.2.2.2.1.cmml" xref="alg1.l6.m1.6.6.2.2.2.1"></times><apply id="alg1.l6.m1.6.6.2.2.2.2.cmml" xref="alg1.l6.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l6.m1.6.6.2.2.2.2.1.cmml" xref="alg1.l6.m1.6.6.2.2.2.2">subscript</csymbol><ci id="alg1.l6.m1.6.6.2.2.2.2.2.cmml" xref="alg1.l6.m1.6.6.2.2.2.2.2">𝑆</ci><ci id="alg1.l6.m1.6.6.2.2.2.2.3.cmml" xref="alg1.l6.m1.6.6.2.2.2.2.3">𝑟</ci></apply><ci id="alg1.l6.m1.2.2.cmml" xref="alg1.l6.m1.2.2">𝐏</ci></apply></list><apply id="alg1.l6.m1.7.7.3.cmml" xref="alg1.l6.m1.7.7.3"><times id="alg1.l6.m1.7.7.3.2.cmml" xref="alg1.l6.m1.7.7.3.2"></times><ci id="alg1.l6.m1.7.7.3.3.cmml" xref="alg1.l6.m1.7.7.3.3">ℛ</ci><vector id="alg1.l6.m1.7.7.3.1.2.cmml" xref="alg1.l6.m1.7.7.3.1.1"><ci id="alg1.l6.m1.3.3.cmml" xref="alg1.l6.m1.3.3">𝐏</ci><apply id="alg1.l6.m1.7.7.3.1.1.1.cmml" xref="alg1.l6.m1.7.7.3.1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.7.7.3.1.1.1.1.cmml" xref="alg1.l6.m1.7.7.3.1.1.1">subscript</csymbol><ci id="alg1.l6.m1.7.7.3.1.1.1.2.cmml" xref="alg1.l6.m1.7.7.3.1.1.1.2">ℳ</ci><ci id="alg1.l6.m1.7.7.3.1.1.1.3a.cmml" xref="alg1.l6.m1.7.7.3.1.1.1.3"><mtext id="alg1.l6.m1.7.7.3.1.1.1.3.cmml" mathsize="70%" xref="alg1.l6.m1.7.7.3.1.1.1.3">r</mtext></ci></apply><ci id="alg1.l6.m1.4.4.cmml" xref="alg1.l6.m1.4.4">𝐾</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.7c">I_{r}(\mathbf{P}),S_{r}(\mathbf{P})\leftarrow\mathcal{R}(\mathbf{P},\mathcal{M%
_{\text{r}}},K)</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.7d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_P ) , italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_P ) ← caligraphic_R ( bold_P , caligraphic_M start_POSTSUBSCRIPT r end_POSTSUBSCRIPT , italic_K )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.2.1.1" style="font-size:80%;">7:</span></span>  
<div class="ltx_inline-block ltx_transformed_outer" id="alg1.l7.1" style="width:175.7pt;height:10.2pt;vertical-align:-2.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-9.8pt,0.4pt) scale(0.9,0.9) ;">
<p class="ltx_p" id="alg1.l7.1.1"><math alttext="P^{\text{init}}=\mathop{\arg\min}_{P^{i}\in\mathbf{P}}{L_{1}\left\{I_{r}(P^{i}%
);I_{q}\right\}+L_{2}\left\{S_{r}(P^{i});S_{q}\right\}}" class="ltx_Math" display="inline" id="alg1.l7.1.1.m1.4"><semantics id="alg1.l7.1.1.m1.4a"><mrow id="alg1.l7.1.1.m1.4.4" xref="alg1.l7.1.1.m1.4.4.cmml"><msup id="alg1.l7.1.1.m1.4.4.6" xref="alg1.l7.1.1.m1.4.4.6.cmml"><mi id="alg1.l7.1.1.m1.4.4.6.2" xref="alg1.l7.1.1.m1.4.4.6.2.cmml">P</mi><mtext id="alg1.l7.1.1.m1.4.4.6.3" xref="alg1.l7.1.1.m1.4.4.6.3a.cmml">init</mtext></msup><mo id="alg1.l7.1.1.m1.4.4.5" xref="alg1.l7.1.1.m1.4.4.5.cmml">=</mo><mrow id="alg1.l7.1.1.m1.4.4.4" xref="alg1.l7.1.1.m1.4.4.4.cmml"><mrow id="alg1.l7.1.1.m1.2.2.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.cmml"><msub id="alg1.l7.1.1.m1.2.2.2.2.3" xref="alg1.l7.1.1.m1.2.2.2.2.3.cmml"><mrow id="alg1.l7.1.1.m1.2.2.2.2.3.2" xref="alg1.l7.1.1.m1.2.2.2.2.3.2.cmml"><mi id="alg1.l7.1.1.m1.2.2.2.2.3.2.1" xref="alg1.l7.1.1.m1.2.2.2.2.3.2.1.cmml">arg</mi><mo id="alg1.l7.1.1.m1.2.2.2.2.3.2a" lspace="0.167em" xref="alg1.l7.1.1.m1.2.2.2.2.3.2.cmml">⁡</mo><mi id="alg1.l7.1.1.m1.2.2.2.2.3.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.3.2.2.cmml">min</mi></mrow><mrow id="alg1.l7.1.1.m1.2.2.2.2.3.3" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.cmml"><msup id="alg1.l7.1.1.m1.2.2.2.2.3.3.2" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2.cmml"><mi id="alg1.l7.1.1.m1.2.2.2.2.3.3.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2.2.cmml">P</mi><mi id="alg1.l7.1.1.m1.2.2.2.2.3.3.2.3" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2.3.cmml">i</mi></msup><mo id="alg1.l7.1.1.m1.2.2.2.2.3.3.1" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.1.cmml">∈</mo><mi id="alg1.l7.1.1.m1.2.2.2.2.3.3.3" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.3.cmml">𝐏</mi></mrow></msub><mrow id="alg1.l7.1.1.m1.2.2.2.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.2.cmml"><msub id="alg1.l7.1.1.m1.2.2.2.2.2.4" xref="alg1.l7.1.1.m1.2.2.2.2.2.4.cmml"><mi id="alg1.l7.1.1.m1.2.2.2.2.2.4.2" xref="alg1.l7.1.1.m1.2.2.2.2.2.4.2.cmml">L</mi><mn id="alg1.l7.1.1.m1.2.2.2.2.2.4.3" xref="alg1.l7.1.1.m1.2.2.2.2.2.4.3.cmml">1</mn></msub><mo id="alg1.l7.1.1.m1.2.2.2.2.2.3" xref="alg1.l7.1.1.m1.2.2.2.2.2.3.cmml">⁢</mo><mrow id="alg1.l7.1.1.m1.2.2.2.2.2.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.3.cmml"><mo id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.3" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.3.cmml">{</mo><mrow id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.2" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml">I</mi><mi id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.3" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi></msub><mo id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.2" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">P</mi><mi id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msup><mo id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.4" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.3.cmml">;</mo><msub id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.2" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.2.cmml">I</mi><mi id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.3" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.3.cmml">q</mi></msub><mo id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.5" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.3.cmml">}</mo></mrow></mrow></mrow><mo id="alg1.l7.1.1.m1.4.4.4.5" xref="alg1.l7.1.1.m1.4.4.4.5.cmml">+</mo><mrow id="alg1.l7.1.1.m1.4.4.4.4" xref="alg1.l7.1.1.m1.4.4.4.4.cmml"><msub id="alg1.l7.1.1.m1.4.4.4.4.4" xref="alg1.l7.1.1.m1.4.4.4.4.4.cmml"><mi id="alg1.l7.1.1.m1.4.4.4.4.4.2" xref="alg1.l7.1.1.m1.4.4.4.4.4.2.cmml">L</mi><mn id="alg1.l7.1.1.m1.4.4.4.4.4.3" xref="alg1.l7.1.1.m1.4.4.4.4.4.3.cmml">2</mn></msub><mo id="alg1.l7.1.1.m1.4.4.4.4.3" xref="alg1.l7.1.1.m1.4.4.4.4.3.cmml">⁢</mo><mrow id="alg1.l7.1.1.m1.4.4.4.4.2.2" xref="alg1.l7.1.1.m1.4.4.4.4.2.3.cmml"><mo id="alg1.l7.1.1.m1.4.4.4.4.2.2.3" xref="alg1.l7.1.1.m1.4.4.4.4.2.3.cmml">{</mo><mrow id="alg1.l7.1.1.m1.3.3.3.3.1.1.1" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.cmml"><msub id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.cmml"><mi id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.2" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.2.cmml">S</mi><mi id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.3" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.3.cmml">r</mi></msub><mo id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.2" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.2.cmml">⁢</mo><mrow id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mo id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.2" stretchy="false" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.cmml">(</mo><msup id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mi id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.2" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.2.cmml">P</mi><mi id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.3" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.3.cmml">i</mi></msup><mo id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.3" stretchy="false" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l7.1.1.m1.4.4.4.4.2.2.4" xref="alg1.l7.1.1.m1.4.4.4.4.2.3.cmml">;</mo><msub id="alg1.l7.1.1.m1.4.4.4.4.2.2.2" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2.cmml"><mi id="alg1.l7.1.1.m1.4.4.4.4.2.2.2.2" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2.2.cmml">S</mi><mi id="alg1.l7.1.1.m1.4.4.4.4.2.2.2.3" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2.3.cmml">q</mi></msub><mo id="alg1.l7.1.1.m1.4.4.4.4.2.2.5" xref="alg1.l7.1.1.m1.4.4.4.4.2.3.cmml">}</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.1.1.m1.4b"><apply id="alg1.l7.1.1.m1.4.4.cmml" xref="alg1.l7.1.1.m1.4.4"><eq id="alg1.l7.1.1.m1.4.4.5.cmml" xref="alg1.l7.1.1.m1.4.4.5"></eq><apply id="alg1.l7.1.1.m1.4.4.6.cmml" xref="alg1.l7.1.1.m1.4.4.6"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.4.4.6.1.cmml" xref="alg1.l7.1.1.m1.4.4.6">superscript</csymbol><ci id="alg1.l7.1.1.m1.4.4.6.2.cmml" xref="alg1.l7.1.1.m1.4.4.6.2">𝑃</ci><ci id="alg1.l7.1.1.m1.4.4.6.3a.cmml" xref="alg1.l7.1.1.m1.4.4.6.3"><mtext id="alg1.l7.1.1.m1.4.4.6.3.cmml" mathsize="70%" xref="alg1.l7.1.1.m1.4.4.6.3">init</mtext></ci></apply><apply id="alg1.l7.1.1.m1.4.4.4.cmml" xref="alg1.l7.1.1.m1.4.4.4"><plus id="alg1.l7.1.1.m1.4.4.4.5.cmml" xref="alg1.l7.1.1.m1.4.4.4.5"></plus><apply id="alg1.l7.1.1.m1.2.2.2.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2"><apply id="alg1.l7.1.1.m1.2.2.2.2.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.2.2.2.2.3.1.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3">subscript</csymbol><apply id="alg1.l7.1.1.m1.2.2.2.2.3.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.2"><arg id="alg1.l7.1.1.m1.2.2.2.2.3.2.1.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.2.1"></arg><min id="alg1.l7.1.1.m1.2.2.2.2.3.2.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.2.2"></min></apply><apply id="alg1.l7.1.1.m1.2.2.2.2.3.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3"><in id="alg1.l7.1.1.m1.2.2.2.2.3.3.1.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.1"></in><apply id="alg1.l7.1.1.m1.2.2.2.2.3.3.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.2.2.2.2.3.3.2.1.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2">superscript</csymbol><ci id="alg1.l7.1.1.m1.2.2.2.2.3.3.2.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2.2">𝑃</ci><ci id="alg1.l7.1.1.m1.2.2.2.2.3.3.2.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.2.3">𝑖</ci></apply><ci id="alg1.l7.1.1.m1.2.2.2.2.3.3.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.3.3.3">𝐏</ci></apply></apply><apply id="alg1.l7.1.1.m1.2.2.2.2.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2"><times id="alg1.l7.1.1.m1.2.2.2.2.2.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.3"></times><apply id="alg1.l7.1.1.m1.2.2.2.2.2.4.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.4"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.2.2.2.2.2.4.1.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.4">subscript</csymbol><ci id="alg1.l7.1.1.m1.2.2.2.2.2.4.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.4.2">𝐿</ci><cn id="alg1.l7.1.1.m1.2.2.2.2.2.4.3.cmml" type="integer" xref="alg1.l7.1.1.m1.2.2.2.2.2.4.3">1</cn></apply><list id="alg1.l7.1.1.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2"><apply id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1"><times id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.2"></times><apply id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.2">𝐼</ci><ci id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.3.3">𝑟</ci></apply><apply id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2">𝑃</ci><ci id="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l7.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.2">𝐼</ci><ci id="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="alg1.l7.1.1.m1.2.2.2.2.2.2.2.2.3">𝑞</ci></apply></list></apply></apply><apply id="alg1.l7.1.1.m1.4.4.4.4.cmml" xref="alg1.l7.1.1.m1.4.4.4.4"><times id="alg1.l7.1.1.m1.4.4.4.4.3.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.3"></times><apply id="alg1.l7.1.1.m1.4.4.4.4.4.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.4"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.4.4.4.4.4.1.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.4">subscript</csymbol><ci id="alg1.l7.1.1.m1.4.4.4.4.4.2.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.4.2">𝐿</ci><cn id="alg1.l7.1.1.m1.4.4.4.4.4.3.cmml" type="integer" xref="alg1.l7.1.1.m1.4.4.4.4.4.3">2</cn></apply><list id="alg1.l7.1.1.m1.4.4.4.4.2.3.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.2.2"><apply id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1"><times id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.2.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.2"></times><apply id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.1.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3">subscript</csymbol><ci id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.2.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.2">𝑆</ci><ci id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.3.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.3.3">𝑟</ci></apply><apply id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1">superscript</csymbol><ci id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.2.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.2">𝑃</ci><ci id="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.3.cmml" xref="alg1.l7.1.1.m1.3.3.3.3.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg1.l7.1.1.m1.4.4.4.4.2.2.2.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.1.1.m1.4.4.4.4.2.2.2.1.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2">subscript</csymbol><ci id="alg1.l7.1.1.m1.4.4.4.4.2.2.2.2.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2.2">𝑆</ci><ci id="alg1.l7.1.1.m1.4.4.4.4.2.2.2.3.cmml" xref="alg1.l7.1.1.m1.4.4.4.4.2.2.2.3">𝑞</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.1.1.m1.4c">P^{\text{init}}=\mathop{\arg\min}_{P^{i}\in\mathbf{P}}{L_{1}\left\{I_{r}(P^{i}%
);I_{q}\right\}+L_{2}\left\{S_{r}(P^{i});S_{q}\right\}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.1.1.m1.4d">italic_P start_POSTSUPERSCRIPT init end_POSTSUPERSCRIPT = start_BIGOP roman_arg roman_min end_BIGOP start_POSTSUBSCRIPT italic_P start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ∈ bold_P end_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT { italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) ; italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT } + italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT { italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) ; italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT }</annotation></semantics></math></p>
</span></div>
<math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><mo id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">▷</annotation></semantics></math> <span class="ltx_text" id="alg1.l7.3" style="color:#008080;">Label/Training-Free Refinement via Diff. Renderer</span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>  <math alttext="P\leftarrow P^{\text{init}}" class="ltx_Math" display="inline" id="alg1.l8.m1.1"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><mi id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml">P</mi><mo id="alg1.l8.m1.1.1.1" stretchy="false" xref="alg1.l8.m1.1.1.1.cmml">←</mo><msup id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"><mi id="alg1.l8.m1.1.1.3.2" xref="alg1.l8.m1.1.1.3.2.cmml">P</mi><mtext id="alg1.l8.m1.1.1.3.3" xref="alg1.l8.m1.1.1.3.3a.cmml">init</mtext></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><ci id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1">←</ci><ci id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2">𝑃</ci><apply id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.1.cmml" xref="alg1.l8.m1.1.1.3">superscript</csymbol><ci id="alg1.l8.m1.1.1.3.2.cmml" xref="alg1.l8.m1.1.1.3.2">𝑃</ci><ci id="alg1.l8.m1.1.1.3.3a.cmml" xref="alg1.l8.m1.1.1.3.3"><mtext id="alg1.l8.m1.1.1.3.3.cmml" mathsize="70%" xref="alg1.l8.m1.1.1.3.3">init</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">P\leftarrow P^{\text{init}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.1d">italic_P ← italic_P start_POSTSUPERSCRIPT init end_POSTSUPERSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l9.2">for</span> <math alttext="i&lt;N" class="ltx_Math" display="inline" id="alg1.l9.m1.1"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><mi id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml">i</mi><mo id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">&lt;</mo><mi id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><lt id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1"></lt><ci id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2">𝑖</ci><ci id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">i&lt;N</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.1d">italic_i &lt; italic_N</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l9.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>     <math alttext="I_{r}(P),S_{r}(P)\leftarrow\mathcal{R}(P,\mathcal{M_{\text{r}}},K)" class="ltx_Math" display="inline" id="alg1.l10.m1.7"><semantics id="alg1.l10.m1.7a"><mrow id="alg1.l10.m1.7.7" xref="alg1.l10.m1.7.7.cmml"><mrow id="alg1.l10.m1.6.6.2.2" xref="alg1.l10.m1.6.6.2.3.cmml"><mrow id="alg1.l10.m1.5.5.1.1.1" xref="alg1.l10.m1.5.5.1.1.1.cmml"><msub id="alg1.l10.m1.5.5.1.1.1.2" xref="alg1.l10.m1.5.5.1.1.1.2.cmml"><mi id="alg1.l10.m1.5.5.1.1.1.2.2" xref="alg1.l10.m1.5.5.1.1.1.2.2.cmml">I</mi><mi id="alg1.l10.m1.5.5.1.1.1.2.3" xref="alg1.l10.m1.5.5.1.1.1.2.3.cmml">r</mi></msub><mo id="alg1.l10.m1.5.5.1.1.1.1" xref="alg1.l10.m1.5.5.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l10.m1.5.5.1.1.1.3.2" xref="alg1.l10.m1.5.5.1.1.1.cmml"><mo id="alg1.l10.m1.5.5.1.1.1.3.2.1" stretchy="false" xref="alg1.l10.m1.5.5.1.1.1.cmml">(</mo><mi id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml">P</mi><mo id="alg1.l10.m1.5.5.1.1.1.3.2.2" stretchy="false" xref="alg1.l10.m1.5.5.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l10.m1.6.6.2.2.3" xref="alg1.l10.m1.6.6.2.3.cmml">,</mo><mrow id="alg1.l10.m1.6.6.2.2.2" xref="alg1.l10.m1.6.6.2.2.2.cmml"><msub id="alg1.l10.m1.6.6.2.2.2.2" xref="alg1.l10.m1.6.6.2.2.2.2.cmml"><mi id="alg1.l10.m1.6.6.2.2.2.2.2" xref="alg1.l10.m1.6.6.2.2.2.2.2.cmml">S</mi><mi id="alg1.l10.m1.6.6.2.2.2.2.3" xref="alg1.l10.m1.6.6.2.2.2.2.3.cmml">r</mi></msub><mo id="alg1.l10.m1.6.6.2.2.2.1" xref="alg1.l10.m1.6.6.2.2.2.1.cmml">⁢</mo><mrow id="alg1.l10.m1.6.6.2.2.2.3.2" xref="alg1.l10.m1.6.6.2.2.2.cmml"><mo id="alg1.l10.m1.6.6.2.2.2.3.2.1" stretchy="false" xref="alg1.l10.m1.6.6.2.2.2.cmml">(</mo><mi id="alg1.l10.m1.2.2" xref="alg1.l10.m1.2.2.cmml">P</mi><mo id="alg1.l10.m1.6.6.2.2.2.3.2.2" stretchy="false" xref="alg1.l10.m1.6.6.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="alg1.l10.m1.7.7.4" stretchy="false" xref="alg1.l10.m1.7.7.4.cmml">←</mo><mrow id="alg1.l10.m1.7.7.3" xref="alg1.l10.m1.7.7.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.7.7.3.3" xref="alg1.l10.m1.7.7.3.3.cmml">ℛ</mi><mo id="alg1.l10.m1.7.7.3.2" xref="alg1.l10.m1.7.7.3.2.cmml">⁢</mo><mrow id="alg1.l10.m1.7.7.3.1.1" xref="alg1.l10.m1.7.7.3.1.2.cmml"><mo id="alg1.l10.m1.7.7.3.1.1.2" stretchy="false" xref="alg1.l10.m1.7.7.3.1.2.cmml">(</mo><mi id="alg1.l10.m1.3.3" xref="alg1.l10.m1.3.3.cmml">P</mi><mo id="alg1.l10.m1.7.7.3.1.1.3" xref="alg1.l10.m1.7.7.3.1.2.cmml">,</mo><msub id="alg1.l10.m1.7.7.3.1.1.1" xref="alg1.l10.m1.7.7.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l10.m1.7.7.3.1.1.1.2" xref="alg1.l10.m1.7.7.3.1.1.1.2.cmml">ℳ</mi><mtext id="alg1.l10.m1.7.7.3.1.1.1.3" xref="alg1.l10.m1.7.7.3.1.1.1.3a.cmml">r</mtext></msub><mo id="alg1.l10.m1.7.7.3.1.1.4" xref="alg1.l10.m1.7.7.3.1.2.cmml">,</mo><mi id="alg1.l10.m1.4.4" xref="alg1.l10.m1.4.4.cmml">K</mi><mo id="alg1.l10.m1.7.7.3.1.1.5" stretchy="false" xref="alg1.l10.m1.7.7.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.7b"><apply id="alg1.l10.m1.7.7.cmml" xref="alg1.l10.m1.7.7"><ci id="alg1.l10.m1.7.7.4.cmml" xref="alg1.l10.m1.7.7.4">←</ci><list id="alg1.l10.m1.6.6.2.3.cmml" xref="alg1.l10.m1.6.6.2.2"><apply id="alg1.l10.m1.5.5.1.1.1.cmml" xref="alg1.l10.m1.5.5.1.1.1"><times id="alg1.l10.m1.5.5.1.1.1.1.cmml" xref="alg1.l10.m1.5.5.1.1.1.1"></times><apply id="alg1.l10.m1.5.5.1.1.1.2.cmml" xref="alg1.l10.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l10.m1.5.5.1.1.1.2.1.cmml" xref="alg1.l10.m1.5.5.1.1.1.2">subscript</csymbol><ci id="alg1.l10.m1.5.5.1.1.1.2.2.cmml" xref="alg1.l10.m1.5.5.1.1.1.2.2">𝐼</ci><ci id="alg1.l10.m1.5.5.1.1.1.2.3.cmml" xref="alg1.l10.m1.5.5.1.1.1.2.3">𝑟</ci></apply><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">𝑃</ci></apply><apply id="alg1.l10.m1.6.6.2.2.2.cmml" xref="alg1.l10.m1.6.6.2.2.2"><times id="alg1.l10.m1.6.6.2.2.2.1.cmml" xref="alg1.l10.m1.6.6.2.2.2.1"></times><apply id="alg1.l10.m1.6.6.2.2.2.2.cmml" xref="alg1.l10.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l10.m1.6.6.2.2.2.2.1.cmml" xref="alg1.l10.m1.6.6.2.2.2.2">subscript</csymbol><ci id="alg1.l10.m1.6.6.2.2.2.2.2.cmml" xref="alg1.l10.m1.6.6.2.2.2.2.2">𝑆</ci><ci id="alg1.l10.m1.6.6.2.2.2.2.3.cmml" xref="alg1.l10.m1.6.6.2.2.2.2.3">𝑟</ci></apply><ci id="alg1.l10.m1.2.2.cmml" xref="alg1.l10.m1.2.2">𝑃</ci></apply></list><apply id="alg1.l10.m1.7.7.3.cmml" xref="alg1.l10.m1.7.7.3"><times id="alg1.l10.m1.7.7.3.2.cmml" xref="alg1.l10.m1.7.7.3.2"></times><ci id="alg1.l10.m1.7.7.3.3.cmml" xref="alg1.l10.m1.7.7.3.3">ℛ</ci><vector id="alg1.l10.m1.7.7.3.1.2.cmml" xref="alg1.l10.m1.7.7.3.1.1"><ci id="alg1.l10.m1.3.3.cmml" xref="alg1.l10.m1.3.3">𝑃</ci><apply id="alg1.l10.m1.7.7.3.1.1.1.cmml" xref="alg1.l10.m1.7.7.3.1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.7.7.3.1.1.1.1.cmml" xref="alg1.l10.m1.7.7.3.1.1.1">subscript</csymbol><ci id="alg1.l10.m1.7.7.3.1.1.1.2.cmml" xref="alg1.l10.m1.7.7.3.1.1.1.2">ℳ</ci><ci id="alg1.l10.m1.7.7.3.1.1.1.3a.cmml" xref="alg1.l10.m1.7.7.3.1.1.1.3"><mtext id="alg1.l10.m1.7.7.3.1.1.1.3.cmml" mathsize="70%" xref="alg1.l10.m1.7.7.3.1.1.1.3">r</mtext></ci></apply><ci id="alg1.l10.m1.4.4.cmml" xref="alg1.l10.m1.4.4">𝐾</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.7c">I_{r}(P),S_{r}(P)\leftarrow\mathcal{R}(P,\mathcal{M_{\text{r}}},K)</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.7d">italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) , italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ← caligraphic_R ( italic_P , caligraphic_M start_POSTSUBSCRIPT r end_POSTSUBSCRIPT , italic_K )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span>     <math alttext="L(P)=L_{1}\left\{I_{r}(P);I_{q}\right\}+L_{2}\left\{S_{r}(P);S_{q}\right\}" class="ltx_Math" display="inline" id="alg1.l11.m1.7"><semantics id="alg1.l11.m1.7a"><mrow id="alg1.l11.m1.7.7" xref="alg1.l11.m1.7.7.cmml"><mrow id="alg1.l11.m1.7.7.6" xref="alg1.l11.m1.7.7.6.cmml"><mi id="alg1.l11.m1.7.7.6.2" xref="alg1.l11.m1.7.7.6.2.cmml">L</mi><mo id="alg1.l11.m1.7.7.6.1" xref="alg1.l11.m1.7.7.6.1.cmml">⁢</mo><mrow id="alg1.l11.m1.7.7.6.3.2" xref="alg1.l11.m1.7.7.6.cmml"><mo id="alg1.l11.m1.7.7.6.3.2.1" stretchy="false" xref="alg1.l11.m1.7.7.6.cmml">(</mo><mi id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">P</mi><mo id="alg1.l11.m1.7.7.6.3.2.2" stretchy="false" xref="alg1.l11.m1.7.7.6.cmml">)</mo></mrow></mrow><mo id="alg1.l11.m1.7.7.5" xref="alg1.l11.m1.7.7.5.cmml">=</mo><mrow id="alg1.l11.m1.7.7.4" xref="alg1.l11.m1.7.7.4.cmml"><mrow id="alg1.l11.m1.5.5.2.2" xref="alg1.l11.m1.5.5.2.2.cmml"><msub id="alg1.l11.m1.5.5.2.2.4" xref="alg1.l11.m1.5.5.2.2.4.cmml"><mi id="alg1.l11.m1.5.5.2.2.4.2" xref="alg1.l11.m1.5.5.2.2.4.2.cmml">L</mi><mn id="alg1.l11.m1.5.5.2.2.4.3" xref="alg1.l11.m1.5.5.2.2.4.3.cmml">1</mn></msub><mo id="alg1.l11.m1.5.5.2.2.3" xref="alg1.l11.m1.5.5.2.2.3.cmml">⁢</mo><mrow id="alg1.l11.m1.5.5.2.2.2.2" xref="alg1.l11.m1.5.5.2.2.2.3.cmml"><mo id="alg1.l11.m1.5.5.2.2.2.2.3" xref="alg1.l11.m1.5.5.2.2.2.3.cmml">{</mo><mrow id="alg1.l11.m1.4.4.1.1.1.1.1" xref="alg1.l11.m1.4.4.1.1.1.1.1.cmml"><msub id="alg1.l11.m1.4.4.1.1.1.1.1.2" xref="alg1.l11.m1.4.4.1.1.1.1.1.2.cmml"><mi id="alg1.l11.m1.4.4.1.1.1.1.1.2.2" xref="alg1.l11.m1.4.4.1.1.1.1.1.2.2.cmml">I</mi><mi id="alg1.l11.m1.4.4.1.1.1.1.1.2.3" xref="alg1.l11.m1.4.4.1.1.1.1.1.2.3.cmml">r</mi></msub><mo id="alg1.l11.m1.4.4.1.1.1.1.1.1" xref="alg1.l11.m1.4.4.1.1.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l11.m1.4.4.1.1.1.1.1.3.2" xref="alg1.l11.m1.4.4.1.1.1.1.1.cmml"><mo id="alg1.l11.m1.4.4.1.1.1.1.1.3.2.1" stretchy="false" xref="alg1.l11.m1.4.4.1.1.1.1.1.cmml">(</mo><mi id="alg1.l11.m1.2.2" xref="alg1.l11.m1.2.2.cmml">P</mi><mo id="alg1.l11.m1.4.4.1.1.1.1.1.3.2.2" stretchy="false" xref="alg1.l11.m1.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l11.m1.5.5.2.2.2.2.4" xref="alg1.l11.m1.5.5.2.2.2.3.cmml">;</mo><msub id="alg1.l11.m1.5.5.2.2.2.2.2" xref="alg1.l11.m1.5.5.2.2.2.2.2.cmml"><mi id="alg1.l11.m1.5.5.2.2.2.2.2.2" xref="alg1.l11.m1.5.5.2.2.2.2.2.2.cmml">I</mi><mi id="alg1.l11.m1.5.5.2.2.2.2.2.3" xref="alg1.l11.m1.5.5.2.2.2.2.2.3.cmml">q</mi></msub><mo id="alg1.l11.m1.5.5.2.2.2.2.5" xref="alg1.l11.m1.5.5.2.2.2.3.cmml">}</mo></mrow></mrow><mo id="alg1.l11.m1.7.7.4.5" xref="alg1.l11.m1.7.7.4.5.cmml">+</mo><mrow id="alg1.l11.m1.7.7.4.4" xref="alg1.l11.m1.7.7.4.4.cmml"><msub id="alg1.l11.m1.7.7.4.4.4" xref="alg1.l11.m1.7.7.4.4.4.cmml"><mi id="alg1.l11.m1.7.7.4.4.4.2" xref="alg1.l11.m1.7.7.4.4.4.2.cmml">L</mi><mn id="alg1.l11.m1.7.7.4.4.4.3" xref="alg1.l11.m1.7.7.4.4.4.3.cmml">2</mn></msub><mo id="alg1.l11.m1.7.7.4.4.3" xref="alg1.l11.m1.7.7.4.4.3.cmml">⁢</mo><mrow id="alg1.l11.m1.7.7.4.4.2.2" xref="alg1.l11.m1.7.7.4.4.2.3.cmml"><mo id="alg1.l11.m1.7.7.4.4.2.2.3" xref="alg1.l11.m1.7.7.4.4.2.3.cmml">{</mo><mrow id="alg1.l11.m1.6.6.3.3.1.1.1" xref="alg1.l11.m1.6.6.3.3.1.1.1.cmml"><msub id="alg1.l11.m1.6.6.3.3.1.1.1.2" xref="alg1.l11.m1.6.6.3.3.1.1.1.2.cmml"><mi id="alg1.l11.m1.6.6.3.3.1.1.1.2.2" xref="alg1.l11.m1.6.6.3.3.1.1.1.2.2.cmml">S</mi><mi id="alg1.l11.m1.6.6.3.3.1.1.1.2.3" xref="alg1.l11.m1.6.6.3.3.1.1.1.2.3.cmml">r</mi></msub><mo id="alg1.l11.m1.6.6.3.3.1.1.1.1" xref="alg1.l11.m1.6.6.3.3.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l11.m1.6.6.3.3.1.1.1.3.2" xref="alg1.l11.m1.6.6.3.3.1.1.1.cmml"><mo id="alg1.l11.m1.6.6.3.3.1.1.1.3.2.1" stretchy="false" xref="alg1.l11.m1.6.6.3.3.1.1.1.cmml">(</mo><mi id="alg1.l11.m1.3.3" xref="alg1.l11.m1.3.3.cmml">P</mi><mo id="alg1.l11.m1.6.6.3.3.1.1.1.3.2.2" stretchy="false" xref="alg1.l11.m1.6.6.3.3.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l11.m1.7.7.4.4.2.2.4" xref="alg1.l11.m1.7.7.4.4.2.3.cmml">;</mo><msub id="alg1.l11.m1.7.7.4.4.2.2.2" xref="alg1.l11.m1.7.7.4.4.2.2.2.cmml"><mi id="alg1.l11.m1.7.7.4.4.2.2.2.2" xref="alg1.l11.m1.7.7.4.4.2.2.2.2.cmml">S</mi><mi id="alg1.l11.m1.7.7.4.4.2.2.2.3" xref="alg1.l11.m1.7.7.4.4.2.2.2.3.cmml">q</mi></msub><mo id="alg1.l11.m1.7.7.4.4.2.2.5" xref="alg1.l11.m1.7.7.4.4.2.3.cmml">}</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.7b"><apply id="alg1.l11.m1.7.7.cmml" xref="alg1.l11.m1.7.7"><eq id="alg1.l11.m1.7.7.5.cmml" xref="alg1.l11.m1.7.7.5"></eq><apply id="alg1.l11.m1.7.7.6.cmml" xref="alg1.l11.m1.7.7.6"><times id="alg1.l11.m1.7.7.6.1.cmml" xref="alg1.l11.m1.7.7.6.1"></times><ci id="alg1.l11.m1.7.7.6.2.cmml" xref="alg1.l11.m1.7.7.6.2">𝐿</ci><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">𝑃</ci></apply><apply id="alg1.l11.m1.7.7.4.cmml" xref="alg1.l11.m1.7.7.4"><plus id="alg1.l11.m1.7.7.4.5.cmml" xref="alg1.l11.m1.7.7.4.5"></plus><apply id="alg1.l11.m1.5.5.2.2.cmml" xref="alg1.l11.m1.5.5.2.2"><times id="alg1.l11.m1.5.5.2.2.3.cmml" xref="alg1.l11.m1.5.5.2.2.3"></times><apply id="alg1.l11.m1.5.5.2.2.4.cmml" xref="alg1.l11.m1.5.5.2.2.4"><csymbol cd="ambiguous" id="alg1.l11.m1.5.5.2.2.4.1.cmml" xref="alg1.l11.m1.5.5.2.2.4">subscript</csymbol><ci id="alg1.l11.m1.5.5.2.2.4.2.cmml" xref="alg1.l11.m1.5.5.2.2.4.2">𝐿</ci><cn id="alg1.l11.m1.5.5.2.2.4.3.cmml" type="integer" xref="alg1.l11.m1.5.5.2.2.4.3">1</cn></apply><list id="alg1.l11.m1.5.5.2.2.2.3.cmml" xref="alg1.l11.m1.5.5.2.2.2.2"><apply id="alg1.l11.m1.4.4.1.1.1.1.1.cmml" xref="alg1.l11.m1.4.4.1.1.1.1.1"><times id="alg1.l11.m1.4.4.1.1.1.1.1.1.cmml" xref="alg1.l11.m1.4.4.1.1.1.1.1.1"></times><apply id="alg1.l11.m1.4.4.1.1.1.1.1.2.cmml" xref="alg1.l11.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l11.m1.4.4.1.1.1.1.1.2.1.cmml" xref="alg1.l11.m1.4.4.1.1.1.1.1.2">subscript</csymbol><ci id="alg1.l11.m1.4.4.1.1.1.1.1.2.2.cmml" xref="alg1.l11.m1.4.4.1.1.1.1.1.2.2">𝐼</ci><ci id="alg1.l11.m1.4.4.1.1.1.1.1.2.3.cmml" xref="alg1.l11.m1.4.4.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="alg1.l11.m1.2.2.cmml" xref="alg1.l11.m1.2.2">𝑃</ci></apply><apply id="alg1.l11.m1.5.5.2.2.2.2.2.cmml" xref="alg1.l11.m1.5.5.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l11.m1.5.5.2.2.2.2.2.1.cmml" xref="alg1.l11.m1.5.5.2.2.2.2.2">subscript</csymbol><ci id="alg1.l11.m1.5.5.2.2.2.2.2.2.cmml" xref="alg1.l11.m1.5.5.2.2.2.2.2.2">𝐼</ci><ci id="alg1.l11.m1.5.5.2.2.2.2.2.3.cmml" xref="alg1.l11.m1.5.5.2.2.2.2.2.3">𝑞</ci></apply></list></apply><apply id="alg1.l11.m1.7.7.4.4.cmml" xref="alg1.l11.m1.7.7.4.4"><times id="alg1.l11.m1.7.7.4.4.3.cmml" xref="alg1.l11.m1.7.7.4.4.3"></times><apply id="alg1.l11.m1.7.7.4.4.4.cmml" xref="alg1.l11.m1.7.7.4.4.4"><csymbol cd="ambiguous" id="alg1.l11.m1.7.7.4.4.4.1.cmml" xref="alg1.l11.m1.7.7.4.4.4">subscript</csymbol><ci id="alg1.l11.m1.7.7.4.4.4.2.cmml" xref="alg1.l11.m1.7.7.4.4.4.2">𝐿</ci><cn id="alg1.l11.m1.7.7.4.4.4.3.cmml" type="integer" xref="alg1.l11.m1.7.7.4.4.4.3">2</cn></apply><list id="alg1.l11.m1.7.7.4.4.2.3.cmml" xref="alg1.l11.m1.7.7.4.4.2.2"><apply id="alg1.l11.m1.6.6.3.3.1.1.1.cmml" xref="alg1.l11.m1.6.6.3.3.1.1.1"><times id="alg1.l11.m1.6.6.3.3.1.1.1.1.cmml" xref="alg1.l11.m1.6.6.3.3.1.1.1.1"></times><apply id="alg1.l11.m1.6.6.3.3.1.1.1.2.cmml" xref="alg1.l11.m1.6.6.3.3.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l11.m1.6.6.3.3.1.1.1.2.1.cmml" xref="alg1.l11.m1.6.6.3.3.1.1.1.2">subscript</csymbol><ci id="alg1.l11.m1.6.6.3.3.1.1.1.2.2.cmml" xref="alg1.l11.m1.6.6.3.3.1.1.1.2.2">𝑆</ci><ci id="alg1.l11.m1.6.6.3.3.1.1.1.2.3.cmml" xref="alg1.l11.m1.6.6.3.3.1.1.1.2.3">𝑟</ci></apply><ci id="alg1.l11.m1.3.3.cmml" xref="alg1.l11.m1.3.3">𝑃</ci></apply><apply id="alg1.l11.m1.7.7.4.4.2.2.2.cmml" xref="alg1.l11.m1.7.7.4.4.2.2.2"><csymbol cd="ambiguous" id="alg1.l11.m1.7.7.4.4.2.2.2.1.cmml" xref="alg1.l11.m1.7.7.4.4.2.2.2">subscript</csymbol><ci id="alg1.l11.m1.7.7.4.4.2.2.2.2.cmml" xref="alg1.l11.m1.7.7.4.4.2.2.2.2">𝑆</ci><ci id="alg1.l11.m1.7.7.4.4.2.2.2.3.cmml" xref="alg1.l11.m1.7.7.4.4.2.2.2.3">𝑞</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.7c">L(P)=L_{1}\left\{I_{r}(P);I_{q}\right\}+L_{2}\left\{S_{r}(P);S_{q}\right\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.7d">italic_L ( italic_P ) = italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT { italic_I start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ; italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT } + italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT { italic_S start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_P ) ; italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT }</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span>     <math alttext="P\leftarrow\texttt{GradientDescent}(L(P),\alpha)" class="ltx_Math" display="inline" id="alg1.l12.m1.3"><semantics id="alg1.l12.m1.3a"><mrow id="alg1.l12.m1.3.3" xref="alg1.l12.m1.3.3.cmml"><mi id="alg1.l12.m1.3.3.3" xref="alg1.l12.m1.3.3.3.cmml">P</mi><mo id="alg1.l12.m1.3.3.2" stretchy="false" xref="alg1.l12.m1.3.3.2.cmml">←</mo><mrow id="alg1.l12.m1.3.3.1" xref="alg1.l12.m1.3.3.1.cmml"><mtext class="ltx_mathvariant_monospace" id="alg1.l12.m1.3.3.1.3" xref="alg1.l12.m1.3.3.1.3a.cmml">GradientDescent</mtext><mo id="alg1.l12.m1.3.3.1.2" xref="alg1.l12.m1.3.3.1.2.cmml">⁢</mo><mrow id="alg1.l12.m1.3.3.1.1.1" xref="alg1.l12.m1.3.3.1.1.2.cmml"><mo id="alg1.l12.m1.3.3.1.1.1.2" stretchy="false" xref="alg1.l12.m1.3.3.1.1.2.cmml">(</mo><mrow id="alg1.l12.m1.3.3.1.1.1.1" xref="alg1.l12.m1.3.3.1.1.1.1.cmml"><mi id="alg1.l12.m1.3.3.1.1.1.1.2" xref="alg1.l12.m1.3.3.1.1.1.1.2.cmml">L</mi><mo id="alg1.l12.m1.3.3.1.1.1.1.1" xref="alg1.l12.m1.3.3.1.1.1.1.1.cmml">⁢</mo><mrow id="alg1.l12.m1.3.3.1.1.1.1.3.2" xref="alg1.l12.m1.3.3.1.1.1.1.cmml"><mo id="alg1.l12.m1.3.3.1.1.1.1.3.2.1" stretchy="false" xref="alg1.l12.m1.3.3.1.1.1.1.cmml">(</mo><mi id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml">P</mi><mo id="alg1.l12.m1.3.3.1.1.1.1.3.2.2" stretchy="false" xref="alg1.l12.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg1.l12.m1.3.3.1.1.1.3" xref="alg1.l12.m1.3.3.1.1.2.cmml">,</mo><mi id="alg1.l12.m1.2.2" xref="alg1.l12.m1.2.2.cmml">α</mi><mo id="alg1.l12.m1.3.3.1.1.1.4" stretchy="false" xref="alg1.l12.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.3b"><apply id="alg1.l12.m1.3.3.cmml" xref="alg1.l12.m1.3.3"><ci id="alg1.l12.m1.3.3.2.cmml" xref="alg1.l12.m1.3.3.2">←</ci><ci id="alg1.l12.m1.3.3.3.cmml" xref="alg1.l12.m1.3.3.3">𝑃</ci><apply id="alg1.l12.m1.3.3.1.cmml" xref="alg1.l12.m1.3.3.1"><times id="alg1.l12.m1.3.3.1.2.cmml" xref="alg1.l12.m1.3.3.1.2"></times><ci id="alg1.l12.m1.3.3.1.3a.cmml" xref="alg1.l12.m1.3.3.1.3"><mtext class="ltx_mathvariant_monospace" id="alg1.l12.m1.3.3.1.3.cmml" xref="alg1.l12.m1.3.3.1.3">GradientDescent</mtext></ci><interval closure="open" id="alg1.l12.m1.3.3.1.1.2.cmml" xref="alg1.l12.m1.3.3.1.1.1"><apply id="alg1.l12.m1.3.3.1.1.1.1.cmml" xref="alg1.l12.m1.3.3.1.1.1.1"><times id="alg1.l12.m1.3.3.1.1.1.1.1.cmml" xref="alg1.l12.m1.3.3.1.1.1.1.1"></times><ci id="alg1.l12.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l12.m1.3.3.1.1.1.1.2">𝐿</ci><ci id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1">𝑃</ci></apply><ci id="alg1.l12.m1.2.2.cmml" xref="alg1.l12.m1.2.2">𝛼</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.3c">P\leftarrow\texttt{GradientDescent}(L(P),\alpha)</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.3d">italic_P ← GradientDescent ( italic_L ( italic_P ) , italic_α )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13.1.1.1" style="font-size:80%;">13:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l13.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l13.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l13a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13a.1.1.1" style="font-size:80%;">13:</span></span>  <math alttext="P" class="ltx_Math" display="inline" id="alg1.l13a.m1.1"><semantics id="alg1.l13a.m1.1a"><mi id="alg1.l13a.m1.1.1" xref="alg1.l13a.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="alg1.l13a.m1.1b"><ci id="alg1.l13a.m1.1.1.cmml" xref="alg1.l13a.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13a.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="alg1.l13a.m1.1d">italic_P</annotation></semantics></math>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experiments</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we extensively validate our method on benchmark datasets including the LineMOD <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib18" title=""><span class="ltx_text" style="font-size:80%;">linemod</span> </a></cite>, YCB-V <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">posecnn</span> </a></cite>, and LineMOD-Occlusion (LM-O) <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib3" title=""><span class="ltx_text" style="font-size:80%;">lmo</span> </a></cite> datasets. We detail the experimental setup in the following.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.5.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.6.2">Experimental Setups</span>
</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">State-of-the-art Methods for Comparison.</span> As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S1.T1" title="TABLE I ‣ I Introduction ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">I</span></a>, there does not exist a method applying the challenging setting of label/training-free and a single reference-query pair like ours. Therefore we choose the state-of-the-art methods that share the closest experimental setups, which are <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.2">ZSP</span> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib14" title=""><span class="ltx_text" style="font-size:80%;">zsp</span> </a></cite>, <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.3">LoFTR</span> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib56" title=""><span class="ltx_text" style="font-size:80%;">loftr</span> </a></cite>, <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.4">RelPose++</span> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite>, <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.5">3DAHV</span> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, and <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.6">DVMNet</span> <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>. Specifically, for <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.7">ZSP</span>, though it was originally proposed to process multiple queries, it is able to accept one RGB-D query as input. We report its performance based on the single RGB-D query and single RGB-D reference pair. For <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.8">LoFTR</span>, we use its pretrained weights released by the authors <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib56" title=""><span class="ltx_text" style="font-size:80%;">loftr</span> </a></cite>. The weights of <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.9">DVMNet</span>, <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.10">3DAHV</span>, and <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.11">RelPose++</span> are retrained on-demand to achieve their best performance (for the details, see the following <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.12">Benchmark Experiments</em>, and the table captions of Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T2" title="TABLE II ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">II</span></a>, Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T3" title="TABLE III ‣ IV-C Experimental Results on the YCB-V Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">III</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T4" title="TABLE IV ‣ IV-D Experimental Results on the LM-O Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">IV</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Datasets.</span> The experiments are carried out on three benchmark object pose estimation datasets, i.e., LineMOD dataset <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib18" title=""><span class="ltx_text" style="font-size:80%;">linemod</span> </a></cite> comprises 13 real objects, each depicting a single low-textured object on varying lighting conditions with approximately 1,200 images. LineMOD-Occlusion (LM-O) <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib3" title=""><span class="ltx_text" style="font-size:80%;">lmo</span> </a></cite> consists of 1,214 images of the 8 occluded objects, extracted from the LineMOD dataset, the average visible fraction of objects in LM-O is 79.45%. YCB-V <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib69" title=""><span class="ltx_text" style="font-size:80%;">posecnn</span> </a></cite> encompasses over 110,000 real images featuring 21 objects characterized by severe occlusion and clutter, it exhibits an average visible object fraction of 87.15%.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.6"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.6.3">Evaluation Metric.</span> Following <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, we report <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.6.4">mean angular error</span> across sampled reference-query pairs. We also evaluate on important metrics of <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.1.1">Acc@5/10/15/30<sup class="ltx_sup" id="S4.SS1.p3.1.1.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.SS1.p3.1.1.1.1">∘</span></sup></span>, i.e., the percentage of the predictions that are within 5/10/15/30<sup class="ltx_sup" id="S4.SS1.p3.6.5"><span class="ltx_text ltx_font_italic" id="S4.SS1.p3.6.5.1">∘</span></sup>, which can be more rigorous (e.g., <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.3.2">Acc@5<sup class="ltx_sup" id="S4.SS1.p3.3.2.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.SS1.p3.3.2.1.1">∘</span></sup></span>) and better characterize the performance. The degree of the pose difference between the ground truth <math alttext="R_{gt}" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m2.1"><semantics id="S4.SS1.p3.4.m2.1a"><msub id="S4.SS1.p3.4.m2.1.1" xref="S4.SS1.p3.4.m2.1.1.cmml"><mi id="S4.SS1.p3.4.m2.1.1.2" xref="S4.SS1.p3.4.m2.1.1.2.cmml">R</mi><mrow id="S4.SS1.p3.4.m2.1.1.3" xref="S4.SS1.p3.4.m2.1.1.3.cmml"><mi id="S4.SS1.p3.4.m2.1.1.3.2" xref="S4.SS1.p3.4.m2.1.1.3.2.cmml">g</mi><mo id="S4.SS1.p3.4.m2.1.1.3.1" xref="S4.SS1.p3.4.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p3.4.m2.1.1.3.3" xref="S4.SS1.p3.4.m2.1.1.3.3.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m2.1b"><apply id="S4.SS1.p3.4.m2.1.1.cmml" xref="S4.SS1.p3.4.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m2.1.1.1.cmml" xref="S4.SS1.p3.4.m2.1.1">subscript</csymbol><ci id="S4.SS1.p3.4.m2.1.1.2.cmml" xref="S4.SS1.p3.4.m2.1.1.2">𝑅</ci><apply id="S4.SS1.p3.4.m2.1.1.3.cmml" xref="S4.SS1.p3.4.m2.1.1.3"><times id="S4.SS1.p3.4.m2.1.1.3.1.cmml" xref="S4.SS1.p3.4.m2.1.1.3.1"></times><ci id="S4.SS1.p3.4.m2.1.1.3.2.cmml" xref="S4.SS1.p3.4.m2.1.1.3.2">𝑔</ci><ci id="S4.SS1.p3.4.m2.1.1.3.3.cmml" xref="S4.SS1.p3.4.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m2.1c">R_{gt}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m2.1d">italic_R start_POSTSUBSCRIPT italic_g italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and the predictions <math alttext="\hat{R}" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m3.1"><semantics id="S4.SS1.p3.5.m3.1a"><mover accent="true" id="S4.SS1.p3.5.m3.1.1" xref="S4.SS1.p3.5.m3.1.1.cmml"><mi id="S4.SS1.p3.5.m3.1.1.2" xref="S4.SS1.p3.5.m3.1.1.2.cmml">R</mi><mo id="S4.SS1.p3.5.m3.1.1.1" xref="S4.SS1.p3.5.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m3.1b"><apply id="S4.SS1.p3.5.m3.1.1.cmml" xref="S4.SS1.p3.5.m3.1.1"><ci id="S4.SS1.p3.5.m3.1.1.1.cmml" xref="S4.SS1.p3.5.m3.1.1.1">^</ci><ci id="S4.SS1.p3.5.m3.1.1.2.cmml" xref="S4.SS1.p3.5.m3.1.1.2">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m3.1c">\hat{R}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.5.m3.1d">over^ start_ARG italic_R end_ARG</annotation></semantics></math> is calculated by the geodesic distance <math alttext="D" class="ltx_Math" display="inline" id="S4.SS1.p3.6.m4.1"><semantics id="S4.SS1.p3.6.m4.1a"><mi id="S4.SS1.p3.6.m4.1.1" xref="S4.SS1.p3.6.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m4.1b"><ci id="S4.SS1.p3.6.m4.1.1.cmml" xref="S4.SS1.p3.6.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m4.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.6.m4.1d">italic_D</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="D=\arccos\left((\text{tr}(\Delta R^{T}_{gt}\Delta\hat{R})-1)/2\right)/\pi" class="ltx_Math" display="block" id="S4.E6.m1.2"><semantics id="S4.E6.m1.2a"><mrow id="S4.E6.m1.2.2" xref="S4.E6.m1.2.2.cmml"><mi id="S4.E6.m1.2.2.3" xref="S4.E6.m1.2.2.3.cmml">D</mi><mo id="S4.E6.m1.2.2.2" xref="S4.E6.m1.2.2.2.cmml">=</mo><mrow id="S4.E6.m1.2.2.1" xref="S4.E6.m1.2.2.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.1" xref="S4.E6.m1.2.2.1.1.2.cmml"><mi id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml">arccos</mi><mo id="S4.E6.m1.2.2.1.1.1a" xref="S4.E6.m1.2.2.1.1.2.cmml">⁡</mo><mrow id="S4.E6.m1.2.2.1.1.1.1" xref="S4.E6.m1.2.2.1.1.2.cmml"><mo id="S4.E6.m1.2.2.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.2.cmml">(</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mtext id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.3a.cmml">tr</mtext><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" mathvariant="normal" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">Δ</mi><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><msubsup id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">R</mi><mrow id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">g</mi><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">T</mi></msubsup><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.4" mathvariant="normal" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.4.cmml">Δ</mi><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1b" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mover accent="true" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.2.cmml">R</mi><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.1" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.1.cmml">^</mo></mover></mrow><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">−</mo><mn id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.E6.m1.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E6.m1.2.2.1.1.1.1.1.2" xref="S4.E6.m1.2.2.1.1.1.1.1.2.cmml">/</mo><mn id="S4.E6.m1.2.2.1.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.1.1.1.3.cmml">2</mn></mrow><mo id="S4.E6.m1.2.2.1.1.1.1.3" xref="S4.E6.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E6.m1.2.2.1.2" xref="S4.E6.m1.2.2.1.2.cmml">/</mo><mi id="S4.E6.m1.2.2.1.3" xref="S4.E6.m1.2.2.1.3.cmml">π</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.2b"><apply id="S4.E6.m1.2.2.cmml" xref="S4.E6.m1.2.2"><eq id="S4.E6.m1.2.2.2.cmml" xref="S4.E6.m1.2.2.2"></eq><ci id="S4.E6.m1.2.2.3.cmml" xref="S4.E6.m1.2.2.3">𝐷</ci><apply id="S4.E6.m1.2.2.1.cmml" xref="S4.E6.m1.2.2.1"><divide id="S4.E6.m1.2.2.1.2.cmml" xref="S4.E6.m1.2.2.1.2"></divide><apply id="S4.E6.m1.2.2.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1"><arccos id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1"></arccos><apply id="S4.E6.m1.2.2.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1"><divide id="S4.E6.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.2"></divide><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1"><minus id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.2"></minus><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1"><times id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.2"></times><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.3"><mtext id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.3">tr</mtext></ci><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><times id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2">Δ</ci><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2">𝑅</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑇</ci></apply><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3"><times id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2">𝑔</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.4">Δ</ci><apply id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5"><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.1">^</ci><ci id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.5.2">𝑅</ci></apply></apply></apply><cn id="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.E6.m1.2.2.1.1.1.1.1.1.1.1.3">1</cn></apply><cn id="S4.E6.m1.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S4.E6.m1.2.2.1.1.1.1.1.3">2</cn></apply></apply><ci id="S4.E6.m1.2.2.1.3.cmml" xref="S4.E6.m1.2.2.1.3">𝜋</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.2c">D=\arccos\left((\text{tr}(\Delta R^{T}_{gt}\Delta\hat{R})-1)/2\right)/\pi</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.2d">italic_D = roman_arccos ( ( tr ( roman_Δ italic_R start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g italic_t end_POSTSUBSCRIPT roman_Δ over^ start_ARG italic_R end_ARG ) - 1 ) / 2 ) / italic_π</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Benchmark Experiments.</span> The in-dataset networks of the state-of-the-art DVMNet, 3DAHV, and RelPose++ methods need to be trained on the leave-out subset which comes from the same dataset as the testing subset but does not include the testing objects. For a fair comparison, on the LineMOD dataset, we follow the experiments in DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> to evaluate 5 objects (i.e., benchvise, camera, cat, driller, duck). For the YCB-V experiments, we design a similar training protocol to enable the comparison with DVMNet, 3DAHV, and RelPose++, where we randomly sample 8 objects (i.e., tuna_fish_can, pudding_box, banana, pitcher_base, mug, power_drill, large_clamp, foam_brick) for evaluation, leaving the remaining 13 objects to train these three methods. Following DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>, we evaluate 3 unseen objects on the LM-O dataset (i.e., cat, driller, and duck). Since the challenging LM-O dataset is typically used solely for evaluation, we directly use the same weights for DVMNet and 3DAHV that were trained in the LineMOD experiments.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.2">Since the results on the rigorous metrics of <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p5.1.1">Acc@5/10<sup class="ltx_sup" id="S4.SS1.p5.1.1.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.SS1.p5.1.1.1.1">∘</span></sup></span> are not reported in the 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> and DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> paper, we thus retrain them using the code released by the authors for the <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p5.2.2">Acc@5/10<sup class="ltx_sup" id="S4.SS1.p5.2.2.1"><span class="ltx_text ltx_font_serif ltx_font_italic" id="S4.SS1.p5.2.2.1.1">∘</span></sup></span> evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">Moreover, as a label/training-free method, the performance of our method can be assessed on all the objects of LineMOD, YCB-V, and LM-O datasets, without the need to leave out any training data or leverage any external dataset. We report the performance of our method on the complete LineMOD, YCB-V, and LM-O datasets in Tables S3, S4, and S5 of the supplementary material.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p7.1.1">In-dataset and Cross-dataset Evaluation.</span> Beyond the unseen objects generalization, we also test the dataset-level generalization for the state-of-the-art network-based methods DVMNet and 3DAHV, reporting both the <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.2">in-dataset</span> and the <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.3">cross-dataset</span> performance. In short, <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.4">in-dataset</span> and <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.5">cross-dataset</span> differ in whether the network needs to be finetuned on a subset that comes from the same dataset with the testing set (though not including the testing objects). Therefore, a good <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.6">cross-dataset</span> performance demonstrates better generalization in terms of the dataset, as the network only needs to be trained once on a large-scale external dataset without finetuning. Specifically, for the <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.7">in-dataset</span> experiments, we follow the exact training protocols of DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, which first pretrain on an external large-scale dataset Objaverse <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib11" title=""><span class="ltx_text" style="font-size:80%;">objaverse</span> </a></cite> then fintune on a certain dataset (e.g., LineMOD or YCB-V). For <span class="ltx_text ltx_font_italic" id="S4.SS1.p7.1.8">cross-dataset</span> experiments, we use the pretrained weights from Objaverse directly without finetuning.</p>
</div>
<div class="ltx_para" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.1">Note that the evaluation of our method, ZSP, and LoFTR does not involve a finetuning phase, demonstrating that our method, ZSP, and LoFTR naturally generalize to an arbitrary dataset<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>This is achieved by that 1) the pose estimation phase of our method, ZSP, and LoFTR are general and do not involve learning a network, and 2) they all use generalizable feature extractors, i.e., DINOv2 or LoFTR.</span></span></span>.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<p class="ltx_p ltx_align_center" id="S4.F4.1"><span class="ltx_text" id="S4.F4.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="249" id="S4.F4.1.1.g1" src="x4.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S4.F4.3.1">Histograms of the geodesic distance between the sampled reference-query pairs.</span> The in-plane rotation is included in calculating the histograms.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p9">
<p class="ltx_p" id="S4.SS1.p9.13"><span class="ltx_text ltx_font_bold" id="S4.SS1.p9.13.1">Reference-Query Pair Generation.</span> We follow DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> to generate the reference-query pairs with sufficient overlaps for training and testing.
Specifically, given a reference rotation <math alttext="R_{r}" class="ltx_Math" display="inline" id="S4.SS1.p9.1.m1.1"><semantics id="S4.SS1.p9.1.m1.1a"><msub id="S4.SS1.p9.1.m1.1.1" xref="S4.SS1.p9.1.m1.1.1.cmml"><mi id="S4.SS1.p9.1.m1.1.1.2" xref="S4.SS1.p9.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS1.p9.1.m1.1.1.3" xref="S4.SS1.p9.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.1.m1.1b"><apply id="S4.SS1.p9.1.m1.1.1.cmml" xref="S4.SS1.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.1.m1.1.1.1.cmml" xref="S4.SS1.p9.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p9.1.m1.1.1.2.cmml" xref="S4.SS1.p9.1.m1.1.1.2">𝑅</ci><ci id="S4.SS1.p9.1.m1.1.1.3.cmml" xref="S4.SS1.p9.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.1.m1.1c">R_{r}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and a query rotation <math alttext="R_{q}" class="ltx_Math" display="inline" id="S4.SS1.p9.2.m2.1"><semantics id="S4.SS1.p9.2.m2.1a"><msub id="S4.SS1.p9.2.m2.1.1" xref="S4.SS1.p9.2.m2.1.1.cmml"><mi id="S4.SS1.p9.2.m2.1.1.2" xref="S4.SS1.p9.2.m2.1.1.2.cmml">R</mi><mi id="S4.SS1.p9.2.m2.1.1.3" xref="S4.SS1.p9.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.2.m2.1b"><apply id="S4.SS1.p9.2.m2.1.1.cmml" xref="S4.SS1.p9.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.2.m2.1.1.1.cmml" xref="S4.SS1.p9.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p9.2.m2.1.1.2.cmml" xref="S4.SS1.p9.2.m2.1.1.2">𝑅</ci><ci id="S4.SS1.p9.2.m2.1.1.3.cmml" xref="S4.SS1.p9.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.2.m2.1c">R_{q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>, we first convert the rotation matrices <math alttext="R_{r}" class="ltx_Math" display="inline" id="S4.SS1.p9.3.m3.1"><semantics id="S4.SS1.p9.3.m3.1a"><msub id="S4.SS1.p9.3.m3.1.1" xref="S4.SS1.p9.3.m3.1.1.cmml"><mi id="S4.SS1.p9.3.m3.1.1.2" xref="S4.SS1.p9.3.m3.1.1.2.cmml">R</mi><mi id="S4.SS1.p9.3.m3.1.1.3" xref="S4.SS1.p9.3.m3.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.3.m3.1b"><apply id="S4.SS1.p9.3.m3.1.1.cmml" xref="S4.SS1.p9.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.3.m3.1.1.1.cmml" xref="S4.SS1.p9.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p9.3.m3.1.1.2.cmml" xref="S4.SS1.p9.3.m3.1.1.2">𝑅</ci><ci id="S4.SS1.p9.3.m3.1.1.3.cmml" xref="S4.SS1.p9.3.m3.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.3.m3.1c">R_{r}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.3.m3.1d">italic_R start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="R_{q}" class="ltx_Math" display="inline" id="S4.SS1.p9.4.m4.1"><semantics id="S4.SS1.p9.4.m4.1a"><msub id="S4.SS1.p9.4.m4.1.1" xref="S4.SS1.p9.4.m4.1.1.cmml"><mi id="S4.SS1.p9.4.m4.1.1.2" xref="S4.SS1.p9.4.m4.1.1.2.cmml">R</mi><mi id="S4.SS1.p9.4.m4.1.1.3" xref="S4.SS1.p9.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.4.m4.1b"><apply id="S4.SS1.p9.4.m4.1.1.cmml" xref="S4.SS1.p9.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.4.m4.1.1.1.cmml" xref="S4.SS1.p9.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p9.4.m4.1.1.2.cmml" xref="S4.SS1.p9.4.m4.1.1.2">𝑅</ci><ci id="S4.SS1.p9.4.m4.1.1.3.cmml" xref="S4.SS1.p9.4.m4.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.4.m4.1c">R_{q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.4.m4.1d">italic_R start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> to Euler angles <math alttext="(\alpha_{r},\beta_{r},\gamma_{r})" class="ltx_Math" display="inline" id="S4.SS1.p9.5.m5.3"><semantics id="S4.SS1.p9.5.m5.3a"><mrow id="S4.SS1.p9.5.m5.3.3.3" xref="S4.SS1.p9.5.m5.3.3.4.cmml"><mo id="S4.SS1.p9.5.m5.3.3.3.4" stretchy="false" xref="S4.SS1.p9.5.m5.3.3.4.cmml">(</mo><msub id="S4.SS1.p9.5.m5.1.1.1.1" xref="S4.SS1.p9.5.m5.1.1.1.1.cmml"><mi id="S4.SS1.p9.5.m5.1.1.1.1.2" xref="S4.SS1.p9.5.m5.1.1.1.1.2.cmml">α</mi><mi id="S4.SS1.p9.5.m5.1.1.1.1.3" xref="S4.SS1.p9.5.m5.1.1.1.1.3.cmml">r</mi></msub><mo id="S4.SS1.p9.5.m5.3.3.3.5" xref="S4.SS1.p9.5.m5.3.3.4.cmml">,</mo><msub id="S4.SS1.p9.5.m5.2.2.2.2" xref="S4.SS1.p9.5.m5.2.2.2.2.cmml"><mi id="S4.SS1.p9.5.m5.2.2.2.2.2" xref="S4.SS1.p9.5.m5.2.2.2.2.2.cmml">β</mi><mi id="S4.SS1.p9.5.m5.2.2.2.2.3" xref="S4.SS1.p9.5.m5.2.2.2.2.3.cmml">r</mi></msub><mo id="S4.SS1.p9.5.m5.3.3.3.6" xref="S4.SS1.p9.5.m5.3.3.4.cmml">,</mo><msub id="S4.SS1.p9.5.m5.3.3.3.3" xref="S4.SS1.p9.5.m5.3.3.3.3.cmml"><mi id="S4.SS1.p9.5.m5.3.3.3.3.2" xref="S4.SS1.p9.5.m5.3.3.3.3.2.cmml">γ</mi><mi id="S4.SS1.p9.5.m5.3.3.3.3.3" xref="S4.SS1.p9.5.m5.3.3.3.3.3.cmml">r</mi></msub><mo id="S4.SS1.p9.5.m5.3.3.3.7" stretchy="false" xref="S4.SS1.p9.5.m5.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.5.m5.3b"><vector id="S4.SS1.p9.5.m5.3.3.4.cmml" xref="S4.SS1.p9.5.m5.3.3.3"><apply id="S4.SS1.p9.5.m5.1.1.1.1.cmml" xref="S4.SS1.p9.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.5.m5.1.1.1.1.1.cmml" xref="S4.SS1.p9.5.m5.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p9.5.m5.1.1.1.1.2.cmml" xref="S4.SS1.p9.5.m5.1.1.1.1.2">𝛼</ci><ci id="S4.SS1.p9.5.m5.1.1.1.1.3.cmml" xref="S4.SS1.p9.5.m5.1.1.1.1.3">𝑟</ci></apply><apply id="S4.SS1.p9.5.m5.2.2.2.2.cmml" xref="S4.SS1.p9.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p9.5.m5.2.2.2.2.1.cmml" xref="S4.SS1.p9.5.m5.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p9.5.m5.2.2.2.2.2.cmml" xref="S4.SS1.p9.5.m5.2.2.2.2.2">𝛽</ci><ci id="S4.SS1.p9.5.m5.2.2.2.2.3.cmml" xref="S4.SS1.p9.5.m5.2.2.2.2.3">𝑟</ci></apply><apply id="S4.SS1.p9.5.m5.3.3.3.3.cmml" xref="S4.SS1.p9.5.m5.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p9.5.m5.3.3.3.3.1.cmml" xref="S4.SS1.p9.5.m5.3.3.3.3">subscript</csymbol><ci id="S4.SS1.p9.5.m5.3.3.3.3.2.cmml" xref="S4.SS1.p9.5.m5.3.3.3.3.2">𝛾</ci><ci id="S4.SS1.p9.5.m5.3.3.3.3.3.cmml" xref="S4.SS1.p9.5.m5.3.3.3.3.3">𝑟</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.5.m5.3c">(\alpha_{r},\beta_{r},\gamma_{r})</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.5.m5.3d">( italic_α start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_β start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_γ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="(\alpha_{q},\beta_{q},\gamma_{q})" class="ltx_Math" display="inline" id="S4.SS1.p9.6.m6.3"><semantics id="S4.SS1.p9.6.m6.3a"><mrow id="S4.SS1.p9.6.m6.3.3.3" xref="S4.SS1.p9.6.m6.3.3.4.cmml"><mo id="S4.SS1.p9.6.m6.3.3.3.4" stretchy="false" xref="S4.SS1.p9.6.m6.3.3.4.cmml">(</mo><msub id="S4.SS1.p9.6.m6.1.1.1.1" xref="S4.SS1.p9.6.m6.1.1.1.1.cmml"><mi id="S4.SS1.p9.6.m6.1.1.1.1.2" xref="S4.SS1.p9.6.m6.1.1.1.1.2.cmml">α</mi><mi id="S4.SS1.p9.6.m6.1.1.1.1.3" xref="S4.SS1.p9.6.m6.1.1.1.1.3.cmml">q</mi></msub><mo id="S4.SS1.p9.6.m6.3.3.3.5" xref="S4.SS1.p9.6.m6.3.3.4.cmml">,</mo><msub id="S4.SS1.p9.6.m6.2.2.2.2" xref="S4.SS1.p9.6.m6.2.2.2.2.cmml"><mi id="S4.SS1.p9.6.m6.2.2.2.2.2" xref="S4.SS1.p9.6.m6.2.2.2.2.2.cmml">β</mi><mi id="S4.SS1.p9.6.m6.2.2.2.2.3" xref="S4.SS1.p9.6.m6.2.2.2.2.3.cmml">q</mi></msub><mo id="S4.SS1.p9.6.m6.3.3.3.6" xref="S4.SS1.p9.6.m6.3.3.4.cmml">,</mo><msub id="S4.SS1.p9.6.m6.3.3.3.3" xref="S4.SS1.p9.6.m6.3.3.3.3.cmml"><mi id="S4.SS1.p9.6.m6.3.3.3.3.2" xref="S4.SS1.p9.6.m6.3.3.3.3.2.cmml">γ</mi><mi id="S4.SS1.p9.6.m6.3.3.3.3.3" xref="S4.SS1.p9.6.m6.3.3.3.3.3.cmml">q</mi></msub><mo id="S4.SS1.p9.6.m6.3.3.3.7" stretchy="false" xref="S4.SS1.p9.6.m6.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.6.m6.3b"><vector id="S4.SS1.p9.6.m6.3.3.4.cmml" xref="S4.SS1.p9.6.m6.3.3.3"><apply id="S4.SS1.p9.6.m6.1.1.1.1.cmml" xref="S4.SS1.p9.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.6.m6.1.1.1.1.1.cmml" xref="S4.SS1.p9.6.m6.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p9.6.m6.1.1.1.1.2.cmml" xref="S4.SS1.p9.6.m6.1.1.1.1.2">𝛼</ci><ci id="S4.SS1.p9.6.m6.1.1.1.1.3.cmml" xref="S4.SS1.p9.6.m6.1.1.1.1.3">𝑞</ci></apply><apply id="S4.SS1.p9.6.m6.2.2.2.2.cmml" xref="S4.SS1.p9.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p9.6.m6.2.2.2.2.1.cmml" xref="S4.SS1.p9.6.m6.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p9.6.m6.2.2.2.2.2.cmml" xref="S4.SS1.p9.6.m6.2.2.2.2.2">𝛽</ci><ci id="S4.SS1.p9.6.m6.2.2.2.2.3.cmml" xref="S4.SS1.p9.6.m6.2.2.2.2.3">𝑞</ci></apply><apply id="S4.SS1.p9.6.m6.3.3.3.3.cmml" xref="S4.SS1.p9.6.m6.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p9.6.m6.3.3.3.3.1.cmml" xref="S4.SS1.p9.6.m6.3.3.3.3">subscript</csymbol><ci id="S4.SS1.p9.6.m6.3.3.3.3.2.cmml" xref="S4.SS1.p9.6.m6.3.3.3.3.2">𝛾</ci><ci id="S4.SS1.p9.6.m6.3.3.3.3.3.cmml" xref="S4.SS1.p9.6.m6.3.3.3.3.3">𝑞</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.6.m6.3c">(\alpha_{q},\beta_{q},\gamma_{q})</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.6.m6.3d">( italic_α start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_β start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , italic_γ start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT )</annotation></semantics></math>. Since the in-plane rotation <math alttext="\gamma" class="ltx_Math" display="inline" id="S4.SS1.p9.7.m7.1"><semantics id="S4.SS1.p9.7.m7.1a"><mi id="S4.SS1.p9.7.m7.1.1" xref="S4.SS1.p9.7.m7.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.7.m7.1b"><ci id="S4.SS1.p9.7.m7.1.1.cmml" xref="S4.SS1.p9.7.m7.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.7.m7.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.7.m7.1d">italic_γ</annotation></semantics></math> does not influence the overlaps between the reference and query pair, it is set to 0 and converted back to the rotation matrix, i.e., <math alttext="\tilde{R}=h(\alpha,\beta,0)" class="ltx_Math" display="inline" id="S4.SS1.p9.8.m8.3"><semantics id="S4.SS1.p9.8.m8.3a"><mrow id="S4.SS1.p9.8.m8.3.4" xref="S4.SS1.p9.8.m8.3.4.cmml"><mover accent="true" id="S4.SS1.p9.8.m8.3.4.2" xref="S4.SS1.p9.8.m8.3.4.2.cmml"><mi id="S4.SS1.p9.8.m8.3.4.2.2" xref="S4.SS1.p9.8.m8.3.4.2.2.cmml">R</mi><mo id="S4.SS1.p9.8.m8.3.4.2.1" xref="S4.SS1.p9.8.m8.3.4.2.1.cmml">~</mo></mover><mo id="S4.SS1.p9.8.m8.3.4.1" xref="S4.SS1.p9.8.m8.3.4.1.cmml">=</mo><mrow id="S4.SS1.p9.8.m8.3.4.3" xref="S4.SS1.p9.8.m8.3.4.3.cmml"><mi id="S4.SS1.p9.8.m8.3.4.3.2" xref="S4.SS1.p9.8.m8.3.4.3.2.cmml">h</mi><mo id="S4.SS1.p9.8.m8.3.4.3.1" xref="S4.SS1.p9.8.m8.3.4.3.1.cmml">⁢</mo><mrow id="S4.SS1.p9.8.m8.3.4.3.3.2" xref="S4.SS1.p9.8.m8.3.4.3.3.1.cmml"><mo id="S4.SS1.p9.8.m8.3.4.3.3.2.1" stretchy="false" xref="S4.SS1.p9.8.m8.3.4.3.3.1.cmml">(</mo><mi id="S4.SS1.p9.8.m8.1.1" xref="S4.SS1.p9.8.m8.1.1.cmml">α</mi><mo id="S4.SS1.p9.8.m8.3.4.3.3.2.2" xref="S4.SS1.p9.8.m8.3.4.3.3.1.cmml">,</mo><mi id="S4.SS1.p9.8.m8.2.2" xref="S4.SS1.p9.8.m8.2.2.cmml">β</mi><mo id="S4.SS1.p9.8.m8.3.4.3.3.2.3" xref="S4.SS1.p9.8.m8.3.4.3.3.1.cmml">,</mo><mn id="S4.SS1.p9.8.m8.3.3" xref="S4.SS1.p9.8.m8.3.3.cmml">0</mn><mo id="S4.SS1.p9.8.m8.3.4.3.3.2.4" stretchy="false" xref="S4.SS1.p9.8.m8.3.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.8.m8.3b"><apply id="S4.SS1.p9.8.m8.3.4.cmml" xref="S4.SS1.p9.8.m8.3.4"><eq id="S4.SS1.p9.8.m8.3.4.1.cmml" xref="S4.SS1.p9.8.m8.3.4.1"></eq><apply id="S4.SS1.p9.8.m8.3.4.2.cmml" xref="S4.SS1.p9.8.m8.3.4.2"><ci id="S4.SS1.p9.8.m8.3.4.2.1.cmml" xref="S4.SS1.p9.8.m8.3.4.2.1">~</ci><ci id="S4.SS1.p9.8.m8.3.4.2.2.cmml" xref="S4.SS1.p9.8.m8.3.4.2.2">𝑅</ci></apply><apply id="S4.SS1.p9.8.m8.3.4.3.cmml" xref="S4.SS1.p9.8.m8.3.4.3"><times id="S4.SS1.p9.8.m8.3.4.3.1.cmml" xref="S4.SS1.p9.8.m8.3.4.3.1"></times><ci id="S4.SS1.p9.8.m8.3.4.3.2.cmml" xref="S4.SS1.p9.8.m8.3.4.3.2">ℎ</ci><vector id="S4.SS1.p9.8.m8.3.4.3.3.1.cmml" xref="S4.SS1.p9.8.m8.3.4.3.3.2"><ci id="S4.SS1.p9.8.m8.1.1.cmml" xref="S4.SS1.p9.8.m8.1.1">𝛼</ci><ci id="S4.SS1.p9.8.m8.2.2.cmml" xref="S4.SS1.p9.8.m8.2.2">𝛽</ci><cn id="S4.SS1.p9.8.m8.3.3.cmml" type="integer" xref="S4.SS1.p9.8.m8.3.3">0</cn></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.8.m8.3c">\tilde{R}=h(\alpha,\beta,0)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.8.m8.3d">over~ start_ARG italic_R end_ARG = italic_h ( italic_α , italic_β , 0 )</annotation></semantics></math> with <math alttext="h" class="ltx_Math" display="inline" id="S4.SS1.p9.9.m9.1"><semantics id="S4.SS1.p9.9.m9.1a"><mi id="S4.SS1.p9.9.m9.1.1" xref="S4.SS1.p9.9.m9.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.9.m9.1b"><ci id="S4.SS1.p9.9.m9.1.1.cmml" xref="S4.SS1.p9.9.m9.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.9.m9.1c">h</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.9.m9.1d">italic_h</annotation></semantics></math> being Euler-angle to rotation matrix transformation. The overlap between the query and the reference is measured by the geodesic distance (i.e., the pose difference in degree) between their in-plane-omitted rotation matrices <math alttext="\tilde{R_{q}}" class="ltx_Math" display="inline" id="S4.SS1.p9.10.m10.1"><semantics id="S4.SS1.p9.10.m10.1a"><mover accent="true" id="S4.SS1.p9.10.m10.1.1" xref="S4.SS1.p9.10.m10.1.1.cmml"><msub id="S4.SS1.p9.10.m10.1.1.2" xref="S4.SS1.p9.10.m10.1.1.2.cmml"><mi id="S4.SS1.p9.10.m10.1.1.2.2" xref="S4.SS1.p9.10.m10.1.1.2.2.cmml">R</mi><mi id="S4.SS1.p9.10.m10.1.1.2.3" xref="S4.SS1.p9.10.m10.1.1.2.3.cmml">q</mi></msub><mo id="S4.SS1.p9.10.m10.1.1.1" xref="S4.SS1.p9.10.m10.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.10.m10.1b"><apply id="S4.SS1.p9.10.m10.1.1.cmml" xref="S4.SS1.p9.10.m10.1.1"><ci id="S4.SS1.p9.10.m10.1.1.1.cmml" xref="S4.SS1.p9.10.m10.1.1.1">~</ci><apply id="S4.SS1.p9.10.m10.1.1.2.cmml" xref="S4.SS1.p9.10.m10.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p9.10.m10.1.1.2.1.cmml" xref="S4.SS1.p9.10.m10.1.1.2">subscript</csymbol><ci id="S4.SS1.p9.10.m10.1.1.2.2.cmml" xref="S4.SS1.p9.10.m10.1.1.2.2">𝑅</ci><ci id="S4.SS1.p9.10.m10.1.1.2.3.cmml" xref="S4.SS1.p9.10.m10.1.1.2.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.10.m10.1c">\tilde{R_{q}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.10.m10.1d">over~ start_ARG italic_R start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> and <math alttext="\tilde{R_{r}}" class="ltx_Math" display="inline" id="S4.SS1.p9.11.m11.1"><semantics id="S4.SS1.p9.11.m11.1a"><mover accent="true" id="S4.SS1.p9.11.m11.1.1" xref="S4.SS1.p9.11.m11.1.1.cmml"><msub id="S4.SS1.p9.11.m11.1.1.2" xref="S4.SS1.p9.11.m11.1.1.2.cmml"><mi id="S4.SS1.p9.11.m11.1.1.2.2" xref="S4.SS1.p9.11.m11.1.1.2.2.cmml">R</mi><mi id="S4.SS1.p9.11.m11.1.1.2.3" xref="S4.SS1.p9.11.m11.1.1.2.3.cmml">r</mi></msub><mo id="S4.SS1.p9.11.m11.1.1.1" xref="S4.SS1.p9.11.m11.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.11.m11.1b"><apply id="S4.SS1.p9.11.m11.1.1.cmml" xref="S4.SS1.p9.11.m11.1.1"><ci id="S4.SS1.p9.11.m11.1.1.1.cmml" xref="S4.SS1.p9.11.m11.1.1.1">~</ci><apply id="S4.SS1.p9.11.m11.1.1.2.cmml" xref="S4.SS1.p9.11.m11.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p9.11.m11.1.1.2.1.cmml" xref="S4.SS1.p9.11.m11.1.1.2">subscript</csymbol><ci id="S4.SS1.p9.11.m11.1.1.2.2.cmml" xref="S4.SS1.p9.11.m11.1.1.2.2">𝑅</ci><ci id="S4.SS1.p9.11.m11.1.1.2.3.cmml" xref="S4.SS1.p9.11.m11.1.1.2.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.11.m11.1c">\tilde{R_{r}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.11.m11.1d">over~ start_ARG italic_R start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> using Eq. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.E6" title="In IV-A Experimental Setups ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">6</span></a>). Finally, following DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, we select the sampled pairs with <math alttext="\tilde{D}" class="ltx_Math" display="inline" id="S4.SS1.p9.12.m12.1"><semantics id="S4.SS1.p9.12.m12.1a"><mover accent="true" id="S4.SS1.p9.12.m12.1.1" xref="S4.SS1.p9.12.m12.1.1.cmml"><mi id="S4.SS1.p9.12.m12.1.1.2" xref="S4.SS1.p9.12.m12.1.1.2.cmml">D</mi><mo id="S4.SS1.p9.12.m12.1.1.1" xref="S4.SS1.p9.12.m12.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.12.m12.1b"><apply id="S4.SS1.p9.12.m12.1.1.cmml" xref="S4.SS1.p9.12.m12.1.1"><ci id="S4.SS1.p9.12.m12.1.1.1.cmml" xref="S4.SS1.p9.12.m12.1.1.1">~</ci><ci id="S4.SS1.p9.12.m12.1.1.2.cmml" xref="S4.SS1.p9.12.m12.1.1.2">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.12.m12.1c">\tilde{D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.12.m12.1d">over~ start_ARG italic_D end_ARG</annotation></semantics></math> less than <math alttext="90^{\circ}" class="ltx_Math" display="inline" id="S4.SS1.p9.13.m13.1"><semantics id="S4.SS1.p9.13.m13.1a"><msup id="S4.SS1.p9.13.m13.1.1" xref="S4.SS1.p9.13.m13.1.1.cmml"><mn id="S4.SS1.p9.13.m13.1.1.2" xref="S4.SS1.p9.13.m13.1.1.2.cmml">90</mn><mo id="S4.SS1.p9.13.m13.1.1.3" xref="S4.SS1.p9.13.m13.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p9.13.m13.1b"><apply id="S4.SS1.p9.13.m13.1.1.cmml" xref="S4.SS1.p9.13.m13.1.1"><csymbol cd="ambiguous" id="S4.SS1.p9.13.m13.1.1.1.cmml" xref="S4.SS1.p9.13.m13.1.1">superscript</csymbol><cn id="S4.SS1.p9.13.m13.1.1.2.cmml" type="integer" xref="S4.SS1.p9.13.m13.1.1.2">90</cn><compose id="S4.SS1.p9.13.m13.1.1.3.cmml" xref="S4.SS1.p9.13.m13.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p9.13.m13.1c">90^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p9.13.m13.1d">90 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p10">
<p class="ltx_p" id="S4.SS1.p10.2">Following DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, for each object, we generate 1000 pairs for testing, and 20000 pairs for training DVMNet, 3DAHV, and RelPose++. Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.F4" title="Figure 4 ‣ IV-A Experimental Setups ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the histograms depicting the statistics of the pairwise pose difference (geodesic distance between rotation matrices <math alttext="R_{r}" class="ltx_Math" display="inline" id="S4.SS1.p10.1.m1.1"><semantics id="S4.SS1.p10.1.m1.1a"><msub id="S4.SS1.p10.1.m1.1.1" xref="S4.SS1.p10.1.m1.1.1.cmml"><mi id="S4.SS1.p10.1.m1.1.1.2" xref="S4.SS1.p10.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS1.p10.1.m1.1.1.3" xref="S4.SS1.p10.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p10.1.m1.1b"><apply id="S4.SS1.p10.1.m1.1.1.cmml" xref="S4.SS1.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p10.1.m1.1.1.1.cmml" xref="S4.SS1.p10.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p10.1.m1.1.1.2.cmml" xref="S4.SS1.p10.1.m1.1.1.2">𝑅</ci><ci id="S4.SS1.p10.1.m1.1.1.3.cmml" xref="S4.SS1.p10.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p10.1.m1.1c">R_{r}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p10.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="R_{q}" class="ltx_Math" display="inline" id="S4.SS1.p10.2.m2.1"><semantics id="S4.SS1.p10.2.m2.1a"><msub id="S4.SS1.p10.2.m2.1.1" xref="S4.SS1.p10.2.m2.1.1.cmml"><mi id="S4.SS1.p10.2.m2.1.1.2" xref="S4.SS1.p10.2.m2.1.1.2.cmml">R</mi><mi id="S4.SS1.p10.2.m2.1.1.3" xref="S4.SS1.p10.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p10.2.m2.1b"><apply id="S4.SS1.p10.2.m2.1.1.cmml" xref="S4.SS1.p10.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p10.2.m2.1.1.1.cmml" xref="S4.SS1.p10.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p10.2.m2.1.1.2.cmml" xref="S4.SS1.p10.2.m2.1.1.2">𝑅</ci><ci id="S4.SS1.p10.2.m2.1.1.3.cmml" xref="S4.SS1.p10.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p10.2.m2.1c">R_{q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p10.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>) on the three datasets. All the experiments are carried out on the same testing reference-query pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p11">
<p class="ltx_p" id="S4.SS1.p11.3"><span class="ltx_text ltx_font_bold" id="S4.SS1.p11.3.1">Implementation Details.</span> For semantic feature extraction, we employ the output tokens from the last layer of the DINOv2 ViT-L model <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib44" title=""><span class="ltx_text" style="font-size:80%;">dinov2</span> </a></cite>. We use nvdiffrast <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib25" title=""><span class="ltx_text" style="font-size:80%;">nvidiffrast</span> </a></cite> as our differentiable renderer. We uniformly sample <math alttext="m=200" class="ltx_Math" display="inline" id="S4.SS1.p11.1.m1.1"><semantics id="S4.SS1.p11.1.m1.1a"><mrow id="S4.SS1.p11.1.m1.1.1" xref="S4.SS1.p11.1.m1.1.1.cmml"><mi id="S4.SS1.p11.1.m1.1.1.2" xref="S4.SS1.p11.1.m1.1.1.2.cmml">m</mi><mo id="S4.SS1.p11.1.m1.1.1.1" xref="S4.SS1.p11.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p11.1.m1.1.1.3" xref="S4.SS1.p11.1.m1.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p11.1.m1.1b"><apply id="S4.SS1.p11.1.m1.1.1.cmml" xref="S4.SS1.p11.1.m1.1.1"><eq id="S4.SS1.p11.1.m1.1.1.1.cmml" xref="S4.SS1.p11.1.m1.1.1.1"></eq><ci id="S4.SS1.p11.1.m1.1.1.2.cmml" xref="S4.SS1.p11.1.m1.1.1.2">𝑚</ci><cn id="S4.SS1.p11.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p11.1.m1.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p11.1.m1.1c">m=200</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p11.1.m1.1d">italic_m = 200</annotation></semantics></math> viewpoints and <math alttext="n=20" class="ltx_Math" display="inline" id="S4.SS1.p11.2.m2.1"><semantics id="S4.SS1.p11.2.m2.1a"><mrow id="S4.SS1.p11.2.m2.1.1" xref="S4.SS1.p11.2.m2.1.1.cmml"><mi id="S4.SS1.p11.2.m2.1.1.2" xref="S4.SS1.p11.2.m2.1.1.2.cmml">n</mi><mo id="S4.SS1.p11.2.m2.1.1.1" xref="S4.SS1.p11.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p11.2.m2.1.1.3" xref="S4.SS1.p11.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p11.2.m2.1b"><apply id="S4.SS1.p11.2.m2.1.1.cmml" xref="S4.SS1.p11.2.m2.1.1"><eq id="S4.SS1.p11.2.m2.1.1.1.cmml" xref="S4.SS1.p11.2.m2.1.1.1"></eq><ci id="S4.SS1.p11.2.m2.1.1.2.cmml" xref="S4.SS1.p11.2.m2.1.1.2">𝑛</ci><cn id="S4.SS1.p11.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.p11.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p11.2.m2.1c">n=20</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p11.2.m2.1d">italic_n = 20</annotation></semantics></math> in-plane rotations (resulting in 4000 initialization candidates), the maximal iteration number for differentiable rendering is set to <math alttext="N=30" class="ltx_Math" display="inline" id="S4.SS1.p11.3.m3.1"><semantics id="S4.SS1.p11.3.m3.1a"><mrow id="S4.SS1.p11.3.m3.1.1" xref="S4.SS1.p11.3.m3.1.1.cmml"><mi id="S4.SS1.p11.3.m3.1.1.2" xref="S4.SS1.p11.3.m3.1.1.2.cmml">N</mi><mo id="S4.SS1.p11.3.m3.1.1.1" xref="S4.SS1.p11.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p11.3.m3.1.1.3" xref="S4.SS1.p11.3.m3.1.1.3.cmml">30</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p11.3.m3.1b"><apply id="S4.SS1.p11.3.m3.1.1.cmml" xref="S4.SS1.p11.3.m3.1.1"><eq id="S4.SS1.p11.3.m3.1.1.1.cmml" xref="S4.SS1.p11.3.m3.1.1.1"></eq><ci id="S4.SS1.p11.3.m3.1.1.2.cmml" xref="S4.SS1.p11.3.m3.1.1.2">𝑁</ci><cn id="S4.SS1.p11.3.m3.1.1.3.cmml" type="integer" xref="S4.SS1.p11.3.m3.1.1.3">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p11.3.m3.1c">N=30</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p11.3.m3.1d">italic_N = 30</annotation></semantics></math>. To backpropagate the refinement losses, we use an Adam optimizer <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib22" title=""><span class="ltx_text" style="font-size:80%;">adam</span> </a></cite> of 0.01 initial learning rate and decay by a <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p11.3.2">ReduceLROnPlateau</span> scheduler. All the experiments are conducted on a single NVIDIA 4090 GPU.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.5.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.6.2">Experimental Results on the LineMOD Dataset</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The results on the LineMOD dataset are illustrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T2" title="TABLE II ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">II</span></a>. We paste the performances of RelPose++ from the 3DAHV paper <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>. We leave the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.1">Acc@5/10<sup class="ltx_sup" id="S4.SS2.p1.1.1.1"><span class="ltx_text ltx_font_serif" id="S4.SS2.p1.1.1.1.1">∘</span></sup></span> performance of RelPose++ blank as those were not reported in <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> and the (pre-) training code of RelPose++ on the external large-scale Objaverse dataset is not available.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T2" title="TABLE II ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">II</span></a> shows that our <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.2">label and training-free</em> method significantly outperforms the <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.3">supervised</em> state-of-the-art DVMNet w.r.t. all the metrics. In addition, the state-of-the-art methods DVMNet and 3DAHV face challenges in generalizing across different datasets, i.e., their in-dataset results substantially outperform their cross-dataset counterparts. In contrast, our approach, without training a network, inherently generalizes across diverse datasets directly. Especially, our method significantly outperforms DVMNet (in-dataset) for 21.6% and 32.08% w.r.t. the rigorous <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p2.1.1">Acc@5/10<sup class="ltx_sup" id="S4.SS2.p2.1.1.1"><span class="ltx_text ltx_font_serif" id="S4.SS2.p2.1.1.1.1">∘</span></sup></span>. The qualitative results of our method are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.F5" title="Figure 5 ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">5</span></a>, and comparisons with different methods are presented in Fig. S3 of the supplementary material. Our results on all the LineMOD objects are detailed in Table S3 of the supplementary material.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span><span class="ltx_text ltx_font_bold" id="S4.T2.13.2">Experimental results on LineMOD.</span> We illustrate both the experimental settings and the performance. In the <span class="ltx_text ltx_font_bold" id="S4.T2.14.3">RGB-D</span> category, <span class="ltx_text ltx_font_bold" id="S4.T2.15.4">both</span> means requiring RGB-D image for both query and reference. <span class="ltx_text ltx_font_typewriter" id="S4.T2.3.1">Acc@<math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.T2.3.1.m1.1"><semantics id="S4.T2.3.1.m1.1b"><msup id="S4.T2.3.1.m1.1.1" xref="S4.T2.3.1.m1.1.1.cmml"><mi id="S4.T2.3.1.m1.1.1.2" xref="S4.T2.3.1.m1.1.1.2.cmml">t</mi><mo id="S4.T2.3.1.m1.1.1.3" xref="S4.T2.3.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.3.1.m1.1c"><apply id="S4.T2.3.1.m1.1.1.cmml" xref="S4.T2.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.1.m1.1.1.1.cmml" xref="S4.T2.3.1.m1.1.1">superscript</csymbol><ci id="S4.T2.3.1.m1.1.1.2.cmml" xref="S4.T2.3.1.m1.1.1.2">𝑡</ci><compose id="S4.T2.3.1.m1.1.1.3.cmml" xref="S4.T2.3.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.1.m1.1d">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.1.m1.1e">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math></span> measures the percentage of the estimated pose within <math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.T2.4.m1.1"><semantics id="S4.T2.4.m1.1b"><msup id="S4.T2.4.m1.1.1" xref="S4.T2.4.m1.1.1.cmml"><mi id="S4.T2.4.m1.1.1.2" xref="S4.T2.4.m1.1.1.2.cmml">t</mi><mo id="S4.T2.4.m1.1.1.3" xref="S4.T2.4.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.4.m1.1c"><apply id="S4.T2.4.m1.1.1.cmml" xref="S4.T2.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.m1.1.1.1.cmml" xref="S4.T2.4.m1.1.1">superscript</csymbol><ci id="S4.T2.4.m1.1.1.2.cmml" xref="S4.T2.4.m1.1.1.2">𝑡</ci><compose id="S4.T2.4.m1.1.1.3.cmml" xref="S4.T2.4.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.m1.1d">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.m1.1e">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> w.r.t. the ground-truth.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.9" style="width:303.5pt;height:125.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-88.0pt,36.3pt) scale(0.633018135082301,0.633018135082301) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.9.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.5.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt" id="S4.T2.5.1.1.2" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S4.T2.5.1.1.2.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="3" id="S4.T2.5.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Settings</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T2.5.1.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">Error↓</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T2.5.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Acc @ <math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.T2.5.1.1.1.m1.1"><semantics id="S4.T2.5.1.1.1.m1.1a"><msup id="S4.T2.5.1.1.1.m1.1.1" xref="S4.T2.5.1.1.1.m1.1.1.cmml"><mi id="S4.T2.5.1.1.1.m1.1.1.2" xref="S4.T2.5.1.1.1.m1.1.1.2.cmml">t</mi><mo id="S4.T2.5.1.1.1.m1.1.1.3" xref="S4.T2.5.1.1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.5.1.1.1.m1.1b"><apply id="S4.T2.5.1.1.1.m1.1.1.cmml" xref="S4.T2.5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.1.1.1.m1.1.1.1.cmml" xref="S4.T2.5.1.1.1.m1.1.1">superscript</csymbol><ci id="S4.T2.5.1.1.1.m1.1.1.2.cmml" xref="S4.T2.5.1.1.1.m1.1.1.2">𝑡</ci><compose id="S4.T2.5.1.1.1.m1.1.1.3.cmml" xref="S4.T2.5.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.1.1.1.m1.1c">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.1.1.1.m1.1d">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> (%) ↑</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">Training</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">Label</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T2.9.5.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">RGB-D</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.9.5.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">Mean Err</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">30<sup class="ltx_sup" id="S4.T2.6.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.6.2.2.1.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.3.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">15<sup class="ltx_sup" id="S4.T2.7.3.3.2.1"><span class="ltx_text ltx_font_italic" id="S4.T2.7.3.3.2.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.8.4.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">10<sup class="ltx_sup" id="S4.T2.8.4.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T2.8.4.4.3.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">5<sup class="ltx_sup" id="S4.T2.9.5.5.4.1"><span class="ltx_text ltx_font_italic" id="S4.T2.9.5.5.4.1.1">∘</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T2.9.5.6.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">ZSP</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.9.5.6.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_ERROR undefined" id="S4.T2.9.5.6.1.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.6.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T2.9.5.6.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">both</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.9.5.6.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">102.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.6.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">8.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.6.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.6.1.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.6.1.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.18</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T2.9.5.7.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LoFTR</th>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.7.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.7.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose+depth</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T2.9.5.7.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.9.5.7.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">63.88</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.7.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.94</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.7.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">10.80</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.7.2.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">6.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.7.2.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.42</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T2.9.5.8.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">RelPose++</th>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.8.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.8.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T2.9.5.8.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.9.5.8.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">46.60</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.8.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.50</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.8.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">15.80</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.8.3.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.8.3.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T2.9.5.9.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">3DAHV (cross-dataset)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.9.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.9.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T2.9.5.9.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.9.5.9.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">69.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.9.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">21.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.9.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">5.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.9.4.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.9.4.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.44</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T2.9.5.10.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">3DAHV (in-dataset)</th>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.10.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.10.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T2.9.5.10.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.9.5.10.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">42.77</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.10.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">59.16</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.10.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">25.92</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.10.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">11.36</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.10.5.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.16</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T2.9.5.11.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DVMNet (cross-dataset)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.11.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.11.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T2.9.5.11.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.9.5.11.6.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">47.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.11.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">36.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.11.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">13.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.11.6.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">5.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.11.6.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.08</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.12.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T2.9.5.12.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DVMNet (in-dataset)</th>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.12.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.12.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T2.9.5.12.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.9.5.12.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">33.28</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.12.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">55.02</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.12.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">22.38</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.12.7.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">10.66</td>
<td class="ltx_td ltx_align_center" id="S4.T2.9.5.12.7.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.72</td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.13.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T2.9.5.13.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Ours (init. only)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.13.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_ERROR undefined" id="S4.T2.9.5.13.8.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.13.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T2.9.5.13.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">reference</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.9.5.13.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.9.5.13.8.5.1">32.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.13.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.9.5.13.8.6.1">70.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.13.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.9.5.13.8.7.1">48.28</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.13.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.9.5.13.8.8.1">29.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.9.5.13.8.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.9.5.13.8.9.1">6.66</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.9.5.14.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S4.T2.9.5.14.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Ours (init. + refine)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.9.5.14.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_ERROR undefined" id="S4.T2.9.5.14.9.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.9.5.14.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="S4.T2.9.5.14.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">reference</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.9.5.14.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T2.9.5.14.9.5.1">29.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.9.5.14.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T2.9.5.14.9.6.1">72.06</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.9.5.14.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T2.9.5.14.9.7.1">54.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.9.5.14.9.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T2.9.5.14.9.8.1">42.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.9.5.14.9.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T2.9.5.14.9.9.1">24.32</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S4.F5">
<p class="ltx_p ltx_align_center" id="S4.F5.1"><span class="ltx_text" id="S4.F5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="232" id="S4.F5.1.1.g1" src="x5.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S4.F5.3.1">Qualitative results on LineMOD.</span> This figure shows that our method can handle partially occluded and texture-less objects. We use a 3D bbox to denote poses.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.5.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.6.2">Experimental Results on the YCB-V Dataset</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To compare with the state-of-the-art DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>, 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite> and RelPose++ <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib32" title=""><span class="ltx_text" style="font-size:80%;">relpose++</span> </a></cite>, we follow the protocols discussed in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.SS1" title="IV-A Experimental Setups ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a> (In-dataset and Cross-dataset Evaluation) to obtain the in-dataset and cross-dataset performance of DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite> and 3DAHV <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib77" title=""><span class="ltx_text" style="font-size:80%;">3DAHV</span> </a></cite>, while RelPose++ is trained on the YCB-V dataset only. The performance on the YCB-V dataset is reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T3" title="TABLE III ‣ IV-C Experimental Results on the YCB-V Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">III</span></a>, where our method exhibits a significant improvement of 11.02% and 17.83% w.r.t. the state-of-the-art DVMNet (in-dataset), respectively on the challenging <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.1">Acc@5/10<sup class="ltx_sup" id="S4.SS3.p1.1.1.1"><span class="ltx_text ltx_font_serif" id="S4.SS3.p1.1.1.1.1">∘</span></sup></span> metrics. We showcase the qualitative results of our method on the YCB-V dataset in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.F6" title="Figure 6 ‣ IV-C Experimental Results on the YCB-V Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">6</span></a>, and those across different methods can be found in Fig. S2 of the supplementary material. Our results on all the YCB-V objects are shown in Table S5 of the supplementary material.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span><span class="ltx_text ltx_font_bold" id="S4.T3.7.1">Experimental results on YCB-V.</span> The performance of DVMNet, 3DAHV, and RelPose++ is obtained by training on a leave-out subset of 13 objects. Other parameters/symbols are the same as those in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T2" title="TABLE II ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">II</span></a>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.5" style="width:303.5pt;height:125.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-88.0pt,36.3pt) scale(0.633018135082301,0.633018135082301) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt" id="S4.T3.1.1.1.2" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text" id="S4.T3.1.1.1.2.1">Method</span></th>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" colspan="3" id="S4.T3.1.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">Settings</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">Error↓</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T3.1.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Acc @ <math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><msup id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.1.m1.1.1.2.cmml">t</mi><mo id="S4.T3.1.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S4.T3.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.1.m1.1.1.2">𝑡</ci><compose id="S4.T3.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> (%) ↑</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">Training</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">Label</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T3.5.5.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">RGB-D</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">Mean Err</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">30<sup class="ltx_sup" id="S4.T3.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.2.2.2.1.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.3.3.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">15<sup class="ltx_sup" id="S4.T3.3.3.3.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.3.3.3.2.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.4.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">10<sup class="ltx_sup" id="S4.T3.4.4.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.4.4.4.3.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">5<sup class="ltx_sup" id="S4.T3.5.5.5.4.1"><span class="ltx_text ltx_font_italic" id="S4.T3.5.5.5.4.1.1">∘</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.5.5.6.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">ZSP</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.6.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_ERROR undefined" id="S4.T3.5.5.6.1.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.6.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T3.5.5.6.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">both</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.6.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">88.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.6.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">15.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.6.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">5.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.6.1.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.6.1.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.65</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T3.5.5.7.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">LoFTR</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.7.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.7.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose+depth</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T3.5.5.7.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.5.5.7.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">68.65</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.7.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">29.45</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.7.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">13.56</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.7.2.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">7.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.7.2.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">3.19</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T3.5.5.8.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">RelPose++</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.8.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.8.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T3.5.5.8.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.5.5.8.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">57.41</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.8.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">23.60</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.8.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">7.13</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.8.3.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">3.28</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.8.3.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.76</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.5.5.9.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">3DAHV (cross-dataset)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.9.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.9.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T3.5.5.9.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.9.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">66.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.9.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">35.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.9.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">16.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.9.4.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">8.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.9.4.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">1.50</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T3.5.5.10.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">3DAHV (in-dataset)</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.10.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.10.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T3.5.5.10.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.5.5.10.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">69.48</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.10.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">44.54</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.10.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">28.41</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.10.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">16.29</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.10.5.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">3.59</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.5.5.11.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DVMNet (cross-dataset)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.11.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.11.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T3.5.5.11.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.11.6.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">54.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.11.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">41.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.11.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">17.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.11.6.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">9.35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.11.6.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">2.53</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.12.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T3.5.5.12.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">DVMNet (in-dataset)</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.12.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.12.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T3.5.5.12.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.5.5.12.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">48.88</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.12.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">51.71</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.12.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.04</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.12.7.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">14.03</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.5.12.7.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">3.16</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.13.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.5.5.13.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Ours (init. only)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.13.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_ERROR undefined" id="S4.T3.5.5.13.8.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.13.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T3.5.5.13.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">reference</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.5.5.13.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.5.5.13.8.5.1">48.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.13.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.5.5.13.8.6.1">56.59</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.13.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.5.5.13.8.7.1">35.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.13.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.5.5.13.8.8.1">21.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.13.8.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T3.5.5.13.8.9.1">5.36</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.14.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S4.T3.5.5.14.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Ours (init. + refine)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.14.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_ERROR undefined" id="S4.T3.5.5.14.9.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.14.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="S4.T3.5.5.14.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">reference</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.5.5.14.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T3.5.5.14.9.5.1">47.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.14.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T3.5.5.14.9.6.1">56.63</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.14.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T3.5.5.14.9.7.1">42.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.14.9.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T3.5.5.14.9.8.1">31.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.14.9.9" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T3.5.5.14.9.9.1">14.18</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S4.F6">
<p class="ltx_p ltx_align_center" id="S4.F6.1"><span class="ltx_text" id="S4.F6.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="232" id="S4.F6.1.1.g1" src="x6.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="S4.F6.3.1">Qualitative results on YCB-V.</span> This figure shows that our method can handle partially occluded and texture-less objects. We use a 3D bbox to denote poses.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.5.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.6.2">Experimental Results on the LM-O Dataset</span>
</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Finally, we carry out the experiments on the challenging LM-O Dataset with severe occlusions. Following DVMNet <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib76" title=""><span class="ltx_text" style="font-size:80%;">zhao2024dvmnet</span> </a></cite>, we conduct the experiments on three unseen objects of the LM-O dataset, i.e., cat, driller, and duck. We note that the LM-O dataset is typically used solely for evaluation. Therefore, the results of DVMNet and 3DAHV are evaluated utilizing the weights finetuned on LineMOD. Nevertheless, since the weights of RelPose++ for the LineMOD dataset have not been released yet and LM-O (with only 8 objects) cannot provide sufficient leave-out data to train RelPose++, we thus do not include RelPose++ for comparison. The results from Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T4" title="TABLE IV ‣ IV-D Experimental Results on the LM-O Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">IV</span></a> demonstrate the promising performance of our method on the severely occluded LM-O dataset. We showcase our performance on the LM-O dataset in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.F7" title="Figure 7 ‣ IV-D Experimental Results on the LM-O Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">7</span></a>, and those across different methods are illustrated in Fig. S2 of the supplementary material. Our results on all the LM-O objects can be found in Table S4 of the supplementary material.</p>
</div>
<figure class="ltx_figure" id="S4.F7">
<p class="ltx_p ltx_align_center" id="S4.F7.1"><span class="ltx_text" id="S4.F7.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="232" id="S4.F7.1.1.g1" src="x7.png" width="830"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_bold" id="S4.F7.3.1">Qualitative results on LM-O.</span> This figure shows that our method can handle severely occluded and texture-less objects. We use a 3D bbox to denote poses.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.3">We observe that our results in terms of <em class="ltx_emph ltx_font_italic" id="S4.SS4.p2.3.1">Mean Err</em> are inferior to the in-dataset results of the state-of-the-art DVMNet and 3DAHV (though our method exhibits better Acc@<math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.SS4.p2.1.m1.1"><semantics id="S4.SS4.p2.1.m1.1a"><msup id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mi id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml">t</mi><mo id="S4.SS4.p2.1.m1.1.1.3" xref="S4.SS4.p2.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">𝑡</ci><compose id="S4.SS4.p2.1.m1.1.1.3.cmml" xref="S4.SS4.p2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.1.m1.1d">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> results). This can be attributed to the extensive occlusions presented in the LM-O dataset, which lead to numerous testing pairs lacking adequate overlap. Consequently, those testing pairs are difficult to handle by all the methods (and also challenging for humans). We show those samples as failure cases in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.F8" title="Figure 8 ‣ V-E Illustrations of the Failure Cases ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">8</span></a> of Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS5" title="V-E Illustrations of the Failure Cases ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-E</span></span></a>, as well as investigating the angle error distribution (ranging from 0 to 180 degrees) on the LM-O dataset in Fig. S1 of the supplementary materials. The statistics reveal that at lower angle error thresholds (e.g., for <math alttext="t\leq 10,20" class="ltx_Math" display="inline" id="S4.SS4.p2.2.m2.2"><semantics id="S4.SS4.p2.2.m2.2a"><mrow id="S4.SS4.p2.2.m2.2.3" xref="S4.SS4.p2.2.m2.2.3.cmml"><mi id="S4.SS4.p2.2.m2.2.3.2" xref="S4.SS4.p2.2.m2.2.3.2.cmml">t</mi><mo id="S4.SS4.p2.2.m2.2.3.1" xref="S4.SS4.p2.2.m2.2.3.1.cmml">≤</mo><mrow id="S4.SS4.p2.2.m2.2.3.3.2" xref="S4.SS4.p2.2.m2.2.3.3.1.cmml"><mn id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">10</mn><mo id="S4.SS4.p2.2.m2.2.3.3.2.1" xref="S4.SS4.p2.2.m2.2.3.3.1.cmml">,</mo><mn id="S4.SS4.p2.2.m2.2.2" xref="S4.SS4.p2.2.m2.2.2.cmml">20</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.2b"><apply id="S4.SS4.p2.2.m2.2.3.cmml" xref="S4.SS4.p2.2.m2.2.3"><leq id="S4.SS4.p2.2.m2.2.3.1.cmml" xref="S4.SS4.p2.2.m2.2.3.1"></leq><ci id="S4.SS4.p2.2.m2.2.3.2.cmml" xref="S4.SS4.p2.2.m2.2.3.2">𝑡</ci><list id="S4.SS4.p2.2.m2.2.3.3.1.cmml" xref="S4.SS4.p2.2.m2.2.3.3.2"><cn id="S4.SS4.p2.2.m2.1.1.cmml" type="integer" xref="S4.SS4.p2.2.m2.1.1">10</cn><cn id="S4.SS4.p2.2.m2.2.2.cmml" type="integer" xref="S4.SS4.p2.2.m2.2.2">20</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.2c">t\leq 10,20</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.2.m2.2d">italic_t ≤ 10 , 20</annotation></semantics></math> in Acc@<math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.SS4.p2.3.m3.1"><semantics id="S4.SS4.p2.3.m3.1a"><msup id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml"><mi id="S4.SS4.p2.3.m3.1.1.2" xref="S4.SS4.p2.3.m3.1.1.2.cmml">t</mi><mo id="S4.SS4.p2.3.m3.1.1.3" xref="S4.SS4.p2.3.m3.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><apply id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p2.3.m3.1.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1">superscript</csymbol><ci id="S4.SS4.p2.3.m3.1.1.2.cmml" xref="S4.SS4.p2.3.m3.1.1.2">𝑡</ci><compose id="S4.SS4.p2.3.m3.1.1.3.cmml" xref="S4.SS4.p2.3.m3.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.3.m3.1d">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>), our approach substantially outperforms both DVMNet and 3DAHV. This indicates that for test pairs with sufficient overlaps (i.e., match-able testing pairs), our method delivers superior performance compared to the state-of-the-art DVMNet and 3DAHV.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span><span class="ltx_text ltx_font_bold" id="S4.T4.7.1">Experimental results on LM-O.</span> LM-O is typically used solely for testing with only 8 objects under severe occlusions. The results of DVMNet and 3DAHV are tested directly using the weights trained on LineMOD. Since the model weights of RelPose++ used in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T2" title="TABLE II ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">II</span></a> were not released, we do not compare our method with RelPose++ in this experiment. Other parameters/symbols are the same as those in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S4.T2" title="TABLE II ‣ IV-B Experimental Results on the LineMOD Dataset ‣ IV Experiments ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">II</span></a>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.5" style="width:303.5pt;height:115.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-85.5pt,32.4pt) scale(0.639688515375176,0.639688515375176) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S4.T4.1.1.1.2" rowspan="2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S4.T4.1.1.1.2.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_tt" colspan="3" id="S4.T4.1.1.1.3" style="padding-top:1pt;padding-bottom:1pt;">Settings</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T4.1.1.1.4" style="padding-top:1pt;padding-bottom:1pt;">Error↓</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S4.T4.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.m1.1a"><msup id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.1.m1.1.1.2.cmml">t</mi><mo id="S4.T4.1.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.1.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S4.T4.1.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.1.m1.1.1.2">𝑡</ci><compose id="S4.T4.1.1.1.1.m1.1.1.3.cmml" xref="S4.T4.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.m1.1d">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> (%) ↑</th>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.5.5.5" style="padding-top:1pt;padding-bottom:1pt;">Training</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.5.5.6" style="padding-top:1pt;padding-bottom:1pt;">Label</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" id="S4.T4.5.5.5.7" style="padding-top:1pt;padding-bottom:1pt;">RGB-D</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.5.5.5.8" style="padding-top:1pt;padding-bottom:1pt;">Mean Err</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.2.2.2.1" style="padding-top:1pt;padding-bottom:1pt;">30<sup class="ltx_sup" id="S4.T4.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.2.2.2.1.1.1">∘</span></sup>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.3.3.3.2" style="padding-top:1pt;padding-bottom:1pt;">15<sup class="ltx_sup" id="S4.T4.3.3.3.2.1"><span class="ltx_text ltx_font_italic" id="S4.T4.3.3.3.2.1.1">∘</span></sup>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.4.4.4.3" style="padding-top:1pt;padding-bottom:1pt;">10<sup class="ltx_sup" id="S4.T4.4.4.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T4.4.4.4.3.1.1">∘</span></sup>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.5.5.5.4" style="padding-top:1pt;padding-bottom:1pt;">5<sup class="ltx_sup" id="S4.T4.5.5.5.4.1"><span class="ltx_text ltx_font_italic" id="S4.T4.5.5.5.4.1.1">∘</span></sup>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.5.5.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T4.5.5.6.1.1" style="padding-top:1pt;padding-bottom:1pt;">ZSP</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.6.1.2" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_ERROR undefined" id="S4.T4.5.5.6.1.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.6.1.3" style="padding-top:1pt;padding-bottom:1pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T4.5.5.6.1.4" style="padding-top:1pt;padding-bottom:1pt;">both</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.5.6.1.5" style="padding-top:1pt;padding-bottom:1pt;">103.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.6.1.6" style="padding-top:1pt;padding-bottom:1pt;">7.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.6.1.7" style="padding-top:1pt;padding-bottom:1pt;">1.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.6.1.8" style="padding-top:1pt;padding-bottom:1pt;">0.60</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.6.1.9" style="padding-top:1pt;padding-bottom:1pt;">0.07</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T4.5.5.7.2.1" style="padding-top:1pt;padding-bottom:1pt;">LoFTR</th>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.7.2.2" style="padding-top:1pt;padding-bottom:1pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.7.2.3" style="padding-top:1pt;padding-bottom:1pt;">pose+depth</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T4.5.5.7.2.4" style="padding-top:1pt;padding-bottom:1pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.5.7.2.5" style="padding-top:1pt;padding-bottom:1pt;">68.15</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.7.2.6" style="padding-top:1pt;padding-bottom:1pt;">20.63</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.7.2.7" style="padding-top:1pt;padding-bottom:1pt;">9.00</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.7.2.8" style="padding-top:1pt;padding-bottom:1pt;">4.87</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.7.2.9" style="padding-top:1pt;padding-bottom:1pt;">1.87</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T4.5.5.8.3.1" style="padding-top:1pt;padding-bottom:1pt;">3DAHV (cross-dataset)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.8.3.2" style="padding-top:1pt;padding-bottom:1pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.8.3.3" style="padding-top:1pt;padding-bottom:1pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T4.5.5.8.3.4" style="padding-top:1pt;padding-bottom:1pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.5.8.3.5" style="padding-top:1pt;padding-bottom:1pt;">55.05</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.8.3.6" style="padding-top:1pt;padding-bottom:1pt;">32.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.8.3.7" style="padding-top:1pt;padding-bottom:1pt;">9.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.8.3.8" style="padding-top:1pt;padding-bottom:1pt;">4.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.8.3.9" style="padding-top:1pt;padding-bottom:1pt;">0.53</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T4.5.5.9.4.1" style="padding-top:1pt;padding-bottom:1pt;">3DAHV (in-dataset)</th>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.9.4.2" style="padding-top:1pt;padding-bottom:1pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.9.4.3" style="padding-top:1pt;padding-bottom:1pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T4.5.5.9.4.4" style="padding-top:1pt;padding-bottom:1pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.5.9.4.5" style="padding-top:1pt;padding-bottom:1pt;">62.30</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.9.4.6" style="padding-top:1pt;padding-bottom:1pt;">40.29</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.9.4.7" style="padding-top:1pt;padding-bottom:1pt;">10.57</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.9.4.8" style="padding-top:1pt;padding-bottom:1pt;">3.84</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.9.4.9" style="padding-top:1pt;padding-bottom:1pt;">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T4.5.5.10.5.1" style="padding-top:1pt;padding-bottom:1pt;">DVMNet (cross-dataset)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.10.5.2" style="padding-top:1pt;padding-bottom:1pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.10.5.3" style="padding-top:1pt;padding-bottom:1pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T4.5.5.10.5.4" style="padding-top:1pt;padding-bottom:1pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.5.10.5.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.5.10.5.5.1">51.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.10.5.6" style="padding-top:1pt;padding-bottom:1pt;">35.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.10.5.7" style="padding-top:1pt;padding-bottom:1pt;">12.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.10.5.8" style="padding-top:1pt;padding-bottom:1pt;">5.30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.10.5.9" style="padding-top:1pt;padding-bottom:1pt;">1.33</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S4.T4.5.5.11.6.1" style="padding-top:1pt;padding-bottom:1pt;">DVMNet (in-dataset)</th>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.11.6.2" style="padding-top:1pt;padding-bottom:1pt;">✓</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.11.6.3" style="padding-top:1pt;padding-bottom:1pt;">pose</td>
<td class="ltx_td ltx_align_center ltx_border_rr" id="S4.T4.5.5.11.6.4" style="padding-top:1pt;padding-bottom:1pt;">no</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.5.11.6.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T4.5.5.11.6.5.1">48.55</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.11.6.6" style="padding-top:1pt;padding-bottom:1pt;">38.62</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.11.6.7" style="padding-top:1pt;padding-bottom:1pt;">14.14</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.11.6.8" style="padding-top:1pt;padding-bottom:1pt;">7.37</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.5.11.6.9" style="padding-top:1pt;padding-bottom:1pt;">1.87</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.12.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T4.5.5.12.7.1" style="padding-top:1pt;padding-bottom:1pt;">Ours (init. only)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.12.7.2" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_ERROR undefined" id="S4.T4.5.5.12.7.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.12.7.3" style="padding-top:1pt;padding-bottom:1pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T4.5.5.12.7.4" style="padding-top:1pt;padding-bottom:1pt;">reference</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.5.12.7.5" style="padding-top:1pt;padding-bottom:1pt;">55.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.12.7.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.5.12.7.6.1">53.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.12.7.7" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.5.12.7.7.1">31.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.12.7.8" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.5.12.7.8.1">17.18</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.12.7.9" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.5.5.12.7.9.1">2.80</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.13.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S4.T4.5.5.13.8.1" style="padding-top:1pt;padding-bottom:1pt;">Ours (init. + refine)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.5.13.8.2" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_ERROR undefined" id="S4.T4.5.5.13.8.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.5.13.8.3" style="padding-top:1pt;padding-bottom:1pt;">label-free</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr" id="S4.T4.5.5.13.8.4" style="padding-top:1pt;padding-bottom:1pt;">reference</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.5.5.13.8.5" style="padding-top:1pt;padding-bottom:1pt;">55.09</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.5.13.8.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T4.5.5.13.8.6.1">54.50</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.5.13.8.7" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T4.5.5.13.8.7.1">34.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.5.13.8.8" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T4.5.5.13.8.8.1">23.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.5.13.8.9" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T4.5.5.13.8.9.1">6.83</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Ablation Analysis</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We carefully investigate the following issues by ablation: 1) the contribution of each comprising element of our method, including <em class="ltx_emph ltx_font_italic" id="S5.p1.1.1">the back-surface culling</em>, and the usage of <em class="ltx_emph ltx_font_italic" id="S5.p1.1.2">RGB</em> or <em class="ltx_emph ltx_font_italic" id="S5.p1.1.3">semantic</em> modality in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS1" title="V-A The Contributions of the Proposed Comprising Elements ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a>; 2) the effects of different initialization strategies in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS2" title="V-B Effects of Different Initialization Strategies ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a>; 3) the effects of different refinement iterations in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS3" title="V-C Effects of Different Refinement Iterations. ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span></span></a>; 4) the inference time statistics of our method in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS4" title="V-D The Statistics of Our Inference Time ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-D</span></span></a>; and 5) the failure cases illustrations from the LM-O dataset in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.SS5" title="V-E Illustrations of the Failure Cases ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-E</span></span></a>.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.5.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.6.2">The Contributions of the Proposed Comprising Elements</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Despite the simplicity of our method, we are interested in investigating the influences for each of our comprising elements, namely <em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.1">the back-surface culling</em>, and the usage of <em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.2">RGB</em> or <em class="ltx_emph ltx_font_italic" id="S5.SS1.p1.1.3">semantic</em> modality. We perform those ablations on the LineMOD, and the results are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T5" title="TABLE V ‣ V-A The Contributions of the Proposed Comprising Elements ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">As expected, removing each of our comprising elements results in a decreased performance, because all of them are exploited with clear motivations. Nonetheless, the encouraging observation is that our method is able to deliver promising results using only the <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">RGB</span> modality without the <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.2">semantic</span> map. This further extends the applicability of our method when the pretrained DINOv2 model is not available or when the DINOv2 model cannot produce reasonable outputs (though the latter case could be rare).</p>
</div>
<figure class="ltx_table" id="S5.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE V: </span>The contributions of <span class="ltx_text ltx_font_bold" id="S5.T5.6.1">the proposed comprising elements</span> on the LineMOD dataset.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T5.4" style="width:433.6pt;height:106.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(33.8pt,-8.3pt) scale(1.18455432319694,1.18455432319694) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T5.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T5.4.4.4.5" style="padding-top:1pt;padding-bottom:1pt;">Metrics</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.4.4.6" style="padding-top:1pt;padding-bottom:1pt;">Mean Err↓</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="30^{\circ}" class="ltx_Math" display="inline" id="S5.T5.1.1.1.1.m1.1"><semantics id="S5.T5.1.1.1.1.m1.1a"><msup id="S5.T5.1.1.1.1.m1.1.1" xref="S5.T5.1.1.1.1.m1.1.1.cmml"><mn id="S5.T5.1.1.1.1.m1.1.1.2" xref="S5.T5.1.1.1.1.m1.1.1.2.cmml">30</mn><mo id="S5.T5.1.1.1.1.m1.1.1.3" xref="S5.T5.1.1.1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.1.m1.1b"><apply id="S5.T5.1.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.1.1.1.1.m1.1.1.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1">superscript</csymbol><cn id="S5.T5.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="S5.T5.1.1.1.1.m1.1.1.2">30</cn><compose id="S5.T5.1.1.1.1.m1.1.1.3.cmml" xref="S5.T5.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.1.m1.1c">30^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T5.1.1.1.1.m1.1d">30 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="15^{\circ}" class="ltx_Math" display="inline" id="S5.T5.2.2.2.2.m1.1"><semantics id="S5.T5.2.2.2.2.m1.1a"><msup id="S5.T5.2.2.2.2.m1.1.1" xref="S5.T5.2.2.2.2.m1.1.1.cmml"><mn id="S5.T5.2.2.2.2.m1.1.1.2" xref="S5.T5.2.2.2.2.m1.1.1.2.cmml">15</mn><mo id="S5.T5.2.2.2.2.m1.1.1.3" xref="S5.T5.2.2.2.2.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.2.m1.1b"><apply id="S5.T5.2.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.2.2.2.2.m1.1.1.1.cmml" xref="S5.T5.2.2.2.2.m1.1.1">superscript</csymbol><cn id="S5.T5.2.2.2.2.m1.1.1.2.cmml" type="integer" xref="S5.T5.2.2.2.2.m1.1.1.2">15</cn><compose id="S5.T5.2.2.2.2.m1.1.1.3.cmml" xref="S5.T5.2.2.2.2.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.2.m1.1c">15^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T5.2.2.2.2.m1.1d">15 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.3.3.3.3" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="10^{\circ}" class="ltx_Math" display="inline" id="S5.T5.3.3.3.3.m1.1"><semantics id="S5.T5.3.3.3.3.m1.1a"><msup id="S5.T5.3.3.3.3.m1.1.1" xref="S5.T5.3.3.3.3.m1.1.1.cmml"><mn id="S5.T5.3.3.3.3.m1.1.1.2" xref="S5.T5.3.3.3.3.m1.1.1.2.cmml">10</mn><mo id="S5.T5.3.3.3.3.m1.1.1.3" xref="S5.T5.3.3.3.3.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.3.m1.1b"><apply id="S5.T5.3.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.3.3.3.3.m1.1.1.1.cmml" xref="S5.T5.3.3.3.3.m1.1.1">superscript</csymbol><cn id="S5.T5.3.3.3.3.m1.1.1.2.cmml" type="integer" xref="S5.T5.3.3.3.3.m1.1.1.2">10</cn><compose id="S5.T5.3.3.3.3.m1.1.1.3.cmml" xref="S5.T5.3.3.3.3.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.3.m1.1c">10^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T5.3.3.3.3.m1.1d">10 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.4.4.4" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="5^{\circ}" class="ltx_Math" display="inline" id="S5.T5.4.4.4.4.m1.1"><semantics id="S5.T5.4.4.4.4.m1.1a"><msup id="S5.T5.4.4.4.4.m1.1.1" xref="S5.T5.4.4.4.4.m1.1.1.cmml"><mn id="S5.T5.4.4.4.4.m1.1.1.2" xref="S5.T5.4.4.4.4.m1.1.1.2.cmml">5</mn><mo id="S5.T5.4.4.4.4.m1.1.1.3" xref="S5.T5.4.4.4.4.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.4.4.m1.1b"><apply id="S5.T5.4.4.4.4.m1.1.1.cmml" xref="S5.T5.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.4.4.4.4.m1.1.1.1.cmml" xref="S5.T5.4.4.4.4.m1.1.1">superscript</csymbol><cn id="S5.T5.4.4.4.4.m1.1.1.2.cmml" type="integer" xref="S5.T5.4.4.4.4.m1.1.1.2">5</cn><compose id="S5.T5.4.4.4.4.m1.1.1.3.cmml" xref="S5.T5.4.4.4.4.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.4.4.m1.1c">5^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T5.4.4.4.4.m1.1d">5 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.4.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.4.4.5.1.1" style="padding-top:1pt;padding-bottom:1pt;">w/o culling</th>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T5.4.4.5.1.2" style="padding-top:1pt;padding-bottom:1pt;">38.09</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T5.4.4.5.1.3" style="padding-top:1pt;padding-bottom:1pt;">67.46</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T5.4.4.5.1.4" style="padding-top:1pt;padding-bottom:1pt;">52.32</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T5.4.4.5.1.5" style="padding-top:1pt;padding-bottom:1pt;">40.82</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t" id="S5.T5.4.4.5.1.6" style="padding-top:1pt;padding-bottom:1pt;">23.58</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.4.4.6.2.1" style="padding-top:1pt;padding-bottom:1pt;">only RGB</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.6.2.2" style="padding-top:1pt;padding-bottom:1pt;">36.26</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.6.2.3" style="padding-top:1pt;padding-bottom:1pt;">67.42</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.6.2.4" style="padding-top:1pt;padding-bottom:1pt;">50.40</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.6.2.5" style="padding-top:1pt;padding-bottom:1pt;">37.70</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.6.2.6" style="padding-top:1pt;padding-bottom:1pt;">19.62</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.4.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.4.4.7.3.1" style="padding-top:1pt;padding-bottom:1pt;">only semantic</th>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.7.3.2" style="padding-top:1pt;padding-bottom:1pt;">31.31</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.7.3.3" style="padding-top:1pt;padding-bottom:1pt;">69.32</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.7.3.4" style="padding-top:1pt;padding-bottom:1pt;">50.86</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.7.3.5" style="padding-top:1pt;padding-bottom:1pt;">38.80</td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S5.T5.4.4.7.3.6" style="padding-top:1pt;padding-bottom:1pt;">19.22</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.4.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S5.T5.4.4.8.4.1" style="padding-top:1pt;padding-bottom:1pt;">Ours</th>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S5.T5.4.4.8.4.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.T5.4.4.8.4.2.1">29.93</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S5.T5.4.4.8.4.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.T5.4.4.8.4.3.1">72.06</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S5.T5.4.4.8.4.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.T5.4.4.8.4.4.1">54.90</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S5.T5.4.4.8.4.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.T5.4.4.8.4.5.1">42.74</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t" id="S5.T5.4.4.8.4.6" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S5.T5.4.4.8.4.6.1">24.32</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.5.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.6.2">Effects of Different Initialization Strategies</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The pose estimation performance under the render-and-compare paradigm is largely affected by the initialization <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib29" title=""><span class="ltx_text" style="font-size:80%;">deepim</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib37" title=""><span class="ltx_text" style="font-size:80%;">cir</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib70" title=""><span class="ltx_text" style="font-size:80%;">rnnpose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib24" title=""><span class="ltx_text" style="font-size:80%;">megapose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib42" title=""><span class="ltx_text" style="font-size:80%;">templates-pose</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib46" title=""><span class="ltx_text" style="font-size:80%;">latentfusion</span> </a></cite>. In the following, we investigate different initializations including: 1) <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.1">random initialization</em>, where we randomly sample candidate poses and choose the best one; and 2) <em class="ltx_emph ltx_font_italic" id="S5.SS2.p1.1.2">uniform initialization</em>, where the candidate poses are uniformly sampled from a Fibonacci lattice with in-plane rotations <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib13" title=""><span class="ltx_text" style="font-size:80%;">gonzalez2010measurement</span> </a></cite>, as detailed in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.SS4" title="III-D Label/Training-Free Refinement via Differentiable Renderer ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a> (Initialization). For the latter, we also examine different densities of the sampling, i.e., the Fibonacci lattice viewpoints including 100 and 200, and in-plane rotations including 20 and 50.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T6" title="TABLE VI ‣ V-B Effects of Different Initialization Strategies ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">VI</span></a> illustrates the performance of different initialization strategies using the LineMOD dataset, which demonstrates that 1) the <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.1.1">uniform initialization</em> outperforms the <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.1.2">random initialization</em>, and 2) uniform initialization with <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.1.3">denser sampling</em> leads to better performance. In our experiments, we choose <em class="ltx_emph ltx_font_italic" id="S5.SS2.p2.1.4">uniform initialization with 4000 samples</em> (200 Fibonacci lattice viewpoints times 20 in-plane rotations) to balance the performance and the efficiency.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VI: </span><span class="ltx_text ltx_font_bold" id="S5.T6.7.1">Effects of different initialization strategies using the LineMOD dataset</span>. We evaluate different initialization strategies (rows 1-2) as well as the sampling density (rows 3-5).</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.5" style="width:368.6pt;height:79pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-111.9pt,23.8pt) scale(0.622278363696126,0.622278363696126) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T6.5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T6.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt" id="S5.T6.1.1.1.2" rowspan="2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S5.T6.1.1.1.2.1">Inital Strategy</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt" id="S5.T6.1.1.1.3" rowspan="2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text" id="S5.T6.1.1.1.3.1">Sampling Numbers</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T6.1.1.1.4" style="padding-top:1pt;padding-bottom:1pt;">Error↓</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T6.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Acc @ <math alttext="t^{\circ}" class="ltx_Math" display="inline" id="S5.T6.1.1.1.1.m1.1"><semantics id="S5.T6.1.1.1.1.m1.1a"><msup id="S5.T6.1.1.1.1.m1.1.1" xref="S5.T6.1.1.1.1.m1.1.1.cmml"><mi id="S5.T6.1.1.1.1.m1.1.1.2" xref="S5.T6.1.1.1.1.m1.1.1.2.cmml">t</mi><mo id="S5.T6.1.1.1.1.m1.1.1.3" xref="S5.T6.1.1.1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.1.m1.1b"><apply id="S5.T6.1.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T6.1.1.1.1.m1.1.1.1.cmml" xref="S5.T6.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S5.T6.1.1.1.1.m1.1.1.2.cmml" xref="S5.T6.1.1.1.1.m1.1.1.2">𝑡</ci><compose id="S5.T6.1.1.1.1.m1.1.1.3.cmml" xref="S5.T6.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.1.m1.1c">t^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T6.1.1.1.1.m1.1d">italic_t start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math> (%) ↑</td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.5.5.5.5" style="padding-top:1pt;padding-bottom:1pt;">Mean Err</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.2.2.2.1" style="padding-top:1pt;padding-bottom:1pt;">30<sup class="ltx_sup" id="S5.T6.2.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S5.T6.2.2.2.1.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.3.3.3.2" style="padding-top:1pt;padding-bottom:1pt;">15<sup class="ltx_sup" id="S5.T6.3.3.3.2.1"><span class="ltx_text ltx_font_italic" id="S5.T6.3.3.3.2.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.4.4.4.3" style="padding-top:1pt;padding-bottom:1pt;">10<sup class="ltx_sup" id="S5.T6.4.4.4.3.1"><span class="ltx_text ltx_font_italic" id="S5.T6.4.4.4.3.1.1">∘</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.5.4" style="padding-top:1pt;padding-bottom:1pt;">5<sup class="ltx_sup" id="S5.T6.5.5.5.4.1"><span class="ltx_text ltx_font_italic" id="S5.T6.5.5.5.4.1.1">∘</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5.6.1">
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" id="S5.T6.5.5.6.1.1" style="padding-top:1pt;padding-bottom:1pt;">Random Init.</td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" id="S5.T6.5.5.6.1.2" style="padding-top:1pt;padding-bottom:1pt;">4000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.5.5.6.1.3" style="padding-top:1pt;padding-bottom:1pt;">31.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.6.1.4" style="padding-top:1pt;padding-bottom:1pt;">70.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.6.1.5" style="padding-top:1pt;padding-bottom:1pt;">52.66</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.6.1.6" style="padding-top:1pt;padding-bottom:1pt;">40.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.6.1.7" style="padding-top:1pt;padding-bottom:1pt;">23.08</td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5.7.2">
<td class="ltx_td ltx_align_left ltx_border_rr" id="S5.T6.5.5.7.2.1" style="padding-top:1pt;padding-bottom:1pt;">Uniform Init. (used in our experiments)</td>
<td class="ltx_td ltx_align_left ltx_border_rr" id="S5.T6.5.5.7.2.2" style="padding-top:1pt;padding-bottom:1pt;">4000 (200 viewpoints, 20 in-plane rotations)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.5.5.7.2.3" style="padding-top:1pt;padding-bottom:1pt;">29.93</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.7.2.4" style="padding-top:1pt;padding-bottom:1pt;">72.06</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.7.2.5" style="padding-top:1pt;padding-bottom:1pt;">54.90</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.7.2.6" style="padding-top:1pt;padding-bottom:1pt;">42.74</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.7.2.7" style="padding-top:1pt;padding-bottom:1pt;">24.32</td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5.8.3">
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" id="S5.T6.5.5.8.3.1" style="padding-top:1pt;padding-bottom:1pt;">Uniform Init.</td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t" id="S5.T6.5.5.8.3.2" style="padding-top:1pt;padding-bottom:1pt;">2000 (100 viewpoints, 20 in-plane rotations)</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.5.5.8.3.3" style="padding-top:1pt;padding-bottom:1pt;">32.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.8.3.4" style="padding-top:1pt;padding-bottom:1pt;">69.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.8.3.5" style="padding-top:1pt;padding-bottom:1pt;">49.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.8.3.6" style="padding-top:1pt;padding-bottom:1pt;">38.80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.5.5.8.3.7" style="padding-top:1pt;padding-bottom:1pt;">21.70</td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5.9.4">
<td class="ltx_td ltx_align_left ltx_border_rr" id="S5.T6.5.5.9.4.1" style="padding-top:1pt;padding-bottom:1pt;">Uniform Init. (used in our experiments)</td>
<td class="ltx_td ltx_align_left ltx_border_rr" id="S5.T6.5.5.9.4.2" style="padding-top:1pt;padding-bottom:1pt;">4000 (200 viewpoints, 20 in-plane rotations)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.5.5.9.4.3" style="padding-top:1pt;padding-bottom:1pt;">29.93</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.9.4.4" style="padding-top:1pt;padding-bottom:1pt;">72.06</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.9.4.5" style="padding-top:1pt;padding-bottom:1pt;">54.90</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.9.4.6" style="padding-top:1pt;padding-bottom:1pt;">42.74</td>
<td class="ltx_td ltx_align_center" id="S5.T6.5.5.9.4.7" style="padding-top:1pt;padding-bottom:1pt;">24.32</td>
</tr>
<tr class="ltx_tr" id="S5.T6.5.5.10.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_rr" id="S5.T6.5.5.10.5.1" style="padding-top:1pt;padding-bottom:1pt;">Uniform Init.</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_rr" id="S5.T6.5.5.10.5.2" style="padding-top:1pt;padding-bottom:1pt;">10000 (200 viewpoints, 50 in-plane rotations)</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T6.5.5.10.5.3" style="padding-top:1pt;padding-bottom:1pt;">29.13</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.5.5.10.5.4" style="padding-top:1pt;padding-bottom:1pt;">73.30</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.5.5.10.5.5" style="padding-top:1pt;padding-bottom:1pt;">57.46</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.5.5.10.5.6" style="padding-top:1pt;padding-bottom:1pt;">44.92</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T6.5.5.10.5.7" style="padding-top:1pt;padding-bottom:1pt;">25.02</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.5.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.6.2">Effects of Different Refinement Iterations.</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T7" title="TABLE VII ‣ V-C Effects of Different Refinement Iterations. ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">VII</span></a> illustrates the impact of the iteration numbers for our label/training-free refinement using the LineMOD dataset. It shows that the improvement becomes marginal after the iteration number <math alttext="N" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><mi id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><ci id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">italic_N</annotation></semantics></math> exceeds 30. We thus set the iteration number to <math alttext="N=30" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml">N</mi><mo id="S5.SS3.p1.2.m2.1.1.1" xref="S5.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">30</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><eq id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></eq><ci id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">𝑁</ci><cn id="S5.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1.3">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">N=30</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.1d">italic_N = 30</annotation></semantics></math> to achieve a balance between performance and efficiency.</p>
</div>
<figure class="ltx_table" id="S5.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Effects of <span class="ltx_text ltx_font_bold" id="S5.T7.6.1">different refinement iterations</span> on LineMOD.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T7.4" style="width:433.6pt;height:119pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(20.1pt,-5.5pt) scale(1.10201746647807,1.10201746647807) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T7.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T7.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S5.T7.4.4.4.5" style="padding-top:1pt;padding-bottom:1pt;">Iterations N</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt" id="S5.T7.4.4.4.6" style="padding-top:1pt;padding-bottom:1pt;">Mean Err↓</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="30^{\circ}" class="ltx_Math" display="inline" id="S5.T7.1.1.1.1.m1.1"><semantics id="S5.T7.1.1.1.1.m1.1a"><msup id="S5.T7.1.1.1.1.m1.1.1" xref="S5.T7.1.1.1.1.m1.1.1.cmml"><mn id="S5.T7.1.1.1.1.m1.1.1.2" xref="S5.T7.1.1.1.1.m1.1.1.2.cmml">30</mn><mo id="S5.T7.1.1.1.1.m1.1.1.3" xref="S5.T7.1.1.1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T7.1.1.1.1.m1.1b"><apply id="S5.T7.1.1.1.1.m1.1.1.cmml" xref="S5.T7.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T7.1.1.1.1.m1.1.1.1.cmml" xref="S5.T7.1.1.1.1.m1.1.1">superscript</csymbol><cn id="S5.T7.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="S5.T7.1.1.1.1.m1.1.1.2">30</cn><compose id="S5.T7.1.1.1.1.m1.1.1.3.cmml" xref="S5.T7.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.1.1.1.1.m1.1c">30^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T7.1.1.1.1.m1.1d">30 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.2.2.2.2" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="15^{\circ}" class="ltx_Math" display="inline" id="S5.T7.2.2.2.2.m1.1"><semantics id="S5.T7.2.2.2.2.m1.1a"><msup id="S5.T7.2.2.2.2.m1.1.1" xref="S5.T7.2.2.2.2.m1.1.1.cmml"><mn id="S5.T7.2.2.2.2.m1.1.1.2" xref="S5.T7.2.2.2.2.m1.1.1.2.cmml">15</mn><mo id="S5.T7.2.2.2.2.m1.1.1.3" xref="S5.T7.2.2.2.2.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T7.2.2.2.2.m1.1b"><apply id="S5.T7.2.2.2.2.m1.1.1.cmml" xref="S5.T7.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.T7.2.2.2.2.m1.1.1.1.cmml" xref="S5.T7.2.2.2.2.m1.1.1">superscript</csymbol><cn id="S5.T7.2.2.2.2.m1.1.1.2.cmml" type="integer" xref="S5.T7.2.2.2.2.m1.1.1.2">15</cn><compose id="S5.T7.2.2.2.2.m1.1.1.3.cmml" xref="S5.T7.2.2.2.2.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.2.2.2.2.m1.1c">15^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T7.2.2.2.2.m1.1d">15 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.3.3.3.3" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="10^{\circ}" class="ltx_Math" display="inline" id="S5.T7.3.3.3.3.m1.1"><semantics id="S5.T7.3.3.3.3.m1.1a"><msup id="S5.T7.3.3.3.3.m1.1.1" xref="S5.T7.3.3.3.3.m1.1.1.cmml"><mn id="S5.T7.3.3.3.3.m1.1.1.2" xref="S5.T7.3.3.3.3.m1.1.1.2.cmml">10</mn><mo id="S5.T7.3.3.3.3.m1.1.1.3" xref="S5.T7.3.3.3.3.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T7.3.3.3.3.m1.1b"><apply id="S5.T7.3.3.3.3.m1.1.1.cmml" xref="S5.T7.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S5.T7.3.3.3.3.m1.1.1.1.cmml" xref="S5.T7.3.3.3.3.m1.1.1">superscript</csymbol><cn id="S5.T7.3.3.3.3.m1.1.1.2.cmml" type="integer" xref="S5.T7.3.3.3.3.m1.1.1.2">10</cn><compose id="S5.T7.3.3.3.3.m1.1.1.3.cmml" xref="S5.T7.3.3.3.3.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.3.3.3.3.m1.1c">10^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T7.3.3.3.3.m1.1d">10 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T7.4.4.4.4" style="padding-top:1pt;padding-bottom:1pt;">Acc @<math alttext="5^{\circ}" class="ltx_Math" display="inline" id="S5.T7.4.4.4.4.m1.1"><semantics id="S5.T7.4.4.4.4.m1.1a"><msup id="S5.T7.4.4.4.4.m1.1.1" xref="S5.T7.4.4.4.4.m1.1.1.cmml"><mn id="S5.T7.4.4.4.4.m1.1.1.2" xref="S5.T7.4.4.4.4.m1.1.1.2.cmml">5</mn><mo id="S5.T7.4.4.4.4.m1.1.1.3" xref="S5.T7.4.4.4.4.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T7.4.4.4.4.m1.1b"><apply id="S5.T7.4.4.4.4.m1.1.1.cmml" xref="S5.T7.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S5.T7.4.4.4.4.m1.1.1.1.cmml" xref="S5.T7.4.4.4.4.m1.1.1">superscript</csymbol><cn id="S5.T7.4.4.4.4.m1.1.1.2.cmml" type="integer" xref="S5.T7.4.4.4.4.m1.1.1.2">5</cn><compose id="S5.T7.4.4.4.4.m1.1.1.3.cmml" xref="S5.T7.4.4.4.4.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.4.4.4.4.m1.1c">5^{\circ}</annotation><annotation encoding="application/x-llamapun" id="S5.T7.4.4.4.4.m1.1d">5 start_POSTSUPERSCRIPT ∘ end_POSTSUPERSCRIPT</annotation></semantics></math>↑</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T7.4.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T7.4.4.5.1.1" style="padding-top:1pt;padding-bottom:1pt;">10</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S5.T7.4.4.5.1.2" style="padding-top:1pt;padding-bottom:1pt;">30.46</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.4.4.5.1.3" style="padding-top:1pt;padding-bottom:1pt;">71.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.4.4.5.1.4" style="padding-top:1pt;padding-bottom:1pt;">53.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.4.4.5.1.5" style="padding-top:1pt;padding-bottom:1pt;">39.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.4.4.5.1.6" style="padding-top:1pt;padding-bottom:1pt;">19.86</td>
</tr>
<tr class="ltx_tr" id="S5.T7.4.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T7.4.4.6.2.1" style="padding-top:1pt;padding-bottom:1pt;">20</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S5.T7.4.4.6.2.2" style="padding-top:1pt;padding-bottom:1pt;">30.16</th>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.6.2.3" style="padding-top:1pt;padding-bottom:1pt;">72.04</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.6.2.4" style="padding-top:1pt;padding-bottom:1pt;">54.18</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.6.2.5" style="padding-top:1pt;padding-bottom:1pt;">41.84</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.6.2.6" style="padding-top:1pt;padding-bottom:1pt;">22.60</td>
</tr>
<tr class="ltx_tr" id="S5.T7.4.4.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T7.4.4.7.3.1" style="padding-top:1pt;padding-bottom:1pt;">30 (used in our exp.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S5.T7.4.4.7.3.2" style="padding-top:1pt;padding-bottom:1pt;">29.93</th>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.7.3.3" style="padding-top:1pt;padding-bottom:1pt;">72.06</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.7.3.4" style="padding-top:1pt;padding-bottom:1pt;">54.90</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.7.3.5" style="padding-top:1pt;padding-bottom:1pt;">42.74</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.7.3.6" style="padding-top:1pt;padding-bottom:1pt;">24.32</td>
</tr>
<tr class="ltx_tr" id="S5.T7.4.4.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr" id="S5.T7.4.4.8.4.1" style="padding-top:1pt;padding-bottom:1pt;">50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S5.T7.4.4.8.4.2" style="padding-top:1pt;padding-bottom:1pt;">29.86</th>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.8.4.3" style="padding-top:1pt;padding-bottom:1pt;">72.10</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.8.4.4" style="padding-top:1pt;padding-bottom:1pt;">54.94</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.8.4.5" style="padding-top:1pt;padding-bottom:1pt;">42.92</td>
<td class="ltx_td ltx_align_center" id="S5.T7.4.4.8.4.6" style="padding-top:1pt;padding-bottom:1pt;">25.18</td>
</tr>
<tr class="ltx_tr" id="S5.T7.4.4.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S5.T7.4.4.9.5.1" style="padding-top:1pt;padding-bottom:1pt;">100</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_rr" id="S5.T7.4.4.9.5.2" style="padding-top:1pt;padding-bottom:1pt;">29.73</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.4.4.9.5.3" style="padding-top:1pt;padding-bottom:1pt;">72.12</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.4.4.9.5.4" style="padding-top:1pt;padding-bottom:1pt;">55.26</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.4.4.9.5.5" style="padding-top:1pt;padding-bottom:1pt;">43.60</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T7.4.4.9.5.6" style="padding-top:1pt;padding-bottom:1pt;">25.64</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.5.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.6.2">The Statistics of Our Inference Time</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We collect the inference time per reference-query pair, averaged across the LineMOD datasets on a single 4090 GPU. We report the runtime for each stage of our method in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T8" title="TABLE VIII ‣ V-D The Statistics of Our Inference Time ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">VIII</span></a>. Note that the initialization is efficient with much more candidate samples than the refinement, because those initializing candidate samples can be evaluated in parallel without backpropagation. Table <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.T8" title="TABLE VIII ‣ V-D The Statistics of Our Inference Time ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">VIII</span></a> demonstrates the efficiency of our method with a per-pair runtime of 4.85 seconds in total.</p>
</div>
<figure class="ltx_table" id="S5.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span><span class="ltx_text ltx_font_bold" id="S5.T8.2.1">Inference time statistics</span> of our method on LineMOD.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T8.3" style="width:433.6pt;height:48.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(57.2pt,-6.4pt) scale(1.3582436662865,1.3582436662865) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.3.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.1.1.1.1">Semantic Fea. Extraction</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.1.1.1.2">Pose Initialization</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.1.1.1.3">Refinement</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T8.3.1.1.1.4">Total</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T8.3.1.2.2.1">0.24 s</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T8.3.1.2.2.2">3.46 s</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T8.3.1.2.2.3">1.03 s</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T8.3.1.2.2.4">4.85 s</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS5.5.1.1">V-E</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS5.6.2">Illustrations of the Failure Cases</span>
</h3>
<div class="ltx_para" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">We show our failure cases on the LM-O dataset in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.F8" title="Figure 8 ‣ V-E Illustrations of the Failure Cases ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">8</span></a>, where there do not exist sufficient overlaps between the query and the reference. We note such an extremely degraded case as our limitation and discuss it in Sect. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S6" title="VI Discussions and Conclusions ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">VI</span></a> (Limitations and Future Works).</p>
</div>
<figure class="ltx_figure" id="S5.F8">
<p class="ltx_p ltx_align_center" id="S5.F8.1"><span class="ltx_text" id="S5.F8.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="266" id="S5.F8.1.1.g1" src="x8.png" width="581"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span class="ltx_text ltx_font_bold" id="S5.F8.3.1">Failure Cases of our method on the LM-O dataset</span>, where there do not exist sufficient overlaps between the query and the reference due to severe occlusions.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Discussions and Conclusions</span>
</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.p1.1.1">Limitations and Future Works.</span> Our method has the following two limitations.
Firstly, our method necessitates the depth information of the reference object as an input. Although this is a one-time requirement per object, the need for depth data can restrict the applicability of our method where a depth sensor is absent. To acquire the depth of the reference image, we evaluated several advanced monocular depth estimation algorithms, including <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib51" title=""><span class="ltx_text" style="font-size:80%;">midas</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib2" title=""><span class="ltx_text" style="font-size:80%;">bhat2023zoedepth</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib50" title=""><span class="ltx_text" style="font-size:80%;">dpt</span> </a>; <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#bib.bib72" title=""><span class="ltx_text" style="font-size:80%;">depthanything</span> </a></cite>. However, we found that these methods often struggle to generalize across different object types. Despite this, our empirical results, presented in Table S1 of the supplementary materials, demonstrate that our method remains robust with imprecise depth (simulated by adding noise to the ground-truth depth). This suggests that the current limitations are likely to be overcome once an object-generalizable depth estimator becomes available.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Secondly, our method is likely to fail in the severely degraded scenario where there do not exist adequate overlaps between the query and the reference (possibly caused by occlusions, e.g., Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S5.F8" title="Figure 8 ‣ V-E Illustrations of the Failure Cases ‣ V Ablation Analysis ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">8</span></a>). Future research with simultaneous render-and-compare and object completion (with minimal inconsistent hallucination) is a promising direction to explore.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">We also note an additional future direction about adaptively determining the loss weights of the RGB pair and the semantic pair in Eq. (<a class="ltx_ref" href="https://arxiv.org/html/2406.18453v1#S3.E3" title="In III-D Label/Training-Free Refinement via Differentiable Renderer ‣ III Method ‣ Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference"><span class="ltx_text ltx_ref_tag">3</span></a>) (preferably adapting in each refinement step), though we empirically showed that simply using equal weights (i.e., both set to 1) leads to promising results.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_bold" id="S6.p4.1.2">Conclusions.</span> In this paper, we addressed the challenging generalizable relative pose estimation under a rigorous circumstance with only a single RGB-D reference and single RGB query pair as input, and the pose label is not a priori. We establish our label- and training-free method following the render-and-compare paradigm, by exploiting 1) the 2.5D (i.e., RGB-D) rotatable reference mesh, 2) the semantic maps of both query and reference (extracted by a pretrained large vision model DINOv2), and 3) a differentiable renderer to produce and back-propagate losses to refine the relative pose. We carried out extensive experiments on the LineMOD, LM-O, and YCB-V datasets. The results demonstrate that our label/training-free approach surpasses the performance of state-of-the-art supervised methods, particularly excelling under the rigorous <span class="ltx_text ltx_font_typewriter" id="S6.p4.1.1">Acc@5/10/15<sup class="ltx_sup" id="S6.p4.1.1.1"><span class="ltx_text ltx_font_serif" id="S6.p4.1.1.1.1">∘</span></sup></span> metrics.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:80%;">[1]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.4.1" style="font-size:80%;">
Pedram Azad, Tamim Asfour, and Ruediger Dillmann.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.5.1" style="font-size:80%;">Stereo-based 6d object localization for grasping with humanoid robot
systems.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib1.7.2" style="font-size:80%;">2007 IEEE/RSJ International Conference on Intelligent Robots
and Systems</span><span class="ltx_text" id="bib.bib1.8.3" style="font-size:80%;">, pages 919–924. IEEE, 2007.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.2.2.1" style="font-size:80%;">[2]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.4.1" style="font-size:80%;">
Shariq Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka, and Matthias
Müller.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.5.1" style="font-size:80%;">Zoedepth: Zero-shot transfer by combining relative and metric depth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.6.1" style="font-size:80%;">arXiv preprint arXiv:2302.12288</span><span class="ltx_text" id="bib.bib2.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.2.2.1" style="font-size:80%;">[3]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.4.1" style="font-size:80%;">
Eric Brachmann, Alexander Krull, Frank Michel, Stefan Gumhold, Jamie Shotton,
and Carsten Rother.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.5.1" style="font-size:80%;">Learning 6d object pose estimation using 3d object coordinates.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib3.7.2" style="font-size:80%;">European conference on computer vision</span><span class="ltx_text" id="bib.bib3.8.3" style="font-size:80%;">, pages 536–551.
Springer, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.2.2.1" style="font-size:80%;">[4]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.4.1" style="font-size:80%;">
Yannick Bukschat and Marcus Vetter.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.5.1" style="font-size:80%;">Efficientpose: An efficient, accurate and scalable end-to-end 6d
multi object pose estimation approach.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.6.1" style="font-size:80%;">arXiv preprint arXiv:2011.04307</span><span class="ltx_text" id="bib.bib4.7.2" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.2.2.1" style="font-size:80%;">[5]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.4.1" style="font-size:80%;">
Andrea Caraffa, Davide Boscaini, Amir Hamza, and Fabio Poiesi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.5.1" style="font-size:80%;">Object 6d pose estimation meets zero-shot learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.6.1" style="font-size:80%;">arXiv preprint arXiv:2312.00947</span><span class="ltx_text" id="bib.bib5.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.2.2.1" style="font-size:80%;">[6]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.4.1" style="font-size:80%;">
Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal,
Piotr Bojanowski, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.5.1" style="font-size:80%;">Emerging properties in self-supervised vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib6.8.3" style="font-size:80%;">, pages 9650–9660, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.2.2.1" style="font-size:80%;">[7]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.4.1" style="font-size:80%;">
Dengsheng Chen, Jun Li, Zheng Wang, and Kai Xu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.5.1" style="font-size:80%;">Learning canonical shape space for category-level 6d object pose and
size estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib7.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib7.8.3" style="font-size:80%;">, pages 11973–11982, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.2.2.1" style="font-size:80%;">[8]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.4.1" style="font-size:80%;">
Jianqiu Chen, Mingshan Sun, Tianpeng Bao, Rui Zhao, Liwei Wu, and Zhenyu He.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.5.1" style="font-size:80%;">Zeropose: Cad-model-based zero-shot pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.6.1" style="font-size:80%;">arXiv preprint arXiv:2305.17934</span><span class="ltx_text" id="bib.bib8.7.2" style="font-size:80%;">, 2, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.2.2.1" style="font-size:80%;">[9]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.4.1" style="font-size:80%;">
Kai Chen and Qi Dou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.5.1" style="font-size:80%;">Sgpa: Structure-guided prior adaptation for category-level 6d object
pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib9.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib9.8.3" style="font-size:80%;">, pages 2773–2782, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.2.2.1" style="font-size:80%;">[10]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.4.1" style="font-size:80%;">
Wei Chen, Xi Jia, Hyung Jin Chang, Jinming Duan, Linlin Shen, and Ales
Leonardis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.5.1" style="font-size:80%;">Fs-net: Fast shape-based network for category-level 6d object pose
estimation with decoupled rotation mechanism.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib10.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib10.8.3" style="font-size:80%;">, pages 1581–1590, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.2.2.1" style="font-size:80%;">[11]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.4.1" style="font-size:80%;">
Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli
VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali
Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.5.1" style="font-size:80%;">Objaverse: A universe of annotated 3d objects.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib11.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib11.8.3" style="font-size:80%;">, pages 13142–13153, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.2.2.1" style="font-size:80%;">[12]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.4.1" style="font-size:80%;">
Yan Di, Fabian Manhardt, Gu Wang, Xiangyang Ji, Nassir Navab, and Federico
Tombari.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.5.1" style="font-size:80%;">So-pose: Exploiting self-occlusion for direct 6d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib12.8.3" style="font-size:80%;">, pages 12396–12405, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.2.2.1" style="font-size:80%;">[13]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.4.1" style="font-size:80%;">
Álvaro González.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.5.1" style="font-size:80%;">Measurement of areas on a sphere using fibonacci and
latitude–longitude lattices.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.6.1" style="font-size:80%;">Mathematical Geosciences</span><span class="ltx_text" id="bib.bib13.7.2" style="font-size:80%;">, 42:49–64, 2010.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.2.2.1" style="font-size:80%;">[14]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.4.1" style="font-size:80%;">
Walter Goodwin, Sagar Vaze, Ioannis Havoutis, and Ingmar Posner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.5.1" style="font-size:80%;">Zero-shot category-level object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib14.7.2" style="font-size:80%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib14.8.3" style="font-size:80%;">, pages 516–532.
Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.2.2.1" style="font-size:80%;">[15]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.4.1" style="font-size:80%;">
Xingyi He, Jiaming Sun, Yuang Wang, Di Huang, Hujun Bao, and Xiaowei Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.5.1" style="font-size:80%;">Onepose++: Keypoint-free one-shot object pose estimation without cad
models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.6.1" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib15.7.2" style="font-size:80%;">,
35:35103–35115, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.2.2.1" style="font-size:80%;">[16]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.4.1" style="font-size:80%;">
Yisheng He, Wei Sun, Haibin Huang, Jianran Liu, Haoqiang Fan, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.5.1" style="font-size:80%;">Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib16.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib16.8.3" style="font-size:80%;">, pages 11632–11641, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.2.2.1" style="font-size:80%;">[17]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.4.1" style="font-size:80%;">
Yisheng He, Yao Wang, Haoqiang Fan, Jian Sun, and Qifeng Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.5.1" style="font-size:80%;">Fs6d: Few-shot 6d pose estimation of novel objects.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib17.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib17.8.3" style="font-size:80%;">, pages 6814–6824, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.2.2.1" style="font-size:80%;">[18]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.4.1" style="font-size:80%;">
Stefan Hinterstoisser, Vincent Lepetit, Slobodan Ilic, Stefan Holzer, Gary
Bradski, Kurt Konolige, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.5.1" style="font-size:80%;">Model based training, detection and pose estimation of texture-less
3d objects in heavily cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib18.7.2" style="font-size:80%;">Computer Vision–ACCV 2012: 11th Asian Conference on Computer
Vision, Daejeon, Korea, November 5-9, 2012, Revised Selected Papers, Part I
11</span><span class="ltx_text" id="bib.bib18.8.3" style="font-size:80%;">, pages 548–562. Springer, 2013.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.2.2.1" style="font-size:80%;">[19]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.4.1" style="font-size:80%;">
Tomas Hodan, Daniel Barath, and Jiri Matas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.5.1" style="font-size:80%;">Epos: Estimating 6d pose of objects with symmetries.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib19.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib19.8.3" style="font-size:80%;">, pages 11703–11712, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.2.2.1" style="font-size:80%;">[20]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.4.1" style="font-size:80%;">
Prakhar Kaushik, Aayush Mishra, Adam Kortylewski, and Alan Yuille.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.5.1" style="font-size:80%;">Source-free and image-only unsupervised domain adaptation for
category level object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.6.1" style="font-size:80%;">arXiv preprint arXiv:2401.10848</span><span class="ltx_text" id="bib.bib20.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.2.2.1" style="font-size:80%;">[21]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.4.1" style="font-size:80%;">
Wadim Kehl, Fabian Manhardt, Federico Tombari, Slobodan Ilic, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.5.1" style="font-size:80%;">Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great
again.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib21.7.2" style="font-size:80%;">Proceedings of the IEEE international conference on computer
vision</span><span class="ltx_text" id="bib.bib21.8.3" style="font-size:80%;">, pages 1521–1529, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.2.2.1" style="font-size:80%;">[22]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.4.1" style="font-size:80%;">
Diederik P Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.5.1" style="font-size:80%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.6.1" style="font-size:80%;">arXiv preprint arXiv:1412.6980</span><span class="ltx_text" id="bib.bib22.7.2" style="font-size:80%;">, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.2.2.1" style="font-size:80%;">[23]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.4.1" style="font-size:80%;">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.5.1" style="font-size:80%;">Segment anything.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.6.1" style="font-size:80%;">arXiv preprint arXiv:2304.02643</span><span class="ltx_text" id="bib.bib23.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.2.2.1" style="font-size:80%;">[24]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.4.1" style="font-size:80%;">
Yann Labbé, Lucas Manuelli, Arsalan Mousavian, Stephen Tyree, Stan
Birchfield, Jonathan Tremblay, Justin Carpentier, Mathieu Aubry, Dieter Fox,
and Josef Sivic.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.5.1" style="font-size:80%;">Megapose: 6d pose estimation of novel objects via render &amp; compare.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib24.6.1" style="font-size:80%;">arXiv preprint arXiv:2212.06870</span><span class="ltx_text" id="bib.bib24.7.2" style="font-size:80%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.2.2.1" style="font-size:80%;">[25]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.4.1" style="font-size:80%;">
Samuli Laine, Janne Hellsten, Tero Karras, Yeongho Seol, Jaakko Lehtinen, and
Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.5.1" style="font-size:80%;">Modular primitives for high-performance differentiable rendering.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.6.1" style="font-size:80%;">ACM Transactions on Graphics (TOG)</span><span class="ltx_text" id="bib.bib25.7.2" style="font-size:80%;">, 39(6):1–14, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.2.2.1" style="font-size:80%;">[26]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.4.1" style="font-size:80%;">
Der-Tsai Lee and Bruce J Schachter.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.5.1" style="font-size:80%;">Two algorithms for constructing a delaunay triangulation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.6.1" style="font-size:80%;">International Journal of Computer &amp; Information Sciences</span><span class="ltx_text" id="bib.bib26.7.2" style="font-size:80%;">,
9(3):219–242, 1980.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.2.2.1" style="font-size:80%;">[27]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.4.1" style="font-size:80%;">
Taeyeop Lee, Byeong-Uk Lee, Myungchul Kim, and In So Kweon.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.5.1" style="font-size:80%;">Category-level metric scale object shape and pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.6.1" style="font-size:80%;">IEEE Robotics and Automation Letters</span><span class="ltx_text" id="bib.bib27.7.2" style="font-size:80%;">, 6(4):8575–8582, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.2.2.1" style="font-size:80%;">[28]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.4.1" style="font-size:80%;">
Vincent Lepetit, Francesc Moreno-Noguer, and Pascal Fua.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.5.1" style="font-size:80%;">Epnp: An accurate o (n) solution to the pnp problem.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib28.6.1" style="font-size:80%;">International journal of computer vision</span><span class="ltx_text" id="bib.bib28.7.2" style="font-size:80%;">, 81(2):155–166, 2009.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.2.2.1" style="font-size:80%;">[29]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.4.1" style="font-size:80%;">
Yi Li, Gu Wang, Xiangyang Ji, Yu Xiang, and Dieter Fox.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.5.1" style="font-size:80%;">Deepim: Deep iterative matching for 6d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib29.7.2" style="font-size:80%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span class="ltx_text" id="bib.bib29.8.3" style="font-size:80%;">, pages 683–698, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.2.2.1" style="font-size:80%;">[30]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.4.1" style="font-size:80%;">
Zhigang Li, Gu Wang, and Xiangyang Ji.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.5.1" style="font-size:80%;">Cdpn: Coordinates-based disentangled pose network for real-time
rgb-based 6-dof object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib30.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib30.8.3" style="font-size:80%;">, pages 7678–7687, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.2.2.1" style="font-size:80%;">[31]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.4.1" style="font-size:80%;">
Ruyi Lian and Haibin Ling.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.5.1" style="font-size:80%;">Checkerpose: Progressive dense keypoint localization for object pose
estimation with graph neural network.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.6.1" style="font-size:80%;">arXiv preprint arXiv:2303.16874</span><span class="ltx_text" id="bib.bib31.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.2.2.1" style="font-size:80%;">[32]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.4.1" style="font-size:80%;">
Amy Lin, Jason Y Zhang, Deva Ramanan, and Shubham Tulsiani.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.5.1" style="font-size:80%;">Relpose++: Recovering 6d poses from sparse-view observations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib32.6.1" style="font-size:80%;">arXiv preprint arXiv:2305.04926</span><span class="ltx_text" id="bib.bib32.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.2.2.1" style="font-size:80%;">[33]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.4.1" style="font-size:80%;">
Jiehong Lin, Lihua Liu, Dekun Lu, and Kui Jia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.5.1" style="font-size:80%;">Sam-6d: Segment anything model meets zero-shot 6d object pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.6.1" style="font-size:80%;">arXiv preprint arXiv:2311.15707</span><span class="ltx_text" id="bib.bib33.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.2.2.1" style="font-size:80%;">[34]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.4.1" style="font-size:80%;">
Jiehong Lin, Zewei Wei, Changxing Ding, and Kui Jia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.5.1" style="font-size:80%;">Category-level 6d object pose and size estimation using
self-supervised deep prior deformation networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib34.7.2" style="font-size:80%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib34.8.3" style="font-size:80%;">, pages 19–34.
Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.2.2.1" style="font-size:80%;">[35]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.4.1" style="font-size:80%;">
Jiehong Lin, Zewei Wei, Zhihao Li, Songcen Xu, Kui Jia, and Yuanqing Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.5.1" style="font-size:80%;">Dualposenet: Category-level 6d object pose and size estimation using
dual pose network with refined learning of pose consistency.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib35.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib35.8.3" style="font-size:80%;">, pages 3560–3569, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.2.2.1" style="font-size:80%;">[36]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.4.1" style="font-size:80%;">
Jiehong Lin, Zewei Wei, Yabin Zhang, and Kui Jia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.5.1" style="font-size:80%;">Vi-net: Boosting category-level 6d object pose estimation via
learning decoupled rotations on the spherical representations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib36.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib36.8.3" style="font-size:80%;">, pages 14001–14011, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.2.2.1" style="font-size:80%;">[37]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.4.1" style="font-size:80%;">
Lahav Lipson, Zachary Teed, Ankit Goyal, and Jia Deng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.5.1" style="font-size:80%;">Coupled iterative refinement for 6d multi-object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib37.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib37.8.3" style="font-size:80%;">, pages 6728–6737, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.2.2.1" style="font-size:80%;">[38]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.4.1" style="font-size:80%;">
Yuan Liu, Yilin Wen, Sida Peng, Cheng Lin, Xiaoxiao Long, Taku Komura, and
Wenping Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.5.1" style="font-size:80%;">Gen6d: Generalizable model-free 6-dof object pose estimation from rgb
images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib38.7.2" style="font-size:80%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib38.8.3" style="font-size:80%;">, pages 298–315.
Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.2.2.1" style="font-size:80%;">[39]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.4.1" style="font-size:80%;">
Fabian Manhardt, Gu Wang, Benjamin Busam, Manuel Nickel, Sven Meier, Luca
Minciullo, Xiangyang Ji, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.5.1" style="font-size:80%;">Cps++: Improving class-level 6d pose and shape estimation from
monocular images with self-supervised learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib39.6.1" style="font-size:80%;">arXiv preprint arXiv:2003.05848</span><span class="ltx_text" id="bib.bib39.7.2" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.2.2.1" style="font-size:80%;">[40]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.4.1" style="font-size:80%;">
Van Nguyen Nguyen, Thibault Groueix, Yinlin Hu, Mathieu Salzmann, and Vincent
Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.5.1" style="font-size:80%;">Nope: Novel object pose estimation from a single image.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.6.1" style="font-size:80%;">arXiv preprint arXiv:2303.13612</span><span class="ltx_text" id="bib.bib40.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.2.2.1" style="font-size:80%;">[41]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.4.1" style="font-size:80%;">
Van Nguyen Nguyen, Thibault Groueix, Mathieu Salzmann, and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.5.1" style="font-size:80%;">Gigapose: Fast and robust novel object pose estimation via one
correspondence.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib41.6.1" style="font-size:80%;">arXiv preprint arXiv:2311.14155</span><span class="ltx_text" id="bib.bib41.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.2.2.1" style="font-size:80%;">[42]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.4.1" style="font-size:80%;">
Van Nguyen Nguyen, Yinlin Hu, Yang Xiao, Mathieu Salzmann, and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.5.1" style="font-size:80%;">Templates for 3d object pose estimation revisited: Generalization to
new objects and robustness to occlusions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib42.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib42.8.3" style="font-size:80%;">, pages 6771–6780, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.2.2.1" style="font-size:80%;">[43]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.4.1" style="font-size:80%;">
Brian Okorn, Qiao Gu, Martial Hebert, and David Held.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.5.1" style="font-size:80%;">Zephyr: Zero-shot pose hypothesis rating.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib43.7.2" style="font-size:80%;">2021 IEEE International Conference on Robotics and Automation
(ICRA)</span><span class="ltx_text" id="bib.bib43.8.3" style="font-size:80%;">, pages 14141–14148. IEEE, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.2.2.1" style="font-size:80%;">[44]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.4.1" style="font-size:80%;">
Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc
Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa,
Alaaeldin El-Nouby, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.5.1" style="font-size:80%;">Dinov2: Learning robust visual features without supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib44.6.1" style="font-size:80%;">arXiv preprint arXiv:2304.07193</span><span class="ltx_text" id="bib.bib44.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.2.2.1" style="font-size:80%;">[45]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.4.1" style="font-size:80%;">
Evin Pınar Örnek, Yann Labbé, Bugra Tekin, Lingni Ma, Cem Keskin,
Christian Forster, and Tomas Hodan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.5.1" style="font-size:80%;">Foundpose: Unseen object pose estimation with foundation features.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib45.6.1" style="font-size:80%;">arXiv preprint arXiv:2311.18809</span><span class="ltx_text" id="bib.bib45.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.2.2.1" style="font-size:80%;">[46]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.4.1" style="font-size:80%;">
Keunhong Park, Arsalan Mousavian, Yu Xiang, and Dieter Fox.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.5.1" style="font-size:80%;">Latentfusion: End-to-end differentiable reconstruction and rendering
for unseen object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib46.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib46.8.3" style="font-size:80%;">, pages 10710–10719, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.2.2.1" style="font-size:80%;">[47]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.4.1" style="font-size:80%;">
Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.5.1" style="font-size:80%;">Pvnet: Pixel-wise voting network for 6dof pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib47.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib47.8.3" style="font-size:80%;">, pages 4561–4570, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.2.2.1" style="font-size:80%;">[48]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.4.1" style="font-size:80%;">
Luis Pérez, Íñigo Rodríguez, Nuria Rodríguez, Rubén
Usamentiaga, and Daniel F García.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.5.1" style="font-size:80%;">Robot guidance using machine vision techniques in industrial
environments: A comparative review.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib48.6.1" style="font-size:80%;">Sensors</span><span class="ltx_text" id="bib.bib48.7.2" style="font-size:80%;">, 16(3):335, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.2.2.1" style="font-size:80%;">[49]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.4.1" style="font-size:80%;">
Mahdi Rad and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.5.1" style="font-size:80%;">Bb8: A scalable, accurate, robust to partial occlusion method for
predicting the 3d poses of challenging objects without using depth.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib49.7.2" style="font-size:80%;">Proceedings of the IEEE international conference on computer
vision</span><span class="ltx_text" id="bib.bib49.8.3" style="font-size:80%;">, pages 3828–3836, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib50.2.2.1" style="font-size:80%;">[50]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.4.1" style="font-size:80%;">
René Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.5.1" style="font-size:80%;">Vision transformers for dense prediction.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib50.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF international conference on
computer vision</span><span class="ltx_text" id="bib.bib50.8.3" style="font-size:80%;">, pages 12179–12188, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib51.2.2.1" style="font-size:80%;">[51]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.4.1" style="font-size:80%;">
René Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen
Koltun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.5.1" style="font-size:80%;">Towards robust monocular depth estimation: Mixing datasets for
zero-shot cross-dataset transfer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib51.6.1" style="font-size:80%;">IEEE transactions on pattern analysis and machine intelligence</span><span class="ltx_text" id="bib.bib51.7.2" style="font-size:80%;">,
44(3):1623–1637, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib52.2.2.1" style="font-size:80%;">[52]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.4.1" style="font-size:80%;">
Tianhe Ren, Shilong Liu, Ailing Zeng, Jing Lin, Kunchang Li, He Cao, Jiayu
Chen, Xinyu Huang, Yukang Chen, Feng Yan, Zhaoyang Zeng, Hao Zhang, Feng Li,
Jie Yang, Hongyang Li, Qing Jiang, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.5.1" style="font-size:80%;">Grounded sam: Assembling open-world models for diverse visual tasks,
2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib53.2.2.1" style="font-size:80%;">[53]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.4.1" style="font-size:80%;">
Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.5.1" style="font-size:80%;">Superglue: Learning feature matching with graph neural networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib53.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span class="ltx_text" id="bib.bib53.8.3" style="font-size:80%;">, pages 4938–4947, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib54.2.2.1" style="font-size:80%;">[54]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.4.1" style="font-size:80%;">
Ivan Shugurov, Fu Li, Benjamin Busam, and Slobodan Ilic.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.5.1" style="font-size:80%;">Osop: A multi-stage one shot object pose estimation framework.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib54.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib54.8.3" style="font-size:80%;">, pages 6835–6844, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib55.2.2.1" style="font-size:80%;">[55]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.4.1" style="font-size:80%;">
Yongzhi Su, Mahdi Saleh, Torben Fetzer, Jason Rambach, Nassir Navab, Benjamin
Busam, Didier Stricker, and Federico Tombari.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.5.1" style="font-size:80%;">Zebrapose: Coarse to fine surface encoding for 6dof object pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib55.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib55.8.3" style="font-size:80%;">, pages 6738–6748, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib56.2.2.1" style="font-size:80%;">[56]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.4.1" style="font-size:80%;">
Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.5.1" style="font-size:80%;">LoFTR: Detector-free local feature matching with transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib56.6.1" style="font-size:80%;">CVPR</span><span class="ltx_text" id="bib.bib56.7.2" style="font-size:80%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib57.2.2.1" style="font-size:80%;">[57]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.4.1" style="font-size:80%;">
Jiaming Sun, Zihao Wang, Siyu Zhang, Xingyi He, Hongcheng Zhao, Guofeng Zhang,
and Xiaowei Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.5.1" style="font-size:80%;">Onepose: One-shot object pose estimation without cad models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib57.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib57.8.3" style="font-size:80%;">, pages 6825–6834, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib58.2.2.1" style="font-size:80%;">[58]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.4.1" style="font-size:80%;">
David Joseph Tan, Federico Tombari, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.5.1" style="font-size:80%;">Real-time accurate 3d head tracking and pose estimation with consumer
rgb-d cameras.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib58.6.1" style="font-size:80%;">International Journal of Computer Vision</span><span class="ltx_text" id="bib.bib58.7.2" style="font-size:80%;">, 126:158–183, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib59.2.2.1" style="font-size:80%;">[59]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.4.1" style="font-size:80%;">
Bugra Tekin, Sudipta N Sinha, and Pascal Fua.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.5.1" style="font-size:80%;">Real-time seamless single shot 6d object pose prediction.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib59.7.2" style="font-size:80%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span class="ltx_text" id="bib.bib59.8.3" style="font-size:80%;">, pages 292–301, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib60.2.2.1" style="font-size:80%;">[60]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.4.1" style="font-size:80%;">
Meng Tian, Marcelo H Ang, and Gim Hee Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.5.1" style="font-size:80%;">Shape prior deformation for categorical 6d object pose and size
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib60.7.2" style="font-size:80%;">Computer Vision–ECCV 2020, : 16th European Conference,
Glasgow, UK, August 23–28, 2020, Proceedings, Part XXI 16</span><span class="ltx_text" id="bib.bib60.8.3" style="font-size:80%;">, pages 530–546.
Springer, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib61.2.2.1" style="font-size:80%;">[61]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.4.1" style="font-size:80%;">
Shinji Umeyama.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.5.1" style="font-size:80%;">Least-squares estimation of transformation parameters between two
point patterns.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib61.6.1" style="font-size:80%;">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</span><span class="ltx_text" id="bib.bib61.7.2" style="font-size:80%;">,
13(04):376–380, 1991.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib62.2.2.1" style="font-size:80%;">[62]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.4.1" style="font-size:80%;">
Boyan Wan, Yifei Shi, and Kai Xu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.5.1" style="font-size:80%;">Socs: Semantically-aware object coordinate space for category-level
6d object pose estimation under large shape variations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib62.6.1" style="font-size:80%;">arXiv preprint arXiv:2303.10346</span><span class="ltx_text" id="bib.bib62.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib63.2.2.1" style="font-size:80%;">[63]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.4.1" style="font-size:80%;">
Angtian Wang, Adam Kortylewski, and Alan Yuille.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.5.1" style="font-size:80%;">Nemo: Neural mesh models of contrastive features for robust 3d pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib63.6.1" style="font-size:80%;">arXiv preprint arXiv:2101.12378</span><span class="ltx_text" id="bib.bib63.7.2" style="font-size:80%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib64.2.2.1" style="font-size:80%;">[64]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.4.1" style="font-size:80%;">
Gu Wang, Fabian Manhardt, Federico Tombari, and Xiangyang Ji.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.5.1" style="font-size:80%;">Gdr-net: Geometry-guided direct regression network for monocular 6d
object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib64.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib64.8.3" style="font-size:80%;">, pages 16611–16621, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib65.2.2.1" style="font-size:80%;">[65]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.4.1" style="font-size:80%;">
He Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran Song, and
Leonidas J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.5.1" style="font-size:80%;">Normalized object coordinate space for category-level 6d object pose
and size estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib65.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib65.8.3" style="font-size:80%;">, pages 2642–2651, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib66.2.2.1" style="font-size:80%;">[66]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.4.1" style="font-size:80%;">
Tianfu Wang, Guosheng Hu, and Hongguang Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.5.1" style="font-size:80%;">Object pose estimation via the aggregation of diffusion features.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib66.6.1" style="font-size:80%;">arXiv preprint arXiv:2403.18791</span><span class="ltx_text" id="bib.bib66.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib67.2.2.1" style="font-size:80%;">[67]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.4.1" style="font-size:80%;">
Bowen Wen, Jonathan Tremblay, Valts Blukis, Stephen Tyree, Thomas Müller,
Alex Evans, Dieter Fox, Jan Kautz, and Stan Birchfield.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.5.1" style="font-size:80%;">Bundlesdf: Neural 6-dof tracking and 3d reconstruction of unknown
objects.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib67.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib67.8.3" style="font-size:80%;">, pages 606–617, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib68.2.2.1" style="font-size:80%;">[68]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.4.1" style="font-size:80%;">
Bowen Wen, Wei Yang, Jan Kautz, and Stan Birchfield.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.5.1" style="font-size:80%;">Foundationpose: Unified 6d pose estimation and tracking of novel
objects.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib68.6.1" style="font-size:80%;">arXiv preprint arXiv:2312.08344</span><span class="ltx_text" id="bib.bib68.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib69.2.2.1" style="font-size:80%;">[69]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.4.1" style="font-size:80%;">
Yu Xiang, Tanner Schmidt, Venkatraman Narayanan, and Dieter Fox.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.5.1" style="font-size:80%;">Posecnn: A convolutional neural network for 6d object pose estimation
in cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib69.6.1" style="font-size:80%;">arXiv preprint arXiv:1711.00199</span><span class="ltx_text" id="bib.bib69.7.2" style="font-size:80%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib70.2.2.1" style="font-size:80%;">[70]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.4.1" style="font-size:80%;">
Yan Xu, Kwan-Yee Lin, Guofeng Zhang, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.5.1" style="font-size:80%;">Rnnpose: Recurrent 6-dof object pose refinement with robust
correspondence field estimation and pose optimization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib70.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib70.8.3" style="font-size:80%;">, pages 14880–14890, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib71.2.2.1" style="font-size:80%;">[71]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.4.1" style="font-size:80%;">
Heng Yang and Marco Pavone.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.5.1" style="font-size:80%;">Object pose estimation with statistical guarantees: Conformal
keypoint detection and geometric uncertainty propagation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib71.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib71.8.3" style="font-size:80%;">, pages 8947–8958, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib72.2.2.1" style="font-size:80%;">[72]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.4.1" style="font-size:80%;">
Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, and Hengshuang
Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.5.1" style="font-size:80%;">Depth anything: Unleashing the power of large-scale unlabeled data.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib72.6.1" style="font-size:80%;">arXiv preprint arXiv:2401.10891</span><span class="ltx_text" id="bib.bib72.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib73.2.2.1" style="font-size:80%;">[73]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.4.1" style="font-size:80%;">
Sergey Zakharov, Ivan Shugurov, and Slobodan Ilic.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.5.1" style="font-size:80%;">Dpod: 6d pose object detector and refiner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib73.7.2" style="font-size:80%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib73.8.3" style="font-size:80%;">, pages 1941–1950, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib74.2.2.1" style="font-size:80%;">[74]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.4.1" style="font-size:80%;">
Hansong Zhang and Kenneth E Hoff III.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.5.1" style="font-size:80%;">Fast backface culling using normal masks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib74.7.2" style="font-size:80%;">Proceedings of the 1997 symposium on Interactive 3D
graphics</span><span class="ltx_text" id="bib.bib74.8.3" style="font-size:80%;">, pages 103–ff, 1997.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib75.2.2.1" style="font-size:80%;">[75]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.4.1" style="font-size:80%;">
Jason Y Zhang, Deva Ramanan, and Shubham Tulsiani.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.5.1" style="font-size:80%;">Relpose: Predicting probabilistic relative rotation for single
objects in the wild.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.6.1" style="font-size:80%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib75.7.2" style="font-size:80%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib75.8.3" style="font-size:80%;">, pages 592–611.
Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib76.2.2.1" style="font-size:80%;">[76]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.4.1" style="font-size:80%;">
Chen Zhao, Tong Zhang, Zheng Dang, and Mathieu Salzmann.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.5.1" style="font-size:80%;">Dvmnet: Computing relative pose for unseen objects beyond hypotheses.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib76.6.1" style="font-size:80%;">arXiv preprint arXiv:2403.13683</span><span class="ltx_text" id="bib.bib76.7.2" style="font-size:80%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib77.2.2.1" style="font-size:80%;">[77]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.4.1" style="font-size:80%;">
Chen Zhao, Tong Zhang, and Mathieu Salzmann.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.5.1" style="font-size:80%;">3d-aware hypothesis &amp; verification for generalizable relative object
pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib77.6.1" style="font-size:80%;">arXiv preprint arXiv:2310.03534</span><span class="ltx_text" id="bib.bib77.7.2" style="font-size:80%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib78.2.2.1" style="font-size:80%;">[78]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.4.1" style="font-size:80%;">
Hang Zhao, Orazio Gallo, Iuri Frosio, and Jan Kautz.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.5.1" style="font-size:80%;">Loss functions for image restoration with neural networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib78.6.1" style="font-size:80%;">IEEE Transactions on computational imaging</span><span class="ltx_text" id="bib.bib78.7.2" style="font-size:80%;">, 3(1):47–57, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib79.2.2.1" style="font-size:80%;">[79]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.4.1" style="font-size:80%;">
Xu Zhao, Wenchao Ding, Yongqi An, Yinglong Du, Tao Yu, Min Li, Ming Tang, and
Jinqiao Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.5.1" style="font-size:80%;">Fast segment anything, 2023.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">See pages 1,2,3 of <a class="ltx_ref" href="sm.pdf" title="">sm.pdf</a></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 26 16:00:22 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
