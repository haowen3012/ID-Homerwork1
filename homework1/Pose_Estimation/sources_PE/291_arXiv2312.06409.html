<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation</title>
<!--Generated on Tue Jul 16 09:28:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.06409v3/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S1" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S2" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S2.SS1" title="In 2 Related Works ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>3D Human Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S2.SS2" title="In 2 Related Works ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Synthetic Dataset Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S2.SS3" title="In 2 Related Works ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Unsupervised Domain Adaption Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.SS1" title="In 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>3D Human Pose Estimation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.SS2" title="In 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Unsupervised Domain Adaptation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.SS2.SSS1" title="In 3.2 Unsupervised Domain Adaptation ‣ 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>SyncHuman Generator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.SS2.SSS2" title="In 3.2 Unsupervised Domain Adaptation ‣ 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Unsupervised Domain Adaptation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS1" title="In 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Implementation details.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS2" title="In 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Datasets and Metrics.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS3" title="In 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>3D Pose Estimation Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS4" title="In 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Unsupervised Domain Adaption</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS4.SSS1" title="In 4.4 Unsupervised Domain Adaption ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.1 </span>Synthetic Setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS4.SSS2" title="In 4.4 Unsupervised Domain Adaption ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.2 </span>Ablation Study on Unsupervised Training Losses</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS5" title="In 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Entropy Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S5" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S6" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Different Scanning Patterns of Point Cloud</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S7" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>BaseketBall</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S8" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>SyncHuman Generator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S9" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Human Prior Loss</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S10" title="In LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Extended Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S10.SS1" title="In 10 Extended Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.1 </span>Human Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S10.SS2" title="In 10 Extended Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10.2 </span>Entropy Analysis</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhiyu Pan
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhicheng Zhong
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wenxuan Guo
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yifan Chen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jianjiang Feng
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jie Zhou
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Department of Automation, Tsinghua University, China 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1" style="font-size:90%;">{pzy20, zhongzc18, gwx22, chenyf21}@mails.tsinghua.edu.cn</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2" style="font-size:90%;">{jfeng, jzhou}@tsinghua.edu.cn</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Several methods have been proposed to estimate 3D human pose from multi-view images, achieving satisfactory performance on public datasets collected under relatively simple conditions. However, there are limited approaches studying extracting 3D human skeletons from multimodal inputs, such as RGB and point cloud data. To address this gap, we introduce LiCamPose, a pipeline that integrates multi-view RGB and sparse point cloud information to estimate robust 3D human poses via single frame. We demonstrate the effectiveness of the volumetric architecture in combining these modalities. Furthermore, to circumvent the need for manually labeled 3D human pose annotations, we develop a synthetic dataset generator for pretraining and design an unsupervised domain adaptation strategy to train a 3D human pose estimator without manual annotations. To validate the generalization capability of our method, LiCamPose is evaluated on four datasets, including two public datasets, one synthetic dataset, and one challenging self-collected dataset named BasketBall, covering diverse scenarios. The results demonstrate that LiCamPose exhibits great generalization performance and significant application potential. The code, generator, and datasets will be made available upon acceptance of this paper.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Human pose estimation is a fundamental task in computer vision and has been widely applied in various fields, such as human-computer interaction, human activity recognition, sports analytics, augmented reality, etc. Specifically, multi-view image datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib49" title="">49</a>]</cite> allow more precise 3D human pose estimation compared to single-view ones <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib33" title="">33</a>]</cite>, due to the ability of multiple views to capture 3D information from epipolar geometry. As technology advances, researchers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib42" title="">42</a>]</cite> have achieved promising results on current public multi-view images datasets. However, practical scenarios are more challenging than existing public datasets, with diverse human motions, severe occlusions, and large scene.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="596" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">The LiCamPose pipeline for extracting 3D poses, as exemplified by the BasketBall dataset, involves pretraining on synthetic data from SyncHuman, followed by detecting and tracking individuals, and finally using unsupervised domain adaptation to estimate poses.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Fusing LiDAR point clouds with RGB camera information has been demonstrated to significantly enhance object detection and tracking performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib52" title="">52</a>]</cite>, leveraging their complementary nature.
LiDAR sensor can obtain precise but quite sparse 3D measurements over long range, while camera can capture images of high resolution but lacks depth perception. Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib55" title="">55</a>]</cite> introduced a LiDAR-Camera capturing system capable of simultaneously providing texture and depth information over a wide coverage range. This advancement enables the capture of complex human activities, such as basketball games, using a minimal number of sensors, which is advantageous for system setup and cost reduction. However, their application has thus far been limited to human detection and tracking. It is essential to consider integrating the information from multiple modalities and multiple views, and fusing them into a cohesive representation which can significantly facilitate the accuracy of 3D human pose estimation.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper, we introduce LiCamPose (Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a>), a 3D human pose estimation pipeline that utilizes multi-view single-frame LiDAR-Camera inputs. We unify different modalities into a volumetric space that reserve each modality’s geometric characteristics which facilitates better realization of single-person 3D pose estimation. Researchers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib53" title="">53</a>]</cite> have shown the effectiveness of voxel-based method. Volumetric architecture can naturally model a space’s geometric characteristics. Besides, it is straightforward to either map the point cloud information or back-project the 2D information into the 3D volumetric representation.
Regarding how to achieve multi-person detection, some pointcloud-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib34" title="">34</a>]</cite> illustrates that they can detect objects accurately with the assist of point cloud. Hence, LiCamPose combines human detection and voxel-based 3D human pose estimation in a top-down manner.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Manually annotating or capturing 3D poses for multiple individuals in large scenes is challenging, time-consuming, and difficult. To achieve better results across diverse scenarios without relying on pose labels, we adopt a two-stage approach: first, pretraining on a synthetic dataset, and then performing unsupervised domain adaptation training on the target dataset. We have developed a synthetic dataset generator named SyncHuman for pretraining. SyncHuman can produce a large volume of synthetic data with multi-modal information, allowing us to adjust LiDAR and camera settings in scenes to meet practical requirements. Moreover, avatar actions are varied and sourced from existing action files or pose annotation files from public motion capture datasets like AMASS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib37" title="">37</a>]</cite>. Consequently, the synthetic data includes accurate 3D pose ground truth for groups of people engaging in complex actions.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To bridge the gap between synthetic data and real-world scenarios, we adopt unsupervised domain adaptation training and propose an efficient strategy that includes entropy-guided pseudo 3D pose supervision, pseudo 2D pose supervision, and constraints based on human pose priors. Using volumetric representation, our approach yields 3D human joint heatmaps, with each channel representing a joint’s probability distribution. We calculate each channel’s entropy to gauge confidence in the corresponding joints, filtering out implausible poses and deriving pseudo 3D pose labels during unsupervised domain adaptation. We utilize off-the-shelf 2D pose estimation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib51" title="">51</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib11" title="">11</a>]</cite> to generate pseudo 2D pose labels for supervision. Additionally, we introduce an intuitive human prior loss to enforce coherence in the predicted 3D poses. By integrating these methodologies, we develop a 3D human pose estimation algorithm that leverages multi-view point cloud and RGB data without requiring annotations on the target dataset. To further validate LiCamPose, we built a four-view LiDAR-Camera system to capture a basketball game, creating the BasketBall dataset for qualitative evaluation of our method.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We summarize the contributions of this paper as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose LiCamPose, a simple and effective pipeline for fusing multi-view, sparse point cloud and RGB information to estimate 3D poses of multiple individuals from single frame.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We developed SyncHuman, a generator for synthetic data under various camera and LiDAR settings. Additionally, we created a four-view LiDAR-Camera system to capture real data from a basketball game, resulting in the BasketBall dataset.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We propose a training strategy that avoids manual annotations by pretraining on synthetic data from SyncHuman and using unsupervised domain adaptation on the target dataset.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we conduct the literature review according to the three contribution points we proposed.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>3D Human Pose Estimation</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">Image-based.</span>
The basic 3D pose estimation method typically follows a two-stage process: first estimating the 2D pose and then lifting it into 3D space <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib42" title="">42</a>]</cite>. For multi-person settings, some methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a>]</cite> match pedestrians from different views and locate them through 2D pose similarity. However, these methods are not robust to inaccurate 2D pose results. Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib54" title="">54</a>]</cite> directly use 2D images as inputs and regress the 3D pose with a transformer architecture, but their training process is time-consuming. Voxel-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib42" title="">42</a>]</cite> locate each person in a 3D volumetric space and estimate 3D poses, significantly improving the precision of 3D human pose estimation. However, these voxel-based methods are not suitable for large scenes due to their high computational cost when detecting people. LiCamPose utilizes pointcloud-based method to locate and track pedestrians, and then employs voxel-based pose estimation for each individual.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">Pointcloud-based.</span>
Initially, several 3D pose estimation methods were based on single-view depth maps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib38" title="">38</a>]</cite>, treating the depth map as 2D information with depth values. Conversely, some methods back-project the depth map into 3D space as a dense 3D point cloud and utilize PointNet networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib3" title="">3</a>]</cite>. Moon et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib39" title="">39</a>]</cite> proposed a single-person pose estimation approach that treats the depth map as a point cloud and fills it into a volumetric space. Bekhtaoui et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib3" title="">3</a>]</cite> employed a PointNet-based approach to detect and estimate 3D human pose. More recently, Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib30" title="">30</a>]</cite> used sparse point clouds scanned from LiDAR to estimate single-person 3D human pose. However, sparse point clouds do not provide sufficient information for accurate 3D pose estimation. Multi-modal fusion is beneficial for precise 3D human pose perception.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.p3.1.1">Multi-modal based.</span>
Several works have been introduced for RGBD human pose estimation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib14" title="">14</a>]</cite>, demonstrating that multi-modal information not only aids in detecting individuals but also ensures the accuracy of 3D human pose estimation. Regarding point cloud and RGB information fusion methods, some approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib18" title="">18</a>]</cite> fuse these modalities at the point level by attaching extracted 2D features to each 3D point. A few methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib31" title="">31</a>]</cite> employ a feature-level fusion strategy. However, these methods do not integrate the different modalities in a feature space that preserves each modality’s spatial properties. In contrast, LiCamPose uses a volumetric representation to unify point cloud and RGB information, preserving the original spatial properties of the real-world space.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.4.1.1" style="font-size:129%;">Table 1</span>: </span><span class="ltx_text" id="S2.T1.5.2" style="font-size:129%;">Comparison of synthetic datasets related to human.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.6" style="width:433.6pt;height:205.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(32.5pt,-15.4pt) scale(1.17612181825142,1.17612181825142) ;">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.6.1">
<tr class="ltx_tr" id="S2.T1.6.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.6.1.1.1" rowspan="2"><span class="ltx_text" id="S2.T1.6.1.1.1.1" style="font-size:70%;">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.1.1.1.1">
<span class="ltx_tr" id="S2.T1.6.1.1.1.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.1.1.1.1.1.1">Synthetic</span></span>
<span class="ltx_tr" id="S2.T1.6.1.1.1.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.1.1.1.1.2.1">Dataset</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="5" id="S2.T1.6.1.1.2"><span class="ltx_text" id="S2.T1.6.1.1.2.1" style="font-size:70%;">Scene setup</span></td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2" id="S2.T1.6.1.1.3"><span class="ltx_text" id="S2.T1.6.1.1.3.1" style="font-size:70%;">Labels</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.2">
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.2.1">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.1.1">
<tr class="ltx_tr" id="S2.T1.6.1.2.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.1.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.1.1.1.1.1" style="font-size:70%;">Multi-</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.2.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.1.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.1.1.2.1.1" style="font-size:70%;">View</span></td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.2.2">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.2.1">
<tr class="ltx_tr" id="S2.T1.6.1.2.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.2.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.2.1.1.1.1" style="font-size:70%;">Multi-</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.2.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.2.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.2.1.2.1.1" style="font-size:70%;">Person</span></td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.6.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.6.1.2.3.1">
<span class="ltx_p" id="S2.T1.6.1.2.3.1.1" style="width:8.0pt;">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.3.1.1.1">
<span class="ltx_tr" id="S2.T1.6.1.2.3.1.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S2.T1.6.1.2.3.1.1.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.3.1.1.1.1.1.1" style="font-size:70%;">RGB</span></span></span>
<span class="ltx_tr" id="S2.T1.6.1.2.3.1.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S2.T1.6.1.2.3.1.1.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.3.1.1.1.2.1.1" style="font-size:70%;">Image</span></span></span>
</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.6.1.2.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.6.1.2.4.1">
<span class="ltx_p" id="S2.T1.6.1.2.4.1.1" style="width:8.0pt;">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.4.1.1.1">
<span class="ltx_tr" id="S2.T1.6.1.2.4.1.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S2.T1.6.1.2.4.1.1.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.4.1.1.1.1.1.1" style="font-size:70%;">Depth</span></span></span>
<span class="ltx_tr" id="S2.T1.6.1.2.4.1.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S2.T1.6.1.2.4.1.1.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.4.1.1.1.2.1.1" style="font-size:70%;">Image</span></span></span>
</span></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.2.5">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.5.1">
<tr class="ltx_tr" id="S2.T1.6.1.2.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.5.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.5.1.1.1.1" style="font-size:70%;">LiDAR</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.2.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.5.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.5.1.2.1.1" style="font-size:70%;">Pointcloud</span></td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.2.6">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.6.1">
<tr class="ltx_tr" id="S2.T1.6.1.2.6.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.6.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.6.1.1.1.1" style="font-size:70%;">2D</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.2.6.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.6.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.6.1.2.1.1" style="font-size:70%;">Pose</span></td>
</tr>
</table>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.2.7">
<table class="ltx_tabular ltx_align_middle" id="S2.T1.6.1.2.7.1">
<tr class="ltx_tr" id="S2.T1.6.1.2.7.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.7.1.1.1"><span class="ltx_text" id="S2.T1.6.1.2.7.1.1.1.1" style="font-size:70%;">3D</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.2.7.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.6.1.2.7.1.2.1"><span class="ltx_text" id="S2.T1.6.1.2.7.1.2.1.1" style="font-size:70%;">Pose</span></td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.6.1.3.1">
<span class="ltx_text" id="S2.T1.6.1.3.1.1" style="font-size:70%;">CAPE </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.T1.6.1.3.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib36" title="">36</a><span class="ltx_text" id="S2.T1.6.1.3.1.3.2" style="font-size:70%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.2">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.2.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.2.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.3">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.3.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.3.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.4">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.4.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.4.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.5">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.5.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.5.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.6">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.6.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.6.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.7">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.7.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.7.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" id="S2.T1.6.1.3.8">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.3.8.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.3.8.2" style="font-size:70%;">2713</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.4">
<td class="ltx_td ltx_align_left" id="S2.T1.6.1.4.1">
<span class="ltx_text" id="S2.T1.6.1.4.1.1" style="font-size:70%;">SURREAL </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.T1.6.1.4.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib48" title="">48</a><span class="ltx_text" id="S2.T1.6.1.4.1.3.2" style="font-size:70%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.2">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.2.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.2.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.3">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.3.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.3.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.4">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.4.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.4.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.5">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.5.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.5.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.6">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.6.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.6.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.7">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.7.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.7.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.4.8">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.4.8.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.4.8.2" style="font-size:70%;">2713</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.5">
<td class="ltx_td ltx_align_left" id="S2.T1.6.1.5.1">
<span class="ltx_text" id="S2.T1.6.1.5.1.1" style="font-size:70%;">PSP </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.T1.6.1.5.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib10" title="">10</a><span class="ltx_text" id="S2.T1.6.1.5.1.3.2" style="font-size:70%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.2">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.2.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.2.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.3">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.3.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.3.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.4">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.4.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.4.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.5">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.5.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.5.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.6">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.6.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.6.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.7">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.7.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.7.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.5.8">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.5.8.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.5.8.2" style="font-size:70%;">2717</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.6">
<td class="ltx_td ltx_align_left" id="S2.T1.6.1.6.1">
<span class="ltx_text" id="S2.T1.6.1.6.1.1" style="font-size:70%;">CALAR </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.T1.6.1.6.1.2.1" style="font-size:70%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib9" title="">9</a><span class="ltx_text" id="S2.T1.6.1.6.1.3.2" style="font-size:70%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.2">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.2.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.2.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.3">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.3.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.3.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.4">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.4.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.4.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.5">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.5.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.5.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.6">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.6.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.6.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.7">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.7.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.7.2" style="font-size:70%;">2717</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" id="S2.T1.6.1.6.8">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.6.8.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.6.8.2" style="font-size:70%;">2717</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.6.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.6.1.7.1"><span class="ltx_text ltx_font_italic" id="S2.T1.6.1.7.1.1" style="font-size:70%;">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.2">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.2.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.2.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.3">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.3.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.3.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.4">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.4.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.4.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.5">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.5.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.5.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.6">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.6.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.6.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.7">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.7.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.7.2" style="font-size:70%;">2713</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_bb" id="S2.T1.6.1.7.8">
<span class="ltx_ERROR undefined" id="S2.T1.6.1.7.8.1">\usym</span><span class="ltx_text" id="S2.T1.6.1.7.8.2" style="font-size:70%;">2713</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic Dataset Generation</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Manually annotating 3D human poses is extremely challenging. Therefore, synthetic datasets are beneficial and useful for pretraining models. Several synthetic datasets for 3D human pose estimation have been developed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib36" title="">36</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib10" title="">10</a>]</cite>. However, these datasets typically feature an RGB photo from one view with random backgrounds and do not consider the realistic interaction between avatars and their environment. Dosovitskiy et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib9" title="">9</a>]</cite> provide a large-scale synthetic dataset for autonomous driving, but it lacks 3D human pose labels, and the actions of the characters are monotonous.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">We introduce our synthetic dataset generator, SyncHuman, which can produce data with greater richness and diversity (Table <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S2.T1" title="Table 1 ‣ 2.1 3D Human Pose Estimation ‣ 2 Related Works ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">1</span></a>). Furthermore, we will release the generation tool, allowing researchers to adjust settings according to their needs via our provided APIs</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Unsupervised Domain Adaption Training</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Numerous works have focused on unsupervised or domain adaptation methods for single-view 3D human pose estimation. Kocabas et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib26" title="">26</a>]</cite> use multi-view geometry to supervise single-view predictions. Several methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib27" title="">27</a>]</cite> employ a teacher-student framework for domain adaptation. Some approaches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib57" title="">57</a>]</cite> utilize optical flow or depth as inputs, which are less affected by domain shifts compared to RGB. Bigalke et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib5" title="">5</a>]</cite> incorporate human prior loss based on human anatomy, while Kundu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib28" title="">28</a>]</cite> define the uncertainty of predictions and control this uncertainty during training. For multi-view 3D human pose generation, some works use non-deeplearning methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib43" title="">43</a>]</cite>. 3DPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib4" title="">4</a>]</cite> and basic triangulation achieve 3D poses with significant computational complexity or inaccuracy. Remelli et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib43" title="">43</a>]</cite> proposed an efficient direct linear transformation (DLT) method that quickly produces relatively accurate 3D results.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Our approach utilizes multi-view 2D pose heatmaps derived from RGB data alongside point clouds, ensuring minimal impact from domain variations. We utilize information entropy to help select reliable results as pseudo 3D labels. Additionally, we incorporate a human prior loss to ensure the plausibility of 3D poses.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="375" id="S2.F2.g1" src="x2.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.3.2" style="font-size:90%;">The detailed structure of LiCamPose in 3D human pose estimation and its corresponding losses calculations.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We introduce LiCamPose from two perspectives: 3D human pose estimation and unsupervised domain adaptation (Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S2.F2" title="Figure 2 ‣ 2.3 Unsupervised Domain Adaption Training ‣ 2 Related Works ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>). Section <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.SS1" title="3.1 3D Human Pose Estimation ‣ 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">3.1</span></a> details the top-down approach for 3D human pose estimation. Section <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.SS2" title="3.2 Unsupervised Domain Adaptation ‣ 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">3.2</span></a> explains how we generate the synthetic dataset to support the training of the pose estimation model using point cloud and RGB data, and how we utilize information entropy and human prior loss to achieve domain adaptation.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>3D Human Pose Estimation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.3">Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib42" title="">42</a>]</cite>, we adopt a top-down approach to estimate 3D poses. Specifically, we use PointPillars <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib29" title="">29</a>]</cite> to detect the 3D bounding box of each person. Once we obtain the 3D bounding box, we derive the 2D bounding box in each view for 2D pose estimation and extract the corresponding point cloud. Initially, we define a volumetric space centered at the point cloud’s centroid, with a size consistent with the detected bounding boxes, and discretize it into an <math alttext="X\times Y\times Z" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">X</mi><mo id="S3.SS1.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.1.m1.1.1.1.cmml">×</mo><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">Y</mi><mo id="S3.SS1.p1.1.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.1.m1.1.1.1.cmml">×</mo><mi id="S3.SS1.p1.1.m1.1.1.4" xref="S3.SS1.p1.1.m1.1.1.4.cmml">Z</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><times id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></times><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑋</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">𝑌</ci><ci id="S3.SS1.p1.1.m1.1.1.4.cmml" xref="S3.SS1.p1.1.m1.1.1.4">𝑍</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">X\times Y\times Z</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_X × italic_Y × italic_Z</annotation></semantics></math> resolution. We fill each voxel based on the coordinates of the point cloud, assigning a value of <math alttext="1" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><cn id="S3.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">1</annotation></semantics></math> to voxels containing points from the point cloud. This allows us to obtain the pointcloud-related feature map <math alttext="f_{\text{p}}\in\mathbb{R}^{F_{1}\times X\times Y\times Z}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><msub id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2.2" xref="S3.SS1.p1.3.m3.1.1.2.2.cmml">f</mi><mtext id="S3.SS1.p1.3.m3.1.1.2.3" xref="S3.SS1.p1.3.m3.1.1.2.3a.cmml">p</mtext></msub><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml"><msub id="S3.SS1.p1.3.m3.1.1.3.3.2" xref="S3.SS1.p1.3.m3.1.1.3.3.2.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.3.2.2" xref="S3.SS1.p1.3.m3.1.1.3.3.2.2.cmml">F</mi><mn id="S3.SS1.p1.3.m3.1.1.3.3.2.3" xref="S3.SS1.p1.3.m3.1.1.3.3.2.3.cmml">1</mn></msub><mo id="S3.SS1.p1.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.3.cmml">X</mi><mo id="S3.SS1.p1.3.m3.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3.4" xref="S3.SS1.p1.3.m3.1.1.3.3.4.cmml">Y</mi><mo id="S3.SS1.p1.3.m3.1.1.3.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3.5" xref="S3.SS1.p1.3.m3.1.1.3.3.5.cmml">Z</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><in id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></in><apply id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2">𝑓</ci><ci id="S3.SS1.p1.3.m3.1.1.2.3a.cmml" xref="S3.SS1.p1.3.m3.1.1.2.3"><mtext id="S3.SS1.p1.3.m3.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.p1.3.m3.1.1.2.3">p</mtext></ci></apply><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3"><times id="S3.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.1"></times><apply id="S3.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.2.2">𝐹</ci><cn id="S3.SS1.p1.3.m3.1.1.3.3.2.3.cmml" type="integer" xref="S3.SS1.p1.3.m3.1.1.3.3.2.3">1</cn></apply><ci id="S3.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.3">𝑋</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.4.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.4">𝑌</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.5.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.5">𝑍</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">f_{\text{p}}\in\mathbb{R}^{F_{1}\times X\times Y\times Z}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_f start_POSTSUBSCRIPT p end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_X × italic_Y × italic_Z end_POSTSUPERSCRIPT</annotation></semantics></math> using the 3D convolutional backbone V2V-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib39" title="">39</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.6">Thanks to the development of 2D pose estimation methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib51" title="">51</a>]</cite>, robust 2D pose results can be predicted using off-the-shelf techniques. We use these methods to obtain 2D pose heatmaps from RGB information of each view. These multi-view heatmaps are then back-projected into the volumetric space according to each camera’s settings, and V2V-Net is used to extract the RGB-related features <math alttext="f_{\text{c}}\in\mathbb{R}^{F_{2}\times X\times Y\times Z}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><msub id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2.2" xref="S3.SS1.p2.1.m1.1.1.2.2.cmml">f</mi><mtext id="S3.SS1.p2.1.m1.1.1.2.3" xref="S3.SS1.p2.1.m1.1.1.2.3a.cmml">c</mtext></msub><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml"><msub id="S3.SS1.p2.1.m1.1.1.3.3.2" xref="S3.SS1.p2.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS1.p2.1.m1.1.1.3.3.2.2" xref="S3.SS1.p2.1.m1.1.1.3.3.2.2.cmml">F</mi><mn id="S3.SS1.p2.1.m1.1.1.3.3.2.3" xref="S3.SS1.p2.1.m1.1.1.3.3.2.3.cmml">2</mn></msub><mo id="S3.SS1.p2.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.3.cmml">X</mi><mo id="S3.SS1.p2.1.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3.4" xref="S3.SS1.p2.1.m1.1.1.3.3.4.cmml">Y</mi><mo id="S3.SS1.p2.1.m1.1.1.3.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3.5" xref="S3.SS1.p2.1.m1.1.1.3.3.5.cmml">Z</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><in id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></in><apply id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.2.1.cmml" xref="S3.SS1.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2.2">𝑓</ci><ci id="S3.SS1.p2.1.m1.1.1.2.3a.cmml" xref="S3.SS1.p2.1.m1.1.1.2.3"><mtext id="S3.SS1.p2.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.p2.1.m1.1.1.2.3">c</mtext></ci></apply><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3"><times id="S3.SS1.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.1"></times><apply id="S3.SS1.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.2.2">𝐹</ci><cn id="S3.SS1.p2.1.m1.1.1.3.3.2.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.3.3.2.3">2</cn></apply><ci id="S3.SS1.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.3">𝑋</ci><ci id="S3.SS1.p2.1.m1.1.1.3.3.4.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.4">𝑌</ci><ci id="S3.SS1.p2.1.m1.1.1.3.3.5.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3.5">𝑍</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">f_{\text{c}}\in\mathbb{R}^{F_{2}\times X\times Y\times Z}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_f start_POSTSUBSCRIPT c end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT × italic_X × italic_Y × italic_Z end_POSTSUPERSCRIPT</annotation></semantics></math>. We concatenate the features from both modalities in the same 3D feature space to get fusion feature <math alttext="f" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">f</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_f</annotation></semantics></math> and obtain the final 3D human pose heatmap <math alttext="h" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">h</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_h</annotation></semantics></math> via a Fusion-Net. To mitigate quantization error, we adopt <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.6.1">Soft-argmax</span> to calculate each joint’s 3D coordinate <math alttext="J^{k}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msup id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">J</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐽</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">J^{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_J start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> from the 3D heatmaps and minimize the <math alttext="L_{1}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">L</mi><mn id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝐿</ci><cn id="S3.SS1.p2.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">L_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> loss with the ground truth <math alttext="J_{*}^{k}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><msubsup id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2.2" xref="S3.SS1.p2.6.m6.1.1.2.2.cmml">J</mi><mo id="S3.SS1.p2.6.m6.1.1.2.3" xref="S3.SS1.p2.6.m6.1.1.2.3.cmml">∗</mo><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">superscript</csymbol><apply id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2.2">𝐽</ci><times id="S3.SS1.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.3"></times></apply><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">J_{*}^{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_J start_POSTSUBSCRIPT ∗ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E1">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E1X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{pose}}=\sum_{k=1}^{K}\left\|J^{k}-J_{*}^{k}%
\right\|_{1}," class="ltx_Math" display="inline" id="S3.E1X.2.1.1.m1.1"><semantics id="S3.E1X.2.1.1.m1.1a"><mrow id="S3.E1X.2.1.1.m1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E1X.2.1.1.m1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1X.2.1.1.m1.1.1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.2.cmml">ℒ</mi><mtext id="S3.E1X.2.1.1.m1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.3a.cmml">pose</mtext></msub><mo id="S3.E1X.2.1.1.m1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E1X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml"><munderover id="S3.E1X.2.1.1.m1.1.1.1.1.1.2a" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml"><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.2" movablelimits="false" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml">k</mi><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.3.cmml">K</mi></munderover></mstyle><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">J</mi><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">k</mi></msup><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msubsup id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">J</mi><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">∗</mo><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">k</mi></msubsup></mrow><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow><mo id="S3.E1X.2.1.1.m1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.2.1.1.m1.1b"><apply id="S3.E1X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1"><eq id="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2"></eq><apply id="S3.E1X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.2">ℒ</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.3.3a.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.3"><mtext id="S3.E1X.2.1.1.m1.1.1.1.1.3.3.cmml" mathsize="70%" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.3">pose</mtext></ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1"><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.2"></sum><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3"><eq id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.2">𝑘</ci><cn id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.3">𝐾</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝐽</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2">𝐽</ci><times id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3"></times></apply><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3">𝑘</ci></apply></apply></apply><cn id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.2.1.1.m1.1c">\displaystyle\mathcal{L}_{\text{pose}}=\sum_{k=1}^{K}\left\|J^{k}-J_{*}^{k}%
\right\|_{1},</annotation><annotation encoding="application/x-llamapun" id="S3.E1X.2.1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT pose end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT ∥ italic_J start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT - italic_J start_POSTSUBSCRIPT ∗ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.7">where <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m1.1"><semantics id="S3.SS1.p2.7.m1.1a"><mi id="S3.SS1.p2.7.m1.1.1" xref="S3.SS1.p2.7.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m1.1b"><ci id="S3.SS1.p2.7.m1.1.1.cmml" xref="S3.SS1.p2.7.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m1.1d">italic_K</annotation></semantics></math> is the number of joints.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Unsupervised Domain Adaptation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Due to the lack of annotated multi-view LiDAR-Camera 3D human pose datasets, we opted to generate a synthetic dataset to assist with training. Our designed SyncHuman can create 3D dynamic scenes with multiple persons and accurate labels. Additionally, we developed an efficient unsupervised domain adaptation method by designing a loss function to transfer the pretrained model from the synthetic dataset to a real-world dataset.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>SyncHuman Generator</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.5">We developed the synthetic system based on the Unity Engine. Its flexibility and productivity allow us to create scenes with specific sizes and backgrounds according to our requirements. For sensors, we use Unity’s built-in camera to obtain RGB images and extract depth information from the GPU’s depth buffer using custom shaders in the rendering pipeline. Additionally, we can generate colored point clouds by sampling the depth and RGB images. To simulate the LiDAR scanning process, we sample points according to a time-based scanning function. We currently focus on the Livox Mid-40 LiDAR due to its affordability for sports or surveillance applications.
We use the following function to simulate its scanning process:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E2">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E2X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle r=\alpha\times\mathbb{\cos}(3.825\times(\theta_{0}+0.0017\times n%
))," class="ltx_Math" display="inline" id="S3.E2X.2.1.1.m1.2"><semantics id="S3.E2X.2.1.1.m1.2a"><mrow id="S3.E2X.2.1.1.m1.2.2.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.cmml"><mrow id="S3.E2X.2.1.1.m1.2.2.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.1.1.3" xref="S3.E2X.2.1.1.m1.2.2.1.1.3.cmml">r</mi><mo id="S3.E2X.2.1.1.m1.2.2.1.1.2" xref="S3.E2X.2.1.1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.1.1.1.3" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.3.cmml">α</mi><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.2.cmml">×</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.E2X.2.1.1.m1.1.1" xref="S3.E2X.2.1.1.m1.1.1.cmml">cos</mi><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1a" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.2.cmml"><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.2.cmml">(</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mn id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml">3.825</mn><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml">×</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.cmml">θ</mi><mn id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.cmml">0</mn></msub><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mn id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml">0.0017</mn><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">×</mo><mi id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">n</mi></mrow></mrow><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2X.2.1.1.m1.2.2.1.2" xref="S3.E2X.2.1.1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2X.2.1.1.m1.2b"><apply id="S3.E2X.2.1.1.m1.2.2.1.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1"><eq id="S3.E2X.2.1.1.m1.2.2.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.2"></eq><ci id="S3.E2X.2.1.1.m1.2.2.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.3">𝑟</ci><apply id="S3.E2X.2.1.1.m1.2.2.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1"><times id="S3.E2X.2.1.1.m1.2.2.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.2"></times><ci id="S3.E2X.2.1.1.m1.2.2.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.3">𝛼</ci><apply id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1"><cos id="S3.E2X.2.1.1.m1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1"></cos><apply id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2"></times><cn id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" type="float" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3">3.825</cn><apply id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1"><plus id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2">𝜃</ci><cn id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.cmml" type="integer" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1"></times><cn id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" type="float" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2">0.0017</cn><ci id="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2X.2.1.1.m1.2c">\displaystyle r=\alpha\times\mathbb{\cos}(3.825\times(\theta_{0}+0.0017\times n%
)),</annotation><annotation encoding="application/x-llamapun" id="S3.E2X.2.1.1.m1.2d">italic_r = italic_α × roman_cos ( 3.825 × ( italic_θ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + 0.0017 × italic_n ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS1.p1.4">where <math alttext="n\in[0,t\times 1e5]" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.1.m1.2"><semantics id="S3.SS2.SSS1.p1.1.m1.2a"><mrow id="S3.SS2.SSS1.p1.1.m1.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.2.2.3" xref="S3.SS2.SSS1.p1.1.m1.2.2.3.cmml">n</mi><mo id="S3.SS2.SSS1.p1.1.m1.2.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.2.cmml">∈</mo><mrow id="S3.SS2.SSS1.p1.1.m1.2.2.1.1" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.2.cmml"><mo id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.2" stretchy="false" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.2.cmml">[</mo><mn id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">0</mn><mo id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.2.cmml">,</mo><mrow id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.cmml"><mrow id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.2.cmml">t</mi><mo id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.1.cmml">×</mo><mn id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.3" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.3.cmml">1</mn></mrow><mo id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.1" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.3.cmml">e</mi><mo id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.1a" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.1.cmml">⁢</mo><mn id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.4" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.4.cmml">5</mn></mrow><mo id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.4" stretchy="false" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.2.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.2b"><apply id="S3.SS2.SSS1.p1.1.m1.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2"><in id="S3.SS2.SSS1.p1.1.m1.2.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.2"></in><ci id="S3.SS2.SSS1.p1.1.m1.2.2.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.3">𝑛</ci><interval closure="closed" id="S3.SS2.SSS1.p1.1.m1.2.2.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1"><cn id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.SSS1.p1.1.m1.1.1">0</cn><apply id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1"><times id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.1"></times><apply id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2"><times id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.1"></times><ci id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.2">𝑡</ci><cn id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.3.cmml" type="integer" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.2.3">1</cn></apply><ci id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.3">𝑒</ci><cn id="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.4.cmml" type="integer" xref="S3.SS2.SSS1.p1.1.m1.2.2.1.1.1.4">5</cn></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.2c">n\in[0,t\times 1e5]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.1.m1.2d">italic_n ∈ [ 0 , italic_t × 1 italic_e 5 ]</annotation></semantics></math> and <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.2.m2.1"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><mi id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><ci id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.2.m2.1d">italic_t</annotation></semantics></math> is in second. <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.3.m3.1"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mi id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><ci id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.3.m3.1d">italic_α</annotation></semantics></math> is the scanning radius in pixel, and <math alttext="\theta_{0}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.4.m4.1"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><msub id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p1.4.m4.1.1.2" xref="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml">θ</mi><mn id="S3.SS2.SSS1.p1.4.m4.1.1.3" xref="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><apply id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.2">𝜃</ci><cn id="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS2.SSS1.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">\theta_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.4.m4.1d">italic_θ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> is a random initial angle. This equation is defined in polar coordinate. Final sampling points can be acquired by transforming it from polar coordinates to Cartesian coordinates and translating it to the center of the image space.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1">For the avatars, we download various human 3D models from Adobe Mixamo<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://mixamo.com</span></span></span>. To ensure the diversity of the generated actions, these avatars can be driven by either pre-made action files or keypoint annotations from other public datasets. We have developed driving APIs for COCO17, COCO19 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib33" title="">33</a>]</cite>, and SMPL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib35" title="">35</a>]</cite> standard keypoint annotated inputs. Regarding ground truth data, we can obtain the 3D human pose from the avatars’ humanoid skeleton; the 2D pose label can be acquired by projecting the 3D pose into 2D views. Additionally, we can fetch the mesh vertices of each avatar and compute the semantic segmentation label for each point cloud by considering the pose label simultaneously.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Unsupervised Domain Adaptation</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.3">Similar to the 2D projection supervision used by other unsupervised or weakly supervised methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib15" title="">15</a>]</cite>, we directly utilize an off-the-shelf 2D human pose estimation method to obtain the pseudo 2D pose label <math alttext="\widetilde{J}{\text{2D}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.1.m1.1"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mrow id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS2.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.2.cmml">J</mi><mo id="S3.SS2.SSS2.p1.1.m1.1.1.2.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS2.SSS2.p1.1.m1.1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml">⁢</mo><mtext id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3a.cmml">2D</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><times id="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1"></times><apply id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.1">~</ci><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.2">𝐽</ci></apply><ci id="S3.SS2.SSS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3"><mtext id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">2D</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">\widetilde{J}{\text{2D}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.1.m1.1d">over~ start_ARG italic_J end_ARG 2D</annotation></semantics></math>. The 2D loss <math alttext="\mathcal{L}{\text{2D}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.2.m2.1"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mrow id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.2.m2.1.1.2" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml">ℒ</mi><mo id="S3.SS2.SSS2.p1.2.m2.1.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.1.cmml">⁢</mo><mtext id="S3.SS2.SSS2.p1.2.m2.1.1.3" xref="S3.SS2.SSS2.p1.2.m2.1.1.3a.cmml">2D</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><apply id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1"><times id="S3.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.1"></times><ci id="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2">ℒ</ci><ci id="S3.SS2.SSS2.p1.2.m2.1.1.3a.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.3"><mtext id="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.3">2D</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">\mathcal{L}{\text{2D}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.2.m2.1d">caligraphic_L 2D</annotation></semantics></math> is computed by calculating the <math alttext="L_{2}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.3.m3.1"><semantics id="S3.SS2.SSS2.p1.3.m3.1a"><msub id="S3.SS2.SSS2.p1.3.m3.1.1" xref="S3.SS2.SSS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p1.3.m3.1.1.2" xref="S3.SS2.SSS2.p1.3.m3.1.1.2.cmml">L</mi><mn id="S3.SS2.SSS2.p1.3.m3.1.1.3" xref="S3.SS2.SSS2.p1.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.3.m3.1b"><apply id="S3.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.2">𝐿</ci><cn id="S3.SS2.SSS2.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS2.SSS2.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.3.m3.1c">L_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.3.m3.1d">italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> norm between the 3D pose projection results and the pseudo 2D label from each view:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E3">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E3X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{2D}}=\sum_{v=1}^{V}\sum_{k=1}^{K}\left\|%
\mathcal{P}_{v}(J^{v,k})-\widetilde{J}_{\text{2D}}^{v,k}\right\|_{2}," class="ltx_Math" display="inline" id="S3.E3X.2.1.1.m1.5"><semantics id="S3.E3X.2.1.1.m1.5a"><mrow id="S3.E3X.2.1.1.m1.5.5.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.cmml"><mrow id="S3.E3X.2.1.1.m1.5.5.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.cmml"><msub id="S3.E3X.2.1.1.m1.5.5.1.1.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3X.2.1.1.m1.5.5.1.1.3.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.3.2.cmml">ℒ</mi><mtext id="S3.E3X.2.1.1.m1.5.5.1.1.3.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.3.3a.cmml">2D</mtext></msub><mo id="S3.E3X.2.1.1.m1.5.5.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.2.cmml">=</mo><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E3X.2.1.1.m1.5.5.1.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.cmml"><munderover id="S3.E3X.2.1.1.m1.5.5.1.1.1.2a" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.cmml"><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.2" movablelimits="false" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.cmml"><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.2.cmml">v</mi><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.3.cmml">V</mi></munderover></mstyle><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.cmml"><munderover id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2a" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.cmml"><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.2" movablelimits="false" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.cmml"><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.2.cmml">k</mi><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.3.cmml">K</mi></munderover></mstyle><msub id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.cmml"><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.2.cmml"><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.2.cmml">𝒫</mi><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.3.cmml">v</mi></msub><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">J</mi><mrow id="S3.E3X.2.1.1.m1.2.2.2.4" xref="S3.E3X.2.1.1.m1.2.2.2.3.cmml"><mi id="S3.E3X.2.1.1.m1.1.1.1.1" xref="S3.E3X.2.1.1.m1.1.1.1.1.cmml">v</mi><mo id="S3.E3X.2.1.1.m1.2.2.2.4.1" xref="S3.E3X.2.1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E3X.2.1.1.m1.2.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.cmml">k</mi></mrow></msup><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.2.cmml">−</mo><msubsup id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.2.cmml">J</mi><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.1" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.1.cmml">~</mo></mover><mtext id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.3a.cmml">2D</mtext><mrow id="S3.E3X.2.1.1.m1.4.4.2.4" xref="S3.E3X.2.1.1.m1.4.4.2.3.cmml"><mi id="S3.E3X.2.1.1.m1.3.3.1.1" xref="S3.E3X.2.1.1.m1.3.3.1.1.cmml">v</mi><mo id="S3.E3X.2.1.1.m1.4.4.2.4.1" xref="S3.E3X.2.1.1.m1.4.4.2.3.cmml">,</mo><mi id="S3.E3X.2.1.1.m1.4.4.2.2" xref="S3.E3X.2.1.1.m1.4.4.2.2.cmml">k</mi></mrow></msubsup></mrow><mo id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow><mo id="S3.E3X.2.1.1.m1.5.5.1.2" xref="S3.E3X.2.1.1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3X.2.1.1.m1.5b"><apply id="S3.E3X.2.1.1.m1.5.5.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1"><eq id="S3.E3X.2.1.1.m1.5.5.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.2"></eq><apply id="S3.E3X.2.1.1.m1.5.5.1.1.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.3.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.3">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.5.5.1.1.3.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.3.2">ℒ</ci><ci id="S3.E3X.2.1.1.m1.5.5.1.1.3.3a.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.3.3"><mtext id="S3.E3X.2.1.1.m1.5.5.1.1.3.3.cmml" mathsize="70%" xref="S3.E3X.2.1.1.m1.5.5.1.1.3.3">2D</mtext></ci></apply><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1"><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2">superscript</csymbol><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2">subscript</csymbol><sum id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.2"></sum><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3"><eq id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.1"></eq><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.2">𝑣</ci><cn id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.2.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.2.3">𝑉</ci></apply><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1"><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2">superscript</csymbol><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2">subscript</csymbol><sum id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.2"></sum><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3"><eq id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.1"></eq><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.2">𝑘</ci><cn id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.2.3">𝐾</ci></apply><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1">subscript</csymbol><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1"><minus id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1"><times id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.2">𝒫</ci><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.3.3">𝑣</ci></apply><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2">𝐽</ci><list id="S3.E3X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.4"><ci id="S3.E3X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1">𝑣</ci><ci id="S3.E3X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2">𝑘</ci></list></apply></apply><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2"><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.1">~</ci><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.2.2">𝐽</ci></apply><ci id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.3a.cmml" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.3"><mtext id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.3.2.3">2D</mtext></ci></apply><list id="S3.E3X.2.1.1.m1.4.4.2.3.cmml" xref="S3.E3X.2.1.1.m1.4.4.2.4"><ci id="S3.E3X.2.1.1.m1.3.3.1.1.cmml" xref="S3.E3X.2.1.1.m1.3.3.1.1">𝑣</ci><ci id="S3.E3X.2.1.1.m1.4.4.2.2.cmml" xref="S3.E3X.2.1.1.m1.4.4.2.2">𝑘</ci></list></apply></apply></apply><cn id="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.3.cmml" type="integer" xref="S3.E3X.2.1.1.m1.5.5.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3X.2.1.1.m1.5c">\displaystyle\mathcal{L}_{\text{2D}}=\sum_{v=1}^{V}\sum_{k=1}^{K}\left\|%
\mathcal{P}_{v}(J^{v,k})-\widetilde{J}_{\text{2D}}^{v,k}\right\|_{2},</annotation><annotation encoding="application/x-llamapun" id="S3.E3X.2.1.1.m1.5d">caligraphic_L start_POSTSUBSCRIPT 2D end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_v = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT ∥ caligraphic_P start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_J start_POSTSUPERSCRIPT italic_v , italic_k end_POSTSUPERSCRIPT ) - over~ start_ARG italic_J end_ARG start_POSTSUBSCRIPT 2D end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v , italic_k end_POSTSUPERSCRIPT ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(3)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS2.p1.6">where <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.4.m1.1"><semantics id="S3.SS2.SSS2.p1.4.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.4.m1.1.1" xref="S3.SS2.SSS2.p1.4.m1.1.1.cmml">𝒫</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.4.m1.1b"><ci id="S3.SS2.SSS2.p1.4.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m1.1.1">𝒫</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.4.m1.1c">\mathcal{P}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.4.m1.1d">caligraphic_P</annotation></semantics></math> is the projection function. <math alttext="V" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.5.m2.1"><semantics id="S3.SS2.SSS2.p1.5.m2.1a"><mi id="S3.SS2.SSS2.p1.5.m2.1.1" xref="S3.SS2.SSS2.p1.5.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.5.m2.1b"><ci id="S3.SS2.SSS2.p1.5.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.5.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.5.m2.1d">italic_V</annotation></semantics></math> is the number of views.
To obtain the pseudo 3D label, we use information entropy as an uncertainty index. The entropy of a keypoint prediction heatmap (a spatial probability distribution) <math alttext="h^{k}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.6.m3.1"><semantics id="S3.SS2.SSS2.p1.6.m3.1a"><msup id="S3.SS2.SSS2.p1.6.m3.1.1" xref="S3.SS2.SSS2.p1.6.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p1.6.m3.1.1.2" xref="S3.SS2.SSS2.p1.6.m3.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS2.p1.6.m3.1.1.3" xref="S3.SS2.SSS2.p1.6.m3.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.6.m3.1b"><apply id="S3.SS2.SSS2.p1.6.m3.1.1.cmml" xref="S3.SS2.SSS2.p1.6.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.6.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p1.6.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p1.6.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p1.6.m3.1.1.2">ℎ</ci><ci id="S3.SS2.SSS2.p1.6.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p1.6.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.6.m3.1c">h^{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.6.m3.1d">italic_h start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> is defined as:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E4">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E4X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{H}(h^{k})=-\sum_{i}h_{i}^{k}\times\log h_{i}^{k}," class="ltx_Math" display="inline" id="S3.E4X.2.1.1.m1.1"><semantics id="S3.E4X.2.1.1.m1.1a"><mrow id="S3.E4X.2.1.1.m1.1.1.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E4X.2.1.1.m1.1.1.1.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E4X.2.1.1.m1.1.1.1.1.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.2.1.1.m1.1.1.1.1.1.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.3.cmml">ℋ</mi><mo id="S3.E4X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">h</mi><mi id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msup><mo id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4X.2.1.1.m1.1.1.1.1.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E4X.2.1.1.m1.1.1.1.1.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.cmml"><mo id="S3.E4X.2.1.1.m1.1.1.1.1.3a" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.cmml">−</mo><mrow id="S3.E4X.2.1.1.m1.1.1.1.1.3.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.cmml"><mstyle displaystyle="true" id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.cmml"><munder id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1a" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.cmml"><mo id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.2" movablelimits="false" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.2.cmml">∑</mo><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.3.cmml">i</mi></munder></mstyle><mrow id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.cmml"><msubsup id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.2.cmml">h</mi><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.3.cmml">i</mi><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.3.cmml">k</mi></msubsup><mo id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.1.cmml">×</mo><mrow id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.1" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.1.cmml">log</mi><mo id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3a" lspace="0.167em" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.cmml">⁡</mo><msubsup id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.2.cmml">h</mi><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.3.cmml">i</mi><mi id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.3" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.3.cmml">k</mi></msubsup></mrow></mrow></mrow></mrow></mrow><mo id="S3.E4X.2.1.1.m1.1.1.1.2" xref="S3.E4X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4X.2.1.1.m1.1b"><apply id="S3.E4X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1"><eq id="S3.E4X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.2"></eq><apply id="S3.E4X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1"><times id="S3.E4X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.2"></times><ci id="S3.E4X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.3">ℋ</ci><apply id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.2">ℎ</ci><ci id="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply></apply><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3"><minus id="S3.E4X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3"></minus><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2"><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1">subscript</csymbol><sum id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.2"></sum><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.1.3">𝑖</ci></apply><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2"><times id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.1"></times><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2">superscript</csymbol><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.2">ℎ</ci><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.2.3">𝑖</ci></apply><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.2.3">𝑘</ci></apply><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3"><log id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.1"></log><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2">superscript</csymbol><apply id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2">subscript</csymbol><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.2">ℎ</ci><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.2.3">𝑖</ci></apply><ci id="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.1.1.3.2.2.3.2.3">𝑘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4X.2.1.1.m1.1c">\displaystyle\mathcal{H}(h^{k})=-\sum_{i}h_{i}^{k}\times\log h_{i}^{k},</annotation><annotation encoding="application/x-llamapun" id="S3.E4X.2.1.1.m1.1d">caligraphic_H ( italic_h start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) = - ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT × roman_log italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS2.p1.7">where <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.7.m1.1"><semantics id="S3.SS2.SSS2.p1.7.m1.1a"><mi id="S3.SS2.SSS2.p1.7.m1.1.1" xref="S3.SS2.SSS2.p1.7.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.7.m1.1b"><ci id="S3.SS2.SSS2.p1.7.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.7.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.7.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.7.m1.1d">italic_i</annotation></semantics></math> represents the voxel index. Higher entropy indicates greater uncertainty in the keypoint location. Moreover, as observed in our experiments (Section <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.SS5" title="4.5 Entropy Analysis ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">4.5</span></a>), there is a correlation between entropy and the rationality of the keypoint location.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.3">To measure a person’s uncertainty, we use the maximum entropy value of all keypoints. Unlike Kundu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib28" title="">28</a>]</cite>, who train a model to learn the uncertainty values, we directly calculate and use entropy as an inherent index. Our experiments demonstrate that the magnitude of entropy values can serve as an indicator of pose estimation quality for a specific network. Consequently, an entropy threshold <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.1.m1.1"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mi id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><ci id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.1.m1.1d">italic_λ</annotation></semantics></math> can be set to filter out the reasonably predicted 3D human poses. Specifically, we select the predicted pose <math alttext="\widetilde{p}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.2.m2.1"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mover accent="true" id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml">p</mi><mo id="S3.SS2.SSS2.p2.2.m2.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><apply id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1"><ci id="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.2">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">\widetilde{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.2.m2.1d">over~ start_ARG italic_p end_ARG</annotation></semantics></math> whose entropy value is less than <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.3.m3.1"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><mi id="S3.SS2.SSS2.p2.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><ci id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.3.m3.1d">italic_λ</annotation></semantics></math> as the pseudo 3D pose label for the next epoch’s training, allowing it to be updated after each training epoch. Therefore, the 3D pseudo pose loss can be obtained by:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E5">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E5X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{3D}}=\sum_{k=1}^{K}\left\|J^{k}-\widetilde{J}^%
{k}\right\|_{1}," class="ltx_Math" display="inline" id="S3.E5X.2.1.1.m1.1"><semantics id="S3.E5X.2.1.1.m1.1a"><mrow id="S3.E5X.2.1.1.m1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E5X.2.1.1.m1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.cmml"><msub id="S3.E5X.2.1.1.m1.1.1.1.1.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5X.2.1.1.m1.1.1.1.1.3.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.3.2.cmml">ℒ</mi><mtext id="S3.E5X.2.1.1.m1.1.1.1.1.3.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.3.3a.cmml">3D</mtext></msub><mo id="S3.E5X.2.1.1.m1.1.1.1.1.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E5X.2.1.1.m1.1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E5X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.cmml"><munderover id="S3.E5X.2.1.1.m1.1.1.1.1.1.2a" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.cmml"><mo id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.2" movablelimits="false" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml">k</mi><mo id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.3.cmml">K</mi></munderover></mstyle><msub id="S3.E5X.2.1.1.m1.1.1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">J</mi><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">k</mi></msup><mo id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">J</mi><mo id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">k</mi></msup></mrow><mo id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow><mo id="S3.E5X.2.1.1.m1.1.1.1.2" xref="S3.E5X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5X.2.1.1.m1.1b"><apply id="S3.E5X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1"><eq id="S3.E5X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.2"></eq><apply id="S3.E5X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.3.2">ℒ</ci><ci id="S3.E5X.2.1.1.m1.1.1.1.1.3.3a.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.3.3"><mtext id="S3.E5X.2.1.1.m1.1.1.1.1.3.3.cmml" mathsize="70%" xref="S3.E5X.2.1.1.m1.1.1.1.1.3.3">3D</mtext></ci></apply><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1"><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.2"></sum><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3"><eq id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.2">𝑘</ci><cn id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.2.3">𝐾</ci></apply><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝐽</ci><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.1">~</ci><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2">𝐽</ci></apply><ci id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3">𝑘</ci></apply></apply></apply><cn id="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E5X.2.1.1.m1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5X.2.1.1.m1.1c">\displaystyle\mathcal{L}_{\text{3D}}=\sum_{k=1}^{K}\left\|J^{k}-\widetilde{J}^%
{k}\right\|_{1},</annotation><annotation encoding="application/x-llamapun" id="S3.E5X.2.1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT 3D end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT ∥ italic_J start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT - over~ start_ARG italic_J end_ARG start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(5)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS2.p2.5">where <math alttext="\widetilde{J}^{k}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.4.m1.1"><semantics id="S3.SS2.SSS2.p2.4.m1.1a"><msup id="S3.SS2.SSS2.p2.4.m1.1.1" xref="S3.SS2.SSS2.p2.4.m1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS2.p2.4.m1.1.1.2" xref="S3.SS2.SSS2.p2.4.m1.1.1.2.cmml"><mi id="S3.SS2.SSS2.p2.4.m1.1.1.2.2" xref="S3.SS2.SSS2.p2.4.m1.1.1.2.2.cmml">J</mi><mo id="S3.SS2.SSS2.p2.4.m1.1.1.2.1" xref="S3.SS2.SSS2.p2.4.m1.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS2.SSS2.p2.4.m1.1.1.3" xref="S3.SS2.SSS2.p2.4.m1.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.4.m1.1b"><apply id="S3.SS2.SSS2.p2.4.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.4.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m1.1.1">superscript</csymbol><apply id="S3.SS2.SSS2.p2.4.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.4.m1.1.1.2"><ci id="S3.SS2.SSS2.p2.4.m1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p2.4.m1.1.1.2.1">~</ci><ci id="S3.SS2.SSS2.p2.4.m1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p2.4.m1.1.1.2.2">𝐽</ci></apply><ci id="S3.SS2.SSS2.p2.4.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.4.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.4.m1.1c">\widetilde{J}^{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.4.m1.1d">over~ start_ARG italic_J end_ARG start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> is the 3D joint of the selected pseudo 3D pose label <math alttext="\widetilde{p}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.5.m2.1"><semantics id="S3.SS2.SSS2.p2.5.m2.1a"><mover accent="true" id="S3.SS2.SSS2.p2.5.m2.1.1" xref="S3.SS2.SSS2.p2.5.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p2.5.m2.1.1.2" xref="S3.SS2.SSS2.p2.5.m2.1.1.2.cmml">p</mi><mo id="S3.SS2.SSS2.p2.5.m2.1.1.1" xref="S3.SS2.SSS2.p2.5.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.5.m2.1b"><apply id="S3.SS2.SSS2.p2.5.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.5.m2.1.1"><ci id="S3.SS2.SSS2.p2.5.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p2.5.m2.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.5.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p2.5.m2.1.1.2">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.5.m2.1c">\widetilde{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.5.m2.1d">over~ start_ARG italic_p end_ARG</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.4">To further ensure the anatomical plausibility of the pose, we design a human prior loss <math alttext="\mathcal{L}{\text{prior}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.1.m1.1"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><mrow id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p3.1.m1.1.1.2" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml">ℒ</mi><mo id="S3.SS2.SSS2.p3.1.m1.1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.1.cmml">⁢</mo><mtext id="S3.SS2.SSS2.p3.1.m1.1.1.3" xref="S3.SS2.SSS2.p3.1.m1.1.1.3a.cmml">prior</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><apply id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1"><times id="S3.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.1"></times><ci id="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2">ℒ</ci><ci id="S3.SS2.SSS2.p3.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.3"><mtext id="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.3">prior</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">\mathcal{L}{\text{prior}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.1.m1.1d">caligraphic_L prior</annotation></semantics></math><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Please refer to the Supplementary Material for details.</span></span></span>. Specifically, we formulate three losses to penalize asymmetric limb lengths (<math alttext="\mathcal{L}{\text{symm}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.2.m2.1"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><mrow id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p3.2.m2.1.1.2" xref="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml">ℒ</mi><mo id="S3.SS2.SSS2.p3.2.m2.1.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml">⁢</mo><mtext id="S3.SS2.SSS2.p3.2.m2.1.1.3" xref="S3.SS2.SSS2.p3.2.m2.1.1.3a.cmml">symm</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><apply id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1"><times id="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.1"></times><ci id="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.2">ℒ</ci><ci id="S3.SS2.SSS2.p3.2.m2.1.1.3a.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.3"><mtext id="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.3">symm</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">\mathcal{L}{\text{symm}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.2.m2.1d">caligraphic_L symm</annotation></semantics></math>), implausible joint angles (<math alttext="\mathcal{L}{\text{angle}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.3.m3.1"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><mrow id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p3.3.m3.1.1.2" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml">ℒ</mi><mo id="S3.SS2.SSS2.p3.3.m3.1.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.1.cmml">⁢</mo><mtext id="S3.SS2.SSS2.p3.3.m3.1.1.3" xref="S3.SS2.SSS2.p3.3.m3.1.1.3a.cmml">angle</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><apply id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1"><times id="S3.SS2.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.1"></times><ci id="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2">ℒ</ci><ci id="S3.SS2.SSS2.p3.3.m3.1.1.3a.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3"><mtext id="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3">angle</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">\mathcal{L}{\text{angle}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.3.m3.1d">caligraphic_L angle</annotation></semantics></math>), and implausible bone lengths (<math alttext="\mathcal{L}{\text{length}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.4.m4.1"><semantics id="S3.SS2.SSS2.p3.4.m4.1a"><mrow id="S3.SS2.SSS2.p3.4.m4.1.1" xref="S3.SS2.SSS2.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p3.4.m4.1.1.2" xref="S3.SS2.SSS2.p3.4.m4.1.1.2.cmml">ℒ</mi><mo id="S3.SS2.SSS2.p3.4.m4.1.1.1" xref="S3.SS2.SSS2.p3.4.m4.1.1.1.cmml">⁢</mo><mtext id="S3.SS2.SSS2.p3.4.m4.1.1.3" xref="S3.SS2.SSS2.p3.4.m4.1.1.3a.cmml">length</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.4.m4.1b"><apply id="S3.SS2.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1"><times id="S3.SS2.SSS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.1"></times><ci id="S3.SS2.SSS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.2">ℒ</ci><ci id="S3.SS2.SSS2.p3.4.m4.1.1.3a.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.3"><mtext id="S3.SS2.SSS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1.3">length</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.4.m4.1c">\mathcal{L}{\text{length}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.4.m4.1d">caligraphic_L length</annotation></semantics></math>).</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p4">
<p class="ltx_p" id="S3.SS2.SSS2.p4.5">In summary, the final loss function is defined as:</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S3.E6">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S3.E6X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{unsup}}=\omega_{\text{1}}\mathcal{L}_{\text{2D%
}}+\omega_{\text{2}}\mathbf{1}(\widetilde{p}&lt;\lambda)\mathcal{L}_{\text{3D}}+%
\omega_{\text{3}}\mathcal{L}_{\text{prior}}," class="ltx_Math" display="inline" id="S3.E6X.2.1.1.m1.1"><semantics id="S3.E6X.2.1.1.m1.1a"><mrow id="S3.E6X.2.1.1.m1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E6X.2.1.1.m1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.cmml"><msub id="S3.E6X.2.1.1.m1.1.1.1.1.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6X.2.1.1.m1.1.1.1.1.3.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.2.cmml">ℒ</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.3.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.3a.cmml">unsup</mtext></msub><mo id="S3.E6X.2.1.1.m1.1.1.1.1.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6X.2.1.1.m1.1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.cmml"><mrow id="S3.E6X.2.1.1.m1.1.1.1.1.1.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.cmml"><msub id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.cmml"><mi id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.2.cmml">ω</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.3a.cmml">1</mtext></msub><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.2.cmml">ℒ</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.3a.cmml">2D</mtext></msub></mrow><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E6X.2.1.1.m1.1.1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.cmml"><msub id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.2.cmml">ω</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.3a.cmml">2</mtext></msub><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mn id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.4" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.4.cmml">𝟏</mn><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2a" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">p</mi><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">&lt;</mo><mi id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2b" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.2.cmml">ℒ</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.3a.cmml">3D</mtext></msub></mrow><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.2a" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E6X.2.1.1.m1.1.1.1.1.1.4" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.cmml"><msub id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.cmml"><mi id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.2.cmml">ω</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.3a.cmml">3</mtext></msub><mo id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.1" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.1.cmml">⁢</mo><msub id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.2.cmml">ℒ</mi><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.3" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.3a.cmml">prior</mtext></msub></mrow></mrow></mrow><mo id="S3.E6X.2.1.1.m1.1.1.1.2" xref="S3.E6X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6X.2.1.1.m1.1b"><apply id="S3.E6X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1"><eq id="S3.E6X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.2"></eq><apply id="S3.E6X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.2">ℒ</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.3.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.3.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.3.3">unsup</mtext></ci></apply><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1"><plus id="S3.E6X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.2"></plus><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3"><times id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.1"></times><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.2">𝜔</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.2.3">1</mtext></ci></apply><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.2">ℒ</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.3.3.3">2D</mtext></ci></apply></apply><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1"><times id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.2"></times><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.2">𝜔</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.3.3">2</mtext></ci></apply><cn id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.4.cmml" type="integer" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.4">1</cn><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1"><lt id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"></lt><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝑝</ci></apply><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">𝜆</ci></apply><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.2">ℒ</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.1.5.3">3D</mtext></ci></apply></apply><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4"><times id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.1"></times><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.2">𝜔</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.2.3">3</mtext></ci></apply><apply id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3"><csymbol cd="ambiguous" id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.1.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3">subscript</csymbol><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.2.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.2">ℒ</ci><ci id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.3a.cmml" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.3"><mtext id="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.3.cmml" mathsize="70%" xref="S3.E6X.2.1.1.m1.1.1.1.1.1.4.3.3">prior</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6X.2.1.1.m1.1c">\displaystyle\mathcal{L}_{\text{unsup}}=\omega_{\text{1}}\mathcal{L}_{\text{2D%
}}+\omega_{\text{2}}\mathbf{1}(\widetilde{p}&lt;\lambda)\mathcal{L}_{\text{3D}}+%
\omega_{\text{3}}\mathcal{L}_{\text{prior}},</annotation><annotation encoding="application/x-llamapun" id="S3.E6X.2.1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT unsup end_POSTSUBSCRIPT = italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT 2D end_POSTSUBSCRIPT + italic_ω start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT bold_1 ( over~ start_ARG italic_p end_ARG &lt; italic_λ ) caligraphic_L start_POSTSUBSCRIPT 3D end_POSTSUBSCRIPT + italic_ω start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT prior end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(6)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS2.p4.4">where <math alttext="\omega_{\text{1}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.1.m1.1"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><msub id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.1.m1.1.1.2" xref="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml">ω</mi><mtext id="S3.SS2.SSS2.p4.1.m1.1.1.3" xref="S3.SS2.SSS2.p4.1.m1.1.1.3a.cmml">1</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><apply id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.2">𝜔</ci><ci id="S3.SS2.SSS2.p4.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.3"><mtext id="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS2.p4.1.m1.1.1.3">1</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">\omega_{\text{1}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p4.1.m1.1d">italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\omega_{\text{2}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.2.m2.1"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><msub id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml">ω</mi><mtext id="S3.SS2.SSS2.p4.2.m2.1.1.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3a.cmml">2</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><apply id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2">𝜔</ci><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3a.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3"><mtext id="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS2.p4.2.m2.1.1.3">2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.1c">\omega_{\text{2}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p4.2.m2.1d">italic_ω start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\omega_{\text{3}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.3.m3.1"><semantics id="S3.SS2.SSS2.p4.3.m3.1a"><msub id="S3.SS2.SSS2.p4.3.m3.1.1" xref="S3.SS2.SSS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p4.3.m3.1.1.2" xref="S3.SS2.SSS2.p4.3.m3.1.1.2.cmml">ω</mi><mtext id="S3.SS2.SSS2.p4.3.m3.1.1.3" xref="S3.SS2.SSS2.p4.3.m3.1.1.3a.cmml">3</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.3.m3.1b"><apply id="S3.SS2.SSS2.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.2">𝜔</ci><ci id="S3.SS2.SSS2.p4.3.m3.1.1.3a.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.3"><mtext id="S3.SS2.SSS2.p4.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS2.p4.3.m3.1.1.3">3</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.3.m3.1c">\omega_{\text{3}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p4.3.m3.1d">italic_ω start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math> are the weights of each loss, and <math alttext="\mathbf{1}(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.4.m4.1"><semantics id="S3.SS2.SSS2.p4.4.m4.1a"><mrow id="S3.SS2.SSS2.p4.4.m4.1.2" xref="S3.SS2.SSS2.p4.4.m4.1.2.cmml"><mn id="S3.SS2.SSS2.p4.4.m4.1.2.2" xref="S3.SS2.SSS2.p4.4.m4.1.2.2.cmml">𝟏</mn><mo id="S3.SS2.SSS2.p4.4.m4.1.2.1" xref="S3.SS2.SSS2.p4.4.m4.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.SSS2.p4.4.m4.1.2.3.2" xref="S3.SS2.SSS2.p4.4.m4.1.2.cmml"><mo id="S3.SS2.SSS2.p4.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS2.SSS2.p4.4.m4.1.2.cmml">(</mo><mo id="S3.SS2.SSS2.p4.4.m4.1.1" lspace="0em" rspace="0em" xref="S3.SS2.SSS2.p4.4.m4.1.1.cmml">⋅</mo><mo id="S3.SS2.SSS2.p4.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS2.SSS2.p4.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.4.m4.1b"><apply id="S3.SS2.SSS2.p4.4.m4.1.2.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.2"><times id="S3.SS2.SSS2.p4.4.m4.1.2.1.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.2.1"></times><cn id="S3.SS2.SSS2.p4.4.m4.1.2.2.cmml" type="integer" xref="S3.SS2.SSS2.p4.4.m4.1.2.2">1</cn><ci id="S3.SS2.SSS2.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.4.m4.1c">\mathbf{1}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p4.4.m4.1d">bold_1 ( ⋅ )</annotation></semantics></math> represents the indicator function.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we introduce all datasets and evaluation metrics used in our experiments. We analyze the performance of our LiCamPose pipeline in supervised and unsupervised manner on different datasets. Additionally, we examine the impact of different configurations on the results in the context of unsupervised domain adaptation.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implementation details.</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.6">We use V2V-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib39" title="">39</a>]</cite> as the feature extractor for point cloud and RGB information. The detailed design of V2V-Net follows the PRN model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>]</cite>. The resolution of the voxel grid is set to <math alttext="64\times 64\times 64" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">64</mn><mo id="S4.SS1.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">64</mn><mo id="S4.SS1.p1.1.m1.1.1.1a" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.1.m1.1.1.4" xref="S4.SS1.p1.1.m1.1.1.4.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><cn id="S4.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.2">64</cn><cn id="S4.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.3">64</cn><cn id="S4.SS1.p1.1.m1.1.1.4.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.4">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">64\times 64\times 64</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">64 × 64 × 64</annotation></semantics></math> within a <math alttext="2\text{m}\times 2\text{m}\times 2\text{m}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mrow id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml"><mrow id="S4.SS1.p1.2.m2.1.1.2.2" xref="S4.SS1.p1.2.m2.1.1.2.2.cmml"><mrow id="S4.SS1.p1.2.m2.1.1.2.2.2" xref="S4.SS1.p1.2.m2.1.1.2.2.2.cmml"><mrow id="S4.SS1.p1.2.m2.1.1.2.2.2.2" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.cmml"><mn id="S4.SS1.p1.2.m2.1.1.2.2.2.2.2" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.2.cmml">2</mn><mo id="S4.SS1.p1.2.m2.1.1.2.2.2.2.1" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.1.cmml">⁢</mo><mtext id="S4.SS1.p1.2.m2.1.1.2.2.2.2.3" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.3a.cmml">m</mtext></mrow><mo id="S4.SS1.p1.2.m2.1.1.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p1.2.m2.1.1.2.2.2.1.cmml">×</mo><mn id="S4.SS1.p1.2.m2.1.1.2.2.2.3" xref="S4.SS1.p1.2.m2.1.1.2.2.2.3.cmml">2</mn></mrow><mo id="S4.SS1.p1.2.m2.1.1.2.2.1" xref="S4.SS1.p1.2.m2.1.1.2.2.1.cmml">⁢</mo><mtext id="S4.SS1.p1.2.m2.1.1.2.2.3" xref="S4.SS1.p1.2.m2.1.1.2.2.3a.cmml">m</mtext></mrow><mo id="S4.SS1.p1.2.m2.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p1.2.m2.1.1.2.1.cmml">×</mo><mn id="S4.SS1.p1.2.m2.1.1.2.3" xref="S4.SS1.p1.2.m2.1.1.2.3.cmml">2</mn></mrow><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mtext id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3a.cmml">m</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></times><apply id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2"><times id="S4.SS1.p1.2.m2.1.1.2.1.cmml" xref="S4.SS1.p1.2.m2.1.1.2.1"></times><apply id="S4.SS1.p1.2.m2.1.1.2.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2"><times id="S4.SS1.p1.2.m2.1.1.2.2.1.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.1"></times><apply id="S4.SS1.p1.2.m2.1.1.2.2.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.2"><times id="S4.SS1.p1.2.m2.1.1.2.2.2.1.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.2.1"></times><apply id="S4.SS1.p1.2.m2.1.1.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2"><times id="S4.SS1.p1.2.m2.1.1.2.2.2.2.1.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.1"></times><cn id="S4.SS1.p1.2.m2.1.1.2.2.2.2.2.cmml" type="integer" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.2">2</cn><ci id="S4.SS1.p1.2.m2.1.1.2.2.2.2.3a.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.3"><mtext id="S4.SS1.p1.2.m2.1.1.2.2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.2.2.3">m</mtext></ci></apply><cn id="S4.SS1.p1.2.m2.1.1.2.2.2.3.cmml" type="integer" xref="S4.SS1.p1.2.m2.1.1.2.2.2.3">2</cn></apply><ci id="S4.SS1.p1.2.m2.1.1.2.2.3a.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.3"><mtext id="S4.SS1.p1.2.m2.1.1.2.2.3.cmml" xref="S4.SS1.p1.2.m2.1.1.2.2.3">m</mtext></ci></apply><cn id="S4.SS1.p1.2.m2.1.1.2.3.cmml" type="integer" xref="S4.SS1.p1.2.m2.1.1.2.3">2</cn></apply><ci id="S4.SS1.p1.2.m2.1.1.3a.cmml" xref="S4.SS1.p1.2.m2.1.1.3"><mtext id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">m</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">2\text{m}\times 2\text{m}\times 2\text{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">2 m × 2 m × 2 m</annotation></semantics></math> space. The weights are set as <math alttext="\omega_{1}=0.02" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><msub id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2.2" xref="S4.SS1.p1.3.m3.1.1.2.2.cmml">ω</mi><mn id="S4.SS1.p1.3.m3.1.1.2.3" xref="S4.SS1.p1.3.m3.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><eq id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></eq><apply id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2.2">𝜔</ci><cn id="S4.SS1.p1.3.m3.1.1.2.3.cmml" type="integer" xref="S4.SS1.p1.3.m3.1.1.2.3">1</cn></apply><cn id="S4.SS1.p1.3.m3.1.1.3.cmml" type="float" xref="S4.SS1.p1.3.m3.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\omega_{1}=0.02</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.02</annotation></semantics></math>, <math alttext="\omega_{2}=1" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><msub id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2.2" xref="S4.SS1.p1.4.m4.1.1.2.2.cmml">ω</mi><mn id="S4.SS1.p1.4.m4.1.1.2.3" xref="S4.SS1.p1.4.m4.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><eq id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"></eq><apply id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.2.1.cmml" xref="S4.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2.2">𝜔</ci><cn id="S4.SS1.p1.4.m4.1.1.2.3.cmml" type="integer" xref="S4.SS1.p1.4.m4.1.1.2.3">2</cn></apply><cn id="S4.SS1.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\omega_{2}=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_ω start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1</annotation></semantics></math>, <math alttext="\omega_{3}=10" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><msub id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2.2" xref="S4.SS1.p1.5.m5.1.1.2.2.cmml">ω</mi><mn id="S4.SS1.p1.5.m5.1.1.2.3" xref="S4.SS1.p1.5.m5.1.1.2.3.cmml">3</mn></msub><mo id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><eq id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1"></eq><apply id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.2.1.cmml" xref="S4.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2.2">𝜔</ci><cn id="S4.SS1.p1.5.m5.1.1.2.3.cmml" type="integer" xref="S4.SS1.p1.5.m5.1.1.2.3">3</cn></apply><cn id="S4.SS1.p1.5.m5.1.1.3.cmml" type="integer" xref="S4.SS1.p1.5.m5.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\omega_{3}=10</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_ω start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 10</annotation></semantics></math>, and <math alttext="\lambda=6" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mrow id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">λ</mi><mo id="S4.SS1.p1.6.m6.1.1.1" xref="S4.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><eq id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1.1"></eq><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">𝜆</ci><cn id="S4.SS1.p1.6.m6.1.1.3.cmml" type="integer" xref="S4.SS1.p1.6.m6.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">\lambda=6</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">italic_λ = 6</annotation></semantics></math>. We train the voxel-based pose estimation network on an NVIDIA GeForce RTX-3090 with a batch size of eight. The learning rate is set to 0.001, and the optimizer used is Adam <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib25" title="">25</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Datasets and Metrics.</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">We use the following datasets in our experiments:
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.1">I. CMU Panoptic Studio <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib24" title="">24</a>]</cite>.</span>
The setup is indoors with a valid scene range of approximately <math alttext="5\text{m}\times 5\text{m}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.2.cmml">5</mn><mo id="S4.SS2.p1.1.m1.1.1.2.2.1" xref="S4.SS2.p1.1.m1.1.1.2.2.1.cmml">⁢</mo><mtext id="S4.SS2.p1.1.m1.1.1.2.2.3" xref="S4.SS2.p1.1.m1.1.1.2.2.3a.cmml">m</mtext></mrow><mo id="S4.SS2.p1.1.m1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">×</mo><mn id="S4.SS2.p1.1.m1.1.1.2.3" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">5</mn></mrow><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mtext id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3a.cmml">m</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><times id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.1"></times><apply id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2"><times id="S4.SS2.p1.1.m1.1.1.2.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2.1"></times><cn id="S4.SS2.p1.1.m1.1.1.2.2.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.2.2.2">5</cn><ci id="S4.SS2.p1.1.m1.1.1.2.2.3a.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2.3"><mtext id="S4.SS2.p1.1.m1.1.1.2.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2.3">m</mtext></ci></apply><cn id="S4.SS2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.2.3">5</cn></apply><ci id="S4.SS2.p1.1.m1.1.1.3a.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><mtext id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">m</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">5\text{m}\times 5\text{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">5 m × 5 m</annotation></semantics></math>. For multi-modal inputs, we select subsets<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>“160422_ultimatum1”, “160224_haggling1”, “160226_haggling1”, “161202_haggling1”, “160906_ian1”, “160906_ian2”, “160906_ian3”, and “160906_band1” for training; “160906_pizza1”, “160422_haggling1”, “160906_ian5”, “160906_band2” for testing.</span></span></span> from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a>]</cite> that include depth information. We unify the depth data from Kinect 1 to 5 and process these depth maps using equation <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.E2" title="Equation 2 ‣ 3.2.1 SyncHuman Generator ‣ 3.2 Unsupervised Domain Adaptation ‣ 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a> to obtain a sparse point cloud, similar to Mid-40 Livox LiDAR scanning. For 2D pose estimation, we use the results from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a>]</cite>, predicted with HRNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib46" title="">46</a>]</cite>.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.2">II. MVOR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib45" title="">45</a>]</cite>.</span>
The dataset was collected indoors in an operating room. We use three sampling functions (equation <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S3.E2" title="Equation 2 ‣ 3.2.1 SyncHuman Generator ‣ 3.2 Unsupervised Domain Adaptation ‣ 3 Methodology ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>) centered at three trisection points of the image width to simulate Mid-100 Livox LiDAR scanning. For 2D pose estimation, we use results from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib45" title="">45</a>]</cite>, predicted using AlphaPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib11" title="">11</a>]</cite>. Due to a semantic keypoints’ definition gap between MVOR (ten keypoints) and our COCO17 standard, we only perform qualitative analysis on MVOR. Data from ”day1, day2, day3” are used for training, and ”day4” for testing.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.3">III. BasketBall.</span>
The dataset was collected outdoors, covering a valid scene range of approximately <math alttext="35\text{m}\times 17\text{m}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mrow id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml"><mrow id="S4.SS2.p1.2.m2.1.1.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2.2.2" xref="S4.SS2.p1.2.m2.1.1.2.2.2.cmml">35</mn><mo id="S4.SS2.p1.2.m2.1.1.2.2.1" xref="S4.SS2.p1.2.m2.1.1.2.2.1.cmml">⁢</mo><mtext id="S4.SS2.p1.2.m2.1.1.2.2.3" xref="S4.SS2.p1.2.m2.1.1.2.2.3a.cmml">m</mtext></mrow><mo id="S4.SS2.p1.2.m2.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml">×</mo><mn id="S4.SS2.p1.2.m2.1.1.2.3" xref="S4.SS2.p1.2.m2.1.1.2.3.cmml">17</mn></mrow><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">⁢</mo><mtext id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3a.cmml">m</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2"><times id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.1"></times><apply id="S4.SS2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2"><times id="S4.SS2.p1.2.m2.1.1.2.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2.1"></times><cn id="S4.SS2.p1.2.m2.1.1.2.2.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.2.2.2">35</cn><ci id="S4.SS2.p1.2.m2.1.1.2.2.3a.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2.3"><mtext id="S4.SS2.p1.2.m2.1.1.2.2.3.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2.3">m</mtext></ci></apply><cn id="S4.SS2.p1.2.m2.1.1.2.3.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.2.3">17</cn></apply><ci id="S4.SS2.p1.2.m2.1.1.3a.cmml" xref="S4.SS2.p1.2.m2.1.1.3"><mtext id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">m</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">35\text{m}\times 17\text{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">35 m × 17 m</annotation></semantics></math>, recording a basketball match. We gathered this real-world dataset with four-view RGB-poincloud information. The point clouds were collected using four Mid-100 Livox LiDARs, and the 2D pose estimation results were predicted by VitPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib51" title="">51</a>]</cite>. The dataset comprises two segments, each containing two thousand frames. It includes manually marked detection and tracking ground truth for each frame but lacks 3D keypoints ground truth. Therefore, it is primarily used for qualitative analysis.
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.4">IV. BasketBallSync.</span>
This synthetic dataset was generated using SyncHuman with the same sensor configuration and settings as BasketBall dataset. The point cloud is obtained by simulating the scan pattern of Mid-100 Livox LiDARs. It contains ten avatars performing random actions, with the first eight used for training and the remaining two for testing, across all 3336 frames at 10Hz. The 2D human poses are predicted using VitPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib51" title="">51</a>]</cite>. 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.5">Evaluation metrics.</span>
To evaluate the 3D human pose, we calculate the mean per-joint position error (MPJPE) and the error after Procrustes Alignment (PA-MPJPE), both in millimeters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib16" title="">16</a>]</cite>. For fairness, we compare our results to methods using single-frame data inputs similar to ours.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="566" id="S4.F3.g1" src="extracted/5734580/figs/mvor_updated.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Three examples of 3D human pose estimation on MVOR. Blue lines represent predictions, green lines represent ground truth. The first three columns show 2D projections from different views, and the fourth column shows the 3D pose results.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="753" id="S4.F4.g1" src="x3.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">Qualitative illustration on the BasketBall dataset from different input modalities. The first row shows 2D pose estimations (missing where not estimable) and point clouds. The second row displays results from using only RGB input, with 2D poses projected from the estimated 3D poses. The third row presents results from using both RGB and point cloud inputs.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="478" id="S4.F5.g1" src="extracted/5734580/figs/ablation_updated.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">Qualitative visualization on BasketBall about different unsupervised training losses. “Baseline” uses only pseudo 2D pose supervision. “Entropy” indicates the addition of entropy-selected pseudo 3D pose supervision. “Prior” denotes the incorporation of human prior loss.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.5.1.1" style="font-size:113%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.6.2" style="font-size:113%;">Comparison of different 3D pose estimation methods on Panoptic and BasketBallSync.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:433.6pt;height:160.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(22.3pt,-8.3pt) scale(1.11476592587757,1.11476592587757) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T2.1.1">
<tr class="ltx_tr" id="S4.T2.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.2.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.1.1" style="font-size:80%;">Methods</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.2.2" rowspan="2"><span class="ltx_text" id="S4.T2.1.1.2.2.1" style="font-size:80%;"><span class="ltx_text" id="S4.T2.1.1.2.2.1.1"></span><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.2.2.1.2.1">
<span class="ltx_tr" id="S4.T2.1.1.2.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.1.1.2.2.1.2.1.1.1">Training</span></span>
<span class="ltx_tr" id="S4.T2.1.1.2.2.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.1.1.2.2.1.2.1.2.1">Manner</span></span>
</span></span><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.2.1.3"> <span class="ltx_text" id="S4.T2.1.1.2.2.1.3.1"></span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.1.1.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.3.1" style="font-size:80%;">Panoptic</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.1.1.2.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.4.1" style="font-size:80%;">BasketBallSync</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.1"><span class="ltx_text" id="S4.T2.1.1.3.1.1" style="font-size:80%;">MPJPE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.2"><span class="ltx_text" id="S4.T2.1.1.3.2.1" style="font-size:80%;">PA-MPJPE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3"><span class="ltx_text" id="S4.T2.1.1.3.3.1" style="font-size:80%;">MPJPE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.4"><span class="ltx_text" id="S4.T2.1.1.3.4.1" style="font-size:80%;">PA-MPJPE</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.4.1">
<span class="ltx_text" id="S4.T2.1.1.4.1.1" style="font-size:80%;">MvP </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.1.1.4.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib54" title="">54</a><span class="ltx_text" id="S4.T2.1.1.4.1.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.4.2"><span class="ltx_text" id="S4.T2.1.1.4.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.3"><span class="ltx_text" id="S4.T2.1.1.4.3.1" style="font-size:80%;">25.78</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4"><span class="ltx_text" id="S4.T2.1.1.4.4.1" style="font-size:80%;">25.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.5"><span class="ltx_text" id="S4.T2.1.1.4.5.1" style="font-size:80%;">291.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.6"><span class="ltx_text" id="S4.T2.1.1.4.6.1" style="font-size:80%;">240.32</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.5">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.5.1">
<span class="ltx_text" id="S4.T2.1.1.5.1.1" style="font-size:80%;">PlanePose </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.1.1.5.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a><span class="ltx_text" id="S4.T2.1.1.5.1.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.5.2"><span class="ltx_text" id="S4.T2.1.1.5.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.3"><span class="ltx_text" id="S4.T2.1.1.5.3.1" style="font-size:80%;">18.54</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4"><span class="ltx_text" id="S4.T2.1.1.5.4.1" style="font-size:80%;">11.92</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.5"><span class="ltx_text" id="S4.T2.1.1.5.5.1" style="font-size:80%;">119.55</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.6"><span class="ltx_text" id="S4.T2.1.1.5.6.1" style="font-size:80%;">65.80</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.6">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.6.1">
<span class="ltx_text" id="S4.T2.1.1.6.1.1" style="font-size:80%;">VoxelPose(PRN) </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.1.1.6.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a><span class="ltx_text" id="S4.T2.1.1.6.1.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.6.2"><span class="ltx_text" id="S4.T2.1.1.6.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.3"><span class="ltx_text" id="S4.T2.1.1.6.3.1" style="font-size:80%;">14.91</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.4"><span class="ltx_text" id="S4.T2.1.1.6.4.1" style="font-size:80%;">11.88</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5"><span class="ltx_text" id="S4.T2.1.1.6.5.1" style="font-size:80%;">40.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.6"><span class="ltx_text" id="S4.T2.1.1.6.6.1" style="font-size:80%;">34.34</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.7">
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.7.1"><span class="ltx_text" id="S4.T2.1.1.7.1.1" style="font-size:80%;">LiCamPose</span></td>
<td class="ltx_td ltx_align_left" id="S4.T2.1.1.7.2"><span class="ltx_text" id="S4.T2.1.1.7.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.3.1" style="font-size:80%;">14.44</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.4.1" style="font-size:80%;">11.61</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.5.1" style="font-size:80%;">31.84</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.6.1" style="font-size:80%;">27.36</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.8.1">
<span class="ltx_text" id="S4.T2.1.1.8.1.1" style="font-size:80%;">DLT </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T2.1.1.8.1.2.1" style="font-size:80%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib43" title="">43</a><span class="ltx_text" id="S4.T2.1.1.8.1.3.2" style="font-size:80%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.8.2"><span class="ltx_text" id="S4.T2.1.1.8.2.1" style="font-size:80%;">unsupervised</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.3"><span class="ltx_text" id="S4.T2.1.1.8.3.1" style="font-size:80%;">38.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.4"><span class="ltx_text" id="S4.T2.1.1.8.4.1" style="font-size:80%;">44.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.5"><span class="ltx_text" id="S4.T2.1.1.8.5.1" style="font-size:80%;">101.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.6"><span class="ltx_text" id="S4.T2.1.1.8.6.1" style="font-size:80%;">62.77</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.1.1.2"><span class="ltx_text" id="S4.T2.1.1.1.2.1" style="font-size:80%;">LiCamPose</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.1.1.1">
<span class="ltx_text" id="S4.T2.1.1.1.1.2" style="font-size:80%;">unsupervised</span><sup class="ltx_sup" id="S4.T2.1.1.1.1.1"><math alttext="\dagger" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.1.m1.1.1" mathsize="80%" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">\dagger</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.1.m1.1d">†</annotation></semantics></math></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1" style="font-size:80%;">22.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1" style="font-size:80%;">15.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.5.1" style="font-size:80%;">72.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.6.1" style="font-size:80%;">62.72</span></td>
</tr>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S4.I1">
<li class="ltx_item" id="S4.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math alttext="\dagger" class="ltx_Math" display="inline" id="S4.I1.ix1.1.1.m1.1"><semantics id="S4.I1.ix1.1.1.m1.1b"><mo id="S4.I1.ix1.1.1.m1.1.1" xref="S4.I1.ix1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.I1.ix1.1.1.m1.1c"><ci id="S4.I1.ix1.1.1.m1.1.1.cmml" xref="S4.I1.ix1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.ix1.1.1.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="S4.I1.ix1.1.1.m1.1e">†</annotation></semantics></math></span>
<div class="ltx_para" id="S4.I1.ix1.p1">
<p class="ltx_p" id="S4.I1.ix1.p1.1"><span class="ltx_text" id="S4.I1.ix1.p1.1.1" style="font-size:70%;">Pretrained on BasketBallSync during Panoptic evaluating and on Panoptic </span>
<br class="ltx_break"/><span class="ltx_text" id="S4.I1.ix1.p1.1.2" style="font-size:70%;">during BasketBallSync testing. It is the same for Table </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.T3" style="font-size:70%;" title="Table 3 ‣ 4.2 Datasets and Metrics. ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S4.I1.ix1.p1.1.3" style="font-size:70%;"> and </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.T5" style="font-size:70%;" title="Table 5 ‣ 4.3 3D Pose Estimation Analysis ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="S4.I1.ix1.p1.1.4" style="font-size:70%;">.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.4.1.1" style="font-size:113%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.5.2" style="font-size:113%;">Comparison of Different Input Modalities for LiCamPose on Panoptic and BasketBallSync.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T3.6" style="width:433.6pt;height:167.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(53.4pt,-20.6pt) scale(1.32672884958244,1.32672884958244) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.6.1">
<tr class="ltx_tr" id="S4.T3.6.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.6.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T3.6.1.1.1.1" style="font-size:80%;"><span class="ltx_text" id="S4.T3.6.1.1.1.1.1"></span><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.1.1.1.1.2.1">
<span class="ltx_tr" id="S4.T3.6.1.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.6.1.1.1.1.2.1.1.1">Input</span></span>
<span class="ltx_tr" id="S4.T3.6.1.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.6.1.1.1.1.2.1.2.1">Modality</span></span>
</span></span><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.1.1.1.3"> <span class="ltx_text" id="S4.T3.6.1.1.1.1.3.1"></span></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.6.1.1.2" rowspan="2"><span class="ltx_text" id="S4.T3.6.1.1.2.1" style="font-size:80%;"><span class="ltx_text" id="S4.T3.6.1.1.2.1.1"></span><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.1.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.6.1.1.2.1.2.1">
<span class="ltx_tr" id="S4.T3.6.1.1.2.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.6.1.1.2.1.2.1.1.1">Training</span></span>
<span class="ltx_tr" id="S4.T3.6.1.1.2.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T3.6.1.1.2.1.2.1.2.1">Manenr</span></span>
</span></span><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.1.2.1.3"> <span class="ltx_text" id="S4.T3.6.1.1.2.1.3.1"></span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.6.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.1.3.1" style="font-size:80%;">Panoptic</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.6.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.1.4.1" style="font-size:80%;">BasketBallSync</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.2.1"><span class="ltx_text" id="S4.T3.6.1.2.1.1" style="font-size:80%;">MPJPE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.2.2"><span class="ltx_text" id="S4.T3.6.1.2.2.1" style="font-size:80%;">PA-MPJPE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.2.3"><span class="ltx_text" id="S4.T3.6.1.2.3.1" style="font-size:80%;">MPJPE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.2.4"><span class="ltx_text" id="S4.T3.6.1.2.4.1" style="font-size:80%;">PA-MPJPE</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.1.3.1"><span class="ltx_text" id="S4.T3.6.1.3.1.1" style="font-size:80%;">point cloud</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.1.3.2"><span class="ltx_text" id="S4.T3.6.1.3.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.3.3"><span class="ltx_text" id="S4.T3.6.1.3.3.1" style="font-size:80%;">164.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.3.4"><span class="ltx_text" id="S4.T3.6.1.3.4.1" style="font-size:80%;">148.78</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.3.5"><span class="ltx_text" id="S4.T3.6.1.3.5.1" style="font-size:80%;">136.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.3.6"><span class="ltx_text" id="S4.T3.6.1.3.6.1" style="font-size:80%;">123.22</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.1.4">
<td class="ltx_td ltx_align_left" id="S4.T3.6.1.4.1"><span class="ltx_text" id="S4.T3.6.1.4.1.1" style="font-size:80%;">RGB</span></td>
<td class="ltx_td ltx_align_left" id="S4.T3.6.1.4.2"><span class="ltx_text" id="S4.T3.6.1.4.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.4.3"><span class="ltx_text" id="S4.T3.6.1.4.3.1" style="font-size:80%;">14.91</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.4.4"><span class="ltx_text" id="S4.T3.6.1.4.4.1" style="font-size:80%;">11.88</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.4.5"><span class="ltx_text" id="S4.T3.6.1.4.5.1" style="font-size:80%;">40.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.4.6"><span class="ltx_text" id="S4.T3.6.1.4.6.1" style="font-size:80%;">34.34</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.1.5">
<td class="ltx_td ltx_align_left" id="S4.T3.6.1.5.1"><span class="ltx_text" id="S4.T3.6.1.5.1.1" style="font-size:80%;">RGB + point cloud</span></td>
<td class="ltx_td ltx_align_left" id="S4.T3.6.1.5.2"><span class="ltx_text" id="S4.T3.6.1.5.2.1" style="font-size:80%;">supervised</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.5.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.5.3.1" style="font-size:80%;">14.44</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.5.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.5.4.1" style="font-size:80%;">11.61</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.5.5"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.5.5.1" style="font-size:80%;">31.84</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.1.5.6"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.5.6.1" style="font-size:80%;">27.36</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.1.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.1.6.1"><span class="ltx_text" id="S4.T3.6.1.6.1.1" style="font-size:80%;">RGB</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.6.1.6.2"><span class="ltx_text" id="S4.T3.6.1.6.2.1" style="font-size:80%;">unsupervised</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.6.3"><span class="ltx_text" id="S4.T3.6.1.6.3.1" style="font-size:80%;">25.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.6.4"><span class="ltx_text" id="S4.T3.6.1.6.4.1" style="font-size:80%;">17.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.6.5"><span class="ltx_text" id="S4.T3.6.1.6.5.1" style="font-size:80%;">263.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.6.1.6.6"><span class="ltx_text" id="S4.T3.6.1.6.6.1" style="font-size:80%;">183.85</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.6.1.7.1"><span class="ltx_text" id="S4.T3.6.1.7.1.1" style="font-size:80%;">RGB + point cloud</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.6.1.7.2"><span class="ltx_text" id="S4.T3.6.1.7.2.1" style="font-size:80%;">unsupervised</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.1.7.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.7.3.1" style="font-size:80%;">22.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.1.7.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.7.4.1" style="font-size:80%;">15.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.1.7.5"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.7.5.1" style="font-size:80%;">72.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.6.1.7.6"><span class="ltx_text ltx_font_bold" id="S4.T3.6.1.7.6.1" style="font-size:80%;">62.72</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>3D Pose Estimation Analysis</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In this section, we evaluate the 3D human pose estimation results using different approaches. For PlaneSweepPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib32" title="">32</a>]</cite>, VoxelPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>]</cite>, and supervised LiCamPose, we incorporate ground truth person locations during both training and testing phases. However, for MvP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib54" title="">54</a>]</cite>, its architecture does not accommodate direct integration of ground truth detection information, making it unable to utilize depth or point cloud data directly. For fairness, we evaluate only the MPJPE@500 metric (considering only per-joint errors less than 500 mm) for the matched person in the case of MvP.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">We evaluate these approaches on Panoptic Studio and BasketBallSync datasets, representing small and large scenes respectively. Table <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.T2" title="Table 2 ‣ 4.2 Datasets and Metrics. ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates that LiCamPose surpasses them in terms of both MPJPE and PA-MPJPE, particularly in the large scene setting. Notably, unsupervised learning LiCamPose even outperforms some supervised multi-view approaches with RGB inputs.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">We evaluate LiCamPose using unsupervised domain adaption on MVOR, and it achieves impressive performance, occasionally outperforming ground truth in some frames (Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.F3" title="Figure 3 ‣ 4.2 Datasets and Metrics. ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">Additionally, we analyze the performance using different modal inputs (point cloud, RGB, and both) in volumetric representation. Table <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.T3" title="Table 3 ‣ 4.2 Datasets and Metrics. ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates that using Livox point cloud information alone struggles to accurately extract the 3D human skeleton due to its sparsity, making it unsuitable for unsupervised learning without 2D pseudo-labels from heatmaps. However, combining it with RGB information significantly enhances performance. Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.F4" title="Figure 4 ‣ 4.2 Datasets and Metrics. ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates that multi-modal inputs improve the model’s robustness to 2D pose estimation errors, even in challenging scenarios such as mispredictions or incorrect person predictions, during unsupervised domain adaptation training.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.2.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.3.2" style="font-size:90%;">Comparison of different scene setups. We simulated four different scene setups using the SyncHuman generator. It shows the performance of LiCamPose when pre-trained on different scenes and directly applied to Panoptic Studio.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle" id="S4.T4.4">
<tr class="ltx_tr" id="S4.T4.4.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.4.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1">Scene’s Size<sup class="ltx_sup" id="S4.T4.4.1.1.1.1"><span class="ltx_text ltx_font_medium" id="S4.T4.4.1.1.1.1.1">1</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T4.4.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.2.1">Sensors’ Setting<sup class="ltx_sup" id="S4.T4.4.1.2.1.1"><span class="ltx_text ltx_font_medium" id="S4.T4.4.1.2.1.1.1">2</span></sup></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T4.4.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.3.1">Metric</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.2.1">Number<sup class="ltx_sup" id="S4.T4.4.2.1.1">3</sup>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.2.2">Position</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.2.3">Orientation</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.2.4">MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.2.5">PA-MPJPE</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.3.1">BaseketBall</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.3.2">4</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.3.3">BaseketBall</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.4.3.4">BaseketBall</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.3.5">82.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.3.6">93.41</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4">
<td class="ltx_td ltx_align_left" id="S4.T4.4.4.1">BaseketBall</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.2">5</td>
<td class="ltx_td ltx_align_left" id="S4.T4.4.4.3">others</td>
<td class="ltx_td ltx_align_left" id="S4.T4.4.4.4">Panoptic</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.5">77.90</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.6">60.42</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.5">
<td class="ltx_td ltx_align_left" id="S4.T4.4.5.1">Panoptic</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.5.2">5</td>
<td class="ltx_td ltx_align_left" id="S4.T4.4.5.3">others</td>
<td class="ltx_td ltx_align_left" id="S4.T4.4.5.4">Panoptic</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.5.5">26.45</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.5.6">22.56</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.4.6.1">Panoptic</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.6.2">5</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.4.6.3">Panoptic</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.4.6.4">Panoptic</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.6.5"><span class="ltx_text ltx_font_bold" id="S4.T4.4.6.5.1">23.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.6.6"><span class="ltx_text ltx_font_bold" id="S4.T4.4.6.6.1">17.63</span></td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S4.I2">
<li class="ltx_item" id="S4.I2.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span>
<div class="ltx_para" id="S4.I2.ix1.p1">
<p class="ltx_p" id="S4.I2.ix1.p1.1"><span class="ltx_text" id="S4.I2.ix1.p1.1.1" style="font-size:80%;">Scene sizes are denoted with the names of the corresponding datasets.</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I2.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2</span>
<div class="ltx_para" id="S4.I2.ix2.p1">
<p class="ltx_p" id="S4.I2.ix2.p1.1"><span class="ltx_text" id="S4.I2.ix2.p1.1.1" style="font-size:80%;">Sensor settings are denoted with the names of the corresponding datasets. ”Others” refers to configurations with different settings.</span></p>
</div>
</li>
<li class="ltx_item" id="S4.I2.ix3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3</span>
<div class="ltx_para" id="S4.I2.ix3.p1">
<p class="ltx_p" id="S4.I2.ix3.p1.1"><span class="ltx_text" id="S4.I2.ix3.p1.1.1" style="font-size:80%;">BasketBall has 4 groups of sensors, and Panoptic Studio has 5 groups of sensors.</span></p>
</div>
</li>
</ul>
</div>
</div>
</figure>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.4.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.5.2" style="font-size:90%;">Comparison of different unsupervised training strategies.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.2" style="width:433.6pt;height:154.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(65.4pt,-23.3pt) scale(1.43187427477836,1.43187427477836) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.2.2">
<tr class="ltx_tr" id="S4.T5.2.2.3">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T5.2.2.3.1"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.3.1.1">Unsupervised loss</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T5.2.2.3.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.3.2.1">Panoptic</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T5.2.2.3.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.3.3.1">BasketBallSync</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.1.1"><math alttext="\mathcal{L}_{\text{3D}}" class="ltx_Math" display="inline" id="S4.T5.1.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.1.m1.1a"><msub id="S4.T5.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T5.1.1.1.1.m1.1.1.2" xref="S4.T5.1.1.1.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S4.T5.1.1.1.1.m1.1.1.3" xref="S4.T5.1.1.1.1.m1.1.1.3a.cmml">3D</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T5.1.1.1.1.m1.1.1.2">ℒ</ci><ci id="S4.T5.1.1.1.1.m1.1.1.3a.cmml" xref="S4.T5.1.1.1.1.m1.1.1.3"><mtext id="S4.T5.1.1.1.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.T5.1.1.1.1.m1.1.1.3">3D</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.m1.1c">\mathcal{L}_{\text{3D}}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT 3D end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.2"><math alttext="\mathcal{L}_{\text{prior}}" class="ltx_Math" display="inline" id="S4.T5.2.2.2.2.m1.1"><semantics id="S4.T5.2.2.2.2.m1.1a"><msub id="S4.T5.2.2.2.2.m1.1.1" xref="S4.T5.2.2.2.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T5.2.2.2.2.m1.1.1.2" xref="S4.T5.2.2.2.2.m1.1.1.2.cmml">ℒ</mi><mtext id="S4.T5.2.2.2.2.m1.1.1.3" xref="S4.T5.2.2.2.2.m1.1.1.3a.cmml">prior</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.2.m1.1b"><apply id="S4.T5.2.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.2.2.2.2.m1.1.1.1.cmml" xref="S4.T5.2.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T5.2.2.2.2.m1.1.1.2.cmml" xref="S4.T5.2.2.2.2.m1.1.1.2">ℒ</ci><ci id="S4.T5.2.2.2.2.m1.1.1.3a.cmml" xref="S4.T5.2.2.2.2.m1.1.1.3"><mtext id="S4.T5.2.2.2.2.m1.1.1.3.cmml" mathsize="70%" xref="S4.T5.2.2.2.2.m1.1.1.3">prior</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.2.m1.1c">\mathcal{L}_{\text{prior}}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.2.m1.1d">caligraphic_L start_POSTSUBSCRIPT prior end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.3">MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.4">PA-MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.5">MPJPE</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.6">PA-MPJPE</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.4.1">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.4.1.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.4.2">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.4.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.4.3">29.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.4.4">16.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.4.5">84.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.4.6">75.55</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.5">
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.5.1">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.5.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.5.2">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.5.2.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.5.3">28.26</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.5.4">25.85</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.5.5">77.38</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.5.6">68.84</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.6">
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.6.1">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.6.1.1">\usym</span>2717</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.6.2">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.6.2.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.6.3">22.88</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.6.4">24.69</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.6.5">76.45</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.2.6.6">65.54</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.7">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.2.2.7.1">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.7.1.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.2.2.7.2">
<span class="ltx_ERROR undefined" id="S4.T5.2.2.7.2.1">\usym</span>2713</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.2.2.7.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.7.3.1">22.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.2.2.7.4"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.7.4.1">15.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.2.2.7.5"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.7.5.1">72.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.2.2.7.6"><span class="ltx_text ltx_font_bold" id="S4.T5.2.2.7.6.1">62.72</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Unsupervised Domain Adaption</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">In this section, we conduct a detailed analysis of synthetic dataset settings and ablation studies on the unsupervised training Losses.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Synthetic Setting</h4>
<div class="ltx_para" id="S4.SS4.SSS1.p1">
<p class="ltx_p" id="S4.SS4.SSS1.p1.1">Tu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a>]</cite> conducted an experiment training VoxelPose with a dataset’s camera configuration and human poses from other sources, then evaluating the model directly on another dataset. In this section, we further analyze the impact of scene settings in volumetric architecture. We simulated four different scene setups using the SyncHuman generator, varying sensor positions and orientations to modify camera parameters and scene sizes. Table <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.T4" title="Table 4 ‣ 4.3 3D Pose Estimation Analysis ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates that the closer the scene setups resemble each other, the better the model performs. This suggests that in practical applications, aligning synthetic data with the sensor arrangement and scene range of the target dataset can enhance the performance of unsupervised domain adaptation or direct inference in new scenarios.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Ablation Study on Unsupervised Training Losses</h4>
<div class="ltx_para" id="S4.SS4.SSS2.p1">
<p class="ltx_p" id="S4.SS4.SSS2.p1.1">For unsupervised domain adaptation, pseudo 2D pose supervision serves as the baseline necessity. Additionally, we incorporate an interpretable human prior loss and a pseudo 3D pose loss (selected based on entropy values) to aid in learning. Thus, we conduct an ablation study to analyze the impact of these two losses. According to Table <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.T5" title="Table 5 ‣ 4.3 3D Pose Estimation Analysis ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">5</span></a>, the entropy-selected pseudo 3D pose loss improves performance, and the prior loss ensures predicted poses remain within a reasonable action range. Therefore, we adopt both losses as part of our effective training strategy. Moreover, these losses enhance robustness to 2D pose estimation errors (Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.F5" title="Figure 5 ‣ 4.2 Datasets and Metrics. ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering" id="S4.F6.g1" src="figs/entropy.eps"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.3.2" style="font-size:90%;">Entropy distributions of reasonable and unreasonable predicted 3D poses.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Entropy Analysis</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">To explore the relationship between entropy values and pose rationality, we categorized some 3D poses predicted by LiCamPose as either reasonable or unreasonable manually. Figure <a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S4.F6" title="Figure 6 ‣ 4.4.2 Ablation Study on Unsupervised Training Losses ‣ 4.4 Unsupervised Domain Adaption ‣ 4 Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the distribution of entropy values for these categories. Natural division of poses occurs based on an entropy threshold. Therefore, the average entropy value can serve as an indicator of a model’s performance on an unlabeled dataset.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we propose LiCamPose, a pipeline for 3D human pose estimation using multi-view RGB and sparse point cloud data. To facilitate unsupervised training, we introduce SyncHuman, a synthetic data generator, and develop specific unsupervised training losses for domain adaptation. Through extensive experiments on synthetic and real-world datasets, we demonstrate the robust learning capabilities of our pipeline for 3D human pose estimation. Additionally, we investigate the influence of scene settings and unsupervised training losses, and explore the relationship between entropy values and pose plausibility. In future work, we aim to expand SyncHuman’s scenarios and integrate temporal information to further enhance estimation accuracy.
</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.2.1" style="font-size:90%;">2D human pose estimation: New benchmark and state of the art
analysis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib1.4.2" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib1.5.3" style="font-size:90%;">, pages 3686–3693, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
Renat Bashirov, Anastasia Ianina, Karim Iskakov, Yevgeniy Kononenko, Valeriya
Strizhkova, Victor Lempitsky, and Alexander Vakhitov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.2.1" style="font-size:90%;">Real-time rgbd-based extended body pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib2.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications
of Computer Vision</span><span class="ltx_text" id="bib.bib2.5.3" style="font-size:90%;">, pages 2807–2816, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
Walid Bekhtaoui, Ruhan Sa, Brian Teixeira, Vivek Singh, Klaus Kirchberg,
Yao-jen Chang, and Ankur Kapoor.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.2.1" style="font-size:90%;">View invariant human body detection and pose estimation from multiple
depth sensors.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.3.1" style="font-size:90%;">arXiv preprint arXiv:2005.04258</span><span class="ltx_text" id="bib.bib3.4.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
Vasileios Belagiannis, Sikandar Amin, Mykhaylo Andriluka, Bernt Schiele, Nassir
Navab, and Slobodan Ilic.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.2.1" style="font-size:90%;">3D pictorial structures for multiple human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib4.4.2" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib4.5.3" style="font-size:90%;">, pages 1669–1676, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
Alexander Bigalke, Lasse Hansen, Jasper Diesel, and Mattias P Heinrich.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.2.1" style="font-size:90%;">Domain adaptation through anatomical constraints for 3D human pose
estimation under the cover.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib5.4.2" style="font-size:90%;">International Conference on Medical Imaging with Deep
Learning</span><span class="ltx_text" id="bib.bib5.5.3" style="font-size:90%;">, pages 173–187, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.2.1" style="font-size:90%;">Realtime multi-person 2D pose estimation using part affinity
fields.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.4.2" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib6.5.3" style="font-size:90%;">, pages 7291–7299, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
Carl Doersch and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.2.1" style="font-size:90%;">Sim2real transfer learning for 3D human pose estimation: motion
to the rescue.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib7.4.2" style="font-size:90%;">, 32, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Junting Dong, Wen Jiang, Qixing Huang, Hujun Bao, and Xiaowei Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.2.1" style="font-size:90%;">Fast and robust multi-person 3D pose estimation from multiple
views.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib8.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib8.5.3" style="font-size:90%;">, pages 7792–7801, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen
Koltun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.2.1" style="font-size:90%;">CARLA: An open urban driving simulator.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib9.4.2" style="font-size:90%;">Conference on Robot Learning</span><span class="ltx_text" id="bib.bib9.5.3" style="font-size:90%;">, pages 1–16, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
Salehe Erfanian Ebadi, You-Cyuan Jhang, Alex Zook, Saurav Dhakad, Adam Crespi,
Pete Parisi, Steven Borkman, Jonathan Hogins, and Sujoy Ganguly.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.2.1" style="font-size:90%;">PeopleSansPeople: a synthetic data generator for human-centric
computer vision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.3.1" style="font-size:90%;">arXiv preprint arXiv:2112.09290</span><span class="ltx_text" id="bib.bib10.4.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
Hao-Shu Fang, Jiefeng Li, Hongyang Tang, Chao Xu, Haoyi Zhu, Yuliang Xiu,
Yong-Lu Li, and Cewu Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.2.1" style="font-size:90%;">Alphapose: Whole-body regional multi-person pose estimation and
tracking in real-time.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.3.1" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span class="ltx_text" id="bib.bib11.4.2" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
Nicola Garau, Niccolo Bisagno, Piotr Bródka, and Nicola Conci.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.2.1" style="font-size:90%;">DECA: Deep viewpoint-equivariant human pose estimation using
capsule autoencoders.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib12.5.3" style="font-size:90%;">, pages 11677–11686, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.2.1" style="font-size:90%;">Are we ready for autonomous driving? the KITTI vision benchmark
suite.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib13.4.2" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib13.5.3" style="font-size:90%;">, pages 3354–3361, 2012.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
Beerend GA Gerats, Jelmer M Wolterink, and Ivo AMJ Broeders.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.2.1" style="font-size:90%;">3D human pose estimation in multi-view operating room videos using
differentiable camera projections.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.3.1" style="font-size:90%;">Computer Methods in Biomechanics and Biomedical Engineering:
Imaging &amp; Visualization</span><span class="ltx_text" id="bib.bib14.4.2" style="font-size:90%;">, pages 1–9, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
Mohsen Gholami, Ahmad Rezaei, Helge Rhodin, Rabab Ward, and Z Jane Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.2.1" style="font-size:90%;">Self-supervised 3D human pose estimation from video.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.3.1" style="font-size:90%;">Neurocomputing</span><span class="ltx_text" id="bib.bib15.4.2" style="font-size:90%;">, 488:97–106, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
John C Gower.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.2.1" style="font-size:90%;">Generalized procrustes analysis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.3.1" style="font-size:90%;">Psychometrika</span><span class="ltx_text" id="bib.bib16.4.2" style="font-size:90%;">, 40:33–51, 1975.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
Hengkai Guo, Guijin Wang, Xinghao Chen, and Cairong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.2.1" style="font-size:90%;">Towards good practices for deep 3D hand pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.3.1" style="font-size:90%;">arXiv preprint arXiv:1707.07248</span><span class="ltx_text" id="bib.bib17.4.2" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
Lasse Hansen, Marlin Siebert, Jasper Diesel, and Mattias P Heinrich.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.2.1" style="font-size:90%;">Fusing information from multiple 2D depth cameras for 3D human
pose estimation in the operating room.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.3.1" style="font-size:90%;">International Journal of Computer Assisted Radiology and
Surgery</span><span class="ltx_text" id="bib.bib18.4.2" style="font-size:90%;">, 14:1871–1879, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
Albert Haque, Boya Peng, Zelun Luo, Alexandre Alahi, Serena Yeung, and Li
Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.2.1" style="font-size:90%;">Towards viewpoint invariant 3D human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib19.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib19.5.3" style="font-size:90%;">,
pages 160–177, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
Yunzhong Hou, Liang Zheng, and Stephen Gould.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.2.1" style="font-size:90%;">Multiview detection with feature perspective transformation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib20.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib20.5.3" style="font-size:90%;">,
pages 1–18, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
Catalin Ionescu, Dragos Papava, Vlad Olaru, and Cristian Sminchisescu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.2.1" style="font-size:90%;">Human3.6M: Large scale datasets and predictive methods for 3D
human sensing in natural environments.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.3.1" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span class="ltx_text" id="bib.bib21.4.2" style="font-size:90%;">,
36(7):1325–1339, 2013.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
Karim Iskakov, Egor Burkov, Victor Lempitsky, and Yury Malkov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.2.1" style="font-size:90%;">Learnable triangulation of human pose.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib22.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib22.5.3" style="font-size:90%;">, pages 7718–7727, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
Sheng Jin, Lumin Xu, Jin Xu, Can Wang, Wentao Liu, Chen Qian, Wanli Ouyang, and
Ping Luo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.2.1" style="font-size:90%;">Whole-body human pose estimation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib23.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib23.5.3" style="font-size:90%;">,
pages 196–214, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
Hanbyul Joo, Hao Liu, Lei Tan, Lin Gui, Bart Nabbe, Iain Matthews, Takeo
Kanade, Shohei Nobuhara, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.2.1" style="font-size:90%;">Panoptic studio: A massively multiview system for social motion
capture.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib24.4.2" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span class="ltx_text" id="bib.bib24.5.3" style="font-size:90%;">, pages 3334–3342, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
Diederik P Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.2.1" style="font-size:90%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.3.1" style="font-size:90%;">arXiv preprint arXiv:1412.6980</span><span class="ltx_text" id="bib.bib25.4.2" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
Muhammed Kocabas, Salih Karagoz, and Emre Akbas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.2.1" style="font-size:90%;">Self-supervised learning of 3D human pose using multi-view
geometry.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib26.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib26.5.3" style="font-size:90%;">, pages 1077–1086, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
Jogendra Nath Kundu, Ambareesh Revanur, Govind Vitthal Waghmare, Rahul Mysore
Venkatesh, and R Venkatesh Babu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.2.1" style="font-size:90%;">Unsupervised cross-modal alignment for multi-person 3D pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib27.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib27.5.3" style="font-size:90%;">,
pages 35–52, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
Jogendra Nath Kundu, Siddharth Seth, Pradyumna YM, Varun Jampani, Anirban
Chakraborty, and R Venkatesh Babu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.2.1" style="font-size:90%;">Uncertainty-aware adaptation for self-supervised 3D human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib28.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib28.5.3" style="font-size:90%;">, pages 20448–20459, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.1.1" style="font-size:90%;">
Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar
Beijbom.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.2.1" style="font-size:90%;">PointPillars: Fast encoders for object detection from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib29.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib29.5.3" style="font-size:90%;">, pages 12697–12705, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.1.1" style="font-size:90%;">
Jialian Li, Jingyi Zhang, Zhiyong Wang, Siqi Shen, Chenglu Wen, Yuexin Ma, Lan
Xu, Jingyi Yu, and Cheng Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.2.1" style="font-size:90%;">Lidarcap: Long-range marker-less 3d human motion capture with lidar
point clouds.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib30.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib30.5.3" style="font-size:90%;">, pages 20502–20512, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.1.1" style="font-size:90%;">
Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.2.1" style="font-size:90%;">Deep continuous fusion for multi-sensor 3D object detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib31.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib31.5.3" style="font-size:90%;">,
pages 641–656, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.1.1" style="font-size:90%;">
Jiahao Lin and Gim Hee Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.2.1" style="font-size:90%;">Multi-view multi-person 3D pose estimation with Plane Sweep
Stereo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib32.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib32.5.3" style="font-size:90%;">, pages 11886–11895, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.1.1" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.2.1" style="font-size:90%;">Microsoft COCO: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib33.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib33.5.3" style="font-size:90%;">,
pages 740–755, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.1.1" style="font-size:90%;">
Zhijian Liu, Haotian Tang, Alexander Amini, Xinyu Yang, Huizi Mao, Daniela Rus,
and Song Han.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.2.1" style="font-size:90%;">BEVFusion: Multi-task multi-sensor fusion with unified bird’s-eye
view representation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.3.1" style="font-size:90%;">arXiv preprint arXiv:2205.13542</span><span class="ltx_text" id="bib.bib34.4.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.1.1" style="font-size:90%;">
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J
Black.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.2.1" style="font-size:90%;">SMPL: A skinned multi-person linear model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib35.3.1" style="font-size:90%;">ACM Transactions on Graphics</span><span class="ltx_text" id="bib.bib35.4.2" style="font-size:90%;">, 34(6):1–16, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.1.1" style="font-size:90%;">
Qianli Ma, Jinlong Yang, Anurag Ranjan, Sergi Pujades, Gerard Pons-Moll, Siyu
Tang, and Michael J Black.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.2.1" style="font-size:90%;">Learning to dress 3D people in generative clothing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib36.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib36.5.3" style="font-size:90%;">, pages 6469–6478, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.1.1" style="font-size:90%;">
Naureen Mahmood, Nima Ghorbani, Nikolaus F Troje, Gerard Pons-Moll, and
Michael J Black.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.2.1" style="font-size:90%;">AMASS: Archive of motion capture as surface shapes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib37.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib37.5.3" style="font-size:90%;">, pages 5442–5451, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.1.1" style="font-size:90%;">
Angel Martínez-González, Michael Villamizar, Olivier Canévet, and
Jean-Marc Odobez.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.2.1" style="font-size:90%;">Residual pose: A decoupled approach for depth-based 3D human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib38.4.2" style="font-size:90%;">IEEE/RSJ International Conference on Intelligent Robots and
Systems</span><span class="ltx_text" id="bib.bib38.5.3" style="font-size:90%;">, pages 10313–10318, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.1.1" style="font-size:90%;">
Gyeongsik Moon, Ju Yong Chang, and Kyoung Mu Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.2.1" style="font-size:90%;">V2V-Posenet: Voxel-to-voxel prediction network for accurate 3D
hand and human pose estimation from a single depth map.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib39.4.2" style="font-size:90%;">Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib39.5.3" style="font-size:90%;">, pages 5079–5088, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.1.1" style="font-size:90%;">
AJ Piergiovanni, Vincent Casser, Michael S Ryoo, and Anelia Angelova.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.2.1" style="font-size:90%;">4D-net for learned multi-modal alignment.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib40.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib40.5.3" style="font-size:90%;">, pages 15435–15445, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.1.1" style="font-size:90%;">
Charles R Qi, Or Litany, Kaiming He, and Leonidas J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.2.1" style="font-size:90%;">Deep hough voting for 3D object detection in point clouds.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib41.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib41.5.3" style="font-size:90%;">, pages 9277–9286, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.1.1" style="font-size:90%;">
N Dinesh Reddy, Laurent Guigues, Leonid Pishchulin, Jayan Eledath, and
Srinivasa G Narasimhan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.2.1" style="font-size:90%;">Tessetrack: End-to-end learnable multi-person articulated 3D pose
tracking.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib42.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib42.5.3" style="font-size:90%;">, pages 15190–15200, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.1.1" style="font-size:90%;">
Edoardo Remelli, Shangchen Han, Sina Honari, Pascal Fua, and Robert Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.2.1" style="font-size:90%;">Lightweight multi-view 3D pose estimation through
camera-disentangled representation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib43.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib43.5.3" style="font-size:90%;">, pages 6040–6049, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.1.1" style="font-size:90%;">
Vinkle Srivastav, Afshin Gangi, and Nicolas Padoy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.2.1" style="font-size:90%;">Self-supervision on unlabelled or data for multi-person 2D/3D human
pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib44.4.2" style="font-size:90%;">Medical Image Computing and Computer Assisted Intervention</span><span class="ltx_text" id="bib.bib44.5.3" style="font-size:90%;">,
pages 761–771, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.1.1" style="font-size:90%;">
Vinkle Srivastav, Thibaut Issenhuth, Abdolrahim Kadkhodamohammadi, Michel de
Mathelin, Afshin Gangi, and Nicolas Padoy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.2.1" style="font-size:90%;">Mvor: A multi-view rgb-d operating room dataset for 2D and 3D
human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib45.3.1" style="font-size:90%;">arXiv preprint arXiv:1808.08180</span><span class="ltx_text" id="bib.bib45.4.2" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.1.1" style="font-size:90%;">
Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.2.1" style="font-size:90%;">Deep high-resolution representation learning for human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib46.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib46.5.3" style="font-size:90%;">, pages 5693–5703, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.1.1" style="font-size:90%;">
Hanyue Tu, Chunyu Wang, and Wenjun Zeng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.2.1" style="font-size:90%;">VoxelPose: Towards multi-camera 3D human pose estimation in wild
environment.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib47.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib47.5.3" style="font-size:90%;">,
pages 197–212, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.1.1" style="font-size:90%;">
Gul Varol, Javier Romero, Xavier Martin, Naureen Mahmood, Michael J Black, Ivan
Laptev, and Cordelia Schmid.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.2.1" style="font-size:90%;">Learning from synthetic humans.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib48.4.2" style="font-size:90%;">Proceedings of the IEEE Conference on computer vision and
pattern recognition</span><span class="ltx_text" id="bib.bib48.5.3" style="font-size:90%;">, pages 109–117, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.1.1" style="font-size:90%;">
Timo Von Marcard, Roberto Henschel, Michael J Black, Bodo Rosenhahn, and Gerard
Pons-Moll.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.2.1" style="font-size:90%;">Recovering accurate 3D human pose in the wild using imus and a
moving camera.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib49.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib49.5.3" style="font-size:90%;">,
pages 601–617, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.1.1" style="font-size:90%;">
Size Wu, Sheng Jin, Wentao Liu, Lei Bai, Chen Qian, Dong Liu, and Wanli Ouyang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.2.1" style="font-size:90%;">Graph-based 3D multi-person pose estimation using multi-view
images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib50.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span class="ltx_text" id="bib.bib50.5.3" style="font-size:90%;">, pages 11148–11157, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.1.1" style="font-size:90%;">
Yufei Xu, Jing Zhang, Qiming Zhang, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.2.1" style="font-size:90%;">Vitpose: Simple vision transformer baselines for human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib51.3.1" style="font-size:90%;">arXiv preprint arXiv:2204.12484</span><span class="ltx_text" id="bib.bib51.4.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.1.1" style="font-size:90%;">
Chenyu Yang, Yuntao Chen, Hao Tian, Chenxin Tao, Xizhou Zhu, Zhaoxiang Zhang,
Gao Huang, Hongyang Li, Yu Qiao, Lewei Lu, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.2.1" style="font-size:90%;">Bevformer v2: Adapting modern image backbones to bird’s-eye-view
recognition via perspective supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib52.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib52.5.3" style="font-size:90%;">, pages 17830–17839, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.1.1" style="font-size:90%;">
Hang Ye, Wentao Zhu, Chunyu Wang, Rujie Wu, and Yizhou Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.2.1" style="font-size:90%;">Faster VoxelPose: Real-time 3d human pose estimation by
orthographic projection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib53.4.2" style="font-size:90%;">Proceedings of the European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib53.5.3" style="font-size:90%;">,
pages 142–159, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.1.1" style="font-size:90%;">
Jianfeng Zhang, Yujun Cai, Shuicheng Yan, Jiashi Feng, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.2.1" style="font-size:90%;">Direct multi-view multi-person 3D pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib54.3.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib54.4.2" style="font-size:90%;">,
34:13153–13164, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.1.1" style="font-size:90%;">
Meng Zhang, Wenxuan Guo, Bohao Fan, Yifan Chen, Jianjiang Feng, and Jie Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.2.1" style="font-size:90%;">A flexible multi-view multi-modal imaging system for outdoor scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib55.4.2" style="font-size:90%;">2022 International Conference on 3D Vision (3DV)</span><span class="ltx_text" id="bib.bib55.5.3" style="font-size:90%;">, pages
322–331. IEEE, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.1.1" style="font-size:90%;">
Song-Hai Zhang, Ruilong Li, Xin Dong, Paul Rosin, Zixi Cai, Xi Han, Dingcheng
Yang, Haozhi Huang, and Shi-Min Hu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.2.1" style="font-size:90%;">Pose2seg: Detection free human instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib56.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib56.5.3" style="font-size:90%;">, pages 889–898, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.1.1" style="font-size:90%;">
Xiheng Zhang, Yongkang Wong, Mohan S Kankanhalli, and Weidong Geng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.2.1" style="font-size:90%;">Unsupervised domain adaptation for 3D human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib57.4.2" style="font-size:90%;">Proceedings of the 27th ACM International Conference on
Multimedia</span><span class="ltx_text" id="bib.bib57.5.3" style="font-size:90%;">, pages 926–934, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.1.1" style="font-size:90%;">
Zihao Zhang, Lei Hu, Xiaoming Deng, and Shihong Xia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.2.1" style="font-size:90%;">Sequential 3D human pose estimation using adaptive point cloud
sampling strategy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib58.4.2" style="font-size:90%;">International Joint Conferences on Artificial Intelligence
Organization</span><span class="ltx_text" id="bib.bib58.5.3" style="font-size:90%;">, pages 1330–1337, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.1.1" style="font-size:90%;">
Jingxiao Zheng, Xinwei Shi, Alexander Gorban, Junhua Mao, Yang Song, Charles R
Qi, Ting Liu, Visesh Chari, Andre Cornman, Yin Zhou, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.2.1" style="font-size:90%;">Multi-modal 3D human pose estimation with 2D weak supervision in
autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib59.4.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span class="ltx_text" id="bib.bib59.5.3" style="font-size:90%;">, pages 4478–4487, 2022.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\thetitle</span>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.2"><span class="ltx_text" id="p1.2.1" style="font-size:144%;">Supplementary Material 
<br class="ltx_break"/></span></p>
</div>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">6 </span>Different Scanning Patterns of Point Cloud</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text" id="S6.p1.1.1" style="font-size:144%;">There are various methods to obtain or scan the point cloud: 1) randomly sampling the depth map; 2) sampling the depth map using multiple equidistant horizontal lines to mimic Velodyne LiDARs; and 3) sampling the depth map with the ”Rose curve” sampling equation as discussed in our paper to replicate Livox LiDARs. Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S8.F7" style="font-size:144%;" title="Figure 7 ‣ 8 SyncHuman Generator ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">7</span></a><span class="ltx_text" id="S6.p1.1.2" style="font-size:144%;"> illustrates that the ”Rose curve” sampling equation yields minimal information due to its localized concentrated scan. However, Livox LiDARs are more cost-effective than Velodyne LiDARs and have been employed in numerous applications, including surveillance. Additionally, our BaseketBall dataset is captured using Livox LiDARs. Therefore, we adopt the Livox scanning pattern to simulate the point cloud scanning in our experiments.</span></p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">7 </span>BaseketBall</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1"><span class="ltx_text" id="S7.p1.1.1" style="font-size:144%;">BasketBall is an outdoor dataset capturing a basketball match using four sensor nodes, each comprising one Livox LiDAR and one RGB camera, in a convergent acquisition setup. The dataset presents challenges due to its extensive coverage, occlusions, and the dynamic motions of the players (Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S8.F8" style="font-size:144%;" title="Figure 8 ‣ 8 SyncHuman Generator ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">8</span></a><span class="ltx_text" id="S7.p1.1.2" style="font-size:144%;">). We have developed an annotation tool to label the players’ 3D bounding boxes and IDs. In the future, we plan to integrate 3D human keypoint annotation into the tool with the assistance of LiCamPose.</span></p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">8 </span>SyncHuman Generator</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1"><span class="ltx_text" id="S8.p1.1.1" style="font-size:144%;">We can use our synthetic data generator, SyncHuman, to simulate any arrangement of sensors to observe a scene. As demonstrated in the experiments in our paper, using the same scene setting for both training and testing yields better transfer performance. Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S8.F8" style="font-size:144%;" title="Figure 8 ‣ 8 SyncHuman Generator ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">8</span></a><span class="ltx_text" id="S8.p1.1.2" style="font-size:144%;"> compares the datasets we generated, PanopticSync and BasketBallSync, with the original datasets.</span></p>
</div>
<figure class="ltx_figure" id="S8.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="318" id="S8.F7.g1" src="extracted/5734580/figs/scanning_pattern.png" width="538"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S8.F7.4.1.1" style="font-size:63%;">Figure 7</span>: </span><span class="ltx_text" id="S8.F7.5.2" style="font-size:63%;">Different scanning patterns of point clouds. All samples shown in this figure are from the same scene, captured at the same time, and contain the same number of points.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S8.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="342" id="S8.F8.g1" src="extracted/5734580/figs/dataset2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S8.F8.4.1.1" style="font-size:63%;">Figure 8</span>: </span><span class="ltx_text" id="S8.F8.5.2" style="font-size:63%;">Real datasets and the corresponding synthetic datasets generated by SyncHuman.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">9 </span>Human Prior Loss</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1"><span class="ltx_text" id="S9.p1.1.1" style="font-size:144%;">We designed the human prior loss to encourage the network to generate human-like 3D keypoints. The human prior loss comprises three components: 1) the predicted bone lengths should be within a reasonable range; 2) the predicted lengths of symmetric bones should be similar; and 3) the predicted bone angles should be reasonable according to human kinematics.</span></p>
</div>
<div class="ltx_para" id="S9.p2">
<p class="ltx_p" id="S9.p2.3"><span class="ltx_text" id="S9.p2.3.1" style="font-size:144%;">We set a limited length range for all bones. In our case,
we set </span><math alttext="l_{\text{min}}=0.05\text{m}" class="ltx_Math" display="inline" id="S9.p2.1.m1.1"><semantics id="S9.p2.1.m1.1a"><mrow id="S9.p2.1.m1.1.1" xref="S9.p2.1.m1.1.1.cmml"><msub id="S9.p2.1.m1.1.1.2" xref="S9.p2.1.m1.1.1.2.cmml"><mi id="S9.p2.1.m1.1.1.2.2" mathsize="144%" xref="S9.p2.1.m1.1.1.2.2.cmml">l</mi><mtext id="S9.p2.1.m1.1.1.2.3" mathsize="144%" xref="S9.p2.1.m1.1.1.2.3a.cmml">min</mtext></msub><mo id="S9.p2.1.m1.1.1.1" mathsize="144%" xref="S9.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S9.p2.1.m1.1.1.3" xref="S9.p2.1.m1.1.1.3.cmml"><mn id="S9.p2.1.m1.1.1.3.2" mathsize="144%" xref="S9.p2.1.m1.1.1.3.2.cmml">0.05</mn><mo id="S9.p2.1.m1.1.1.3.1" xref="S9.p2.1.m1.1.1.3.1.cmml">⁢</mo><mtext id="S9.p2.1.m1.1.1.3.3" mathsize="144%" xref="S9.p2.1.m1.1.1.3.3a.cmml">m</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.p2.1.m1.1b"><apply id="S9.p2.1.m1.1.1.cmml" xref="S9.p2.1.m1.1.1"><eq id="S9.p2.1.m1.1.1.1.cmml" xref="S9.p2.1.m1.1.1.1"></eq><apply id="S9.p2.1.m1.1.1.2.cmml" xref="S9.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S9.p2.1.m1.1.1.2.1.cmml" xref="S9.p2.1.m1.1.1.2">subscript</csymbol><ci id="S9.p2.1.m1.1.1.2.2.cmml" xref="S9.p2.1.m1.1.1.2.2">𝑙</ci><ci id="S9.p2.1.m1.1.1.2.3a.cmml" xref="S9.p2.1.m1.1.1.2.3"><mtext id="S9.p2.1.m1.1.1.2.3.cmml" mathsize="101%" xref="S9.p2.1.m1.1.1.2.3">min</mtext></ci></apply><apply id="S9.p2.1.m1.1.1.3.cmml" xref="S9.p2.1.m1.1.1.3"><times id="S9.p2.1.m1.1.1.3.1.cmml" xref="S9.p2.1.m1.1.1.3.1"></times><cn id="S9.p2.1.m1.1.1.3.2.cmml" type="float" xref="S9.p2.1.m1.1.1.3.2">0.05</cn><ci id="S9.p2.1.m1.1.1.3.3a.cmml" xref="S9.p2.1.m1.1.1.3.3"><mtext id="S9.p2.1.m1.1.1.3.3.cmml" mathsize="144%" xref="S9.p2.1.m1.1.1.3.3">m</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.1.m1.1c">l_{\text{min}}=0.05\text{m}</annotation><annotation encoding="application/x-llamapun" id="S9.p2.1.m1.1d">italic_l start_POSTSUBSCRIPT min end_POSTSUBSCRIPT = 0.05 m</annotation></semantics></math><span class="ltx_text" id="S9.p2.3.2" style="font-size:144%;"> and </span><math alttext="l_{\text{max}}=0.7\text{m}" class="ltx_Math" display="inline" id="S9.p2.2.m2.1"><semantics id="S9.p2.2.m2.1a"><mrow id="S9.p2.2.m2.1.1" xref="S9.p2.2.m2.1.1.cmml"><msub id="S9.p2.2.m2.1.1.2" xref="S9.p2.2.m2.1.1.2.cmml"><mi id="S9.p2.2.m2.1.1.2.2" mathsize="144%" xref="S9.p2.2.m2.1.1.2.2.cmml">l</mi><mtext id="S9.p2.2.m2.1.1.2.3" mathsize="144%" xref="S9.p2.2.m2.1.1.2.3a.cmml">max</mtext></msub><mo id="S9.p2.2.m2.1.1.1" mathsize="144%" xref="S9.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S9.p2.2.m2.1.1.3" xref="S9.p2.2.m2.1.1.3.cmml"><mn id="S9.p2.2.m2.1.1.3.2" mathsize="144%" xref="S9.p2.2.m2.1.1.3.2.cmml">0.7</mn><mo id="S9.p2.2.m2.1.1.3.1" xref="S9.p2.2.m2.1.1.3.1.cmml">⁢</mo><mtext id="S9.p2.2.m2.1.1.3.3" mathsize="144%" xref="S9.p2.2.m2.1.1.3.3a.cmml">m</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.p2.2.m2.1b"><apply id="S9.p2.2.m2.1.1.cmml" xref="S9.p2.2.m2.1.1"><eq id="S9.p2.2.m2.1.1.1.cmml" xref="S9.p2.2.m2.1.1.1"></eq><apply id="S9.p2.2.m2.1.1.2.cmml" xref="S9.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S9.p2.2.m2.1.1.2.1.cmml" xref="S9.p2.2.m2.1.1.2">subscript</csymbol><ci id="S9.p2.2.m2.1.1.2.2.cmml" xref="S9.p2.2.m2.1.1.2.2">𝑙</ci><ci id="S9.p2.2.m2.1.1.2.3a.cmml" xref="S9.p2.2.m2.1.1.2.3"><mtext id="S9.p2.2.m2.1.1.2.3.cmml" mathsize="101%" xref="S9.p2.2.m2.1.1.2.3">max</mtext></ci></apply><apply id="S9.p2.2.m2.1.1.3.cmml" xref="S9.p2.2.m2.1.1.3"><times id="S9.p2.2.m2.1.1.3.1.cmml" xref="S9.p2.2.m2.1.1.3.1"></times><cn id="S9.p2.2.m2.1.1.3.2.cmml" type="float" xref="S9.p2.2.m2.1.1.3.2">0.7</cn><ci id="S9.p2.2.m2.1.1.3.3a.cmml" xref="S9.p2.2.m2.1.1.3.3"><mtext id="S9.p2.2.m2.1.1.3.3.cmml" mathsize="144%" xref="S9.p2.2.m2.1.1.3.3">m</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.2.m2.1c">l_{\text{max}}=0.7\text{m}</annotation><annotation encoding="application/x-llamapun" id="S9.p2.2.m2.1d">italic_l start_POSTSUBSCRIPT max end_POSTSUBSCRIPT = 0.7 m</annotation></semantics></math><span class="ltx_text" id="S9.p2.3.3" style="font-size:144%;">. So the </span><math alttext="\mathcal{L}_{\text{length}}" class="ltx_Math" display="inline" id="S9.p2.3.m3.1"><semantics id="S9.p2.3.m3.1a"><msub id="S9.p2.3.m3.1.1" xref="S9.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.p2.3.m3.1.1.2" mathsize="144%" xref="S9.p2.3.m3.1.1.2.cmml">ℒ</mi><mtext id="S9.p2.3.m3.1.1.3" mathsize="144%" xref="S9.p2.3.m3.1.1.3a.cmml">length</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p2.3.m3.1b"><apply id="S9.p2.3.m3.1.1.cmml" xref="S9.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S9.p2.3.m3.1.1.1.cmml" xref="S9.p2.3.m3.1.1">subscript</csymbol><ci id="S9.p2.3.m3.1.1.2.cmml" xref="S9.p2.3.m3.1.1.2">ℒ</ci><ci id="S9.p2.3.m3.1.1.3a.cmml" xref="S9.p2.3.m3.1.1.3"><mtext id="S9.p2.3.m3.1.1.3.cmml" mathsize="101%" xref="S9.p2.3.m3.1.1.3">length</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.3.m3.1c">\mathcal{L}_{\text{length}}</annotation><annotation encoding="application/x-llamapun" id="S9.p2.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT length end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p2.3.4" style="font-size:144%;"> can be defined as:</span></p>
<table class="ltx_equationgroup ltx_eqn_table" id="S9.E7">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S9.E7X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{length}}=\sum_{b=1}^{N}\mathcal{C}(B_{i}-l_{%
\text{max}},0)+\mathcal{C}(l_{\text{min}}-B_{i},0)," class="ltx_Math" display="inline" id="S9.E7X.2.1.1.m1.3"><semantics id="S9.E7X.2.1.1.m1.3a"><mrow id="S9.E7X.2.1.1.m1.3.3.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.cmml"><mrow id="S9.E7X.2.1.1.m1.3.3.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.cmml"><msub id="S9.E7X.2.1.1.m1.3.3.1.1.4" xref="S9.E7X.2.1.1.m1.3.3.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E7X.2.1.1.m1.3.3.1.1.4.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.4.2.cmml">ℒ</mi><mtext id="S9.E7X.2.1.1.m1.3.3.1.1.4.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.4.3a.cmml">length</mtext></msub><mo id="S9.E7X.2.1.1.m1.3.3.1.1.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.3.cmml">=</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.cmml"><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.cmml"><mstyle displaystyle="true" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.cmml"><munderover id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2a" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.cmml"><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.2" maxsize="144%" minsize="144%" movablelimits="false" stretchy="true" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.cmml"><mi id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.2.cmml">b</mi><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.1" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.3.cmml">N</mi></munderover></mstyle><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.3.cmml">𝒞</mi><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml"><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.2" maxsize="144%" minsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml">B</mi><mi id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">l</mi><mtext id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.3a.cmml">max</mtext></msub></mrow><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml">,</mo><mn id="S9.E7X.2.1.1.m1.1.1" mathsize="144%" xref="S9.E7X.2.1.1.m1.1.1.cmml">0</mn><mo id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.4" maxsize="144%" minsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S9.E7X.2.1.1.m1.3.3.1.1.2.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.3.cmml">+</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.2.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.3.cmml">𝒞</mi><mo id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.2.cmml">⁢</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.2.cmml"><mo id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.2" maxsize="144%" minsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.2.cmml">(</mo><mrow id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.cmml"><msub id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.cmml"><mi id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.2.cmml">l</mi><mtext id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.3a.cmml">min</mtext></msub><mo id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.1" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.1.cmml">−</mo><msub id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.cmml"><mi id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.2.cmml">B</mi><mi id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.3" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.2.cmml">,</mo><mn id="S9.E7X.2.1.1.m1.2.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.2.2.cmml">0</mn><mo id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.4" maxsize="144%" minsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S9.E7X.2.1.1.m1.3.3.1.2" mathsize="144%" xref="S9.E7X.2.1.1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E7X.2.1.1.m1.3b"><apply id="S9.E7X.2.1.1.m1.3.3.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1"><eq id="S9.E7X.2.1.1.m1.3.3.1.1.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.3"></eq><apply id="S9.E7X.2.1.1.m1.3.3.1.1.4.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.4.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.4">subscript</csymbol><ci id="S9.E7X.2.1.1.m1.3.3.1.1.4.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.4.2">ℒ</ci><ci id="S9.E7X.2.1.1.m1.3.3.1.1.4.3a.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.4.3"><mtext id="S9.E7X.2.1.1.m1.3.3.1.1.4.3.cmml" mathsize="101%" xref="S9.E7X.2.1.1.m1.3.3.1.1.4.3">length</mtext></ci></apply><apply id="S9.E7X.2.1.1.m1.3.3.1.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2"><plus id="S9.E7X.2.1.1.m1.3.3.1.1.2.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.3"></plus><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1"><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2">superscript</csymbol><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.2"></sum><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3"><eq id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.2">𝑏</ci><cn id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.2.3">𝑁</ci></apply><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1"><times id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.2"></times><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.3">𝒞</ci><interval closure="open" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1"><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1"><minus id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.1"></minus><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.2">𝐵</ci><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.2">𝑙</ci><ci id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.3a.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.3"><mtext id="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" mathsize="101%" xref="S9.E7X.2.1.1.m1.3.3.1.1.1.1.1.1.1.1.3.3">max</mtext></ci></apply></apply><cn id="S9.E7X.2.1.1.m1.1.1.cmml" type="integer" xref="S9.E7X.2.1.1.m1.1.1">0</cn></interval></apply></apply><apply id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2"><times id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.2"></times><ci id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.3">𝒞</ci><interval closure="open" id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1"><apply id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1"><minus id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.1"></minus><apply id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2">subscript</csymbol><ci id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.2">𝑙</ci><ci id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.3a.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.3"><mtext id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.2.3">min</mtext></ci></apply><apply id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.1.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3">subscript</csymbol><ci id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.2.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.2">𝐵</ci><ci id="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.3.cmml" xref="S9.E7X.2.1.1.m1.3.3.1.1.2.2.1.1.1.3.3">𝑖</ci></apply></apply><cn id="S9.E7X.2.1.1.m1.2.2.cmml" type="integer" xref="S9.E7X.2.1.1.m1.2.2">0</cn></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E7X.2.1.1.m1.3c">\displaystyle\mathcal{L}_{\text{length}}=\sum_{b=1}^{N}\mathcal{C}(B_{i}-l_{%
\text{max}},0)+\mathcal{C}(l_{\text{min}}-B_{i},0),</annotation><annotation encoding="application/x-llamapun" id="S9.E7X.2.1.1.m1.3d">caligraphic_L start_POSTSUBSCRIPT length end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_b = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT caligraphic_C ( italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_l start_POSTSUBSCRIPT max end_POSTSUBSCRIPT , 0 ) + caligraphic_C ( italic_l start_POSTSUBSCRIPT min end_POSTSUBSCRIPT - italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , 0 ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(7)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S9.p2.8"><span class="ltx_text" id="S9.p2.8.1" style="font-size:144%;">where </span><math alttext="\mathcal{C}(\cdot)" class="ltx_Math" display="inline" id="S9.p2.4.m1.1"><semantics id="S9.p2.4.m1.1a"><mrow id="S9.p2.4.m1.1.2" xref="S9.p2.4.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.p2.4.m1.1.2.2" mathsize="144%" xref="S9.p2.4.m1.1.2.2.cmml">𝒞</mi><mo id="S9.p2.4.m1.1.2.1" xref="S9.p2.4.m1.1.2.1.cmml">⁢</mo><mrow id="S9.p2.4.m1.1.2.3.2" xref="S9.p2.4.m1.1.2.cmml"><mo id="S9.p2.4.m1.1.2.3.2.1" maxsize="144%" minsize="144%" xref="S9.p2.4.m1.1.2.cmml">(</mo><mo id="S9.p2.4.m1.1.1" lspace="0em" mathsize="144%" rspace="0em" xref="S9.p2.4.m1.1.1.cmml">⋅</mo><mo id="S9.p2.4.m1.1.2.3.2.2" maxsize="144%" minsize="144%" xref="S9.p2.4.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.p2.4.m1.1b"><apply id="S9.p2.4.m1.1.2.cmml" xref="S9.p2.4.m1.1.2"><times id="S9.p2.4.m1.1.2.1.cmml" xref="S9.p2.4.m1.1.2.1"></times><ci id="S9.p2.4.m1.1.2.2.cmml" xref="S9.p2.4.m1.1.2.2">𝒞</ci><ci id="S9.p2.4.m1.1.1.cmml" xref="S9.p2.4.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.4.m1.1c">\mathcal{C}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S9.p2.4.m1.1d">caligraphic_C ( ⋅ )</annotation></semantics></math><span class="ltx_text" id="S9.p2.8.2" style="font-size:144%;"> is the clipping function that clip the value greater than </span><math alttext="0" class="ltx_Math" display="inline" id="S9.p2.5.m2.1"><semantics id="S9.p2.5.m2.1a"><mn id="S9.p2.5.m2.1.1" mathsize="144%" xref="S9.p2.5.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S9.p2.5.m2.1b"><cn id="S9.p2.5.m2.1.1.cmml" type="integer" xref="S9.p2.5.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="S9.p2.8.3" style="font-size:144%;">, </span><math alttext="N" class="ltx_Math" display="inline" id="S9.p2.6.m3.1"><semantics id="S9.p2.6.m3.1a"><mi id="S9.p2.6.m3.1.1" mathsize="144%" xref="S9.p2.6.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S9.p2.6.m3.1b"><ci id="S9.p2.6.m3.1.1.cmml" xref="S9.p2.6.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.6.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S9.p2.6.m3.1d">italic_N</annotation></semantics></math><span class="ltx_text" id="S9.p2.8.4" style="font-size:144%;"> is the number of bones.
As to the symmetric bones, we set the symmetric bones as a pair, and set </span><math alttext="L_{\text{2}}" class="ltx_Math" display="inline" id="S9.p2.7.m4.1"><semantics id="S9.p2.7.m4.1a"><msub id="S9.p2.7.m4.1.1" xref="S9.p2.7.m4.1.1.cmml"><mi id="S9.p2.7.m4.1.1.2" mathsize="144%" xref="S9.p2.7.m4.1.1.2.cmml">L</mi><mtext id="S9.p2.7.m4.1.1.3" mathsize="144%" xref="S9.p2.7.m4.1.1.3a.cmml">2</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p2.7.m4.1b"><apply id="S9.p2.7.m4.1.1.cmml" xref="S9.p2.7.m4.1.1"><csymbol cd="ambiguous" id="S9.p2.7.m4.1.1.1.cmml" xref="S9.p2.7.m4.1.1">subscript</csymbol><ci id="S9.p2.7.m4.1.1.2.cmml" xref="S9.p2.7.m4.1.1.2">𝐿</ci><ci id="S9.p2.7.m4.1.1.3a.cmml" xref="S9.p2.7.m4.1.1.3"><mtext id="S9.p2.7.m4.1.1.3.cmml" mathsize="101%" xref="S9.p2.7.m4.1.1.3">2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.7.m4.1c">L_{\text{2}}</annotation><annotation encoding="application/x-llamapun" id="S9.p2.7.m4.1d">italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p2.8.5" style="font-size:144%;"> loss among them. So the </span><math alttext="\mathcal{L}_{\text{symm}}" class="ltx_Math" display="inline" id="S9.p2.8.m5.1"><semantics id="S9.p2.8.m5.1a"><msub id="S9.p2.8.m5.1.1" xref="S9.p2.8.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.p2.8.m5.1.1.2" mathsize="144%" xref="S9.p2.8.m5.1.1.2.cmml">ℒ</mi><mtext id="S9.p2.8.m5.1.1.3" mathsize="144%" xref="S9.p2.8.m5.1.1.3a.cmml">symm</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p2.8.m5.1b"><apply id="S9.p2.8.m5.1.1.cmml" xref="S9.p2.8.m5.1.1"><csymbol cd="ambiguous" id="S9.p2.8.m5.1.1.1.cmml" xref="S9.p2.8.m5.1.1">subscript</csymbol><ci id="S9.p2.8.m5.1.1.2.cmml" xref="S9.p2.8.m5.1.1.2">ℒ</ci><ci id="S9.p2.8.m5.1.1.3a.cmml" xref="S9.p2.8.m5.1.1.3"><mtext id="S9.p2.8.m5.1.1.3.cmml" mathsize="101%" xref="S9.p2.8.m5.1.1.3">symm</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p2.8.m5.1c">\mathcal{L}_{\text{symm}}</annotation><annotation encoding="application/x-llamapun" id="S9.p2.8.m5.1d">caligraphic_L start_POSTSUBSCRIPT symm end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p2.8.6" style="font-size:144%;"> can be defined as:</span></p>
<table class="ltx_equationgroup ltx_eqn_table" id="S9.E8">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S9.E8X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{symm}}=\sum_{b=1}^{N}\|B_{i}-B_{\text{symm}(i)%
}\|_{2}," class="ltx_Math" display="inline" id="S9.E8X.2.1.1.m1.2"><semantics id="S9.E8X.2.1.1.m1.2a"><mrow id="S9.E8X.2.1.1.m1.2.2.1" xref="S9.E8X.2.1.1.m1.2.2.1.1.cmml"><mrow id="S9.E8X.2.1.1.m1.2.2.1.1" xref="S9.E8X.2.1.1.m1.2.2.1.1.cmml"><msub id="S9.E8X.2.1.1.m1.2.2.1.1.3" xref="S9.E8X.2.1.1.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E8X.2.1.1.m1.2.2.1.1.3.2" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.3.2.cmml">ℒ</mi><mtext id="S9.E8X.2.1.1.m1.2.2.1.1.3.3" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.3.3a.cmml">symm</mtext></msub><mo id="S9.E8X.2.1.1.m1.2.2.1.1.2" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S9.E8X.2.1.1.m1.2.2.1.1.1" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.cmml"><mstyle displaystyle="true" id="S9.E8X.2.1.1.m1.2.2.1.1.1.2" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.cmml"><munderover id="S9.E8X.2.1.1.m1.2.2.1.1.1.2a" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.cmml"><mo id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.2" maxsize="144%" minsize="144%" movablelimits="false" stretchy="true" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.2.cmml">∑</mo><mrow id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.cmml"><mi id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.2" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.2.cmml">b</mi><mo id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.1" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.3" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.3" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.3.cmml">N</mi></munderover></mstyle><msub id="S9.E8X.2.1.1.m1.2.2.1.1.1.1" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.cmml"><mrow id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.2.cmml"><mo id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.2" maxsize="144%" minsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.2" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">B</mi><mi id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.3" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.2" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">B</mi><mrow id="S9.E8X.2.1.1.m1.1.1.1" xref="S9.E8X.2.1.1.m1.1.1.1.cmml"><mtext id="S9.E8X.2.1.1.m1.1.1.1.3" mathsize="144%" xref="S9.E8X.2.1.1.m1.1.1.1.3a.cmml">symm</mtext><mo id="S9.E8X.2.1.1.m1.1.1.1.2" xref="S9.E8X.2.1.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S9.E8X.2.1.1.m1.1.1.1.4.2" xref="S9.E8X.2.1.1.m1.1.1.1.cmml"><mo id="S9.E8X.2.1.1.m1.1.1.1.4.2.1" maxsize="144%" minsize="144%" xref="S9.E8X.2.1.1.m1.1.1.1.cmml">(</mo><mi id="S9.E8X.2.1.1.m1.1.1.1.1" mathsize="144%" xref="S9.E8X.2.1.1.m1.1.1.1.1.cmml">i</mi><mo id="S9.E8X.2.1.1.m1.1.1.1.4.2.2" maxsize="144%" minsize="144%" xref="S9.E8X.2.1.1.m1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow><mo id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.3" maxsize="144%" minsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.3" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow><mo id="S9.E8X.2.1.1.m1.2.2.1.2" mathsize="144%" xref="S9.E8X.2.1.1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E8X.2.1.1.m1.2b"><apply id="S9.E8X.2.1.1.m1.2.2.1.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1"><eq id="S9.E8X.2.1.1.m1.2.2.1.1.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.2"></eq><apply id="S9.E8X.2.1.1.m1.2.2.1.1.3.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S9.E8X.2.1.1.m1.2.2.1.1.3.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.3">subscript</csymbol><ci id="S9.E8X.2.1.1.m1.2.2.1.1.3.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.3.2">ℒ</ci><ci id="S9.E8X.2.1.1.m1.2.2.1.1.3.3a.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.3.3"><mtext id="S9.E8X.2.1.1.m1.2.2.1.1.3.3.cmml" mathsize="101%" xref="S9.E8X.2.1.1.m1.2.2.1.1.3.3">symm</mtext></ci></apply><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1"><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2">superscript</csymbol><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2">subscript</csymbol><sum id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.2"></sum><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3"><eq id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.1"></eq><ci id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.2">𝑏</ci><cn id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.3.cmml" type="integer" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S9.E8X.2.1.1.m1.2.2.1.1.1.2.3.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.2.3">𝑁</ci></apply><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1">subscript</csymbol><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.2">norm</csymbol><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1"><minus id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.1"></minus><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.2">𝐵</ci><ci id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.1.1.1.3.2">𝐵</ci><apply id="S9.E8X.2.1.1.m1.1.1.1.cmml" xref="S9.E8X.2.1.1.m1.1.1.1"><times id="S9.E8X.2.1.1.m1.1.1.1.2.cmml" xref="S9.E8X.2.1.1.m1.1.1.1.2"></times><ci id="S9.E8X.2.1.1.m1.1.1.1.3a.cmml" xref="S9.E8X.2.1.1.m1.1.1.1.3"><mtext id="S9.E8X.2.1.1.m1.1.1.1.3.cmml" mathsize="101%" xref="S9.E8X.2.1.1.m1.1.1.1.3">symm</mtext></ci><ci id="S9.E8X.2.1.1.m1.1.1.1.1.cmml" xref="S9.E8X.2.1.1.m1.1.1.1.1">𝑖</ci></apply></apply></apply></apply><cn id="S9.E8X.2.1.1.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="S9.E8X.2.1.1.m1.2.2.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E8X.2.1.1.m1.2c">\displaystyle\mathcal{L}_{\text{symm}}=\sum_{b=1}^{N}\|B_{i}-B_{\text{symm}(i)%
}\|_{2},</annotation><annotation encoding="application/x-llamapun" id="S9.E8X.2.1.1.m1.2d">caligraphic_L start_POSTSUBSCRIPT symm end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_b = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ∥ italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_B start_POSTSUBSCRIPT symm ( italic_i ) end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(8)</span></td>
</tr>
</tbody>
</table>
</div>
<figure class="ltx_figure" id="S9.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="196" id="S9.F9.g1" src="extracted/5734580/figs/pose_angle_bone.png" width="206"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S9.F9.7.2.1" style="font-size:63%;">Figure 9</span>: </span><span class="ltx_text" id="S9.F9.2.1" style="font-size:63%;">Definition of <math alttext="\mathcal{L}_{\text{angle}}" class="ltx_Math" display="inline" id="S9.F9.2.1.m1.1"><semantics id="S9.F9.2.1.m1.1b"><msub id="S9.F9.2.1.m1.1.1" xref="S9.F9.2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.F9.2.1.m1.1.1.2" xref="S9.F9.2.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S9.F9.2.1.m1.1.1.3" xref="S9.F9.2.1.m1.1.1.3a.cmml">angle</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.F9.2.1.m1.1c"><apply id="S9.F9.2.1.m1.1.1.cmml" xref="S9.F9.2.1.m1.1.1"><csymbol cd="ambiguous" id="S9.F9.2.1.m1.1.1.1.cmml" xref="S9.F9.2.1.m1.1.1">subscript</csymbol><ci id="S9.F9.2.1.m1.1.1.2.cmml" xref="S9.F9.2.1.m1.1.1.2">ℒ</ci><ci id="S9.F9.2.1.m1.1.1.3a.cmml" xref="S9.F9.2.1.m1.1.1.3"><mtext id="S9.F9.2.1.m1.1.1.3.cmml" mathsize="70%" xref="S9.F9.2.1.m1.1.1.3">angle</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.F9.2.1.m1.1d">\mathcal{L}_{\text{angle}}</annotation><annotation encoding="application/x-llamapun" id="S9.F9.2.1.m1.1e">caligraphic_L start_POSTSUBSCRIPT angle end_POSTSUBSCRIPT</annotation></semantics></math>.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S9.p3">
<p class="ltx_p" id="S9.p3.5"><span class="ltx_text" id="S9.p3.5.1" style="font-size:144%;">where </span><math alttext="B_{\text{symm}}" class="ltx_Math" display="inline" id="S9.p3.1.m1.1"><semantics id="S9.p3.1.m1.1a"><msub id="S9.p3.1.m1.1.1" xref="S9.p3.1.m1.1.1.cmml"><mi id="S9.p3.1.m1.1.1.2" mathsize="144%" xref="S9.p3.1.m1.1.1.2.cmml">B</mi><mtext id="S9.p3.1.m1.1.1.3" mathsize="144%" xref="S9.p3.1.m1.1.1.3a.cmml">symm</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.1.m1.1b"><apply id="S9.p3.1.m1.1.1.cmml" xref="S9.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S9.p3.1.m1.1.1.1.cmml" xref="S9.p3.1.m1.1.1">subscript</csymbol><ci id="S9.p3.1.m1.1.1.2.cmml" xref="S9.p3.1.m1.1.1.2">𝐵</ci><ci id="S9.p3.1.m1.1.1.3a.cmml" xref="S9.p3.1.m1.1.1.3"><mtext id="S9.p3.1.m1.1.1.3.cmml" mathsize="101%" xref="S9.p3.1.m1.1.1.3">symm</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.1.m1.1c">B_{\text{symm}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.1.m1.1d">italic_B start_POSTSUBSCRIPT symm end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.5.2" style="font-size:144%;"> is the symmetric bone of </span><math alttext="B_{i}" class="ltx_Math" display="inline" id="S9.p3.2.m2.1"><semantics id="S9.p3.2.m2.1a"><msub id="S9.p3.2.m2.1.1" xref="S9.p3.2.m2.1.1.cmml"><mi id="S9.p3.2.m2.1.1.2" mathsize="144%" xref="S9.p3.2.m2.1.1.2.cmml">B</mi><mi id="S9.p3.2.m2.1.1.3" mathsize="144%" xref="S9.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S9.p3.2.m2.1b"><apply id="S9.p3.2.m2.1.1.cmml" xref="S9.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S9.p3.2.m2.1.1.1.cmml" xref="S9.p3.2.m2.1.1">subscript</csymbol><ci id="S9.p3.2.m2.1.1.2.cmml" xref="S9.p3.2.m2.1.1.2">𝐵</ci><ci id="S9.p3.2.m2.1.1.3.cmml" xref="S9.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.2.m2.1c">B_{i}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.2.m2.1d">italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.5.3" style="font-size:144%;">.
As to angle loss, we limit the nose-neck-midhip angle and hip-knee-ankle angle specifically to let nose be in front of the
body and legs be bent forward. Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S9.F9" style="font-size:144%;" title="Figure 9 ‣ 9 Human Prior Loss ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">9</span></a><span class="ltx_text" id="S9.p3.5.4" style="font-size:144%;"> shows the definition of each joint and vectors.
Specially, we do not directly calculate the angle of the bones, but calculate the dot product of corresponding vectors.
First, we calculate the forward direction vector </span><math alttext="\vec{d}_{\text{forward}}" class="ltx_Math" display="inline" id="S9.p3.3.m3.1"><semantics id="S9.p3.3.m3.1a"><msub id="S9.p3.3.m3.1.1" xref="S9.p3.3.m3.1.1.cmml"><mover accent="true" id="S9.p3.3.m3.1.1.2" xref="S9.p3.3.m3.1.1.2.cmml"><mi id="S9.p3.3.m3.1.1.2.2" mathsize="144%" xref="S9.p3.3.m3.1.1.2.2.cmml">d</mi><mo id="S9.p3.3.m3.1.1.2.1" mathsize="144%" stretchy="false" xref="S9.p3.3.m3.1.1.2.1.cmml">→</mo></mover><mtext id="S9.p3.3.m3.1.1.3" mathsize="144%" xref="S9.p3.3.m3.1.1.3a.cmml">forward</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.3.m3.1b"><apply id="S9.p3.3.m3.1.1.cmml" xref="S9.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S9.p3.3.m3.1.1.1.cmml" xref="S9.p3.3.m3.1.1">subscript</csymbol><apply id="S9.p3.3.m3.1.1.2.cmml" xref="S9.p3.3.m3.1.1.2"><ci id="S9.p3.3.m3.1.1.2.1.cmml" xref="S9.p3.3.m3.1.1.2.1">→</ci><ci id="S9.p3.3.m3.1.1.2.2.cmml" xref="S9.p3.3.m3.1.1.2.2">𝑑</ci></apply><ci id="S9.p3.3.m3.1.1.3a.cmml" xref="S9.p3.3.m3.1.1.3"><mtext id="S9.p3.3.m3.1.1.3.cmml" mathsize="101%" xref="S9.p3.3.m3.1.1.3">forward</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.3.m3.1c">\vec{d}_{\text{forward}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.3.m3.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT forward end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.5.5" style="font-size:144%;"> of the body, which is the cross product of the unit vector from neck to midhip </span><math alttext="\overrightarrow{J_{\text{0}}J_{\text{2}}}" class="ltx_Math" display="inline" id="S9.p3.4.m4.1"><semantics id="S9.p3.4.m4.1a"><mover accent="true" id="S9.p3.4.m4.1.1" xref="S9.p3.4.m4.1.1.cmml"><mrow id="S9.p3.4.m4.1.1.2" xref="S9.p3.4.m4.1.1.2.cmml"><msub id="S9.p3.4.m4.1.1.2.2" xref="S9.p3.4.m4.1.1.2.2.cmml"><mi id="S9.p3.4.m4.1.1.2.2.2" mathsize="144%" xref="S9.p3.4.m4.1.1.2.2.2.cmml">J</mi><mtext id="S9.p3.4.m4.1.1.2.2.3" mathsize="144%" xref="S9.p3.4.m4.1.1.2.2.3a.cmml">0</mtext></msub><mo id="S9.p3.4.m4.1.1.2.1" xref="S9.p3.4.m4.1.1.2.1.cmml">⁢</mo><msub id="S9.p3.4.m4.1.1.2.3" xref="S9.p3.4.m4.1.1.2.3.cmml"><mi id="S9.p3.4.m4.1.1.2.3.2" mathsize="144%" xref="S9.p3.4.m4.1.1.2.3.2.cmml">J</mi><mtext id="S9.p3.4.m4.1.1.2.3.3" mathsize="144%" xref="S9.p3.4.m4.1.1.2.3.3a.cmml">2</mtext></msub></mrow><mo id="S9.p3.4.m4.1.1.1" mathsize="144%" stretchy="false" xref="S9.p3.4.m4.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S9.p3.4.m4.1b"><apply id="S9.p3.4.m4.1.1.cmml" xref="S9.p3.4.m4.1.1"><ci id="S9.p3.4.m4.1.1.1.cmml" xref="S9.p3.4.m4.1.1.1">→</ci><apply id="S9.p3.4.m4.1.1.2.cmml" xref="S9.p3.4.m4.1.1.2"><times id="S9.p3.4.m4.1.1.2.1.cmml" xref="S9.p3.4.m4.1.1.2.1"></times><apply id="S9.p3.4.m4.1.1.2.2.cmml" xref="S9.p3.4.m4.1.1.2.2"><csymbol cd="ambiguous" id="S9.p3.4.m4.1.1.2.2.1.cmml" xref="S9.p3.4.m4.1.1.2.2">subscript</csymbol><ci id="S9.p3.4.m4.1.1.2.2.2.cmml" xref="S9.p3.4.m4.1.1.2.2.2">𝐽</ci><ci id="S9.p3.4.m4.1.1.2.2.3a.cmml" xref="S9.p3.4.m4.1.1.2.2.3"><mtext id="S9.p3.4.m4.1.1.2.2.3.cmml" mathsize="101%" xref="S9.p3.4.m4.1.1.2.2.3">0</mtext></ci></apply><apply id="S9.p3.4.m4.1.1.2.3.cmml" xref="S9.p3.4.m4.1.1.2.3"><csymbol cd="ambiguous" id="S9.p3.4.m4.1.1.2.3.1.cmml" xref="S9.p3.4.m4.1.1.2.3">subscript</csymbol><ci id="S9.p3.4.m4.1.1.2.3.2.cmml" xref="S9.p3.4.m4.1.1.2.3.2">𝐽</ci><ci id="S9.p3.4.m4.1.1.2.3.3a.cmml" xref="S9.p3.4.m4.1.1.2.3.3"><mtext id="S9.p3.4.m4.1.1.2.3.3.cmml" mathsize="101%" xref="S9.p3.4.m4.1.1.2.3.3">2</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.4.m4.1c">\overrightarrow{J_{\text{0}}J_{\text{2}}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.4.m4.1d">over→ start_ARG italic_J start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG</annotation></semantics></math><span class="ltx_text" id="S9.p3.5.6" style="font-size:144%;"> and unit vector from
neck to left shoulder </span><math alttext="\overrightarrow{J_{\text{0}}J_{\text{3}}}" class="ltx_Math" display="inline" id="S9.p3.5.m5.1"><semantics id="S9.p3.5.m5.1a"><mover accent="true" id="S9.p3.5.m5.1.1" xref="S9.p3.5.m5.1.1.cmml"><mrow id="S9.p3.5.m5.1.1.2" xref="S9.p3.5.m5.1.1.2.cmml"><msub id="S9.p3.5.m5.1.1.2.2" xref="S9.p3.5.m5.1.1.2.2.cmml"><mi id="S9.p3.5.m5.1.1.2.2.2" mathsize="144%" xref="S9.p3.5.m5.1.1.2.2.2.cmml">J</mi><mtext id="S9.p3.5.m5.1.1.2.2.3" mathsize="144%" xref="S9.p3.5.m5.1.1.2.2.3a.cmml">0</mtext></msub><mo id="S9.p3.5.m5.1.1.2.1" xref="S9.p3.5.m5.1.1.2.1.cmml">⁢</mo><msub id="S9.p3.5.m5.1.1.2.3" xref="S9.p3.5.m5.1.1.2.3.cmml"><mi id="S9.p3.5.m5.1.1.2.3.2" mathsize="144%" xref="S9.p3.5.m5.1.1.2.3.2.cmml">J</mi><mtext id="S9.p3.5.m5.1.1.2.3.3" mathsize="144%" xref="S9.p3.5.m5.1.1.2.3.3a.cmml">3</mtext></msub></mrow><mo id="S9.p3.5.m5.1.1.1" mathsize="144%" stretchy="false" xref="S9.p3.5.m5.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S9.p3.5.m5.1b"><apply id="S9.p3.5.m5.1.1.cmml" xref="S9.p3.5.m5.1.1"><ci id="S9.p3.5.m5.1.1.1.cmml" xref="S9.p3.5.m5.1.1.1">→</ci><apply id="S9.p3.5.m5.1.1.2.cmml" xref="S9.p3.5.m5.1.1.2"><times id="S9.p3.5.m5.1.1.2.1.cmml" xref="S9.p3.5.m5.1.1.2.1"></times><apply id="S9.p3.5.m5.1.1.2.2.cmml" xref="S9.p3.5.m5.1.1.2.2"><csymbol cd="ambiguous" id="S9.p3.5.m5.1.1.2.2.1.cmml" xref="S9.p3.5.m5.1.1.2.2">subscript</csymbol><ci id="S9.p3.5.m5.1.1.2.2.2.cmml" xref="S9.p3.5.m5.1.1.2.2.2">𝐽</ci><ci id="S9.p3.5.m5.1.1.2.2.3a.cmml" xref="S9.p3.5.m5.1.1.2.2.3"><mtext id="S9.p3.5.m5.1.1.2.2.3.cmml" mathsize="101%" xref="S9.p3.5.m5.1.1.2.2.3">0</mtext></ci></apply><apply id="S9.p3.5.m5.1.1.2.3.cmml" xref="S9.p3.5.m5.1.1.2.3"><csymbol cd="ambiguous" id="S9.p3.5.m5.1.1.2.3.1.cmml" xref="S9.p3.5.m5.1.1.2.3">subscript</csymbol><ci id="S9.p3.5.m5.1.1.2.3.2.cmml" xref="S9.p3.5.m5.1.1.2.3.2">𝐽</ci><ci id="S9.p3.5.m5.1.1.2.3.3a.cmml" xref="S9.p3.5.m5.1.1.2.3.3"><mtext id="S9.p3.5.m5.1.1.2.3.3.cmml" mathsize="101%" xref="S9.p3.5.m5.1.1.2.3.3">3</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.5.m5.1c">\overrightarrow{J_{\text{0}}J_{\text{3}}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.5.m5.1d">over→ start_ARG italic_J start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_J start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG</annotation></semantics></math><span class="ltx_text" id="S9.p3.5.7" style="font-size:144%;">:</span></p>
<table class="ltx_equation ltx_eqn_table" id="S9.E9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\centering\vec{d}_{\text{forward}}=\overrightarrow{J_{\text{0}}J_{\text{2}}}%
\times\overrightarrow{J_{\text{0}}J_{\text{3}}},\@add@centering" class="ltx_Math" display="block" id="S9.E9.m1.1"><semantics id="S9.E9.m1.1a"><mrow id="S9.E9.m1.1.1.1" xref="S9.E9.m1.1.1.1.1.cmml"><mrow id="S9.E9.m1.1.1.1.1" xref="S9.E9.m1.1.1.1.1.cmml"><msub id="S9.E9.m1.1.1.1.1.2" xref="S9.E9.m1.1.1.1.1.2.cmml"><mover accent="true" id="S9.E9.m1.1.1.1.1.2.2" xref="S9.E9.m1.1.1.1.1.2.2.cmml"><mi id="S9.E9.m1.1.1.1.1.2.2.2" mathsize="144%" xref="S9.E9.m1.1.1.1.1.2.2.2.cmml">d</mi><mo id="S9.E9.m1.1.1.1.1.2.2.1" mathsize="144%" stretchy="false" xref="S9.E9.m1.1.1.1.1.2.2.1.cmml">→</mo></mover><mtext id="S9.E9.m1.1.1.1.1.2.3" mathsize="144%" xref="S9.E9.m1.1.1.1.1.2.3a.cmml">forward</mtext></msub><mo id="S9.E9.m1.1.1.1.1.1" mathsize="144%" xref="S9.E9.m1.1.1.1.1.1.cmml">=</mo><mrow id="S9.E9.m1.1.1.1.1.3" xref="S9.E9.m1.1.1.1.1.3.cmml"><mover accent="true" id="S9.E9.m1.1.1.1.1.3.2" xref="S9.E9.m1.1.1.1.1.3.2.cmml"><mrow id="S9.E9.m1.1.1.1.1.3.2.2" xref="S9.E9.m1.1.1.1.1.3.2.2.cmml"><msub id="S9.E9.m1.1.1.1.1.3.2.2.2" xref="S9.E9.m1.1.1.1.1.3.2.2.2.cmml"><mi id="S9.E9.m1.1.1.1.1.3.2.2.2.2" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.2.2.2.2.cmml">J</mi><mtext id="S9.E9.m1.1.1.1.1.3.2.2.2.3" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.2.2.2.3a.cmml">0</mtext></msub><mo id="S9.E9.m1.1.1.1.1.3.2.2.1" xref="S9.E9.m1.1.1.1.1.3.2.2.1.cmml">⁢</mo><msub id="S9.E9.m1.1.1.1.1.3.2.2.3" xref="S9.E9.m1.1.1.1.1.3.2.2.3.cmml"><mi id="S9.E9.m1.1.1.1.1.3.2.2.3.2" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.2.2.3.2.cmml">J</mi><mtext id="S9.E9.m1.1.1.1.1.3.2.2.3.3" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.2.2.3.3a.cmml">2</mtext></msub></mrow><mo id="S9.E9.m1.1.1.1.1.3.2.1" mathsize="144%" stretchy="false" xref="S9.E9.m1.1.1.1.1.3.2.1.cmml">→</mo></mover><mo id="S9.E9.m1.1.1.1.1.3.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="S9.E9.m1.1.1.1.1.3.1.cmml">×</mo><mover accent="true" id="S9.E9.m1.1.1.1.1.3.3" xref="S9.E9.m1.1.1.1.1.3.3.cmml"><mrow id="S9.E9.m1.1.1.1.1.3.3.2" xref="S9.E9.m1.1.1.1.1.3.3.2.cmml"><msub id="S9.E9.m1.1.1.1.1.3.3.2.2" xref="S9.E9.m1.1.1.1.1.3.3.2.2.cmml"><mi id="S9.E9.m1.1.1.1.1.3.3.2.2.2" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.3.2.2.2.cmml">J</mi><mtext id="S9.E9.m1.1.1.1.1.3.3.2.2.3" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.3.2.2.3a.cmml">0</mtext></msub><mo id="S9.E9.m1.1.1.1.1.3.3.2.1" xref="S9.E9.m1.1.1.1.1.3.3.2.1.cmml">⁢</mo><msub id="S9.E9.m1.1.1.1.1.3.3.2.3" xref="S9.E9.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S9.E9.m1.1.1.1.1.3.3.2.3.2" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.3.2.3.2.cmml">J</mi><mtext id="S9.E9.m1.1.1.1.1.3.3.2.3.3" mathsize="144%" xref="S9.E9.m1.1.1.1.1.3.3.2.3.3a.cmml">3</mtext></msub></mrow><mo id="S9.E9.m1.1.1.1.1.3.3.1" mathsize="144%" stretchy="false" xref="S9.E9.m1.1.1.1.1.3.3.1.cmml">→</mo></mover></mrow></mrow><mo id="S9.E9.m1.1.1.1.2" mathsize="144%" xref="S9.E9.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E9.m1.1b"><apply id="S9.E9.m1.1.1.1.1.cmml" xref="S9.E9.m1.1.1.1"><eq id="S9.E9.m1.1.1.1.1.1.cmml" xref="S9.E9.m1.1.1.1.1.1"></eq><apply id="S9.E9.m1.1.1.1.1.2.cmml" xref="S9.E9.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E9.m1.1.1.1.1.2.1.cmml" xref="S9.E9.m1.1.1.1.1.2">subscript</csymbol><apply id="S9.E9.m1.1.1.1.1.2.2.cmml" xref="S9.E9.m1.1.1.1.1.2.2"><ci id="S9.E9.m1.1.1.1.1.2.2.1.cmml" xref="S9.E9.m1.1.1.1.1.2.2.1">→</ci><ci id="S9.E9.m1.1.1.1.1.2.2.2.cmml" xref="S9.E9.m1.1.1.1.1.2.2.2">𝑑</ci></apply><ci id="S9.E9.m1.1.1.1.1.2.3a.cmml" xref="S9.E9.m1.1.1.1.1.2.3"><mtext id="S9.E9.m1.1.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E9.m1.1.1.1.1.2.3">forward</mtext></ci></apply><apply id="S9.E9.m1.1.1.1.1.3.cmml" xref="S9.E9.m1.1.1.1.1.3"><times id="S9.E9.m1.1.1.1.1.3.1.cmml" xref="S9.E9.m1.1.1.1.1.3.1"></times><apply id="S9.E9.m1.1.1.1.1.3.2.cmml" xref="S9.E9.m1.1.1.1.1.3.2"><ci id="S9.E9.m1.1.1.1.1.3.2.1.cmml" xref="S9.E9.m1.1.1.1.1.3.2.1">→</ci><apply id="S9.E9.m1.1.1.1.1.3.2.2.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2"><times id="S9.E9.m1.1.1.1.1.3.2.2.1.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.1"></times><apply id="S9.E9.m1.1.1.1.1.3.2.2.2.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S9.E9.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S9.E9.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.2.2">𝐽</ci><ci id="S9.E9.m1.1.1.1.1.3.2.2.2.3a.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.2.3"><mtext id="S9.E9.m1.1.1.1.1.3.2.2.2.3.cmml" mathsize="101%" xref="S9.E9.m1.1.1.1.1.3.2.2.2.3">0</mtext></ci></apply><apply id="S9.E9.m1.1.1.1.1.3.2.2.3.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S9.E9.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.3">subscript</csymbol><ci id="S9.E9.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.3.2">𝐽</ci><ci id="S9.E9.m1.1.1.1.1.3.2.2.3.3a.cmml" xref="S9.E9.m1.1.1.1.1.3.2.2.3.3"><mtext id="S9.E9.m1.1.1.1.1.3.2.2.3.3.cmml" mathsize="101%" xref="S9.E9.m1.1.1.1.1.3.2.2.3.3">2</mtext></ci></apply></apply></apply><apply id="S9.E9.m1.1.1.1.1.3.3.cmml" xref="S9.E9.m1.1.1.1.1.3.3"><ci id="S9.E9.m1.1.1.1.1.3.3.1.cmml" xref="S9.E9.m1.1.1.1.1.3.3.1">→</ci><apply id="S9.E9.m1.1.1.1.1.3.3.2.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2"><times id="S9.E9.m1.1.1.1.1.3.3.2.1.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.1"></times><apply id="S9.E9.m1.1.1.1.1.3.3.2.2.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S9.E9.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.2">subscript</csymbol><ci id="S9.E9.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.2.2">𝐽</ci><ci id="S9.E9.m1.1.1.1.1.3.3.2.2.3a.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.2.3"><mtext id="S9.E9.m1.1.1.1.1.3.3.2.2.3.cmml" mathsize="101%" xref="S9.E9.m1.1.1.1.1.3.3.2.2.3">0</mtext></ci></apply><apply id="S9.E9.m1.1.1.1.1.3.3.2.3.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S9.E9.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="S9.E9.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.3.2">𝐽</ci><ci id="S9.E9.m1.1.1.1.1.3.3.2.3.3a.cmml" xref="S9.E9.m1.1.1.1.1.3.3.2.3.3"><mtext id="S9.E9.m1.1.1.1.1.3.3.2.3.3.cmml" mathsize="101%" xref="S9.E9.m1.1.1.1.1.3.3.2.3.3">3</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E9.m1.1c">\centering\vec{d}_{\text{forward}}=\overrightarrow{J_{\text{0}}J_{\text{2}}}%
\times\overrightarrow{J_{\text{0}}J_{\text{3}}},\@add@centering</annotation><annotation encoding="application/x-llamapun" id="S9.E9.m1.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT forward end_POSTSUBSCRIPT = over→ start_ARG italic_J start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_J start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG × over→ start_ARG italic_J start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_J start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S9.p3.9"><span class="ltx_text" id="S9.p3.9.1" style="font-size:144%;">Then, as to the nose-neck-midhip angle,
we calculate the unit vector from neck to nose </span><math alttext="\overrightarrow{J_{\text{1}}J_{\text{0}}}" class="ltx_Math" display="inline" id="S9.p3.6.m1.1"><semantics id="S9.p3.6.m1.1a"><mover accent="true" id="S9.p3.6.m1.1.1" xref="S9.p3.6.m1.1.1.cmml"><mrow id="S9.p3.6.m1.1.1.2" xref="S9.p3.6.m1.1.1.2.cmml"><msub id="S9.p3.6.m1.1.1.2.2" xref="S9.p3.6.m1.1.1.2.2.cmml"><mi id="S9.p3.6.m1.1.1.2.2.2" mathsize="144%" xref="S9.p3.6.m1.1.1.2.2.2.cmml">J</mi><mtext id="S9.p3.6.m1.1.1.2.2.3" mathsize="144%" xref="S9.p3.6.m1.1.1.2.2.3a.cmml">1</mtext></msub><mo id="S9.p3.6.m1.1.1.2.1" xref="S9.p3.6.m1.1.1.2.1.cmml">⁢</mo><msub id="S9.p3.6.m1.1.1.2.3" xref="S9.p3.6.m1.1.1.2.3.cmml"><mi id="S9.p3.6.m1.1.1.2.3.2" mathsize="144%" xref="S9.p3.6.m1.1.1.2.3.2.cmml">J</mi><mtext id="S9.p3.6.m1.1.1.2.3.3" mathsize="144%" xref="S9.p3.6.m1.1.1.2.3.3a.cmml">0</mtext></msub></mrow><mo id="S9.p3.6.m1.1.1.1" mathsize="144%" stretchy="false" xref="S9.p3.6.m1.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S9.p3.6.m1.1b"><apply id="S9.p3.6.m1.1.1.cmml" xref="S9.p3.6.m1.1.1"><ci id="S9.p3.6.m1.1.1.1.cmml" xref="S9.p3.6.m1.1.1.1">→</ci><apply id="S9.p3.6.m1.1.1.2.cmml" xref="S9.p3.6.m1.1.1.2"><times id="S9.p3.6.m1.1.1.2.1.cmml" xref="S9.p3.6.m1.1.1.2.1"></times><apply id="S9.p3.6.m1.1.1.2.2.cmml" xref="S9.p3.6.m1.1.1.2.2"><csymbol cd="ambiguous" id="S9.p3.6.m1.1.1.2.2.1.cmml" xref="S9.p3.6.m1.1.1.2.2">subscript</csymbol><ci id="S9.p3.6.m1.1.1.2.2.2.cmml" xref="S9.p3.6.m1.1.1.2.2.2">𝐽</ci><ci id="S9.p3.6.m1.1.1.2.2.3a.cmml" xref="S9.p3.6.m1.1.1.2.2.3"><mtext id="S9.p3.6.m1.1.1.2.2.3.cmml" mathsize="101%" xref="S9.p3.6.m1.1.1.2.2.3">1</mtext></ci></apply><apply id="S9.p3.6.m1.1.1.2.3.cmml" xref="S9.p3.6.m1.1.1.2.3"><csymbol cd="ambiguous" id="S9.p3.6.m1.1.1.2.3.1.cmml" xref="S9.p3.6.m1.1.1.2.3">subscript</csymbol><ci id="S9.p3.6.m1.1.1.2.3.2.cmml" xref="S9.p3.6.m1.1.1.2.3.2">𝐽</ci><ci id="S9.p3.6.m1.1.1.2.3.3a.cmml" xref="S9.p3.6.m1.1.1.2.3.3"><mtext id="S9.p3.6.m1.1.1.2.3.3.cmml" mathsize="101%" xref="S9.p3.6.m1.1.1.2.3.3">0</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.6.m1.1c">\overrightarrow{J_{\text{1}}J_{\text{0}}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.6.m1.1d">over→ start_ARG italic_J start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_J start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG</annotation></semantics></math><span class="ltx_text" id="S9.p3.9.2" style="font-size:144%;"> denoted by </span><math alttext="\vec{d}_{\text{nose}}" class="ltx_Math" display="inline" id="S9.p3.7.m2.1"><semantics id="S9.p3.7.m2.1a"><msub id="S9.p3.7.m2.1.1" xref="S9.p3.7.m2.1.1.cmml"><mover accent="true" id="S9.p3.7.m2.1.1.2" xref="S9.p3.7.m2.1.1.2.cmml"><mi id="S9.p3.7.m2.1.1.2.2" mathsize="144%" xref="S9.p3.7.m2.1.1.2.2.cmml">d</mi><mo id="S9.p3.7.m2.1.1.2.1" mathsize="144%" stretchy="false" xref="S9.p3.7.m2.1.1.2.1.cmml">→</mo></mover><mtext id="S9.p3.7.m2.1.1.3" mathsize="144%" xref="S9.p3.7.m2.1.1.3a.cmml">nose</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.7.m2.1b"><apply id="S9.p3.7.m2.1.1.cmml" xref="S9.p3.7.m2.1.1"><csymbol cd="ambiguous" id="S9.p3.7.m2.1.1.1.cmml" xref="S9.p3.7.m2.1.1">subscript</csymbol><apply id="S9.p3.7.m2.1.1.2.cmml" xref="S9.p3.7.m2.1.1.2"><ci id="S9.p3.7.m2.1.1.2.1.cmml" xref="S9.p3.7.m2.1.1.2.1">→</ci><ci id="S9.p3.7.m2.1.1.2.2.cmml" xref="S9.p3.7.m2.1.1.2.2">𝑑</ci></apply><ci id="S9.p3.7.m2.1.1.3a.cmml" xref="S9.p3.7.m2.1.1.3"><mtext id="S9.p3.7.m2.1.1.3.cmml" mathsize="101%" xref="S9.p3.7.m2.1.1.3">nose</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.7.m2.1c">\vec{d}_{\text{nose}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.7.m2.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT nose end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.9.3" style="font-size:144%;">,
and we calculate the dot product of </span><math alttext="\vec{d}_{\text{nose}}" class="ltx_Math" display="inline" id="S9.p3.8.m3.1"><semantics id="S9.p3.8.m3.1a"><msub id="S9.p3.8.m3.1.1" xref="S9.p3.8.m3.1.1.cmml"><mover accent="true" id="S9.p3.8.m3.1.1.2" xref="S9.p3.8.m3.1.1.2.cmml"><mi id="S9.p3.8.m3.1.1.2.2" mathsize="144%" xref="S9.p3.8.m3.1.1.2.2.cmml">d</mi><mo id="S9.p3.8.m3.1.1.2.1" mathsize="144%" stretchy="false" xref="S9.p3.8.m3.1.1.2.1.cmml">→</mo></mover><mtext id="S9.p3.8.m3.1.1.3" mathsize="144%" xref="S9.p3.8.m3.1.1.3a.cmml">nose</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.8.m3.1b"><apply id="S9.p3.8.m3.1.1.cmml" xref="S9.p3.8.m3.1.1"><csymbol cd="ambiguous" id="S9.p3.8.m3.1.1.1.cmml" xref="S9.p3.8.m3.1.1">subscript</csymbol><apply id="S9.p3.8.m3.1.1.2.cmml" xref="S9.p3.8.m3.1.1.2"><ci id="S9.p3.8.m3.1.1.2.1.cmml" xref="S9.p3.8.m3.1.1.2.1">→</ci><ci id="S9.p3.8.m3.1.1.2.2.cmml" xref="S9.p3.8.m3.1.1.2.2">𝑑</ci></apply><ci id="S9.p3.8.m3.1.1.3a.cmml" xref="S9.p3.8.m3.1.1.3"><mtext id="S9.p3.8.m3.1.1.3.cmml" mathsize="101%" xref="S9.p3.8.m3.1.1.3">nose</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.8.m3.1c">\vec{d}_{\text{nose}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.8.m3.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT nose end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.9.4" style="font-size:144%;"> and </span><math alttext="\vec{d}_{\text{forward}}" class="ltx_Math" display="inline" id="S9.p3.9.m4.1"><semantics id="S9.p3.9.m4.1a"><msub id="S9.p3.9.m4.1.1" xref="S9.p3.9.m4.1.1.cmml"><mover accent="true" id="S9.p3.9.m4.1.1.2" xref="S9.p3.9.m4.1.1.2.cmml"><mi id="S9.p3.9.m4.1.1.2.2" mathsize="144%" xref="S9.p3.9.m4.1.1.2.2.cmml">d</mi><mo id="S9.p3.9.m4.1.1.2.1" mathsize="144%" stretchy="false" xref="S9.p3.9.m4.1.1.2.1.cmml">→</mo></mover><mtext id="S9.p3.9.m4.1.1.3" mathsize="144%" xref="S9.p3.9.m4.1.1.3a.cmml">forward</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.9.m4.1b"><apply id="S9.p3.9.m4.1.1.cmml" xref="S9.p3.9.m4.1.1"><csymbol cd="ambiguous" id="S9.p3.9.m4.1.1.1.cmml" xref="S9.p3.9.m4.1.1">subscript</csymbol><apply id="S9.p3.9.m4.1.1.2.cmml" xref="S9.p3.9.m4.1.1.2"><ci id="S9.p3.9.m4.1.1.2.1.cmml" xref="S9.p3.9.m4.1.1.2.1">→</ci><ci id="S9.p3.9.m4.1.1.2.2.cmml" xref="S9.p3.9.m4.1.1.2.2">𝑑</ci></apply><ci id="S9.p3.9.m4.1.1.3a.cmml" xref="S9.p3.9.m4.1.1.3"><mtext id="S9.p3.9.m4.1.1.3.cmml" mathsize="101%" xref="S9.p3.9.m4.1.1.3">forward</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.9.m4.1c">\vec{d}_{\text{forward}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.9.m4.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT forward end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.9.5" style="font-size:144%;"> and get the head angle loss:</span></p>
<table class="ltx_equationgroup ltx_eqn_table" id="S9.E10">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S9.E10X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{head\_ang}}=\mathcal{C}(\vec{d}_{\text{forward%
}}\cdot\vec{d}_{\text{nose}},0,1)," class="ltx_Math" display="inline" id="S9.E10X.2.1.1.m1.3"><semantics id="S9.E10X.2.1.1.m1.3a"><mrow id="S9.E10X.2.1.1.m1.3.3.1" xref="S9.E10X.2.1.1.m1.3.3.1.1.cmml"><mrow id="S9.E10X.2.1.1.m1.3.3.1.1" xref="S9.E10X.2.1.1.m1.3.3.1.1.cmml"><msub id="S9.E10X.2.1.1.m1.3.3.1.1.3" xref="S9.E10X.2.1.1.m1.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E10X.2.1.1.m1.3.3.1.1.3.2" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.3.2.cmml">ℒ</mi><mtext id="S9.E10X.2.1.1.m1.3.3.1.1.3.3" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.3.3a.cmml">head_ang</mtext></msub><mo id="S9.E10X.2.1.1.m1.3.3.1.1.2" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S9.E10X.2.1.1.m1.3.3.1.1.1" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E10X.2.1.1.m1.3.3.1.1.1.3" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.3.cmml">𝒞</mi><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.2" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.2.cmml"><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.2" maxsize="144%" minsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.2.cmml">(</mo><mrow id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.cmml"><mi id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.2" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.2.cmml">d</mi><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.1" mathsize="144%" stretchy="false" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.1.cmml">→</mo></mover><mtext id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.3" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.3a.cmml">forward</mtext></msub><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.cmml"><mi id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.2" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.2.cmml">d</mi><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.1" mathsize="144%" stretchy="false" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.1.cmml">→</mo></mover><mtext id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.3" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.3a.cmml">nose</mtext></msub></mrow><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.3" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.2.cmml">,</mo><mn id="S9.E10X.2.1.1.m1.1.1" mathsize="144%" xref="S9.E10X.2.1.1.m1.1.1.cmml">0</mn><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.4" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.2.cmml">,</mo><mn id="S9.E10X.2.1.1.m1.2.2" mathsize="144%" xref="S9.E10X.2.1.1.m1.2.2.cmml">1</mn><mo id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.5" maxsize="144%" minsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S9.E10X.2.1.1.m1.3.3.1.2" mathsize="144%" xref="S9.E10X.2.1.1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E10X.2.1.1.m1.3b"><apply id="S9.E10X.2.1.1.m1.3.3.1.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1"><eq id="S9.E10X.2.1.1.m1.3.3.1.1.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.2"></eq><apply id="S9.E10X.2.1.1.m1.3.3.1.1.3.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S9.E10X.2.1.1.m1.3.3.1.1.3.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.3">subscript</csymbol><ci id="S9.E10X.2.1.1.m1.3.3.1.1.3.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.3.2">ℒ</ci><ci id="S9.E10X.2.1.1.m1.3.3.1.1.3.3a.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.3.3"><mtext id="S9.E10X.2.1.1.m1.3.3.1.1.3.3.cmml" mathsize="101%" xref="S9.E10X.2.1.1.m1.3.3.1.1.3.3">head_ang</mtext></ci></apply><apply id="S9.E10X.2.1.1.m1.3.3.1.1.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1"><times id="S9.E10X.2.1.1.m1.3.3.1.1.1.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.2"></times><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.3.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.3">𝒞</ci><vector id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1"><apply id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1"><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.1">⋅</ci><apply id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2">subscript</csymbol><apply id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2"><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.1">→</ci><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.2.2">𝑑</ci></apply><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.3a.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.3"><mtext id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.2.3">forward</mtext></ci></apply><apply id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><apply id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2"><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.1.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.1">→</ci><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.2.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.2.2">𝑑</ci></apply><ci id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.3a.cmml" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.3"><mtext id="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.3.cmml" mathsize="101%" xref="S9.E10X.2.1.1.m1.3.3.1.1.1.1.1.1.3.3">nose</mtext></ci></apply></apply><cn id="S9.E10X.2.1.1.m1.1.1.cmml" type="integer" xref="S9.E10X.2.1.1.m1.1.1">0</cn><cn id="S9.E10X.2.1.1.m1.2.2.cmml" type="integer" xref="S9.E10X.2.1.1.m1.2.2">1</cn></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E10X.2.1.1.m1.3c">\displaystyle\mathcal{L}_{\text{head\_ang}}=\mathcal{C}(\vec{d}_{\text{forward%
}}\cdot\vec{d}_{\text{nose}},0,1),</annotation><annotation encoding="application/x-llamapun" id="S9.E10X.2.1.1.m1.3d">caligraphic_L start_POSTSUBSCRIPT head_ang end_POSTSUBSCRIPT = caligraphic_C ( over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT forward end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT nose end_POSTSUBSCRIPT , 0 , 1 ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(10)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S9.p3.16"><span class="ltx_text" id="S9.p3.16.1" style="font-size:144%;">where </span><math alttext="\mathcal{C}(\cdot)" class="ltx_Math" display="inline" id="S9.p3.10.m1.1"><semantics id="S9.p3.10.m1.1a"><mrow id="S9.p3.10.m1.1.2" xref="S9.p3.10.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.p3.10.m1.1.2.2" mathsize="144%" xref="S9.p3.10.m1.1.2.2.cmml">𝒞</mi><mo id="S9.p3.10.m1.1.2.1" xref="S9.p3.10.m1.1.2.1.cmml">⁢</mo><mrow id="S9.p3.10.m1.1.2.3.2" xref="S9.p3.10.m1.1.2.cmml"><mo id="S9.p3.10.m1.1.2.3.2.1" maxsize="144%" minsize="144%" xref="S9.p3.10.m1.1.2.cmml">(</mo><mo id="S9.p3.10.m1.1.1" lspace="0em" mathsize="144%" rspace="0em" xref="S9.p3.10.m1.1.1.cmml">⋅</mo><mo id="S9.p3.10.m1.1.2.3.2.2" maxsize="144%" minsize="144%" xref="S9.p3.10.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.p3.10.m1.1b"><apply id="S9.p3.10.m1.1.2.cmml" xref="S9.p3.10.m1.1.2"><times id="S9.p3.10.m1.1.2.1.cmml" xref="S9.p3.10.m1.1.2.1"></times><ci id="S9.p3.10.m1.1.2.2.cmml" xref="S9.p3.10.m1.1.2.2">𝒞</ci><ci id="S9.p3.10.m1.1.1.cmml" xref="S9.p3.10.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.10.m1.1c">\mathcal{C}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S9.p3.10.m1.1d">caligraphic_C ( ⋅ )</annotation></semantics></math><span class="ltx_text" id="S9.p3.16.2" style="font-size:144%;"> is the clipping function that clip the value into </span><math alttext="0" class="ltx_Math" display="inline" id="S9.p3.11.m2.1"><semantics id="S9.p3.11.m2.1a"><mn id="S9.p3.11.m2.1.1" mathsize="144%" xref="S9.p3.11.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S9.p3.11.m2.1b"><cn id="S9.p3.11.m2.1.1.cmml" type="integer" xref="S9.p3.11.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="S9.p3.16.3" style="font-size:144%;"> to </span><math alttext="1" class="ltx_Math" display="inline" id="S9.p3.12.m3.1"><semantics id="S9.p3.12.m3.1a"><mn id="S9.p3.12.m3.1.1" mathsize="144%" xref="S9.p3.12.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S9.p3.12.m3.1b"><cn id="S9.p3.12.m3.1.1.cmml" type="integer" xref="S9.p3.12.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.12.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S9.p3.12.m3.1d">1</annotation></semantics></math><span class="ltx_text" id="S9.p3.16.4" style="font-size:144%;">.
As to the hip-knee-ankle angle, we need to get the midpoint of the hip and ankle denoted by </span><math alttext="c_{\text{l}}" class="ltx_Math" display="inline" id="S9.p3.13.m4.1"><semantics id="S9.p3.13.m4.1a"><msub id="S9.p3.13.m4.1.1" xref="S9.p3.13.m4.1.1.cmml"><mi id="S9.p3.13.m4.1.1.2" mathsize="144%" xref="S9.p3.13.m4.1.1.2.cmml">c</mi><mtext id="S9.p3.13.m4.1.1.3" mathsize="144%" xref="S9.p3.13.m4.1.1.3a.cmml">l</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.13.m4.1b"><apply id="S9.p3.13.m4.1.1.cmml" xref="S9.p3.13.m4.1.1"><csymbol cd="ambiguous" id="S9.p3.13.m4.1.1.1.cmml" xref="S9.p3.13.m4.1.1">subscript</csymbol><ci id="S9.p3.13.m4.1.1.2.cmml" xref="S9.p3.13.m4.1.1.2">𝑐</ci><ci id="S9.p3.13.m4.1.1.3a.cmml" xref="S9.p3.13.m4.1.1.3"><mtext id="S9.p3.13.m4.1.1.3.cmml" mathsize="101%" xref="S9.p3.13.m4.1.1.3">l</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.13.m4.1c">c_{\text{l}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.13.m4.1d">italic_c start_POSTSUBSCRIPT l end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.16.5" style="font-size:144%;"> and
</span><math alttext="c_{\text{r}}" class="ltx_Math" display="inline" id="S9.p3.14.m5.1"><semantics id="S9.p3.14.m5.1a"><msub id="S9.p3.14.m5.1.1" xref="S9.p3.14.m5.1.1.cmml"><mi id="S9.p3.14.m5.1.1.2" mathsize="144%" xref="S9.p3.14.m5.1.1.2.cmml">c</mi><mtext id="S9.p3.14.m5.1.1.3" mathsize="144%" xref="S9.p3.14.m5.1.1.3a.cmml">r</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.14.m5.1b"><apply id="S9.p3.14.m5.1.1.cmml" xref="S9.p3.14.m5.1.1"><csymbol cd="ambiguous" id="S9.p3.14.m5.1.1.1.cmml" xref="S9.p3.14.m5.1.1">subscript</csymbol><ci id="S9.p3.14.m5.1.1.2.cmml" xref="S9.p3.14.m5.1.1.2">𝑐</ci><ci id="S9.p3.14.m5.1.1.3a.cmml" xref="S9.p3.14.m5.1.1.3"><mtext id="S9.p3.14.m5.1.1.3.cmml" mathsize="101%" xref="S9.p3.14.m5.1.1.3">r</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.14.m5.1c">c_{\text{r}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.14.m5.1d">italic_c start_POSTSUBSCRIPT r end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.16.6" style="font-size:144%;"> for left leg and right leg respectively. Then, we calculate the unit vectors from knee point to the leg’s midpoint
as </span><math alttext="\vec{d}_{\text{l\_leg}}" class="ltx_Math" display="inline" id="S9.p3.15.m6.1"><semantics id="S9.p3.15.m6.1a"><msub id="S9.p3.15.m6.1.1" xref="S9.p3.15.m6.1.1.cmml"><mover accent="true" id="S9.p3.15.m6.1.1.2" xref="S9.p3.15.m6.1.1.2.cmml"><mi id="S9.p3.15.m6.1.1.2.2" mathsize="144%" xref="S9.p3.15.m6.1.1.2.2.cmml">d</mi><mo id="S9.p3.15.m6.1.1.2.1" mathsize="144%" stretchy="false" xref="S9.p3.15.m6.1.1.2.1.cmml">→</mo></mover><mtext id="S9.p3.15.m6.1.1.3" mathsize="144%" xref="S9.p3.15.m6.1.1.3a.cmml">l_leg</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.15.m6.1b"><apply id="S9.p3.15.m6.1.1.cmml" xref="S9.p3.15.m6.1.1"><csymbol cd="ambiguous" id="S9.p3.15.m6.1.1.1.cmml" xref="S9.p3.15.m6.1.1">subscript</csymbol><apply id="S9.p3.15.m6.1.1.2.cmml" xref="S9.p3.15.m6.1.1.2"><ci id="S9.p3.15.m6.1.1.2.1.cmml" xref="S9.p3.15.m6.1.1.2.1">→</ci><ci id="S9.p3.15.m6.1.1.2.2.cmml" xref="S9.p3.15.m6.1.1.2.2">𝑑</ci></apply><ci id="S9.p3.15.m6.1.1.3a.cmml" xref="S9.p3.15.m6.1.1.3"><mtext id="S9.p3.15.m6.1.1.3.cmml" mathsize="101%" xref="S9.p3.15.m6.1.1.3">l_leg</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.15.m6.1c">\vec{d}_{\text{l\_leg}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.15.m6.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT l_leg end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.16.7" style="font-size:144%;"> and </span><math alttext="\vec{d}_{\text{r\_leg}}" class="ltx_Math" display="inline" id="S9.p3.16.m7.1"><semantics id="S9.p3.16.m7.1a"><msub id="S9.p3.16.m7.1.1" xref="S9.p3.16.m7.1.1.cmml"><mover accent="true" id="S9.p3.16.m7.1.1.2" xref="S9.p3.16.m7.1.1.2.cmml"><mi id="S9.p3.16.m7.1.1.2.2" mathsize="144%" xref="S9.p3.16.m7.1.1.2.2.cmml">d</mi><mo id="S9.p3.16.m7.1.1.2.1" mathsize="144%" stretchy="false" xref="S9.p3.16.m7.1.1.2.1.cmml">→</mo></mover><mtext id="S9.p3.16.m7.1.1.3" mathsize="144%" xref="S9.p3.16.m7.1.1.3a.cmml">r_leg</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.16.m7.1b"><apply id="S9.p3.16.m7.1.1.cmml" xref="S9.p3.16.m7.1.1"><csymbol cd="ambiguous" id="S9.p3.16.m7.1.1.1.cmml" xref="S9.p3.16.m7.1.1">subscript</csymbol><apply id="S9.p3.16.m7.1.1.2.cmml" xref="S9.p3.16.m7.1.1.2"><ci id="S9.p3.16.m7.1.1.2.1.cmml" xref="S9.p3.16.m7.1.1.2.1">→</ci><ci id="S9.p3.16.m7.1.1.2.2.cmml" xref="S9.p3.16.m7.1.1.2.2">𝑑</ci></apply><ci id="S9.p3.16.m7.1.1.3a.cmml" xref="S9.p3.16.m7.1.1.3"><mtext id="S9.p3.16.m7.1.1.3.cmml" mathsize="101%" xref="S9.p3.16.m7.1.1.3">r_leg</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.16.m7.1c">\vec{d}_{\text{r\_leg}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.16.m7.1d">over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT r_leg end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.16.8" style="font-size:144%;">. Therefore, we get the leg angle loss:</span></p>
<table class="ltx_equationgroup ltx_eqn_table" id="S9.E11">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S9.E11X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{leg\_ang}}=\mathcal{C}(\vec{d}_{\text{forward}%
}\cdot\vec{d}_{\text{l\_leg}},0,1)+\mathcal{C}(\vec{d}_{\text{forward}}\cdot%
\vec{d}_{\text{r\_leg}},0,1)," class="ltx_Math" display="inline" id="S9.E11X.2.1.1.m1.5"><semantics id="S9.E11X.2.1.1.m1.5a"><mrow id="S9.E11X.2.1.1.m1.5.5.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.cmml"><mrow id="S9.E11X.2.1.1.m1.5.5.1.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.cmml"><msub id="S9.E11X.2.1.1.m1.5.5.1.1.4" xref="S9.E11X.2.1.1.m1.5.5.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E11X.2.1.1.m1.5.5.1.1.4.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.4.2.cmml">ℒ</mi><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.4.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.4.3a.cmml">leg_ang</mtext></msub><mo id="S9.E11X.2.1.1.m1.5.5.1.1.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.3.cmml">=</mo><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.cmml"><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.1.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.3.cmml">𝒞</mi><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.2.cmml">⁢</mo><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml"><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.2" maxsize="144%" minsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml">(</mo><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.cmml"><msub id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.cmml"><mi id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.2.cmml">d</mi><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.1" mathsize="144%" stretchy="false" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.1.cmml">→</mo></mover><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.3a.cmml">forward</mtext></msub><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.cmml"><mi id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.2.cmml">d</mi><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.1" mathsize="144%" stretchy="false" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.1.cmml">→</mo></mover><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.3a.cmml">l_leg</mtext></msub></mrow><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml">,</mo><mn id="S9.E11X.2.1.1.m1.1.1" mathsize="144%" xref="S9.E11X.2.1.1.m1.1.1.cmml">0</mn><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.4" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml">,</mo><mn id="S9.E11X.2.1.1.m1.2.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.2.2.cmml">1</mn><mo id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.5" maxsize="144%" minsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.3.cmml">+</mo><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.2.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.3.cmml">𝒞</mi><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.2.cmml">⁢</mo><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.2.cmml"><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.2" maxsize="144%" minsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.2.cmml">(</mo><mrow id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.cmml"><msub id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.cmml"><mover accent="true" id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.cmml"><mi id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.2.cmml">d</mi><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.1" mathsize="144%" stretchy="false" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.1.cmml">→</mo></mover><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.3a.cmml">forward</mtext></msub><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.1" lspace="0.222em" mathsize="144%" rspace="0.222em" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.1.cmml">⋅</mo><msub id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.cmml"><mover accent="true" id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.cmml"><mi id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.2.cmml">d</mi><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.1" mathsize="144%" stretchy="false" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.1.cmml">→</mo></mover><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.3a.cmml">r_leg</mtext></msub></mrow><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.2.cmml">,</mo><mn id="S9.E11X.2.1.1.m1.3.3" mathsize="144%" xref="S9.E11X.2.1.1.m1.3.3.cmml">0</mn><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.4" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.2.cmml">,</mo><mn id="S9.E11X.2.1.1.m1.4.4" mathsize="144%" xref="S9.E11X.2.1.1.m1.4.4.cmml">1</mn><mo id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.5" maxsize="144%" minsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S9.E11X.2.1.1.m1.5.5.1.2" mathsize="144%" xref="S9.E11X.2.1.1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E11X.2.1.1.m1.5b"><apply id="S9.E11X.2.1.1.m1.5.5.1.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1"><eq id="S9.E11X.2.1.1.m1.5.5.1.1.3.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.3"></eq><apply id="S9.E11X.2.1.1.m1.5.5.1.1.4.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.4"><csymbol cd="ambiguous" id="S9.E11X.2.1.1.m1.5.5.1.1.4.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.4">subscript</csymbol><ci id="S9.E11X.2.1.1.m1.5.5.1.1.4.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.4.2">ℒ</ci><ci id="S9.E11X.2.1.1.m1.5.5.1.1.4.3a.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.4.3"><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.4.3.cmml" mathsize="101%" xref="S9.E11X.2.1.1.m1.5.5.1.1.4.3">leg_ang</mtext></ci></apply><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2"><plus id="S9.E11X.2.1.1.m1.5.5.1.1.2.3.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.3"></plus><apply id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1"><times id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.2"></times><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.3.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.3">𝒞</ci><vector id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1"><apply id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1"><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.1">⋅</ci><apply id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2"><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.1">→</ci><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.2.2">𝑑</ci></apply><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.3a.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.3"><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.2.3">forward</mtext></ci></apply><apply id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2"><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.1">→</ci><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.2.2">𝑑</ci></apply><ci id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.3a.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.3"><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.3.cmml" mathsize="101%" xref="S9.E11X.2.1.1.m1.5.5.1.1.1.1.1.1.1.3.3">l_leg</mtext></ci></apply></apply><cn id="S9.E11X.2.1.1.m1.1.1.cmml" type="integer" xref="S9.E11X.2.1.1.m1.1.1">0</cn><cn id="S9.E11X.2.1.1.m1.2.2.cmml" type="integer" xref="S9.E11X.2.1.1.m1.2.2">1</cn></vector></apply><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2"><times id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.2"></times><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.3.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.3">𝒞</ci><vector id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1"><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1"><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.1">⋅</ci><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2">subscript</csymbol><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2"><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.1">→</ci><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.2.2">𝑑</ci></apply><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.3a.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.3"><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.2.3">forward</mtext></ci></apply><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3">subscript</csymbol><apply id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2"><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.1.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.1">→</ci><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.2.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.2.2">𝑑</ci></apply><ci id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.3a.cmml" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.3"><mtext id="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.3.cmml" mathsize="101%" xref="S9.E11X.2.1.1.m1.5.5.1.1.2.2.1.1.1.3.3">r_leg</mtext></ci></apply></apply><cn id="S9.E11X.2.1.1.m1.3.3.cmml" type="integer" xref="S9.E11X.2.1.1.m1.3.3">0</cn><cn id="S9.E11X.2.1.1.m1.4.4.cmml" type="integer" xref="S9.E11X.2.1.1.m1.4.4">1</cn></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E11X.2.1.1.m1.5c">\displaystyle\mathcal{L}_{\text{leg\_ang}}=\mathcal{C}(\vec{d}_{\text{forward}%
}\cdot\vec{d}_{\text{l\_leg}},0,1)+\mathcal{C}(\vec{d}_{\text{forward}}\cdot%
\vec{d}_{\text{r\_leg}},0,1),</annotation><annotation encoding="application/x-llamapun" id="S9.E11X.2.1.1.m1.5d">caligraphic_L start_POSTSUBSCRIPT leg_ang end_POSTSUBSCRIPT = caligraphic_C ( over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT forward end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT l_leg end_POSTSUBSCRIPT , 0 , 1 ) + caligraphic_C ( over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT forward end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_d end_ARG start_POSTSUBSCRIPT r_leg end_POSTSUBSCRIPT , 0 , 1 ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(11)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S9.p3.19"><span class="ltx_text" id="S9.p3.19.1" style="font-size:144%;">where </span><math alttext="\mathcal{C}(\cdot)" class="ltx_Math" display="inline" id="S9.p3.17.m1.1"><semantics id="S9.p3.17.m1.1a"><mrow id="S9.p3.17.m1.1.2" xref="S9.p3.17.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.p3.17.m1.1.2.2" mathsize="144%" xref="S9.p3.17.m1.1.2.2.cmml">𝒞</mi><mo id="S9.p3.17.m1.1.2.1" xref="S9.p3.17.m1.1.2.1.cmml">⁢</mo><mrow id="S9.p3.17.m1.1.2.3.2" xref="S9.p3.17.m1.1.2.cmml"><mo id="S9.p3.17.m1.1.2.3.2.1" maxsize="144%" minsize="144%" xref="S9.p3.17.m1.1.2.cmml">(</mo><mo id="S9.p3.17.m1.1.1" lspace="0em" mathsize="144%" rspace="0em" xref="S9.p3.17.m1.1.1.cmml">⋅</mo><mo id="S9.p3.17.m1.1.2.3.2.2" maxsize="144%" minsize="144%" xref="S9.p3.17.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S9.p3.17.m1.1b"><apply id="S9.p3.17.m1.1.2.cmml" xref="S9.p3.17.m1.1.2"><times id="S9.p3.17.m1.1.2.1.cmml" xref="S9.p3.17.m1.1.2.1"></times><ci id="S9.p3.17.m1.1.2.2.cmml" xref="S9.p3.17.m1.1.2.2">𝒞</ci><ci id="S9.p3.17.m1.1.1.cmml" xref="S9.p3.17.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.17.m1.1c">\mathcal{C}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S9.p3.17.m1.1d">caligraphic_C ( ⋅ )</annotation></semantics></math><span class="ltx_text" id="S9.p3.19.2" style="font-size:144%;"> is the clipping function that clip the value into </span><math alttext="0" class="ltx_Math" display="inline" id="S9.p3.18.m2.1"><semantics id="S9.p3.18.m2.1a"><mn id="S9.p3.18.m2.1.1" mathsize="144%" xref="S9.p3.18.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S9.p3.18.m2.1b"><cn id="S9.p3.18.m2.1.1.cmml" type="integer" xref="S9.p3.18.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="S9.p3.19.3" style="font-size:144%;"> to </span><math alttext="1" class="ltx_Math" display="inline" id="S9.p3.19.m3.1"><semantics id="S9.p3.19.m3.1a"><mn id="S9.p3.19.m3.1.1" mathsize="144%" xref="S9.p3.19.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S9.p3.19.m3.1b"><cn id="S9.p3.19.m3.1.1.cmml" type="integer" xref="S9.p3.19.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.19.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S9.p3.19.m3.1d">1</annotation></semantics></math><span class="ltx_text" id="S9.p3.19.4" style="font-size:144%;">.
Therefore, we can calculate the angle loss:</span></p>
<table class="ltx_equationgroup ltx_eqn_table" id="S9.E12">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S9.E12X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{angle}}=\mathcal{L}_{\text{head\_ang}}+%
\mathcal{L}_{\text{leg\_ang}}," class="ltx_Math" display="inline" id="S9.E12X.2.1.1.m1.1"><semantics id="S9.E12X.2.1.1.m1.1a"><mrow id="S9.E12X.2.1.1.m1.1.1.1" xref="S9.E12X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S9.E12X.2.1.1.m1.1.1.1.1" xref="S9.E12X.2.1.1.m1.1.1.1.1.cmml"><msub id="S9.E12X.2.1.1.m1.1.1.1.1.2" xref="S9.E12X.2.1.1.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E12X.2.1.1.m1.1.1.1.1.2.2" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.2.2.cmml">ℒ</mi><mtext id="S9.E12X.2.1.1.m1.1.1.1.1.2.3" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.2.3a.cmml">angle</mtext></msub><mo id="S9.E12X.2.1.1.m1.1.1.1.1.1" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S9.E12X.2.1.1.m1.1.1.1.1.3" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.cmml"><msub id="S9.E12X.2.1.1.m1.1.1.1.1.3.2" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.2" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2.2.cmml">ℒ</mi><mtext id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.3" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2.3a.cmml">head_ang</mtext></msub><mo id="S9.E12X.2.1.1.m1.1.1.1.1.3.1" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S9.E12X.2.1.1.m1.1.1.1.1.3.3" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.2" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3.2.cmml">ℒ</mi><mtext id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.3" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3.3a.cmml">leg_ang</mtext></msub></mrow></mrow><mo id="S9.E12X.2.1.1.m1.1.1.1.2" mathsize="144%" xref="S9.E12X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E12X.2.1.1.m1.1b"><apply id="S9.E12X.2.1.1.m1.1.1.1.1.cmml" xref="S9.E12X.2.1.1.m1.1.1.1"><eq id="S9.E12X.2.1.1.m1.1.1.1.1.1.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.1"></eq><apply id="S9.E12X.2.1.1.m1.1.1.1.1.2.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E12X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S9.E12X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.2.2">ℒ</ci><ci id="S9.E12X.2.1.1.m1.1.1.1.1.2.3a.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.2.3"><mtext id="S9.E12X.2.1.1.m1.1.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E12X.2.1.1.m1.1.1.1.1.2.3">angle</mtext></ci></apply><apply id="S9.E12X.2.1.1.m1.1.1.1.1.3.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3"><plus id="S9.E12X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.1"></plus><apply id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.1.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.2.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2.2">ℒ</ci><ci id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.3a.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2.3"><mtext id="S9.E12X.2.1.1.m1.1.1.1.1.3.2.3.cmml" mathsize="101%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.2.3">head_ang</mtext></ci></apply><apply id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.1.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.2.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3.2">ℒ</ci><ci id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.3a.cmml" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3.3"><mtext id="S9.E12X.2.1.1.m1.1.1.1.1.3.3.3.cmml" mathsize="101%" xref="S9.E12X.2.1.1.m1.1.1.1.1.3.3.3">leg_ang</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E12X.2.1.1.m1.1c">\displaystyle\mathcal{L}_{\text{angle}}=\mathcal{L}_{\text{head\_ang}}+%
\mathcal{L}_{\text{leg\_ang}},</annotation><annotation encoding="application/x-llamapun" id="S9.E12X.2.1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT angle end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT head_ang end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT leg_ang end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(12)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S9.p3.24"><span class="ltx_text" id="S9.p3.24.1" style="font-size:144%;">Finally, we combine the three losses together as the human prior loss:</span></p>
<table class="ltx_equationgroup ltx_eqn_table" id="S9.E13">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S9.E13X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{prior}}=\gamma_{\text{1}}\mathcal{L}_{\text{%
length}}+\gamma_{\text{2}}\mathcal{L}_{\text{symm}}+\gamma_{\text{3}}\mathcal{%
L}_{\text{angle}}," class="ltx_Math" display="inline" id="S9.E13X.2.1.1.m1.1"><semantics id="S9.E13X.2.1.1.m1.1a"><mrow id="S9.E13X.2.1.1.m1.1.1.1" xref="S9.E13X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S9.E13X.2.1.1.m1.1.1.1.1" xref="S9.E13X.2.1.1.m1.1.1.1.1.cmml"><msub id="S9.E13X.2.1.1.m1.1.1.1.1.2" xref="S9.E13X.2.1.1.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E13X.2.1.1.m1.1.1.1.1.2.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.2.2.cmml">ℒ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.2.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.2.3a.cmml">prior</mtext></msub><mo id="S9.E13X.2.1.1.m1.1.1.1.1.1" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S9.E13X.2.1.1.m1.1.1.1.1.3" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.cmml"><mrow id="S9.E13X.2.1.1.m1.1.1.1.1.3.2" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.cmml"><msub id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.cmml"><mi id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.2.cmml">γ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.3a.cmml">1</mtext></msub><mo id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.1" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.1.cmml">⁢</mo><msub id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.2.cmml">ℒ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.3a.cmml">length</mtext></msub></mrow><mo id="S9.E13X.2.1.1.m1.1.1.1.1.3.1" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S9.E13X.2.1.1.m1.1.1.1.1.3.3" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.cmml"><msub id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.cmml"><mi id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.2.cmml">γ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.3a.cmml">2</mtext></msub><mo id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.1" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.1.cmml">⁢</mo><msub id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.3a.cmml">symm</mtext></msub></mrow><mo id="S9.E13X.2.1.1.m1.1.1.1.1.3.1a" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S9.E13X.2.1.1.m1.1.1.1.1.3.4" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.cmml"><msub id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.cmml"><mi id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.2.cmml">γ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.3a.cmml">3</mtext></msub><mo id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.1" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.1.cmml">⁢</mo><msub id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.2.cmml">ℒ</mi><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.3" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.3a.cmml">angle</mtext></msub></mrow></mrow></mrow><mo id="S9.E13X.2.1.1.m1.1.1.1.2" mathsize="144%" xref="S9.E13X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S9.E13X.2.1.1.m1.1b"><apply id="S9.E13X.2.1.1.m1.1.1.1.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1"><eq id="S9.E13X.2.1.1.m1.1.1.1.1.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.1"></eq><apply id="S9.E13X.2.1.1.m1.1.1.1.1.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.2.2">ℒ</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.2.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.2.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.2.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.2.3">prior</mtext></ci></apply><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3"><plus id="S9.E13X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.1"></plus><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2"><times id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.1"></times><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.2">𝛾</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.2.3">1</mtext></ci></apply><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.2">ℒ</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.2.3.3">length</mtext></ci></apply></apply><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3"><times id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.1"></times><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.2">𝛾</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.2.3">2</mtext></ci></apply><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.2">ℒ</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.3.3.3">symm</mtext></ci></apply></apply><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4"><times id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.1"></times><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.2">𝛾</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.2.3">3</mtext></ci></apply><apply id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.1.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3">subscript</csymbol><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.2.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.2">ℒ</ci><ci id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.3a.cmml" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.3"><mtext id="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.3.cmml" mathsize="101%" xref="S9.E13X.2.1.1.m1.1.1.1.1.3.4.3.3">angle</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.E13X.2.1.1.m1.1c">\displaystyle\mathcal{L}_{\text{prior}}=\gamma_{\text{1}}\mathcal{L}_{\text{%
length}}+\gamma_{\text{2}}\mathcal{L}_{\text{symm}}+\gamma_{\text{3}}\mathcal{%
L}_{\text{angle}},</annotation><annotation encoding="application/x-llamapun" id="S9.E13X.2.1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT prior end_POSTSUBSCRIPT = italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT length end_POSTSUBSCRIPT + italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT symm end_POSTSUBSCRIPT + italic_γ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT angle end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(13)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S9.p3.23"><span class="ltx_text" id="S9.p3.23.1" style="font-size:144%;">where </span><math alttext="\gamma_{\text{1}}" class="ltx_Math" display="inline" id="S9.p3.20.m1.1"><semantics id="S9.p3.20.m1.1a"><msub id="S9.p3.20.m1.1.1" xref="S9.p3.20.m1.1.1.cmml"><mi id="S9.p3.20.m1.1.1.2" mathsize="144%" xref="S9.p3.20.m1.1.1.2.cmml">γ</mi><mtext id="S9.p3.20.m1.1.1.3" mathsize="144%" xref="S9.p3.20.m1.1.1.3a.cmml">1</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.20.m1.1b"><apply id="S9.p3.20.m1.1.1.cmml" xref="S9.p3.20.m1.1.1"><csymbol cd="ambiguous" id="S9.p3.20.m1.1.1.1.cmml" xref="S9.p3.20.m1.1.1">subscript</csymbol><ci id="S9.p3.20.m1.1.1.2.cmml" xref="S9.p3.20.m1.1.1.2">𝛾</ci><ci id="S9.p3.20.m1.1.1.3a.cmml" xref="S9.p3.20.m1.1.1.3"><mtext id="S9.p3.20.m1.1.1.3.cmml" mathsize="101%" xref="S9.p3.20.m1.1.1.3">1</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.20.m1.1c">\gamma_{\text{1}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.20.m1.1d">italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.23.2" style="font-size:144%;">, </span><math alttext="\gamma_{\text{2}}" class="ltx_Math" display="inline" id="S9.p3.21.m2.1"><semantics id="S9.p3.21.m2.1a"><msub id="S9.p3.21.m2.1.1" xref="S9.p3.21.m2.1.1.cmml"><mi id="S9.p3.21.m2.1.1.2" mathsize="144%" xref="S9.p3.21.m2.1.1.2.cmml">γ</mi><mtext id="S9.p3.21.m2.1.1.3" mathsize="144%" xref="S9.p3.21.m2.1.1.3a.cmml">2</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.21.m2.1b"><apply id="S9.p3.21.m2.1.1.cmml" xref="S9.p3.21.m2.1.1"><csymbol cd="ambiguous" id="S9.p3.21.m2.1.1.1.cmml" xref="S9.p3.21.m2.1.1">subscript</csymbol><ci id="S9.p3.21.m2.1.1.2.cmml" xref="S9.p3.21.m2.1.1.2">𝛾</ci><ci id="S9.p3.21.m2.1.1.3a.cmml" xref="S9.p3.21.m2.1.1.3"><mtext id="S9.p3.21.m2.1.1.3.cmml" mathsize="101%" xref="S9.p3.21.m2.1.1.3">2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.21.m2.1c">\gamma_{\text{2}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.21.m2.1d">italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.23.3" style="font-size:144%;"> and </span><math alttext="\gamma_{\text{3}}" class="ltx_Math" display="inline" id="S9.p3.22.m3.1"><semantics id="S9.p3.22.m3.1a"><msub id="S9.p3.22.m3.1.1" xref="S9.p3.22.m3.1.1.cmml"><mi id="S9.p3.22.m3.1.1.2" mathsize="144%" xref="S9.p3.22.m3.1.1.2.cmml">γ</mi><mtext id="S9.p3.22.m3.1.1.3" mathsize="144%" xref="S9.p3.22.m3.1.1.3a.cmml">3</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.p3.22.m3.1b"><apply id="S9.p3.22.m3.1.1.cmml" xref="S9.p3.22.m3.1.1"><csymbol cd="ambiguous" id="S9.p3.22.m3.1.1.1.cmml" xref="S9.p3.22.m3.1.1">subscript</csymbol><ci id="S9.p3.22.m3.1.1.2.cmml" xref="S9.p3.22.m3.1.1.2">𝛾</ci><ci id="S9.p3.22.m3.1.1.3a.cmml" xref="S9.p3.22.m3.1.1.3"><mtext id="S9.p3.22.m3.1.1.3.cmml" mathsize="101%" xref="S9.p3.22.m3.1.1.3">3</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.22.m3.1c">\gamma_{\text{3}}</annotation><annotation encoding="application/x-llamapun" id="S9.p3.22.m3.1d">italic_γ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S9.p3.23.4" style="font-size:144%;"> are the weights of each loss. In our case, we set
all the weights as </span><math alttext="1" class="ltx_Math" display="inline" id="S9.p3.23.m4.1"><semantics id="S9.p3.23.m4.1a"><mn id="S9.p3.23.m4.1.1" mathsize="144%" xref="S9.p3.23.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S9.p3.23.m4.1b"><cn id="S9.p3.23.m4.1.1.cmml" type="integer" xref="S9.p3.23.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S9.p3.23.m4.1c">1</annotation><annotation encoding="application/x-llamapun" id="S9.p3.23.m4.1d">1</annotation></semantics></math><span class="ltx_text" id="S9.p3.23.5" style="font-size:144%;">.</span></p>
</div>
<figure class="ltx_table" id="S9.T6">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S9.T6.11.2.1" style="font-size:63%;">Table 6</span>: </span><span class="ltx_text" id="S9.T6.2.1" style="font-size:63%;">Human detection results on different datasets. “<math alttext="\#" class="ltx_Math" display="inline" id="S9.T6.2.1.m1.1"><semantics id="S9.T6.2.1.m1.1b"><mi id="S9.T6.2.1.m1.1.1" mathvariant="normal" xref="S9.T6.2.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S9.T6.2.1.m1.1c"><ci id="S9.T6.2.1.m1.1.1.cmml" xref="S9.T6.2.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T6.2.1.m1.1d">\#</annotation><annotation encoding="application/x-llamapun" id="S9.T6.2.1.m1.1e">#</annotation></semantics></math>” means using synthetic datasets (BaseketBallSync and PanopticSync) to pretrain and
directly evaluate on corresponding real-world datasets.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S9.T6.6">
<tr class="ltx_tr" id="S9.T6.6.5">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S9.T6.6.5.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S9.T6.6.5.1.1" style="font-size:144%;">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S9.T6.6.5.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S9.T6.6.5.2.1" style="font-size:144%;">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S9.T6.6.5.3"><span class="ltx_text ltx_font_bold" id="S9.T6.6.5.3.1" style="font-size:144%;">Metric</span></td>
</tr>
<tr class="ltx_tr" id="S9.T6.4.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.3.1.1"><math alttext="\text{AP}_{\text{50}}" class="ltx_Math" display="inline" id="S9.T6.3.1.1.m1.1"><semantics id="S9.T6.3.1.1.m1.1a"><msub id="S9.T6.3.1.1.m1.1.1" xref="S9.T6.3.1.1.m1.1.1.cmml"><mtext id="S9.T6.3.1.1.m1.1.1.2" mathsize="144%" xref="S9.T6.3.1.1.m1.1.1.2a.cmml">AP</mtext><mtext id="S9.T6.3.1.1.m1.1.1.3" mathsize="144%" xref="S9.T6.3.1.1.m1.1.1.3a.cmml">50</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.T6.3.1.1.m1.1b"><apply id="S9.T6.3.1.1.m1.1.1.cmml" xref="S9.T6.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S9.T6.3.1.1.m1.1.1.1.cmml" xref="S9.T6.3.1.1.m1.1.1">subscript</csymbol><ci id="S9.T6.3.1.1.m1.1.1.2a.cmml" xref="S9.T6.3.1.1.m1.1.1.2"><mtext id="S9.T6.3.1.1.m1.1.1.2.cmml" mathsize="144%" xref="S9.T6.3.1.1.m1.1.1.2">AP</mtext></ci><ci id="S9.T6.3.1.1.m1.1.1.3a.cmml" xref="S9.T6.3.1.1.m1.1.1.3"><mtext id="S9.T6.3.1.1.m1.1.1.3.cmml" mathsize="101%" xref="S9.T6.3.1.1.m1.1.1.3">50</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T6.3.1.1.m1.1c">\text{AP}_{\text{50}}</annotation><annotation encoding="application/x-llamapun" id="S9.T6.3.1.1.m1.1d">AP start_POSTSUBSCRIPT 50 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.4.2.2"><math alttext="\text{AP}_{\text{70}}" class="ltx_Math" display="inline" id="S9.T6.4.2.2.m1.1"><semantics id="S9.T6.4.2.2.m1.1a"><msub id="S9.T6.4.2.2.m1.1.1" xref="S9.T6.4.2.2.m1.1.1.cmml"><mtext id="S9.T6.4.2.2.m1.1.1.2" mathsize="144%" xref="S9.T6.4.2.2.m1.1.1.2a.cmml">AP</mtext><mtext id="S9.T6.4.2.2.m1.1.1.3" mathsize="144%" xref="S9.T6.4.2.2.m1.1.1.3a.cmml">70</mtext></msub><annotation-xml encoding="MathML-Content" id="S9.T6.4.2.2.m1.1b"><apply id="S9.T6.4.2.2.m1.1.1.cmml" xref="S9.T6.4.2.2.m1.1.1"><csymbol cd="ambiguous" id="S9.T6.4.2.2.m1.1.1.1.cmml" xref="S9.T6.4.2.2.m1.1.1">subscript</csymbol><ci id="S9.T6.4.2.2.m1.1.1.2a.cmml" xref="S9.T6.4.2.2.m1.1.1.2"><mtext id="S9.T6.4.2.2.m1.1.1.2.cmml" mathsize="144%" xref="S9.T6.4.2.2.m1.1.1.2">AP</mtext></ci><ci id="S9.T6.4.2.2.m1.1.1.3a.cmml" xref="S9.T6.4.2.2.m1.1.1.3"><mtext id="S9.T6.4.2.2.m1.1.1.3.cmml" mathsize="101%" xref="S9.T6.4.2.2.m1.1.1.3">70</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S9.T6.4.2.2.m1.1c">\text{AP}_{\text{70}}</annotation><annotation encoding="application/x-llamapun" id="S9.T6.4.2.2.m1.1d">AP start_POSTSUBSCRIPT 70 end_POSTSUBSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S9.T6.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.6.1" rowspan="3"><span class="ltx_text" id="S9.T6.6.6.1.1" style="font-size:144%;">BasketBall</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.6.2"><span class="ltx_text" id="S9.T6.6.6.2.1" style="font-size:144%;">MVDet</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.6.3"><span class="ltx_text" id="S9.T6.6.6.3.1" style="font-size:144%;">69.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.6.4"><span class="ltx_text" id="S9.T6.6.6.4.1" style="font-size:144%;">37.66</span></td>
</tr>
<tr class="ltx_tr" id="S9.T6.5.3">
<td class="ltx_td ltx_align_center" id="S9.T6.5.3.1">
<span class="ltx_text" id="S9.T6.5.3.1.1" style="font-size:144%;">PointPillars</span><math alttext="\#" class="ltx_Math" display="inline" id="S9.T6.5.3.1.m1.1"><semantics id="S9.T6.5.3.1.m1.1a"><mi id="S9.T6.5.3.1.m1.1.1" mathsize="144%" mathvariant="normal" xref="S9.T6.5.3.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S9.T6.5.3.1.m1.1b"><ci id="S9.T6.5.3.1.m1.1.1.cmml" xref="S9.T6.5.3.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T6.5.3.1.m1.1c">\#</annotation><annotation encoding="application/x-llamapun" id="S9.T6.5.3.1.m1.1d">#</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S9.T6.5.3.2"><span class="ltx_text" id="S9.T6.5.3.2.1" style="font-size:144%;">88.17</span></td>
<td class="ltx_td ltx_align_center" id="S9.T6.5.3.3"><span class="ltx_text" id="S9.T6.5.3.3.1" style="font-size:144%;">44.26</span></td>
</tr>
<tr class="ltx_tr" id="S9.T6.6.7">
<td class="ltx_td ltx_align_center" id="S9.T6.6.7.1"><span class="ltx_text" id="S9.T6.6.7.1.1" style="font-size:144%;">PointPillars</span></td>
<td class="ltx_td ltx_align_center" id="S9.T6.6.7.2"><span class="ltx_text ltx_font_bold" id="S9.T6.6.7.2.1" style="font-size:144%;">89.77</span></td>
<td class="ltx_td ltx_align_center" id="S9.T6.6.7.3"><span class="ltx_text ltx_font_bold" id="S9.T6.6.7.3.1" style="font-size:144%;">69.96</span></td>
</tr>
<tr class="ltx_tr" id="S9.T6.6.8">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S9.T6.6.8.1" rowspan="3"><span class="ltx_text" id="S9.T6.6.8.1.1" style="font-size:144%;">Panoptic</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.8.2"><span class="ltx_text" id="S9.T6.6.8.2.1" style="font-size:144%;">VoxelPose</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.8.3"><span class="ltx_text" id="S9.T6.6.8.3.1" style="font-size:144%;">21.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S9.T6.6.8.4"><span class="ltx_text" id="S9.T6.6.8.4.1" style="font-size:144%;">0.19</span></td>
</tr>
<tr class="ltx_tr" id="S9.T6.6.4">
<td class="ltx_td ltx_align_center" id="S9.T6.6.4.1">
<span class="ltx_text" id="S9.T6.6.4.1.1" style="font-size:144%;">PointPillars</span><math alttext="\#" class="ltx_Math" display="inline" id="S9.T6.6.4.1.m1.1"><semantics id="S9.T6.6.4.1.m1.1a"><mi id="S9.T6.6.4.1.m1.1.1" mathsize="144%" mathvariant="normal" xref="S9.T6.6.4.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S9.T6.6.4.1.m1.1b"><ci id="S9.T6.6.4.1.m1.1.1.cmml" xref="S9.T6.6.4.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.T6.6.4.1.m1.1c">\#</annotation><annotation encoding="application/x-llamapun" id="S9.T6.6.4.1.m1.1d">#</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S9.T6.6.4.2"><span class="ltx_text" id="S9.T6.6.4.2.1" style="font-size:144%;">40.17</span></td>
<td class="ltx_td ltx_align_center" id="S9.T6.6.4.3"><span class="ltx_text" id="S9.T6.6.4.3.1" style="font-size:144%;">6.25</span></td>
</tr>
<tr class="ltx_tr" id="S9.T6.6.9">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S9.T6.6.9.1"><span class="ltx_text" id="S9.T6.6.9.1.1" style="font-size:144%;">PointPillars</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S9.T6.6.9.2"><span class="ltx_text ltx_font_bold" id="S9.T6.6.9.2.1" style="font-size:144%;">73.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S9.T6.6.9.3"><span class="ltx_text ltx_font_bold" id="S9.T6.6.9.3.1" style="font-size:144%;">13.97</span></td>
</tr>
</table>
</figure>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">10 </span>Extended Experiments</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1"><span class="ltx_text" id="S10.p1.1.1" style="font-size:144%;">In this section, we conduct experiments to verify the advantages of using point cloud input for pedestrian detection. Additionally, we present more examples to explain the relationship between entropy value and pose rationality.</span></p>
</div>
<figure class="ltx_figure" id="S10.F10"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="421" id="S10.F10.g1" src="extracted/5734580/figs/entropy2.png" width="274"/>
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S10.F10.7.2.1" style="font-size:63%;">Figure 10</span>: </span><span class="ltx_text" id="S10.F10.2.1" style="font-size:63%;">The entropy value and the specific poses. <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="8" id="S10.F10.2.1.g1" src="extracted/5734580/figs/force.png" width="27"/> represents an increasing entropy value from left to right among row’s samples.
The size of joints’ ball represents the magnitude of the joint’s entropy value.</span></figcaption>
</figure>
<section class="ltx_subsection" id="S10.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">10.1 </span>Human Detection</h3>
<div class="ltx_para" id="S10.SS1.p1">
<p class="ltx_p" id="S10.SS1.p1.2"><span class="ltx_text" id="S10.SS1.p1.2.1" style="font-size:144%;">For evaluating human detection, we assess performance using the established average precision (AP) metric as described in KITTI </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S10.SS1.p1.2.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib13" title="">13</a><span class="ltx_text" id="S10.SS1.p1.2.3.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="S10.SS1.p1.2.4" style="font-size:144%;">. We consider detections as true positives if they overlap by more than 70% (AP</span><sub class="ltx_sub" id="S10.SS1.p1.2.5"><span class="ltx_text ltx_font_italic" id="S10.SS1.p1.2.5.1" style="font-size:144%;">70</span></sub><span class="ltx_text" id="S10.SS1.p1.2.6" style="font-size:144%;">) or 50% (AP</span><sub class="ltx_sub" id="S10.SS1.p1.2.7"><span class="ltx_text ltx_font_italic" id="S10.SS1.p1.2.7.1" style="font-size:144%;">50</span></sub><span class="ltx_text" id="S10.SS1.p1.2.8" style="font-size:144%;">).</span></p>
</div>
<div class="ltx_para" id="S10.SS1.p2">
<p class="ltx_p" id="S10.SS1.p2.6"><span class="ltx_text" id="S10.SS1.p2.6.1" style="font-size:144%;">In our current experiment, we adopt PointPillars </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S10.SS1.p2.6.2.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib29" title="">29</a><span class="ltx_text" id="S10.SS1.p2.6.3.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="S10.SS1.p2.6.4" style="font-size:144%;"> to detect human bounding boxes. For comparison with multi-view RGB-based methods, we utilize VoxelPose’s CPN </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S10.SS1.p2.6.5.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a><span class="ltx_text" id="S10.SS1.p2.6.6.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="S10.SS1.p2.6.7" style="font-size:144%;"> and MVDet </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S10.SS1.p2.6.8.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib20" title="">20</a><span class="ltx_text" id="S10.SS1.p2.6.9.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="S10.SS1.p2.6.10" style="font-size:144%;">, which is more suitable for large scene applications. In the CMU Panoptic Studio setup, VoxelPose </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S10.SS1.p2.6.11.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a><span class="ltx_text" id="S10.SS1.p2.6.12.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="S10.SS1.p2.6.13" style="font-size:144%;"> achieves relatively accurate center localization. However, it sets the bounding box size to a constant value (we use 0.8m </span><math alttext="\times" class="ltx_Math" display="inline" id="S10.SS1.p2.1.m1.1"><semantics id="S10.SS1.p2.1.m1.1a"><mo id="S10.SS1.p2.1.m1.1.1" mathsize="144%" xref="S10.SS1.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S10.SS1.p2.1.m1.1b"><times id="S10.SS1.p2.1.m1.1.1.cmml" xref="S10.SS1.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S10.SS1.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S10.SS1.p2.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S10.SS1.p2.6.14" style="font-size:144%;"> 0.8m </span><math alttext="\times" class="ltx_Math" display="inline" id="S10.SS1.p2.2.m2.1"><semantics id="S10.SS1.p2.2.m2.1a"><mo id="S10.SS1.p2.2.m2.1.1" mathsize="144%" xref="S10.SS1.p2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S10.SS1.p2.2.m2.1b"><times id="S10.SS1.p2.2.m2.1.1.cmml" xref="S10.SS1.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S10.SS1.p2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S10.SS1.p2.2.m2.1d">×</annotation></semantics></math><span class="ltx_text" id="S10.SS1.p2.6.15" style="font-size:144%;"> 1.9m for tighter results, compared to 2m </span><math alttext="\times" class="ltx_Math" display="inline" id="S10.SS1.p2.3.m3.1"><semantics id="S10.SS1.p2.3.m3.1a"><mo id="S10.SS1.p2.3.m3.1.1" mathsize="144%" xref="S10.SS1.p2.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S10.SS1.p2.3.m3.1b"><times id="S10.SS1.p2.3.m3.1.1.cmml" xref="S10.SS1.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S10.SS1.p2.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S10.SS1.p2.3.m3.1d">×</annotation></semantics></math><span class="ltx_text" id="S10.SS1.p2.6.16" style="font-size:144%;"> 2m </span><math alttext="\times" class="ltx_Math" display="inline" id="S10.SS1.p2.4.m4.1"><semantics id="S10.SS1.p2.4.m4.1a"><mo id="S10.SS1.p2.4.m4.1.1" mathsize="144%" xref="S10.SS1.p2.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S10.SS1.p2.4.m4.1b"><times id="S10.SS1.p2.4.m4.1.1.cmml" xref="S10.SS1.p2.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S10.SS1.p2.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S10.SS1.p2.4.m4.1d">×</annotation></semantics></math><span class="ltx_text" id="S10.SS1.p2.6.17" style="font-size:144%;"> 2m in </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S10.SS1.p2.6.18.1" style="font-size:144%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#bib.bib47" title="">47</a><span class="ltx_text" id="S10.SS1.p2.6.19.2" style="font-size:144%;">]</span></cite><span class="ltx_text" id="S10.SS1.p2.6.20" style="font-size:144%;">), which affects detection performance. In the BasketBall dataset, we adopt MVDet to detect humans. Table </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S9.T6" style="font-size:144%;" title="Table 6 ‣ 9 Human Prior Loss ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S10.SS1.p2.6.21" style="font-size:144%;"> shows that the point cloud-based method outperforms the multi-view RGB-based method in terms of AP</span><sub class="ltx_sub" id="S10.SS1.p2.6.22"><span class="ltx_text ltx_font_italic" id="S10.SS1.p2.6.22.1" style="font-size:144%;">50</span></sub><span class="ltx_text" id="S10.SS1.p2.6.23" style="font-size:144%;"> and AP</span><sub class="ltx_sub" id="S10.SS1.p2.6.24"><span class="ltx_text ltx_font_italic" id="S10.SS1.p2.6.24.1" style="font-size:144%;">70</span></sub><span class="ltx_text" id="S10.SS1.p2.6.25" style="font-size:144%;">, benefiting from the 3D information of the original point cloud. Additionally, we verify the generalization ability of the point cloud-based method by pretraining it on our synthetic dataset, and it still produces acceptable results.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S10.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">10.2 </span>Entropy Analysis</h3>
<div class="ltx_para" id="S10.SS2.p1">
<p class="ltx_p" id="S10.SS2.p1.1"><span class="ltx_text" id="S10.SS2.p1.1.1" style="font-size:144%;">Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2312.06409v3#S10.F10" style="font-size:144%;" title="Figure 10 ‣ 10 Extended Experiments ‣ LiCamPose: Combining Multi-View LiDAR and RGB Cameras for Robust Single-frame 3D Human Pose Estimation"><span class="ltx_text ltx_ref_tag">10</span></a><span class="ltx_text" id="S10.SS2.p1.1.2" style="font-size:144%;"> shows the entropy value and the specific poses, and we can find that the 3D poses become more and more irrational while the entropy goes up.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jul 16 09:28:00 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
