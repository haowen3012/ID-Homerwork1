<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique</title>
<!--Generated on Wed Jan  3 07:28:59 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2401.01587v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1 Introduction ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S2" title="2 Background Study ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S3" title="3 Related Work ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S4" title="4 Methodology ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S5" title="5 Dataset ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S6" title="6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Result</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S7" title="7 Conclusion and Future Scope ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion and Future Scope</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: CC BY-NC-ND 4.0</div><div id="watermark-tr">arXiv:2401.01587v1 [cs.CV] 03 Jan 2024</div></div>
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Department of Computer Science, Gour Mahavidyalaya,West Bengal, India
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Department of Computer Science, University of Gour Banga, India
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Department of Computer and System Sciences, Visva-Bharati University, India
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>National Research Council of Italy, Institute of Applied Sciences and Intelligent Systems, 73100
Lecce, Italy </span></span></span>
<h1 class="ltx_title ltx_title_document">Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ekram Alam
</span><span class="ltx_author_notes">1133</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Abu Sufian
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Paramartha Dutta
</span><span class="ltx_author_notes">33</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marco Leo
</span><span class="ltx_author_notes">44</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">The elderly population is increasing rapidly around the world. There are no enough caretakers for them. Use of AI-based in-home medical care systems is gaining momentum due to this. Human fall detection is one of the most important tasks of medical care system for the aged people. Human fall is a common problem among elderly people. Detection of a fall and providing medical help as early as possible is very important to reduce any further complexity. The chances of death and other medical complications can be reduced by detecting and providing medical help as early as possible after the fall. There are many state-of-the-art fall detection techniques available these days, but the majority of them need very high computing power. In this paper, we proposed a lightweight and fast human fall detection system using pose estimation. We used ‘Movenet’ for human joins key-points extraction. Our proposed method can work in real-time on any low-computing device with any basic camera. All computation can be processed locally, so there is no problem of privacy of the subject. We used two datasets ‘GMDCSA’ and ‘URFD’ for the experiment. We got the sensitivity value of 0.9375 and 0.9167 for the dataset ‘GMDCSA’ and ‘URFD’ respectively. The source code and the dataset GMDCSA of our work are available online to access.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Fall Detection, Pose Estimation, GMDCSA, Movenet, Lightweight Fall Detection, Real-time Fall Detection
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Human fall is one of the major reasons for hospitalization in elder people around the world <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>. Detection of human falls is very vital so that medical help can be provided as early as possible. Human fall detection can be done using wearable, ambient, or vision sensors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>. Vision-based fall detection system is more suitable, especially for elder people <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>]</cite>. There is no need to attach the vision sensor to the body like wearable sensors. Wearable sensors need to be charged frequently whereas vision sensors can work on a direct home power supply. Human fall detection is one of the useful application of computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>. In this paper, we have proposed a lightweight human fall detection system using pose estimation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>. We have used a lightweight and fast pose estimation model ‘Movenet Thunder’ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite> for our work. The main contributions of this work are as given below.</p>
</div>
<div class="ltx_para" id="S1.p2">
<dl class="ltx_description" id="S1.I1">
<dt class="ltx_item" id="S1.I1.ix1"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix1.1.1.1">Real Time</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S1.I1.ix1.p1">
<p class="ltx_p" id="S1.I1.ix1.p1.1">‘Movenet’ processes the video with 30+ FPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite> (real-time) in the majority of current low computing devices like mobile phones, laptops, and desktops. So the proposed system can work in real-time on these devices. We tested our work on an average computing laptop with inbuilt webcam.</p>
</div>
</dd>
<dt class="ltx_item" id="S1.I1.ix2"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix2.1.1.1">Lightweight</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S1.I1.ix2.p1">
<p class="ltx_p" id="S1.I1.ix2.p1.1">The proposed system does not required very high computing power and can work on any normal laptop/desktop or mobile device.</p>
</div>
</dd>
<dt class="ltx_item" id="S1.I1.ix3"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix3.1.1.1">Local Computation</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S1.I1.ix3.p1">
<p class="ltx_p" id="S1.I1.ix3.p1.1">All computation can be processed locally. There is no personal data (images/frames) transfer from edge <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite> to the cloud and vice versa. Only the output (fall) is sent to the caretaker center for necessary medical help. In this way, our system also preserves the privacy of the subject.</p>
</div>
</dd>
<dt class="ltx_item" id="S1.I1.ix4"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S1.I1.ix4.1.1.1">GMDCSA Dataset</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="S1.I1.ix4.p1">
<p class="ltx_p" id="S1.I1.ix4.p1.1">A new fall detection dataset named GMDCSA was introduced.</p>
</div>
</dd>
</dl>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The rest of the paper is structured as follows. Section <a class="ltx_ref" href="#S3" title="3 Related Work ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">3</span></a> describes related work briefly. Section <a class="ltx_ref" href="#S2" title="2 Background Study ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">2</span></a> gives an overview of the pose estimation using ‘Movenet’. Section <a class="ltx_ref" href="#S4" title="4 Methodology ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">4</span></a> discusses the methodology of our work. Section <a class="ltx_ref" href="#S5" title="5 Dataset ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">5</span></a> describes the datasets which were used in this work. Section <a class="ltx_ref" href="#S6" title="6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">6</span></a> provides the results of this work in the form of different metrics. Finally, section <a class="ltx_ref" href="#S7" title="7 Conclusion and Future Scope ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">7</span></a> concludes the proposed work with possible future scopes.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background Study</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We have used a lightweight pose estimation model named ‘Movenet Thunder’ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>. This model accepts an RGB frame or image of the size 256 x 256 and extracts the normalized coordinate and confidence values of the 17 key-points of the human body joints. The 17 key-points are shown in Figure <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2 Background Study ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="731" id="S2.F1.g1" src="extracted/5327693/FG/pose6.jpg" width="320"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">17 Keypoints of the Movenet pose estimation model</span></figcaption>
</figure>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The indices (from 0 to 16), Keypoints, Y values, X values, and confidences value of a sample image are shown in Table. <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2 Background Study ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Index, Keypoint, Y value, X value and confidence of an sample image</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.4.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_l ltx_border_t" id="S2.T1.4.1.1.1" style="width:37.0pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.4.1.1.1.1" style="font-size:90%;">Index</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t" id="S2.T1.4.1.1.2" style="width:71.1pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.4.1.1.2.1" style="font-size:90%;">Keypoint</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t" id="S2.T1.4.1.1.3" style="width:56.9pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.4.1.1.3.1" style="font-size:90%;">Y Value</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_t" id="S2.T1.4.1.1.4" style="width:56.9pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S2.T1.4.1.1.4.1" style="font-size:90%;">X Value</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T1.4.1.1.5"><span class="ltx_text ltx_font_bold" id="S2.T1.4.1.1.5.1" style="font-size:90%;">Confidence</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.4.2.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_t" id="S2.T1.4.2.1.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.2.1.1.1"><span class="ltx_text" id="S2.T1.4.2.1.1.1.1" style="font-size:90%;">0</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.4.2.1.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.2.1.2.1"><span class="ltx_text" id="S2.T1.4.2.1.2.1.1" style="font-size:90%;">Nose</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.4.2.1.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.2.1.3.1"><span class="ltx_text" id="S2.T1.4.2.1.3.1.1" style="font-size:90%;">0.22416662</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T1.4.2.1.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.2.1.4.1"><span class="ltx_text" id="S2.T1.4.2.1.4.1.1" style="font-size:90%;">0.579579</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.4.2.1.5"><span class="ltx_text" id="S2.T1.4.2.1.5.1" style="font-size:90%;">0.7201656</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.3.2">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.3.2.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.3.2.1.1"><span class="ltx_text" id="S2.T1.4.3.2.1.1.1" style="font-size:90%;">1</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.3.2.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.3.2.2.1"><span class="ltx_text" id="S2.T1.4.3.2.2.1.1" style="font-size:90%;">Left Eye</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.3.2.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.3.2.3.1"><span class="ltx_text" id="S2.T1.4.3.2.3.1.1" style="font-size:90%;">0.20926172</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.3.2.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.3.2.4.1"><span class="ltx_text" id="S2.T1.4.3.2.4.1.1" style="font-size:90%;">0.5974146</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.3.2.5"><span class="ltx_text" id="S2.T1.4.3.2.5.1" style="font-size:90%;">0.8043867</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.4.3">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.4.3.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.4.3.1.1"><span class="ltx_text" id="S2.T1.4.4.3.1.1.1" style="font-size:90%;">2</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.4.3.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.4.3.2.1"><span class="ltx_text" id="S2.T1.4.4.3.2.1.1" style="font-size:90%;">Right Eye</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.4.3.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.4.3.3.1"><span class="ltx_text" id="S2.T1.4.4.3.3.1.1" style="font-size:90%;">0.20485064</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.4.3.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.4.3.4.1"><span class="ltx_text" id="S2.T1.4.4.3.4.1.1" style="font-size:90%;">0.5642889</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.4.3.5"><span class="ltx_text" id="S2.T1.4.4.3.5.1" style="font-size:90%;">0.5905826</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.5.4">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.5.4.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.5.4.1.1"><span class="ltx_text" id="S2.T1.4.5.4.1.1.1" style="font-size:90%;">3</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.5.4.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.5.4.2.1"><span class="ltx_text" id="S2.T1.4.5.4.2.1.1" style="font-size:90%;">Left Ear</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.5.4.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.5.4.3.1"><span class="ltx_text" id="S2.T1.4.5.4.3.1.1" style="font-size:90%;">0.22323</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.5.4.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.5.4.4.1"><span class="ltx_text" id="S2.T1.4.5.4.4.1.1" style="font-size:90%;">0.6126661</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.5.4.5"><span class="ltx_text" id="S2.T1.4.5.4.5.1" style="font-size:90%;">0.7964257</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.6.5">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.6.5.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.6.5.1.1"><span class="ltx_text" id="S2.T1.4.6.5.1.1.1" style="font-size:90%;">4</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.6.5.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.6.5.2.1"><span class="ltx_text" id="S2.T1.4.6.5.2.1.1" style="font-size:90%;">Right Ear</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.6.5.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.6.5.3.1"><span class="ltx_text" id="S2.T1.4.6.5.3.1.1" style="font-size:90%;">0.21771489</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.6.5.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.6.5.4.1"><span class="ltx_text" id="S2.T1.4.6.5.4.1.1" style="font-size:90%;">0.5370738</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.6.5.5"><span class="ltx_text" id="S2.T1.4.6.5.5.1" style="font-size:90%;">0.7529471</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.7.6">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.7.6.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.7.6.1.1"><span class="ltx_text" id="S2.T1.4.7.6.1.1.1" style="font-size:90%;">5</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.7.6.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.7.6.2.1"><span class="ltx_text" id="S2.T1.4.7.6.2.1.1" style="font-size:90%;">Left Shoulder</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.7.6.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.7.6.3.1"><span class="ltx_text" id="S2.T1.4.7.6.3.1.1" style="font-size:90%;">0.3235461</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.7.6.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.7.6.4.1"><span class="ltx_text" id="S2.T1.4.7.6.4.1.1" style="font-size:90%;">0.6375601</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.7.6.5"><span class="ltx_text" id="S2.T1.4.7.6.5.1" style="font-size:90%;">0.8950565</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.8.7">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.8.7.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.8.7.1.1"><span class="ltx_text" id="S2.T1.4.8.7.1.1.1" style="font-size:90%;">6</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.8.7.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.8.7.2.1"><span class="ltx_text" id="S2.T1.4.8.7.2.1.1" style="font-size:90%;">Right Shoulder</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.8.7.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.8.7.3.1"><span class="ltx_text" id="S2.T1.4.8.7.3.1.1" style="font-size:90%;">0.2964768</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.8.7.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.8.7.4.1"><span class="ltx_text" id="S2.T1.4.8.7.4.1.1" style="font-size:90%;">0.48282918</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.8.7.5"><span class="ltx_text" id="S2.T1.4.8.7.5.1" style="font-size:90%;">0.65825576</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.9.8">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.9.8.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.9.8.1.1"><span class="ltx_text" id="S2.T1.4.9.8.1.1.1" style="font-size:90%;">7</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.9.8.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.9.8.2.1"><span class="ltx_text" id="S2.T1.4.9.8.2.1.1" style="font-size:90%;">Left Elbow</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.9.8.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.9.8.3.1"><span class="ltx_text" id="S2.T1.4.9.8.3.1.1" style="font-size:90%;">0.43468294</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.9.8.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.9.8.4.1"><span class="ltx_text" id="S2.T1.4.9.8.4.1.1" style="font-size:90%;">0.63684213</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.9.8.5"><span class="ltx_text" id="S2.T1.4.9.8.5.1" style="font-size:90%;">0.7667525</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.10.9">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.10.9.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.10.9.1.1"><span class="ltx_text" id="S2.T1.4.10.9.1.1.1" style="font-size:90%;">8</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.10.9.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.10.9.2.1"><span class="ltx_text" id="S2.T1.4.10.9.2.1.1" style="font-size:90%;">Right Elbow</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.10.9.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.10.9.3.1"><span class="ltx_text" id="S2.T1.4.10.9.3.1.1" style="font-size:90%;">0.42770475</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.10.9.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.10.9.4.1"><span class="ltx_text" id="S2.T1.4.10.9.4.1.1" style="font-size:90%;">0.4406372</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.10.9.5"><span class="ltx_text" id="S2.T1.4.10.9.5.1" style="font-size:90%;">0.8829603</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.11.10">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.11.10.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.11.10.1.1"><span class="ltx_text" id="S2.T1.4.11.10.1.1.1" style="font-size:90%;">9</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.11.10.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.11.10.2.1"><span class="ltx_text" id="S2.T1.4.11.10.2.1.1" style="font-size:90%;">Left Wrist</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.11.10.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.11.10.3.1"><span class="ltx_text" id="S2.T1.4.11.10.3.1.1" style="font-size:90%;">0.54110587</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.11.10.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.11.10.4.1"><span class="ltx_text" id="S2.T1.4.11.10.4.1.1" style="font-size:90%;">0.6462866</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.11.10.5"><span class="ltx_text" id="S2.T1.4.11.10.5.1" style="font-size:90%;">0.6282949</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.12.11">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.12.11.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.12.11.1.1"><span class="ltx_text" id="S2.T1.4.12.11.1.1.1" style="font-size:90%;">10</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.12.11.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.12.11.2.1"><span class="ltx_text" id="S2.T1.4.12.11.2.1.1" style="font-size:90%;">Right Wrist</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.12.11.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.12.11.3.1"><span class="ltx_text" id="S2.T1.4.12.11.3.1.1" style="font-size:90%;">0.5392799</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.12.11.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.12.11.4.1"><span class="ltx_text" id="S2.T1.4.12.11.4.1.1" style="font-size:90%;">0.42464092</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.12.11.5"><span class="ltx_text" id="S2.T1.4.12.11.5.1" style="font-size:90%;">0.8215329</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.13.12">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.13.12.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.13.12.1.1"><span class="ltx_text" id="S2.T1.4.13.12.1.1.1" style="font-size:90%;">11</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.13.12.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.13.12.2.1"><span class="ltx_text" id="S2.T1.4.13.12.2.1.1" style="font-size:90%;">Left Hip</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.13.12.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.13.12.3.1"><span class="ltx_text" id="S2.T1.4.13.12.3.1.1" style="font-size:90%;">0.54277164</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.13.12.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.13.12.4.1"><span class="ltx_text" id="S2.T1.4.13.12.4.1.1" style="font-size:90%;">0.57565194</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.13.12.5"><span class="ltx_text" id="S2.T1.4.13.12.5.1" style="font-size:90%;">0.85804665</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.14.13">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.14.13.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.14.13.1.1"><span class="ltx_text" id="S2.T1.4.14.13.1.1.1" style="font-size:90%;">12</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.14.13.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.14.13.2.1"><span class="ltx_text" id="S2.T1.4.14.13.2.1.1" style="font-size:90%;">Right Hip</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.14.13.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.14.13.3.1"><span class="ltx_text" id="S2.T1.4.14.13.3.1.1" style="font-size:90%;">0.53679305</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.14.13.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.14.13.4.1"><span class="ltx_text" id="S2.T1.4.14.13.4.1.1" style="font-size:90%;">0.48321638</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.14.13.5"><span class="ltx_text" id="S2.T1.4.14.13.5.1" style="font-size:90%;">0.88962007</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.15.14">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.15.14.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.15.14.1.1"><span class="ltx_text" id="S2.T1.4.15.14.1.1.1" style="font-size:90%;">13</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.15.14.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.15.14.2.1"><span class="ltx_text" id="S2.T1.4.15.14.2.1.1" style="font-size:90%;">Left Knee</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.15.14.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.15.14.3.1"><span class="ltx_text" id="S2.T1.4.15.14.3.1.1" style="font-size:90%;">0.69595444</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.15.14.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.15.14.4.1"><span class="ltx_text" id="S2.T1.4.15.14.4.1.1" style="font-size:90%;">0.609515</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.15.14.5"><span class="ltx_text" id="S2.T1.4.15.14.5.1" style="font-size:90%;">0.8796475</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.16.15">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.16.15.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.16.15.1.1"><span class="ltx_text" id="S2.T1.4.16.15.1.1.1" style="font-size:90%;">14</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.16.15.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.16.15.2.1"><span class="ltx_text" id="S2.T1.4.16.15.2.1.1" style="font-size:90%;">Right Knee</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.16.15.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.16.15.3.1"><span class="ltx_text" id="S2.T1.4.16.15.3.1.1" style="font-size:90%;">0.7019378</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.16.15.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.16.15.4.1"><span class="ltx_text" id="S2.T1.4.16.15.4.1.1" style="font-size:90%;">0.46842176</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.16.15.5"><span class="ltx_text" id="S2.T1.4.16.15.5.1" style="font-size:90%;">0.6786141</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.17.16">
<td class="ltx_td ltx_align_justify ltx_border_l" id="S2.T1.4.17.16.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.17.16.1.1"><span class="ltx_text" id="S2.T1.4.17.16.1.1.1" style="font-size:90%;">15</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.17.16.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.17.16.2.1"><span class="ltx_text" id="S2.T1.4.17.16.2.1.1" style="font-size:90%;">Left Ankle</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.17.16.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.17.16.3.1"><span class="ltx_text" id="S2.T1.4.17.16.3.1.1" style="font-size:90%;">0.85588527</span></p>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T1.4.17.16.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.17.16.4.1"><span class="ltx_text" id="S2.T1.4.17.16.4.1.1" style="font-size:90%;">0.56420994</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.4.17.16.5"><span class="ltx_text" id="S2.T1.4.17.16.5.1" style="font-size:90%;">0.7951814</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.4.18.17">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l" id="S2.T1.4.18.17.1" style="width:37.0pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.18.17.1.1"><span class="ltx_text" id="S2.T1.4.18.17.1.1.1" style="font-size:90%;">16</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b" id="S2.T1.4.18.17.2" style="width:71.1pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.18.17.2.1"><span class="ltx_text" id="S2.T1.4.18.17.2.1.1" style="font-size:90%;">Right Ankle</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b" id="S2.T1.4.18.17.3" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.18.17.3.1"><span class="ltx_text" id="S2.T1.4.18.17.3.1.1" style="font-size:90%;">0.8588409</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b" id="S2.T1.4.18.17.4" style="width:56.9pt;">
<p class="ltx_p ltx_align_top" id="S2.T1.4.18.17.4.1"><span class="ltx_text" id="S2.T1.4.18.17.4.1.1" style="font-size:90%;">0.47616798</span></p>
</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S2.T1.4.18.17.5"><span class="ltx_text" id="S2.T1.4.18.17.5.1" style="font-size:90%;">0.82729894</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The values of y,x, and confidence are normalized from 0 to 1. The top left position is the origin(0,0) and the bottom right position has the value (1,1). When the keypoints are clearly visible then confidence tends to 1 (100%) otherwise it tends to 0 (0%).</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related Work</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section briefly describes some recent related works. Asif et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite> introduced a single-shot fall detection technique using 3D poseNet. Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>]</cite> proposed a 3D posed estimator which was used as input for the fall detection network. Apicella and Snidaro <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite> proposed a fall detection method based on CNN, RNN and PoseNet pose estimation. Leite et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite> introduced a multi (three) channel CNN-based fall detection system. Optical flow, pose estimation, and visual rhythm were used as inputs for three different streams of the CNN. OpenPose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite> was used for pose estimation. Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite> proposed a fall detection system using the Yolov5 network <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>]</cite>. Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite> proposed a fall detection system based on BlazePose-LSTM. This system was introduced especially for seafarers. Beddiar et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite> introduced a work based on the angle formed by the line from the centroid of the human face to the centroid of the hip to the line formed from the centroid of the hip to the horizontal axis. Amsaprabhaa et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite> proposed a multimodal gate feature-based fall detection system.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The methodology of the proposed work is shown in Figure <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ 4 Methodology ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="717" id="S4.F2.g1" src="extracted/5327693/FG/RTFPD.jpg" width="470"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">Proposed work methodology</span></figcaption>
</figure>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The input can be an image, frames of a video, or the live video stream. The input images / frames were resized to 256 x 256 as preprocessing before feeding it to the Movenet. After preprocessing, pose estimation was done using the Movenet. The Movenet extracts the key-point co-ordinates with their confidence score as shown in Table <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2 Background Study ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">1</span></a>. Confidence score can vary from 0 (0%) to 1 (100%) for each keypoints. If all key-points with very low confidence are also used for fall detection then it might select the wrong keypoints and this will reduce the performance of the system. If the high confidence value threshold are used it may ignore some good keypoints which might be useful for the detection of the fall. After experimenting with different threshold values of the confidence score, we finally selected 0.5 as threshold value because it gave good results. We have selected only those key-points whose confidence scores are greater than 0.5. The fall activity and sleeping activity are very similar and there are high chances of detecting a sleeping activity as fall. If there is a sleeping like activity on the floor then the system should detect it as fall activity, but if there is a sleeping like activity on the bed then the system should detect it as ADL (not fall) activity. To filter out this we compared the approximate y value of the top of the bed with the y value of the nose, eyes, ears, shoulders, elbows and wrists (upper body part). If the y value of these key-points (upper body part) are greater than the approximate y value of the top of the bed, then the activities of these frames are not fall and filtered out for the fall detection.
</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="481" id="S4.F3.g1" src="extracted/5327693/FG/Analysis.jpg" width="430"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Proposed work methodology flowchart</span></figcaption>
</figure>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">After that the coordinates (x, y values) of the keypoints of the upper body parts were compared with the coordinates of key-points of the lower body parts(hips, knees, ankles). If the differences of the y value of the upper body keypoints (UBK) with lower body keypoints (LBK) is less than or equal to 0.05 (threshold-y) and the absolute differences of the x value is greater than 0.5 (threshold-x) then there is a chance of a Fall and the fall counter is increased by one. The selection of the values for the threshold-y and threshold-x were done after doing many experiments with different values. These values gave the best results. If in the next frame this is false then counter reset to 0. If this happens continuously for 2 or more frames (minimum counter value 2), then the system detects it as a fall, and a fall alert is sent. Detail of the analysis is shown in Figure <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4 Methodology ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">3</span></a>. The source code of the proposed work is available here <a class="ltx_ref ltx_url" href="https://github.com/ekramalam/RTHFD" title="">https://github.com/ekramalam/RTHFD</a>.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Dataset</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We used two datasets for the proposed experiment, the URFD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite> dataset and a dataset (GMDCSA) created by us. The URFD dataset contains 40 ADL (not fall) activities and 30 fall activities. The GMDCSA dataset contains 16 ADL (not fall) activities and 16 Fall activities. The GMDCSA dataset has been created by performing the fall and the ADL activities by a single subject wearing different set of clothes. The web camera of a laptop (HP 348 G5 Laptop : Core i5 8th Gen/8 GB/512 GB SSD/Windows 10) was used to capture the activities. The description of the ADL and Fall video sequences of the GMDCSA dataset are shown in Table <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5 Dataset ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5 Dataset ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">3</span></a> respectively. The link to access this dataset is as follows <a class="ltx_ref ltx_url" href="https://drive.google.com/drive/folders/1ohDEXki8Wz12cJ1XzyKIK4T6y1_hAf3p?usp=sharing" title="">https://drive.google.com/drive/folders/1ohDEXki8Wz12cJ1XzyKIK4T6y1˙hAf3p?usp=sharing</a>.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.4.1.1" style="font-size:129%;">Table 2</span>: </span><span class="ltx_text" id="S5.T2.5.2" style="font-size:129%;">GMDCSA Dataset: ADL Activities</span></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.6.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.6.1.1.1" style="width:28.5pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.6.1.1.1.1" style="font-size:70%;">File Name</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.6.1.1.2" style="width:28.5pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.6.1.1.2.1" style="font-size:70%;">Length</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.6.1.1.3"><span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T2.6.1.1.3.1" style="font-size:70%;">Description</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.6.2.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.6.2.1.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.2.1.1.1"><span class="ltx_text" id="S5.T2.6.2.1.1.1.1" style="font-size:70%;">01.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T2.6.2.1.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.2.1.2.1"><span class="ltx_text" id="S5.T2.6.2.1.2.1.1" style="font-size:70%;">08 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T2.6.2.1.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.2.1.3.1"><span class="ltx_text" id="S5.T2.6.2.1.3.1.1" style="font-size:70%;">Sitting on the bed to sleeping right side on the bed. Face towards camera</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.3.2">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.3.2.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.3.2.1.1"><span class="ltx_text" id="S5.T2.6.3.2.1.1.1" style="font-size:70%;">02.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.3.2.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.3.2.2.1"><span class="ltx_text" id="S5.T2.6.3.2.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.3.2.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.3.2.3.1"><span class="ltx_text" id="S5.T2.6.3.2.3.1.1" style="font-size:70%;">Sitting on the bed to sleeping left side on the bed. Face towards camera.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.4.3">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.4.3.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.4.3.1.1"><span class="ltx_text" id="S5.T2.6.4.3.1.1.1" style="font-size:70%;">03.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.4.3.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.4.3.2.1"><span class="ltx_text" id="S5.T2.6.4.3.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.4.3.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.4.3.3.1"><span class="ltx_text" id="S5.T2.6.4.3.3.1.1" style="font-size:70%;">Sitting on the bed to sleeping left side on the bed. Face towards ceiling.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.5.4">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.5.4.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.5.4.1.1"><span class="ltx_text" id="S5.T2.6.5.4.1.1.1" style="font-size:70%;">04.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.5.4.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.5.4.2.1"><span class="ltx_text" id="S5.T2.6.5.4.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.5.4.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.5.4.3.1"><span class="ltx_text" id="S5.T2.6.5.4.3.1.1" style="font-size:70%;">From sleeping left side on the bed (Face towards ceiling) to sitting on the bed.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.6.5">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.6.5.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.6.5.1.1"><span class="ltx_text" id="S5.T2.6.6.5.1.1.1" style="font-size:70%;">05.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.6.5.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.6.5.2.1"><span class="ltx_text" id="S5.T2.6.6.5.2.1.1" style="font-size:70%;">10 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.6.5.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.6.5.3.1"><span class="ltx_text" id="S5.T2.6.6.5.3.1.1" style="font-size:70%;">Coming to the bed and reading book in sitting position. Front view of the subject. One leg folded.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.7.6">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.7.6.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.7.6.1.1"><span class="ltx_text" id="S5.T2.6.7.6.1.1.1" style="font-size:70%;">06.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.7.6.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.7.6.2.1"><span class="ltx_text" id="S5.T2.6.7.6.2.1.1" style="font-size:70%;">12 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.7.6.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.7.6.3.1"><span class="ltx_text" id="S5.T2.6.7.6.3.1.1" style="font-size:70%;">Sitting on the bed (front view) to reading the book while supporting towards the wall. Side view, Leg straight.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.8.7">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.8.7.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.8.7.1.1"><span class="ltx_text" id="S5.T2.6.8.7.1.1.1" style="font-size:70%;">07.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.8.7.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.8.7.2.1"><span class="ltx_text" id="S5.T2.6.8.7.2.1.1" style="font-size:70%;">07 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.8.7.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.8.7.3.1"><span class="ltx_text" id="S5.T2.6.8.7.3.1.1" style="font-size:70%;">Reading book while sitting on the chair. Front view.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.9.8">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.9.8.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.9.8.1.1"><span class="ltx_text" id="S5.T2.6.9.8.1.1.1" style="font-size:70%;">08.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.9.8.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.9.8.2.1"><span class="ltx_text" id="S5.T2.6.9.8.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.9.8.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.9.8.3.1"><span class="ltx_text" id="S5.T2.6.9.8.3.1.1" style="font-size:70%;">Walking in the room.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.10.9">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.10.9.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.10.9.1.1"><span class="ltx_text" id="S5.T2.6.10.9.1.1.1" style="font-size:70%;">09.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.10.9.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.10.9.2.1"><span class="ltx_text" id="S5.T2.6.10.9.2.1.1" style="font-size:70%;">04 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.10.9.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.10.9.3.1"><span class="ltx_text" id="S5.T2.6.10.9.3.1.1" style="font-size:70%;">Reading book while walking in the room.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.11.10">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.11.10.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.11.10.1.1"><span class="ltx_text" id="S5.T2.6.11.10.1.1.1" style="font-size:70%;">10.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.11.10.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.11.10.2.1"><span class="ltx_text" id="S5.T2.6.11.10.2.1.1" style="font-size:70%;">03 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.11.10.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.11.10.3.1"><span class="ltx_text" id="S5.T2.6.11.10.3.1.1" style="font-size:70%;">Reading book while walking in the room.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.12.11">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.12.11.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.12.11.1.1"><span class="ltx_text" id="S5.T2.6.12.11.1.1.1" style="font-size:70%;">11.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.12.11.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.12.11.2.1"><span class="ltx_text" id="S5.T2.6.12.11.2.1.1" style="font-size:70%;">09 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.12.11.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.12.11.3.1"><span class="ltx_text" id="S5.T2.6.12.11.3.1.1" style="font-size:70%;">Walking to sitting on the chair and then reading book.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.13.12">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.13.12.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.13.12.1.1"><span class="ltx_text" id="S5.T2.6.13.12.1.1.1" style="font-size:70%;">12.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.13.12.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.13.12.2.1"><span class="ltx_text" id="S5.T2.6.13.12.2.1.1" style="font-size:70%;">07 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.13.12.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.13.12.3.1"><span class="ltx_text" id="S5.T2.6.13.12.3.1.1" style="font-size:70%;">Reading book while sitting on the chair to stand up and keeping the book on the chair and going out of the room.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.14.13">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.14.13.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.14.13.1.1"><span class="ltx_text" id="S5.T2.6.14.13.1.1.1" style="font-size:70%;">13.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.14.13.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.14.13.2.1"><span class="ltx_text" id="S5.T2.6.14.13.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.14.13.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.14.13.3.1"><span class="ltx_text" id="S5.T2.6.14.13.3.1.1" style="font-size:70%;">Walking to sitting on the chair (side view).</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.15.14">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.15.14.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.15.14.1.1"><span class="ltx_text" id="S5.T2.6.15.14.1.1.1" style="font-size:70%;">14.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.15.14.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.15.14.2.1"><span class="ltx_text" id="S5.T2.6.15.14.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.15.14.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.15.14.3.1"><span class="ltx_text" id="S5.T2.6.15.14.3.1.1" style="font-size:70%;">Sitting on the chair (side view) to walking.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.16.15">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T2.6.16.15.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.16.15.1.1"><span class="ltx_text" id="S5.T2.6.16.15.1.1.1" style="font-size:70%;">15.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.16.15.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.16.15.2.1"><span class="ltx_text" id="S5.T2.6.16.15.2.1.1" style="font-size:70%;">07 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T2.6.16.15.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.16.15.3.1"><span class="ltx_text" id="S5.T2.6.16.15.3.1.1" style="font-size:70%;">Walking to picking a mobile phone from the ground and then sitting on the chair.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.6.17.16">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r" id="S5.T2.6.17.16.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.17.16.1.1"><span class="ltx_text" id="S5.T2.6.17.16.1.1.1" style="font-size:70%;">16.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" id="S5.T2.6.17.16.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T2.6.17.16.2.1"><span class="ltx_text" id="S5.T2.6.17.16.2.1.1" style="font-size:70%;">03 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" id="S5.T2.6.17.16.3">
<p class="ltx_p ltx_align_top" id="S5.T2.6.17.16.3.1"><span class="ltx_text" id="S5.T2.6.17.16.3.1.1" style="font-size:70%;">Picking the mobile phone from the ground while sitting on the chair</span></p>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.4.1.1" style="font-size:129%;">Table 3</span>: </span><span class="ltx_text" id="S5.T3.5.2" style="font-size:129%;">GMDCSA Dataset: Fall Activities</span></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.6.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.6.1.1.1" style="width:28.5pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T3.6.1.1.1.1" style="font-size:70%;">File Name</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.6.1.1.2" style="width:28.5pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T3.6.1.1.2.1" style="font-size:70%;">Length</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.6.1.1.3"><span class="ltx_text ltx_font_bold ltx_align_top" id="S5.T3.6.1.1.3.1" style="font-size:70%;">Description</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.6.2.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.6.2.1.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.2.1.1.1"><span class="ltx_text" id="S5.T3.6.2.1.1.1.1" style="font-size:70%;">01.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T3.6.2.1.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.2.1.2.1"><span class="ltx_text" id="S5.T3.6.2.1.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S5.T3.6.2.1.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.2.1.3.1"><span class="ltx_text" id="S5.T3.6.2.1.3.1.1" style="font-size:70%;">Falling from sitting on the chair to the ground. Left side Fall. Full body not visible.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.3.2">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.3.2.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.3.2.1.1"><span class="ltx_text" id="S5.T3.6.3.2.1.1.1" style="font-size:70%;">02.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.3.2.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.3.2.2.1"><span class="ltx_text" id="S5.T3.6.3.2.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.3.2.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.3.2.3.1"><span class="ltx_text" id="S5.T3.6.3.2.3.1.1" style="font-size:70%;">Falling from sitting on the chair to the ground. Left side Fall. Full body not visible.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.4.3">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.4.3.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.4.3.1.1"><span class="ltx_text" id="S5.T3.6.4.3.1.1.1" style="font-size:70%;">03.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.4.3.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.4.3.2.1"><span class="ltx_text" id="S5.T3.6.4.3.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.4.3.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.4.3.3.1"><span class="ltx_text" id="S5.T3.6.4.3.3.1.1" style="font-size:70%;">Falling from sitting on the chair to the ground. Left side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.5.4">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.5.4.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.5.4.1.1"><span class="ltx_text" id="S5.T3.6.5.4.1.1.1" style="font-size:70%;">04.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.5.4.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.5.4.2.1"><span class="ltx_text" id="S5.T3.6.5.4.2.1.1" style="font-size:70%;">04 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.5.4.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.5.4.3.1"><span class="ltx_text" id="S5.T3.6.5.4.3.1.1" style="font-size:70%;">Falling from sitting on the chair to the ground. Right side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.6.5">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.6.5.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.6.5.1.1"><span class="ltx_text" id="S5.T3.6.6.5.1.1.1" style="font-size:70%;">05.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.6.5.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.6.5.2.1"><span class="ltx_text" id="S5.T3.6.6.5.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.6.5.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.6.5.3.1"><span class="ltx_text" id="S5.T3.6.6.5.3.1.1" style="font-size:70%;">Walking to falling. Right side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.7.6">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.7.6.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.7.6.1.1"><span class="ltx_text" id="S5.T3.6.7.6.1.1.1" style="font-size:70%;">06.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.7.6.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.7.6.2.1"><span class="ltx_text" id="S5.T3.6.7.6.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.7.6.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.7.6.3.1"><span class="ltx_text" id="S5.T3.6.7.6.3.1.1" style="font-size:70%;">Walking to falling. Right side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.8.7">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.8.7.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.8.7.1.1"><span class="ltx_text" id="S5.T3.6.8.7.1.1.1" style="font-size:70%;">07.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.8.7.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.8.7.2.1"><span class="ltx_text" id="S5.T3.6.8.7.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.8.7.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.8.7.3.1"><span class="ltx_text" id="S5.T3.6.8.7.3.1.1" style="font-size:70%;">Walking to falling. Right side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.9.8">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.9.8.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.9.8.1.1"><span class="ltx_text" id="S5.T3.6.9.8.1.1.1" style="font-size:70%;">08.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.9.8.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.9.8.2.1"><span class="ltx_text" id="S5.T3.6.9.8.2.1.1" style="font-size:70%;">04 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.9.8.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.9.8.3.1"><span class="ltx_text" id="S5.T3.6.9.8.3.1.1" style="font-size:70%;">Walking to falling. Left side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.10.9">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.10.9.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.10.9.1.1"><span class="ltx_text" id="S5.T3.6.10.9.1.1.1" style="font-size:70%;">09.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.10.9.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.10.9.2.1"><span class="ltx_text" id="S5.T3.6.10.9.2.1.1" style="font-size:70%;">04 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.10.9.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.10.9.3.1"><span class="ltx_text" id="S5.T3.6.10.9.3.1.1" style="font-size:70%;">Standing position to falling. Forward Fall. Full body (head) not visible.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.11.10">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.11.10.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.11.10.1.1"><span class="ltx_text" id="S5.T3.6.11.10.1.1.1" style="font-size:70%;">10.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.11.10.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.11.10.2.1"><span class="ltx_text" id="S5.T3.6.11.10.2.1.1" style="font-size:70%;">04 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.11.10.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.11.10.3.1"><span class="ltx_text" id="S5.T3.6.11.10.3.1.1" style="font-size:70%;">Standing position to falling. Forward Fall. Full body (right eye) not visible.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.12.11">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.12.11.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.12.11.1.1"><span class="ltx_text" id="S5.T3.6.12.11.1.1.1" style="font-size:70%;">11.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.12.11.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.12.11.2.1"><span class="ltx_text" id="S5.T3.6.12.11.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.12.11.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.12.11.3.1"><span class="ltx_text" id="S5.T3.6.12.11.3.1.1" style="font-size:70%;">Standing position to falling. Backward Fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.13.12">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.13.12.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.13.12.1.1"><span class="ltx_text" id="S5.T3.6.13.12.1.1.1" style="font-size:70%;">12.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.13.12.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.13.12.2.1"><span class="ltx_text" id="S5.T3.6.13.12.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.13.12.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.13.12.3.1"><span class="ltx_text" id="S5.T3.6.13.12.3.1.1" style="font-size:70%;">Standing position to falling. Backward Fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.14.13">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.14.13.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.14.13.1.1"><span class="ltx_text" id="S5.T3.6.14.13.1.1.1" style="font-size:70%;">13.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.14.13.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.14.13.2.1"><span class="ltx_text" id="S5.T3.6.14.13.2.1.1" style="font-size:70%;">04 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.14.13.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.14.13.3.1"><span class="ltx_text" id="S5.T3.6.14.13.3.1.1" style="font-size:70%;">Standing position to falling. Backward fall. Full body (head ) is not visible.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.15.14">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.15.14.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.15.14.1.1"><span class="ltx_text" id="S5.T3.6.15.14.1.1.1" style="font-size:70%;">14.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.15.14.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.15.14.2.1"><span class="ltx_text" id="S5.T3.6.15.14.2.1.1" style="font-size:70%;">05 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.15.14.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.15.14.3.1"><span class="ltx_text" id="S5.T3.6.15.14.3.1.1" style="font-size:70%;">Standing position to falling. Backward fall. Full body (both ankles) is not visible.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.16.15">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" id="S5.T3.6.16.15.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.16.15.1.1"><span class="ltx_text" id="S5.T3.6.16.15.1.1.1" style="font-size:70%;">15.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.16.15.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.16.15.2.1"><span class="ltx_text" id="S5.T3.6.16.15.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r" id="S5.T3.6.16.15.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.16.15.3.1"><span class="ltx_text" id="S5.T3.6.16.15.3.1.1" style="font-size:70%;">Sitting on the chair (side view) to right side fall.</span></p>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.17.16">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r" id="S5.T3.6.17.16.1" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.17.16.1.1"><span class="ltx_text" id="S5.T3.6.17.16.1.1.1" style="font-size:70%;">16.mp4</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" id="S5.T3.6.17.16.2" style="width:28.5pt;">
<p class="ltx_p ltx_align_top" id="S5.T3.6.17.16.2.1"><span class="ltx_text" id="S5.T3.6.17.16.2.1.1" style="font-size:70%;">06 sec</span></p>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" id="S5.T3.6.17.16.3">
<p class="ltx_p ltx_align_top" id="S5.T3.6.17.16.3.1"><span class="ltx_text" id="S5.T3.6.17.16.3.1.1" style="font-size:70%;">Sitting on the chair (side view) to left side fall.</span></p>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Result</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The performance of a model can be measured using different evaluation metrics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite> like sensitivity, specificity, precision, etc. The values of True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) are needed to calculate the values of these metrics. The value of TP, TN, FP, and FN can easily be found from the confusion matrix as shown in Figure <a class="ltx_ref" href="#S6.F4" title="Figure 4 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S6.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S6.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="221" id="S6.F3.sf1.g1" src="extracted/5327693/FG/ConfMx2.jpg" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F3.sf1.3.2" style="font-size:90%;">GMDCSA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S6.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="206" id="S6.F3.sf2.g1" src="extracted/5327693/FG/ConfMxURFD.jpg" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F3.sf2.3.2" style="font-size:90%;">URFD</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S6.F4.3.2" style="font-size:90%;">Confusion Matrix</span></figcaption>
</figure>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The value of TP, TN, FP, and FN for the two dataset GMDCSA and URFD are shown in Table <a class="ltx_ref" href="#S6.T4" title="Table 4 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="S6.T4">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>The value of TP, TN, FP, and FN for the dataset GMDCSA and URFD</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T4.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S6.T4.4.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T4.4.1.1.1.1" style="font-size:90%;">Dataset</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T4.4.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T4.4.1.1.2.1" style="font-size:90%;">TP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T4.4.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T4.4.1.1.3.1" style="font-size:90%;">TN</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T4.4.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T4.4.1.1.4.1" style="font-size:90%;">FP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T4.4.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T4.4.1.1.5.1" style="font-size:90%;">FN</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T4.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S6.T4.4.2.1.1"><span class="ltx_text" id="S6.T4.4.2.1.1.1" style="font-size:90%;">GMDCSA</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T4.4.2.1.2"><span class="ltx_text" id="S6.T4.4.2.1.2.1" style="font-size:90%;">15</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T4.4.2.1.3"><span class="ltx_text" id="S6.T4.4.2.1.3.1" style="font-size:90%;">15</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T4.4.2.1.4"><span class="ltx_text" id="S6.T4.4.2.1.4.1" style="font-size:90%;">1</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T4.4.2.1.5"><span class="ltx_text" id="S6.T4.4.2.1.5.1" style="font-size:90%;">1</span></td>
</tr>
<tr class="ltx_tr" id="S6.T4.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S6.T4.4.3.2.1"><span class="ltx_text" id="S6.T4.4.3.2.1.1" style="font-size:90%;">URFD</span></th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S6.T4.4.3.2.2"><span class="ltx_text" id="S6.T4.4.3.2.2.1" style="font-size:90%;">22</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S6.T4.4.3.2.3"><span class="ltx_text" id="S6.T4.4.3.2.3.1" style="font-size:90%;">29</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S6.T4.4.3.2.4"><span class="ltx_text" id="S6.T4.4.3.2.4.1" style="font-size:90%;">11</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S6.T4.4.3.2.5"><span class="ltx_text" id="S6.T4.4.3.2.5.1" style="font-size:90%;">2</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Table <a class="ltx_ref" href="#S6.T5" title="Table 5 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">5</span></a> shows the values of sensitivity, specificity, precision, false positive rate, false negative rate, accuracy, and F1 Score.</p>
</div>
<figure class="ltx_table" id="S6.T5">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Results of the experiment</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T5.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T5.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S6.T5.2.3.1.1"><span class="ltx_text ltx_font_bold" id="S6.T5.2.3.1.1.1" style="font-size:90%;">Metric</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S6.T5.2.3.1.2"><span class="ltx_text ltx_font_bold" id="S6.T5.2.3.1.2.1" style="font-size:90%;">Expression</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S6.T5.2.3.1.3"><span class="ltx_text" id="S6.T5.2.3.1.3.1" style="font-size:90%;">Dataset</span></th>
</tr>
<tr class="ltx_tr" id="S6.T5.2.4.2">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r" id="S6.T5.2.4.2.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S6.T5.2.4.2.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T5.2.4.2.3"><span class="ltx_text ltx_font_bold" id="S6.T5.2.4.2.3.1" style="font-size:90%;">GMDCSA</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S6.T5.2.4.2.4"><span class="ltx_text ltx_font_bold" id="S6.T5.2.4.2.4.1" style="font-size:90%;">URFD</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T5.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S6.T5.2.2.3"><span class="ltx_text" id="S6.T5.2.2.3.1" style="font-size:90%;">Sensitivity</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T5.2.2.2"><span class="ltx_text" id="S6.T5.2.2.2.1" style="font-size:90%;">TP / (TP + FN)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T5.2.2.4"><span class="ltx_text" id="S6.T5.2.2.4.1" style="font-size:90%;">0.9375</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S6.T5.2.2.5"><span class="ltx_text" id="S6.T5.2.2.5.1" style="font-size:90%;">0.9167</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S6.T5.2.5.1.1"><span class="ltx_text" id="S6.T5.2.5.1.1.1" style="font-size:90%;">Specificity</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T5.2.5.1.2"><span class="ltx_text" id="S6.T5.2.5.1.2.1" style="font-size:90%;">TN / (FP + TN)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.5.1.3"><span class="ltx_text" id="S6.T5.2.5.1.3.1" style="font-size:90%;">0.9375</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.5.1.4"><span class="ltx_text" id="S6.T5.2.5.1.4.1" style="font-size:90%;">0.7250</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S6.T5.2.6.2.1"><span class="ltx_text" id="S6.T5.2.6.2.1.1" style="font-size:90%;">Precision</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T5.2.6.2.2"><span class="ltx_text" id="S6.T5.2.6.2.2.1" style="font-size:90%;">TP / (TP + FP)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.6.2.3"><span class="ltx_text" id="S6.T5.2.6.2.3.1" style="font-size:90%;">0.9375</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.6.2.4"><span class="ltx_text" id="S6.T5.2.6.2.4.1" style="font-size:90%;">0.6667</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S6.T5.2.7.3.1"><span class="ltx_text" id="S6.T5.2.7.3.1.1" style="font-size:90%;">False Positive Rate</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T5.2.7.3.2"><span class="ltx_text" id="S6.T5.2.7.3.2.1" style="font-size:90%;">FP / (FP + TN)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.7.3.3"><span class="ltx_text" id="S6.T5.2.7.3.3.1" style="font-size:90%;">0.0625</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.7.3.4"><span class="ltx_text" id="S6.T5.2.7.3.4.1" style="font-size:90%;">0.2750</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S6.T5.2.8.4.1"><span class="ltx_text" id="S6.T5.2.8.4.1.1" style="font-size:90%;">False Negative Rate</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T5.2.8.4.2"><span class="ltx_text" id="S6.T5.2.8.4.2.1" style="font-size:90%;">FN / (FN + TP)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.8.4.3"><span class="ltx_text" id="S6.T5.2.8.4.3.1" style="font-size:90%;">0.0625</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.8.4.4"><span class="ltx_text" id="S6.T5.2.8.4.4.1" style="font-size:90%;">0.0833</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="S6.T5.2.9.5.1"><span class="ltx_text" id="S6.T5.2.9.5.1.1" style="font-size:90%;">Accuracy</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T5.2.9.5.2"><span class="ltx_text" id="S6.T5.2.9.5.2.1" style="font-size:90%;">(TP + TN) / (P + N)</span></th>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.9.5.3"><span class="ltx_text" id="S6.T5.2.9.5.3.1" style="font-size:90%;">0.9375</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S6.T5.2.9.5.4"><span class="ltx_text" id="S6.T5.2.9.5.4.1" style="font-size:90%;">0.7969</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.2.10.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r" id="S6.T5.2.10.6.1"><span class="ltx_text" id="S6.T5.2.10.6.1.1" style="font-size:90%;">F1 Score</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S6.T5.2.10.6.2"><span class="ltx_text" id="S6.T5.2.10.6.2.1" style="font-size:90%;">2TP / (2TP + FP + FN)</span></th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S6.T5.2.10.6.3"><span class="ltx_text" id="S6.T5.2.10.6.3.1" style="font-size:90%;">0.9375</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S6.T5.2.10.6.4"><span class="ltx_text" id="S6.T5.2.10.6.4.1" style="font-size:90%;">0.6216</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">These values can be calculated using the values of TP, TN, FP, and FN as shown in Table <a class="ltx_ref" href="#S6.T4" title="Table 4 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">4</span></a>. Table <a class="ltx_ref" href="#S6.T5" title="Table 5 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">5</span></a> also shows the expressions of the corresponding metrics. The Sensitivity is more important than other metrics for any medical classification problem like human fall detection. The values of sensitivity are 0.9375, and 0.9167 for GMDCSA and URFD respectively. These values are good enough for a lightweight system. The specificity for GMDCSA is 0.9375 whereas for URFD it is 0.7250. The performance of our model is better using the GMDCSA dataset than the URFD dataset. This may be because the ADL activities of URFD contained many complex falls-like activities. Some of these activities were classified wrongly as falls by our system.</p>
</div>
<figure class="ltx_figure" id="S6.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="478" id="S6.F4.sf1.g1" src="extracted/5327693/FG/GA04_21_2.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F4.sf1.3.2" style="font-size:90%;">ADL (04)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="476" id="S6.F4.sf2.g1" src="extracted/5327693/FG/GA07_21_2.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F4.sf2.3.2" style="font-size:90%;">ADL (07)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="478" id="S6.F4.sf3.g1" src="extracted/5327693/FG/UA14_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S6.F4.sf3.3.2" style="font-size:90%;">ADL (14)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F4.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="493" id="S6.F4.sf4.g1" src="extracted/5327693/FG/GF03_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf4.2.1.1" style="font-size:90%;">(d)</span> </span><span class="ltx_text" id="S6.F4.sf4.3.2" style="font-size:90%;">Fall (03)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F4.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="488" id="S6.F4.sf5.g1" src="extracted/5327693/FG/UF12_2_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf5.2.1.1" style="font-size:90%;">(e)</span> </span><span class="ltx_text" id="S6.F4.sf5.3.2" style="font-size:90%;">Fall (12)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F4.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="489" id="S6.F4.sf6.g1" src="extracted/5327693/FG/UF14_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf6.2.1.1" style="font-size:90%;">(f)</span> </span><span class="ltx_text" id="S6.F4.sf6.3.2" style="font-size:90%;">Fall (14)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S6.F5.3.2" style="font-size:90%;">Sample outputs using the GMDCSA dataset</span></figcaption>
</figure>
<figure class="ltx_figure" id="S6.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="448" id="S6.F5.sf1.g1" src="extracted/5327693/FG/ua01_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F5.sf1.3.2" style="font-size:90%;">ADL (01)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="447" id="S6.F5.sf2.g1" src="extracted/5327693/FG/ua12_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F5.sf2.3.2" style="font-size:90%;">ADL (12)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="450" id="S6.F5.sf3.g1" src="extracted/5327693/FG/UA25_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S6.F5.sf3.3.2" style="font-size:90%;">ADL (25)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F5.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="452" id="S6.F5.sf4.g1" src="extracted/5327693/FG/UF01_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf4.2.1.1" style="font-size:90%;">(d)</span> </span><span class="ltx_text" id="S6.F5.sf4.3.2" style="font-size:90%;">Fall (01)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F5.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="449" id="S6.F5.sf5.g1" src="extracted/5327693/FG/UF08_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf5.2.1.1" style="font-size:90%;">(e)</span> </span><span class="ltx_text" id="S6.F5.sf5.3.2" style="font-size:90%;">Fall (08)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S6.F5.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="443" id="S6.F5.sf6.g1" src="extracted/5327693/FG/UF14_2_21.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf6.2.1.1" style="font-size:90%;">(f)</span> </span><span class="ltx_text" id="S6.F5.sf6.3.2" style="font-size:90%;">Fall (14)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S6.F6.3.2" style="font-size:90%;">Sample outputs using the URFD dataset</span></figcaption>
</figure>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1">Some of the sample outputs of this experiment using the GMDCSA and URFD datasets are shown in Figure <a class="ltx_ref" href="#S6.F5" title="Figure 5 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="#S6.F6" title="Figure 6 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">6</span></a> respectively. The captions of the subfigure tell whether the frames are from the ADL sequence or the fall sequence. The number in the brackets of the caption is the file name of the video of the corresponding dataset. Figure <a class="ltx_ref" href="#S6.F5" title="Figure 5 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">5</span></a> shows three sample ADL frames and three fall frames from the GMDCSA dataset video sequences. Similarly, Figure <a class="ltx_ref" href="#S6.F6" title="Figure 6 ‣ 6 Result ‣ Real-Time Human Fall Detection using a Lightweight Pose Estimation Technique"><span class="ltx_text ltx_ref_tag">6</span></a> shows three sample ADL frames and three fall frames from the GMDCSA dataset video sequences.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Scope</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we proposed a lightweight and fast human fall detection system using ‘Movenet Thunder’ pose estimation. Our proposed system is very fast and requires very low computing power. It can run easily in real-time on any low-computing device like mobile, laptop, desktop, etc. All computation is done locally, so it also preserves the privacy of the subject. The metrics are also good enough considering the low computing requirement of the system. The proposed technique gave good results using the GMDCSA dataset. The sensitivity values are good for both datasets. The Movenet pose estimation model is a fast and lightweight model, but its accuracy is moderate. Also, our system can not work for more than one subject at the same time. In the future, we are thinking to improve our system so that it can work in multi-person <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite> environments with high accuracy while maintaining the low computing requirement.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:70%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:70%;">
E. Alam, A. Sufian, P. Dutta, M. Leo, Vision-based human fall detection systems
using deep learning: A review, Computers in Biology and Medicine (2022)
105626.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:70%;">
Z. Wang, V. Ramamoorthy, U. Gal, A. Guez, Possible life saver: A review on
human fall detection technology, Robotics 9 (3) (2020) 55.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:70%;">
J. Gutiérrez, V. Rodríguez, S. Martin, Comprehensive review of
vision-based fall detection systems, Sensors 21 (3) (2021) 947.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:70%;">
E. Alam, A. Sufian, A. K. Das, A. Bhattacharya, M. F. Ali, M. H. Rahman,
Leveraging deep learning for computer vision: A review, in: 2021 22nd
International Arab Conference on Information Technology (ACIT), IEEE, 2021,
</span><span class="ltx_text" id="bib.bib4.2.2" style="font-size:70%;">pp. 1–8.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:70%;">
X. Wang, J. Ellul, G. Azzopardi, Elderly fall detection systems: A literature
survey, Frontiers in Robotics and AI 7 (2020) 71.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:70%;">
T. L. Munea, Y. Z. Jembre, H. T. Weldegebriel, L. Chen, C. Huang, C. Yang, The
progress of human pose estimation: a survey and taxonomy of models applied in
2d human pose estimation, IEEE Access 8 (2020) 133330–133348.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:70%;">
Y. Chen, Y. Tian, M. He, Monocular human pose estimation: A survey of deep
learning-based methods, Computer Vision and Image Understanding 192 (2020)
102897.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:70%;">
R. Bajpai, D. Joshi, Movenet: A deep neural network for joint profile
prediction across variable walking speeds and slopes, IEEE Transactions on
Instrumentation and Measurement 70 (2021) 1–11.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:70%;">
MoveNet: Ultra fast and accurate pose detection model. — TensorFlow
Hub — tensorflow.org,
</span><a class="ltx_ref ltx_url" href="https://www.tensorflow.org/hub/tutorials/movenet" style="font-size:70%;" title="">https://www.tensorflow.org/hub/tutorials/movenet</a><span class="ltx_text" id="bib.bib9.2.2" style="font-size:70%;">, [Accessed
</span><span class="ltx_text" id="bib.bib9.3.3" style="font-size:70%;">21-Oct-2022].
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:70%;">
A. Sufian, E. Alam, A. Ghosh, F. Sultana, D. De, M. Dong, Deep learning in
computer vision through mobile edge computing for iot, in: Mobile Edge
Computing, Springer, 2021, pp. 443–471.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:70%;">
U. Asif, S. Von Cavallar, J. Tang, S. Harrer, Sshfd: Single shot human fall
detection with occluded joints resilience, arXiv preprint arXiv:2004.00797
(2020).
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:70%;">
Z. Chen, Y. Wang, W. Yang, Video based fall detection using human poses, in:
CCF Conference on Big Data, Springer, 2022, pp. 283–296.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:70%;">
A. Apicella, L. Snidaro, Deep neural networks for real-time remote fall
detection, in: International Conference on Pattern Recognition, Springer,
2021, pp. 188–201.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:70%;">
G. V. Leite, G. P. da Silva, H. Pedrini, Three-stream convolutional neural
network for human fall detection, in: Deep Learning Applications, Volume 2,
Springer, 2021, pp. 49–80.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:70%;">
Z. Cao, T. Simon, S.-E. Wei, Y. Sheikh, Realtime multi-person 2d pose
estimation using part affinity fields, in: Proceedings of the IEEE conference
on computer vision and pattern recognition, 2017, pp. 7291–7299.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:70%;">
T. Chen, Z. Ding, B. Li, Elderly fall detection based on improved yolov5s
network, IEEE Access 10 (2022) 91273–91282.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:70%;">
Ultralytics, Yolov5, </span><a class="ltx_ref ltx_url" href="https://github.com/ultralytics/yolov5" style="font-size:70%;" title="">https://github.com/ultralytics/yolov5</a><span class="ltx_text" id="bib.bib17.2.2" style="font-size:70%;">, [Accessed
14-Jan-2023].
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:70%;">
W. Liu, X. Liu, Y. Hu, J. Shi, X. Chen, J. Zhao, S. Wang, Q. Hu, Fall detection
for shipboard seafarers based on optimized blazepose and lstm, Sensors
22 (14) (2022) 5449.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:70%;">
D. R. Beddiar, M. Oussalah, B. Nini, Fall detection using body geometry and
human pose estimation in video sequences, Journal of Visual Communication and
Image Representation 82 (2022) 103407.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:70%;">
</span><span class="ltx_text" id="bib.bib20.2.2" style="font-size:70%;">M. Amsaprabhaa, et al., Multimodal spatiotemporal skeletal kinematic gait
feature fusion for vision-based fall detection, Expert Systems with
Applications 212 (2023) 118681.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:70%;">
B. Kwolek, M. Kepski, Human fall detection on embedded platform using depth
maps and wireless accelerometer, Computer methods and programs in biomedicine
117 (3) (2014) 489–501.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:70%;">
M. Kocabas, S. Karagoz, E. Akbas, Multiposenet: Fast multi-person pose
estimation using pose residual network, in: Proceedings of the European
conference on computer vision (ECCV), 2018, pp. 417–433.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jan  3 07:28:59 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
